quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Deployability,"This release fixes several bugs when using HttpPath resolve methods that have been affecting users. In particular, they were causing issues when trying to construct HTTP URIs for companion files such as fasta/bam indices.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8889:5,release,release,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8889,1,['release'],['release']
Deployability,This release potentially fixes a bug that the SV team (specifically @SHuang-Broad) encountered.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2277:5,release,release,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2277,1,['release'],['release']
Deployability,"This replaces a secret that requires a pr to fix, and updates the name of one of the others.; Requires 1 more step after this.; * Switch travis variable name from DOCKER_SERVICE_PASS -> DOCKER_SERVICE_TOKEN for clarity; * Replace gcloud encrypted key",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7521:54,update,updates,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7521,1,['update'],['updates']
Deployability,"This request was created from a contribution made by Duo Xie on August 20, 2022 16:16 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/8235601014427-Issue-when-running-BaseRecalibrator](https://gatk.broadinstitute.org/hc/en-us/community/posts/8235601014427-Issue-when-running-BaseRecalibrator). \--. REQUIRED for all errors and issues: ; ; a) GATK version used:v4.2.6.1  ; ; b) Exact command used: see below ; ; c) Entire program log: see below ; ; **How can I assign a temp directory and won't get the bug?**. I always got error when I assigned the temp directory:. /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx8G -Djava.io.tmpdir=/data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/shell/temp"" BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz  -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test.table ; ; Using GATK jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar ; ; Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx8G -Djava.io.tmpdir=/data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/shell/temp -jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --know",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:610,pipeline,pipeline,610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,2,['pipeline'],['pipeline']
Deployability,"This request was created from a contribution made by Min-Hwan Sohn on March 05, 2020 01:00 UTC. Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360057956031-PathseqPipelineSpark-stop-with-error-message-regarding-com-esotericsoftware-kryo-KryoException-Buffer-underflow-. --. Hi GATK team. I recently used PathseqPipelineSpark embedded in GATK v4.1.4.1 (installed from anaconda) to identify potential microbial composition of human tissue Whole-Genome samples. . NovaSeq-sequenced paired-end reads (2X151bp) were aligned (onto hg19 reference), duplicate-removed, base quality score-recalibrated and BQSR-applied, which eventually used as an input to the PathseqPipelineSpark. . Since I failed to find hg19 host reference in the GATK resource bundle, first I created a BWA image file and a Kmer file originated from hg19 reference fasta with the command below. But for microbe-related files, I used ones that were contained in the bundle.  . **'''** ; ; **gatk --java-options ""-Xmx50G"" BwaMemIndexImageCreator -I ./ref.fasta** ; **gatk --java-options ""-Xmx50G"" PathSeqBuildKmers --reference ./ref.fasta -O ref.hss** ; ; **'''**.  . And then I ran PathSeq with the following command.  . **'''** ; ; **gatk --java-options ""-Xmx200G"" PathSeqPipelineSpark \** ; **--input sample.bam \** ; **--filter-bwa-image ref.fasta.img \** ; **--kmer-file ref.hss \** ; **--is-host-aligned true \** ; **--min-clipped-read-length 70 \** ; **--microbe-fasta pathseq\_microbe.fa \** ; **--microbe-bwa-image pathseq\_microbe.fa.img \** ; **--taxonomy-file pathseq\_taxonomy.db \** ; **--output sample.pathseq.bam \** ; **--scores-output sample.pathseq.txt** ; ; ; **'''**.  . and unfortunately it was shut down by this error message. **09:27:43.974 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/mnt/clinix1/Analysis/mongol/phenomata/Tools/Anaconda3/envs/gatk4/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so** ; **Mar 05, 2020 9:27",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:368,install,installed,368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['install'],['installed']
Deployability,"This requires a Barclay upgrade (that is not yet published) since most of the basic WDL generation code is in Barclay. WDL is only generated for tools that are annotated with @RuntimeProperties, and that have input/output files arguments that are annotated with@WorkflowResource. For each WDL generated, an accompanying JSON input file is generated that contains all the tool's arguments, with the optional arguments initialized to the tool's default values, and the required args initialized to a string that describes the required type. A temporary commit that contains a sample WDL/JSON generated by the WDL gen task in included to make it easier to see the WDL that results. The only commits in this branch that are directly WDL-gen related are the [WDL Gen](https://github.com/broadinstitute/gatk/pull/6504/commits/ffbd6ce5751924c76785c09baa3be04e37b7b3ac) commit itself, and the [sample output](https://github.com/broadinstitute/gatk/pull/6504/commits/ffbd6ce5751924c76785c09baa3be04e37b7b3ac) commit. The other commits are either related to GATKPathSpecifier migration (not required for WDL gen) or Barclay upgrade migration (required for WDL gen).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6504:24,upgrade,upgrade,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6504,2,['upgrade'],['upgrade']
Deployability,"This requires a Barclay upgrade (that is not yet published) since most of the basic WDL generation code is in Barclay. WDL is only generated for tools that are annotated with `@RuntimeProperties`, and that have input/output files arguments that are annotated with`@WorkflowResource`. For each WDL generated, an accompanying JSON input file is generated that contains all the tool's arguments, with the optional arguments initialized to the tool's default values, and the required args initialized to a string that describes the required type. A temporary commit that contains a sample WDL/JSON generated by the WDL gen task.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6503:24,upgrade,upgrade,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6503,1,['upgrade'],['upgrade']
Deployability,"This requires also a finer control for the codecs, once the configuration-code is implemented, to ignore default packages, and include/exclude single classes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2139#issuecomment-324272895:60,configurat,configuration-code,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2139#issuecomment-324272895,1,['configurat'],['configuration-code']
Deployability,This reverts commit 8a366c7ba570c61338f7109b86c3284b80d5cf47. We noticed a major performance regression in `BaseRecalibratorSpark` and `HaplotypeCallerSpark` after we upgraded our ADAM dependency (see https://github.com/broadinstitute/gatk/issues/4376). This PR reverts that upgrade for now until we understand the underlying cause.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4428:167,upgrade,upgraded,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4428,2,['upgrade'],"['upgrade', 'upgraded']"
Deployability,"This reworks callRegion() as you suggest and removes most other changes originally here. Expected VCFs are updated and it includes the tests I added. I rebased due to a conflict in gvcf.basepairResolution.includeNonVariantSites.vcf. I think the changes in master are merged correctly, but dont know the context around those that well. If you look at the diff, you'll see some changes in includeLowQualSites.vcf. The version on this branch is updated from the GenotypeGVCFs output - do you think the dropping of the LowQual filter is right?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582269090:107,update,updated,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582269090,2,['update'],['updated']
Deployability,"This seems to be caused by an incompatible minor update of a transitive dependency called typing_extensions that is installed as part of pymc3. . The maintainers say that their release shouldn't be picked up by package managers because it contains an instruction to only be used in 3.7+. Our version of conda is picking it up anyway though and apparently doesn't understand their package files. . It's possible upgrading the conda version in the base docker will fix this problem, but as far as I can tell we're using the most recent release of miniconda that supports python 3.6. . Ideally we can peg the version of typing_extensions to 4.1.1 somehow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7800#issuecomment-1104432972:49,update,update,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7800#issuecomment-1104432972,4,"['install', 'release', 'update']","['installed', 'release', 'update']"
Deployability,"This should be an option that you can toggle, but should default to ignoring transcript versions. With the toggle will need to double-check Gencode as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4668#issuecomment-389265736:38,toggle,toggle,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4668#issuecomment-389265736,2,['toggle'],['toggle']
Deployability,"This should be doable, if not in the integration test framework, then in the new testing framework @KevinCLydon is working on.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6013#issuecomment-581493620:37,integrat,integration,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6013#issuecomment-581493620,1,['integrat'],['integration']
Deployability,This should be done after #5688 does in. Some Mutect2 integration tests should be deleted once this is done.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5763:54,integrat,integration,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5763,1,['integrat'],['integration']
Deployability,This should be fixed in the next release as we are now on Picard 2.25.4 in master via #7255. If you need a docker build with an updated picard dependency I would suggest checking out our nightly builds gs://gatk-nightly-builds which should have an up-to-date version of master soon or simply waiting for the next release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7254#issuecomment-841405791:33,release,release,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7254#issuecomment-841405791,6,"['release', 'update']","['release', 'updated']"
Deployability,"This should fix the travis failure by forcing lfs to overwrite the existing commit hooks. The issue seems to be this:. We install lfs in the first part of the travis build, and then we run a docker build and mount the git folder into it. Docker then installs lfs again. The problem is occurring because git lfs 3.1.1 which released 2 days ago changed the format of the pre-push and other git hooks. Then it throws an error when it's installed again and there are hooks that look different than it expects already in place. Running install with `--force` fixes it. The lfs devs actually have a system for ignoring these differences, but they forgot to update their list of allowed differences ( or however they match it) in 3.1.1. They then released 3.1.2 today which fixes this. In most cases this would fix the issue, except the git-lfs installed INSIDE the docker image is on an ancient version and never updates since the ancient image ubuntu is pegged to an out of date one. While the one in travis outside of docker gets updated to the most recent one. So we have to manually force this. We should probably also update our ubuntu image to a newer one. Of note, we don't actually NEED lfs in the docker for the tests at all, since we've already downloaded the files outside of docker and are mounting them in. Here's a passing build where I remove it https://app.travis-ci.com/github/broadinstitute/gatk/builds/246595037. I'm afraid though that some other system depends on it so I don't want to change it. . Rebasing on this should fix the stuck branches. @droazen @jonn-smith @ldgauthier @jamesemery",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7682:122,install,install,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7682,11,"['install', 'release', 'update']","['install', 'installed', 'installs', 'released', 'update', 'updated', 'updates']"
Deployability,This should not be merged before the next release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3680#issuecomment-335514307:42,release,release,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3680#issuecomment-335514307,1,['release'],['release']
Deployability,"This should prevent the confusing case of accidentally corrupting an existing GenomicsDB. The next genomicsDB update is supposed to make this unnecessary, but until it happens lets avoid this problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3975:110,update,update,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3975,1,['update'],['update']
Deployability,"This takes @takutosato's first commit in https://github.com/broadinstitute/gatk/pull/4035 and adds my updates to the PrintReads document, and uses the latest master branch.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4084:102,update,updates,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4084,1,['update'],['updates']
Deployability,"This task has been completed with recent updates to the tie-breaking code, to continue tracking MarkDuplicatesSpark tie out see this branch: #4675",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3705#issuecomment-421426395:41,update,updates,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3705#issuecomment-421426395,1,['update'],['updates']
Deployability,"This test input is malformed. When I try to read it with the Dataflow code, I get this error:. htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *. Here's the corresponding read:. 809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S \* 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?C<E@########## MD:Z:67 PG:Z:BWA RG:Z:809R9.5 AM:i:0 NM:i:0 SM:i:37 MQ:i:0 OQ:Z:DGEGGGGBFGGGGGDF8@@FGFBGGGBGCECCEEDFGGGFGFGGGBDGGF9DBFFGFBF;@>A4@@########## UQ:i:0. @droazen confirms that Picard's ValidateSAMFile utility reports that this bam has multiple errors. We should replace it with a clean input, and update the ""known good"" output accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/568:824,update,update,824,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/568,1,['update'],['update']
Deployability,"This ticket is done -- the tool has physically been run on 11k samples. We still need to move to a new google-cloud-java snapshot/release to fix the intermittent GCS failures, but that is captured by https://github.com/broadinstitute/gatk/issues/3120",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2633#issuecomment-314129844:130,release,release,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2633#issuecomment-314129844,1,['release'],['release']
Deployability,"This ticket set out to do VS-962 (one FOFN to rule them all) only, but along the way I found I also needed to do VS-984 (use Bulk Ingest from integration test) as the interface to `GvsAssignIds` had changed. After making these changes I realized I had basically done VS-982 as well (use Bulk Ingest in Beta WDL) due to the beta WDL picking up the changes to the unified WDL both it and Quickstart call. - [Successful integration run](https://job-manager.dsde-prod.broadinstitute.org/jobs/ab07dffd-a2ea-4b69-9c4c-eec0019e5b3b); - [Pending beta run](https://job-manager.dsde-prod.broadinstitute.org/jobs/37f6be29-5aae-42c4-a86b-c6d00c3caec5)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404:142,integrat,integration,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404,2,['integrat'],['integration']
Deployability,"This ticket was intended as a spike but in the process of spiking I was able to create a peer Hail VDS integration test to the VCF integration test. This seems like a viable candidate for Q4 MVP so putting it out for review as is. This creates a separate integration test for AoU Delta-style Hail VDS outputs with a tieout to regular GVS VCFs. The existing `GvsQuickstartIntegration` WDL has become an ""uber"" integration WDL that by default runs both the VCF and Hail VDS integration tests, but these can be toggled on or off separately with optional boolean inputs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8086:103,integrat,integration,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8086,6,"['integrat', 'toggle']","['integration', 'toggled']"
Deployability,"This tool copies single large files or directories from GCS into HDFS using Spark. Spark parallelization allows each task to copy a chunk in the size of the blocks of the target HDFS system simultaneously. When copying a directory containing a 120GB WGS bam and its index, this takes approximately 1 minute on a 10 worker / 160 core cluster, as opposed to approximately 20 minutes using Hadoop distcp. This may eventually be superseded by the NIO GCS integration work if that ends up performing comparably. @lbergelson would you like to review? Or feel free to nominate someone else.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2540:451,integrat,integration,451,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2540,1,['integrat'],['integration']
Deployability,This tool was part of the legacy CNV pipeline that was deleted in https://github.com/broadinstitute/gatk/pull/3935. @samuelklee can point you to the appropriate replacement tool.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358365117:37,pipeline,pipeline,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358365117,1,['pipeline'],['pipeline']
Deployability,This update means the pipeline won't die on single-ended reads (it just filters them out).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5818:5,update,update,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5818,2,"['pipeline', 'update']","['pipeline', 'update']"
Deployability,"This update of genomicsDB includes the option to not validate the sampleMapFile against the actual headers. Choosing to not validate allows us to save time at the start by not having to open each file on the initial header construction when using --`sampleMapFile`. closes #2713, closes #2714, and closes #2715. It also includes an update to have GenomicsDB capture RSId's by default, (closes #2636) which should make diffs easier on our end at a slight cost of storage size. If that's an issue we may need to revisit the default.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2733#issuecomment-306254281:5,update,update,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2733#issuecomment-306254281,2,['update'],['update']
Deployability,This upgrades Spark Dataflow to the correct version of Dataflow (Spark Dataflow 0.3.0 targets 0.4.150710). This fixes the runtime exception when running Spark tests due to library mismatches.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/785:5,upgrade,upgrades,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/785,1,['upgrade'],['upgrades']
Deployability,This upgrades htsjdk to v3.0.0 which was attempted in #7867 and then reverted in #7960 in order to unblock the jukebox merge.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8025:5,upgrade,upgrades,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8025,1,['upgrade'],['upgrades']
Deployability,"This version can compute on either locally, or on the cloud. There are a few things still on the table: it can't read dbSNP from GCS yet (no point in doing that since the skeleton team's working on the same thing) and it repatriates the recalTables even if the report is meant to be on the cloud (I expect many things to change, so better to do that once things are more stable. Besides, report on the cloud is an edge case, normally we want the textual report on the client's machine. This relies on dataflow-java 0.9; it has now released so we're good.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/529:531,release,released,531,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/529,1,['release'],['released']
Deployability,This was also a GATK3 issue: https://github.com/broadinstitute/gsa-unstable/issues/1624. GQ should be updated to reflect the subset PLs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3404:102,update,updated,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3404,1,['update'],['updated']
Deployability,This was an issue with propagating polymorphic std::exception code from the native library's logger utility and has been fixed in the [1.3.2 release ](https://mvnrepository.com/artifact/org.genomicsdb/genomicsdb/1.3.2) of the GenomicsDB library. Also note that using java option `GATK_STACKTRACE_ON_USER_EXCEPTION` with gatk will also output a C/C++ limited stacktrace as requested by @lbergelson.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6852:141,release,release,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6852,1,['release'],['release']
Deployability,This was done to some extent. Docs are being updated now in https://github.com/broadinstitute/gatk/pull/3937.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2815#issuecomment-350891878:45,update,updated,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2815#issuecomment-350891878,1,['update'],['updated']
Deployability,"This was fixed in #5475 and released in 4.1.0.0. HaplotypeCallerSpark can be run in ""strict"" mode (with the `--strict` flag) to closely match the walker version. Even when not run using strict mode the result is much better than it used to be (closer to the walker version, and shouldn't jitter).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4231#issuecomment-464754012:28,release,released,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4231#issuecomment-464754012,1,['release'],['released']
Deployability,"This was mentioned already as a comment in #562 but it should be an issue instead. BQSR on Dataflow can _theoretically_ avoid the step of saving the textual report, instead piping the recalibration analysis results directly to the ApplyBQSR phase. In practice it cannot, because it turns out that **saving a report and immediately loading it back is not a no-op**. it actually changes in some necessary way. It would be great if someone familiar with that part of the code could help factor the mutation apart from the saving/loading, so I could just call that in the pipeline. This would speed things up a bit and the code would be that much cleaner.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/799:568,pipeline,pipeline,568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/799,1,['pipeline'],['pipeline']
Deployability,This was missed in #7754 ; @droazen I even updated the all important badge...,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7808:43,update,updated,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7808,1,['update'],['updated']
Deployability,This was resolved by a patch to PAPIv1 just released by Google (see https://partnerissuetracker.corp.google.com/issues/112704449). Closing!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-415867155:23,patch,patch,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-415867155,2,"['patch', 'release']","['patch', 'released']"
Deployability,"This will be fixed once https://github.com/googleapis/google-auth-library-java/pull/214 is incorporated into gatk, but we're waiting on another release of the google auth library and then the nio library which might take a bit.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-449468992:144,release,release,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-449468992,1,['release'],['release']
Deployability,This will provide a temporary fix for https://github.com/broadinstitute/gatk/issues/2793 so that we can release beta,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3118:104,release,release,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3118,1,['release'],['release']
Deployability,"This will seemingly make the clinical pipeline data sources so large they are completely unusable. Gnomad data for the whole genome is apparently **106Gb**, exome data is **16Gb** (this would be OK, but is at the upper limit) (http://gnomad.broadinstitute.org/downloads). @LeeTL1220 - what are your thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5259#issuecomment-430327508:38,pipeline,pipeline,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5259#issuecomment-430327508,1,['pipeline'],['pipeline']
Deployability,"Those sound like issues with the IndelRealigner tool from GATK3, which is; not part of our pipeline anymore. Is this still a problem with 4.1.4.1?. On Wed, Feb 19, 2020, 1:00 AM Dario Strbenac <notifications@github.com>; wrote:. > In the news file of a structural variant software I use, I read; >; > Added FIX_SA and FIX_MISSING_HARD_CLIP; > FIX_SA: rewrites split read SA tags; > corrects GATK indel realignment SA tag data inconsistency; > FIX_MISSING_HARD_CLIP: infers missing hard clipping if split read records; > have different lengths; > corrects for GATK indel realignment stripping hard clipping when realigning; >; > Could such issues perhaps be resolved in an update to GATK?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6459?email_source=notifications&email_token=ABSGC5E7CIUF53HYCPS76FDRDTDHBA5CNFSM4KXSMK22YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4IOQ3U6A>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABSGC5DYKL5KH6EZS5ZU66DRDTDHBANCNFSM4KXSMK2Q>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6459#issuecomment-588488049:91,pipeline,pipeline,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6459#issuecomment-588488049,2,"['pipeline', 'update']","['pipeline', 'update']"
Deployability,"Three major changes here.; 1. Added in logic to create the ploidy table during ingest (with necessary supporting class) and use it during extract automatically as part of the default joint workflow. Also removed a column that we won't need when creating it automatically.; 2. Rearranged the PAR checking logic to consolidate it in its own class (PloidyUtils.java). Successful run against tiny sample set ""PLOIDY_TEST"" in echo callset project:. https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20WGS%20Echo%20Callset%20v2/job_history/a93aa2ef-9cef-451d-8cf8-b31f1c6a8407. You'll need your aou credentials to see the results. Successful integration run on XY:; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/6a9a5fdf-ffaa-4dcb-af73-56a4b25e69a4. This run shows all of the OTHER integration tests running successfully except BGE, due to the test data needing an updates for BGE X and Y:; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/21664810-7516-49f2-a60c-51b2e05faf06. The only difference between those two tests running was an update to the expected values for integration tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8994:650,integrat,integration,650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8994,5,"['integrat', 'update']","['integration', 'update', 'updates']"
Deployability,Throttling integration test [VS-1076],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8545:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8545,1,['integrat'],['integration']
Deployability,"Ticks off a few straggler issues noted in #7724. @meganshand mind reviewing? Hopefully should be quick and we can get it in before @droazen cuts the next release. Note that this shouldn't change behavior in the Ultima pipeline, as the default toggle is still the same start-position resource-matching strategy inherited from VQSR, but we might want to explore the effect of choosing another strategy there.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8049:154,release,release,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8049,3,"['pipeline', 'release', 'toggle']","['pipeline', 'release', 'toggle']"
Deployability,"To add, just in case it wasn't clear, note that this is almost certainly overkill for most somatic applications. However, if this is going to double as a more lightweight germline pipeline (as it is for the time being, as we are using some of the results to prototype SV integration), it might be worthwhile.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386269562:180,pipeline,pipeline,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386269562,4,"['integrat', 'pipeline']","['integration', 'pipeline']"
Deployability,"To clarify our experimental setup: for the benchmark we are using the latest release (v.1.2) somatic ""ground truth"" of the HCC1395 cell line from . [https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/seqc/Somatic_Mutation_WG/release/latest/](https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/seqc/Somatic_Mutation_WG/release/latest/). It contains ~40k SNVs and ~2k INDELs in ~2.4Gb high-confidence regions.; In high-confidence regions intersected with WES bed, we still have ~1.1k SNVs and ~100 INDELs. Therefore, even in the WES analysis scenario, the SNV counts should be high enough to draw reliable conclusions when comparing performance between different callers and releases.; For WES INDELs, the counts are indeed rather low and results should be interpreted with caution.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1172101032:77,release,release,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1172101032,4,['release'],"['release', 'releases']"
Deployability,"To clarify what needs to be done here:. -Add a new `--javaOptions` argument to `gatk-launch`. -When running with a packaged local jar, the value of `--javaOptions` should be injected into the command line built by `formatLocalJarCommand()`. -When running with the ""wrapper script"" (as a result of building with `./gradlew installDist` instead of `./gradlew localJar`), propagate the value of `--javaOptions` to the `JAVA_OPTS` environment variable the wrapper script expects. You can inspect the wrapper script itself by running `./gradlew installDist` and then examining `build/install/gatk/bin/gatk`. -When running on Spark, you'll need to add the `--javaOptions` to `spark.driver.extraJavaOptions` and `spark.executor.extraJavaOptions`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2694#issuecomment-305007868:322,install,installDist,322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2694#issuecomment-305007868,3,['install'],"['install', 'installDist']"
Deployability,"To clarify, the tests are being run. It appears to be a bug in how we have configured the jacocoTestReport job that gets executed inside the docker image which seems to result some missing xml files that codeCoverage uses to build its reports. Since we have our integration and cloud tests outside of the docker image the coverage didn't drop to zero. I am looking into reconfiguring the jacocoTestReport task to behave correctly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5001#issuecomment-404629551:262,integrat,integration,262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5001#issuecomment-404629551,1,['integrat'],['integration']
Deployability,"To phrase it another way, you imported the new program group, but you didn't update the `programGroup = ` line in the `CommandLineProgramProperties` to refer to it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4673#issuecomment-382458425:77,update,update,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4673#issuecomment-382458425,1,['update'],['update']
Deployability,"To reiterate, for me, GenotypeGVCFs 4.2.4.1 gives an ```IllegalStateException``` at the exact same place regardless of whether I run GenomicsDBImport 4.2.4.0 (with the 50 max allele bug) or GenomicsDBImport 4.2.4.1 (with the fix to respect 6 max alleles). As far as I can tell, the ```IllegalStateException``` has nothing to do with GenomicsDBImport, it's simply a new bug in GenotypeGVCFs 4.2.4.1 that happens to occur when the number of ALT alleles is 1 more than the limit set in GenotypeGVCFs. As @mlathara stated: ""the AF calculation [in GenotypeGVCFs] used to [in 4.2.4.0] ignore sites if they didn't have likelihoods, but has now been updated slightly [in 4.2.4.1] to also allow sites with GQ or sites where any alleles are called+nonref+not symbolic. The stack traces above show the AlleleFrequencyCalculator as the culprit:; ```; java.lang.IllegalStateException: Genotype [T199970 ATATATAT/T GQ 49 DP 4 AD 0,2,0,0,0,2,0,0 {SB=0,0,2,2}] does not contain likelihoods necessary to calculate posteriors.; 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.log10NormalizedGenotypePosteriors(AlleleFrequencyCalculator.java:89); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.effectiveAlleleCounts(AlleleFrequencyCalculator.java:258); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.calculate(AlleleFrequencyCalculator.java:141); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023545370:642,update,updated,642,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023545370,2,['update'],['updated']
Deployability,To remove warning about unfound logger.; Also updated latest version in gatk; Updated to latest version of gatk in wdls.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7774:46,update,updated,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7774,2,"['Update', 'update']","['Updated', 'updated']"
Deployability,"To support running CARROT tests from PR comments, it's necessary that the [carrot-publish-github-action ](https://github.com/broadinstitute/carrot-publish-github-action) be integrated following the instructions in the README for that repo, so that PR comments will be processed by the GitHub action. This also requires that secrets be set for the pubsub topic and SA key for sending the messages.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6916:173,integrat,integrated,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6916,1,['integrat'],['integrated']
Deployability,"To the question on building it: I guess it isnt really a problem with your build per-se, but rather it seems to make a variety of assumptions or requirements on the environment that were difficult to replicate on our cluster (where i lack admin privs). Using your docker image was the faster way i could find to replicate the needed environment. Issues I hit included: 1) needed git lfs installed (on cluster i lack sudo/apt access), 2) gradle complained about building on the lustre filesystem, so i needed to move to other disks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042026487:387,install,installed,387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042026487,1,['install'],['installed']
Deployability,"To update:. Chris and I just tested copying the bam and indices (3 files) from `gs://broad-dsde-methods-sv/samples/G94797_CHM_MIX/WGS1` (note that Chris reports it works on this bucket) to a just-created ""directory"" `gs://broad-dsde-methods-sv/samples/G94797_CHM_MIX/WGS1/tmp`, and it fails. Also an interested behavior we noticed, and a suspicion that is hard to test (due to lack of access to time machine), that this might be related when the ""directory"" is created: any directory freshly created after October 2018 might be susceptible to this, which is also the month when newer (>66) release of NIO became available.; In the mean time, if one does ; `gsutil ls -L gs://broad-dsde-methods-sv/samples/G94797_CHM_MIX/WGS1`; you'd get, at the last line, `TOTAL: 3 objects`, which is expected, whereas if one does; `gsutil ls -L gs://broad-dsde-methods-sv/samples/G94797_CHM_MIX/WGS1/tmp`; guess what: `TOTAL: 4 objects`!; It seems to list the ""directory"" itself as an object as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-491969032:3,update,update,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-491969032,2,"['release', 'update']","['release', 'update']"
Deployability,"To upgrade ApplyBQSR for cloud execution I had to:. (i) change the input to remove reads with the unaligned flag; (ii) load the recalibration report from GCS instead of shipping it as a serialized object, because Dataflow explodes if we ship too much (error is: ""malformed JSON"").; (iii) for the case of a remote execution with a local output file name, add logic to copy the output via GCS to the client's machine.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/595:3,upgrade,upgrade,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/595,1,['upgrade'],['upgrade']
Deployability,Tool.getReads(GATKSparkTool.java:212); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.runTool(MarkDuplicatesSpark.java:68); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:111); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:169); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:218); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.NullPointerException; 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:184); 	... 21 more; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [dee81497-fad3-4d70-a33e-68a5d5584d9a] entered state [ERROR] while waiting for [DONE].; ```. I'm not sure if it's a jenkins problem or a real regression but we need to investigate it either way.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2449:2232,deploy,deploy,2232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2449,6,['deploy'],['deploy']
Deployability,"Tool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.NoSuchFileException: /user/yaron/output.bam.parts/_SUCCESS: Unable to find _SUCCESS file; at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:53); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:152); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:250); ... 18 more; ```; However, I can find that _SUCCESS file exists in output.bam.parts. Could someone tell me what may be the cause? Thanks!; ```; $ hdfs dfs -ls outp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:6086,deploy,deploy,6086,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['deploy'],['deploy']
Deployability,Tool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:743); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)Caused by: java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2722); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1565); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2227); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2151); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2009); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1533); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:420); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:9872,deploy,deploy,9872,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['deploy'],['deploy']
Deployability,Tool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:233); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:5645,deploy,deploy,5645,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,1,['deploy'],['deploy']
Deployability,Tool.java:387); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.Contai,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:43513,deploy,deploy,43513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['deploy'],['deploy']
Deployability,Tool.java:387); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.Contai,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:44259,deploy,deploy,44259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['deploy'],['deploy']
Deployability,Tool.java:387); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:153); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:277); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.GATKException: Erred when inferring breakpoint location and event type from chimeric alignment:; asm010450:tig00000 1_189_chrUn_JTFH01000312v1_decoy:663-851_-_189M512H_60_8_149_O 153_701_chrUn_JTFH01000312v1_decoy:1-549_+_152S549M_60_0_549_O; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignmentsSAMSpark.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePip,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:11332,deploy,deploy,11332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['deploy'],['deploy']
Deployability,"Tool.java:470); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(I",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:17343,deploy,deploy,17343,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['deploy'],['deploy']
Deployability,"Tools, filters and annotations for mitochondria pipeline",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193:48,pipeline,pipeline,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193,1,['pipeline'],['pipeline']
Deployability,Towards updates:. - CalculateGenotypePosteriors tooldoc (v4.0.12.0) commentable GoogleDoc: https://docs.google.com/document/d/1Ab8YGOCnTtT6Dapx8-wReDi-6E6NJ_FRbEOjWtll7hw/edit?usp=sharing; - Article#11074 commentable GoogleDoc:; https://docs.google.com/document/d/1si-XASjYRXpF7kCj1Ivw40-UOyOQ5uTYTDJx1JlQr6w/edit?usp=sharing,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-454559871:8,update,updates,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-454559871,1,['update'],['updates']
Deployability,Trailing SNP sites and depth intervals without read coverage were being omitted from the output.; Integration tests have been updated to test that this revision solves that problem.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8045:98,Integrat,Integration,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8045,2,"['Integrat', 'update']","['Integration', 'updated']"
Deployability,"TrainVariantAnnotationsModel:. Trains a model for scoring variant calls based on site-level annotations. TODOs:. - [x] Integration tests. Exact-match tests for (non-exhaustive) configurations given by the Cartesian product of the following options:; * non-allele-specific vs. allele-specific; * SNP-only vs. SNP+INDEL (for both of these options, we use extracted annotations that contain both SNP and INDEL variants as input); * positive (training with *.annot.hdf5) vs. positive-unlabeled (training with *.annot.hdf5 and *.unlabeled.annot.hdf5); * Java Bayesian Gaussian Mixture Model (BGMM) backend vs. python sklearn IsolationForest backend; (BGMM tests to be added once PR for the backend goes in.); - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs.; - [x] Parameter/mode validation.; - [x] Refactor main code block for model training; it's a bit monolithic and procedural now.; - [x] Decide on behavior for ill-behaved annotations. E.g., all missing, zero variance. Future work:. - [ ] We could allow subsetting of annotations here, which might allow for easier treatment of ill-behaved annotations. However, I'd say enabling workflows where the set of annotations is fixed is the priority.; - [ ] We could do positive-unlabeled training more rigorously or iteratively. Right now, we essentially do a single iteration to determine negative data. This could perhaps be preceded by a round of refactoring to clean up model training and make it less procedural.; - [ ] Automatic threshold tuning could be built into the tool, see #7711. We'd probably have to introduce a ""validation"" label. Perhaps it makes sense to keep this sort of thing at the workflow level?; - [ ] In the positive-negative framework enforced by the Java code in this tool, a ""model"" is anything that assigns a score, we fit two models to different subsets of the data, and then take the difference of the two scores. While the python backend does give some freedom to specify a model, future developers may want",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369:119,Integrat,Integration,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369,2,"['Integrat', 'configurat']","['Integration', 'configurations']"
Deployability,"Travis [updated](https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/) the trusty images last night (seems to be ok so far). They also added a new update schedule and a new [group](https://blog.travis-ci.com/2017-12-01-new-update-schedule-for-linux-build-images) declaration. The default appears to be ""stability ensured"", but this adds an explicit declaration for that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3953:8,update,updated,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3953,4,['update'],"['update', 'update-schedule-for-linux-build-images', 'updated', 'updates']"
Deployability,Travis reported job failures from build [27940](https://travis-ci.com/broadinstitute/gatk/builds/135299602); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [27940.1](https://travis-ci.com/broadinstitute/gatk/jobs/253708933) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27940.1/tests/test/index.html) |; | cloud | openjdk11 | [27940.14](https://travis-ci.com/broadinstitute/gatk/jobs/253708946) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27940.14/tests/test/index.html) |; | integration | oraclejdk8 | [27940.11](https://travis-ci.com/broadinstitute/gatk/jobs/253708943) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27940.11/tests/test/index.html) |; | integration | openjdk11 | [27940.12](https://travis-ci.com/broadinstitute/gatk/jobs/253708944) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27940.12/tests/test/index.html) |; | integration | openjdk8 | [27940.2](https://travis-ci.com/broadinstitute/gatk/jobs/253708934) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27940.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550409459:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550409459,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [27949](https://travis-ci.com/broadinstitute/gatk/builds/135327240); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [27949.11](https://travis-ci.com/broadinstitute/gatk/jobs/253773862) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27949.11/tests/test/index.html) |; | integration | openjdk11 | [27949.12](https://travis-ci.com/broadinstitute/gatk/jobs/253773863) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27949.12/tests/test/index.html) |; | integration | openjdk8 | [27949.2](https://travis-ci.com/broadinstitute/gatk/jobs/253773853) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27949.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550484410:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550484410,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [27951](https://travis-ci.com/broadinstitute/gatk/builds/135328116); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [27951.11](https://travis-ci.com/broadinstitute/gatk/jobs/253775865) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27951.11/tests/test/index.html) |; | integration | openjdk11 | [27951.12](https://travis-ci.com/broadinstitute/gatk/jobs/253775866) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27951.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550488826:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550488826,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [27953](https://travis-ci.com/broadinstitute/gatk/builds/135328325); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [27953.12](https://travis-ci.com/broadinstitute/gatk/jobs/253776493) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27953.12/tests/test/index.html) |; | integration | oraclejdk8 | [27953.11](https://travis-ci.com/broadinstitute/gatk/jobs/253776492) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27953.11/tests/test/index.html) |; | integration | openjdk8 | [27953.2](https://travis-ci.com/broadinstitute/gatk/jobs/253776483) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27953.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550488386:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550488386,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [27955](https://travis-ci.com/broadinstitute/gatk/builds/135328649); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [27955.11](https://travis-ci.com/broadinstitute/gatk/jobs/253777172) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27955.11/tests/test/index.html) |; | integration | openjdk11 | [27955.12](https://travis-ci.com/broadinstitute/gatk/jobs/253777173) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27955.12/tests/test/index.html) |; | integration | openjdk8 | [27955.2](https://travis-ci.com/broadinstitute/gatk/jobs/253777162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27955.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550487300:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550487300,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [27983](https://travis-ci.com/broadinstitute/gatk/builds/135478554); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [27983.11](https://travis-ci.com/broadinstitute/gatk/jobs/254104520) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27983.11/tests/test/index.html) |; | integration | openjdk11 | [27983.12](https://travis-ci.com/broadinstitute/gatk/jobs/254104521) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27983.12/tests/test/index.html) |; | integration | openjdk8 | [27983.2](https://travis-ci.com/broadinstitute/gatk/jobs/254104511) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27983.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-551166492:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-551166492,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28043](https://travis-ci.com/broadinstitute/gatk/builds/137035017); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28043.11](https://travis-ci.com/broadinstitute/gatk/jobs/257824467) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28043.11/tests/test/index.html) |; | integration | openjdk11 | [28043.12](https://travis-ci.com/broadinstitute/gatk/jobs/257824468) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28043.12/tests/test/index.html) |; | integration | openjdk8 | [28043.2](https://travis-ci.com/broadinstitute/gatk/jobs/257824445) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28043.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-555111252:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-555111252,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28083](https://travis-ci.com/broadinstitute/gatk/builds/137456935); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28083.11](https://travis-ci.com/broadinstitute/gatk/jobs/258764558) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28083.11/tests/test/index.html) |; | integration | openjdk11 | [28083.12](https://travis-ci.com/broadinstitute/gatk/jobs/258764559) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28083.12/tests/test/index.html) |; | integration | openjdk8 | [28083.2](https://travis-ci.com/broadinstitute/gatk/jobs/258764549) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28083.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-556381618:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-556381618,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28122](https://travis-ci.com/broadinstitute/gatk/builds/137698341); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [28122.4](https://travis-ci.com/broadinstitute/gatk/jobs/259308339) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.4/tests/test/index.html) |; | cloud | openjdk8 | [28122.1](https://travis-ci.com/broadinstitute/gatk/jobs/259308336) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.1/tests/test/index.html) |; | cloud | openjdk11 | [28122.14](https://travis-ci.com/broadinstitute/gatk/jobs/259308349) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.14/tests/test/index.html) |; | unit | openjdk11 | [28122.13](https://travis-ci.com/broadinstitute/gatk/jobs/259308348) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.13/tests/test/index.html) |; | integration | oraclejdk8 | [28122.11](https://travis-ci.com/broadinstitute/gatk/jobs/259308346) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.11/tests/test/index.html) |; | unit | openjdk8 | [28122.3](https://travis-ci.com/broadinstitute/gatk/jobs/259308338) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.3/tests/test/index.html) |; | integration | openjdk11 | [28122.12](https://travis-ci.com/broadinstitute/gatk/jobs/259308347) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.12/tests/test/index.html) |; | integration | openjdk8 | [28122.2](https://travis-ci.com/broadinstitute/gatk/jobs/259308337) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557361260:1052,integrat,integration,1052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557361260,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28130](https://travis-ci.com/broadinstitute/gatk/builds/137807694); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [28130.1](https://travis-ci.com/broadinstitute/gatk/jobs/259581190) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.1/tests/test/index.html) |; | cloud | openjdk11 | [28130.14](https://travis-ci.com/broadinstitute/gatk/jobs/259581203) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.14/tests/test/index.html) |; | variantcalling | openjdk8 | [28130.4](https://travis-ci.com/broadinstitute/gatk/jobs/259581193) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.4/tests/test/index.html) |; | integration | oraclejdk8 | [28130.11](https://travis-ci.com/broadinstitute/gatk/jobs/259581200) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.11/tests/test/index.html) |; | integration | openjdk11 | [28130.12](https://travis-ci.com/broadinstitute/gatk/jobs/259581201) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.12/tests/test/index.html) |; | integration | openjdk8 | [28130.2](https://travis-ci.com/broadinstitute/gatk/jobs/259581191) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557639788:845,integrat,integration,845,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557639788,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28139](https://travis-ci.com/broadinstitute/gatk/builds/137849676); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28139.13](https://travis-ci.com/broadinstitute/gatk/jobs/259674809) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.13/tests/test/index.html) |; | integration | oraclejdk8 | [28139.11](https://travis-ci.com/broadinstitute/gatk/jobs/259674807) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.11/tests/test/index.html) |; | integration | openjdk11 | [28139.12](https://travis-ci.com/broadinstitute/gatk/jobs/259674808) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.12/tests/test/index.html) |; | variantcalling | openjdk8 | [28139.4](https://travis-ci.com/broadinstitute/gatk/jobs/259674800) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.4/tests/test/index.html) |; | unit | openjdk8 | [28139.3](https://travis-ci.com/broadinstitute/gatk/jobs/259674799) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.3/tests/test/index.html) |; | integration | openjdk8 | [28139.2](https://travis-ci.com/broadinstitute/gatk/jobs/259674798) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557713113:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557713113,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28143](https://travis-ci.com/broadinstitute/gatk/builds/137902492); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28143.11](https://travis-ci.com/broadinstitute/gatk/jobs/259801266) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28143.11/tests/test/index.html) |; | unit | openjdk11 | [28143.13](https://travis-ci.com/broadinstitute/gatk/jobs/259801268) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28143.13/tests/test/index.html) |; | integration | openjdk11 | [28143.12](https://travis-ci.com/broadinstitute/gatk/jobs/259801267) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28143.12/tests/test/index.html) |; | unit | openjdk8 | [28143.3](https://travis-ci.com/broadinstitute/gatk/jobs/259801258) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28143.3/tests/test/index.html) |; | integration | openjdk8 | [28143.2](https://travis-ci.com/broadinstitute/gatk/jobs/259801257) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28143.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557830936:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557830936,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28145](https://travis-ci.com/broadinstitute/gatk/builds/137904160); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28145.13](https://travis-ci.com/broadinstitute/gatk/jobs/259805318) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28145.13/tests/test/index.html) |; | integration | oraclejdk8 | [28145.11](https://travis-ci.com/broadinstitute/gatk/jobs/259805316) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28145.11/tests/test/index.html) |; | integration | openjdk11 | [28145.12](https://travis-ci.com/broadinstitute/gatk/jobs/259805317) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28145.12/tests/test/index.html) |; | unit | openjdk8 | [28145.3](https://travis-ci.com/broadinstitute/gatk/jobs/259805308) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28145.3/tests/test/index.html) |; | integration | openjdk8 | [28145.2](https://travis-ci.com/broadinstitute/gatk/jobs/259805307) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28145.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557834045:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557834045,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28162](https://travis-ci.com/broadinstitute/gatk/builds/138106843); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28162.13](https://travis-ci.com/broadinstitute/gatk/jobs/260296087) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28162.13/tests/test/index.html) |; | integration | oraclejdk8 | [28162.11](https://travis-ci.com/broadinstitute/gatk/jobs/260296085) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28162.11/tests/test/index.html) |; | integration | openjdk11 | [28162.12](https://travis-ci.com/broadinstitute/gatk/jobs/260296086) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28162.12/tests/test/index.html) |; | unit | openjdk8 | [28162.3](https://travis-ci.com/broadinstitute/gatk/jobs/260296076) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28162.3/tests/test/index.html) |; | integration | openjdk8 | [28162.2](https://travis-ci.com/broadinstitute/gatk/jobs/260296074) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28162.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-558291603:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-558291603,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28165](https://travis-ci.com/broadinstitute/gatk/builds/138115218); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28165.11](https://travis-ci.com/broadinstitute/gatk/jobs/260315679) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28165.11/tests/test/index.html) |; | integration | openjdk11 | [28165.12](https://travis-ci.com/broadinstitute/gatk/jobs/260315680) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28165.12/tests/test/index.html) |; | integration | openjdk8 | [28165.2](https://travis-ci.com/broadinstitute/gatk/jobs/260315669) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28165.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-558314958:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-558314958,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28167](https://travis-ci.com/broadinstitute/gatk/builds/138118033); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [28167.12](https://travis-ci.com/broadinstitute/gatk/jobs/260322542) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28167.12/tests/test/index.html) |; | integration | oraclejdk8 | [28167.11](https://travis-ci.com/broadinstitute/gatk/jobs/260322540) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28167.11/tests/test/index.html) |; | integration | openjdk8 | [28167.2](https://travis-ci.com/broadinstitute/gatk/jobs/260322530) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28167.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-558324081:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-558324081,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28277](https://travis-ci.com/broadinstitute/gatk/builds/139364724); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [28277.12](https://travis-ci.com/broadinstitute/gatk/jobs/263099166) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28277.12/tests/test/index.html) |; | integration | oraclejdk8 | [28277.11](https://travis-ci.com/broadinstitute/gatk/jobs/263099165) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28277.11/tests/test/index.html) |; | integration | openjdk8 | [28277.2](https://travis-ci.com/broadinstitute/gatk/jobs/263099156) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28277.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6274#issuecomment-561730330:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6274#issuecomment-561730330,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:424,integrat,integration,424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28535](https://travis-ci.com/broadinstitute/gatk/builds/143616436); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [28535.4](https://travis-ci.com/broadinstitute/gatk/jobs/273613592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28535.4/tests/test/index.html) |; | integration | openjdk11 | [28535.12](https://travis-ci.com/broadinstitute/gatk/jobs/273613600) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28535.12/tests/test/index.html) |; | integration | oraclejdk8 | [28535.11](https://travis-ci.com/broadinstitute/gatk/jobs/273613599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28535.11/tests/test/index.html) |; | integration | openjdk8 | [28535.2](https://travis-ci.com/broadinstitute/gatk/jobs/273613590) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28535.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572218616:432,integrat,integration,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572218616,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28547](https://travis-ci.com/broadinstitute/gatk/builds/143771509); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28547.11](https://travis-ci.com/broadinstitute/gatk/jobs/273966397) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28547.11/tests/test/index.html) |; | variantcalling | openjdk8 | [28547.4](https://travis-ci.com/broadinstitute/gatk/jobs/273966388) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28547.4/tests/test/index.html) |; | integration | openjdk11 | [28547.12](https://travis-ci.com/broadinstitute/gatk/jobs/273966398) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28547.12/tests/test/index.html) |; | integration | openjdk8 | [28547.2](https://travis-ci.com/broadinstitute/gatk/jobs/273966386) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28547.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572677906:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572677906,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28550](https://travis-ci.com/broadinstitute/gatk/builds/143787017); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [28550.4](https://travis-ci.com/broadinstitute/gatk/jobs/274003454) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28550.4/tests/test/index.html) |; | integration | oraclejdk8 | [28550.11](https://travis-ci.com/broadinstitute/gatk/jobs/274003461) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28550.11/tests/test/index.html) |; | integration | openjdk11 | [28550.12](https://travis-ci.com/broadinstitute/gatk/jobs/274003462) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28550.12/tests/test/index.html) |; | unit | openjdk8 | [28550.3](https://travis-ci.com/broadinstitute/gatk/jobs/274003453) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28550.3/tests/test/index.html) |; | integration | openjdk8 | [28550.2](https://travis-ci.com/broadinstitute/gatk/jobs/274003452) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28550.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572729169:432,integrat,integration,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572729169,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28552](https://travis-ci.com/broadinstitute/gatk/builds/143787227); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28552.11](https://travis-ci.com/broadinstitute/gatk/jobs/274004057) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28552.11/tests/test/index.html) |; | variantcalling | openjdk8 | [28552.4](https://travis-ci.com/broadinstitute/gatk/jobs/274004050) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28552.4/tests/test/index.html) |; | integration | openjdk11 | [28552.12](https://travis-ci.com/broadinstitute/gatk/jobs/274004058) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28552.12/tests/test/index.html) |; | integration | openjdk8 | [28552.2](https://travis-ci.com/broadinstitute/gatk/jobs/274004048) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28552.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572728974:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572728974,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28553](https://travis-ci.com/broadinstitute/gatk/builds/143787525); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [28553.4](https://travis-ci.com/broadinstitute/gatk/jobs/274004800) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28553.4/tests/test/index.html) |; | integration | oraclejdk8 | [28553.11](https://travis-ci.com/broadinstitute/gatk/jobs/274004808) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28553.11/tests/test/index.html) |; | integration | openjdk11 | [28553.12](https://travis-ci.com/broadinstitute/gatk/jobs/274004810) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28553.12/tests/test/index.html) |; | integration | openjdk8 | [28553.2](https://travis-ci.com/broadinstitute/gatk/jobs/274004798) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28553.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572730586:432,integrat,integration,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572730586,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28716](https://travis-ci.com/broadinstitute/gatk/builds/145422010); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28716.11](https://travis-ci.com/broadinstitute/gatk/jobs/278054948) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28716.11/tests/test/index.html) |; | integration | openjdk11 | [28716.12](https://travis-ci.com/broadinstitute/gatk/jobs/278054949) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28716.12/tests/test/index.html) |; | integration | openjdk8 | [28716.2](https://travis-ci.com/broadinstitute/gatk/jobs/278054938) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28716.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6401#issuecomment-576845315:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6401#issuecomment-576845315,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28795](https://travis-ci.com/broadinstitute/gatk/builds/145954484); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [28795.4](https://travis-ci.com/broadinstitute/gatk/jobs/279782040) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28795.4/tests/test/index.html) |; | integration | oraclejdk8 | [28795.11](https://travis-ci.com/broadinstitute/gatk/jobs/279782047) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28795.11/tests/test/index.html) |; | unit | openjdk8 | [28795.3](https://travis-ci.com/broadinstitute/gatk/jobs/279782039) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28795.3/tests/test/index.html) |; | integration | openjdk8 | [28795.2](https://travis-ci.com/broadinstitute/gatk/jobs/279782038) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28795.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-578185465:432,integrat,integration,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-578185465,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [28808](https://travis-ci.com/broadinstitute/gatk/builds/146011126); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28808.11](https://travis-ci.com/broadinstitute/gatk/jobs/279909754) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28808.11/tests/test/index.html) |; | integration | openjdk11 | [28808.12](https://travis-ci.com/broadinstitute/gatk/jobs/279909755) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28808.12/tests/test/index.html) |; | integration | openjdk8 | [28808.2](https://travis-ci.com/broadinstitute/gatk/jobs/279909745) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28808.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6417#issuecomment-578310009:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6417#issuecomment-578310009,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28853](https://travis-ci.com/broadinstitute/gatk/builds/146340414); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [28853.2](https://travis-ci.com/broadinstitute/gatk/jobs/280854279) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28853.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6274#issuecomment-579107366:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6274#issuecomment-579107366,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [28922](https://travis-ci.com/broadinstitute/gatk/builds/146980249); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28922.11](https://travis-ci.com/broadinstitute/gatk/jobs/282436321) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28922.11/tests/test/index.html) |; | integration | openjdk11 | [28922.12](https://travis-ci.com/broadinstitute/gatk/jobs/282436322) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28922.12/tests/test/index.html) |; | integration | openjdk8 | [28922.2](https://travis-ci.com/broadinstitute/gatk/jobs/282436309) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28922.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-580903507:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-580903507,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28928](https://travis-ci.com/broadinstitute/gatk/builds/146990377); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28928.11](https://travis-ci.com/broadinstitute/gatk/jobs/282468192) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.11/tests/test/index.html) |; | variantcalling | openjdk8 | [28928.4](https://travis-ci.com/broadinstitute/gatk/jobs/282468185) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.4/tests/test/index.html) |; | unit | openjdk11 | [28928.13](https://travis-ci.com/broadinstitute/gatk/jobs/282468194) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.13/tests/test/index.html) |; | integration | openjdk11 | [28928.12](https://travis-ci.com/broadinstitute/gatk/jobs/282468193) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.12/tests/test/index.html) |; | unit | openjdk8 | [28928.3](https://travis-ci.com/broadinstitute/gatk/jobs/282468184) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.3/tests/test/index.html) |; | integration | openjdk8 | [28928.2](https://travis-ci.com/broadinstitute/gatk/jobs/282468183) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-580926214:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-580926214,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28947](https://travis-ci.com/broadinstitute/gatk/builds/147248704); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28947.11](https://travis-ci.com/broadinstitute/gatk/jobs/283088574) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28947.11/tests/test/index.html) |; | integration | openjdk11 | [28947.12](https://travis-ci.com/broadinstitute/gatk/jobs/283088576) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28947.12/tests/test/index.html) |; | integration | openjdk8 | [28947.2](https://travis-ci.com/broadinstitute/gatk/jobs/283088564) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28947.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6436#issuecomment-581541781:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6436#issuecomment-581541781,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [28980](https://travis-ci.com/broadinstitute/gatk/builds/147447359); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [28980.12](https://travis-ci.com/broadinstitute/gatk/jobs/283563549) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28980.12/tests/test/index.html) |; | integration | openjdk8 | [28980.2](https://travis-ci.com/broadinstitute/gatk/jobs/283563537) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28980.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6436#issuecomment-582121672:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6436#issuecomment-582121672,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [29013](https://travis-ci.com/broadinstitute/gatk/builds/147827421); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29013.11](https://travis-ci.com/broadinstitute/gatk/jobs/284497171) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29013.11/tests/test/index.html) |; | integration | openjdk11 | [29013.12](https://travis-ci.com/broadinstitute/gatk/jobs/284497172) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29013.12/tests/test/index.html) |; | integration | openjdk8 | [29013.2](https://travis-ci.com/broadinstitute/gatk/jobs/284497162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29013.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6411#issuecomment-583142673:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6411#issuecomment-583142673,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29015](https://travis-ci.com/broadinstitute/gatk/builds/147828086); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29015.11](https://travis-ci.com/broadinstitute/gatk/jobs/284498893) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29015.11/tests/test/index.html) |; | integration | openjdk11 | [29015.12](https://travis-ci.com/broadinstitute/gatk/jobs/284498894) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29015.12/tests/test/index.html) |; | integration | openjdk8 | [29015.2](https://travis-ci.com/broadinstitute/gatk/jobs/284498882) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29015.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6411#issuecomment-583143781:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6411#issuecomment-583143781,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29059](https://travis-ci.com/broadinstitute/gatk/builds/148070808); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [29059.1](https://travis-ci.com/broadinstitute/gatk/jobs/285180550) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29059.1/tests/test/index.html) |; | cloud | openjdk11 | [29059.14](https://travis-ci.com/broadinstitute/gatk/jobs/285180563) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29059.14/tests/test/index.html) |; | integration | oraclejdk8 | [29059.11](https://travis-ci.com/broadinstitute/gatk/jobs/285180560) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29059.11/tests/test/index.html) |; | integration | openjdk11 | [29059.12](https://travis-ci.com/broadinstitute/gatk/jobs/285180561) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29059.12/tests/test/index.html) |; | integration | openjdk8 | [29059.2](https://travis-ci.com/broadinstitute/gatk/jobs/285180551) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29059.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6446#issuecomment-583802851:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6446#issuecomment-583802851,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29063](https://travis-ci.com/broadinstitute/gatk/builds/148075396); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [29063.5](https://travis-ci.com/broadinstitute/gatk/jobs/285190126) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29063.5/tests/test/index.html) |; | unit | openjdk8 | [29063.3](https://travis-ci.com/broadinstitute/gatk/jobs/285190124) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29063.3/tests/test/index.html) |; | integration | openjdk8 | [29063.2](https://travis-ci.com/broadinstitute/gatk/jobs/285190123) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29063.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6448#issuecomment-583812428:628,integrat,integration,628,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6448#issuecomment-583812428,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [29125](https://travis-ci.com/broadinstitute/gatk/builds/148726118); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [29125.5](https://travis-ci.com/broadinstitute/gatk/jobs/286704576) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29125.5/tests/test/index.html) |; | variantcalling | openjdk8 | [29125.4](https://travis-ci.com/broadinstitute/gatk/jobs/286704575) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29125.4/tests/test/index.html) |; | unit | openjdk8 | [29125.3](https://travis-ci.com/broadinstitute/gatk/jobs/286704574) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29125.3/tests/test/index.html) |; | integration | openjdk8 | [29125.2](https://travis-ci.com/broadinstitute/gatk/jobs/286704573) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29125.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6445#issuecomment-585577409:842,integrat,integration,842,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6445#issuecomment-585577409,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [29157](https://travis-ci.com/broadinstitute/gatk/builds/148868090); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29157.12](https://travis-ci.com/broadinstitute/gatk/jobs/287031748) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29157.12/tests/test/index.html) |; | unit | openjdk11 | [29157.14](https://travis-ci.com/broadinstitute/gatk/jobs/287031750) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29157.14/tests/test/index.html) |; | integration | openjdk11 | [29157.13](https://travis-ci.com/broadinstitute/gatk/jobs/287031749) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29157.13/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6454#issuecomment-586001111:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6454#issuecomment-586001111,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [29224](https://travis-ci.com/broadinstitute/gatk/builds/149883140); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29224.12](https://travis-ci.com/broadinstitute/gatk/jobs/289430111) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29224.12/tests/test/index.html) |; | unit | openjdk11 | [29224.14](https://travis-ci.com/broadinstitute/gatk/jobs/289430113) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29224.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29224.4](https://travis-ci.com/broadinstitute/gatk/jobs/289430103) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29224.4/tests/test/index.html) |; | integration | openjdk11 | [29224.13](https://travis-ci.com/broadinstitute/gatk/jobs/289430112) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29224.13/tests/test/index.html) |; | integration | openjdk8 | [29224.2](https://travis-ci.com/broadinstitute/gatk/jobs/289430101) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29224.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-589296062:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-589296062,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29238](https://travis-ci.com/broadinstitute/gatk/builds/150105026); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [29238.14](https://travis-ci.com/broadinstitute/gatk/jobs/289940648) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29238.14/tests/test/index.html) |; | integration | oraclejdk8 | [29238.12](https://travis-ci.com/broadinstitute/gatk/jobs/289940646) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29238.12/tests/test/index.html) |; | unit | openjdk8 | [29238.3](https://travis-ci.com/broadinstitute/gatk/jobs/289940637) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29238.3/tests/test/index.html) |; | integration | openjdk11 | [29238.13](https://travis-ci.com/broadinstitute/gatk/jobs/289940647) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29238.13/tests/test/index.html) |; | integration | openjdk8 | [29238.2](https://travis-ci.com/broadinstitute/gatk/jobs/289940636) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29238.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6465#issuecomment-589866076:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6465#issuecomment-589866076,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29412](https://travis-ci.com/broadinstitute/gatk/builds/151996956); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29412.12](https://travis-ci.com/broadinstitute/gatk/jobs/295002547) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29412.12/tests/test/index.html) |; | integration | openjdk11 | [29412.13](https://travis-ci.com/broadinstitute/gatk/jobs/295002548) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29412.13/tests/test/index.html) |; | integration | openjdk8 | [29412.2](https://travis-ci.com/broadinstitute/gatk/jobs/295002537) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29412.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595341676:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595341676,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29414](https://travis-ci.com/broadinstitute/gatk/builds/151997149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29414.12](https://travis-ci.com/broadinstitute/gatk/jobs/295003009) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29414.12/tests/test/index.html) |; | integration | openjdk11 | [29414.13](https://travis-ci.com/broadinstitute/gatk/jobs/295003010) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29414.13/tests/test/index.html) |; | integration | openjdk8 | [29414.2](https://travis-ci.com/broadinstitute/gatk/jobs/295002999) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29414.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595342221:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595342221,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29416](https://travis-ci.com/broadinstitute/gatk/builds/152000044); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29416.12](https://travis-ci.com/broadinstitute/gatk/jobs/295015583) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29416.12/tests/test/index.html) |; | integration | openjdk11 | [29416.13](https://travis-ci.com/broadinstitute/gatk/jobs/295015584) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29416.13/tests/test/index.html) |; | integration | openjdk8 | [29416.2](https://travis-ci.com/broadinstitute/gatk/jobs/295015573) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29416.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595346842:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595346842,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29475](https://travis-ci.com/broadinstitute/gatk/builds/152932209); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [29475.14](https://travis-ci.com/broadinstitute/gatk/jobs/297213806) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29475.14/tests/test/index.html) |; | unit | openjdk8 | [29475.3](https://travis-ci.com/broadinstitute/gatk/jobs/297213795) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29475.3/tests/test/index.html) |; | integration | openjdk8 | [29475.2](https://travis-ci.com/broadinstitute/gatk/jobs/297213794) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29475.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6498#issuecomment-598028671:629,integrat,integration,629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6498#issuecomment-598028671,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [29539](https://travis-ci.com/broadinstitute/gatk/builds/153610218); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29539.6](https://travis-ci.com/broadinstitute/gatk/jobs/298810423) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29539.6/tests/test/index.html) |; | python | openjdk8 | [29539.5](https://travis-ci.com/broadinstitute/gatk/jobs/298810422) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29539.5/tests/test/index.html) |; | variantcalling | openjdk8 | [29539.4](https://travis-ci.com/broadinstitute/gatk/jobs/298810421) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29539.4/tests/test/index.html) |; | unit | openjdk8 | [29539.3](https://travis-ci.com/broadinstitute/gatk/jobs/298810420) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29539.3/tests/test/index.html) |; | integration | openjdk8 | [29539.2](https://travis-ci.com/broadinstitute/gatk/jobs/298810419) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29539.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6507#issuecomment-599901701:1043,integrat,integration,1043,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6507#issuecomment-599901701,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [29604](https://travis-ci.com/broadinstitute/gatk/builds/154146351); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [29604.14](https://travis-ci.com/broadinstitute/gatk/jobs/300039008) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.14/tests/test/index.html) |; | integration | oraclejdk8 | [29604.12](https://travis-ci.com/broadinstitute/gatk/jobs/300039006) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.12/tests/test/index.html) |; | integration | openjdk11 | [29604.13](https://travis-ci.com/broadinstitute/gatk/jobs/300039007) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.13/tests/test/index.html) |; | integration | openjdk8 | [29604.2](https://travis-ci.com/broadinstitute/gatk/jobs/300038996) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29682](https://travis-ci.com/broadinstitute/gatk/builds/154630422); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29682.12](https://travis-ci.com/broadinstitute/gatk/jobs/301258495) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29682.12/tests/test/index.html) |; | integration | openjdk11 | [29682.13](https://travis-ci.com/broadinstitute/gatk/jobs/301258496) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29682.13/tests/test/index.html) |; | integration | openjdk8 | [29682.2](https://travis-ci.com/broadinstitute/gatk/jobs/301258485) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29682.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602719177:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602719177,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29684](https://travis-ci.com/broadinstitute/gatk/builds/154637286); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29684.12](https://travis-ci.com/broadinstitute/gatk/jobs/301273903) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29684.12/tests/test/index.html) |; | integration | openjdk11 | [29684.13](https://travis-ci.com/broadinstitute/gatk/jobs/301273904) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29684.13/tests/test/index.html) |; | integration | openjdk8 | [29684.2](https://travis-ci.com/broadinstitute/gatk/jobs/301273893) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29684.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602739941:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602739941,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29685](https://travis-ci.com/broadinstitute/gatk/builds/154640951); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29685.12](https://travis-ci.com/broadinstitute/gatk/jobs/301286235) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29685.12/tests/test/index.html) |; | integration | openjdk11 | [29685.13](https://travis-ci.com/broadinstitute/gatk/jobs/301286236) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29685.13/tests/test/index.html) |; | integration | openjdk8 | [29685.2](https://travis-ci.com/broadinstitute/gatk/jobs/301286225) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29685.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602742528:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602742528,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29688](https://travis-ci.com/broadinstitute/gatk/builds/154646560); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29688.12](https://travis-ci.com/broadinstitute/gatk/jobs/301299237) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29688.12/tests/test/index.html) |; | integration | openjdk11 | [29688.13](https://travis-ci.com/broadinstitute/gatk/jobs/301299238) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29688.13/tests/test/index.html) |; | integration | openjdk8 | [29688.2](https://travis-ci.com/broadinstitute/gatk/jobs/301299227) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29688.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602759165:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602759165,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29804](https://travis-ci.com/broadinstitute/gatk/builds/156857783); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29804.6](https://travis-ci.com/broadinstitute/gatk/jobs/309185373) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.6/tests/test/index.html) |; | integration | oraclejdk8 | [29804.12](https://travis-ci.com/broadinstitute/gatk/jobs/309185379) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.12/tests/test/index.html) |; | python | openjdk8 | [29804.5](https://travis-ci.com/broadinstitute/gatk/jobs/309185372) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.5/tests/test/index.html) |; | cloud | openjdk8 | [29804.1](https://travis-ci.com/broadinstitute/gatk/jobs/309185366) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.1/tests/test/index.html) |; | integration | openjdk11 | [29804.13](https://travis-ci.com/broadinstitute/gatk/jobs/309185380) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.13/tests/test/index.html) |; | cloud | openjdk11 | [29804.15](https://travis-ci.com/broadinstitute/gatk/jobs/309185382) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.15/tests/test/index.html) |; | integration | openjdk8 | [29804.2](https://travis-ci.com/broadinstitute/gatk/jobs/309185367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29804.4](https://travis-ci.com/broadinstitute/gatk/jobs/309185371) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-606204666:419,integrat,integration,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-606204666,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29830](https://travis-ci.com/broadinstitute/gatk/builds/157356833); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29830.12](https://travis-ci.com/broadinstitute/gatk/jobs/310893235) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29830.12/tests/test/index.html) |; | integration | openjdk11 | [29830.13](https://travis-ci.com/broadinstitute/gatk/jobs/310893236) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29830.13/tests/test/index.html) |; | cloud | openjdk8 | [29830.1](https://travis-ci.com/broadinstitute/gatk/jobs/310893224) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29830.1/tests/test/index.html) |; | cloud | openjdk11 | [29830.15](https://travis-ci.com/broadinstitute/gatk/jobs/310893238) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29830.15/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-606967314:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-606967314,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [29832](https://travis-ci.com/broadinstitute/gatk/builds/157562667); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29832.12](https://travis-ci.com/broadinstitute/gatk/jobs/311543311) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29832.12/tests/test/index.html) |; | integration | openjdk11 | [29832.13](https://travis-ci.com/broadinstitute/gatk/jobs/311543312) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29832.13/tests/test/index.html) |; | cloud | openjdk11 | [29832.15](https://travis-ci.com/broadinstitute/gatk/jobs/311543314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29832.15/tests/test/index.html) |; | cloud | openjdk8 | [29832.1](https://travis-ci.com/broadinstitute/gatk/jobs/311543300) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29832.1/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607339427:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607339427,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [29837](https://travis-ci.com/broadinstitute/gatk/builds/157591374); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29837.12](https://travis-ci.com/broadinstitute/gatk/jobs/311628431) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29837.12/tests/test/index.html) |; | integration | openjdk11 | [29837.13](https://travis-ci.com/broadinstitute/gatk/jobs/311628432) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29837.13/tests/test/index.html) |; | integration | openjdk8 | [29837.2](https://travis-ci.com/broadinstitute/gatk/jobs/311628421) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29837.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607423696:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607423696,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29839](https://travis-ci.com/broadinstitute/gatk/builds/157593279); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29839.12](https://travis-ci.com/broadinstitute/gatk/jobs/311633272) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29839.12/tests/test/index.html) |; | integration | openjdk11 | [29839.13](https://travis-ci.com/broadinstitute/gatk/jobs/311633273) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29839.13/tests/test/index.html) |; | integration | openjdk8 | [29839.2](https://travis-ci.com/broadinstitute/gatk/jobs/311633261) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29839.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607427515:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607427515,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29842](https://travis-ci.com/broadinstitute/gatk/builds/157628713); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29842.12](https://travis-ci.com/broadinstitute/gatk/jobs/311717563) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29842.12/tests/test/index.html) |; | integration | openjdk11 | [29842.13](https://travis-ci.com/broadinstitute/gatk/jobs/311717564) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29842.13/tests/test/index.html) |; | integration | openjdk8 | [29842.2](https://travis-ci.com/broadinstitute/gatk/jobs/311717553) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29842.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607510446:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607510446,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29895](https://travis-ci.com/broadinstitute/gatk/builds/158261477); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29895.6](https://travis-ci.com/broadinstitute/gatk/jobs/313692987) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.6/tests/test/index.html) |; | python | openjdk8 | [29895.5](https://travis-ci.com/broadinstitute/gatk/jobs/313692986) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.5/tests/test/index.html) |; | integration | oraclejdk8 | [29895.12](https://travis-ci.com/broadinstitute/gatk/jobs/313692993) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.12/tests/test/index.html) |; | cloud | openjdk8 | [29895.1](https://travis-ci.com/broadinstitute/gatk/jobs/313692982) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.1/tests/test/index.html) |; | integration | openjdk11 | [29895.13](https://travis-ci.com/broadinstitute/gatk/jobs/313692994) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.13/tests/test/index.html) |; | cloud | openjdk11 | [29895.15](https://travis-ci.com/broadinstitute/gatk/jobs/313692996) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.15/tests/test/index.html) |; | integration | openjdk8 | [29895.2](https://travis-ci.com/broadinstitute/gatk/jobs/313692983) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29895.4](https://travis-ci.com/broadinstitute/gatk/jobs/313692985) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608562413:625,integrat,integration,625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608562413,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29897](https://travis-ci.com/broadinstitute/gatk/builds/158264975); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [29897.5](https://travis-ci.com/broadinstitute/gatk/jobs/313702266) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.5/tests/test/index.html) |; | integration | oraclejdk8 | [29897.12](https://travis-ci.com/broadinstitute/gatk/jobs/313702273) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.12/tests/test/index.html) |; | cloud | openjdk8 | [29897.1](https://travis-ci.com/broadinstitute/gatk/jobs/313702262) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.1/tests/test/index.html) |; | integration | openjdk11 | [29897.13](https://travis-ci.com/broadinstitute/gatk/jobs/313702274) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.13/tests/test/index.html) |; | integration | openjdk8 | [29897.2](https://travis-ci.com/broadinstitute/gatk/jobs/313702263) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.2/tests/test/index.html) |; | cloud | openjdk11 | [29897.15](https://travis-ci.com/broadinstitute/gatk/jobs/313702276) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.15/tests/test/index.html) |; | variantcalling | openjdk8 | [29897.4](https://travis-ci.com/broadinstitute/gatk/jobs/313702265) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608574955:424,integrat,integration,424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608574955,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29900](https://travis-ci.com/broadinstitute/gatk/builds/158267113); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29900.6](https://travis-ci.com/broadinstitute/gatk/jobs/313708020) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.6/tests/test/index.html) |; | integration | oraclejdk8 | [29900.12](https://travis-ci.com/broadinstitute/gatk/jobs/313708026) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.12/tests/test/index.html) |; | integration | openjdk11 | [29900.13](https://travis-ci.com/broadinstitute/gatk/jobs/313708027) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.13/tests/test/index.html) |; | cloud | openjdk8 | [29900.1](https://travis-ci.com/broadinstitute/gatk/jobs/313708015) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.1/tests/test/index.html) |; | integration | openjdk8 | [29900.2](https://travis-ci.com/broadinstitute/gatk/jobs/313708016) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.2/tests/test/index.html) |; | cloud | openjdk11 | [29900.15](https://travis-ci.com/broadinstitute/gatk/jobs/313708029) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.15/tests/test/index.html) |; | variantcalling | openjdk8 | [29900.4](https://travis-ci.com/broadinstitute/gatk/jobs/313708018) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608580670:419,integrat,integration,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608580670,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [29984](https://travis-ci.com/broadinstitute/gatk/builds/159673754); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29984.6](https://travis-ci.com/broadinstitute/gatk/jobs/317851324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.6/tests/test/index.html) |; | python | openjdk8 | [29984.5](https://travis-ci.com/broadinstitute/gatk/jobs/317851323) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.5/tests/test/index.html) |; | integration | oraclejdk8 | [29984.12](https://travis-ci.com/broadinstitute/gatk/jobs/317851330) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.12/tests/test/index.html) |; | integration | openjdk11 | [29984.13](https://travis-ci.com/broadinstitute/gatk/jobs/317851331) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.13/tests/test/index.html) |; | cloud | openjdk8 | [29984.1](https://travis-ci.com/broadinstitute/gatk/jobs/317851319) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.1/tests/test/index.html) |; | cloud | openjdk11 | [29984.15](https://travis-ci.com/broadinstitute/gatk/jobs/317851333) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.15/tests/test/index.html) |; | unit | openjdk11 | [29984.14](https://travis-ci.com/broadinstitute/gatk/jobs/317851332) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.14/tests/test/index.html) |; | integration | openjdk8 | [29984.2](https://travis-ci.com/broadinstitute/gatk/jobs/317851320) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29984.4](https://travis-ci.com/broadinstitute/gatk/jobs/317851322) | [logs](https://sto,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611695380:625,integrat,integration,625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611695380,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [29988](https://travis-ci.com/broadinstitute/gatk/builds/159678058); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29988.6](https://travis-ci.com/broadinstitute/gatk/jobs/317861684) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.6/tests/test/index.html) |; | integration | oraclejdk8 | [29988.12](https://travis-ci.com/broadinstitute/gatk/jobs/317861697) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.12/tests/test/index.html) |; | python | openjdk8 | [29988.5](https://travis-ci.com/broadinstitute/gatk/jobs/317861683) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.5/tests/test/index.html) |; | integration | openjdk11 | [29988.13](https://travis-ci.com/broadinstitute/gatk/jobs/317861698) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.13/tests/test/index.html) |; | cloud | openjdk11 | [29988.15](https://travis-ci.com/broadinstitute/gatk/jobs/317861700) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.15/tests/test/index.html) |; | cloud | openjdk8 | [29988.1](https://travis-ci.com/broadinstitute/gatk/jobs/317861676) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.1/tests/test/index.html) |; | unit | openjdk11 | [29988.14](https://travis-ci.com/broadinstitute/gatk/jobs/317861699) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.14/tests/test/index.html) |; | integration | openjdk8 | [29988.2](https://travis-ci.com/broadinstitute/gatk/jobs/317861680) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29988.4](https://travis-ci.com/broadinstitute/gatk/jobs/317861682) | [logs](https://sto,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611710351:419,integrat,integration,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611710351,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [29990](https://travis-ci.com/broadinstitute/gatk/builds/159681491); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29990.6](https://travis-ci.com/broadinstitute/gatk/jobs/317870153) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.6/tests/test/index.html) |; | integration | oraclejdk8 | [29990.12](https://travis-ci.com/broadinstitute/gatk/jobs/317870159) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.12/tests/test/index.html) |; | python | openjdk8 | [29990.5](https://travis-ci.com/broadinstitute/gatk/jobs/317870152) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.5/tests/test/index.html) |; | cloud | openjdk8 | [29990.1](https://travis-ci.com/broadinstitute/gatk/jobs/317870147) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.1/tests/test/index.html) |; | cloud | openjdk11 | [29990.15](https://travis-ci.com/broadinstitute/gatk/jobs/317870162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.15/tests/test/index.html) |; | integration | openjdk11 | [29990.13](https://travis-ci.com/broadinstitute/gatk/jobs/317870160) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.13/tests/test/index.html) |; | integration | openjdk8 | [29990.2](https://travis-ci.com/broadinstitute/gatk/jobs/317870149) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.2/tests/test/index.html) |; | unit | openjdk11 | [29990.14](https://travis-ci.com/broadinstitute/gatk/jobs/317870161) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29990.4](https://travis-ci.com/broadinstitute/gatk/jobs/317870151) | [logs](https://sto,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629:419,integrat,integration,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [29992](https://travis-ci.com/broadinstitute/gatk/builds/159687710); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29992.6](https://travis-ci.com/broadinstitute/gatk/jobs/317887706) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.6/tests/test/index.html) |; | python | openjdk8 | [29992.5](https://travis-ci.com/broadinstitute/gatk/jobs/317887705) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.5/tests/test/index.html) |; | integration | oraclejdk8 | [29992.12](https://travis-ci.com/broadinstitute/gatk/jobs/317887712) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.12/tests/test/index.html) |; | integration | openjdk11 | [29992.13](https://travis-ci.com/broadinstitute/gatk/jobs/317887713) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.13/tests/test/index.html) |; | cloud | openjdk8 | [29992.1](https://travis-ci.com/broadinstitute/gatk/jobs/317887701) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.1/tests/test/index.html) |; | cloud | openjdk11 | [29992.15](https://travis-ci.com/broadinstitute/gatk/jobs/317887715) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.15/tests/test/index.html) |; | integration | openjdk8 | [29992.2](https://travis-ci.com/broadinstitute/gatk/jobs/317887702) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.2/tests/test/index.html) |; | unit | openjdk11 | [29992.14](https://travis-ci.com/broadinstitute/gatk/jobs/317887714) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29992.4](https://travis-ci.com/broadinstitute/gatk/jobs/317887704) | [logs](https://sto,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611733065:625,integrat,integration,625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611733065,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30007](https://travis-ci.com/broadinstitute/gatk/builds/159946837); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk8 | [30007.3](https://travis-ci.com/broadinstitute/gatk/jobs/318548433) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30007.3/tests/test/index.html) |; | integration | openjdk8 | [30007.2](https://travis-ci.com/broadinstitute/gatk/jobs/318548432) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30007.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6544#issuecomment-612573044:422,integrat,integration,422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6544#issuecomment-612573044,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [30166](https://travis-ci.com/broadinstitute/gatk/builds/161861232); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30166.13](https://travis-ci.com/broadinstitute/gatk/jobs/323065577) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30166.13/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-619117426:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-619117426,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [30170](https://travis-ci.com/broadinstitute/gatk/builds/161888712); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [30170.12](https://travis-ci.com/broadinstitute/gatk/jobs/323130022) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30170.12/tests/test/index.html) |; | integration | openjdk11 | [30170.13](https://travis-ci.com/broadinstitute/gatk/jobs/323130023) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30170.13/tests/test/index.html) |; | integration | openjdk8 | [30170.2](https://travis-ci.com/broadinstitute/gatk/jobs/323130012) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30170.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-619192806:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-619192806,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [30184](https://travis-ci.com/broadinstitute/gatk/builds/162226990); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [30184.12](https://travis-ci.com/broadinstitute/gatk/jobs/323827982) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30184.12/tests/test/index.html) |; | integration | openjdk11 | [30184.13](https://travis-ci.com/broadinstitute/gatk/jobs/323827983) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30184.13/tests/test/index.html) |; | integration | openjdk8 | [30184.2](https://travis-ci.com/broadinstitute/gatk/jobs/323827972) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30184.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-620008431:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-620008431,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [30367](https://travis-ci.com/broadinstitute/gatk/builds/166938202); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [30367.1](https://travis-ci.com/broadinstitute/gatk/jobs/337021781) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.1/tests/test/index.html) |; | conda | openjdk8 | [30367.5](https://travis-ci.com/broadinstitute/gatk/jobs/337021785) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.5/tests/test/index.html) |; | cloud | openjdk11 | [30367.13](https://travis-ci.com/broadinstitute/gatk/jobs/337021793) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.13/tests/test/index.html) |; | unit | openjdk11 | [30367.12](https://travis-ci.com/broadinstitute/gatk/jobs/337021792) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.12/tests/test/index.html) |; | integration | openjdk11 | [30367.11](https://travis-ci.com/broadinstitute/gatk/jobs/337021791) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.11/tests/test/index.html) |; | variantcalling | openjdk8 | [30367.4](https://travis-ci.com/broadinstitute/gatk/jobs/337021784) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.4/tests/test/index.html) |; | unit | openjdk8 | [30367.3](https://travis-ci.com/broadinstitute/gatk/jobs/337021783) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.3/tests/test/index.html) |; | integration | openjdk8 | [30367.2](https://travis-ci.com/broadinstitute/gatk/jobs/337021782) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-630883022:1043,integrat,integration,1043,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-630883022,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30416](https://travis-ci.com/broadinstitute/gatk/builds/168461453); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30416.11](https://travis-ci.com/broadinstitute/gatk/jobs/340668381) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30416.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6571#issuecomment-634926766:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6571#issuecomment-634926766,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [30432](https://travis-ci.com/broadinstitute/gatk/builds/168636249); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30432.11](https://travis-ci.com/broadinstitute/gatk/jobs/341109053) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30432.11/tests/test/index.html) |; | integration | openjdk8 | [30432.2](https://travis-ci.com/broadinstitute/gatk/jobs/341109044) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30432.2/tests/test/index.html) |; | integration | openjdk11 | [30432.11](https://travis-ci.com/broadinstitute/gatk/jobs/341109053) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30432.11/tests/test/index.html) |; | integration | openjdk8 | [30432.2](https://travis-ci.com/broadinstitute/gatk/jobs/341109044) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30432.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6536#issuecomment-635559332:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6536#issuecomment-635559332,4,['integrat'],['integration']
Deployability,Travis reported job failures from build [30435](https://travis-ci.com/broadinstitute/gatk/builds/168646579); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30435.11](https://travis-ci.com/broadinstitute/gatk/jobs/341136130) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30435.11/tests/test/index.html) |; | integration | openjdk8 | [30435.2](https://travis-ci.com/broadinstitute/gatk/jobs/341136121) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30435.2/tests/test/index.html) |; | integration | openjdk11 | [30435.11](https://travis-ci.com/broadinstitute/gatk/jobs/341136130) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30435.11/tests/test/index.html) |; | integration | openjdk8 | [30435.2](https://travis-ci.com/broadinstitute/gatk/jobs/341136121) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30435.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-635608349:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-635608349,4,['integrat'],['integration']
Deployability,Travis reported job failures from build [30438](https://travis-ci.com/broadinstitute/gatk/builds/168656638); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30438.11](https://travis-ci.com/broadinstitute/gatk/jobs/341162861) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30438.11/tests/test/index.html) |; | integration | openjdk8 | [30438.2](https://travis-ci.com/broadinstitute/gatk/jobs/341162852) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30438.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-635642092:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-635642092,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30440](https://travis-ci.com/broadinstitute/gatk/builds/168676133); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30440.11](https://travis-ci.com/broadinstitute/gatk/jobs/341217438) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30440.11/tests/test/index.html) |; | integration | openjdk8 | [30440.2](https://travis-ci.com/broadinstitute/gatk/jobs/341217429) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30440.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6571#issuecomment-635722922:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6571#issuecomment-635722922,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30450](https://travis-ci.com/broadinstitute/gatk/builds/168819223); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30450.11](https://travis-ci.com/broadinstitute/gatk/jobs/341603988) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30450.11/tests/test/index.html) |; | integration | openjdk8 | [30450.2](https://travis-ci.com/broadinstitute/gatk/jobs/341603979) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30450.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6626#issuecomment-636225750:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6626#issuecomment-636225750,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30452](https://travis-ci.com/broadinstitute/gatk/builds/168836017); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30452.11](https://travis-ci.com/broadinstitute/gatk/jobs/341649474) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30452.11/tests/test/index.html) |; | integration | openjdk8 | [30452.2](https://travis-ci.com/broadinstitute/gatk/jobs/341649465) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30452.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-636272145:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-636272145,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30457](https://travis-ci.com/broadinstitute/gatk/builds/169030325); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30457.11](https://travis-ci.com/broadinstitute/gatk/jobs/342158813) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30457.11/tests/test/index.html) |; | integration | openjdk8 | [30457.2](https://travis-ci.com/broadinstitute/gatk/jobs/342158804) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30457.2/tests/test/index.html) |; | integration | openjdk11 | [30457.11](https://travis-ci.com/broadinstitute/gatk/jobs/342158813) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30457.11/tests/test/index.html) |; | integration | openjdk8 | [30457.2](https://travis-ci.com/broadinstitute/gatk/jobs/342158804) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30457.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6628#issuecomment-636901985:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6628#issuecomment-636901985,4,['integrat'],['integration']
Deployability,Travis reported job failures from build [30459](https://travis-ci.com/broadinstitute/gatk/builds/169034436); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30459.11](https://travis-ci.com/broadinstitute/gatk/jobs/342168332) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30459.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-636917795:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-636917795,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [30475](https://travis-ci.com/broadinstitute/gatk/builds/169229345); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30475.11](https://travis-ci.com/broadinstitute/gatk/jobs/342675165) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30475.11/tests/test/index.html) |; | integration | openjdk8 | [30475.2](https://travis-ci.com/broadinstitute/gatk/jobs/342675156) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30475.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-637680721:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-637680721,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30477](https://travis-ci.com/broadinstitute/gatk/builds/169277901); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30477.11](https://travis-ci.com/broadinstitute/gatk/jobs/342782902) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30477.11/tests/test/index.html) |; | integration | openjdk8 | [30477.2](https://travis-ci.com/broadinstitute/gatk/jobs/342782893) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30477.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-637717214:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-637717214,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30481](https://travis-ci.com/broadinstitute/gatk/builds/169292148); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30481.11](https://travis-ci.com/broadinstitute/gatk/jobs/342819741) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30481.11/tests/test/index.html) |; | integration | openjdk8 | [30481.2](https://travis-ci.com/broadinstitute/gatk/jobs/342819732) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30481.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6632#issuecomment-637767968:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6632#issuecomment-637767968,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30487](https://travis-ci.com/broadinstitute/gatk/builds/169311637); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30487.11](https://travis-ci.com/broadinstitute/gatk/jobs/342871642) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30487.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-637836728:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-637836728,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [30489](https://travis-ci.com/broadinstitute/gatk/builds/169313463); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30489.11](https://travis-ci.com/broadinstitute/gatk/jobs/342876908) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30489.11/tests/test/index.html) |; | integration | openjdk8 | [30489.2](https://travis-ci.com/broadinstitute/gatk/jobs/342876899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30489.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6559#issuecomment-637843246:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6559#issuecomment-637843246,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30494](https://travis-ci.com/broadinstitute/gatk/builds/169351481); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30494.11](https://travis-ci.com/broadinstitute/gatk/jobs/342986478) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30494.11/tests/test/index.html) |; | integration | openjdk8 | [30494.2](https://travis-ci.com/broadinstitute/gatk/jobs/342986469) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30494.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6636#issuecomment-637936325:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6636#issuecomment-637936325,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30509](https://travis-ci.com/broadinstitute/gatk/builds/169658943); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30509.11](https://travis-ci.com/broadinstitute/gatk/jobs/343744765) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30509.11/tests/test/index.html) |; | integration | openjdk8 | [30509.2](https://travis-ci.com/broadinstitute/gatk/jobs/343744756) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30509.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6626#issuecomment-639041011:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6626#issuecomment-639041011,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30624](https://travis-ci.com/broadinstitute/gatk/builds/171270341); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30624.11](https://travis-ci.com/broadinstitute/gatk/jobs/348890773) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30624.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-643784213:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-643784213,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [30643](https://travis-ci.com/broadinstitute/gatk/builds/171606871); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | conda | openjdk8 | [30643.5](https://travis-ci.com/broadinstitute/gatk/jobs/349726487) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30643.5/tests/test/index.html) |; | unit | openjdk11 | [30643.12](https://travis-ci.com/broadinstitute/gatk/jobs/349726494) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30643.12/tests/test/index.html) |; | integration | openjdk11 | [30643.11](https://travis-ci.com/broadinstitute/gatk/jobs/349726493) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30643.11/tests/test/index.html) |; | unit | openjdk8 | [30643.3](https://travis-ci.com/broadinstitute/gatk/jobs/349726485) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30643.3/tests/test/index.html) |; | integration | openjdk8 | [30643.2](https://travis-ci.com/broadinstitute/gatk/jobs/349726484) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30643.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-644793169:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-644793169,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30644](https://travis-ci.com/broadinstitute/gatk/builds/171613538); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30644.11](https://travis-ci.com/broadinstitute/gatk/jobs/349743817) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30644.11/tests/test/index.html) |; | integration | openjdk8 | [30644.2](https://travis-ci.com/broadinstitute/gatk/jobs/349743808) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30644.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-644819369:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-644819369,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30666](https://travis-ci.com/broadinstitute/gatk/builds/171680645); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [30666.12](https://travis-ci.com/broadinstitute/gatk/jobs/349984895) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30666.12/tests/test/index.html) |; | conda | openjdk8 | [30666.5](https://travis-ci.com/broadinstitute/gatk/jobs/349984888) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30666.5/tests/test/index.html) |; | integration | openjdk11 | [30666.11](https://travis-ci.com/broadinstitute/gatk/jobs/349984894) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30666.11/tests/test/index.html) |; | unit | openjdk8 | [30666.3](https://travis-ci.com/broadinstitute/gatk/jobs/349984886) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30666.3/tests/test/index.html) |; | integration | openjdk8 | [30666.2](https://travis-ci.com/broadinstitute/gatk/jobs/349984885) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30666.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-644966563:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-644966563,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30678](https://travis-ci.com/broadinstitute/gatk/builds/171691595); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [30678.12](https://travis-ci.com/broadinstitute/gatk/jobs/350014518) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30678.12/tests/test/index.html) |; | conda | openjdk8 | [30678.5](https://travis-ci.com/broadinstitute/gatk/jobs/350014511) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30678.5/tests/test/index.html) |; | integration | openjdk11 | [30678.11](https://travis-ci.com/broadinstitute/gatk/jobs/350014517) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30678.11/tests/test/index.html) |; | unit | openjdk8 | [30678.3](https://travis-ci.com/broadinstitute/gatk/jobs/350014509) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30678.3/tests/test/index.html) |; | integration | openjdk8 | [30678.2](https://travis-ci.com/broadinstitute/gatk/jobs/350014508) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30678.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-645006687:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-645006687,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30698](https://travis-ci.com/broadinstitute/gatk/builds/171852295); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30698.11](https://travis-ci.com/broadinstitute/gatk/jobs/350395411) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30698.11/tests/test/index.html) |; | variantcalling | openjdk8 | [30698.4](https://travis-ci.com/broadinstitute/gatk/jobs/350395404) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30698.4/tests/test/index.html) |; | integration | openjdk8 | [30698.2](https://travis-ci.com/broadinstitute/gatk/jobs/350395402) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30698.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-645419790:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-645419790,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30705](https://travis-ci.com/broadinstitute/gatk/builds/171899359); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [30705.12](https://travis-ci.com/broadinstitute/gatk/jobs/350530956) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30705.12/tests/test/index.html) |; | conda | openjdk8 | [30705.5](https://travis-ci.com/broadinstitute/gatk/jobs/350530949) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30705.5/tests/test/index.html) |; | integration | openjdk11 | [30705.11](https://travis-ci.com/broadinstitute/gatk/jobs/350530955) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30705.11/tests/test/index.html) |; | unit | openjdk8 | [30705.3](https://travis-ci.com/broadinstitute/gatk/jobs/350530947) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30705.3/tests/test/index.html) |; | integration | openjdk8 | [30705.2](https://travis-ci.com/broadinstitute/gatk/jobs/350530946) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30705.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-645543363:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-645543363,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30712](https://travis-ci.com/broadinstitute/gatk/builds/171935407); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30712.11](https://travis-ci.com/broadinstitute/gatk/jobs/350622577) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30712.11/tests/test/index.html) |; | cloud | openjdk8 | [30712.1](https://travis-ci.com/broadinstitute/gatk/jobs/350622567) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30712.1/tests/test/index.html) |; | cloud | openjdk11 | [30712.13](https://travis-ci.com/broadinstitute/gatk/jobs/350622579) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30712.13/tests/test/index.html) |; | unit | openjdk11 | [30712.12](https://travis-ci.com/broadinstitute/gatk/jobs/350622578) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30712.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6612#issuecomment-645656060:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6612#issuecomment-645656060,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [30869](https://travis-ci.com/broadinstitute/gatk/builds/174096694); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [30869.13](https://travis-ci.com/broadinstitute/gatk/jobs/357066667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30869.13/tests/test/index.html) |; | integration | openjdk11 | [30869.12](https://travis-ci.com/broadinstitute/gatk/jobs/357066666) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30869.12/tests/test/index.html) |; | variantcalling | openjdk8 | [30869.4](https://travis-ci.com/broadinstitute/gatk/jobs/357066658) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30869.4/tests/test/index.html) |; | unit | openjdk8 | [30869.3](https://travis-ci.com/broadinstitute/gatk/jobs/357066657) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30869.3/tests/test/index.html) |; | integration | openjdk8 | [30869.2](https://travis-ci.com/broadinstitute/gatk/jobs/357066656) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30869.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6113#issuecomment-653150268:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6113#issuecomment-653150268,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30892](https://travis-ci.com/broadinstitute/gatk/builds/174640358); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30892.12](https://travis-ci.com/broadinstitute/gatk/jobs/358397668) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30892.12/tests/test/index.html) |; | integration | openjdk8 | [30892.2](https://travis-ci.com/broadinstitute/gatk/jobs/358397658) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30892.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6684#issuecomment-654947147:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6684#issuecomment-654947147,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30955](https://travis-ci.com/broadinstitute/gatk/builds/175590051); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30955.12](https://travis-ci.com/broadinstitute/gatk/jobs/360964271) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30955.12/tests/test/index.html) |; | integration | openjdk8 | [30955.2](https://travis-ci.com/broadinstitute/gatk/jobs/360964260) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30955.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658304029:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658304029,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30957](https://travis-ci.com/broadinstitute/gatk/builds/175592807); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30957.12](https://travis-ci.com/broadinstitute/gatk/jobs/360970944) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30957.12/tests/test/index.html) |; | integration | openjdk8 | [30957.2](https://travis-ci.com/broadinstitute/gatk/jobs/360970934) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30957.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658313849:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658313849,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30961](https://travis-ci.com/broadinstitute/gatk/builds/175596623); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30961.12](https://travis-ci.com/broadinstitute/gatk/jobs/360981529) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30961.12/tests/test/index.html) |; | integration | openjdk8 | [30961.2](https://travis-ci.com/broadinstitute/gatk/jobs/360981519) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30961.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658331353:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658331353,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30964](https://travis-ci.com/broadinstitute/gatk/builds/175616122); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30964.12](https://travis-ci.com/broadinstitute/gatk/jobs/361032988) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30964.12/tests/test/index.html) |; | integration | openjdk8 | [30964.2](https://travis-ci.com/broadinstitute/gatk/jobs/361032978) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30964.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658402464:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658402464,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30972](https://travis-ci.com/broadinstitute/gatk/builds/175949953); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [30972.1](https://travis-ci.com/broadinstitute/gatk/jobs/361875017) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30972.1/tests/test/index.html) |; | integration | openjdk11 | [30972.12](https://travis-ci.com/broadinstitute/gatk/jobs/361875028) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30972.12/tests/test/index.html) |; | integration | openjdk8 | [30972.2](https://travis-ci.com/broadinstitute/gatk/jobs/361875018) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30972.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-659640018:423,integrat,integration,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-659640018,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30974](https://travis-ci.com/broadinstitute/gatk/builds/175951574); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [30974.1](https://travis-ci.com/broadinstitute/gatk/jobs/361879074) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.1/tests/test/index.html) |; | unit | openjdk11 | [30974.13](https://travis-ci.com/broadinstitute/gatk/jobs/361879086) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.13/tests/test/index.html) |; | conda | openjdk8 | [30974.5](https://travis-ci.com/broadinstitute/gatk/jobs/361879078) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.5/tests/test/index.html) |; | integration | openjdk11 | [30974.12](https://travis-ci.com/broadinstitute/gatk/jobs/361879085) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.12/tests/test/index.html) |; | unit | openjdk8 | [30974.3](https://travis-ci.com/broadinstitute/gatk/jobs/361879076) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.3/tests/test/index.html) |; | integration | openjdk8 | [30974.2](https://travis-ci.com/broadinstitute/gatk/jobs/361879075) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-659647328:835,integrat,integration,835,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-659647328,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30976](https://travis-ci.com/broadinstitute/gatk/builds/175952777); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30976.12](https://travis-ci.com/broadinstitute/gatk/jobs/361882175) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30976.12/tests/test/index.html) |; | integration | openjdk8 | [30976.2](https://travis-ci.com/broadinstitute/gatk/jobs/361882165) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30976.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-659661207:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-659661207,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30984](https://travis-ci.com/broadinstitute/gatk/builds/176331364); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30984.12](https://travis-ci.com/broadinstitute/gatk/jobs/362887049) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30984.12/tests/test/index.html) |; | integration | openjdk8 | [30984.2](https://travis-ci.com/broadinstitute/gatk/jobs/362887038) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30984.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6602#issuecomment-661096333:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6602#issuecomment-661096333,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [30988](https://travis-ci.com/broadinstitute/gatk/builds/176344004); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30988.12](https://travis-ci.com/broadinstitute/gatk/jobs/362915950) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30988.12/tests/test/index.html) |; | integration | openjdk8 | [30988.2](https://travis-ci.com/broadinstitute/gatk/jobs/362915940) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30988.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6602#issuecomment-661139174:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6602#issuecomment-661139174,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31014](https://travis-ci.com/broadinstitute/gatk/builds/176929508); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31014.12](https://travis-ci.com/broadinstitute/gatk/jobs/364378637) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31014.12/tests/test/index.html) |; | integration | openjdk8 | [31014.2](https://travis-ci.com/broadinstitute/gatk/jobs/364378627) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31014.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6723#issuecomment-663219099:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6723#issuecomment-663219099,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31019](https://travis-ci.com/broadinstitute/gatk/builds/177075400); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [31019.13](https://travis-ci.com/broadinstitute/gatk/jobs/364732566) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31019.13/tests/test/index.html) |; | integration | openjdk11 | [31019.12](https://travis-ci.com/broadinstitute/gatk/jobs/364732565) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31019.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-663706251:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-663706251,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [31021](https://travis-ci.com/broadinstitute/gatk/builds/177076345); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [31021.13](https://travis-ci.com/broadinstitute/gatk/jobs/364735420) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31021.13/tests/test/index.html) |; | conda | openjdk8 | [31021.5](https://travis-ci.com/broadinstitute/gatk/jobs/364735412) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31021.5/tests/test/index.html) |; | integration | openjdk11 | [31021.12](https://travis-ci.com/broadinstitute/gatk/jobs/364735419) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31021.12/tests/test/index.html) |; | unit | openjdk8 | [31021.3](https://travis-ci.com/broadinstitute/gatk/jobs/364735410) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31021.3/tests/test/index.html) |; | integration | openjdk8 | [31021.2](https://travis-ci.com/broadinstitute/gatk/jobs/364735409) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31021.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-663710294:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-663710294,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31043](https://travis-ci.com/broadinstitute/gatk/builds/177838328); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [31043.13](https://travis-ci.com/broadinstitute/gatk/jobs/366761867) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31043.13/tests/test/index.html) |; | conda | openjdk8 | [31043.5](https://travis-ci.com/broadinstitute/gatk/jobs/366761859) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31043.5/tests/test/index.html) |; | integration | openjdk11 | [31043.12](https://travis-ci.com/broadinstitute/gatk/jobs/366761866) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31043.12/tests/test/index.html) |; | unit | openjdk8 | [31043.3](https://travis-ci.com/broadinstitute/gatk/jobs/366761857) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31043.3/tests/test/index.html) |; | integration | openjdk8 | [31043.2](https://travis-ci.com/broadinstitute/gatk/jobs/366761856) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31043.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-666525725:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-666525725,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31078](https://travis-ci.com/broadinstitute/gatk/builds/178593210); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31078.12](https://travis-ci.com/broadinstitute/gatk/jobs/368742472) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31078.12/tests/test/index.html) |; | variantcalling | openjdk8 | [31078.4](https://travis-ci.com/broadinstitute/gatk/jobs/368742464) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31078.4/tests/test/index.html) |; | integration | openjdk8 | [31078.2](https://travis-ci.com/broadinstitute/gatk/jobs/368742462) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31078.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-669368534:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-669368534,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31080](https://travis-ci.com/broadinstitute/gatk/builds/178599096); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31080.12](https://travis-ci.com/broadinstitute/gatk/jobs/368765328) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31080.12/tests/test/index.html) |; | integration | openjdk8 | [31080.2](https://travis-ci.com/broadinstitute/gatk/jobs/368765318) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31080.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-669402367:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-669402367,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31110](https://travis-ci.com/broadinstitute/gatk/builds/179177202); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31110.12](https://travis-ci.com/broadinstitute/gatk/jobs/370468323) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31110.12/tests/test/index.html) |; | integration | openjdk8 | [31110.2](https://travis-ci.com/broadinstitute/gatk/jobs/370468313) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31110.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-671583467:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-671583467,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31195](https://travis-ci.com/broadinstitute/gatk/builds/181151716); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [31195.14](https://travis-ci.com/broadinstitute/gatk/jobs/377065385) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31195.14/tests/test/index.html) |; | integration | openjdk8 | [31195.2](https://travis-ci.com/broadinstitute/gatk/jobs/377065373) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31195.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-679370909:426,integrat,integration,426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-679370909,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [31212](https://travis-ci.com/broadinstitute/gatk/builds/181345735); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31212.2](https://travis-ci.com/broadinstitute/gatk/jobs/377600452) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31212.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680182147:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680182147,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [31215](https://travis-ci.com/broadinstitute/gatk/builds/181356386); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31215.2](https://travis-ci.com/broadinstitute/gatk/jobs/377629183) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31215.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680225942:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680225942,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [31219](https://travis-ci.com/broadinstitute/gatk/builds/181373545); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31219.2](https://travis-ci.com/broadinstitute/gatk/jobs/377677482) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31219.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680264087:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680264087,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [31232](https://travis-ci.com/broadinstitute/gatk/builds/181489744); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31232.12](https://travis-ci.com/broadinstitute/gatk/jobs/377973557) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31232.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680949614:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680949614,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [31239](https://travis-ci.com/broadinstitute/gatk/builds/181521398); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31239.12](https://travis-ci.com/broadinstitute/gatk/jobs/378060367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31239.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-681066658:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-681066658,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [31247](https://travis-ci.com/broadinstitute/gatk/builds/181644287); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31247.2](https://travis-ci.com/broadinstitute/gatk/jobs/378372688) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31247.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-681992455:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-681992455,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [31250](https://travis-ci.com/broadinstitute/gatk/builds/181656346); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31250.2](https://travis-ci.com/broadinstitute/gatk/jobs/378403341) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31250.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-682037890:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-682037890,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [31337](https://travis-ci.com/broadinstitute/gatk/builds/183389891); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31337.12](https://travis-ci.com/broadinstitute/gatk/jobs/382388334) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31337.12/tests/test/index.html) |; | integration | openjdk8 | [31337.2](https://travis-ci.com/broadinstitute/gatk/jobs/382388324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31337.2/tests/test/index.html) |; | integration | openjdk8 | [31337.2](https://travis-ci.com/broadinstitute/gatk/jobs/382388324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31337.2/tests/test/index.html) |; | integration | openjdk11 | [31337.12](https://travis-ci.com/broadinstitute/gatk/jobs/382388334) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31337.12/tests/test/index.html) |; | integration | openjdk8 | [31337.2](https://travis-ci.com/broadinstitute/gatk/jobs/382388324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31337.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6799#issuecomment-688972966:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6799#issuecomment-688972966,5,['integrat'],['integration']
Deployability,Travis reported job failures from build [31339](https://travis-ci.com/broadinstitute/gatk/builds/183391027); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31339.12](https://travis-ci.com/broadinstitute/gatk/jobs/382390918) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31339.12/tests/test/index.html) |; | integration | openjdk8 | [31339.2](https://travis-ci.com/broadinstitute/gatk/jobs/382390908) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31339.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-688977676:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-688977676,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31347](https://travis-ci.com/broadinstitute/gatk/builds/183553091); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31347.12](https://travis-ci.com/broadinstitute/gatk/jobs/382751875) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31347.12/tests/test/index.html) |; | integration | openjdk8 | [31347.2](https://travis-ci.com/broadinstitute/gatk/jobs/382751865) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31347.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6802#issuecomment-689573574:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6802#issuecomment-689573574,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31349](https://travis-ci.com/broadinstitute/gatk/builds/183570461); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [31349.1](https://travis-ci.com/broadinstitute/gatk/jobs/382794132) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31349.1/tests/test/index.html) |; | integration | openjdk11 | [31349.12](https://travis-ci.com/broadinstitute/gatk/jobs/382794143) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31349.12/tests/test/index.html) |; | integration | openjdk8 | [31349.2](https://travis-ci.com/broadinstitute/gatk/jobs/382794133) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31349.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-689627653:423,integrat,integration,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-689627653,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31351](https://travis-ci.com/broadinstitute/gatk/builds/183609447); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31351.12](https://travis-ci.com/broadinstitute/gatk/jobs/382897378) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31351.12/tests/test/index.html) |; | integration | openjdk8 | [31351.2](https://travis-ci.com/broadinstitute/gatk/jobs/382897368) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31351.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-689773463:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-689773463,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31353](https://travis-ci.com/broadinstitute/gatk/builds/183610371); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31353.12](https://travis-ci.com/broadinstitute/gatk/jobs/382899552) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31353.12/tests/test/index.html) |; | integration | openjdk8 | [31353.2](https://travis-ci.com/broadinstitute/gatk/jobs/382899542) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31353.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-689779833:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-689779833,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31358](https://travis-ci.com/broadinstitute/gatk/builds/183616396); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31358.12](https://travis-ci.com/broadinstitute/gatk/jobs/382914758) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31358.12/tests/test/index.html) |; | integration | openjdk8 | [31358.2](https://travis-ci.com/broadinstitute/gatk/jobs/382914748) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31358.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-689804506:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-689804506,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31362](https://travis-ci.com/broadinstitute/gatk/builds/183621979); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31362.12](https://travis-ci.com/broadinstitute/gatk/jobs/382955645) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31362.12/tests/test/index.html) |; | integration | openjdk8 | [31362.2](https://travis-ci.com/broadinstitute/gatk/jobs/382955635) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31362.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6718#issuecomment-689817531:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6718#issuecomment-689817531,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31384](https://travis-ci.com/broadinstitute/gatk/builds/183805923); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31384.12](https://travis-ci.com/broadinstitute/gatk/jobs/383393943) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_31384.12/tests/test/index.html) |; | integration | openjdk8 | [31384.2](https://travis-ci.com/broadinstitute/gatk/jobs/383393933) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_31384.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6806#issuecomment-690768109:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6806#issuecomment-690768109,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31394](https://travis-ci.com/broadinstitute/gatk/builds/183915996); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [31394.14](https://travis-ci.com/broadinstitute/gatk/jobs/383673641) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31394.14/tests/test/index.html) |; | integration | openjdk11 | [31394.12](https://travis-ci.com/broadinstitute/gatk/jobs/383673639) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31394.12/tests/test/index.html) |; | integration | openjdk8 | [31394.2](https://travis-ci.com/broadinstitute/gatk/jobs/383673629) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31394.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6809#issuecomment-691150417:426,integrat,integration,426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6809#issuecomment-691150417,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31727](https://travis-ci.com/broadinstitute/gatk/builds/189051039); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31727.2](https://travis-ci.com/broadinstitute/gatk/jobs/397423689) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31727.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-706233780:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-706233780,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [31792](https://travis-ci.com/broadinstitute/gatk/builds/189715425); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31792.13](https://travis-ci.com/broadinstitute/gatk/jobs/398842818) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_31792.13/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6881#issuecomment-707791058:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6881#issuecomment-707791058,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [31957](https://travis-ci.com/broadinstitute/gatk/builds/195786303); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31957.12](https://travis-ci.com/broadinstitute/gatk/jobs/419334595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31957.12/tests/test/index.html) |; | integration | openjdk8 | [31957.2](https://travis-ci.com/broadinstitute/gatk/jobs/419334585) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31957.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-718862955:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-718862955,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [31965](https://travis-ci.com/broadinstitute/gatk/builds/195873537); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31965.12](https://travis-ci.com/broadinstitute/gatk/jobs/419598303) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31965.12/tests/test/index.html) |; | integration | openjdk8 | [31965.2](https://travis-ci.com/broadinstitute/gatk/jobs/419598293) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31965.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-718895504:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-718895504,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [32049](https://travis-ci.com/broadinstitute/gatk/builds/198559577); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32049.12](https://travis-ci.com/broadinstitute/gatk/jobs/429147025) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32049.12/tests/test/index.html) |; | integration | openjdk8 | [32049.2](https://travis-ci.com/broadinstitute/gatk/jobs/429147015) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32049.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-722658012:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-722658012,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [32149](https://travis-ci.com/broadinstitute/gatk/builds/202173930); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [32149.1](https://travis-ci.com/broadinstitute/gatk/jobs/441791105) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32149.1/tests/test/index.html) |; | integration | openjdk11 | [32149.12](https://travis-ci.com/broadinstitute/gatk/jobs/441791121) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32149.12/tests/test/index.html) |; | conda | openjdk8 | [32149.5](https://travis-ci.com/broadinstitute/gatk/jobs/441791111) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32149.5/tests/test/index.html) |; | unit | openjdk8 | [32149.3](https://travis-ci.com/broadinstitute/gatk/jobs/441791108) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32149.3/tests/test/index.html) |; | integration | openjdk8 | [32149.2](https://travis-ci.com/broadinstitute/gatk/jobs/441791106) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32149.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-729060312:423,integrat,integration,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-729060312,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [32180](https://travis-ci.com/broadinstitute/gatk/builds/202787538); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32180.12](https://travis-ci.com/broadinstitute/gatk/jobs/443607068) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32180.12/tests/test/index.html) |; | integration | openjdk8 | [32180.2](https://travis-ci.com/broadinstitute/gatk/jobs/443607058) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32180.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-730467975:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-730467975,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [32196](https://travis-ci.com/broadinstitute/gatk/builds/202875234); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32196.12](https://travis-ci.com/broadinstitute/gatk/jobs/443900497) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32196.12/tests/test/index.html) |; | integration | openjdk8 | [32196.2](https://travis-ci.com/broadinstitute/gatk/jobs/443900487) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32196.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-730608277:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-730608277,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [32198](https://travis-ci.com/broadinstitute/gatk/builds/202876316); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32198.12](https://travis-ci.com/broadinstitute/gatk/jobs/443903163) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32198.12/tests/test/index.html) |; | integration | openjdk8 | [32198.2](https://travis-ci.com/broadinstitute/gatk/jobs/443903153) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32198.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-730613743:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-730613743,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [32308](https://travis-ci.com/broadinstitute/gatk/builds/206017880); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32308.12](https://travis-ci.com/broadinstitute/gatk/jobs/452716639) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32308.12/tests/test/index.html) |; | integration | openjdk8 | [32308.2](https://travis-ci.com/broadinstitute/gatk/jobs/452716628) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32308.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-737442197:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-737442197,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [32329](https://travis-ci.com/broadinstitute/gatk/builds/206640419); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [32329.1](https://travis-ci.com/broadinstitute/gatk/jobs/454533901) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.1/tests/test/index.html) |; | cloud | openjdk11 | [32329.14](https://travis-ci.com/broadinstitute/gatk/jobs/454533914) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.14/tests/test/index.html) |; | integration | openjdk11 | [32329.12](https://travis-ci.com/broadinstitute/gatk/jobs/454533912) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.12/tests/test/index.html) |; | integration | openjdk8 | [32329.2](https://travis-ci.com/broadinstitute/gatk/jobs/454533902) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.2/tests/test/index.html) |; | cloud | openjdk8 | [32329.1](https://travis-ci.com/broadinstitute/gatk/jobs/454533901) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.1/tests/test/index.html) |; | cloud | openjdk11 | [32329.14](https://travis-ci.com/broadinstitute/gatk/jobs/454533914) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.14/tests/test/index.html) |; | integration | openjdk11 | [32329.12](https://travis-ci.com/broadinstitute/gatk/jobs/454533912) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.12/tests/test/index.html) |; | integration | openjdk8 | [32329.2](https://travis-ci.com/broadinstitute/gatk/jobs/454533902) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6989#issuecomment-738879938:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6989#issuecomment-738879938,4,['integrat'],['integration']
Deployability,Travis reported job failures from build [32366](https://travis-ci.com/broadinstitute/gatk/builds/208141255); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [32366.13](https://travis-ci.com/broadinstitute/gatk/jobs/458419765) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32366.13/tests/test/index.html) |; | integration | openjdk11 | [32366.12](https://travis-ci.com/broadinstitute/gatk/jobs/458419764) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32366.12/tests/test/index.html) |; | conda | openjdk8 | [32366.5](https://travis-ci.com/broadinstitute/gatk/jobs/458419757) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32366.5/tests/test/index.html) |; | unit | openjdk8 | [32366.3](https://travis-ci.com/broadinstitute/gatk/jobs/458419755) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32366.3/tests/test/index.html) |; | integration | openjdk8 | [32366.2](https://travis-ci.com/broadinstitute/gatk/jobs/458419754) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32366.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-743353051:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-743353051,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [32512](https://travis-ci.com/broadinstitute/gatk/builds/212721931); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk8 | [32512.3](https://travis-ci.com/broadinstitute/gatk/jobs/470580370) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.3/tests/test/index.html) |; | integration | openjdk8 | [32512.2](https://travis-ci.com/broadinstitute/gatk/jobs/470580369) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.2/tests/test/index.html) |; | cloud | openjdk11 | [32512.14](https://travis-ci.com/broadinstitute/gatk/jobs/470580381) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.14/tests/test/index.html) |; | cloud | openjdk8 | [32512.1](https://travis-ci.com/broadinstitute/gatk/jobs/470580368) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.1/tests/test/index.html) |; | unit | openjdk11 | [32512.13](https://travis-ci.com/broadinstitute/gatk/jobs/470580380) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.13/tests/test/index.html) |; | integration | openjdk11 | [32512.12](https://travis-ci.com/broadinstitute/gatk/jobs/470580379) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.12/tests/test/index.html) |; | unit | openjdk8 | [32512.3](https://travis-ci.com/broadinstitute/gatk/jobs/470580370) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.3/tests/test/index.html) |; | integration | openjdk8 | [32512.2](https://travis-ci.com/broadinstitute/gatk/jobs/470580369) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-758148911:422,integrat,integration,422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-758148911,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [32589](https://travis-ci.com/broadinstitute/gatk/builds/213965618); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32589.12](https://travis-ci.com/broadinstitute/gatk/jobs/473858986) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32589.12/tests/test/index.html) |; | integration | openjdk8 | [32589.2](https://travis-ci.com/broadinstitute/gatk/jobs/473858976) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32589.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7046#issuecomment-764774849:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7046#issuecomment-764774849,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [32607](https://travis-ci.com/broadinstitute/gatk/builds/214188217); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [32607.1](https://travis-ci.com/broadinstitute/gatk/jobs/474485135) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.1/tests/test/index.html) |; | cloud | openjdk11 | [32607.14](https://travis-ci.com/broadinstitute/gatk/jobs/474485148) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.14/tests/test/index.html) |; | integration | openjdk11 | [32607.12](https://travis-ci.com/broadinstitute/gatk/jobs/474485146) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.12/tests/test/index.html) |; | integration | openjdk8 | [32607.2](https://travis-ci.com/broadinstitute/gatk/jobs/474485136) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.2/tests/test/index.html) |; | cloud | openjdk11 | [32607.14](https://travis-ci.com/broadinstitute/gatk/jobs/474485148) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.14/tests/test/index.html) |; | cloud | openjdk8 | [32607.1](https://travis-ci.com/broadinstitute/gatk/jobs/474485135) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.1/tests/test/index.html) |; | integration | openjdk11 | [32607.12](https://travis-ci.com/broadinstitute/gatk/jobs/474485146) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.12/tests/test/index.html) |; | integration | openjdk8 | [32607.2](https://travis-ci.com/broadinstitute/gatk/jobs/474485136) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-765667586:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-765667586,4,['integrat'],['integration']
Deployability,Travis reported job failures from build [32618](https://travis-ci.com/broadinstitute/gatk/builds/214398386); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [32618.1](https://travis-ci.com/broadinstitute/gatk/jobs/475091885) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32618.1/tests/test/index.html) |; | cloud | openjdk11 | [32618.14](https://travis-ci.com/broadinstitute/gatk/jobs/475091898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32618.14/tests/test/index.html) |; | integration | openjdk11 | [32618.12](https://travis-ci.com/broadinstitute/gatk/jobs/475091896) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32618.12/tests/test/index.html) |; | integration | openjdk8 | [32618.2](https://travis-ci.com/broadinstitute/gatk/jobs/475091886) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32618.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6989#issuecomment-766922899:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6989#issuecomment-766922899,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [32622](https://travis-ci.com/broadinstitute/gatk/builds/214430101); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [32622.1](https://travis-ci.com/broadinstitute/gatk/jobs/475160500) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32622.1/tests/test/index.html) |; | cloud | openjdk11 | [32622.14](https://travis-ci.com/broadinstitute/gatk/jobs/475160513) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32622.14/tests/test/index.html) |; | integration | openjdk11 | [32622.12](https://travis-ci.com/broadinstitute/gatk/jobs/475160511) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32622.12/tests/test/index.html) |; | integration | openjdk8 | [32622.2](https://travis-ci.com/broadinstitute/gatk/jobs/475160501) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32622.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-767055706:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-767055706,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [32624](https://travis-ci.com/broadinstitute/gatk/builds/214440857); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32624.12](https://travis-ci.com/broadinstitute/gatk/jobs/475184731) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32624.12/tests/test/index.html) |; | integration | openjdk8 | [32624.2](https://travis-ci.com/broadinstitute/gatk/jobs/475184721) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32624.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-767117162:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-767117162,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [32658](https://travis-ci.com/broadinstitute/gatk/builds/214909015); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32658.12](https://travis-ci.com/broadinstitute/gatk/jobs/477355523) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32658.12/tests/test/index.html) |; | integration | openjdk8 | [32658.2](https://travis-ci.com/broadinstitute/gatk/jobs/477355513) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32658.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7058#issuecomment-768431643:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7058#issuecomment-768431643,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [32698](https://travis-ci.com/broadinstitute/gatk/builds/215638691); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32698.12](https://travis-ci.com/broadinstitute/gatk/jobs/479312671) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32698.12/tests/test/index.html) |; | integration | openjdk8 | [32698.2](https://travis-ci.com/broadinstitute/gatk/jobs/479312661) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32698.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7063#issuecomment-771066064:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7063#issuecomment-771066064,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [32700](https://travis-ci.com/broadinstitute/gatk/builds/215640700); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [32700.2](https://travis-ci.com/broadinstitute/gatk/jobs/479317038) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32700.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7063#issuecomment-771096981:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7063#issuecomment-771096981,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [32714](https://travis-ci.com/broadinstitute/gatk/builds/215832180); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32714.12](https://travis-ci.com/broadinstitute/gatk/jobs/479776403) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32714.12/tests/test/index.html) |; | integration | openjdk8 | [32714.2](https://travis-ci.com/broadinstitute/gatk/jobs/479776393) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32714.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7066#issuecomment-772003143:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7066#issuecomment-772003143,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [32755](https://travis-ci.com/broadinstitute/gatk/builds/216440553); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [32755.13](https://travis-ci.com/broadinstitute/gatk/jobs/481338469) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32755.13/tests/test/index.html) |; | integration | openjdk11 | [32755.12](https://travis-ci.com/broadinstitute/gatk/jobs/481338468) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32755.12/tests/test/index.html) |; | unit | openjdk8 | [32755.3](https://travis-ci.com/broadinstitute/gatk/jobs/481338459) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32755.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6763#issuecomment-775371146:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6763#issuecomment-775371146,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [32758](https://travis-ci.com/broadinstitute/gatk/builds/216451581); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32758.12](https://travis-ci.com/broadinstitute/gatk/jobs/481368144) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32758.12/tests/test/index.html) |; | integration | openjdk8 | [32758.2](https://travis-ci.com/broadinstitute/gatk/jobs/481368134) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32758.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6763#issuecomment-775457190:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6763#issuecomment-775457190,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [33028](https://travis-ci.com/broadinstitute/gatk/builds/218904203); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [33028.13](https://travis-ci.com/broadinstitute/gatk/jobs/487894628) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33028.13/tests/test/index.html) |; | integration | openjdk11 | [33028.12](https://travis-ci.com/broadinstitute/gatk/jobs/487894627) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33028.12/tests/test/index.html) |; | integration | openjdk8 | [33028.2](https://travis-ci.com/broadinstitute/gatk/jobs/487894617) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33028.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-790085277:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-790085277,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [33241](https://travis-ci.com/broadinstitute/gatk/builds/220390768); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33241.12](https://travis-ci.com/broadinstitute/gatk/jobs/491751868) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33241.12/tests/test/index.html) |; | integration | openjdk8 | [33241.2](https://travis-ci.com/broadinstitute/gatk/jobs/491751858) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33241.2/tests/test/index.html) |; | integration | openjdk11 | [33241.12](https://travis-ci.com/broadinstitute/gatk/jobs/491751868) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33241.12/tests/test/index.html) |; | integration | openjdk8 | [33241.2](https://travis-ci.com/broadinstitute/gatk/jobs/491751858) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33241.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-801174546:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-801174546,4,['integrat'],['integration']
Deployability,Travis reported job failures from build [33277](https://travis-ci.com/broadinstitute/gatk/builds/220814326); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [33277.1](https://travis-ci.com/broadinstitute/gatk/jobs/492787754) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.1/tests/test/index.html) |; | cloud | openjdk11 | [33277.14](https://travis-ci.com/broadinstitute/gatk/jobs/492787767) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.14/tests/test/index.html) |; | unit | openjdk11 | [33277.13](https://travis-ci.com/broadinstitute/gatk/jobs/492787766) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.13/tests/test/index.html) |; | integration | openjdk11 | [33277.12](https://travis-ci.com/broadinstitute/gatk/jobs/492787765) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.12/tests/test/index.html) |; | unit | openjdk8 | [33277.3](https://travis-ci.com/broadinstitute/gatk/jobs/492787756) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.3/tests/test/index.html) |; | integration | openjdk8 | [33277.2](https://travis-ci.com/broadinstitute/gatk/jobs/492787755) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-804124554:838,integrat,integration,838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-804124554,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [33368](https://travis-ci.com/broadinstitute/gatk/builds/221347661); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [33368.1](https://travis-ci.com/broadinstitute/gatk/jobs/494112466) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33368.1/tests/test/index.html) |; | cloud | openjdk11 | [33368.14](https://travis-ci.com/broadinstitute/gatk/jobs/494112479) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33368.14/tests/test/index.html) |; | integration | openjdk11 | [33368.12](https://travis-ci.com/broadinstitute/gatk/jobs/494112477) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33368.12/tests/test/index.html) |; | integration | openjdk8 | [33368.2](https://travis-ci.com/broadinstitute/gatk/jobs/494112467) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33368.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7166#issuecomment-808550699:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7166#issuecomment-808550699,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [33381](https://travis-ci.com/broadinstitute/gatk/builds/221504222); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [33381.14](https://travis-ci.com/broadinstitute/gatk/jobs/494506581) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.14/tests/test/index.html) |; | cloud | openjdk8 | [33381.1](https://travis-ci.com/broadinstitute/gatk/jobs/494506568) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.1/tests/test/index.html) |; | unit | openjdk11 | [33381.13](https://travis-ci.com/broadinstitute/gatk/jobs/494506580) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.13/tests/test/index.html) |; | integration | openjdk11 | [33381.12](https://travis-ci.com/broadinstitute/gatk/jobs/494506579) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.12/tests/test/index.html) |; | unit | openjdk8 | [33381.3](https://travis-ci.com/broadinstitute/gatk/jobs/494506570) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.3/tests/test/index.html) |; | integration | openjdk8 | [33381.2](https://travis-ci.com/broadinstitute/gatk/jobs/494506569) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7166#issuecomment-809438028:838,integrat,integration,838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7166#issuecomment-809438028,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [33441](https://travis-ci.com/broadinstitute/gatk/builds/221813707); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33441.12](https://travis-ci.com/broadinstitute/gatk/jobs/495278045) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33441.12/tests/test/index.html) |; | integration | openjdk8 | [33441.2](https://travis-ci.com/broadinstitute/gatk/jobs/495278035) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33441.2/tests/test/index.html) |; | integration | openjdk11 | [33441.12](https://travis-ci.com/broadinstitute/gatk/jobs/495278045) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33441.12/tests/test/index.html) |; | integration | openjdk8 | [33441.2](https://travis-ci.com/broadinstitute/gatk/jobs/495278035) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33441.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-811282668:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-811282668,4,['integrat'],['integration']
Deployability,Travis reported job failures from build [33523](https://travis-ci.com/broadinstitute/gatk/builds/222089183); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33523.12](https://travis-ci.com/broadinstitute/gatk/jobs/495929374) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33523.12/tests/test/index.html) |; | integration | openjdk8 | [33523.2](https://travis-ci.com/broadinstitute/gatk/jobs/495929364) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33523.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813018382:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813018382,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [33528](https://travis-ci.com/broadinstitute/gatk/builds/222109060); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33528.12](https://travis-ci.com/broadinstitute/gatk/jobs/495994529) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33528.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813154031:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813154031,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [33531](https://travis-ci.com/broadinstitute/gatk/builds/222109820); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33531.12](https://travis-ci.com/broadinstitute/gatk/jobs/495997078) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33531.12/tests/test/index.html) |; | integration | openjdk8 | [33531.2](https://travis-ci.com/broadinstitute/gatk/jobs/495997068) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33531.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813161773:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813161773,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [33698](https://travis-ci.com/broadinstitute/gatk/builds/222963404); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33698.12](https://travis-ci.com/broadinstitute/gatk/jobs/498206052) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33698.12/tests/test/index.html) |; | integration | openjdk8 | [33698.2](https://travis-ci.com/broadinstitute/gatk/jobs/498206042) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33698.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-818922214:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-818922214,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [33752](https://travis-ci.com/broadinstitute/gatk/builds/223087196); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [33752.14](https://travis-ci.com/broadinstitute/gatk/jobs/498538900) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.14/tests/test/index.html) |; | cloud | openjdk8 | [33752.1](https://travis-ci.com/broadinstitute/gatk/jobs/498538887) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.1/tests/test/index.html) |; | unit | openjdk11 | [33752.13](https://travis-ci.com/broadinstitute/gatk/jobs/498538899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.13/tests/test/index.html) |; | integration | openjdk11 | [33752.12](https://travis-ci.com/broadinstitute/gatk/jobs/498538898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.12/tests/test/index.html) |; | variantcalling | openjdk8 | [33752.4](https://travis-ci.com/broadinstitute/gatk/jobs/498538890) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.4/tests/test/index.html) |; | unit | openjdk8 | [33752.3](https://travis-ci.com/broadinstitute/gatk/jobs/498538889) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.3/tests/test/index.html) |; | conda | openjdk8 | [33752.5](https://travis-ci.com/broadinstitute/gatk/jobs/498538891) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.5/tests/test/index.html) |; | integration | openjdk8 | [33752.2](https://travis-ci.com/broadinstitute/gatk/jobs/498538888) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.2/tests/test/index.html) |; | cloud | openjdk11 | [33752.14](https://travis-ci.com/broadinstitute/gatk/jobs/498538900) | [logs](https://storage.g,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-819750234:838,integrat,integration,838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-819750234,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [33764](https://travis-ci.com/broadinstitute/gatk/builds/223104949); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [33764.13](https://travis-ci.com/broadinstitute/gatk/jobs/498596230) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_33764.13/tests/test/index.html) |; | integration | openjdk11 | [33764.12](https://travis-ci.com/broadinstitute/gatk/jobs/498596229) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_33764.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7192#issuecomment-819880055:431,integrat,integration,431,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7192#issuecomment-819880055,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [33778](https://travis-ci.com/broadinstitute/gatk/builds/223218042); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [33778.1](https://travis-ci.com/broadinstitute/gatk/jobs/498881502) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.1/tests/test/index.html) |; | cloud | openjdk11 | [33778.14](https://travis-ci.com/broadinstitute/gatk/jobs/498881515) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.14/tests/test/index.html) |; | unit | openjdk11 | [33778.13](https://travis-ci.com/broadinstitute/gatk/jobs/498881514) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.13/tests/test/index.html) |; | integration | openjdk11 | [33778.12](https://travis-ci.com/broadinstitute/gatk/jobs/498881513) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.12/tests/test/index.html) |; | variantcalling | openjdk8 | [33778.4](https://travis-ci.com/broadinstitute/gatk/jobs/498881505) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.4/tests/test/index.html) |; | unit | openjdk8 | [33778.3](https://travis-ci.com/broadinstitute/gatk/jobs/498881504) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-820624091:838,integrat,integration,838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-820624091,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [33826](https://travis-ci.com/broadinstitute/gatk/builds/223338129); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [33826.13](https://travis-ci.com/broadinstitute/gatk/jobs/499176631) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33826.13/tests/test/index.html) |; | integration | openjdk11 | [33826.12](https://travis-ci.com/broadinstitute/gatk/jobs/499176630) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33826.12/tests/test/index.html) |; | unit | openjdk8 | [33826.3](https://travis-ci.com/broadinstitute/gatk/jobs/499176621) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33826.3/tests/test/index.html) |; | variantcalling | openjdk8 | [33826.4](https://travis-ci.com/broadinstitute/gatk/jobs/499176622) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33826.4/tests/test/index.html) |; | integration | openjdk8 | [33826.2](https://travis-ci.com/broadinstitute/gatk/jobs/499176620) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33826.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-821531530:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-821531530,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [33926](https://travis-ci.com/broadinstitute/gatk/builds/224016577); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [33926.14](https://travis-ci.com/broadinstitute/gatk/jobs/500776650) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33926.14/tests/test/index.html) |; | cloud | openjdk8 | [33926.1](https://travis-ci.com/broadinstitute/gatk/jobs/500776637) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33926.1/tests/test/index.html) |; | integration | openjdk11 | [33926.12](https://travis-ci.com/broadinstitute/gatk/jobs/500776648) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33926.12/tests/test/index.html) |; | variantcalling | openjdk8 | [33926.4](https://travis-ci.com/broadinstitute/gatk/jobs/500776640) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33926.4/tests/test/index.html) |; | integration | openjdk8 | [33926.2](https://travis-ci.com/broadinstitute/gatk/jobs/500776638) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33926.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6514#issuecomment-825820423:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6514#issuecomment-825820423,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [34034](https://travis-ci.com/broadinstitute/gatk/builds/224639210); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [34034.1](https://travis-ci.com/broadinstitute/gatk/jobs/502313480) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.1/tests/test/index.html) |; | cloud | openjdk11 | [34034.14](https://travis-ci.com/broadinstitute/gatk/jobs/502313493) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.14/tests/test/index.html) |; | unit | openjdk11 | [34034.13](https://travis-ci.com/broadinstitute/gatk/jobs/502313492) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.13/tests/test/index.html) |; | integration | openjdk11 | [34034.12](https://travis-ci.com/broadinstitute/gatk/jobs/502313491) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.12/tests/test/index.html) |; | variantcalling | openjdk8 | [34034.4](https://travis-ci.com/broadinstitute/gatk/jobs/502313483) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.4/tests/test/index.html) |; | conda | openjdk8 | [34034.5](https://travis-ci.com/broadinstitute/gatk/jobs/502313484) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.5/tests/test/index.html) |; | unit | openjdk8 | [34034.3](https://travis-ci.com/broadinstitute/gatk/jobs/502313482) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.3/tests/test/index.html) |; | integration | openjdk8 | [34034.2](https://travis-ci.com/broadinstitute/gatk/jobs/502313481) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-830228734:838,integrat,integration,838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-830228734,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [34176](https://travis-ci.com/broadinstitute/gatk/builds/225873785); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34176.12](https://travis-ci.com/broadinstitute/gatk/jobs/505251208) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34176.12/tests/test/index.html) |; | integration | openjdk8 | [34176.2](https://travis-ci.com/broadinstitute/gatk/jobs/505251198) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34176.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-840825700:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-840825700,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [34203](https://travis-ci.com/broadinstitute/gatk/builds/226224930); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34203.12](https://travis-ci.com/broadinstitute/gatk/jobs/506165950) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34203.12/tests/test/index.html) |; | integration | openjdk8 | [34203.2](https://travis-ci.com/broadinstitute/gatk/jobs/506165940) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34203.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-843369362:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-843369362,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [34279](https://travis-ci.com/broadinstitute/gatk/builds/226733391); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34279.12](https://travis-ci.com/broadinstitute/gatk/jobs/507507826) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34279.12/tests/test/index.html) |; | integration | openjdk8 | [34279.2](https://travis-ci.com/broadinstitute/gatk/jobs/507507816) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34279.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-847313079:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-847313079,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [34296](https://travis-ci.com/broadinstitute/gatk/builds/226870023); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34296.12](https://travis-ci.com/broadinstitute/gatk/jobs/507857713) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34296.12/tests/test/index.html) |; | integration | openjdk8 | [34296.2](https://travis-ci.com/broadinstitute/gatk/jobs/507857703) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34296.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-848129767:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-848129767,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [34321](https://travis-ci.com/broadinstitute/gatk/builds/227013958); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34321.12](https://travis-ci.com/broadinstitute/gatk/jobs/508266496) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_34321.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7242#issuecomment-849067439:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7242#issuecomment-849067439,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [34441](https://travis-ci.com/broadinstitute/gatk/builds/228463818); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34441.12](https://travis-ci.com/broadinstitute/gatk/jobs/512421669) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34441.12/tests/test/index.html) |; | unit | openjdk8 | [34441.3](https://travis-ci.com/broadinstitute/gatk/jobs/512421660) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34441.3/tests/test/index.html) |; | variantcalling | openjdk8 | [34441.4](https://travis-ci.com/broadinstitute/gatk/jobs/512421661) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34441.4/tests/test/index.html) |; | integration | openjdk8 | [34441.2](https://travis-ci.com/broadinstitute/gatk/jobs/512421659) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34441.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-857761857:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-857761857,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [34475](https://travis-ci.com/broadinstitute/gatk/builds/228578939); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34475.12](https://travis-ci.com/broadinstitute/gatk/jobs/512727645) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34475.12/tests/test/index.html) |; | integration | openjdk8 | [34475.2](https://travis-ci.com/broadinstitute/gatk/jobs/512727635) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34475.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7303#issuecomment-858525709:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7303#issuecomment-858525709,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [34532](https://travis-ci.com/broadinstitute/gatk/builds/228754848); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34532.12](https://travis-ci.com/broadinstitute/gatk/jobs/513165911) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34532.12/tests/test/index.html) |; | unit | openjdk8 | [34532.3](https://travis-ci.com/broadinstitute/gatk/jobs/513165902) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34532.3/tests/test/index.html) |; | variantcalling | openjdk8 | [34532.4](https://travis-ci.com/broadinstitute/gatk/jobs/513165903) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34532.4/tests/test/index.html) |; | integration | openjdk8 | [34532.2](https://travis-ci.com/broadinstitute/gatk/jobs/513165901) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34532.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-859898603:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-859898603,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [34651](https://travis-ci.com/broadinstitute/gatk/builds/230215055); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34651.12](https://travis-ci.com/broadinstitute/gatk/jobs/517109941) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34651.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7295#issuecomment-865183878:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7295#issuecomment-865183878,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [34916](https://app.travis-ci.com/broadinstitute/gatk/builds/232376083); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34916.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/523434656) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_34916.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7305#issuecomment-877695650:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7305#issuecomment-877695650,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [34953](https://app.travis-ci.com/broadinstitute/gatk/builds/232776802); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34953.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524527790) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34953.12/tests/test/index.html) |; | integration | openjdk8 | [34953.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/524527780) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34953.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-880180901:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-880180901,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [34955](https://app.travis-ci.com/broadinstitute/gatk/builds/232778439); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34955.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524531918) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34955.12/tests/test/index.html) |; | integration | openjdk8 | [34955.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/524531908) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34955.2/tests/test/index.html) |; | integration | openjdk11 | [34955.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524531918) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34955.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-880195656:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-880195656,3,['integrat'],['integration']
Deployability,Travis reported job failures from build [34968](https://app.travis-ci.com/broadinstitute/gatk/builds/232871891); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34968.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524746057) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_34968.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7342#issuecomment-880918843:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7342#issuecomment-880918843,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [34975](https://app.travis-ci.com/broadinstitute/gatk/builds/232883183); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34975.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524775421) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34975.12/tests/test/index.html) |; | integration | openjdk8 | [34975.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/524775411) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34975.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-880991859:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-880991859,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [34989](https://app.travis-ci.com/broadinstitute/gatk/builds/232957715); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34989.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524971906) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34989.12/tests/test/index.html) |; | integration | openjdk8 | [34989.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/524971896) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34989.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881554091:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881554091,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [34993](https://app.travis-ci.com/broadinstitute/gatk/builds/232963432); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34993.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524986404) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34993.12/tests/test/index.html) |; | integration | openjdk8 | [34993.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/524986393) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34993.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881599208:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881599208,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [34997](https://app.travis-ci.com/broadinstitute/gatk/builds/232970936); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34997.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/525003829) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34997.12/tests/test/index.html) |; | integration | openjdk8 | [34997.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/525003819) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34997.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881652786:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881652786,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [34999](https://app.travis-ci.com/broadinstitute/gatk/builds/232971052); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34999.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/525004179) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34999.12/tests/test/index.html) |; | integration | openjdk8 | [34999.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/525004169) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34999.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881652638:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881652638,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35038](https://app.travis-ci.com/broadinstitute/gatk/builds/233229631); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [35038.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731805) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.1/tests/test/index.html) |; | cloud | openjdk11 | [35038.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731818) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.14/tests/test/index.html) |; | unit | openjdk11 | [35038.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731817) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.13/tests/test/index.html) |; | integration | openjdk11 | [35038.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731816) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.12/tests/test/index.html) |; | unit | openjdk8 | [35038.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731807) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.3/tests/test/index.html) |; | variantcalling | openjdk8 | [35038.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731808) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.4/tests/test/index.html) |; | conda | openjdk8 | [35038.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731809) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.5/tests/test/index.html) |; | integration | openjdk8 | [35038.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731806) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-883544427:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-883544427,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35066](https://app.travis-ci.com/broadinstitute/gatk/builds/233352611); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [35066.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037648) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.1/tests/test/index.html) |; | cloud | openjdk11 | [35066.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037661) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.14/tests/test/index.html) |; | unit | openjdk11 | [35066.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037660) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.13/tests/test/index.html) |; | integration | openjdk11 | [35066.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037659) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.12/tests/test/index.html) |; | unit | openjdk8 | [35066.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037650) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.3/tests/test/index.html) |; | variantcalling | openjdk8 | [35066.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037651) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.4/tests/test/index.html) |; | conda | openjdk8 | [35066.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037652) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.5/tests/test/index.html) |; | integration | openjdk8 | [35066.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037649) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884405742:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884405742,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35068](https://app.travis-ci.com/broadinstitute/gatk/builds/233354016); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [35068.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041270) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.14/tests/test/index.html) |; | cloud | openjdk8 | [35068.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041257) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.1/tests/test/index.html) |; | unit | openjdk11 | [35068.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041269) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.13/tests/test/index.html) |; | integration | openjdk11 | [35068.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041268) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.12/tests/test/index.html) |; | unit | openjdk8 | [35068.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041259) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.3/tests/test/index.html) |; | conda | openjdk8 | [35068.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041261) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.5/tests/test/index.html) |; | variantcalling | openjdk8 | [35068.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041260) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.4/tests/test/index.html) |; | integration | openjdk8 | [35068.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041258) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884419815:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884419815,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35073](https://app.travis-ci.com/broadinstitute/gatk/builds/233356361); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [35073.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047078) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.1/tests/test/index.html) |; | cloud | openjdk11 | [35073.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047091) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.14/tests/test/index.html) |; | unit | openjdk11 | [35073.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047090) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.13/tests/test/index.html) |; | integration | openjdk11 | [35073.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047089) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.12/tests/test/index.html) |; | unit | openjdk8 | [35073.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.3/tests/test/index.html) |; | conda | openjdk8 | [35073.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047082) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.5/tests/test/index.html) |; | variantcalling | openjdk8 | [35073.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.4/tests/test/index.html) |; | integration | openjdk8 | [35073.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884440415:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884440415,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35075](https://app.travis-ci.com/broadinstitute/gatk/builds/233357441); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35075.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050087) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35075.13/tests/test/index.html) |; | integration | openjdk11 | [35075.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050086) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35075.12/tests/test/index.html) |; | unit | openjdk8 | [35075.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050077) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35075.3/tests/test/index.html) |; | integration | openjdk8 | [35075.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050076) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35075.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884464290:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884464290,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35077](https://app.travis-ci.com/broadinstitute/gatk/builds/233357592); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35077.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050451) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35077.13/tests/test/index.html) |; | integration | openjdk11 | [35077.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050450) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35077.12/tests/test/index.html) |; | unit | openjdk8 | [35077.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050441) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35077.3/tests/test/index.html) |; | integration | openjdk8 | [35077.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050440) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35077.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884466100:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884466100,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35104](https://app.travis-ci.com/broadinstitute/gatk/builds/233468304); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35104.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526328126) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35104.13/tests/test/index.html) |; | integration | openjdk11 | [35104.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526328125) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35104.12/tests/test/index.html) |; | unit | openjdk8 | [35104.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526328116) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35104.3/tests/test/index.html) |; | integration | openjdk8 | [35104.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526328115) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35104.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-885267425:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-885267425,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35151](https://app.travis-ci.com/broadinstitute/gatk/builds/233705984); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35151.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526977289) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35151.13/tests/test/index.html) |; | integration | openjdk11 | [35151.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526977288) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35151.12/tests/test/index.html) |; | unit | openjdk8 | [35151.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526977279) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35151.3/tests/test/index.html) |; | integration | openjdk8 | [35151.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526977278) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35151.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7370#issuecomment-886981872:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7370#issuecomment-886981872,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35153](https://app.travis-ci.com/broadinstitute/gatk/builds/233712151); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35153.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526992860) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35153.13/tests/test/index.html) |; | integration | openjdk11 | [35153.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526992859) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35153.12/tests/test/index.html) |; | unit | openjdk8 | [35153.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526992850) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35153.3/tests/test/index.html) |; | integration | openjdk8 | [35153.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526992849) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35153.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887032589:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887032589,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35156](https://app.travis-ci.com/broadinstitute/gatk/builds/233712370); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35156.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526993410) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35156.13/tests/test/index.html) |; | integration | openjdk11 | [35156.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526993409) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35156.12/tests/test/index.html) |; | unit | openjdk8 | [35156.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526993400) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35156.3/tests/test/index.html) |; | integration | openjdk8 | [35156.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526993399) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35156.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887035947:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887035947,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35159](https://app.travis-ci.com/broadinstitute/gatk/builds/233733841); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35159.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/527041438) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35159.13/tests/test/index.html) |; | integration | openjdk11 | [35159.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/527041437) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35159.12/tests/test/index.html) |; | unit | openjdk8 | [35159.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/527041428) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35159.3/tests/test/index.html) |; | integration | openjdk8 | [35159.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/527041427) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35159.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887209071:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887209071,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35162](https://app.travis-ci.com/broadinstitute/gatk/builds/233781027); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35162.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/527164191) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35162.13/tests/test/index.html) |; | integration | openjdk11 | [35162.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/527164190) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35162.12/tests/test/index.html) |; | unit | openjdk8 | [35162.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/527164181) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35162.3/tests/test/index.html) |; | integration | openjdk8 | [35162.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/527164180) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35162.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7370#issuecomment-887581627:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7370#issuecomment-887581627,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35191](https://app.travis-ci.com/broadinstitute/gatk/builds/233897916); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35191.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/527474110) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35191.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7378#issuecomment-888459910:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7378#issuecomment-888459910,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [35222](https://app.travis-ci.com/broadinstitute/gatk/builds/234104192); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35222.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/528002701) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35222.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7355#issuecomment-889960163:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7355#issuecomment-889960163,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [35263](https://app.travis-ci.com/broadinstitute/gatk/builds/234381437); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35263.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/528794786) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35263.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7389#issuecomment-891948742:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7389#issuecomment-891948742,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [35281](https://app.travis-ci.com/broadinstitute/gatk/builds/234493943); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35281.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/529086898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35281.13/tests/test/index.html) |; | integration | openjdk11 | [35281.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/529086897) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35281.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35281.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/529086889) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35281.4/tests/test/index.html) |; | unit | openjdk8 | [35281.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/529086888) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35281.3/tests/test/index.html) |; | integration | openjdk8 | [35281.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/529086887) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35281.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-892730894:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-892730894,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35283](https://app.travis-ci.com/broadinstitute/gatk/builds/234495207); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35283.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/529090922) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35283.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35283.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/529090914) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35283.4/tests/test/index.html) |; | integration | openjdk8 | [35283.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/529090912) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35283.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892751062:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892751062,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35285](https://app.travis-ci.com/broadinstitute/gatk/builds/234495551); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35285.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/529091673) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35285.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35285.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/529091665) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35285.4/tests/test/index.html) |; | integration | openjdk8 | [35285.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/529091663) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35285.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892753629:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892753629,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35299](https://app.travis-ci.com/broadinstitute/gatk/builds/234500111); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35299.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/529102784) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35299.13/tests/test/index.html) |; | integration | openjdk11 | [35299.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/529102783) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35299.12/tests/test/index.html) |; | unit | openjdk8 | [35299.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/529102774) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35299.3/tests/test/index.html) |; | variantcalling | openjdk8 | [35299.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/529102775) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35299.4/tests/test/index.html) |; | integration | openjdk8 | [35299.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/529102773) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35299.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-892780628:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-892780628,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35352](https://app.travis-ci.com/broadinstitute/gatk/builds/234805799); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35352.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/529942933) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35352.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7381#issuecomment-894924291:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7381#issuecomment-894924291,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [35359](https://app.travis-ci.com/broadinstitute/gatk/builds/234864331); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35359.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/530084737) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35359.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7396#issuecomment-895367993:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7396#issuecomment-895367993,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [35408](https://app.travis-ci.com/broadinstitute/gatk/builds/235081908); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [35408.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/530725600) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35408.4/tests/test/index.html) |; | integration | openjdk8 | [35408.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/530725598) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896970810:440,integrat,integration,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896970810,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [35460](https://app.travis-ci.com/broadinstitute/gatk/builds/235309831); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35460.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/531318301) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35460.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-898668477:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-898668477,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [35462](https://app.travis-ci.com/broadinstitute/gatk/builds/235310455); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35462.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/531320214) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35462.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-898675262:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-898675262,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [35466](https://app.travis-ci.com/broadinstitute/gatk/builds/235310716); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35466.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/531321172) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35466.12/tests/test/index.html) |; | integration | openjdk8 | [35466.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/531321162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35466.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7223#issuecomment-898680924:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7223#issuecomment-898680924,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35514](https://app.travis-ci.com/broadinstitute/gatk/builds/235493198); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35514.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/531838051) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35514.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-899777125:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-899777125,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [35542](https://app.travis-ci.com/broadinstitute/gatk/builds/235595824); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35542.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/532100892) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35542.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35542.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/532100884) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35542.4/tests/test/index.html) |; | integration | openjdk8 | [35542.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/532100882) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35542.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900593417:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900593417,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35544](https://app.travis-ci.com/broadinstitute/gatk/builds/235596805); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35544.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103274) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35544.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35544.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103266) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35544.4/tests/test/index.html) |; | integration | openjdk8 | [35544.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103264) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35544.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900601946:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900601946,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35546](https://app.travis-ci.com/broadinstitute/gatk/builds/235596899); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35546.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103522) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35546.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35546.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103514) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35546.4/tests/test/index.html) |; | integration | openjdk8 | [35546.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103512) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35546.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900603007:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900603007,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35614](https://app.travis-ci.com/broadinstitute/gatk/builds/235796214); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35614.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/532702729) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35614.13/tests/test/index.html) |; | integration | openjdk11 | [35614.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/532702728) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35614.12/tests/test/index.html) |; | unit | openjdk8 | [35614.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/532702719) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35614.3/tests/test/index.html) |; | integration | openjdk8 | [35614.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/532702718) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35614.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-902180244:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-902180244,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35652](https://app.travis-ci.com/broadinstitute/gatk/builds/236008516); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35652.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/533261173) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35652.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7435#issuecomment-903940281:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7435#issuecomment-903940281,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [35656](https://app.travis-ci.com/broadinstitute/gatk/builds/236041444); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35656.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/533345256) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35656.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7434#issuecomment-904228563:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7434#issuecomment-904228563,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [35662](https://app.travis-ci.com/broadinstitute/gatk/builds/236042965); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35662.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/533348915) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35662.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7434#issuecomment-904245474:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7434#issuecomment-904245474,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [35724](https://app.travis-ci.com/broadinstitute/gatk/builds/236321310); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35724.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/534059154) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35724.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7440#issuecomment-906727232:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7440#issuecomment-906727232,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [35827](https://app.travis-ci.com/broadinstitute/gatk/builds/236734529); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35827.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/535106160) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35827.13/tests/test/index.html) |; | integration | openjdk11 | [35827.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/535106159) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35827.12/tests/test/index.html) |; | unit | openjdk8 | [35827.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/535106150) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35827.3/tests/test/index.html) |; | integration | openjdk8 | [35827.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/535106149) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35827.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7223#issuecomment-910535218:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7223#issuecomment-910535218,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35833](https://app.travis-ci.com/broadinstitute/gatk/builds/236752487); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35833.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/535149111) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35833.13/tests/test/index.html) |; | integration | openjdk11 | [35833.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/535149110) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35833.12/tests/test/index.html) |; | unit | openjdk8 | [35833.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/535149101) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35833.3/tests/test/index.html) |; | integration | openjdk8 | [35833.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/535149100) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35833.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-910840432:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-910840432,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [35880](https://app.travis-ci.com/broadinstitute/gatk/builds/237199054); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35880.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/536209432) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35880.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7426#issuecomment-915310800:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7426#issuecomment-915310800,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [35897](https://app.travis-ci.com/broadinstitute/gatk/builds/237244422); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35897.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/536323693) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35897.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7457#issuecomment-915694430:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7457#issuecomment-915694430,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [35935](https://app.travis-ci.com/broadinstitute/gatk/builds/237322016); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35935.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/536512235) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35935.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7463#issuecomment-916403114:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7463#issuecomment-916403114,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [35951](https://app.travis-ci.com/broadinstitute/gatk/builds/237326442); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35951.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/536522087) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35951.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7463#issuecomment-916440221:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7463#issuecomment-916440221,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [36058](https://app.travis-ci.com/broadinstitute/gatk/builds/237840259); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36058.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/537863419) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36058.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7452#issuecomment-921082427:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7452#issuecomment-921082427,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [36081](https://app.travis-ci.com/broadinstitute/gatk/builds/237929248); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36081.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/538089676) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36081.12/tests/test/index.html) |; | integration | openjdk8 | [36081.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/538089666) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36081.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-921944948:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-921944948,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36105](https://app.travis-ci.com/broadinstitute/gatk/builds/238044050); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36105.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/538399326) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36105.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7475#issuecomment-922931171:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7475#issuecomment-922931171,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [36112](https://app.travis-ci.com/broadinstitute/gatk/builds/238062338); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36112.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/538446562) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36112.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7452#issuecomment-923093725:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7452#issuecomment-923093725,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [36116](https://app.travis-ci.com/broadinstitute/gatk/builds/238079815); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36116.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/538495506) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36116.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7477#issuecomment-923269951:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7477#issuecomment-923269951,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [36174](https://app.travis-ci.com/broadinstitute/gatk/builds/238460134); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36174.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/539549145) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36174.12/tests/test/index.html) |; | integration | openjdk8 | [36174.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/539549135) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36174.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-926929814:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-926929814,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36176](https://app.travis-ci.com/broadinstitute/gatk/builds/238460981); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36176.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/539551561) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36176.12/tests/test/index.html) |; | integration | openjdk8 | [36176.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/539551551) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36176.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-926933533:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-926933533,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36275](https://app.travis-ci.com/broadinstitute/gatk/builds/239090322); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36275.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/541228649) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36275.12/tests/test/index.html) |; | integration | openjdk8 | [36275.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/541228639) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36275.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7491#issuecomment-933868301:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7491#issuecomment-933868301,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36352](https://app.travis-ci.com/broadinstitute/gatk/builds/239379640); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36352.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/542050919) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36352.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7495#issuecomment-938192993:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7495#issuecomment-938192993,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [36425](https://app.travis-ci.com/broadinstitute/gatk/builds/239885552); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36425.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/543355253) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36425.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7450#issuecomment-944020627:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7450#issuecomment-944020627,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [36457](https://app.travis-ci.com/broadinstitute/gatk/builds/240144608); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36457.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/544058431) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/rsa_parallelize_execute_sql_36457.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7509#issuecomment-946831152:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7509#issuecomment-946831152,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [36459](https://app.travis-ci.com/broadinstitute/gatk/builds/240145151); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36459.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/544060034) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36459.12/tests/test/index.html) |; | integration | openjdk8 | [36459.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/544060024) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36459.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946834797:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946834797,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36461](https://app.travis-ci.com/broadinstitute/gatk/builds/240145685); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36461.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/544061450) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36461.12/tests/test/index.html) |; | integration | openjdk8 | [36461.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/544061440) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36461.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946842201:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946842201,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36463](https://app.travis-ci.com/broadinstitute/gatk/builds/240151564); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36463.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/544076662) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36463.12/tests/test/index.html) |; | integration | openjdk8 | [36463.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/544076652) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36463.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946896833:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946896833,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36659](https://app.travis-ci.com/broadinstitute/gatk/builds/240872073); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [36659.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/545893308) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36659.1/tests/test/index.html) |; | cloud | openjdk11 | [36659.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/545893321) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36659.14/tests/test/index.html) |; | integration | openjdk11 | [36659.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/545893319) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36659.12/tests/test/index.html) |; | integration | openjdk8 | [36659.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/545893309) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36659.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-955060271:655,integrat,integration,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-955060271,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36699](https://app.travis-ci.com/broadinstitute/gatk/builds/241035376); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [36699.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/546298343) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36699.1/tests/test/index.html) |; | cloud | openjdk11 | [36699.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/546298356) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36699.14/tests/test/index.html) |; | integration | openjdk11 | [36699.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546298354) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36699.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-957815959:655,integrat,integration,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-957815959,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [36704](https://app.travis-ci.com/broadinstitute/gatk/builds/241045493); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [36704.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/546319630) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36704.1/tests/test/index.html) |; | cloud | openjdk11 | [36704.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/546319643) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36704.14/tests/test/index.html) |; | integration | openjdk11 | [36704.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546319641) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36704.12/tests/test/index.html) |; | integration | openjdk8 | [36704.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546319631) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36704.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-957942604:655,integrat,integration,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-957942604,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36712](https://app.travis-ci.com/broadinstitute/gatk/builds/241134777); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [36712.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/546539784) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36712.1/tests/test/index.html) |; | cloud | openjdk11 | [36712.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/546539797) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36712.14/tests/test/index.html) |; | integration | openjdk11 | [36712.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546539795) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36712.12/tests/test/index.html) |; | integration | openjdk8 | [36712.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546539785) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36712.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-959840632:655,integrat,integration,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-959840632,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36716](https://app.travis-ci.com/broadinstitute/gatk/builds/241142844); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [36716.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/546560178) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36716.1/tests/test/index.html) |; | cloud | openjdk11 | [36716.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/546560192) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36716.14/tests/test/index.html) |; | integration | openjdk11 | [36716.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546560189) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36716.12/tests/test/index.html) |; | integration | openjdk8 | [36716.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546560179) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36716.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-960096611:655,integrat,integration,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-960096611,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36725](https://app.travis-ci.com/broadinstitute/gatk/builds/241190517); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36725.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546679928) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36725.12/tests/test/index.html) |; | integration | openjdk8 | [36725.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546679918) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36725.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961166918:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961166918,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36729](https://app.travis-ci.com/broadinstitute/gatk/builds/241192115); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36729.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546683875) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36729.12/tests/test/index.html) |; | integration | openjdk8 | [36729.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546683865) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36729.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961184778:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961184778,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36733](https://app.travis-ci.com/broadinstitute/gatk/builds/241200444); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36733.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546705723) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36733.12/tests/test/index.html) |; | integration | openjdk8 | [36733.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546705713) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36733.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961272306:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961272306,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36735](https://app.travis-ci.com/broadinstitute/gatk/builds/241201544); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36735.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546708298) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36735.12/tests/test/index.html) |; | integration | openjdk8 | [36735.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546708288) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36735.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961283261:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961283261,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36737](https://app.travis-ci.com/broadinstitute/gatk/builds/241202305); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36737.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546710279) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36737.12/tests/test/index.html) |; | integration | openjdk8 | [36737.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546710269) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36737.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961293526:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961293526,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36739](https://app.travis-ci.com/broadinstitute/gatk/builds/241202374); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36739.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546710447) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36739.12/tests/test/index.html) |; | integration | openjdk8 | [36739.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546710437) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36739.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961291100:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961291100,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36747](https://app.travis-ci.com/broadinstitute/gatk/builds/241218893); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36747.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546762423) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36747.12/tests/test/index.html) |; | integration | openjdk8 | [36747.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546762413) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36747.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961477821:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961477821,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36844](https://app.travis-ci.com/broadinstitute/gatk/builds/241531802); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36844.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/547544565) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36844.12/tests/test/index.html) |; | conda | openjdk8 | [36844.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/547544558) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36844.5/tests/test/index.html) |; | integration | openjdk8 | [36844.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/547544555) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36844.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7559#issuecomment-965446296:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7559#issuecomment-965446296,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36923](https://app.travis-ci.com/broadinstitute/gatk/builds/241945043); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36923.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/548529658) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36923.12/tests/test/index.html) |; | integration | openjdk8 | [36923.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/548529648) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36923.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971704225:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971704225,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36925](https://app.travis-ci.com/broadinstitute/gatk/builds/241945819); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36925.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/548531508) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36925.12/tests/test/index.html) |; | integration | openjdk8 | [36925.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/548531498) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36925.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971715805:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971715805,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36927](https://app.travis-ci.com/broadinstitute/gatk/builds/241946394); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36927.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/548532718) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36927.12/tests/test/index.html) |; | integration | openjdk8 | [36927.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/548532708) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36927.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971720500:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971720500,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [36937](https://app.travis-ci.com/broadinstitute/gatk/builds/242038149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36937.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/548759909) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36937.12/tests/test/index.html) |; | integration | openjdk8 | [36937.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/548759899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36937.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7571#issuecomment-973153376:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7571#issuecomment-973153376,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38060](https://app.travis-ci.com/broadinstitute/gatk/builds/247666991); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [38060.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/562747871) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38060.13/tests/test/index.html) |; | integration | openjdk11 | [38060.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/562747870) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38060.12/tests/test/index.html) |; | unit | openjdk8 | [38060.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/562747861) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38060.3/tests/test/index.html) |; | integration | openjdk8 | [38060.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/562747860) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38060.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1063589941:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1063589941,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38083](https://app.travis-ci.com/broadinstitute/gatk/builds/247786992); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38083.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563060315) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38083.12/tests/test/index.html) |; | integration | openjdk8 | [38083.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563060305) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38083.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1065595863:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1065595863,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38087](https://app.travis-ci.com/broadinstitute/gatk/builds/247802968); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38087.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563097964) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38087.12/tests/test/index.html) |; | integration | openjdk8 | [38087.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563097954) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38087.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1065926332:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1065926332,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38091](https://app.travis-ci.com/broadinstitute/gatk/builds/247852896); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [38091.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/563219289) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38091.13/tests/test/index.html) |; | integration | openjdk11 | [38091.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563219288) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38091.12/tests/test/index.html) |; | unit | openjdk8 | [38091.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/563219279) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38091.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1066920877:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1066920877,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [38096](https://app.travis-ci.com/broadinstitute/gatk/builds/247860433); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38096.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563238843) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38096.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7720#issuecomment-1067068324:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7720#issuecomment-1067068324,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [38098](https://app.travis-ci.com/broadinstitute/gatk/builds/247860511); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38098.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563239018) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38098.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7720#issuecomment-1067069713:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7720#issuecomment-1067069713,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [38100](https://app.travis-ci.com/broadinstitute/gatk/builds/247864839); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084,4,['integrat'],['integration']
Deployability,Travis reported job failures from build [38110](https://app.travis-ci.com/broadinstitute/gatk/builds/247893700); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [38110.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325496) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.14/tests/test/index.html) |; | cloud | openjdk8 | [38110.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325483) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.1/tests/test/index.html) |; | unit | openjdk11 | [38110.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325495) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.13/tests/test/index.html) |; | integration | openjdk11 | [38110.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325494) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.12/tests/test/index.html) |; | unit | openjdk8 | [38110.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325485) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.3/tests/test/index.html) |; | variantcalling | openjdk8 | [38110.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325486) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.4/tests/test/index.html) |; | integration | openjdk8 | [38110.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325484) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1067659375:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1067659375,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38112](https://app.travis-ci.com/broadinstitute/gatk/builds/247913834); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38112.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563379132) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38112.12/tests/test/index.html) |; | integration | openjdk8 | [38112.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563379122) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38112.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1068024511:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1068024511,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38115](https://app.travis-ci.com/broadinstitute/gatk/builds/247937100); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [38115.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444106) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.1/tests/test/index.html) |; | cloud | openjdk11 | [38115.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444119) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.14/tests/test/index.html) |; | unit | openjdk11 | [38115.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444118) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.13/tests/test/index.html) |; | integration | openjdk11 | [38115.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444117) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.12/tests/test/index.html) |; | unit | openjdk8 | [38115.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444108) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.3/tests/test/index.html) |; | variantcalling | openjdk8 | [38115.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444109) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.4/tests/test/index.html) |; | integration | openjdk8 | [38115.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444107) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1068358237:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1068358237,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38129](https://app.travis-ci.com/broadinstitute/gatk/builds/248000561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38129.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563600186) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38129.12/tests/test/index.html) |; | integration | openjdk8 | [38129.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563600176) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38129.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069521375:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069521375,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38164](https://app.travis-ci.com/broadinstitute/gatk/builds/248125832); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [38164.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/563917586) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38164.1/tests/test/index.html) |; | cloud | openjdk11 | [38164.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/563917599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38164.14/tests/test/index.html) |; | conda | openjdk8 | [38164.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/563917590) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38164.5/tests/test/index.html) |; | integration | openjdk8 | [38164.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563917587) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38164.2/tests/test/index.html) |; | variantcalling | openjdk8 | [38164.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/563917589) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38164.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072776529:852,integrat,integration,852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072776529,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [38166](https://app.travis-ci.com/broadinstitute/gatk/builds/248127071); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38166.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563920785) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38166.12/tests/test/index.html) |; | integration | openjdk8 | [38166.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563920775) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38166.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1072830769:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1072830769,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38168](https://app.travis-ci.com/broadinstitute/gatk/builds/248128606); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [38168.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/563924706) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38168.14/tests/test/index.html) |; | cloud | openjdk8 | [38168.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/563924693) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38168.1/tests/test/index.html) |; | integration | openjdk8 | [38168.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563924694) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38168.2/tests/test/index.html) |; | conda | openjdk8 | [38168.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/563924697) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38168.5/tests/test/index.html) |; | variantcalling | openjdk8 | [38168.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/563924696) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38168.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072841847:643,integrat,integration,643,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072841847,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [38170](https://app.travis-ci.com/broadinstitute/gatk/builds/248128971); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [38170.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/563925511) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38170.1/tests/test/index.html) |; | cloud | openjdk11 | [38170.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/563925524) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38170.14/tests/test/index.html) |; | conda | openjdk8 | [38170.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/563925515) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38170.5/tests/test/index.html) |; | integration | openjdk8 | [38170.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563925512) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38170.2/tests/test/index.html) |; | variantcalling | openjdk8 | [38170.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/563925514) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38170.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072847450:852,integrat,integration,852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072847450,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [38174](https://app.travis-ci.com/broadinstitute/gatk/builds/248186522); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38174.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564065551) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38174.12/tests/test/index.html) |; | integration | openjdk8 | [38174.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564065541) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38174.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074044045:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074044045,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38177](https://app.travis-ci.com/broadinstitute/gatk/builds/248191891); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38177.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564080035) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38177.12/tests/test/index.html) |; | integration | openjdk8 | [38177.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564080025) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38177.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074141420:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074141420,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38179](https://app.travis-ci.com/broadinstitute/gatk/builds/248192670); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38179.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564082094) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38179.12/tests/test/index.html) |; | integration | openjdk8 | [38179.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564082084) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38179.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074156376:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074156376,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38183](https://app.travis-ci.com/broadinstitute/gatk/builds/248198988); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38183.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564098711) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38183.12/tests/test/index.html) |; | integration | openjdk8 | [38183.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564098701) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38183.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074271488:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074271488,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38185](https://app.travis-ci.com/broadinstitute/gatk/builds/248205358); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38185.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564114801) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38185.12/tests/test/index.html) |; | integration | openjdk8 | [38185.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564114791) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38185.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074353651:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074353651,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38187](https://app.travis-ci.com/broadinstitute/gatk/builds/248207168); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38187.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564119758) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38187.12/tests/test/index.html) |; | integration | openjdk8 | [38187.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564119748) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38187.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074389896:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074389896,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38191](https://app.travis-ci.com/broadinstitute/gatk/builds/248213511); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38191.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564136597) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38191.12/tests/test/index.html) |; | integration | openjdk8 | [38191.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564136587) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38191.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074495163:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074495163,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38203](https://app.travis-ci.com/broadinstitute/gatk/builds/248266948); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38203.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564269407) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38203.12/tests/test/index.html) |; | integration | openjdk8 | [38203.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564269397) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38203.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7734#issuecomment-1075494924:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7734#issuecomment-1075494924,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38216](https://app.travis-ci.com/broadinstitute/gatk/builds/248313687); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [38216.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/564383062) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38216.13/tests/test/index.html) |; | integration | openjdk11 | [38216.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564383061) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38216.12/tests/test/index.html) |; | unit | openjdk8 | [38216.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/564383052) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38216.3/tests/test/index.html) |; | integration | openjdk8 | [38216.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564383051) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38216.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1076366765:439,integrat,integration,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1076366765,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38225](https://app.travis-ci.com/broadinstitute/gatk/builds/248338488); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38225.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564447801) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38225.12/tests/test/index.html) |; | integration | openjdk8 | [38225.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564447791) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38225.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7734#issuecomment-1076776102:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7734#issuecomment-1076776102,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38233](https://app.travis-ci.com/broadinstitute/gatk/builds/248387440); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38233.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564566861) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38233.12/tests/test/index.html) |; | integration | openjdk8 | [38233.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564566851) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38233.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7733#issuecomment-1077790207:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7733#issuecomment-1077790207,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38284](https://app.travis-ci.com/broadinstitute/gatk/builds/248554579); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [38284.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/564972333) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38284.13/tests/test/index.html) |; | integration | openjdk11 | [38284.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564972332) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38284.12/tests/test/index.html) |; | cloud | openjdk8 | [38284.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/564972321) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38284.1/tests/test/index.html) |; | cloud | openjdk11 | [38284.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/564972334) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38284.14/tests/test/index.html) |; | unit | openjdk8 | [38284.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/564972323) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38284.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1081073154:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1081073154,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [38286](https://app.travis-ci.com/broadinstitute/gatk/builds/248555577); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38286.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564975067) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38286.12/tests/test/index.html) |; | integration | openjdk8 | [38286.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564975057) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38286.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7739#issuecomment-1081135051:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7739#issuecomment-1081135051,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38293](https://app.travis-ci.com/broadinstitute/gatk/builds/248569068); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38293.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/565009924) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38293.12/tests/test/index.html) |; | integration | openjdk8 | [38293.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/565009914) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38293.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7664#issuecomment-1081368863:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7664#issuecomment-1081368863,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38297](https://app.travis-ci.com/broadinstitute/gatk/builds/248597167); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [38297.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/565077614) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38297.13/tests/test/index.html) |; | integration | openjdk11 | [38297.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/565077613) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38297.12/tests/test/index.html) |; | cloud | openjdk8 | [38297.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/565077602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38297.1/tests/test/index.html) |; | cloud | openjdk11 | [38297.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/565077615) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38297.14/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1081845776:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1081845776,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [38312](https://app.travis-ci.com/broadinstitute/gatk/builds/248621240); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38312.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/565138626) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38312.12/tests/test/index.html) |; | integration | openjdk8 | [38312.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/565138616) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38312.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1082317832:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1082317832,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38347](https://app.travis-ci.com/broadinstitute/gatk/builds/248689004); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38347.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/565306999) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38347.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7746#issuecomment-1083594910:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7746#issuecomment-1083594910,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [38393](https://app.travis-ci.com/broadinstitute/gatk/builds/248813440); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [38393.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/565618194) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38393.1/tests/test/index.html) |; | cloud | openjdk11 | [38393.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/565618207) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38393.14/tests/test/index.html) |; | conda | openjdk8 | [38393.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/565618198) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38393.5/tests/test/index.html) |; | integration | openjdk8 | [38393.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/565618195) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38393.2/tests/test/index.html) |; | variantcalling | openjdk8 | [38393.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/565618197) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38393.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1086251277:852,integrat,integration,852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1086251277,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [38445](https://app.travis-ci.com/broadinstitute/gatk/builds/248902356); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38445.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/565826830) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38445.12/tests/test/index.html) |; | integration | openjdk8 | [38445.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/565826820) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7750#issuecomment-1087979534:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7750#issuecomment-1087979534,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38522](https://app.travis-ci.com/broadinstitute/gatk/builds/249024354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38522.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566140964) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38522.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7739#issuecomment-1090476624:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7739#issuecomment-1090476624,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [38567](https://app.travis-ci.com/broadinstitute/gatk/builds/249037237); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [38567.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/566174075) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38567.2/tests/test/index.html) |; | conda | openjdk8 | [38567.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/566174078) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38567.5/tests/test/index.html) |; | variantcalling | openjdk8 | [38567.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/566174077) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38567.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1090792544:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1090792544,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [38623](https://app.travis-ci.com/broadinstitute/gatk/builds/249089579); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38623.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566299427) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38623.12/tests/test/index.html) |; | integration | openjdk8 | [38623.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/566299417) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38623.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7752#issuecomment-1091967282:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7752#issuecomment-1091967282,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38735](https://app.travis-ci.com/broadinstitute/gatk/builds/249251446); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38735.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566697912) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38735.12/tests/test/index.html) |; | integration | openjdk11 | [38735.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566697912) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38735.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7713#issuecomment-1095535534:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7713#issuecomment-1095535534,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38745](https://app.travis-ci.com/broadinstitute/gatk/builds/249258011); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38745.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566714710) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38745.12/tests/test/index.html) |; | integration | openjdk8 | [38745.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/566714700) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38745.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7773#issuecomment-1095668751:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7773#issuecomment-1095668751,2,['integrat'],['integration']
Deployability,Travis reported job failures from build [38757](https://app.travis-ci.com/broadinstitute/gatk/builds/249261923); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38757.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566724825) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38757.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7772#issuecomment-1095767061:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7772#issuecomment-1095767061,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [38788](https://app.travis-ci.com/broadinstitute/gatk/builds/249322535); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38788.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566886037) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38788.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7776#issuecomment-1097243112:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7776#issuecomment-1097243112,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [38872](https://app.travis-ci.com/broadinstitute/gatk/builds/249441958); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38872.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/567177790) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38872.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7784#issuecomment-1099583851:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7784#issuecomment-1099583851,1,['integrat'],['integration']
Deployability,Travis reported job failures from build [38983](https://app.travis-ci.com/broadinstitute/gatk/builds/249657082); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38983.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/567712058) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38983.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7801#issuecomment-1104482113:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7801#issuecomment-1104482113,1,['integrat'],['integration']
Deployability,"Travis rolled out updated images that caused our builds to start failing. It looks like some of the WDL tests had been failing for a [while](https://github.com/broadinstitute/gatk/issues/3558), but that wasn't causing the **builds** to fail until the new Travis images were rolled out, at which point we started running out of space logging the errors. We're temporarily requesting to use the old Travis image (https://github.com/broadinstitute/gatk/pull/3557), but we should revert that once we address the underlying issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3559:18,update,updated,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3559,1,['update'],['updated']
Deployability,Travis-CI now has git-lfs baked into the images so we can delete our installation script and just use their instance. ; deleted download_lfs_files.sh,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3226:69,install,installation,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3226,1,['install'],['installation']
Deployability,Trivial formatting update for skip interval file parser,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2379:19,update,update,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2379,1,['update'],['update']
Deployability,"True that this is in the GATK repository, but someone should be able to run these instructions without having to build the GATK from source (and rather, just install it from the zip distribution, etc)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7268#issuecomment-846275065:158,install,install,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7268#issuecomment-846275065,1,['install'],['install']
Deployability,Try using SAMRecord instead of model read in Spark pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/875:51,pipeline,pipeline,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/875,1,['pipeline'],['pipeline']
Deployability,Trying to write bam to dev null using PrintReadsSpark results in:. ```; org.broadinstitute.hellbender.exceptions.GATKException: unable to write bam: org.apache.hadoop.fs.ParentNotDirectoryException: Parent path is not a directory: file:/dev/null; at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:50); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:257); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66); at org.broadinstitute.hellbender.Main.main(Main.java:81); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1436:292,pipeline,pipelines,292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1436,1,['pipeline'],['pipelines']
Deployability,Turn on and update tests skipped in #8741,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8893:12,update,update,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8893,1,['update'],['update']
Deployability,"Turns out I've been self-consistently using SVIntervals as BED intervals, which is the wrong interpretation according to its methods `toBEDInterval(...)` and `toSimpleInterval(...)`. Note to self to update the interpretation in package `sv.discovery`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5154:199,update,update,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5154,1,['update'],['update']
Deployability,"Turns out that the failure rate with this patch was greatly reduced, but there were still a few failures. We're trying a run now where we tell the tool to import one file at a time (as opposed to a batch of 25 or 100), and we'll see how that goes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307506558:42,patch,patch,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307506558,1,['patch'],['patch']
Deployability,"Turns out this change as it currently stands is incompatible with the `--include-non-variant-sites` mode in `GenotypeGVCFs`, but I believe this can be fixed. The allele remapping logic needs to be updated to handle reference bases within reference blocks correctly. I'll attempt a fix next week. Worst case, we can implement a separate toggle for the GVS tools to use rather than trying to unify into a single codepath, but we'll explore other options first.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8288#issuecomment-1509295869:197,update,updated,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8288#issuecomment-1509295869,2,"['toggle', 'update']","['toggle', 'updated']"
Deployability,Turns out we disabled codecov 3 years ago for a reason. We can leave it on for informational purposes with this patch.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7815:112,patch,patch,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7815,1,['patch'],['patch']
Deployability,"Two .vcf.idx files used by the haplotype caller integration test had; file name lengths > 144. This is incompatible with ecryptfs, which is; commonly used for encrypted home directories on linux. Renaming the; .vcf and .vcf.idx files and updating references to them fixed the; problem. Fixes #4718.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4736:48,integrat,integration,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4736,1,['integrat'],['integration']
Deployability,"Two annotations, allele depth and total depth, consider whether reads are informative relative to the alleles in the output `VariantContext`, which is in general a subset of the alleles contains in the `ReadLikelihoods`. In PR #2185 I overlooked this and forgot to subset the likelihoods' alleles to those of the vc, which was the previous behavior (see the diff from that PR for the two annotations in this PR). This PR duplicates the old behavior. This fixes failures in the HaplotypeCaller integration tests introduced by the previous PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2239:493,integrat,integration,493,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2239,1,['integrat'],['integration']
Deployability,"UPDATE: @lbergelson and I started creating this as an extension to SplitIntervals, but it quickly because very complex to fit it into that framework/abstraction so we decided to create a specialized tool for GVS. It would be valuable for SplitIntervals to be able to split intervals based not on number of genomic bases, but by using a set of weights. Ideally this new mode would read in a BED file containing the weights in the score field and attempt to produce a series of intervals that have equal total weights. . Note: ` --dont-mix-contigs` should still continue to work. ** Why? **; In the Genomic Variant Store, we have found that scattering work by ""# of genomic bases"" does not lead to even runtimes for the shards. ![image](https://user-images.githubusercontent.com/1423491/147964102-d2c83dea-8486-4699-9e7a-eef3dc759732.png). Instead we have found that an excellent proxy for runtime is the number of variants contained in a given interval:. ![image](https://user-images.githubusercontent.com/1423491/147964259-333f4058-a701-4b31-b410-242518d1b3b2.png). And furthermore, that this generalizes even when we use a subset of a different dataset. ![image](https://user-images.githubusercontent.com/1423491/147964392-17d045e9-e2f2-467b-8eae-77bd63291902.png)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7622:0,UPDATE,UPDATE,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7622,1,['UPDATE'],['UPDATE']
Deployability,"UPDATE: I solved the issue on my end. A collaborator was having the same issue with their haploid data, but not their diploid. The problems I described above were for haploid data. He added ""--new-qual"" to his GenotypeGVCFs command and that solved the issue. It did for me as well! Using the same combined GVCF file as I was before, genotyping finished in less than half a minute after adding the new-qual parameter. Thought it would be useful to know that:. 1, this issue appears to affect non-diploids more than diploids. 2, using --new-qual solved the issue, at least for me. I've attached the log-file generated from this new output, hopefully it helps in debugging.; [genotype108_newqual.e5290702.txt](https://github.com/broadinstitute/gatk/files/1853188/genotype108_newqual.e5290702.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376620043:0,UPDATE,UPDATE,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376620043,1,['UPDATE'],['UPDATE']
Deployability,"UPDATE: the issue might still be relevant, though the tool at hand is long gone. It seems like the relevant code at the time of this update is in `AlignedAssemblyOrExcuse FermiLiteAssemblyHandler.apply(...)`, which shells out the alignment job at the bottom of that method to `BwaMemAligner` which is an JNI layer to bwa mem. Hence the fix, assuming it is still needed, is preferably to be issued in the JNI bindings repo.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2123#issuecomment-406403299:0,UPDATE,UPDATE,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2123#issuecomment-406403299,2,"['UPDATE', 'update']","['UPDATE', 'update']"
Deployability,"Ugh, there's some wierd bug with one of our dependencies not understanding java version id's with 4 parts. The install java action must have just moved from installing 11.0.16 too 11.0.16.1 behind our back. It sounds like we have to update Jetty or something manually. ```; java.lang.ExceptionInInitializerError; at org.eclipse.jetty.webapp.WebInfConfiguration.findAndFilterContainerPaths(WebInfConfiguration.java:185); at org.eclipse.jetty.webapp.WebInfConfiguration.preConfigure(WebInfConfiguration.java:155); at org.eclipse.jetty.webapp.WebAppContext.preConfigure(WebAppContext.java:485); at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:521); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:131); at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:113); at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:61); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:131); at org.eclipse.jetty.server.Server.start(Server.java:[42](https://github.com/broadinstitute/gatk/actions/runs/3499912997/jobs/5862011952#step:10:43)7); at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:105); at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:61); at org.eclipse.jetty.server.Server.doStart(Server.java:394); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1155); at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:181); at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:885); at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(Nam",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8098#issuecomment-1320505279:111,install,install,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8098#issuecomment-1320505279,3,"['install', 'update']","['install', 'installing', 'update']"
Deployability,"Ultima, New/Updated Features",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8579:12,Update,Updated,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8579,1,['Update'],['Updated']
Deployability,"Uncompressed size of the Docker goes up from 4.12GB to 4.76GB. The correct Tensorflow + MKL + R packages contribute most of the extra bulk. However, using `conda clean -afy` (as opposed to `conda clean -ay`, which we were doing before) and additionally deleting *.a and *.pyc files after the conda install saves ~700MB in the end (without these, the image goes up to 5.43GB).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-607967425:298,install,install,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-607967425,1,['install'],['install']
Deployability,Unfortunately we are still getting the error about gcloud.py not found so it seems that the piped installer responses were not the problem:. ```; python3: can't open file '/home/travis/gcloud/google-cloud-sdk/lib/gcloud.py': [Errno 2] No such file or directory; ```. This file is definitely present in a fresh gcloud installation I just created for testing purposes...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6974#issuecomment-730660441:98,install,installer,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6974#issuecomment-730660441,2,['install'],"['installation', 'installer']"
Deployability,Unfortunately we can't merge this until we get the corresponding Barclay changes released in Barclay and integrated into GATK.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4523#issuecomment-454157311:81,release,released,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4523#issuecomment-454157311,2,"['integrat', 'release']","['integrated', 'released']"
Deployability,"Unit and integration tests are now all passing on openjdk11. The build does not however work on Java 8, since the javadoc compilation has been commented out. This will need to be made conditional on the Java version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-529514256:9,integrat,integration,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-529514256,1,['integrat'],['integration']
Deployability,"Unlike the other validation rules, this does not test the validity of the VAT, but whether the pipeline completed as we expected it to--so I have added this as the singular test that runs during the pipeline. Validation Rule 2: The number of passing variants in GVS matches the number of variants in the VAT. Please note that we are counting the number of variants in GVS, not the number of sites, which may add a difficulty to this task. Another way to phrase it: ""If I were to make a sites only VCF of GVS and split each passing variant into it's own line, that number should equal the number of unique VIDs in the VAT."". Measure number of unique variants in sites only VCF that is generated. We don't want to count filtered variants so we can't count the GVS table. NOTE:. this pr also has some general cleanup as per discussion with Andrea. ; where would y'all suggest I put the template file for the custom annotations?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7374:95,pipeline,pipeline,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7374,2,['pipeline'],['pipeline']
Deployability,"UnpairedMapping SKIPPED; ```. This test fails because some JAR wasn't built:; ```; Running Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest); Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: No local jar was found, please build one by running. Gradle suite > Gradle test > org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest > testPipeForPicardTools STANDARD_ERROR; No local jar was found, please build one by running; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err:. Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: /disk-samsung/ports/biology/gatk/work/gatk-4.6.0.0/gradlew localJar. /disk-samsung/ports/biology/gatk/work/gatk-4.6.0.0/gradlew localJar; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: or. or; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: export GATK_LOCAL_JAR=<path_to_local_jar>. export GATK_LOCAL_JAR=<path_to_local_jar>; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: No local jar was found, please build one by running. No local jar was found, please build one by running; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err:. Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: /disk-samsung/ports/biology/gatk/work/gatk-4.6.0.0/gradlew localJar. ```. etc... etc... Version: 4.6.0.0; FreeBSD 14.1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8940:4233,Pipeline,PipelineSupportIntegrationTest,4233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8940,5,['Pipeline'],['PipelineSupportIntegrationTest']
Deployability,Update -autosomal-coverage description,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7165:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7165,1,['Update'],['Update']
Deployability,"Update . We tried Snapshop Reblock + GATK 4.2.6.1 JointGenotype pipeline, and It broke again.; Same error as above at ""GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.2.6.1"" step.... =/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7797#issuecomment-1110202709:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7797#issuecomment-1110202709,2,"['Update', 'pipeline']","['Update', 'pipeline']"
Deployability,Update .dockstore.yml,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7553:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7553,2,['Update'],['Update']
Deployability,Update AS_RMSMappingQuality.java comments,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7607:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7607,1,['Update'],['Update']
Deployability,Update AUTHORS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/494:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/494,2,['Update'],['Update']
Deployability,Update AUTHORS with new contributors.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5033:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5033,1,['Update'],['Update']
Deployability,Update AoU Documentation for GvsImportGenomes to reflect new behavior,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8571:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8571,1,['Update'],['Update']
Deployability,Update AsynchronousStreamWriterService unit test timeouts.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4028:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4028,1,['Update'],['Update']
Deployability,Update Beta User WDL to use bulk ingest [VS-982],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8379:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8379,1,['Update'],['Update']
Deployability,Update Beta workspace [VS-969],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8496:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8496,1,['Update'],['Update']
Deployability,Update Broken Links in Tool Docs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7270:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7270,1,['Update'],['Update']
Deployability,Update CNV WDLs to WDL 1.0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6502:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6502,1,['Update'],['Update']
Deployability,Update CNV WDLs to use PreprocessIntervals and CollectReadCounts.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3661:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3661,1,['Update'],['Update']
Deployability,Update CNV tool docs to clarify log2 status of inputs and outputs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3156:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3156,1,['Update'],['Update']
Deployability,Update CNV tools and documentation to use IntervalMergingRule.NONE.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5891:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5891,1,['Update'],['Update']
Deployability,Update CRAM detector output files.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8971:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8971,1,['Update'],['Update']
Deployability,Update CommonSuffixSplitter.java,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4213:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4213,1,['Update'],['Update']
Deployability,Update Docker to newer version of miniconda.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5866:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5866,1,['Update'],['Update']
Deployability,Update Docs Around Callset Cleanup and Cost [VS-1107],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8976:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8976,1,['Update'],['Update']
Deployability,Update EchoCallset gatk docker to most recent build.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8803:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8803,1,['Update'],['Update']
Deployability,Update GATK dependencies to patch security vulnerabilities,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8352:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8352,2,"['Update', 'patch']","['Update', 'patch']"
Deployability,Update GATK docker base image to Ubuntu 22.04,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8243:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8243,1,['Update'],['Update']
Deployability,Update GATK jar used in GvsJointVariantCalling WDL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8216:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8216,1,['Update'],['Update']
Deployability,Update GCS connector from 1.6.1 to 1.6.3.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4590:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4590,1,['Update'],['Update']
Deployability,"Update GKL to 0.4.1 and HTSJDK to 2.9.1. GKL 0.4.1 provides the following improvements over GKL 0.1.2 (currently used by GATK4):; - Improved performance and compression ratio for level-1 compression; - Improved performance for compression levels > 1; - Decompression acceleration with `IntelInflater`. The `IntelInflater` is enabled by default and can be disabled with the option `--use_jdk_inflater`. Resolves #2421, #2315, #2302",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423,1,['Update'],['Update']
Deployability,Update GKL to 0.8.2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3865:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3865,1,['Update'],['Update']
Deployability,Update GVS Docs to cover additional use cases and troubleshooting suggestions,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8917:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8917,1,['Update'],['Update']
Deployability,Update GVS docs with VETS information,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8466:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8466,1,['Update'],['Update']
Deployability,Update GVS sample QC to support multiple callsets per datasset [VS-177],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7451:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7451,1,['Update'],['Update']
Deployability,Update Gradle to 7.5.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8098:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8098,1,['Update'],['Update']
Deployability,Update GvsCalculatePrecisionAndSensitivity.wdl to allow for different scale of calibration_sensitivity vs. lod score.; Also retrieving score from JointVcfFiltering and storing that in BQ and in the VCF. (Probably don't need this long term.),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8230:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8230,1,['Update'],['Update']
Deployability,Update GvsCreateFilterSet.wdl to disable excess alleles by default,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7239:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7239,1,['Update'],['Update']
Deployability,"Update GvsCreateVAT.wdl to build the subpopulation-specific files from the input ancestry file.; Have GvsCreateVAT.wdl only pull fields from the VCF for the selected subpopulations.; Update create_variant_annotation_table.py to set empty population-specific AC/AN/AF, etc. values if population is not present.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7965:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7965,2,['Update'],['Update']
Deployability,Update GvsExtractCallset.example.inputs.json,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7469:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7469,1,['Update'],['Update']
Deployability,Update GvsExtractCallset.wdl to use public weights bed,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7678:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7678,1,['Update'],['Update']
Deployability,"Update GvsPrepareCallset step so that, instead of creating and inserting all the data into the `_pet_new` table in one step (which errors out with large callsets), add the data in smaller sections that correspond to each `pet_` in the GVS. Closes https://broadworkbench.atlassian.net/browse/VS-48",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7395:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7395,1,['Update'],['Update']
Deployability,Update HTSJDK to 4.1.1 and Picard to 3.2.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8900:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8900,1,['Update'],['Update']
Deployability,Update HTSJDK to 4.1.1 and Picard to 3.2.0. Included a unit test to check for the presence of the fix in HTSJDK 4.1.1 for the CRAM base corruption bug reported in https://github.com/broadinstitute/gatk/issues/8768; ; Resolves #8768,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8900:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8900,1,['Update'],['Update']
Deployability,Update Intel GKL to 0.8.10,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8181:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8181,1,['Update'],['Update']
Deployability,Update JEXL recommendations in public documentation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5509:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5509,1,['Update'],['Update']
Deployability,Update JexlExpression.java link,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7317:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7317,1,['Update'],['Update']
Deployability,Update LeftAlignIndels documentation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6177:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6177,1,['Update'],['Update']
Deployability,Update M2ArgumentCollection.java,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6840:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6840,1,['Update'],['Update']
Deployability,Update Main.java to reflect Picard command line parser selection changes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6229:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6229,1,['Update'],['Update']
Deployability,Update MarkDuplicatesGATK/MarkDuplicatesSpark to incorporate recent Picard development,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3705:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3705,1,['Update'],['Update']
Deployability,Update MarkDuplicatesSpark OpticalDuplicate code to match Picards,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4700:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4700,1,['Update'],['Update']
Deployability,Update MitochondriaPipeline.wdl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8395:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8395,1,['Update'],['Update']
Deployability,Update ModelSegments documentation to describe param table values,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4640:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4640,1,['Update'],['Update']
Deployability,Update MuTect2 documentation about not computing obvious germline variants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2499:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2499,1,['Update'],['Update']
Deployability,Update Mutect2 javadoc to reflect v4.1 changes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5769:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5769,1,['Update'],['Update']
Deployability,Update Mutect2 pon WDL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5859:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5859,1,['Update'],['Update']
Deployability,Update Mutect2's filtering,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6903:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6903,1,['Update'],['Update']
Deployability,Update Mutect2.java Documentation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8999:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8999,1,['Update'],['Update']
Deployability,Update Owner to latest version / new Maven release,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4490:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4490,2,"['Update', 'release']","['Update', 'release']"
Deployability,Update P + S WDL to get around input limits [VS-970],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8449:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8449,1,['Update'],['Update']
Deployability,Update POPAF retrieval,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6999:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6999,1,['Update'],['Update']
Deployability,Update PathSeq read filters and DUST transformer,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2665:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2665,1,['Update'],['Update']
Deployability,Update PathSeqFilterSpark and PathSeqBuildKmers tools,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3115:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3115,1,['Update'],['Update']
Deployability,Update Picard to 2.25.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7075:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7075,1,['Update'],['Update']
Deployability,Update Picard to 2.27.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7766:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7766,1,['Update'],['Update']
Deployability,Update Protocol Buffer dependency to 3.0.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2437:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2437,1,['Update'],['Update']
Deployability,Update Quickstart & Integration to use re-blocked v2 gVCFs [VS-491],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7924:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7924,2,"['Integrat', 'Update']","['Integration', 'Update']"
Deployability,Update Quickstart Integration for X/Y scaling changes [VS-464],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7881:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7881,2,"['Integrat', 'Update']","['Integration', 'Update']"
Deployability,Update README before changing repo name to GATK,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/950:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/950,1,['Update'],['Update']
Deployability,Update README to include list of popular software included in docker image,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8745:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8745,1,['Update'],['Update']
Deployability,Update README to mention that we use zenhub (or migrate from zenhub to github's new equivalent),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2487:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2487,1,['Update'],['Update']
Deployability,Update README with new gatk-dev-public list address,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1093:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1093,1,['Update'],['Update']
Deployability,Update README.md,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/239:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/239,4,['Update'],['Update']
Deployability,Update README.md - adding profiling documentation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1612:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1612,1,['Update'],['Update']
Deployability,Update README.md - clarified that you can run dataproc from laptop,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1789:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1789,1,['Update'],['Update']
Deployability,Update README.md - recommend gradlew and use in all examples,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1511:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1511,1,['Update'],['Update']
Deployability,Update README.md on testing,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/837:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/837,1,['Update'],['Update']
Deployability,Update README.md to add info about dynamic allocation on YARN,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1737:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1737,1,['Update'],['Update']
Deployability,Update README.md to remove outdated references to the Intel conda environment.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5753:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5753,1,['Update'],['Update']
Deployability,Update ReadFilters documentation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3128:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3128,1,['Update'],['Update']
Deployability,"Update Readme, added info on how to contribute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1061:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1061,1,['Update'],['Update']
Deployability,Update Readme.md to reflect switch from Travis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7808:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7808,1,['Update'],['Update']
Deployability,Update RecalDatum.java,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1851:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1851,1,['Update'],['Update']
Deployability,Update STS Delivery Doc [VS-770],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8150:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8150,1,['Update'],['Update']
Deployability,Update SV clustering classes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7243:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7243,1,['Update'],['Update']
Deployability,Update SV split-read strand validation and clustering,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8378:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8378,1,['Update'],['Update']
Deployability,Update Script to Handle Both Files and FOFN [VS-1441],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8954:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8954,1,['Update'],['Update']
Deployability,Update Spark scripts to reflect changes from #5386 and #5127.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5415:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5415,1,['Update'],['Update']
Deployability,"Update StandardSomaticAnnotation to reflect M2's default annotations, currently under M2ArgumentCollection as annotation",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3123:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3123,1,['Update'],['Update']
Deployability,Update Storage API to handle no data query return,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7082:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7082,1,['Update'],['Update']
Deployability,Update StrandBiasBySample documentation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7283:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7283,1,['Update'],['Update']
Deployability,Update To handle if no data error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7084:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7084,1,['Update'],['Update']
Deployability,Update ValidateSamFileIntegrationTest once htsjdk #369 CRAM bug fix is available,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1138:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1138,1,['Update'],['Update']
Deployability,Update VariantRecalibrator RScript Compatibility with Newer ggplot2 Versions,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8992:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8992,1,['Update'],['Update']
Deployability,Update WDL tests to Cromwell 30.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3960:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3960,1,['Update'],['Update']
Deployability,Update `AlignContigsAndCallBreakpointsSpark` with jBWA's para changing capacity,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2001:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2001,1,['Update'],['Update']
Deployability,Update `isInformative` to use the natural log,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6884:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6884,1,['Update'],['Update']
Deployability,"Update all to createVCFWriter(Path) (not File). As a result, all VCF tools should now be able to write to Cloud (including Funcolator). This commit also removes createVCFWriter(File), ensuring all new; code retains the ability to write to Cloud. This touches many files, but the changes are mostly the same everywhere. Only `FilterByOrientationBias.java` is a bit different since it also needed code to add a suffix to a file name. . Fixes #5726",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5728:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5728,1,['Update'],['Update']
Deployability,Update allele subsetting to support genotype posteriors,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7390:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7390,1,['Update'],['Update']
Deployability,Update annotation args to GATK4 names,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7413:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7413,1,['Update'],['Update']
Deployability,Update artifactory URL.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3200:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3200,1,['Update'],['Update']
Deployability,Update base image,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8228:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8228,1,['Update'],['Update']
Deployability,Update beta docs to tell people not to use free credits,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8184:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8184,1,['Update'],['Update']
Deployability,Update beta/gvs-quickstart.md,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8364:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8364,1,['Update'],['Update']
Deployability,Update build.gradle to make sure that tests are always rerunable.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1719:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1719,1,['Update'],['Update']
Deployability,Update bwamem-jni dependency to 1.0.3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3723:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3723,1,['Update'],['Update']
Deployability,Update changelog for Beta release,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8743:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8743,2,"['Update', 'release']","['Update', 'release']"
Deployability,Update cleanup doc [VS-787],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8981:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8981,1,['Update'],['Update']
Deployability,Update command-line examples in docs to use gatk-launch,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3039:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3039,1,['Update'],['Update']
Deployability,Update compareBamFiles test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/227:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/227,1,['Update'],['Update']
Deployability,Update copyright date in LICENSE.TXT,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6383:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6383,1,['Update'],['Update']
Deployability,Update copyright date in license,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4018:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4018,1,['Update'],['Update']
Deployability,Update cromwell and womtool from v51 to v59.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7824:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7824,1,['Update'],['Update']
Deployability,Update cromwell and womtool. See if I feel lucky.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7824:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7824,1,['Update'],['Update']
Deployability,Update data.table R dependency.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3712:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3712,1,['Update'],['Update']
Deployability,"Update dependencies to address security vulnerabilities, and add a security scanner to build.gradle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8607:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8607,1,['Update'],['Update']
Deployability,Update disq to 0.3.2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6040:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6040,1,['Update'],['Update']
Deployability,Update disq to 0.3.4,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6252:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6252,1,['Update'],['Update']
Deployability,Update disq to 0.3.5,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6323:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6323,1,['Update'],['Update']
Deployability,Update do spark 2.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2911:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2911,1,['Update'],['Update']
Deployability,"Update doc templates to reflect ""Experimental"" tag.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4033:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4033,1,['Update'],['Update']
Deployability,Update docker base,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9005:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9005,1,['Update'],['Update']
Deployability,Update docs for Funcotator. Tool documentation and GencodeFuncotationFactory / GencodeFuncotation documents (to create a proper spec. for the gencode annotations).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5611:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5611,1,['Update'],['Update']
Deployability,Update docs for Nirvana reference disk [VS-796] [VS-531],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8170:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8170,1,['Update'],['Update']
Deployability,Update docs for callset stats [VS-1094],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8591:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8591,1,['Update'],['Update']
Deployability,Update documentation for VDS/VAT [VS-1125],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8688:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8688,1,['Update'],['Update']
Deployability,Update documentation for various tools (MW),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4026:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4026,1,['Update'],['Update']
Deployability,Update documentation to point to newly released BGE exome calling list.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8407:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8407,2,"['Update', 'release']","['Update', 'released']"
Deployability,Update error message based on https://github.com/broadinstitute/gatk/issues/4669.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4678:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4678,1,['Update'],['Update']
Deployability,Update example code to correspond to Barclay arg tagging change,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5710:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5710,1,['Update'],['Update']
Deployability,Update firehose to reflect standardization of target table format,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2867:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2867,1,['Update'],['Update']
Deployability,Update for funcotator data sources,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660,1,['Update'],['Update']
Deployability,Update forum posts for the name change in CNLoH caller,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2904:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2904,1,['Update'],['Update']
Deployability,Update forum posts to reflect standardization of target table format,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2866:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2866,1,['Update'],['Update']
Deployability,Update funcotator bundled data sources,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8296:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8296,1,['Update'],['Update']
Deployability,Update gCNV mappability track.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6591:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6591,1,['Update'],['Update']
Deployability,Update gcloud docker commands in build_docker.sh,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7078:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7078,1,['Update'],['Update']
Deployability,Update gcloud-java-nio to version 0.2.8. Addresses #2110.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2132:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2132,1,['Update'],['Update']
Deployability,Update git-lfs prerequisite message.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4678:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4678,1,['Update'],['Update']
Deployability,Update google-cloud-java dependency to a snapshot containing newly added NIO API methods,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2441:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2441,1,['Update'],['Update']
Deployability,Update google-cloud-nio dependency to 0.20.4-alpha-20170727.190814-1:shaded,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3373:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3373,1,['Update'],['Update']
Deployability,Update google-cloud-nio to support underscores in bucket names,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8439:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8439,1,['Update'],['Update']
Deployability,Update gradle and build.gradle,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8998:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8998,1,['Update'],['Update']
Deployability,Update gvs workspace description [VS-1042],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8509:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8509,1,['Update'],['Update']
Deployability,Update hail version to 120 in Integration test VS 1025,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8502:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8502,2,"['Integrat', 'Update']","['Integration', 'Update']"
Deployability,Update hail_create_vat_inputs.py,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8772:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8772,1,['Update'],['Update']
Deployability,Update haplochecker dockerfile and task to match,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5760:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5760,1,['Update'],['Update']
Deployability,"Update hdf5-java-bindings to version 1.2.0-hdf5_2.11.0, which removes log4j 1.x",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8908:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8908,1,['Update'],['Update']
Deployability,Update hmmUrl in install_R_packages.R,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8638:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8638,1,['Update'],['Update']
Deployability,Update htsjdk to 1.137,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/758:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/758,1,['Update'],['Update']
Deployability,Update htsjdk to 1.141.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1122:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1122,1,['Update'],['Update']
Deployability,Update htsjdk to 2.18.2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5585:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5585,1,['Update'],['Update']
Deployability,Update htsjdk to 2.20.2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6094:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6094,1,['Update'],['Update']
Deployability,Update htsjdk to 2.20.3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6126:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6126,1,['Update'],['Update']
Deployability,Update htsjdk to 2.23.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6702:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6702,1,['Update'],['Update']
Deployability,Update htsjdk to 2.24.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7073:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7073,1,['Update'],['Update']
Deployability,Update htsjdk to 2.24.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7149:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7149,1,['Update'],['Update']
Deployability,Update htsjdk to 2.7.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2247:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2247,1,['Update'],['Update']
Deployability,Update htsjdk to 2.8.1-17-g19bd848-SNAPSHOT,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2354:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2354,1,['Update'],['Update']
Deployability,Update http-nio and wire its new settings,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8611:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8611,1,['Update'],['Update']
Deployability,Update http-nio to 1.1.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8889:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8889,1,['Update'],['Update']
Deployability,Update import_gvs.py,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8617:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8617,1,['Update'],['Update']
Deployability,Update instructions for installing Java 8 in the README,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8089:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8089,2,"['Update', 'install']","['Update', 'installing']"
Deployability,Update instructions for installing R packages in README.md.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3601:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3601,2,"['Update', 'install']","['Update', 'installing']"
Deployability,Update license copyright date,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2752:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2752,1,['Update'],['Update']
Deployability,Update links to old GATK forum and website,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6382:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6382,1,['Update'],['Update']
Deployability,Update log4j to 2.17.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7624:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7624,1,['Update'],['Update']
Deployability,Update logic around missing sample data in TDM [VS-997],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8422:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8422,1,['Update'],['Update']
Deployability,"Update multiple tools to use a Path instead of File. Updated: FeatureWalker, ReadWalker, IntervalWalker, MultiVariantWalker, AnnotateIntervals, BaseRecalibrator, SelectVariants, SplitNCigarReads. Some tools will need a change to ReferenceSequenceFileWalker in htsjdk, so I couldn't change those. Same for the writers. Part of addressing issue #3709",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3921:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3921,2,['Update'],"['Update', 'Updated']"
Deployability,Update numpy\scipy\pymc3 python package,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6978:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6978,2,['Update'],['Update']
Deployability,Update ojAlgo and improve commons-math / ojAlgo integration,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3970:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3970,2,"['Update', 'integrat']","['Update', 'integration']"
Deployability,Update old docs with GATK4 name: ApplyRecalibration -> ApplyVQSR,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7058:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7058,1,['Update'],['Update']
Deployability,"Update on the gene list format discussion: We recently in added GFF3 support in HTSJDK and one possible path forwards for supporting more general gene list formate for DoC would be to leverage the existing implementation that was included in #6602 to allow a second source of gene objects. This could be trivially implemented if we wanted to follow the same approach as #6602 where we simply farm the decision about what feature type is important out to the user to specify. This would mean that if the user cares about genes they could specify a count for each gene object with its reported boundaries that would be output as a line. This is similar but not analogous to the current behavior for the existing gene lists where we take pains to exclude from the overlap counts bases that are intronic bases in the gene list. . Unfortunately, since the GFF3 format is hierarchical and supports a very large number of feature types it will be very difficult to extract the intron/exon boundaries without properly parsing the GFF3 format. The GFF3 format supports .obo files that lay out the feature hierarchy and through parsing of that format it would be possible to extract intron/exon boundaries but that is not currently supported by HTSJDK and would involve us merging https://github.com/kachulis/htsjdk/tree/ck_gff3_feature_evaluator first in order to support and then on top of that coming up with some rules for deciding what units exactly make up a gene that should be merged for coverage counting. . I see a few options going forwards:; - We could support GFF3 gene lists with hard coded genes/CDS features to be included. This is brittle given that there are a number of more specific names for CDS (coding sequence) exons in genes that might end up being excluded.; - We could support GFF3 format but ignore exon sequences which would mean that the behavior for counting the same genes will vary depending on which format the gene is provided.; - We could support GFF3 gene lists but allow th",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6491#issuecomment-683963413:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6491#issuecomment-683963413,1,['Update'],['Update']
Deployability,"Update on this: @kgururaj will try to provide us with a GATK branch that uses the GenomicsDB fork this week, and ask Gans's team for help if he's not able to build it himself.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4331#issuecomment-372392590:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4331#issuecomment-372392590,1,['Update'],['Update']
Deployability,"Update on this: we've submitted a patch to the `java-storage-nio` library that fixes this issue (https://github.com/googleapis/java-storage-nio/pull/832), and are waiting for Google to merge / release it. Once Google has released a new version of their library we'll upgrade GATK to it and this should be resolved. We still anticipate that this will happen in time for the next GATK release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6179#issuecomment-1057201689:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6179#issuecomment-1057201689,6,"['Update', 'patch', 'release', 'upgrade']","['Update', 'patch', 'release', 'released', 'upgrade']"
Deployability,Update orientation bias model command in mutect2.pdf,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5856:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5856,1,['Update'],['Update']
Deployability,Update our HTSJDK dependency to 4.0.2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8584:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8584,1,['Update'],['Update']
Deployability,Update our google-cloud-java fork to 0.20.5-alpha-GCS-RETRY-FIX,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5099:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5099,1,['Update'],['Update']
Deployability,Update overlap calculation in FragmentUtils,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6824:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6824,1,['Update'],['Update']
Deployability,Update override jar in bulk ingest staging,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8451:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8451,1,['Update'],['Update']
Deployability,Update phasingString so it is unique across contigs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6936:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6936,1,['Update'],['Update']
Deployability,Update picard and htsjdk,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6462:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6462,1,['Update'],['Update']
Deployability,Update picard to 2.21.2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6253:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6253,1,['Update'],['Update']
Deployability,Update picard to 3.1.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8585:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8585,1,['Update'],['Update']
Deployability,Update protobuf to 3.21.6,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8036:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8036,1,['Update'],['Update']
Deployability,Update quickstart,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7439:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7439,1,['Update'],['Update']
Deployability,Update references to old-style arguments,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5063:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5063,1,['Update'],['Update']
Deployability,Update repo location in install_R_packages.R.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3777:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3777,1,['Update'],['Update']
Deployability,Update serializable objects to use lambda functions where appropriate after upgrading to Kryo 3.0+,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1510:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1510,1,['Update'],['Update']
Deployability,Update several dependencies to fix vulnerabilities,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8898:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8898,1,['Update'],['Update']
Deployability,Update spark-dataflow to fix Combine.Globally bug affecting ApplyWhol…,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/600:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/600,1,['Update'],['Update']
Deployability,Update spark.md,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1195:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1195,1,['Update'],['Update']
Deployability,Update sqllite library to support M1 Macs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7519:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7519,1,['Update'],['Update']
Deployability,Update stand_call_conf doc string,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2332:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2332,2,['Update'],['Update']
Deployability,Update sv pipeline scripts for dataproc timed self-termination,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3574:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3574,2,"['Update', 'pipeline']","['Update', 'pipeline']"
Deployability,Update tandem duplication annotations,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2567:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2567,1,['Update'],['Update']
Deployability,Update the BQSR integration tests to test without BAQ and indel qualities,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2563:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2563,2,"['Update', 'integrat']","['Update', 'integration']"
Deployability,Update the GATK base image to a newer LTS ubuntu release,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8610:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8610,2,"['Update', 'release']","['Update', 'release']"
Deployability,Update the GQ after PLs get subset,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3409:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409,1,['Update'],['Update']
Deployability,"Update the Intel GKL to the latest release, 0.8.11",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8409:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8409,2,"['Update', 'release']","['Update', 'release']"
Deployability,Update the M2 WDL readme with Funcotator instead of Oncotator,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5889:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5889,1,['Update'],['Update']
Deployability,Update the Owner version with the latest release from Maven.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4490:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4490,2,"['Update', 'release']","['Update', 'release']"
Deployability,Update the PGT FORMAT header as discussed in #6937:. PGT format field on each genotype can be interpreted as being an indicator of which of the two phased haplotypes in the sample contains the site-specific alternate allele at the site. See also #6220 and #6952,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6954:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6954,1,['Update'],['Update']
Deployability,Update the README for alpha,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1327:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1327,1,['Update'],['Update']
Deployability,Update the VAT pipeline readme to know about the VDS inputs. This will need to further be edited once George's VDS VAT pipeline changes have been completed,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8090:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8090,3,"['Update', 'pipeline']","['Update', 'pipeline']"
Deployability,Update the change log in preparation for releasing version 0.3.2. of the Beta workflow.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8518:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8518,1,['Update'],['Update']
Deployability,Update the conda environment and build.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4749:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4749,1,['Update'],['Update']
Deployability,Update the gcloud package signing key during the docker build,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7180:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7180,1,['Update'],['Update']
Deployability,"Update the gradle distribution commands to include the sparkJar, gatk-launch, and settings.gradle in the zipped archive so we can have a single command to build a distributable zip.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1779:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1779,1,['Update'],['Update']
Deployability,Update the header of AS_FilterStatus,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6858:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6858,1,['Update'],['Update']
Deployability,Update the large CRAM files to v3.0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8832:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8832,1,['Update'],['Update']
Deployability,Update the main project README for beta,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3158:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3158,1,['Update'],['Update']
Deployability,Update the setup_cloud github action,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8651:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8651,1,['Update'],['Update']
Deployability,Update the strand artifact filter,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4500:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4500,1,['Update'],['Update']
Deployability,Update the wikis to use gatk-launch syntax,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1328:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1328,1,['Update'],['Update']
Deployability,Update to 1.1.2.2 with Linux and MacOS shared libraries packaged and added junit to check if they are in the genomicsdb-<VERSION>.jar.; Also brought back #6188 and #6190 into this branch which had to be reverted before - see #6204.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6206:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6206,1,['Update'],['Update']
Deployability,Update to Barclay 1.0.0-24-g87c3fa2-SNAPSHOT,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2455:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2455,1,['Update'],['Update']
Deployability,Update to GKL 0.3.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2259:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2259,1,['Update'],['Update']
Deployability,"Update to GKL 0.3.1 which provides the following features compared to GKL 0.1.2 currently used by GATK:. 1. Improved performance for Level 1 compression.; 1. OpenMP AVX PairHMM with fallback to non-OpenMP support logic in GATK.; 1. Individual shared library objects for each native binding.; 1. Flush-to-zero get/set support. Updated `VectorPairHMMUnitTest` to test all supported implementations of `VectorLoglessPairHMM` and skip the test if no implementations are supported. **Note**; The default number of threads used by OpenMP AVX PairHMM is set to 1, and the command line argument to change the number of threads is not connected yet (see #1946). So, the OpenMP and non-OpenMP PairHMM currently have the same performance. Resolves #1819; First step for #1946",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2259:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2259,2,['Update'],"['Update', 'Updated']"
Deployability,"Update to GKL 0.4.1, HTSJDK 2.9.1, and enable IntelInflater",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423,1,['Update'],['Update']
Deployability,"Update to GKL 0.5.8, which fixes bug in AVX detection, which was beha…",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3513:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3513,1,['Update'],['Update']
Deployability,Update to GKL version 0.8.8,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203,1,['Update'],['Update']
Deployability,Update to Genomicsdb 1.1.2.2 with Linux and MacOS shared libraries packaged,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6206:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6206,1,['Update'],['Update']
Deployability,Update to Intel GKL version 0.5.3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3392:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3392,1,['Update'],['Update']
Deployability,Update to Intel GKL version 0.5.5,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3401:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3401,1,['Update'],['Update']
Deployability,Update to Spark 3.0 and Java 11 (or 17),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6671:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6671,1,['Update'],['Update']
Deployability,Update to gatk script to contain custom jdk path parameter,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8495:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8495,1,['Update'],['Update']
Deployability,Update to gcloud NIO 0.19.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3044:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3044,1,['Update'],['Update']
Deployability,Update to htsjdk 2.16.0. This only updates gatk to fix the compile warnings from deprecations. An additional PR is needed in order to support fasta.gz files. fixes #4039,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4914:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4914,2,"['Update', 'update']","['Update', 'updates']"
Deployability,Update to htsjdk 2.24.1. This fixes a gross issue where we accidentally included Junit as a runtime dependency.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7149:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7149,1,['Update'],['Update']
Deployability,Update to htsjdk 2.4.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1867:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1867,1,['Update'],['Update']
Deployability,Update to htsjdk 2.8.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2301:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2301,1,['Update'],['Update']
Deployability,"Update to latest gcloud, uncomment getAuthenticatedGcs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2581:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2581,1,['Update'],['Update']
Deployability,Update to latest version of VQSR Lite; Refactor GvsCreateFilterSet.wdl to move VQSR Classic code to its own WDL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8269:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8269,1,['Update'],['Update']
Deployability,Update to latest version of ah_var_store gatk override jar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7793:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7793,1,['Update'],['Update']
Deployability,Update to new gcloud release when it's out,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2822:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2822,2,"['Update', 'release']","['Update', 'release']"
Deployability,Update to next google-cloud-java release once it's out,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3500:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3500,2,"['Update', 'release']","['Update', 'release']"
Deployability,Update to reflect Picard version 1.130.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/332:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/332,1,['Update'],['Update']
Deployability,Update to spark-dataflow 0.1.1 and fix unit tests that are failing wh…,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/574:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/574,1,['Update'],['Update']
Deployability,Update to the latest import_gvs() code,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8330:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8330,1,['Update'],['Update']
Deployability,Update tool docs for Funcotator,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7160:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7160,1,['Update'],['Update']
Deployability,Update tool documentation to reflect GATK4 changes (with comms team),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2474:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2474,1,['Update'],['Update']
Deployability,Update two instances of '--genotyping_mode' with '--genotyping-mode',MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5658:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5658,1,['Update'],['Update']
Deployability,Update utils.text package to work on java.nio.Path,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5747:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5747,1,['Update'],['Update']
Deployability,Update variable names in mutect2_pon.wdl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4259:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4259,1,['Update'],['Update']
Deployability,Update variable names in mutect2_pon.wdl to reflect changes in mutect2.wdl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4259:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4259,1,['Update'],['Update']
Deployability,Update variants base image [VS-866],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8262:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8262,1,['Update'],['Update']
Deployability,Update versions of htsjdk/picard/disq,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6637:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6637,1,['Update'],['Update']
Deployability,Update wiki pages that talk about gatk-protected,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2794:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2794,1,['Update'],['Update']
Deployability,Update: #2613 is now done,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2633#issuecomment-299515175:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2633#issuecomment-299515175,1,['Update'],['Update']
Deployability,Update: . The issue may have been fixed in Disq via [this](https://github.com/disq-bio/disq/pull/111). @lbergelson can you teach me how to test this?; The PR didn't lead to a release (yet) so I don't know how to appropriately change `build.gradle` to test.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6027#issuecomment-510105948:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6027#issuecomment-510105948,2,"['Update', 'release']","['Update', 'release']"
Deployability,"Update: @davidbenjamin has generated a new panel of normals, and is in the process of running some analysis on it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1416106674:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1416106674,1,['Update'],['Update']
Deployability,Update: Google just merged https://github.com/googleapis/java-storage-nio/pull/841 and is doing a release. We'll update to the newer library version here and test it out to make sure it resolves the RP issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1059491048:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1059491048,3,"['Update', 'release', 'update']","['Update', 'release', 'update']"
Deployability,Update: I did some more cutting on the VCF and I can reproducibly cause a segfault with only these 4 variants in the VCF. I am attaching the associated VCF and log files here. The other files should remain the same as above.; [in2510-8.orientationFilter.vcf.txt](https://github.com/broadinstitute/gatk/files/6206926/in2510-8.orientationFilter.vcf.txt); [hs_err_pid1358.log](https://github.com/broadinstitute/gatk/files/6206937/hs_err_pid1358.log),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7162#issuecomment-807210386:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7162#issuecomment-807210386,1,['Update'],['Update']
Deployability,"Update: I have looked as far back as gatk4.0 and found the same issue, so it likely isn't a recent Hadoop-BAM issue (like the new split guessing).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5133#issuecomment-415874170:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5133#issuecomment-415874170,1,['Update'],['Update']
Deployability,"Update: I localized gnomAD and got the same result. So I looked at the gnomAD annotation files and found the issue - there is a bug in how the gnomad_genome annotation files were prepared. Some variants appear twice, which is causing Funcotator to output two allele frequency annotations for each variant:. Example:; chr11	54942730	.	C	T	979.63	PASS	AF=8.55286e-05;AF_afr=0;AF_afr_female=0;AF_afr_male=0;AF_amr=0;AF_amr_female=0;AF_amr_male=0;AF_asj=0;AF_asj_female=0;AF_asj_male=0;AF_eas=0.00149477;AF_eas_female=0;AF_eas_male=0.00225734;AF_female=0;AF_fin=0;AF_fin_female=0;AF_fin_male=0;AF_male=0.000154131;AF_nfe=0;AF_nfe_est=0;AF_nfe_female=0;AF_nfe_male=0;AF_nfe_nwe=0;AF_nfe_onf=0;AF_nfe_seu=0;AF_oth=0;AF_oth_female=0;AF_oth_male=0;AF_popmax=0.00149477;AF_raw=0.000164376;OriginalContig=11;OriginalStart=51175001;ReverseComplementedAlleles; chr11	54942730	rs1267687142	C	T	1483.06	PASS	AF=0.000346021;AF_afr=0;AF_afr_female=0;AF_afr_male=0;AF_amr=0;AF_amr_female=0;AF_amr_male=0;AF_asj=0;AF_asj_female=0;AF_asj_male=0;AF_eas=0.00980392;AF_eas_female=0.00694444;AF_eas_male=0.0113636;AF_female=0.000160256;AF_fin=0;AF_fin_female=0;AF_fin_male=0;AF_male=0.000487211;AF_nfe=0;AF_nfe_est=0;AF_nfe_female=0;AF_nfe_male=0;AF_nfe_nwe=0;AF_nfe_onf=0;AF_nfe_seu=0;AF_oth=0.00221239;AF_oth_female=0;AF_oth_male=0.00438596;AF_popmax=0.00980392;AF_raw=0.000561325;OriginalContig=11;OriginalStart=54710206. This bug would affect every pipeline that uses gnomad genome Funcotator for filtering.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8965#issuecomment-2313675104:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8965#issuecomment-2313675104,2,"['Update', 'pipeline']","['Update', 'pipeline']"
Deployability,"Update: I made a list of particularly bad intervals for the DREAM4 and 20-plex Hapmap bams by scattering 500 ways, choosing the 20 slowest jobs (weighting by an empirical 3x slowness factor for jobs on nodes that couldn't use AVX PairHMM acceleration), scattering again etc to obtain 100 or so intervals of roughly 200 bp that took long. Then I confirmed that the slowness had nothing to do with SGE or cromwell (it shouldn't, because I was getting runtime from the GATK output log, not the cromwell log, but just in case. . .) by re-running each interval on gsa5. In *every* case, the slow intervals had extremely deep coverage (2,000 - 30,000) due to mapping error. Even after filtering to MQ == 60, the high coverage usually remained, although it often decreased significantly. In addition to the extreme depth, the only other sign was a significant proportion of reads with multiple SNVs relative to the reference. Unfortunately, something cheap to compute, like CIGAR complexity, was often not a sign, because many CIGARs were eg 101M, with many of the M's coming from SNVs. One quick solution would be to completely skip calling on regions with extremely high depth. It's hard to imagine being able to trust any calls from them. Another option is MQ-based downsampling, for example downsampling to the 1000 reads with the best MQ. Some people might like the downsampling option for the secure feeling of not losing sensitivity, although realistically those regions are so terrible that this security is an illusion. The only real protection is a more complete reference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2975#issuecomment-309565338:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2975#issuecomment-309565338,1,['Update'],['Update']
Deployability,"Update: I wrote an integration test in my branch that runs M2 with ; `--kmer-size 1 --dont-increase-kmer-sizes-for-cycles`. It still calls the given alleles, whereas in master it does not.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571,2,"['Update', 'integrat']","['Update', 'integration']"
Deployability,"Update: after some offline discussion, we found that this was a two-fold issue that has since been fixed.; 1. END was set to END2 in some older VCFs from GATK-SV, so it represented the breakpoint on the second chromosome rather than the first. This has been fixed - multiple more recent GATK-SV VCFs were found to have the correct values for END for CTX events; 2. Older versions of SVAnnotate annotated the interval CHROM:POS-END for CTX, expecting END to be very close to POS. This produced incorrect intervals when END was set to END2, which could be very large, resulting in long lists of genes under PREDICTED_LOF. This has been fixed in #8693 so SVAnnotate now independently annotates breakpoints at CHROM:POS and CHROM:END for CTX. For other users encountering this issue in their VCFs produced by older versions of GATK-SV, I recommend rerunning CleanVcf and AnnotateVcf with the latest versions of GATK-SV. A more manual alternative that requires less re-running of workflows would be: ; 1. Extract CTX SVs; 2. Set END to POS; 4. Strip out functional consequence annotations; 5. Re-annotate with the latest version of SVAnnotate.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8852#issuecomment-2392219403:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8852#issuecomment-2392219403,1,['Update'],['Update']
Deployability,"Update: it appears that SortSamSparkIntegration.testSortBAMsSharded fails locally for me even on master (when run from intellij or from gradle), so that issue appears to be unrelated to the htsjdk upgrade.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5877#issuecomment-482556548:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5877#issuecomment-482556548,2,"['Update', 'upgrade']","['Update', 'upgrade']"
Deployability,"Update: the 1000 (okay, 856 to be precise) exomes test passed without a hiccup. After David R's big HC test PR goes in I will address this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-380136134:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-380136134,1,['Update'],['Update']
Deployability,Update: the cfDNA validation is all set up.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2942#issuecomment-357065450:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2942#issuecomment-357065450,1,['Update'],['Update']
Deployability,Update: the wgs whitelist helps greatly but our work is not yet done. Even on the overlap of the exome with the whitelist a few very slow some scattered jobs delay everything else.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2975#issuecomment-306510675:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2975#issuecomment-306510675,1,['Update'],['Update']
Deployability,Update: there's another example on that thread now. If no one objects I'm going to do this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-478308694:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-478308694,1,['Update'],['Update']
Deployability,Update: this issue is still happening. User ran GATK 4.4: https://gatk.broadinstitute.org/hc/en-us/community/posts/15706942393371-Error-when-running-VariantAnnotator. Here is a PR to deploy a bugfix for a similar issue in HaplotypeCaller. https://github.com/broadinstitute/gatk/pull/5365,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6689#issuecomment-1625517529:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689#issuecomment-1625517529,2,"['Update', 'deploy']","['Update', 'deploy']"
Deployability,"Update:. 1000 samples on one interval, 11GB Xmx to the JVM:; 20 runs for each parameter set. - batchSize at **200** and buffering **disabled** yields: 25% success and 75% OOM; Runtime (when it succeed) is ~ 1.75x longer than batchSize 100 (with or without buffer); ; - batchSize at 100: ; Tried on both OpenJDK8 and Oracle JDK, with buffer disabled and default.; Overall similar performances. Got 2 failures over the 80 total runs:; - One SSL handshake on the ""default buffer OpenJDK""; - One `com.google.cloud.storage.StorageException: 503 Service Unavailable` on the ""buffer disabled OracleJDK""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301153727:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301153727,1,['Update'],['Update']
Deployability,"Update:. Dataproc's preview image was just updated to use Spark 2.0.2. ; The specific `CocurrentModificationException` is gone after this upgrade, but a new IO exception emerges, which might be related to the problem described [here](http://stackoverflow.com/questions/29781489/apache-spark-network-errors-between-executors).; Needs more testing to find where the problem is.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2277#issuecomment-264500821:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2277#issuecomment-264500821,3,"['Update', 'update', 'upgrade']","['Update', 'updated', 'upgrade']"
Deployability,"Update:; - [ ] A cool name! (Marduk, Clarendon, NeuroVar) ? maybe I'll do a slack poll of dsde methods?; - [x] Model training script (in Python, eventually in Java); - [x] Pretrained model for WGS; - [x] Pretrained model for WEx (still being validated and was only trained on NA12878); - [x] Model inference and VCF annotation (in Java); - [x] Solution for applying filters based on CNN score cutoff (tranches.py script); - [ ] Alternate joint calling WDL? Or for re-filtering? (ideally with a $$$ estimate); - [ ] Performance optimizations?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4225#issuecomment-363436039:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4225#issuecomment-363436039,1,['Update'],['Update']
Deployability,"Update:; The problem seemingly was caused by the logging part in Spark (thanks to Carlos H. Andrade Costa from IBM for pointing this out). So a temporary solution that works for now is to add the following lines in the initialization script for spinning up the cluster to turn off logging, . ```bash; sudo sed -i -- 's/log4j.rootCategory=INFO, console/log4j.rootCategory=OFF, console/g'\; /etc/spark/conf/log4j.properties; sudo sed -i -- 's/log4j.logger.org.apache.spark=WARN/log4j.logger.org.apache.spark=OFF/g'\; /etc/spark/conf/log4j.properties; sudo sed -i -- 's/hadoop.root.logger=INFO,console/hadoop.root.logger=OFF,console/g'\; /etc/hadoop/conf/log4j.properties; ```. assuming the cluster was created with . --image-version preview. I test run the tool where I observed the bug (`FindBreakpointEvidenceSpark`) twice on a cluster created & initialized this way and didn't observe any `ConcurrentModificationException`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2277#issuecomment-262640914:0,Update,Update,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2277#issuecomment-262640914,1,['Update'],['Update']
Deployability,"UpdateVCFSequenceDictionary replaces ""##FORMAT=<ID=GQ"" with stock text",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8629:0,Update,UpdateVCFSequenceDictionary,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8629,1,['Update'],['UpdateVCFSequenceDictionary']
Deployability,UpdateVCFSequenceDictionary tool.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2234:0,Update,UpdateVCFSequenceDictionary,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2234,1,['Update'],['UpdateVCFSequenceDictionary']
Deployability,Updated --mapping-quality-threshold and its documentation to be less confusing,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7036:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7036,1,['Update'],['Updated']
Deployability,Updated COSMIC to annotate protein change strings with their counts.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5181:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5181,1,['Update'],['Updated']
Deployability,Updated Callset stats README [VS-210],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7502:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7502,1,['Update'],['Updated']
Deployability,Updated Funcotator to support ENSEMBL GTF files (and non-human species).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6477:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6477,1,['Update'],['Updated']
Deployability,"Updated GVCF ""reblocking"" with no gaps, no overlaps",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122,1,['Update'],['Updated']
Deployability,Updated GencodeGtfCodec to be more permissive.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7166:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7166,1,['Update'],['Updated']
Deployability,Updated M2 WDL README with Funcotator info.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5892:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5892,1,['Update'],['Updated']
Deployability,Updated M2 parameters to make them consistent with HC,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8186:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8186,1,['Update'],['Updated']
Deployability,Updated M2 with latest Funcotator info.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5735:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5735,1,['Update'],['Updated']
Deployability,Updated MarkDuplicates Scoring and Comparison code to reflect mismatches to picard,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5023:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5023,1,['Update'],['Updated']
Deployability,Updated MarkDuplicates code to rely on the Picard OpticalDuplicatesFinder,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4750:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4750,1,['Update'],['Updated']
Deployability,Updated MarkDuplicates to use Picard metrics code,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4779:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4779,1,['Update'],['Updated']
Deployability,Updated Picard to version 2.18.25,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5597:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5597,1,['Update'],['Updated']
Deployability,"Updated PostprocessGermlineCNVCalls (segments VCF writing, WDL scripts, unit tests, integration tests)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4396:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4396,2,"['Update', 'integrat']","['Updated', 'integration']"
Deployability,"Updated Python and PyMC, removed TensorFlow, and added PyTorch in conda environment.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561,1,['Update'],['Updated']
Deployability,Updated Quickstart,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7568:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7568,1,['Update'],['Updated']
Deployability,Updated R requirement in the README,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4023:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4023,1,['Update'],['Updated']
Deployability,Updated README to mention that macOS is not supported at this time.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6788:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6788,1,['Update'],['Updated']
Deployability,Updated README to state that only 64-bit Linux distributions are supported. Made this edit under the Python dependencies section. Fix issue #6786,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6788:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6788,1,['Update'],['Updated']
Deployability,"Updated RMS Mapping quality annotations to be of type long/Long instead; of int/Integer. With int types, a large cohort could overflow; Integer.MAX_VALUE when handling sum of squared mapping qualities. With; long types this should not be a problem until we have off-world; colonies. This resolves issue 5433.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5435:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5435,1,['Update'],['Updated']
Deployability,Updated TODO list:. - [x] #4962 ; - [x] #4970; - [x] #4971; - [ ] #5077 . (optional):. - [ ] #4406 or make a PR to address #4684 ; - [ ] #4789,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-401497712:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-401497712,1,['Update'],['Updated']
Deployability,Updated VCF gencode annotation positions/alleles.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5131:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5131,1,['Update'],['Updated']
Deployability,"Updated WDL generation, upgrade to Barclay 4.0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6800:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6800,2,"['Update', 'upgrade']","['Updated', 'upgrade']"
Deployability,Updated arg names for engine-level arguments. Fixed logging for PossibleDeNovo annotation. Also addresses #3927 -- minor bug in CalculateGenotypePosteriors,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3928:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3928,1,['Update'],['Updated']
Deployability,Updated arguments and tests to use a datasources directory.; ; Fixed the way dna repair genes get parsed.; Fixed a coding sequence bug when dealing with multiple gencode sources.; Fixed a bug in COSMIC annotaitons when GENCODE annotations are in IGRs.; ; Fixes #3999,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4020:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4020,1,['Update'],['Updated']
Deployability,Updated carrot publish github action version,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8084:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8084,1,['Update'],['Updated']
Deployability,Updated code to allow for protein changes with N / IUPAC bases.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6778:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6778,1,['Update'],['Updated']
Deployability,Updated datasource version parsing,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5149:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5149,1,['Update'],['Updated']
Deployability,Updated doc templates to match website updates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4805:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4805,2,"['Update', 'update']","['Updated', 'updates']"
Deployability,Updated docs with usage examples and kebabed long args for:; - HaplotypeCaller; - HaplotypeCallerSpark; - CombineGVCFs; - GenomicsDBImport; - GenotypeGVCFs; - VariantFiltration; - ASEReadCounter; - SplitNCigarReads; - CalculateGenotypePosteriors; - VariantRecalibrator; - ApplyVQSR. Elaborated on/fixed docs for:; - InbreedingCoeff; - ExcessHet; - SampleList. Hid GatherTranches. Added a ReadTransformer to SplitNCigarReads to simplify the command from the old RNA best practices (https://software.broadinstitute.org/gatk/documentation/article.php?id=3891) NOTE: this slightly changes the default behavior @vdauwera . Unfortunately I squashed the SplitNCigarReads changes into the doc fixes. :( If that's a problem I can split into two commits.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3891:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3891,1,['Update'],['Updated']
Deployability,Updated documentation with FAQ section to respond to user comments.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5755:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5755,1,['Update'],['Updated']
Deployability,Updated gCNV WDLs for FireCloud and changed CNV/M2 WDLs to use gatk launch script.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4071:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4071,1,['Update'],['Updated']
Deployability,Updated install_R_packages.R to fix broken ggplot2 dependency in gatkbase Docker image.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5040:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5040,1,['Update'],['Updated']
Deployability,Updated log4j to version 2.16.0 to further mitigate CVE-2021-44228,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7605:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7605,1,['Update'],['Updated']
Deployability,Updated mutect2.wdl and funcotator.wdl with latest args for funcotator.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4890:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4890,1,['Update'],['Updated']
Deployability,Updated one set of outdated forum links.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8273:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8273,1,['Update'],['Updated']
Deployability,"Updated per conversation yesterday:; - If a single input is used, no sequence dictionary is required.; - If multiple inputs are used, at least one must have a sequence dictionary. Other comments:; - We should consider making FeatureDataSource do the same header/dictionary reconciliation that we're doing here; - In theory you should be able to intermix GenomicsDB/file inputs, but there are no tests for that here (separate ticket ?); - There is currently no protection against writing out a VCF with a header that contains an index-derived dictionary with zero-len sequences; - I added a GATK3 compatibility arg to VariantRecalibrator in this commit since I was using it for perf testing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2182#issuecomment-253244790:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2182#issuecomment-253244790,1,['Update'],['Updated']
Deployability,"Updated plan. ----------; ## Small improvements in new interpretation tool; ; - [x] Output bam instead of sam for assembly alignments; - [x] Instead of creating directory, new interpretation tool writes files (behavior consistent with current interpretation tool); - [x] Prefix with sample name for output files' names; - [x] Add `INSLEN` annotation when there's `INSSEQ`; - [x] Clarify the boundary between `AlignedContig` and `AssemblyContigWithFineTunedAlignments`; - [x] Increase test coverage for `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:601,update,update,601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021,3,"['Update', 'update']","['Updated', 'update']"
Deployability,Updated plotting for ModelSegments CNV pipeline.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3729:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3729,2,"['Update', 'pipeline']","['Updated', 'pipeline']"
Deployability,"Updated scripts for sv cluster creation, initialization and pipeline execution",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2468:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2468,2,"['Update', 'pipeline']","['Updated', 'pipeline']"
Deployability,Updated templates to fit current website logic,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3165:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3165,1,['Update'],['Updated']
Deployability,Updated testing Gencode data sources to fully exercise test data set,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5423:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5423,1,['Update'],['Updated']
Deployability,"Updated the carrot github action workflow to the most recent version, which supports using #carrot_pr to trigger branch vs master comparison runs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8084:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8084,1,['Update'],['Updated']
Deployability,Updated the code that grabs a resource file to use Resource.getResour…,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4723:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4723,1,['Update'],['Updated']
Deployability,Updated the experimental funcotator.wdl to work properly in cromwell.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4870:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4870,1,['Update'],['Updated']
Deployability,Updated the link to the Funcotator info/tutorial page.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6920:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6920,1,['Update'],['Updated']
Deployability,Updated the stats script to be more easily used.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7759:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7759,1,['Update'],['Updated']
Deployability,Updated the ubuntu version for the carrot github action because github dropped support for 18.04,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8299:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8299,1,['Update'],['Updated']
Deployability,"Updated the wiki with docker/gcloud setup instructions, and linked to them in a comment at the top of the script.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7078#issuecomment-780050462:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7078#issuecomment-780050462,1,['Update'],['Updated']
Deployability,Updated to a newer release of the carrot-publish-github-action,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6986:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6986,2,"['Update', 'release']","['Updated', 'release']"
Deployability,Updated to the latest GATK docker.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7611#issuecomment-1007820718:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7611#issuecomment-1007820718,1,['Update'],['Updated']
Deployability,Updated top-level class documentation for Funcotator.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4655:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4655,1,['Update'],['Updated']
Deployability,"Updated with [this](https://github.com/SHuang-Broad/JNIFermiLite). @cwhelan would you mind taking a brief look and see what improvements can be made to the interface?; @lbergelson I also added you as a contributor so later if we decide to make use of fermi-lite in the SV pipeline, you'll be in control. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2072#issuecomment-237125901:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2072#issuecomment-237125901,2,"['Update', 'pipeline']","['Updated', 'pipeline']"
Deployability,Updated:; Successful VQSR Lite Run (with monitoring summary output) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/ccdc0ec5-3737-407f-ac84-ca2309167a2b); Successful VQSR Classic Run (with monitoring summary output) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/001671aa-21db-437a-8d92-42bced766ca6),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1502284208:0,Update,Updated,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1502284208,1,['Update'],['Updated']
Deployability,UpdatedConcordanceDoc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3108:0,Update,UpdatedConcordanceDoc,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3108,1,['Update'],['UpdatedConcordanceDoc']
Deployability,"Updates (EchoCallset Version):. Changes to scatter width of VCFs generated has changed the amount of data generated in tests, so need to update truth; Adding a new field to extracted VCF Header EXCESS_ALLLELES and that will break the tests.; And why not validate our VCFs for jollies.; Updates 'truth' path for data to match these changes. Integration tests failed due to different number of output VCFs now. So I cherry-picked Miguel's commit on ah_var_store that changed the scatter.; Integration tests *still* [failing](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/8f7b0cc9-4a31-404b-99b3-89e182707e8b) due to the change in VCF Header:. > 6,7d5; < ##FILTER=<ID=high_CALIBRATION_SENSITIVITY_INDEL,Description=""Site failed INDEL model calibration sensitivity cutoff (0.99)"">; < ##FILTER=<ID=high_CALIBRATION_SENSITIVITY_SNP,Description=""Site failed SNP model calibration sensitivity cutoff (0.997)"">; 9c7; < ##FORMAT=<ID=FT,Number=1,Type=String,Description=""Genotype Filter Field"">; ---; > ##FORMAT=<ID=FT,Number=1,Type=String,Description=""Sample Genotype Filter Field"">; 3388a3387,3388; > ##high_CALIBRATION_SENSITIVITY_INDEL=Sample Genotype FT filter value indicating that the genotyped allele failed INDEL model calibration sensitivity cutoff (0.99); > ##high_CALIBRATION_SENSITIVITY_SNP=Sample Genotype FT filter value indicating that the genotyped allele failed SNP model calibration sensitivity cutoff (0.997)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8848:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8848,5,"['Integrat', 'Update', 'update']","['Integration', 'Updates', 'update']"
Deployability,Updates M2 WDLs to 1.0 and fixes NIO,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6108:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6108,1,['Update'],['Updates']
Deployability,"Updates SVAnnotate's functional consequence annotation of complex SVs.; * Introduce PREDICTED_PARTIAL_DISPERSED_DUP annotation to describe dispersed duplications of coding sequence that are not expected to behave the same way as tandem duplications; * Ignore INV intervals in dDUP events; * Modify INV intervals in dupINV and similar events to more accurately capture the overall impact of the complex SV; * Ignore complex DUP segments for promoter, noncoding, and nearest TSS annotations because these DUPs are never in tandem; * Merge relevant intervals before annotating nearest TSS for complex events containing DELs; * Update documentation. Testing; * Add unit test for CPX SV segment determination; * Add CPX SV unit test cases; * Update unit/integration test expected outputs; * All unit & integration tests for SVAnnotate ran successfully",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8516:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8516,5,"['Update', 'integrat']","['Update', 'Updates', 'integration']"
Deployability,Updates bwamem-jni depedency to 1.0.2 and adds the possibility of ali…,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3474:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3474,1,['Update'],['Updates']
Deployability,Updates expectations for the X/Y scaling changes that went in a couple of weeks ago and slip in a few unrelated minor improvements.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7881:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7881,1,['Update'],['Updates']
Deployability,Updates files for integration tests that were failing because of a conflict between #3876 and #3611. (Feel free to merge if it passes review so others can continue working immediately),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3910:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3910,2,"['Update', 'integrat']","['Updates', 'integration']"
Deployability,Updates for latest data source release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5614:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5614,2,"['Update', 'release']","['Updates', 'release']"
Deployability,Updates gatk-bwamem-jni dependency to 1.0.3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3727:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3727,1,['Update'],['Updates']
Deployability,Updates in preparation for release 0.5.2 [VS-1196],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8659:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8659,2,"['Update', 'release']","['Updates', 'release']"
Deployability,Updates in preparation for release 0.6.0 [VS-1376],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8925:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8925,2,"['Update', 'release']","['Updates', 'release']"
Deployability,"Updates the code to pull the PS field out of gVCFs and stores it in the VET_* table(s).; Note schema change on the VET table; Successful BulkIngest [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Exome%20Beta%20Test%20ggrant/job_history/5d1f17a9-eeb2-4db3-a681-32d36d9e567e) (run on Exomes as they have PGT, PID, and PS in their gVCFs).; Successful Integration Test Run [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/9ab365ff-743b-4d97-9c2a-6a09cf8728f4) - But note that the Exome Integration test failed for slight (and expected) difference in table sizes. I have updated the truth in `gs://gvs-internal-quickstart/integration/2023-07-25-quicker/exome_weighted/table_sizes_expected.csv`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8531:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8531,5,"['Integrat', 'Update', 'integrat', 'update']","['Integration', 'Updates', 'integration', 'updated']"
Deployability,Updates to VcfComparator,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8973:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8973,1,['Update'],['Updates']
Deployability,Updates to `gatk` launch script to fix properties and config file definitions.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4653:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4653,1,['Update'],['Updates']
Deployability,Updates to rc-vs-651-vat-from-vds to support Scattering.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8122:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8122,1,['Update'],['Updates']
Deployability,Updates to reduce size of docker,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8259:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8259,1,['Update'],['Updates']
Deployability,Updates to the dockerfile to use latest intel-optimized tensorflow,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5725:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725,1,['Update'],['Updates']
Deployability,"Updates:; - Changes to scatter width of VCFs generated has changed the amount of data generated in tests, so need to update truth; - Adding a new field to extracted VCF Header `EXCESS_ALLLELES` and that will break the tests.; - And why not validate our VCFs for jollies.; - Updates 'truth' path for data to match these changes. Integration Tests:; Passing test against Chr20/X/Y [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/985fbc06-36ed-4006-9703-0b86577f704c); Passing test against All Chromosomes [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/9d473c81-4742-4188-bc70-1e9371bfcc11)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8846:0,Update,Updates,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8846,4,"['Integrat', 'Update', 'update']","['Integration', 'Updates', 'update']"
Deployability,Updating Funcotator tool documentation for 4.1 release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5620:47,release,release,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5620,1,['release'],['release']
Deployability,Updating dockers to include updates to Google cloud storage libraries,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8401:28,update,updates,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8401,1,['update'],['updates']
Deployability,Updating parameters used in local assembly step in SV pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1938:54,pipeline,pipeline,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1938,1,['pipeline'],['pipeline']
Deployability,"Updating the AUTHORS file to include authors who contributed to gatk-protected who's work has been integrated into GATK by the merger. I need to find out the preferred emails for the newly listed authors. Anders Peterson; Ayman Abdel Ghany <aymana.ghany@devfactory.com>; Kenji Kaneda ; Nils Homer. @apete @AymanDF @kkaneda @nh13 Would you like to be included here and if so, what email address would you like listed? Have I spelled your name correctly?. Resolves #3048",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3330:99,integrat,integrated,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3330,1,['integrat'],['integrated']
Deployability,Updating the README.md to fix the R installation instructions which were out of date.; scripts/install_R_packages.R -> scripts/docker/gatkbase/install_R_packages.R; fixes #3601,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3602:36,install,installation,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3602,1,['install'],['installation']
Deployability,Upgrade Barclay and integrate ExperimentalFeature annotation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2744:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2744,2,"['Upgrade', 'integrat']","['Upgrade', 'integrate']"
Deployability,"Upgrade Barclay, suppress file expansion for interval arguments.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4270:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4270,1,['Upgrade'],['Upgrade']
Deployability,Upgrade Barclay.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2790:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2790,1,['Upgrade'],['Upgrade']
Deployability,Upgrade CNV WDLs to 1.0 spec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6506:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6506,1,['Upgrade'],['Upgrade']
Deployability,Upgrade GCS Connector to 1.9.17,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6135:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6135,1,['Upgrade'],['Upgrade']
Deployability,Upgrade GenomicsDB to version 0.7.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3575:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3575,1,['Upgrade'],['Upgrade']
Deployability,Upgrade Mockito from 1.10.19 -> 2.10.0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3581:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3581,1,['Upgrade'],['Upgrade']
Deployability,"Upgrade Nirvana to 3.18.1, add a workflow to push GVS output VCFs [VS-661]",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8056:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8056,1,['Upgrade'],['Upgrade']
Deployability,Upgrade Oncotator version in the cromwell M2 WDL test json,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4808:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4808,1,['Upgrade'],['Upgrade']
Deployability,Upgrade Picard and remove/resolve placeholder program groups.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4034:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4034,1,['Upgrade'],['Upgrade']
Deployability,Upgrade Picard from 2.18.7 -> 2.18.13.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5173:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5173,1,['Upgrade'],['Upgrade']
Deployability,Upgrade Picard to 2.14.0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3737:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3737,1,['Upgrade'],['Upgrade']
Deployability,Upgrade automatic WDL tests to use cromwell 30,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4418:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4418,1,['Upgrade'],['Upgrade']
Deployability,"Upgrade barclay, htsjdk, gatk-fermilite-jni and gatk-bwamem-jni",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3127:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3127,1,['Upgrade'],['Upgrade']
Deployability,Upgrade cromwell to v51.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6628:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6628,1,['Upgrade'],['Upgrade']
Deployability,Upgrade google-cloud-java from 0.23.1 to 0.24.0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3594:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3594,1,['Upgrade'],['Upgrade']
Deployability,Upgrade google-cloud-java to 0.30.0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855,1,['Upgrade'],['Upgrade']
Deployability,Upgrade htsjdk to 1.140.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/979:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/979,1,['Upgrade'],['Upgrade']
Deployability,Upgrade htsjdk to 2.1.1.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1551:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1551,1,['Upgrade'],['Upgrade']
Deployability,Upgrade htsjdk to 2.11.0-4-g958dc6e-SNAPSHOT.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3504:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3504,1,['Upgrade'],['Upgrade']
Deployability,Upgrade htsjdk to 2.3.0 and Hadoop-BAM to 7.5.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1817:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1817,1,['Upgrade'],['Upgrade']
Deployability,Upgrade htsjdk to v3.0.0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7867:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7867,1,['Upgrade'],['Upgrade']
Deployability,Upgrade htsjdk to v3.0.1 and picard to 2.27.5,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8025:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8025,1,['Upgrade'],['Upgrade']
Deployability,Upgrade log4j to 2.17.0 to mitigate another newly discovered issue,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7615:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7615,1,['Upgrade'],['Upgrade']
Deployability,Upgrade miniconda version installed on docker,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5851:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5851,2,"['Upgrade', 'install']","['Upgrade', 'installed']"
Deployability,Upgrade numpy in the conda environment,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6480:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6480,1,['Upgrade'],['Upgrade']
Deployability,Upgrade numpy to version 1.17.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6494:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6494,1,['Upgrade'],['Upgrade']
Deployability,Upgrade picard version and gCNV WDLs after scatter-by-interval is added to IntervalListTools.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5174:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5174,1,['Upgrade'],['Upgrade']
Deployability,Upgrade samtools in the GATK docker image,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8460:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8460,1,['Upgrade'],['Upgrade']
Deployability,Upgrade samtools in the GATK docker image to 1.10 (at least),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7886:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7886,1,['Upgrade'],['Upgrade']
Deployability,Upgrade spark dependency to 1.5,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1406:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1406,1,['Upgrade'],['Upgrade']
Deployability,"Upgrade testNG to 6.11, use force dependency resolution for testNG",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2617:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2617,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Barclay 1.0.0-17-g30db73c-SNAPSHOT.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2392:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2392,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Barclay 1.2.2.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3804:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3804,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Barclay 2.0.0 and Picard 2.17.2.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4070:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4070,1,['Upgrade'],['Upgrade']
Deployability,"Upgrade to Barclay 3.0.0, with changes for FeatureInput discovery based on Barclay refactoring.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4523:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4523,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Barclay 4.0.1.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6864:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6864,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Barclay 4.0.2.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7602:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7602,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Barclay snapshot for tagged arguments.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2388:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2388,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Disq 0.3.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5981:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5981,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to GKL 0.7,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3615:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3615,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Gradle 7,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7609:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7609,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Hadoop-BAM 7.9.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3991:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3991,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Picard 2.18.1.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4620:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4620,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Picard 2.18.16.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5412:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5412,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Picard 2.21.7.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6416:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6416,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Picard 2.23.3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6717:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6717,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Spark 2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2220:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2220,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Spark 2.0.2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2277:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2277,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Spark 2.4,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5782:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5782,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to Spark 2.4.3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5990:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5990,1,['Upgrade'],['Upgrade']
Deployability,"Upgrade to Spark Dataflow 0.2.3, which has scalability and performance",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/657:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/657,1,['Upgrade'],['Upgrade']
Deployability,"Upgrade to Spark Dataflow 0.4.0, which implements Dataflow 0.4.150727.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/785:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/785,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to TestNG 7,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5787:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to a released htsjdk.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3505:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3505,2,"['Upgrade', 'release']","['Upgrade', 'released']"
Deployability,"Upgrade to gkl-0.5.6, and added log4j-1.2-api bridge to dependencies,…",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3416:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to gradle 5.4.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6007:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6007,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to htsjdk 2.11.0. Make TargetCodec indexable.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3403:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3403,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to htsjdk 2.5 and hadoop-bam 7.6.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1958:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1958,1,['Upgrade'],['Upgrade']
Deployability,Upgrade to htsjdk2.0.0 and update HadoopReferenceSequenceFileFactory for nio path changes.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1243:0,Upgrade,Upgrade,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1243,2,"['Upgrade', 'update']","['Upgrade', 'update']"
Deployability,Upgraded Funcotator.wdl to WDL 1.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5589:0,Upgrade,Upgraded,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5589,1,['Upgrade'],['Upgraded']
Deployability,Upgraded Owner to 1.0.10.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4638:0,Upgrade,Upgraded,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4638,1,['Upgrade'],['Upgraded']
Deployability,Upgraded the Funcotator WDL to WDL 1.0 and implemented new features:; * Automatic disk size calculation; * More readable default parameter settings; * Use of WDL 1.0 features such as defaults and true/false operators; * Using GATK to pull the default datasource rather than wget,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5589:0,Upgrade,Upgraded,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5589,1,['Upgrade'],['Upgraded']
Deployability,"Upgrades Barclay to 4.1.0. Adds an `@DeprecatedFeature` annotation that can be applied to any `@DocumentedFeature` or `@Argument`, and updates the handful of such features that are already tagged with the standard Java annotation `@Deprecated` to use the new annotation. Mutually exclusive with `@Beta` and `@Experimental`. The output for `--use-new-qual-calculator`:; <img width=""783"" alt=""Screen Shot 2022-11-21 at 5 04 44 PM"" src=""https://user-images.githubusercontent.com/10062863/203168110-381424c7-e0e2-4f93-b51b-41f74212b669.png"">; <img width=""918"" alt=""Screen Shot 2022-11-21 at 5 14 16 PM"" src=""https://user-images.githubusercontent.com/10062863/203168311-cfc7b1b1-79d8-48c8-b965-766e424135ab.png"">; <img width=""851"" alt=""Screen Shot 2022-11-21 at 6 39 03 PM"" src=""https://user-images.githubusercontent.com/10062863/203179466-b817bba3-312b-4718-a758-9c063f41d755.png"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8100:0,Upgrade,Upgrades,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8100,2,"['Upgrade', 'update']","['Upgrades', 'updates']"
Deployability,"Upgrades PathSeqScoreSpark to perform abundance score calculations on the executors rather than the driver. This was crashing on inputs with a lot of pathogen reads. . This also required some minor changes to the `PSPathogenTaxonScore` class to be able to keep track of abundance score contributions that come directly from hits to that taxon and those that are from the taxon's descendents. As a result, some of the test output changed when using bitwise, exact checks on the output. So the tests now check for output equivalence, meaning parsing the scores table, checking that all the taxa are the same, and that the scores are equal to within some defined epsilon.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3406:0,Upgrade,Upgrades,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3406,1,['Upgrade'],['Upgrades']
Deployability,"Upgrading directly to the latest `google-cloud-java` is blocked by https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2453, but we could update our fork to include the built-in prefetching.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4986#issuecomment-403542398:150,update,update,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4986#issuecomment-403542398,1,['update'],['update']
Deployability,Upgrading to Gradle 7. - removed all deprecation warnings; - upgraded shadow and download plugins for compatibility; - moved to maven-publish (existing maven plugin is deprecated); - install/uploadArtifacts are now PublishToMavenLocal/publish respectively (due to above move). Caveats. - I was unable to test signing of artifacts fully. I did test it by commenting out the requirement that we only sign release jars published and it did perform the signing. ; - I was unable to test publish to Sonatype as I do not have an account,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7609:61,upgrade,upgraded,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7609,3,"['install', 'release', 'upgrade']","['install', 'release', 'upgraded']"
Deployability,"Upgrading to Spark 2.4 causes build errors that are fixed by also upgrading to Gradle 5. (Without upgrading Gradle, the shadow JAR could not be built, and I couldn't find a fix that didn't involve a Gradle upgrade.) The remaining failures are all due to the docker build with Gradle 5, see #6007 for a standalone PR tracking this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5990#issuecomment-502659658:206,upgrade,upgrade,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5990#issuecomment-502659658,1,['upgrade'],['upgrade']
Deployability,Upgrading to Spark 3.3 (switches to log4j 2.x) when it's released would be ideal since it would solve the security issue mentioned [here](https://gatk.broadinstitute.org/hc/en-us/community/posts/4592331786651-vulnerability-issue-for-gatk-package-4-2-5-0-local-jar),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6671#issuecomment-1155747154:57,release,released,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6671#issuecomment-1155747154,1,['release'],['released']
Deployability,"Upon running Mutect2 using the germline and pon provided by gatk inside a pipeline while running in parallel. If I use an intervals BED file I get the following error:. ```; org.broadinstitute.hellbender.exceptions.GATKException: Error initializing feature reader for path /media/AGROS/hg19/af-only-gnomad.raw.sites.vcf.gz; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:383); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:335); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.FeatureManager.addToFeatureSources(FeatureManager.java:246); 	at org.broadinstitute.hellbender.engine.FeatureManager.initializeFeatureSources(FeatureManager.java:209); 	at org.broadinstitute.hellbender.engine.FeatureManager.<init>(FeatureManager.java:156); 	at org.broadinstitute.hellbender.engine.GATKTool.initializeFeatures(GATKTool.java:488); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:709); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.onStartup(AssemblyRegionWalker.java:79); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: /media/AGROS/hg19/af-only-gnomad.raw.sites.vcf.gz (Device or resource busy), for input source: /media/AGROS/hg19/af-only-gnomad.raw.sites.vcf.gz; 	at htsjdk.tribble.TabixFea",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7059:74,pipeline,pipeline,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7059,1,['pipeline'],['pipeline']
Deployability,"Use Cromwell's [noAddress](https://support.terra.bio/hc/en-us/community/posts/360060020871-noAddress-true-results-in-stalling-jobs) feature to avoid the unnecessary use of external IPs on Cromwell worker VMs on wide scatters that cause us Google quota problems. For most of the GVS code this only involves adding `noAddress: true` to the existing runtime attributes. In the PGEN code this was slightly more work to change away from `docker: ""ubuntu:22.04""` which is implicitly pulled from Docker Hub. Since `noAddress: true` means the VM can only interact with Google services, we have to switch to a GCR-hosted image as Docker Hub has become unreachable. - [Mostly successful integration test](https://job-manager.dsde-prod.broadinstitute.org/jobs/32b9e2b5-3c56-4bf8-ab5e-66fa72c7cadb), delta some existing issues with cost discrepancies documented in VS-1324.; - [Successful PGEN extract](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/1f19bea2-a9b9-4ec5-b741-e9f64bbfa35a)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8764:677,integrat,integration,677,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8764,1,['integrat'],['integration']
Deployability,"Use Java 11.0.11+9 for testing, upgrade hadoop to v3.3.1.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8102:32,upgrade,upgrade,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8102,1,['upgrade'],['upgrade']
Deployability,Use Spark to speed up the MarkDuplicates and SortSam steps in the single-sample pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3706:80,pipeline,pipeline,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3706,1,['pipeline'],['pipeline']
Deployability,Use conda env create --force rather than conda env update in localDevCondaEnv task.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5776:51,update,update,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5776,1,['update'],['update']
Deployability,Use gvs-internal project in integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7901:28,integrat,integration,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7901,1,['integrat'],['integration']
Deployability,Use the latest GKL 0.8.3 release which includes optimizations for Level 2 compression,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4311:25,release,release,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4311,1,['release'],['release']
Deployability,"Used to be used. Used to be tested through an integration test that is no longer, I guess. Merge away. @lbergelson",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4078#issuecomment-355870074:46,integrat,integration,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4078#issuecomment-355870074,1,['integrat'],['integration']
Deployability,"User brought up that Broad's google-cloud-sdk is not up to date, so I added a note telling people to upgrade regularly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3663:101,upgrade,upgrade,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3663,1,['upgrade'],['upgrade']
Deployability,"User has reported default settings in other countries cause tools to error because of the switch between commas and periods. The tools themselves generate the data with the commas that then error downstream tools. User reports a workaround solution of adding `-Duser.language=en -Duser.country=US` to commands but this is cumbersome. . Should our tools should be internationally compatible?. ---; Hi @shlee, @slee,. yes it is working when I replace the commas with points, but since I am using the wdl-pipeline which was provided by slee on gitHub, this is not a sufficient workaround. Due to my expectation that the problem (commas instead of points) arise from my language settings I try different thing to change my actual language on the system. To make the long story short the solution was to start CalculateTargetCoverage with the flags (I added them in the cnv_somatic_tasks.wdl):; ```; java -Duser.language=en -Duser.country=US -Xmx${default=4 mem}g -jar ${gatk_jar} CalculateTargetCoverage; ```; And now the cnv_somatic_panel_workflow.wdl runs smoothly to the end, with points instead of commas :). An other solution would be to running the pipeline in a DockerContainer wich have an english java-version installed, like the one which is provide by the gatk-team. I hope this helps other user too which are working with non-englisch java versions. Greetings EADG. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/40481#Comment_40481",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3297:502,pipeline,pipeline,502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3297,3,"['install', 'pipeline']","['installed', 'pipeline']"
Deployability,User has reported longer runtimes in GATK4 beta3 release compared to GATK4 beta 2 release. It sounds like this is not expected. Her runtimes are below. The first post in the forum thread has her original report. . | Tool | 4.beta.2 | 4.beta.3 |; | ------------------------------------- | -----------:| -----------:|; | BaseRecalibrator | 1m 3s | 3m 3s |; | ApplyBQSR (scattered) | 4m 48s | 11m 51s |; | HaplotypeCaller (scattered) | 23m 42s | 29m 7s |; | GenotypeGVCFs (scattered) | 4m 6s | 9m 28s |; | VariantRecalibrator (for SNPs) | 4m 7s | 6m 38s |; | VariantRecalibrator (for INDELs) | 2m 7s | 4m 8s |; | ApplyVQSR (for SNPs) | 37s | 2m 36s |; | ApplyVQSR (for INDELs) | 39s | 2m 35s |. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/41669#Comment_41669,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491:49,release,release,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491,2,['release'],['release']
Deployability,"User has tested GATK3.7 HaplotypeCaller and GATK4 HaplotypeCaller. GATK4 takes ~35 hours while GATK3.7 takes about 18 hours. Original report is here: https://github.com/broadinstitute/gatk/issues/3631 David, I assigned you just so you could take a look. User seems satisfied that GATK4 is faster, but I am just making sure this is expected. I asked for more details on what type of data they are using and whether Spark version is faster (assuming this is from non-Spark version). . ----; User Report; ----. @Sheila,. Hi Sheila,. I repeated the experiment with GATK4.0.0 version. The performance is much better than GATK4beta5 version. Here are the logs: . $ tail -400 NA12892.HaplotypeCaller.err; Using GATK jar /gpfs/software/genomics/GATK/4.0.0/gatk-package-4.0.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar /gpfs/software/genomics/GATK/4.0.0/gatk-package-4.0.0.0-local.jar HaplotypeCaller --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa --input /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4.0.0/NA12892/bam/NA12892.recal.bam --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz --emit-ref-confidence GVCF --read-validation-stringency LENIENT --native-pair-hmm-threads 32 --output /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4.0.0/NA12892/vcf/NA12892.raw.snps.indels.g.vcf; [January 26, 2018 1:09:58 AM AST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: **2,133.48 minutes**.; Runtime.totalMemory()=2183659520; real 128010.56; user 436969.62; sys 3030.18. Thanks and Regards,; Naga. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/45634#Comment_45634",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4361:1139,pipeline,pipeline,1139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4361,2,['pipeline'],['pipeline']
Deployability,"User is @wleeidt and they outline their case in <https://gatkforums.broadinstitute.org/gatk/discussion/comment/40530#Comment_40530>. **I can generate plots** with their data and so presumably they are missing some component for the tool to generate plots. Whatever these dependencies, the tool should not emit a `SUCCESS` for the run when plots are absent. User instead gets a `plotting_dump.rda` file. Data is at `/humgen/gsa-scr1/pub/incoming/bugReport_by_wleeidt.updated.zip`.; User's system is; ```; Mac OS X; 10.11.4 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_101-b13; ; ```; GATK Version:; ```; 4.beta.1; ```; Command; ```; gatk-launch PlotSegmentedCopyRatio -TN S4_tumor.pn.tsv -PTN S4_tumor.ptn.tsv -S S4_tumor.seg -O sandbox -SD hg19.dict -pre S4_gatk4_cnv_segment -LOG; ```. Tool could use better error messaging. I will hand this to @LeeTL1220 for appropriate assignment.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3301:466,update,updated,466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3301,1,['update'],['updated']
Deployability,"User is reporting a nearly exact 2 minute pause at tool startup. Seems very suspicious, possibly some sort of gcs operation trying and timing out?. ```; 14:33:39.416 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/gatk-package-4.beta.3-local.jar!/com/intel/gkl/native/libgkl_compression.so; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 5; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 14:35:46.844 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:35:46.844 INFO BaseRecalibrator - Deflater: IntelDeflater; 14:35:46.844 INFO BaseRecalibrator - Inflater: IntelInflater; 14:35:46.844 INFO BaseRecalibrator - GCS max retries/reopens: 20; 14:35:46.844 INFO BaseRecalibrator - Using google-cloud-java patch 317951be3c2e898e3916a4b1abf5a9c220d84df8; 14:35:46.844 INFO BaseRecalibrator - Initializing engine; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-325211756:926,patch,patch,926,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-325211756,2,['patch'],['patch']
Deployability,"User provided input files that i tested and one of the AD values did get concatenated but not all AD values greater than 100 were concatenated. . ### User post; ---; I am trying to extract info from a vcf file using the following command and encountered a problem:<br />; ```<br />; gatk VariantsToTable -R $REF -V final_SNP.vcf -F CHROM -F POS -F REF -F ALT -F QUAL -GF AD -GF GQ -GF PL -GF GT -O snpPE_final.tsv<br />; ```<br />; For SNPs with its AD value less than 100, the results are fine, but for SNPs with its AD value greater than 100, VariantsToTable just concatenates the two AD values. Here is an entry in the vcf file:<br />; ```<br />; 1 15880 . G A 3785.46 PASS AC=2;AF=0.500;AN=4;BaseQRankSum=6.325;DP=296;ExcessHet=4.7712;FS=3.153;MLEAC=2;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=12.79;ReadPosRankSum=-1.165;SOR=0.888 GT:AD:DP:GQ:PL 0/1:58,35:93:99:895,0,2296 0/1:98,105:203:99:2900,0,3782<br />; ```<br />; And here is the corresponding row in the tsv file:<br />; ```<br />; CHROM POS REF ALT QUAL S1.AD S1.GQ S1.PL S1.GT S2.AD S2.GQ S2.PL S2.GT<br />; 1 15880 G A 3785.46 58,35 99 895,0,2296 G/A 98105 99 2900,0,3782 G/A<br />; ```<br />; The AD values in the S2.AD column should be 98,105, not 98105. I use GATK4-4.1.2.0-1 and openjdk 1.8.0_152-release on Ubuntu 18.04. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/24368/seems-variantstotable-not-properly-handle-ad-greater-than-100/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6115:1265,release,release,1265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6115,1,['release'],['release']
Deployability,"User replies the missing element was the Rscript packages and once this was installed they were able to plot. So the error message needs to point to the repo's Rscript and the dependent R packages it installs. As of this writing, here is what the error message should say:. > Install R package dependencies using `Rscript install_R_packages.R` with the script from https://github.com/broadinstitute/gatk/blob/master/scripts/docker/gatkbase/install_R_packages.R. The script lists the packages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504:76,install,installed,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504,3,"['Install', 'install']","['Install', 'installed', 'installs']"
Deployability,"User report:. I am using GATK 4.1.4.0 and noticed the following : if Mutect2 is run with parameter --bam-output it makes a BAM file that contains :; @PG ID:HalpotypeBAMWriter; (note the typo); If then FilterAlignmentArtifacts is run with this file as input and BAM output is asked, it says; java.lang.IllegalArgumentException: Program record with group id HalpotypeBAMWriter already exists in SAMFileHeader!; and does not create the file. Command Used:; gatk Mutect2 --input normal.recalibrated.vcf --input tumor.recalibrated.vcf -normal mormal -tumor tumor --reference /data/Homo_sapiens.UCSC.hg38.fa --output tumor.recalibrated.mutect2/vcf --f1r2-tar-gz f1r2.tar.gz --native-pair-hmm-threads 4 --bam-output tumor.recalibrated.realigned.bam --add-output-sam-program-record false -bam-output. The log of the command that generated the error was :. Using GATK jar /data/genepattern/patches/gatk-4.1.4.0/gatk-package-4.1.4.0-local.jar. Running:. java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /data/genepattern/patches/gatk-4.1.4.0/gatk-package-4.1.4.0-local.jar FilterAlignmentArtifacts --variant tumor.recalibrated.filtered.vcf --input tumor.recalibrated.realigned.bam --reference /data/genepattern/users/.cache/uploads/cache/data.gp.vib.be/pub/genome/Homo_sapiens.UCSC.hg38.fa --bwa-mem-index-image /data/genepattern/users/.cache/uploads/cache/data.gp.vib.be/pub/bwa_index_img/Homo_sapiens.UCSC.hg38.img --output tumor.recalibrated.filtered2.vcf --bam-output tumor.recalibrated.realigned2.bam --verbosity ERROR --tmp-dir TMP --QUIET true. 14:38:44.077 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/data/genepattern/patches/gatk-4.1.4.0/gatk-package-4.1.4.0-local.jar!/com/intel/gkl/native/libgkl_utils.so. 14:38:44.103 INFO SmithWatermanAligner - AVX accelerated SmithWaterman implementation is not supported, falling back to the Java implementation. java.lang.I",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6287:881,patch,patches,881,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6287,1,['patch'],['patches']
Deployability,"User report:. I test this in 4.1.4.0 and 4.1.4.1. ```shell; gatk CountBasesSpark \; -I input_reads.bam \; -O base_count.txt; ```. When run this cmd, it is OK, and get a right output base_count.txt.; But I want compute bases located in a interval file, so:; ```; gatk CountBasesSpark \; -I input_reads.bam \; -O base_count.txt\; -L interval.file; ```. This cmd cannot run successfully, with some errors I find like this:. ```shell; ......; 9/11/28 17:44:01 INFO NewHadoopRDD: Input split: file:/disks/disk1/data_sample/19NGS14; 2/19NGS142.bam:1476395008+33554432; 19/11/28 17:44:01 INFO NewHadoopRDD: Input split: file:/disks/disk1/data_sample/19NGS14; 2/19NGS142.bam:1509949440+33554432; 19/11/28 17:44:01 INFO NewHadoopRDD: Input split: file:/disks/disk1/data_sample/19NGS14; 2/19NGS142.bam:704643072+33554432; 19/11/28 17:44:02 ERROR Executor: Exception in task 6.0 in stage 1.0 (TID 7); java.util.NoSuchElementException: next on empty iterator; at scala.collection.Iterator$$anon$2.next(Iterator.scala:39); at scala.collection.Iterator$$anon$2.next(Iterator.scala:37); at scala.collection.Iterator$$anon$13.next(Iterator.scala:469); ......; ```; The interval.file is fine because I use it for the whole GATK pipeline. ; The CountReadsSpark has the same error. Please check this. Thanks.; Chris. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/24645/countbasesspark-doesnt-work-with-l-opt/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6319:1211,pipeline,pipeline,1211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6319,1,['pipeline'],['pipeline']
Deployability,"User reporting major time differences between 3.7 HaplotypeCaller and GATK4 latest beta release. . ----; User Report; ----. Dear team,. I am using GATK 4 Beta2 for testing HaplotypeCaller for our NGS workflow. . The command which I used is: . _time -p /gpfs/software/genomics/GATK/4b.2/gatk/gatk-launch HaplotypeCaller \ ; --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa \; --input NA12892.recal.bam \ ; --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz \ ; --emitRefConfidence GVCF \; --readValidationStringency LENIENT \ ; --nativePairHmmThreads 32 \; --createOutputVariantIndex true \; --output NA12892.raw.snps.indels.g.vcf_. **This execution time for GATK 4 Beta2 is: 51 Hours, 32 min**. Alternatively, I was running the same sample (NA12892) using GATK 3.7 using the following command: . _time -p java -XX:+UseParallelGC -XX:ParallelGCThreads=32 -Xmx128g \; -jar /gpfs/software/genomics/GATK/3.7/base/GenomeAnalysisTK.jar -T HaplotypeCaller \; -nct 8 -pairHMM VECTOR_LOGLESS_CACHING \ ; -R /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa \; -I NA12892.realigned.recal.bam -\ ; -emitRefConfidence GVCF \; --variant_index_type LINEAR \; --variant_index_parameter 128000 \; --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz \; -o NA12892.raw.snps.indels.g.vcf _. **This execution time for GATK 3.7 is: 18 Hours, 12 min**. I don't know, how to use multithreads (e.g. -nct) for GATK 4 version to reduce the execution time on the single node. Because, we have 32 cores per node with 512GB memory available for benchmarking. To parallelize the GATK 4 workload, I used the Spark version also. . I used **GATK 4 Beta2 Spark job on the cluster of 32 nodes** (32 nodes x 32 cores, totaling 1024 cores). The execution time is almost same as GATK 4 Beta2 ( 50 Hours, 21 min). Please help me, how to reduce the execution time for GATK 4 Beta2 HaplotypeCaller? . Please see this below Spark logs:. + /gpfs/software/spark/spark-2.1.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3631:88,release,release,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631,1,['release'],['release']
Deployability,"User says beta 2 is much faster than release. . ----; User Report; ----; Hi @Geraldine_VdAuwera , thanks for the quick response!. We used CCLE WES FASTQs for the purpose of testing (6GB per paired end). We scattered the tool using a custom BED file with 86 intervals. 4.0.0.0 failed due to memory with 2GB per job. It completed with 4GB per job. Each job lasted approximately 1h 10 min. 4.beta.2 completed with 2GB per job and each job lasted approximately 5m. This is in gVCF mode, with the same settings as described above. All input files, settings and hardware are the same between versions. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/44970#Comment_44970",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4169:37,release,release,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4169,1,['release'],['release']
Deployability,"User would like to know if we have guidelines to provide. It would be nice to have a timeframe to tell our users or some generic guidelines in setting parameters. . ---; I find really interesting the Flagstat [chart](https://software.broadinstitute.org/gatk/resources/img_tutorials/tutorial_10060_figures/wes_increase_executors_chart.png ""chart"") and the relative [table](https://software.broadinstitute.org/gatk/resources/img_tutorials/tutorial_10060_figures/wes_increase_executors_table.png ""table""), it lets me understand that 7 is the most efficient executors-number for this tool. It's the same even for other tools? Or is there something similar (charts) for Pipelines like [BwaAndMarkDuplicatesPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.2/org_broadinstitute_hellbender_tools_spark_pipelines_BwaAndMarkDuplicatesPipelineSpark.php ""BwaAndMarkDuplicatesPipelineSpark""), [BQSRPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.3/org_broadinstitute_hellbender_tools_spark_pipelines_BQSRPipelineSpark.php ""BQSRPipelineSpark""), HaplotypeCallerSpark and [ReadsPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.5/org_broadinstitute_hellbender_tools_spark_pipelines_ReadsPipelineSpark.php ""ReadsPipelineSpark"") ?; And then, the ```--driver-memory``` is an important parameter? Which should be his value?. I'm waiting for a your kind answer,; Nicholas. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/43894#Comment_43894",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3822:665,Pipeline,Pipelines,665,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3822,1,['Pipeline'],['Pipelines']
Deployability,Using adaptive pruning in mitochondria pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5669:39,pipeline,pipeline,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5669,1,['pipeline'],['pipeline']
Deployability,"Using https://jitpack.io/#broadinstitute/gatk for building SNAPSHOTS (independent on your jfrog repository, which has a expired date for snapshots - https://github.com/broadinstitute/gatk/issues/4565) is not working any longer due to the requirement of git-lfs (e.g., https://jitpack.io/com/github/broadinstitute/gatk/4.0.4.0/build.log). It will be nice to add a `jitpack.yml` file (see https://jitpack.io/docs/BUILDING/#custom-commands) to install dependencies - this will be useful for downstream project depending on SNAPSHOTS.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4819:441,install,install,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4819,1,['install'],['install']
Deployability,"Using the latest version of ADAM (which has a Scala 2.12 version) fixes the 2bit failures. I also added a fix for the `java.nio.ByteBuffer.clear()` problem. All unit tests are passing, and the only integration test failures are the `Could not serialize lambda` problems. It should be possible to fix these by making the relevant classes implement `Serializable` (like in https://github.com/samtools/htsjdk/pull/1408).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527483090:198,integrat,integration,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527483090,2,['integrat'],['integration']
Deployability,"Usually when we see silent failures like what's happening in singularity, it's due to an out of memory error that results in the JVM process being rudely killed before it can output an error message. It's possible that's what's happening there. If you're running in a container with a limited memory pool, you have to be sure to set the java memory explicitly with -Xmx, but also be sure to leave some memory left over for the system and for native code invoked by java. For example, if you have a container with 8G of memory available I would set -Xmx7g to leave a bit of overhead available. . I think trying with a newer release of java 17 is a good idea.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8988#issuecomment-2386655253:623,release,release,623,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8988#issuecomment-2386655253,1,['release'],['release']
Deployability,"VAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:33:28 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-07 11:33:29 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-07 11:33:30 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-07 11:33:30 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-07 11:33:30 INFO Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-07 11:33:30 INFO Client:54 - Setting up container launch context for our AM; 2019-01-07 11:33:30 INFO Client:54 - Setting up the launch environment for our AM container; 2019-01-07 11:33:30 INFO Client:54 - Preparing resources for our AM container; 2019-01",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:10254,install,install,10254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['install'],['install']
Deployability,VAT Readme updates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8090:11,update,updates,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8090,1,['update'],['updates']
Deployability,"VCF output can be a reach for the release. On Wed, Dec 20, 2017 at 1:44 PM, samuelklee <notifications@github.com>; wrote:. > @asmirnov239 <https://github.com/asmirnov239> @MartonKN; > <https://github.com/martonkn> @mbabadi <https://github.com/mbabadi> Note; > the remaining TODOs. Let's be in a position where we can get all; > gCNV-related branches merged shortly after @mbabadi; > <https://github.com/mbabadi> returns on 1/4 but with a margin before; > release on 1/9. I will spend some time over break to get my review in.; >; > I will also finish up docs for ModelSegments + update PreprocessIntervals; > this week. Review should be quick.; >; > I think we can consider preliminary evaluations complete; we'll run more; > and shore up evaluation infrastructure after break.; >; > @LeeTL1220 <https://github.com/leetl1220> Following our discussion about; > evaluation tools, I added VCF output for the somatic pipeline as a TODO.; > Hopefully I can have some basic output by release, if not shortly; > thereafter.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3826#issuecomment-353148440>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk02sFz6dsTAaLaJ3gzcMLWzbFAJGks5tCVWKgaJpZM4Qcfhw>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3826#issuecomment-353150539:34,release,release,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826#issuecomment-353150539,5,"['pipeline', 'release', 'update']","['pipeline', 'release', 'update']"
Deployability,"VCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false --minimumMappingQuality 20; [August 24, 2017 7:26:43 PM EDT] Executing as shlee@WMCF9-CB5 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14; Version: 4.beta.3; 19:26:43.243 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 19:26:43.243 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:26:43.243 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:26:43.243 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:26:43.243 INFO Mutect2 - Deflater: IntelDeflater; 19:26:43.243 INFO Mutect2 - Inflater: IntelInflater; 19:26:43.243 INFO Mutect2 - GCS max retries/reopens: 20; 19:26:43.243 INFO Mutect2 - Using google-cloud-java patch 317951be3c2e898e3916a4b1abf5a9c220d84df8; 19:26:43.243 INFO Mutect2 - Initializing engine; 19:26:43.871 INFO Mutect2 - Done initializing engine; 19:26:44.130 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 19:26:44.346 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 19:26:44.624 WARN NativeLibraryLoader - Unable to find native library: native/libgkl_pairhmm_omp.dylib; 19:26:44.624 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported; 19:26:44.643 INFO NativeLibraryLoader - Loading libgkl_pairhmm.dylib from jar:file:/Applications/genomicstools/gatk/gatk-4.latest/gatk-package-4.beta.3-local.jar!/com/intel/gkl/native/libgkl_pairhmm.dylib; [WARNING] Ignoring request for 4 threads; not using OpenMP implementation; 19:26:44.664 INFO PairHMM - Using the AVX-accelerated native PairHMM implementation; 19:26:44.7",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3514:5713,patch,patch,5713,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3514,1,['patch'],['patch']
Deployability,VS 1102 add vds creation wdl to integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8554:32,integrat,integration,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8554,1,['integrat'],['integration']
Deployability,VS 1171 Add an optional Hail whl to the integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8624:40,integrat,integration,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8624,1,['integrat'],['integration']
Deployability,VS-1001 update dockers for google storage library update,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8401:8,update,update,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8401,2,['update'],['update']
Deployability,VS-1003. Update documentation to point to newly released BGE exome calling list.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8407:9,Update,Update,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8407,2,"['Update', 'release']","['Update', 'released']"
Deployability,VS-1090 - Update AoU Documentation for GvsImportGenomes to reflect new behavior,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8571:10,Update,Update,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8571,1,['Update'],['Update']
Deployability,"VS-1092 - Fix for GvsCreateFilterSet OOD; Integration test ran [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f2dc8eca-1fc2-4ab3-ac38-ab430fb1d60a).; One failure - in the Exome test on AssertCostIsTrackedAndExpected. Doesn't seem related to this code change, so am going to allow it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8573:42,Integrat,Integration,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8573,1,['Integrat'],['Integration']
Deployability,VS-1113 Update VQSR and VETS naming,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8948:8,Update,Update,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8948,1,['Update'],['Update']
Deployability,VS-1163 - Update changelog prior to doing release,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8641:10,Update,Update,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8641,2,"['Update', 'release']","['Update', 'release']"
Deployability,VS-1190 - Update GvsCreateVATfromVDS.wdl to use new Nirvana reference.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8755:10,Update,Update,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8755,1,['Update'],['Update']
Deployability,VS-1211. Update usage documentation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8704:9,Update,Update,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8704,1,['Update'],['Update']
Deployability,VS-1288 Updates to ah_var_store from echo callset.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8991:8,Update,Updates,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8991,1,['Update'],['Updates']
Deployability,VS-1291 fix integration test in ah var store,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8736:12,integrat,integration,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8736,1,['integrat'],['integration']
Deployability,VS-1310. Update gatk docker on EchoCallset,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8803:9,Update,Update,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8803,1,['Update'],['Update']
Deployability,VS-1324 Investigate integration test failures,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8787:20,integrat,integration,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8787,1,['integrat'],['integration']
Deployability,VS-1356 - Update docker from master,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8801:10,Update,Update,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8801,1,['Update'],['Update']
Deployability,VS-1397 Update Tests - ah_var_store edition,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8846:8,Update,Update,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8846,1,['Update'],['Update']
Deployability,VS-1397 update tests echo callset version,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8848:8,update,update,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8848,1,['update'],['update']
Deployability,VS-1433.; This PR adds the tool vcf-validator to our variants docker and uses it in our integration test.; It validates that the VCFs have no errors in the `AD` field (which were previously reported by AoU friends).; It also modifies the Beta integration test to only run on WGS samples (previously ran on all samples). Passing Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/0c9fb830-7831-4bee-a82c-d0146b250e59).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8903:88,integrat,integration,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8903,3,"['Integrat', 'integrat']","['Integration', 'integration']"
Deployability,VS-1476. Removing All usage of VQSR from VDS creation. Only will accept VETS annotated data now. Passing Integration Test (small chrs) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/fa745d55-38d6-4899-a75d-474081eac013); Passing Integration Test (all chrs) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/bb04d1a6-7cf6-45cb-b17f-5e934ab42631),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9015:105,Integrat,Integration,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9015,2,['Integrat'],['Integration']
Deployability,VS-1483 Update AoU documentation to include details for VAT delivery,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8967:8,Update,Update,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8967,1,['Update'],['Update']
Deployability,VS-598 - Minor update to AoU Documentation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7994:15,update,update,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7994,1,['update'],['update']
Deployability,VS-695. Updates to run Precision and Sensitivity on VQSR Lite,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8230:8,Update,Updates,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8230,1,['Update'],['Updates']
Deployability,VS-776. Update to latest version of VQSR Lite.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8269:8,Update,Update,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8269,1,['Update'],['Update']
Deployability,VS-857.; Change default behavior of GvsBulkIngestGenomes.wdl BACK to not dropping GQ0 ref blocks.; Updated AoU documentation to say we need to do it there (as an input). Passing Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/c4f921d8-52e7-4a44-9e0b-9f876eac71f3),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8550:99,Update,Updated,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8550,2,"['Integrat', 'Update']","['Integration', 'Updated']"
Deployability,VS-914 Add support for vqsr lite to integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8324:36,integrat,integration,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8324,1,['integrat'],['integration']
Deployability,VS-917. Update override jar in GvsJointCalling wdl to fix support issue.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8312:8,Update,Update,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8312,1,['Update'],['Update']
Deployability,VS-924 - Have pipeline automatically differentiate between VQSR Lite and Classic,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8336:14,pipeline,pipeline,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8336,1,['pipeline'],['pipeline']
Deployability,VS-931 Exome integration test on bulk ingest staging,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8448:13,integrat,integration,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8448,1,['integrat'],['integration']
Deployability,VS-931 exome integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8433:13,integrat,integration,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8433,1,['integrat'],['integration']
Deployability,VS_492 - Beta User Jar release,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7934:23,release,release,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7934,1,['release'],['release']
Deployability,"ValidateVariants give an `IllegalArgumentException` if a reference isn't provided. . It should be a `UserException`. I don't know but I think there may be modes that don't require the reference, so it may need to give a smart error message. ```; gatk-launch ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.119 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/louisb/Workspace/gatk/build/install/gatk/lib/gkl-0.4.1.jar!/com/intel/gkl/native/libgkl_compression.dylib; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf --doNotValidateFilteredRecords false --warnOnErrors false --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Def",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:453,install,install,453,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,3,['install'],['install']
Deployability,VariantFiltration update for new htsjdk,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/672:18,update,update,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/672,1,['update'],['update']
Deployability,"VariantQC is a tool we made that is somewhat analogous to FastQC. Given an input VCF, it runs VariantEval to generate various summary tables of data, and then makes an HTML report (borrowing a lot from the tool MultiQC) summarizing that VCF. . I wrote this originally by forking GATK3 and wrote a new walker that internally called and run VariantEval. That was never the final plan. I dont know what this will need to look like in GATK4 yet. I'm fine with the expectation that GATK4 VariantEval will evolve and we'd need to update our code wrapping it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440806347:524,update,update,524,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440806347,1,['update'],['update']
Deployability,VariantRecalibrator R-script fails if `scales` v1.3.0 is installed,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664:57,install,installed,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664,1,['install'],['installed']
Deployability,VariantRecalibrator and ApplyVQSR integration tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2164:34,integrat,integration,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2164,1,['integrat'],['integration']
Deployability,VariantRecalibrator and ApplyVQSR port part 1 (no integration tests).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2094:50,integrat,integration,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2094,1,['integrat'],['integration']
Deployability,"VariantWalker was the only remaining Walker type that didn't support full traversal by; intervals using -L/-XL due to lack of underlying FeatureDataSource support for traversal; by intervals (it only supported individual queries by one interval at a time). This; commit updates FeatureDataSource to allow traversal across all Features overlapping a set; of intervals, and enables -L support in VariantWalker. -Added support for full traversal by a set of intervals to FeatureDataSource; (+ tests). -Enabled -L/-XL support in VariantWalker. Resolves #232",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/326:270,update,updates,270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/326,1,['update'],['updates']
Deployability,"Variants with the `-no-overlaps` option, a USER ERROR is outputted after the entire tool finishes running, as shown below:. ```; ***********************************************************************. A USER ERROR has occurred: This GVCF contained overlapping reference blocks. The first overlapping interval is [genomic coordinates here]. ***********************************************************************; ```. This error should be generally helpful, but it appears that the interval that is reported in the error message is the _last_ overlapping interval, not the _first_. I'm not super familiar with java, but I'm guessing that `firstOverlap` might be continuously replaced by `refInterval` if there are multiple overlaps, which is inconsistent with expected behavior. . Potentially relevant lines of code: ; - `-no-overlaps` argument description ([lines 192-201](; https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L192-L201)); - `firstOverlap = refInterval` ([line 275](https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L275)). #### Steps to reproduce. Running ValidateVariants with the `-no-overlaps` flag on a .g.vcf with overlapping intervals will cause this error. More specifically, we're running this within WARP's Exome Germline Single Sample v.3.1.7 WDL release. Our command is as follows:. ```; gatk --java-options ""-Xms6000m -Xmx6500m"" \; ValidateVariants \; -V /path/to/our/.g.vcf.gz \; -R /path/to/our/.fa \; -L /path/to/our/.interval_list \; -gvcf \; --validation-type-to-exclude ALLELES \; --dbsnp /path/to/our/.vcf.gz \; --no-overlaps; ```. #### Expected behavior. The error message should report the _first_ overlapping interval. #### Actual behavior; The error message is reporting the _last_ overlapping interval.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103:1897,release,release,1897,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103,1,['release'],['release']
Deployability,"VariantsSpark - Done initializing engine; 19/02/18 16:58:10 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19/02/18 16:58:10 INFO org.spark_project.jetty.util.log: Logging initialized @8431ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: Started @8536ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 19/02/18 16:58:11 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 19/02/18 16:58:12 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:8032; 19/02/18 16:58:13 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:10200; 19/02/18 16:58:15 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1550508751046_0004; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; 19/02/18 16:58:25 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1; 19/02/18 16:58",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:4890,configurat,configuration,4890,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['configurat'],['configuration']
Deployability,Vat pipeline--Even more juice,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8794:4,pipeline,pipeline--Even,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8794,1,['pipeline'],['pipeline--Even']
Deployability,"Version 3.0.0 of the base image is still on 18.04 (albeit an updated version of 18.04). Although 18.04 is still supported, we should try to move to the latest LTS release, 22.04",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8243:61,update,updated,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8243,2,"['release', 'update']","['release', 'updated']"
Deployability,"Version: 2.23.0; 12:57:16.776 INFO AnalyzeCovariates - Picard Version: 2.22.8; 12:57:16.776 INFO AnalyzeCovariates - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:57:16.776 INFO AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:57:16.776 INFO AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:57:16.776 INFO AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:57:16.776 INFO AnalyzeCovariates - Deflater: IntelDeflater; 12:57:16.776 INFO AnalyzeCovariates - Inflater: IntelInflater; 12:57:16.776 INFO AnalyzeCovariates - GCS max retries/reopens: 20; 12:57:16.776 INFO AnalyzeCovariates - Requester pays: disabled; 12:57:16.776 INFO AnalyzeCovariates - Initializing engine; 12:57:16.776 INFO AnalyzeCovariates - Done initializing engine; 12:57:17.333 INFO AnalyzeCovariates - Generating csv file '/tmp/AnalyzeCovariates17353441228865531235.csv'; 12:57:17.414 INFO AnalyzeCovariates - Generating plots file '/home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf'; 12:57:17.829 INFO AnalyzeCovariates - Shutting down engine; [December 17, 2020 at 12:57:17 PM TRT] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=633339904; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.10272183847736955081';source('/tmp/BQSR.16251220439562120273.R'); /tmp/AnalyzeCovariates17353441228865531235.csv /home/detagen/Desktop/pipeline/playground/BACKUP/FMF-248_Backup/before.recal.FMF-248.table /home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Stdout: ; Stderr: Error in library(gplots) : there is no package called ‘gplots’; Calls: source -> withVisible -> eval -> eval -> library; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7006:3357,pipeline,pipeline,3357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006,1,['pipeline'],['pipeline']
Deployability,"Versions of Kryo less than 3.0 can't serialize Java 8 lambda functions, forcing us in some cases to replace lambdas with full function class objects even when a lambda would be simpler and easier to read. See for example https://github.com/broadinstitute/gatk/pull/1489 . This ticket is to look through the codebase after an upgrade to Kryo 3.0+ takes place and to replace unnecessary function classes with lambdas where they'd be more appropriate.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1510:325,upgrade,upgrade,325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1510,1,['upgrade'],['upgrade']
Deployability,"Very minor comments, otherwise looks good. Thanks for the patch!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356136768:58,patch,patch,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356136768,1,['patch'],['patch']
Deployability,Very simple implementation of #2297 using a custom `GATKConf` class to allow both promatically (`GATKConfBuilder`) and by commons-configuration API (constructor). Only includes:. * Packages/Classes to include in the CLP on startup.; * Packages to look for codecs on startup.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2322:130,configurat,configuration,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2322,1,['configurat'],['configuration']
Deployability,Very simple patch to extract arguments that may be useful for other toolkits into `StandardArgumentDefinitions` and some in-class changes.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2283:12,patch,patch,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2283,1,['patch'],['patch']
Deployability,Vs 299 spike speed up integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8706:22,integrat,integration,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8706,1,['integrat'],['integration']
Deployability,"VsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (ø)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `77.6% <0%> (-9.6%)` | `28% <0%> (-8%)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2467?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2467?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2467?src=pr&el=footer). Last update [e1e71d7...71c03a3](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2467#issuecomment-287565894:5080,update,update,5080,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2467#issuecomment-287565894,2,['update'],['update']
Deployability,W50V2l0aFBoYXNlUG9zdGVyaW9yc0NvbGxlY3Rpb24uamF2YQ==) | `64.286% <0%> (-3.571%)` | `5% <0%> (-1%)` | |; | [...ols/exome/alleliccount/AllelicCountCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3033?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9hbGxlbGljY291bnQvQWxsZWxpY0NvdW50Q29sbGVjdGlvbi5qYXZh) | `72.727% <0%> (-3.03%)` | `9% <0%> (-1%)` | |; | [.../broadinstitute/hellbender/utils/tsv/DataLine.java](https://codecov.io/gh/broadinstitute/gatk/pull/3033?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvRGF0YUxpbmUuamF2YQ==) | `90.598% <0%> (-0.855%)` | `62% <0%> (-1%)` | |; | [...nstitute/hellbender/utils/help/GATKHelpDoclet.java](https://codecov.io/gh/broadinstitute/gatk/pull/3033?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oZWxwL0dBVEtIZWxwRG9jbGV0LmphdmE=) | `100% <0%> (ø)` | `9% <0%> (+3%)` | :arrow_up: |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3033?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `100% <0%> (ø)` | `15% <0%> (+7%)` | :arrow_up: |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3033?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `92.908% <0%> (+3.324%)` | `58% <0%> (+29%)` | :arrow_up: |; | [.../hellbender/tools/genomicsdb/GenomicsDBImport.java](https://codecov.io/gh/broadinstitute/gatk/pull/3033?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWljc2RiL0dlbm9taWNzREJJbXBvcnQuamF2YQ==) | `77.5% <0%> (+4.461%)` | `72% <0%> (+24%)` | :arrow_up: |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/3033?src=pr&el=tree,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3033#issuecomment-306379926:2425,pipeline,pipelines,2425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3033#issuecomment-306379926,1,['pipeline'],['pipelines']
Deployability,"W9uVGVzdC5qYXZh) | `1.66% <0%> (-98.34%)` | `1% <0%> (-5%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.75% <0%> (-98.25%)` | `1% <0%> (-6%)` | |; | [...bender/tools/spark/PileupSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QaWxldXBTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `2.04% <0%> (-97.96%)` | `2% <0%> (-13%)` | |; | [...tute/hellbender/tools/FlagStatIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GbGFnU3RhdEludGVncmF0aW9uVGVzdC5qYXZh) | `2.08% <0%> (-97.92%)` | `1% <0%> (-5%)` | |; | [...rs/variantutils/SelectVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `0.25% <0%> (-97.75%)` | `1% <0%> (-70%)` | |; | ... and [154 more](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=footer). Last update [1d6f5b3...d98f9dc](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5760#issuecomment-469855399:4849,update,update,4849,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5760#issuecomment-469855399,2,['update'],['update']
Deployability,WDL for running PathSeq pipeline with a readme and example json input.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4143:24,pipeline,pipeline,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4143,1,['pipeline'],['pipeline']
Deployability,"WIth the 4.2.2.0 ReblockGVCF it is running fine. This was without rerunning the HaplotypeCaller to create the gvcf just the reblock. . ```; Using GATK jar /share/pkg.7/gatk/4.2.2.0/install/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.2.2.0/install/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar ReblockGVCF -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -V gvcf.gather/GARDWGSN00001.autosome.g.vcf.gz -drop-low-quals -rgq-threshold 20 -do-qual-approx -O g1.test.reblock.g.vcf.gz; 00:54:40.318 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.2.0/install/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 25, 2021 12:54:40 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 00:54:40.501 INFO ReblockGVCF - ------------------------------------------------------------; 00:54:40.501 INFO ReblockGVCF - The Genome Analysis Toolkit (GATK) v4.2.2.0; 00:54:40.501 INFO ReblockGVCF - For support and documentation go to https://software.broadinstitute.org/gatk/; 00:54:40.501 INFO ReblockGVCF - Executing as farrell@scc-hadoop.bu.edu on Linux v3.10.0-1160.36.2.el7.x86_64 amd64; 00:54:40.502 INFO ReblockGVCF - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 00:54:40.502 INFO ReblockGVCF - Start Date/Time: August 25, 2021 12:54:40 AM EDT; 00:54:40.502 INFO ReblockGVCF - ------------------------------------------------------------; 00:54:40.502 INFO ReblockGVCF - ------------------------------------------------------------; 00:54:40.503 INFO ReblockGVCF - HTSJDK Version: 2.24.1; 00:54:40.503 INFO ReblockGVCF - Picard",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7334#issuecomment-905183643:181,install,install,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7334#issuecomment-905183643,3,['install'],['install']
Deployability,WRONG! FYI - the `RUN_VCF_SITE_LEVEL_FILTERING_WDL` test is failing because it is trying to build the gatk jar off of the current branch and we have not merged the updated (java) code into our branch. It was failing because I hadn't ported the test data. Now it passes!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8269#issuecomment-1516429270:164,update,updated,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8269#issuecomment-1516429270,1,['update'],['updated']
Deployability,"WRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9FdmlkZW5jZVRhcmdldExpbmsuamF2YQ==) | `70.51% <0%> (-4.12%)` | `18% <0%> (+2%)` | |; | [...ools/copynumber/CreateReadCountPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NyZWF0ZVJlYWRDb3VudFBhbmVsT2ZOb3JtYWxzLmphdmE=) | `86.07% <0%> (-3.93%)` | `11% <0%> (+2%)` | |; | [...er/tools/copynumber/formats/records/CopyRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9Db3B5UmF0aW8uamF2YQ==) | `74.35% <0%> (-1.65%)` | `17% <0%> (+8%)` | |; | [...ellbender/tools/walkers/annotator/QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9RdWFsQnlEZXB0aC5qYXZh) | `95.74% <0%> (-1.56%)` | `20% <0%> (+3%)` | |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `70.62% <0%> (-1.32%)` | `71% <0%> (+26%)` | |; | ... and [170 more](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=footer). Last update [9eb1704...ff52e6b](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4498#issuecomment-370663327:4649,update,update,4649,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4498#issuecomment-370663327,2,['update'],['update']
Deployability,"WRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <ø> (-62.264%)` | `8% <ø> (+8%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <ø> (-60.87%)` | `2% <ø> (+2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `44.444% <ø> (-29.861%)` | `28% <ø> (+28%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <ø> (-23.729%)` | `0% <ø> (ø)` | |; | ... and [15 more](https://codecov.io/gh/broadinstitute/gatk/pull/2385/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2385?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2385?src=pr&el=footer). Last update [14f73e2...b1802b2](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2385#issuecomment-279409892:5133,update,update,5133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2385#issuecomment-279409892,2,['update'],['update']
Deployability,"Wait, actually, let me check some issues discussed in https://github.com/broadinstitute/gatk/pull/5781 and https://github.com/broadinstitute/gatk/issues/5764. Is the pip-installed version of numpy compiled against MKL? I didn't realize the change in #5781 was reverted in https://github.com/broadinstitute/gatk/pull/6413 while I was on leave.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6494#issuecomment-599691717:170,install,installed,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6494#issuecomment-599691717,1,['install'],['installed']
Deployability,We also need to identify exactly what the issue is so we can report it properly. . Most likely it's that the wrong version of gencode somehow got into the hg38 area for this release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7265#issuecomment-847977040:174,release,release,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7265#issuecomment-847977040,1,['release'],['release']
Deployability,"We are currently using numpy 1.13.1, but that version is old and has incompatibilities with gcc on some platforms (see [this forum post](https://gatk.broadinstitute.org/hc/en-us/community/posts/360056743551-Problem-Installing-GATK-python-environment-SOLUTION-POSTED-?page=1#community_comment_360009536172)).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6480:215,Install,Installing-GATK-python-environment-SOLUTION-POSTED,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6480,1,['Install'],['Installing-GATK-python-environment-SOLUTION-POSTED']
Deployability,We are going to cut a release now to push out the fix for this issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4875#issuecomment-396309460:22,release,release,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4875#issuecomment-396309460,1,['release'],['release']
Deployability,We are trying to replace travis CI and we must test that the push tests work as expected. This will eventually require we rebase everything. . ; We should get rid of/update our old travis tickets,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7754:166,update,update,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7754,1,['update'],['update']
Deployability,We are two major versions behind the latest gradle release. A later version is needed for upgrading Spark (#5990) and using BigQuery (#5928).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6007:51,release,release,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6007,1,['release'],['release']
Deployability,"We are unable to run joint genotyping on the cloud when it includes a sample with a space in the name; it fails when calling GATK's GenomicsDBImport functionality (see error log below). . This practice (samples with spaces in the name) is unfortunately not uncommon, so we've had to modify our various workflows one by one to add support for this case. Please update GenomicsDBImport to handle samples with a space in the name. . Example error log: ; gsutil cat gs://broad-jg-dev-cromwell-execution/JointGenotyping/6918095f-ca06-4883-bcb5-f5c2e343bb6d/call-ImportGVCFs/shard-0/ImportGVCFs-0-stderr.log. Using GATK jar /usr/gitc/gatk-package-4.beta.6-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Xmx4g -Xms4g -jar /usr/gitc/gatk-package-4.beta.6-local.jar GenomicsDBImport --genomicsDBWorkspace genomicsdb --batchSize 50 -L chr1:1-391754 --sampleNameMap /cromwell_root/broad-jg-dev-storage/freimer_dutch_fin_wgs_v1/v1/sample_map --readerThreads 5 -ip 500; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.H9t5pC; [December 14, 2017 7:41:30 PM UTC] GenomicsDBImport --genomicsDBWorkspace genomicsdb --batchSize 50 --sampleNameMap /cromwell_root/broad-jg-dev-storage/freimer_dutch_fin_wgs_v1/v1/sample_map --readerThreads 5 --intervals chr1:1-391754 --interval_padding 500 --genomicsDBSegmentSize 1048576 --genomicsDBVCFBufferSize 16384 --overwriteExistingGenomicsDBWorkspace false --consolidate false --validateSampleNameMap false --interval_set_rule UNION --interval_exclusion_padding 0 --interval_merging_rule ALL --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 0 -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3979:360,update,update,360,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3979,1,['update'],['update']
Deployability,"We built a debug build of `google-cloud-java` and hooked it up to GATK, and I think we've identified the problem. The retry settings were not being correctly propagated to `google-cloud-java` for this particular tool (`GenomicsDBImport`), and so it was running with the default settings of `maxChannelReopens == 0 and maxRetries == 3`. This also explains why we resolved the issue with 503's (which are handled by the retries), but not the SSL errors (which are handled by the reopens). We are currently working on a patch to fix this. We could guard ourselves against this sort of issue in the future by implementing https://github.com/broadinstitute/gatk/issues/3120 (the ability to set retry settings globally for the `google-cloud-java` library, rather than per-Path).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-309098253:517,patch,patch,517,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-309098253,1,['patch'],['patch']
Deployability,We can re-open if the error persists in the current release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5965#issuecomment-580428029:52,release,release,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5965#issuecomment-580428029,1,['release'],['release']
Deployability,We can re-open if the error remains in the current release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6248#issuecomment-580426729:51,release,release,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6248#issuecomment-580426729,1,['release'],['release']
Deployability,"We currently install v4.3.3, which is quite a few releases behind the current version v4.6.8. The preferred method for activating/deactivating has changed, and the method we currently suggest/use (`source activate`) is [deprecated](https://github.com/conda/conda/releases/tag/4.4.0) and has been replaced with conda commands. The readme/online doc should be modified to reflect these changes as well.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5851:13,install,install,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5851,3,"['install', 'release']","['install', 'releases']"
Deployability,"We determined that dbSNP should have the `all` data. Individual data sources will be versioned as well as the Broad-provided packages. Broad-packaged data sources will be semantic versioned (see https://semver.org/) with the `patch` version corresponding to the date of release and any `decorators` on the data. A decorator is an arbitrary string that adds information to the version. For instance, two data source releases may contain several overlapping data sources and some use-case specific ones (such as in the germline and somatic uses of the tool). For these two data source releases, they will have the same version number, but with different decorators. . Concretely: ; `funcotator_dataSources.v1.4.20180829g.tar.gz` - germline data sources; `funcotator_dataSources.v1.4.20180829s.tar.gz` - somatic data sources",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4582#issuecomment-417439030:226,patch,patch,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4582#issuecomment-417439030,4,"['patch', 'release']","['patch', 'release', 'releases']"
Deployability,We do not have a supported installation medium through mamba. That could be the reason why repositories do not return the needed packages. ; We recommend installing miniconda and using miniconda to create the environment. ; If these options don't work for you we also have our docker image with conda environment installed and you may use it if your compute environment permits.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8838#issuecomment-2118624025:27,install,installation,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8838#issuecomment-2118624025,3,['install'],"['installation', 'installed', 'installing']"
Deployability,"We don't want users to have to prepend ""file://"" to their input/output files. Let's create a class that wraps URI, and prepends ""file://"" by default when there's no explicit prefix. It should have a constructor that takes a single String to integrate with our argument parsing system.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/477:241,integrat,integrate,241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/477,1,['integrat'],['integrate']
Deployability,We drop regions containing all Ns in the pipelines before they get to GC-bias correction.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2882#issuecomment-356696877:41,pipeline,pipelines,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2882#issuecomment-356696877,1,['pipeline'],['pipelines']
Deployability,We forgot to update this when travis migrated. We're seeing old output.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5617:13,update,update,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5617,1,['update'],['update']
Deployability,"We found an issue with the way GKL was freeing an internal data structure. The issue was exposed by the `IntelInflaterIntegrationTest`, which uses the Inflater API in a different way than HTSJDK and GATK. We've fixed that issue and the GATK integration tests pass. We're releasing GKL 0.4.1 now and will update this PR when 0.4.1 is available in Maven Central.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282325096:241,integrat,integration,241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282325096,2,"['integrat', 'update']","['integration', 'update']"
Deployability,"We found some links that needed to be fixed in the Funcotator, ASEReadCounter, and VariantRecalibrator tool docs. We updated them or removed the links as needed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7270:117,update,updated,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7270,1,['update'],['updated']
Deployability,"We found that many GATK4 commands accept an option to let them output ""sharded"" files. But we didn't find how those commands accept ""sharded"" data that generated from the last step. For example,. ```; gatk ReadsPipelineSpark \; -I hdfs://ip-/user/tianj/${sample}_sort.bam \; -R hdfs://ip-/genome/ref/human_g1k_v37.2bit \; -O hdfs://ip-/user/tianj/${sample}_ReadsPipelineSpark.bam \; --knownSites hdfs://ip-/genome/ref/Mills_and_1000G_gold_standard.indels.b37.vcf \; --shardedOutput true \; -- \; --sparkRunner SPARK \; --sparkMaster spark://ip- \; --num-executors 2 \; --executor-cores 16 \; --executor-memory 60g \; --driver-memory 60g \; --conf ""spark.eventLog.dir=hdfs://ip-/user/tianj/tmp"" \; --conf ""spark.local.dir=hdfs://ip-/user/tianj/tmp"". HaplotypeCallerSpark \; -I hdfs://ip-/user/tianj/${sample}_ReadsPipelineSpark.bam \; -O hdfs://ip-/user/tianj/$sample.vcf \; -R hdfs://ip-/genome/ref/human_g1k_v37.2bit \; -- \; --sparkRunner SPARK \; --sparkMaster spark://ip-172-31-2-45:7077 \; --num-executors 2 \; --executor-cores 16 \; --executor-memory 60g \; --driver-memory 60g \; --conf ""spark.eventLog.dir=hdfs://ip-/user/tianj/tmp"" \; --conf ""spark.local.dir=hdfs://ip-/user/tianj/tmp""; ```; This pipeline makes ${sample}_ReadsPipelineSpark.bam a directory and it doesn't work. I didn't find any option to specify that the input file is ""sharded"" or not.**How should we use the ""shardedoutput"" option?**. And also, we noticed that for SV calling, there is a whole pipeline command, but for SNP&Indels calling, we only found partial pipeline such as ReadPipelineSpark. **Is there a whole SNP&Indels calling pipeline script we can use?** Though it still seems to cost some unnecessary time keeps writing and reading files.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3141:1206,pipeline,pipeline,1206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3141,4,['pipeline'],['pipeline']
Deployability,"We got an email complaining that we were the only users in the world still using the beta API. This updates to the most recent version, they changed the api from `List<String> -> List<Object>`, but the documentation still says it has to be a `String`, so I've just added some explicit casts. . Fix for #2009",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2011:100,update,updates,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2011,1,['update'],['updates']
Deployability,"We had a little bit of trouble with AllelicCNV at the Finland workshop last week. Apologies that this isn't the most complete bug report, but the hands-on portion of the workshop moved pretty fast. Soo Hee took a picture of the error with her phone:; ![image](https://user-images.githubusercontent.com/6578548/30697898-6dff7e24-9eae-11e7-8ec3-d876483fec1a.png); The rest of the relevant line is ""undefined symbol: cblas_daxpy"". The version was the GATK4 beta 4 release and the command was:; ```; gatk-launch AllelicCNV \; --tumorHets tumor_hets.tsv \; --tangentNormalized tumor_C.tn.tsv \; --segments tumor_C.seg \; --outputPrefix acnv \; --intervalThresholdCopyRatio 5.0; ```; The inputs are in the AllelicCNV workshop bundle in Google Drive: https://drive.google.com/drive/folders/0BzI1CyccGsZiU1dkcndQMkRmTTQ. I think the host institution was running Red Hat, but it might have been Ubuntu. Like I said, sorry this is a pretty sad bug report. I haven't tried to reproduce the error since it seems platform-specific, but maybe some weirdo who doesn't use a Mac (@LeeTL1220) would give it a shot?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3599:461,release,release,461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3599,1,['release'],['release']
Deployability,"We had another edge-case bug in our clipping code: when calling ReadClipper.revertSoftClippedBases(); on a read at the start of a contig (position == 1), we could end up with an empty read if the cigar; was something like ""41S59H"", since the reverted soft-clipped bases would just get hard-clipped away.; The method did not correctly handle this case, and blew up with an exception. Added a unit test for ReadClipper that fails before the fix and passes after it, as well as an; integration test for HaplotypeCaller that also fails before the fix and passes after it. Resolves #3845",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4203:479,integrat,integration,479,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4203,1,['integrat'],['integration']
Deployability,We have a lot of links to the old forum in our source code and in code documentation. All the ones I've tested are redirecting to the new locations correctly but it would be good to test them and find any dead links. . There are constants in HelpConstants that should be updated as well.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6382:271,update,updated,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6382,1,['update'],['updated']
Deployability,"We have a user keen on seeing this done, either in the official release or in a nightly, whichever is sooner. Please can whoever is working on this either post to tell the user at https://gatkforums.broadinstitute.org/gatk/discussion/11107/gatk4beta6-annotation-incompatibility-between-haplotypecaller-and-genomicsdbimport#latest or ping me please? Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3707#issuecomment-355058384:64,release,release,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3707#issuecomment-355058384,1,['release'],['release']
Deployability,We have already updated those GATK3 tests to point to a newer version output.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7634:16,update,updated,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7634,1,['update'],['updated']
Deployability,"We have another researcher asking about this feature at <https://gatkforums.broadinstitute.org/gatk/discussion/14299/gatk4-variantannotator-de-novo-ped-workshop-1809#latest>. If annotating de novos will not be a feature, then please can we remove the option and/or update the error message to be more informative? Would appreciate it. Thank you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4987#issuecomment-439235429:265,update,update,265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4987#issuecomment-439235429,1,['update'],['update']
Deployability,We have asked the green team to run their pipeline tests on this branch to at least limit the risk of more full sample failures. It will probably be a few more days before we have those results. @gbggrant,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-614126868:42,pipeline,pipeline,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-614126868,1,['pipeline'],['pipeline']
Deployability,We have received a request to incorporate some of the picard tool improvements in newer versions of picard. This is a bump in preparation of an eventual GATK release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7255:158,release,release,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7255,1,['release'],['release']
Deployability,"We have two methods that compare variants for our tests:. `VariantContextTestUtils::assertEqualVariants` is doing string conversions to compare variants. This is not so good. `VariantContextTestUtils::assertVariantContextsAreEqual` may not do a complete comparison. Either way, these should be combined into a single method and updated to be a complete comparison.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5572:328,update,updated,328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5572,1,['update'],['updated']
Deployability,We have updated to a newer version of compression engine in GKL. Could you test with the latest GATK/GKL? and report if the problem still exists.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-340501007:8,update,updated,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-340501007,1,['update'],['updated']
Deployability,"We haven't resolved the issue with our project configuration yet, so we need to publish this ourselves.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4008:47,configurat,configuration,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4008,1,['configurat'],['configuration']
Deployability,We hope to have this fixed by the 4.0 release on tuesday.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3466#issuecomment-355649619:38,release,release,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3466#issuecomment-355649619,1,['release'],['release']
Deployability,"We identified the piece of code that was causing the compilation error; it was removed in #4215, which was just merged. Can you update your master and try again?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4248#issuecomment-360244997:128,update,update,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4248#issuecomment-360244997,1,['update'],['update']
Deployability,"We keep our shards as tarred genomicsDB workspaces. Cromwell helps manage all the references, though. You can see our exome workflow here: https://github.com/gatk-workflows/gatk4-germline-snps-indels/blob/master/JointGenotyping.wdl. We don't have a pipeline with incremental addition of samples, so we don't have a ready made solution there. Subjectively the json idea sounds pretty good, although just keeping a list of paths would also work since you expect the same number of scatters, provided they're sorted, which isn't too hard.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6557#issuecomment-617320822:249,pipeline,pipeline,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6557#issuecomment-617320822,1,['pipeline'],['pipeline']
Deployability,"We need a mechanism to guarantee that all spark tools are written in a way that allows them to be composed into larger pipelines. Currently, we rely on the tool author to extract the core of their tool into a separate method or class that can be called externally, but there is nothing forcing tool authors to do this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/960:119,pipeline,pipelines,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/960,1,['pipeline'],['pipelines']
Deployability,"We need a way to install GATK Python modules onto the docker image, from repo source, in a way that doesn't assume a repo clone is present on the docker image (there currently is one, but we want to remove it to recover space), and that also doesn't make the conda environment dependent on a repo clone. This PR adds a build task that creates a zip archive of the GATK Python source; propagates that to the docker image, and then pip installs the contents of the archive into the conda environment on the docker. Since we don't have an actual python module in the repo at the moment, there is a second, temporary, commit that contains a dummy python module used only to trigger and test that the installation works.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3964:17,install,install,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3964,3,['install'],"['install', 'installation', 'installs']"
Deployability,We need to produce a script that will make it easy to evaluate what changes to the HalpotypeCallerSpark will result in the biggest performance impact. To that end we want to write wdls and associated scripts that will make it easier for us to evaluate what each incremental change to the tool will change about accuracy and runtime for the machine configurations we care about. We should probably also hammer down what the machine types we consider important are as well.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5396:348,configurat,configurations,348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5396,1,['configurat'],['configurations']
Deployability,We need to wait for google cloud dependency updates in order for the fix to be incorporated into gatk.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-442117552:44,update,updates,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-442117552,1,['update'],['updates']
Deployability,"We noticed a strong drop in precision for SNVs (~10% for tumor-normal mode, ~20% in tumor-only mode) between releases 4.1.7.0 and 4.2.6.0.; With more testing using the HCC1395 somatic benchmark (https://pubmed.ncbi.nlm.nih.gov/34504347/) and sequencing data provided by the Somatic Mutation Working Group (Fudan university WES tumor-normal data set, 2 x 100x coverage), the drop in performance can be traced to changes between 4.1.8.1 and 4.1.9.0. Here are the performance metrics for selected gatk releases: . ![FD_TN_4170_filter_FD_TN_4181_filter_FD_TN_4190_filter_FD_TN_4200_filter_FD_TN_4260_filter](https://user-images.githubusercontent.com/15612230/176261673-e13b9ada-0462-4cd4-b645-67459895363b.png). The calling was done with essentially default parameters:; `; tools/gatk-${version}/gatk Mutect2 --normal-sample WES_FD_N --output $outvcf --intervals $wesbed --interval-padding 0 --input $inbam_t --input $inbam_n --reference $ref ; `. ` ; tools/gatk-${version}/gatk FilterMutectCalls --output ${outvcf%.vcf}_filtered.vcf --variant $outvcf --intervals $wesbed --reference $ref --stats ${outvcf}.stats --threshold-strategy OPTIMAL_F_SCORE --f-score-beta 1.0 ; `. som.py was used for calculating performance metrics. Curiously, we do not observe a such a substantial drop in precision in WGS data, neither in tumor-only nor in tumor-normal mode.; In the foillowing, our ""v04"" corresponds to gatk 4.1.7.0 and out ""v05"" corresponds to gatk 4.2.6.0:. Tumor-normal:. ![WGS_FD_tumor-normal_reference_workflow_v04_WGS_FD_tumor-normal_reference_workflow_v05](https://user-images.githubusercontent.com/15612230/176270981-2e56bb2e-c3a6-4715-bcce-33cbe0d0cf67.png). Tumor-only:. ![WGS_FD_tumor_reference_workflow_v04_WGS_FD_tumor_reference_workflow_v05](https://user-images.githubusercontent.com/15612230/176271103-6863a6f7-26f6-4841-b066-d963221ff735.png). In my opinion, the small gains in recall between 4.1.8.1 and 4.1.9.0. do not justify the drop in precision. This and the fact that WES data is affe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921:109,release,releases,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921,2,['release'],['releases']
Deployability,We now want to fully update the AoU documentation so that a VDS can be created (no VCFs!),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8169:21,update,update,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8169,1,['update'],['update']
Deployability,"We recently created the ""variantcalling"" task in the travis CI test suite to reduce the runtime of our integration tests. Once we refactored the docker image we found that the the integration tests are still taking an uncomfortable amount of time to run (upwards of 57 minutes). Short of resolving the issue more permanently (#4989) we can temporarily fix the solution by just splitting off more of the integration tests to other jobs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4990:103,integrat,integration,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4990,3,['integrat'],['integration']
Deployability,"We recently determined that the FTZ setting gets cleared during integration tests for unknown reasons. We temporarily fixed this by explicitly turning FTZ on in every call to `jniComputeLikelihoods()` (https://github.com/broadinstitute/gatk/pull/1764), but this might be inefficient, and even if it isn't it would be good to understand what's going on. Without the fix in https://github.com/broadinstitute/gatk/pull/1764, if you run `HaplotypeCallerIntegrationTest`, the ""consistent with past results"" tests will either succeed or fail depending on whether they run first or not, and the failure is definitely due to FTZ somehow getting unset between tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1771:64,integrat,integration,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1771,1,['integrat'],['integration']
Deployability,"We recently updated (PR #4858) the default Smith-Waterman parameters for realigning reads to their best haplotype. Although there is no reason for the alignment of haplotypes to the reference to use the same parameters, it seems like we are similarly favoring indels too much. There is a forum discussion to this effect:. https://gatkforums.broadinstitute.org/gatk/discussion/23230/gatk-haplotypecaller-mnp-output-problem. Here are the parameters we use:. * match: 200; * substitution: -150; * indel start: -260; * indel extend: -11. These parameters, which are essentially a prior on biological variation, prefer an indel, with a cost of 260, to a SNP, with a cost of 350. This does not seem correct. It almost never comes up because the correct alignment is usually unambiguous, but when it does, shouldn't we break the tie in favor of the SNP?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564:12,update,updated,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564,1,['update'],['updated']
Deployability,"We recommend backing up data just because it is the ""cleanest"" way to roll back. If backing up data is really such a pain point, you could skip doing that. Just back up the callset.json file, and don't turn on `--consolidate` when you're doing incremental import. If a failure happens, just roll back the callset.json and re-do the import. The downside is that the failed import will hang around and take up disk space, but hopefully it is a rare enough occurrence that it doesn't matter - and you will have saved yourself backing up the data. In response to 2) - I guess you're implying that the overhead of cluster/job scheduling won't amortize any benefits from parallelism there? I suppose that could be true, but doesn't seem to be worth optimizing towards that. What I'm asking is whether split and merge are purely an instrument to allow you to choose the granularity of parallelism you want to use? Or is there something else? As I said before, we are considering enabling other ways to do distributed import which would work for the former. It might go something like:; - Create a workspace/initialize configuration+intervals to be imported; - Actually do the import by kicking off (multiple) import(s). User can pick the number of intervals each import is responsible for. User must ensure that no interval gets specified in multiple import processes. P.S: regarding 1000s of small contigs - the current GenomicsDBImport doesn't so so well with large number of contigs (unless you do concatenate the contigs into fewer groups). We hope to have some changes coming soon that will help with that by adding an option for the tool to merge multiple contigs into a single folder in the workspace.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-641037548:1111,configurat,configuration,1111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-641037548,1,['configurat'],['configuration']
Deployability,We run contamination checks on the somatic VCF using the AMBER / COBALT / PURPLE pipeline. It does not flag contamination. [PURPLE](https://github.com/hartwigmedical/hmftools/tree/master/purity-ploidy-estimator) is a purity and ploidy estimator but often struggles with low purity samples and erroneously reports a samples such as this as purity 1.00 and ploidy 2.00. I wonder if such a sample could be detected using some tool from GATK?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6674#issuecomment-649095750:81,pipeline,pipeline,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6674#issuecomment-649095750,1,['pipeline'],['pipeline']
Deployability,"We ship an Intel conda environment that uses the Intel optimized tensorflow implementation for those with AVX-enabled hardware, but the environment requires AVX, so there are no tests since we can't assume we have AVX hardware on Travis. We need to provision some kind of continuous test that ensures that the CNN tools continue to work in this environment as we upgrade our dependencies for things like tensorflow, keras, etc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5255:272,continuous,continuous,272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5255,2,"['continuous', 'upgrade']","['continuous', 'upgrade']"
Deployability,"We should add a runtime check, probably at the ScriptExecutor level, to verify that the version of the python package we're running matches the version of GATK. Otherwise subtle failure modes could ensue when a user upgrades GATK but does not re-establish the conda env.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4995:216,upgrade,upgrades,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4995,1,['upgrade'],['upgrades']
Deployability,"We should audit the plugin system (and add tests) to ensure that crazy combinations of enable/disable arguments (like `--readFilter` and `--disableReadFilter`) are disallowed, while useful combinations are permitted. Here's my attempt at an initial proposal:. `--enable X --disable X`: crazy, should be an error. `--enable X --enable X`: error. `--disable X --disable X`: error. `--enable X when X is already on by default in the tool`: warning, but should be allowed -- this is useful for pipeline authors to guarantee that a particular filter will be on, even if tool defaults change over time. We should make sure that the filter is only actually applied ONCE, however. `--disable X when X is not enabled by default in the tool`: warning, but should be allowed -- this is useful for pipeline authors to guarantee that a particular filter will be off, even if tool defaults change over time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2377:490,pipeline,pipeline,490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2377,2,['pipeline'],['pipeline']
Deployability,"We should check if we can use their copy of google-cloud-sdk instead of installing our own. We added our own installation a long time ago, but maybe the version they use is now up to date enough to not have to install it ourself.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3954:72,install,installing,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3954,3,['install'],"['install', 'installation', 'installing']"
Deployability,"We should figure out how to fail the travis build if the before_install or install blocks fail. We have confusing test failures when earlier stages fail, it would be better to error early.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3444:75,install,install,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3444,1,['install'],['install']
Deployability,"We should fix it though. All it uses the locatable for is essentially to call toString on it, so we could just make it take a string in update.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577263587:136,update,update,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577263587,1,['update'],['update']
Deployability,"We should have an installer script checked in to the repo for downloading the Funcotator datasources. Ideally the script would have a trivial Java frontend in the form of a simple GATK tool, to make it more discoverable by users.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4549:18,install,installer,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4549,1,['install'],['installer']
Deployability,We should install the `python-is-python3` package during our docker build to create a symlink from `/usr/bin/python` to `/usr/bin/python3`. This would help avoid problems such as https://github.com/broadinstitute/gatk/issues/8402,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8497:10,install,install,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8497,1,['install'],['install']
Deployability,We should patch to give a better error message as well...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6260#issuecomment-553004443:10,patch,patch,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6260#issuecomment-553004443,1,['patch'],['patch']
Deployability,"We should provide a way for tools to generate standardized VCF header metadata lines. Most tools start with the lines from the input header, but after that there is a variation since each tool has custom code. We should rationalize how these are created/updated, for at least:; - ## contig: Some tools use the ones from the input directly, even if a specific reference is provided on the command line, but some update them based on the reference. Since we don't require a reference, but will accept one, we should be consistent about whether we keep or destroy the old attributes in each case, and whether we use an assembly attribute, URL attribute, etc.; - ## reference: same as above; - ## source: it seems like we should always add/update this. This is all somewhat related to https://github.com/broadinstitute/gatk/issues/1116.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2112:254,update,updated,254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2112,3,['update'],"['update', 'updated']"
Deployability,We should revert the change in https://github.com/broadinstitute/gatk/pull/3766 to retry 403s on GCS as soon as Google patches its service to return the correct status code (503) instead of 403. We can do this via a straight-up:; `git revert e11d7b9410e0fcecf2d98c5ac55ce05fad21ee17`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3800:119,patch,patches,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3800,1,['patch'],['patches']
Deployability,"We should run all of our dataflow tests on spark local runner as well as the dataflow direct pipeline runner. The plan is to run these as ""optional"" tests so that spark failure doesn't block our builds but we will be aware of any differences between the spark and google implementations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/551:93,pipeline,pipeline,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/551,1,['pipeline'],['pipeline']
Deployability,We should try to keep on top of the latest spark version while we're still not released yet. . When we upgrade we should verify that #2545 is resolved.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2555:79,release,released,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2555,2,"['release', 'upgrade']","['released', 'upgrade']"
Deployability,"We should update all command lines in the docs to use `gatk-launch`. Running with `java -jar` and bypassing `gatk-launch` causes several important system properties to not get set, including htsjdk compression level.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3039:10,update,update,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3039,1,['update'],['update']
Deployability,"We should update any public docs that contain recommendations on how to write JEXL expressions to reflect the align with the doc changes made in https://github.com/broadinstitute/gatk/pull/5422. Specifically, we should recommend that multiple simple expressions be used in place of a single compound expression. Here are @sooheelee 's notes on what docs need to change:. Here are the documents we should also update to reflect these updates:. https://gatkforums.broadinstitute.org/gatk/discussion/1255/using-jexl-to-apply-hard-filters-or-select-variants-based-on-annotation-values; https://software.broadinstitute.org/gatk/documentation/article?id=11080; Also, here is a list of documents with the jexl tag:; https://gatkforums.broadinstitute.org/gatk/discussions/tagged/jexl. I have put in a word of caution in https://gatkforums.broadinstitute.org/gatk/discussion/12350/how-to-filter-on-genotype-using-variantfiltration/p1?new=1.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5509:10,update,update,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5509,3,['update'],"['update', 'updates']"
Deployability,We should update our small dependencies if they need it. - [x] gatk-native-bindings -> release it as version 1.0.0; - [x] gatk-fermilite-jni -> release the current version as 1.1.0; - [x] gatk-bwamem-jni -> release a version 1.0.4 which includes a new method; - [ ] update gatk with new libraries,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4030:10,update,update,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4030,5,"['release', 'update']","['release', 'update']"
Deployability,We should update the class doc and arg doc strings to reflect this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5939#issuecomment-493031324:10,update,update,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5939#issuecomment-493031324,1,['update'],['update']
Deployability,We should update the whitepaper to describe the new pipelines.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3005#issuecomment-356735709:10,update,update,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3005#issuecomment-356735709,2,"['pipeline', 'update']","['pipelines', 'update']"
Deployability,"We somehow missed some new deprecation warnings that gradle gives when we updated to 7.3.2. . When running `bundle`; ex:; ```; Task :sparkJar; Execution optimizations have been disabled for task ':sparkJar' to ensure correctness due to the following reasons:; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/classes/java/main'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/resources/main'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/tmp/sparkJar/MANIFEST.MF'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; ```. ```; Deprecated Gradle features were used in this build, making it incompatible with Gradle 8.0. You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins. See https://docs.g",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7625:74,update,updated,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7625,1,['update'],['updated']
Deployability,"We think this release also addresses #3532, but have no way of testing ourselves. @magicDGS -- can you test if this is the case?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3615#issuecomment-332264310:14,release,release,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3615#issuecomment-332264310,1,['release'],['release']
Deployability,"We use Gauss-Legendre integration in the strand bias model. The number of subdivisions increases with the read count and for very deep coverage this can cause a stack overflow because, unfortunately, Apache Commons has a very questionable recursive implementation. The short-term fix is to cap the number of subdivisions. The long-term fix is to write some sort of simple adaptive 1D and 2D quadrature method. This ticket is for the short-term fix.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3317:22,integrat,integration,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3317,1,['integrat'],['integration']
Deployability,"We use the overclippedReadFilter as an argument to HaplotypeCaller in our; standard WGS production pipeline. Maybe it would be worthwhile making it; the default for HC. I expect some GQ0 sites, but 62K still seems high. How does that compare; to running HC while ignoring soft clips?. On Mon, Mar 25, 2019 at 3:08 PM jjfarrell <notifications@github.com> wrote:. > Yes, those are bacterial reads. I had recently used blat to align those; > soft-clipped reads and found they were a 100% match to a bacteria. The; > cigar string has *21bp* of the 150bp read aligning to the APOE gene near; > the two variants which is consistent with your observation on bacteria.; >; > I ran HaplotypeCaller with the -RF OverclippedReadFilter argument.; >; > That filtered out the reads and as a result made an accurate call with a; > GQ=48 instead of 0 when creating the g.vcf.; >; > chr19 44908684 . T <NON_REF> . . END=44908684 GT:DP:GQ:MIN_DP:PL 0/0:39:; > *48*:39:0,48,1167; >; > Without the OverclippedReadFilter, the GQ ad been set to 0 when creating a; > g.vcf.; > chr19 44908684 . T <NON_REF> . . END=44908688 GT:DP:GQ:MIN_DP:PL 0/0:44:; > *0*:41:0,0,1097; >; > The number of sites on chr19 with a GQ=0 dropped from 78,342 to 62,470; > with the OverclippedReadFilter.; >; > So that filter does clean things up when creating a gvcf. Is there a; > reason that is not a default filter? Are there any cons to always apply; > this filter when running HaplotypeCaller?; >; > John; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5445#issuecomment-476337308>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdCE7EM8R-_js3szXniGOAaGAJ-nGks5vaR7IgaJpZM4YxgEF>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5445#issuecomment-476360195:99,pipeline,pipeline,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5445#issuecomment-476360195,1,['pipeline'],['pipeline']
Deployability,"We want to know whether it's faster to convert upfront from cram to bam, and then read from bam in all of our tools, or skip the conversion and read directly from cram at every step in the pipeline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5208#issuecomment-423307049:189,pipeline,pipeline,189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5208#issuecomment-423307049,1,['pipeline'],['pipeline']
Deployability,"We wanted to standardize on something since before there was a mix of various styles. See https://github.com/broadinstitute/gatk/issues/2596. We did this change for all of the GTAK4 tools before we released 4.0, so almost a year ago now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-433425363:198,release,released,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-433425363,1,['release'],['released']
Deployability,"We were looking at this just now, and it seems like the problem might be this line in `GenomicsDBImport.getFeatureReadersInParallel()`:. ```; return new InitializedQueryWrapper(getReaderFromPath(variantPath), intervals.get(0));; ```. Notice that it's unconditionally calling `intervals.get(0)` in every thread...it looks like this line didn't get updated when multi-interval support was added to the tool, and the multi-interval tests don't run with reader threads > 1.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5300#issuecomment-438834782:347,update,updated,347,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5300#issuecomment-438834782,1,['update'],['updated']
Deployability,"We will certainly output VCFs for our final calls, but we also have useful intermediate file formats that would benefit from having the sample name (and sequence dictionary, if appropriate) attached---for example, our read-count and allelic-count files. I see no reason that these shouldn't have a header with the appropriate tags generated from the input BAM and be read/written in the Tribble framework. However, there are a few exceptions in the CNV pipeline for files that not collections of Features but are still associated with a sample, so I think it would be nice to extract out the sample-name related code across the various tools. This is not only to avoid duplicating effort, but also to standardize how we store this information in our various file formats.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3726#issuecomment-338288560:453,pipeline,pipeline,453,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3726#issuecomment-338288560,1,['pipeline'],['pipeline']
Deployability,"We will do a GATK point release within the next few days to patch the GenotypeGVCFs bug, and also add a `--max-genomicsdb-alternate-alleles` argument that is separate from (and greater than) `--max-alternate-alleles`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023555029:24,release,release,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023555029,2,"['patch', 'release']","['patch', 'release']"
Deployability,We will just read from `gnomAD` directly using the NIO updates for Funcotator data sources. Should fix this at the same time as #5428 and #5429.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5259#issuecomment-442226791:55,update,updates,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5259#issuecomment-442226791,1,['update'],['updates']
Deployability,We would be happy to accept a patch to move to a new version of gradle. (We've wanted to do so for a long time but haven't gotten around to it... https://github.com/broadinstitute/gatk/issues/4659). There's a partial upgraded version [here](https://github.com/broadinstitute/gatk/tree/lb_update_to_gradle_4.8) but it had some problem and I never got around to finishing it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444198609:30,patch,patch,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444198609,2,"['patch', 'upgrade']","['patch', 'upgraded']"
Deployability,"We'd also need a good integration test that reads in a VCF containing genotypes using `SelectVariants` with `--sites-only`, writes it out, reads it back in using `VariantContextTestUtils.readEntireVCFIntoMemory()`, and asserts that the genotypes are gone. The test should probably live someplace like `GATKToolIntegrationTest` or `FeatureSupportIntegrationTest` -- don't put it in `SelectVariantsIntegrationTest`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4763#issuecomment-388453987:22,integrat,integration,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4763#issuecomment-388453987,1,['integrat'],['integration']
Deployability,"We'd prefer something tightly integrated with our main test suite in travis, and reserve jenkins for long-running/nightly tests. Having to deal with two CI environments for pull requests is too cumbersome.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2298#issuecomment-287474520:30,integrat,integrated,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2298#issuecomment-287474520,1,['integrat'],['integrated']
Deployability,"We'd really like to be able to move forward to newer java versions. Unfortunately we have a pretty long list of dependencies which don't support any version newer than 8 yet. In particular, our dependency on Spark is problematic. Spark is stuck on java 8 because of issues with scala on java 9+ as well as issues with their dependencies. As I understand it, Java 9+ made changes to various methods which were widely used by libraries that do low level memory management. It also deprecated some forms of cross package reflection. Spark makes heavy use of both of those things so I think there having trouble updating. . So... we'd like to update, I have no idea when will be able to. Probably not for at least a year.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5737#issuecomment-468476353:639,update,update,639,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5737#issuecomment-468476353,1,['update'],['update']
Deployability,We'll need a simple build system + README + documented release procedure.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2208#issuecomment-253618598:55,release,release,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2208#issuecomment-253618598,2,['release'],['release']
Deployability,"We're going to release the new model in 3.7 and have users test-drive that for quite a bit before we move to release 4.0, so we should be able to get some feedback on performance in the wild before we need to make any final decisions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2255#issuecomment-258412589:15,release,release,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2255#issuecomment-258412589,4,['release'],['release']
Deployability,We're seeing a high rate of failures running BQSR pipelines in production with `ExecutionException`s. . The root cause seems to be an `UnknownHostException` thrown in the google storage api client. ```; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: www.googleapis.com; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:567); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:556); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:525); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:458); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:196); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:331); 	at java.io.DataInputStream.read(DataInputStream.java:149); 	at htsjdk.samtools.util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readByteBuffer(BinaryCodec.java:490); 	at htsjdk.samtools.util.BinaryCodec.readInt(BinaryCodec.java:501); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:198); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.jav,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094:50,pipeline,pipelines,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094,1,['pipeline'],['pipelines']
Deployability,"We've been implementing new features but the coverage in the `sv.utils` package has been non-pretty. Some of the classes like `ExternalCommandlineProgramModule.java` and `GATKSVVCFConstants.java` are OK (`ExternalCommandlineProgramModule` exists for historical reason, when we had SGA as the assembler; `GATKSVVCFConstants` is mostly holding String literals), but other classes are doing actual work and have low coverage. We should test them, not via integration tests only, but also unit tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5139:452,integrat,integration,452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5139,1,['integrat'],['integration']
Deployability,"We've been using 4.beta.6 to generate new callsets because it has the GenomicsDBImport batching fix and it seems to have introduced transient Auth errors that production was not seeing before. This happens a maybe one shard at every task level and when rerun usually succeeds but as you can imagine is pretty annoying. This happens across multiple tools (GenomicsDBImport, GatherVcfs). Sometimes we get this as the only response from GATK when this happens. ```; ***********************************************************************. A USER ERROR has occurred: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-gotc-prod-storage/pipeline/G101956/gvcfs/DDP_ATCP_42_1.4afb46bb-4009-47c4-9aa0-407e92de0db8.g.vcf.gz. ***********************************************************************; ```. and other times we get a nice stacktrace for this issue. ```; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.IOUtil.transferByStream(IOUtil.java:141); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.gatherWithBlockCopying(GatherVcfsCloud.java:394); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.doWork(GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineP",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3735:841,pipeline,pipeline,841,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735,1,['pipeline'],['pipeline']
Deployability,"We've discovered a confusing git-lfs bug that effects people who have a git fork of gatk that started before the gatk/gatk-protected merge. . The symptom is that if you try to update your fork from the gatk master branch, and then push to your master, you'll see git errors like this:. ```; $ git push; open/Users/louisb/tmp/gatk-1/src/test/resources/large-protected/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx: no such file or directory; ```. This will prevent you from updating your master. The solution is to checkout the commit `32a2b39` which will manually trigger a git-lfs download of 1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx. Then checkout master again and push. @magicDGS This probably affects you. . We're going to open a git-lfs issue since it seems to be a pretty serious git-lfs bug, I'll update this ticket with more information when we have it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3038:176,update,update,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3038,2,['update'],['update']
Deployability,"We've had a request to retry 502's in `google-cloud-nio`, so we'll likely have to patch our custom fork again. When we do so, we should move it to a more standard location (broadinstitute org instead of my personal account).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4762:82,patch,patch,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4762,1,['patch'],['patch']
Deployability,"We've had reports of two kinds of intermittent network errors when using NIO that are not currently caught by google-cloud-nio:. * `UnknownHostException`; * 502 Bad Gateway. We should patch the library to add these errors to the list of retryable/reopenable errors. We can start by patching the GATK fork of `google-cloud-java`, and then concurrently submit a PR against `google-cloud-java` proper.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4888:184,patch,patch,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4888,2,['patch'],"['patch', 'patching']"
Deployability,"We've patched GatherVCFs to allow it to read from NIO, but since it's a picard tool it's going to be reverted when we switch to depending on the real picard. We need to either port the changes to picard or make a gatk-tool version",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2745:6,patch,patched,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2745,1,['patch'],['patched']
Deployability,"We've seen at least 1 non-deterministically occurring instance of ConcurrentModificationException while running the `ReadsPipelineSparkIntegrationTest.testReadsPipelineSpark[5]`. It seems like there is a race condition somewhere. ```; testReadsPipelineSpark[5](ReadsPipeline(bam='/home/travis/build/broadinstitute/gatk/src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.tiny.unaligned.bam', args='--align --bwa-mem-index-image /home/travis/build/broadinstitute/gatk/src/test/resources/large/human_g1k_v37.20.21.fasta.img --known-sites src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf')); com.esotericsoftware.kryo.KryoException: java.util.ConcurrentModificationException; Serialization trace:; classes (sun.misc.Launcher$AppClassLoader); classLoader (org.apache.hadoop.conf.Configuration); conf (org.apache.hadoop.hdfs.DistributedFileSystem); fs (hdfs.jsr203.HadoopFileSystem); hdfs (hdfs.jsr203.HadoopPath); path (htsjdk.samtools.seekablestream.SeekablePathStream); seekableStream (htsjdk.tribble.TribbleIndexedFeatureReader); featureReader (org.broadinstitute.hellbender.engine.FeatureDataSource); featureSources (org.broadinstitute.hellbender.engine.FeatureManager); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:101); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectFie",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5680:827,Configurat,Configuration,827,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680,1,['Configurat'],['Configuration']
Deployability,"We've taken a stab at this with the tooldoc updates. There may be things to change going forward, but we can deal with them as they come.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-358068521:44,update,updates,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-358068521,1,['update'],['updates']
Deployability,"Well, after install hadoop 3.1.1 with Linuxbrew, I managed to run `CreateReadCountPanelOfNormals`. Still, I think it is better not to copy input files to hadoop when running on single machine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5686#issuecomment-465393400:12,install,install,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686#issuecomment-465393400,1,['install'],['install']
Deployability,"Well, you're welcome to use gatk-launch as a launch script if you'd like (and feel free to rename to whatever you like...) A. There are a few reasons we have spark and non-spark versions of the tools. . 1. We wanted to port and validate certain tools as quickly as possible and doing a direct port from gatk3 -> gatk4 was easier than making them sparkified at the same time. 2. There's a tradeoff in using spark where you end up spending more total cpu hours in order to finish a job faster. Ideally this would be 1:1, double the number of cores and you halve the time to finish a job. It never scales perfectly though, there's always some overhead for being parallel. Our production pipelines are extremely sensitive to cost and not very sensitive to runtime, so they prefer we have a version that's optimized to use the least cpu hours even if that means a longer runtime. Other users prefer to be able to finish a job quickly and are willing to pay slightly more to do so, so we also have a spark version. . 3. Some tool are complicated to make work well spark. Spark works best when you can divide the input data into independent shards and then process them separately. This is complicated for things like the AssemblyRegion walker where you need context around each location of interest. We had to do things like add extra overlapping padding and things like that to avoid boundary issues where there are shard divisions. We don't yet fully understand spark performance and it's caveats, we're looking into that actively now. We hope that we'll be able to optimize our tools so that a spark pipeline of several tools in series is faster than running the individual non-spark versions, since it lets us avoid doing things like loading the bam file multiple times from disk. Whether or not we can achieve this is still and open question though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2345#issuecomment-273318100:684,pipeline,pipelines,684,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2345#issuecomment-273318100,2,['pipeline'],"['pipeline', 'pipelines']"
Deployability,"What about this GATK 4 pipeline script, written by Chat-GPT",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8905:23,pipeline,pipeline,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8905,1,['pipeline'],['pipeline']
Deployability,"What is the best Sparkified way to recapitulate our germline Best Practices workflow? Is there one pipeline that encompasses all steps from BWA alignment to HaplotypeCaller calling?. Please see forum thread as I have answered the user question tentatively with these two options:. [1] BwaSpark --> SortReadFileSpark --> ReadsPipelineSpark; [2] BwaAndMarkDuplicatesPipelineSpark --> SortReadFileSpark --> BQSRPipelineSpark --> HaplotypeCallerSpark. Thanks. ---; Hi @shlee ,; I am really sorry for the delay but I was busy in the last weeks. Anyway I will try to be clearer with this picture:. ![](https://us.v-cdn.net/5019796/uploads/editor/3x/9bu9fsvbgjrh.png """"). as you can see I would like to combine the tools `BwaAndMarkDuplicatesPipelineSpark` and `BQSRPipelineSpark` in one single tool, in order to improve efficiency of the pipeline (avoiding for example a disk writing). ; I tried to do it with [this](https://pastebin.com/XEqvpKmG ""this"") naive approach as I reported in previous comments, but executing this code I obtain this error (as you can see at the end of this [stack-trace](https://paste.ee/p/dMod1 ""stack-trace"") ) : ; ```; 17/11/03 13:02:14 ERROR Utils: Aborting task; java.lang.IllegalArgumentException: Reference index for 'chr11' not found in sequence dictionary.; ```. Do you think is better if I speak directly with developers in the GitHub repository?. Best regards,; Nicholas. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/44143#Comment_44143",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3878:99,pipeline,pipeline,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3878,2,['pipeline'],['pipeline']
Deployability,"What is the current behavior when OpenMP is not available or is the wrong version on a Linux system? If the answer is ""it blows up with a gross error"", then let's patch the code so that it gracefully falls back to the single-threaded version, as on a Mac.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1819:163,patch,patch,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1819,1,['patch'],['patch']
Deployability,What is the source of the GTF file you are using? It look like the issue you are seeing has to do with the parsing of your new GTF file. The GTF codec in GATK4 is bespoke and designed to handle GencodeGTF files specifically and expects some specific fields to be present in all records which looks to be what is causing problems for you right here (this will be subject to change in the next release to some extent). It expects that gene feature object comes first in the order of family gene elements and it also requires that all of the gene transcript/exome families are and appear together as a group. . Its hard to say without seeing your GTF file but if it is coordinate sorted this could happen or it could also happen if its is mis-formatted and elements are not hierarchically organized into gene -> transcripts -> exons-> features.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8394#issuecomment-1613357793:392,release,release,392,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8394#issuecomment-1613357793,1,['release'],['release']
Deployability,"What is the status of this bug? The rate of failure in SparkGenomeReadCounts is non-negligible, so this is becoming an issue for testing the new CNV WGS pipeline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3659#issuecomment-339350516:153,pipeline,pipeline,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659#issuecomment-339350516,1,['pipeline'],['pipeline']
Deployability,"What is your cluster configuration? . That's a lot of memory for one executor, it may be having trouble allocating workers with that much memory, or using all the memory on 1 very large executor.; Have you tried setting executor cores as well? I would usually set it to something like `--executor-cores 4 --executor-memory 16G` . You want to design your executors so they fit evenly into the worker nodes on your cluster but don't have too many cores per executor. . An aside, you *should* be able to create a bam index as part of SortSamSpark now, we have support for generating it in parallel and merging the indexes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6233#issuecomment-547077382:21,configurat,configuration,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6233#issuecomment-547077382,1,['configurat'],['configuration']
Deployability,"What this PR does: ; * implemented alignment breaker based on CIGAR gaps; ; * calls insertion, deletion and naive tandem repeat annotation in addition to inversion; ; * some further refactoring of code related to sv caller; ; * tests updated accordingly. The PR is into another branch but NOT `master` because it is based on a continuation effort, which is already reviewed in #2258 , therefore has all the changes already made there (a little Spark 2 phobia caused this derail; once changes are reviewed, will see if tool is runnable and ""pipelineable"" with previous stages in the SV pipeline under the new Spark version). @cwhelan please review.; Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2320:234,update,updated,234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2320,3,"['pipeline', 'update']","['pipeline', 'pipelineable', 'updated']"
Deployability,What's holding us up is me being very and busy with other things. I don't think there are any technical problems that we know about. The newest disq releases support 3+. We just need to upgrade and test to find out what we broke.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6671#issuecomment-1042249080:149,release,releases,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6671#issuecomment-1042249080,2,"['release', 'upgrade']","['releases', 'upgrade']"
Deployability,Whats the status here? Also the bundled sources got no updates since 2020.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1497538526:55,update,updates,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1497538526,1,['update'],['updates']
Deployability,"When I tried to run the latest build of the spark gatk I got the following error message on both dataproc and the onprem cluster.; `File Not Found: [/Users/emeryj/IdeaProjects/gatk/build/libIntelDeflater.so]`. Making the following changes to gatk-launch seems to fix it. ```; @@ -23,14 +23,13 @@ BUILD_LOCATION = script +""/build/install/"" + projectName + ""/bin/""; GATK_RUN_SCRIPT = BUILD_LOCATION + projectName; BIN_PATH = script + ""/build/libs"". -EXTRA_JAVA_OPTIONS=""-Dsamjdk.intel_deflater_so_path=libIntelDeflater.so -Dsamjdk.compression_level=1 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true ""; +EXTRA_JAVA_OPTIONS=""-DGATK_STACKTRACE_ON_USER_EXCEPTION=true "". DEFAULT_SPARK_ARGS = [""--conf"", ""spark.kryoserializer.buffer.max=512m"",; ""--conf"", ""spark.driver.maxResultSize=0"",; ""--conf"", ""spark.driver.userClassPathFirst=true"",; ""--conf"", ""spark.io.compression.codec=lzf"",; ""--conf"", ""spark.yarn.executor.memoryOverhead=600"",; -""--conf"", ""spark.yarn.dist.files="" + script + ""/build/libIntelDeflater.so"",; ""--conf"", ""spark.driver.extraJavaOptions="" + EXTRA_JAVA_OPTIONS,; ""--conf"", ""spark.executor.extraJavaOptions="" + EXTRA_JAVA_OPTIONS]; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1930:329,install,install,329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1930,1,['install'],['install']
Deployability,"When I was trying to use user exceptions in a consistent way independently of the constructor (mostly related with files), I found very weird behaviour with the messages. Here I try to fix some of the things that I was struggling with:. * Support for path in constructors for `CouldNotReadInputFile`, `CouldNotCreateOutputFile`, `MalformedFile` and `MalformedBAM`, in addition to some missing constructors to have the same structure for all of them (with `File` and/or `String`).; * ~~Updated javadoc in `CommandLineException`, including extending classes to make clear that in the GATK framework is not printed out if it is thrown out of parameter validation.~~ __Edited__: this is not longer required, because `CommandLineException` is decoupled from `UserException` through barclay.; * Added a TODO into the `MalformedBAM` constructor that includes a `GATKRead` that is not used.; * __Edited__: added final to constructors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282:485,Update,Updated,485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282,1,['Update'],['Updated']
Deployability,"When SelectVariants samples are subset and PLs are updated, GQ doesn't appear to get updated. This fixes some incorrect results for LeftAlignAndTrimVariants -split. Also fixes results for SelectVariants -trimAlternates -- PLs are just 0 with no called alts, so there shouldn't be GQ. Port of https://github.com/broadinstitute/gsa-unstable/pull/1625",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3409:51,update,updated,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409,2,['update'],['updated']
Deployability,"When `GenotypeGVCFs` is sharded by `-L` interval, as it typically is in production, it needs a way to avoid emitting the same call across shards in the case of indels that span interval boundaries. The simplest way to do this is to only emit records that start in the current interval. It might make sense to do this at the VCF writer level, and hook it up to an engine-wide argument to toggle this behavior. `HaplotypeCaller` and `Mutect` currently do something similar internally, and could possibly leverage this functionality.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2735:387,toggle,toggle,387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2735,1,['toggle'],['toggle']
Deployability,"When extracting the overlapped bases of two reads, FragmentUtils miscalculates the starting position of the second read if there are softclipped bases at its head. This leads to misalignment of the two reads and incorrect updating of the base qualities. In some other cases, it may fail to detect overlapping bases if the first and second read both contain softclips. This pull request updates the position calculation and adds a unit test to demonstrate the issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6824:386,update,updates,386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6824,1,['update'],['updates']
Deployability,"When hard clipping a read resulted in an empty read, and the read was sufficiently; close to the start of a contig, we could end up trying to set the read to a negative; start position and blowing up. This patch causes us to return an empty read earlier,; preventing us from setting an invalid start. Resolves the ""IllegalArgumentException during clipping: contig must be non-null and not; equal to *, and start must be >= 1"" error reported by many users of the GATK4; HaplotypeCaller. Resolves #3466",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4080:206,patch,patch,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4080,1,['patch'],['patch']
Deployability,"When originally released, Funcotator had blistering speed. In the latest tests, this speed has dropped off to be a very small fraction of that original data processing rate. We need to profile Funcotator to determine the source of the slowdown, and then we must remedy it. In particular the hg38 acceptance testing dataset (`hg38_trio.vcf`) has slowed significantly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6574:16,release,released,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6574,1,['release'],['released']
Deployability,"When parsing interval arguments in GATK using the latest htsjdk, files that end in "".interval_list"" are claimed by the new IntervalListCodec introduced in https://github.com/samtools/htsjdk/pull/1327. This PR renames the one test file in GATK that has a Picard interval list file extension but isn't really a Picard interval list; without this change, CountReads and CountReadsSpark integration tests will fail when we upgrade to the next htsjdk.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5879:383,integrat,integration,383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5879,2,"['integrat', 'upgrade']","['integration', 'upgrade']"
Deployability,"When run with the current master build against our snapshot HG00514 sample, the experimental variant interpretation pipeline fails with the following exception:. ```; 18/04/11 20:27:50 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 32.0 in stage 42.0 (TID 56552, cwhelan-hg00514-1-cram-samtools-bam-feature-w-4.c.broad-dsde-methods.internal, executor 28): org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter$UnhandledCaseSeen: 1st segment is not overlapping with head alignment but it is not immediately before/after the head alignment either; AssemblyContigWithFineTunedAlignments{sourceTig=(asm022672:tig00004, [1_1430_chr9:130955309-130956738_-_1430M2216S_60_-1_-1_S, 1587_1763_chr9:130955156-130955308_-_1586S54M24I99M1883S_60_-1_-1_S, 1824_2015_chr9:130954964-130955155_-_1823S192M1631S_60_-1_-1_S, 2164_3646_chr9:130953867-130955307_-_2163H167M42I1274M_60_55_1318_O]), insertionMappings=[1963_2177_chr9:130955093-130955304_-_1962H179M3I33M1469H_19_14_138_O], hasEquallyGoodAlnConfigurations=false, saTAGForGoodMappingToNonCanonicalChromosome='NONE'}; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantCanonicalRepresentation.extractAltHaplotypeSeq(CpxVariantCanonicalRepresentation.java:338); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantCanonicalRepresentation.<init>(CpxVariantCanonicalRepresentation.java:143); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.lambda$inferCpxVariant$b3be3b47$1(CpxVariantInterpreter.java:53); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4649:116,pipeline,pipeline,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4649,1,['pipeline'],['pipeline']
Deployability,"When running PrintReads on GCS with shardedOutput false, I'm experiencing a file write failure for my output. I have verified that I can write to the bucket I specify and that when shardedOutput is true this error does not occur. @tomwhite - any thoughts?. Here's my invocation:; ```; ./gatk-launch PrintReadsSpark -I gs://hellbender/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam -O gs://jonn-test-bucket/foo.bam --shardedOutput false -- --sparkRunner GCS --cluster jonn-test-cluster --num-executors 5 --executor-cores 4 --executor-memory 4g; ```; Here is the stack trace:; ```; org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file gs://jonn-test-bucket/foo.bam because writing failed with exception jonn-test-bucket/foo.bam.parts; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:255); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:37); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:220); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.inv",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2793:938,pipeline,pipelines,938,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2793,1,['pipeline'],['pipelines']
Deployability,"When running Spark tools with GCS files on Dataproc the [GCS connector](https://github.com/GoogleCloudPlatform/bigdata-interop/tree/master/gcs) is set up and configured for you, but this isn't the case when running with local Spark, even on a GCP VM. We should make the experience easier through documentation and/or configuration improvements.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5996:317,configurat,configuration,317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5996,1,['configurat'],['configuration']
Deployability,"When running StructuralVariationDiscoveryPipelineSpark (GATK 4.0.1.1) on a hadoop cluster, the following exception occurs. The pipeline has been running fine on other cram files. **Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0**. Below is the stack and other details. . The pipeline looks like it is running through all the contigs and is not limited to chr1-chr22, ChrY, ChrX and ChrM. Would it help running the software if the extra 3000+ contig names in the GRCh38 reference are excluded? If so, what is the best way to exclude processing the extra contigs?. ```; 18/02/23 23:06:22 INFO scheduler.TaskSetManager: Finished task 24.0 in stage 15.0 (TID 29435) in 2906 ms on scc-q04.scc.bu.edu (executor 1) (48/70); 18/02/23 23:06:23 INFO scheduler.TaskSetManager: Finished task 52.0 in stage 15.0 (TID 29463) in 2354 ms on scc-q04.scc.bu.edu (executor 1) (49/70); 18/02/23 23:06:23 INFO scheduler.TaskSetManager: Finished task 37.0 in stage 15.0 (TID 29448) in 2653 ms on scc-q03.scc.bu.edu (executor 6) (50/70); 18/02/23 23:06:23 WARN scheduler.TaskSetManager: Lost task 27.0 in stage 15.0 (TID 29438, scc-q13.scc.bu.edu, executor 7): org.broadinstitute.hellbender.exceptions.GATKException: Erred when inferring breakpoint location and event type from chimeric alignment:; asm010450:tig00000 1_189_chrUn_JTFH01000312v1_decoy:663-851_-_189M512H_60_8_149_O 153_701_chrUn_JTFH01000312v1_decoy:1-549_+_152S549M_60_0_549_O; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignmentsSAMSpark.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); at java.util.stream.StreamSplitera",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:127,pipeline,pipeline,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,2,['pipeline'],['pipeline']
Deployability,"When running StructuralVariationDiscoveryPipelineSpark, we found the local storage on our Hadoop Datanodes filling up. The pipeline was generating 2 GB of output and filling up the /var storage on the datanodes. The job would then fail. Is there a way to turnoff this extensive logging info for this pipeline and make less extensive logging the default? . Here is an example of one of the files.....; container_e2417_1520821377253_0060_01_000052/stdout. writing; 10000139 2/2 76b aligned read.; writing; 1000014 1/2 76b aligned read.; writing; 1000014 2/2 76b aligned read.; writing; 10000140 2/2 76b aligned read.; writing; 10000140 1/2 76b aligned read.; writing; 10000141 1/2 76b aligned read.; writing; 10000141 2/2 76b aligned read.; writing; 10000142 1/2 76b aligned read.; writing; 10000142 2/2 76b aligned read.; writing; 10000143 1/2 76b aligned read.; writing; 10000143 2/2 76b aligned read.; writing; 10000144 2/2 76b aligned read.; writing; 10000144 1/2 76b aligned read.; writing; 10000145 2/2 76b aligned read.; writing; 10000145 1/2 76b aligned read.; writing; 10000146 2/2 76b aligned read.; writing; 10000146 1/2 76b aligned read.; writing; 10000147 1/2 76b aligned read.; writing; 10000147 2/2 76b aligned read.; writing; 10000148 2/2 76b aligned read.; writing; 10000148 1/2 76b aligned read.; writing; 10000149 2/2 76b aligned read.; writing; 10000149 1/2 76b aligned read.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4531:123,pipeline,pipeline,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4531,2,['pipeline'],['pipeline']
Deployability,"When running the current version of the SV pipeline against the NA12878_PCR-_30X bam file aligned to hg19/b37, stage 10 is held up by a single assembly task that takes much longer than the others. Unfortunately I don't have exact timings yet, and haven't identified the assembly issue that's causing the problem, but I wanted to log this as an issue so we don't forget about it. It's possible that other samples will have similar outlier assemblies so it would be good to track down cases like this so that we can try to identify and remove pathological intervals. @tedsharpe if you find yourself with free time could you take a look at this? Whatever is going wrong with it might be fixed or relevant to your work on debugging assemblies and kmer gathering (if we're lucky perhaps your 'diffuse k-mer' fix will solve this issue).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3607:43,pipeline,pipeline,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3607,1,['pipeline'],['pipeline']
Deployability,"When running the following command. gatk4 BaseRecalibratorSpark -I xx_markduplicatespark.bam -knownSites dbsnp_138.b37.vcf -knownSites Mills_and_1000G_gold_standard.indels.b37.vcf -O xx_baserecalibratespark.table -R humann_g1k_v37.2bit --TMP_DIR tmp. I got error message,. Using GATK wrapper script /curr/tianj/software/gatk/build/install/gatk/bin/gatk; Running:; /curr/tianj/software/gatk/build/install/gatk/bin/gatk BaseRecalibratorSpark -I A15_markduplicatespark.bam -knownSites ref/Mills_and_1000G_gold_standard.indels.b37.vcf -O A15_baserecalibratespark.table -R /curr/tianj/data/humann_g1k_v37.2bit; 17:19:00.338 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/curr/tianj/software/gatk/build/instabgkl_compression.so; [May 17, 2017 5:19:00 PM UTC] org.broadinstitute.hellbender.tools.spark.BaseRecalibratorSpark --knownSites /genome/ref/db_1000G_gold_standard.indels.b37.vcf --output A15_baserecalibratespark.table --reference /curr/tianj/data/humann_g1k_v37.2bp --joinStrategy BROADCAST --mismatches_context_size 2 --indels_context_size 3 --maximum_cycle_value 500 --mismatches_defdeletions_default_quality 45 --low_quality_tail 2 --quantizing_levels 16 --bqsrBAQGapOpenPenalty 40.0 --preserve_qscores_lles false --useOriginalQualities false --defaultBaseQualities -1 --readShardSize 10000 --readShardPadding 1000 --readValid-interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --sharl[*] --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inf; [May 17, 2017 5:19:00 PM UTC] Executing as tianj@ip-172-31-78-66 on Linux 4.4.41-36.55.amzn1.x86_64 amd64; Java HotSpot(TM:4.alpha.2-261-gb8d32ee-SNAPSHOT; 17:19:00.371 INFO BaseRecalibratorSpark - Defaults.BUFFER_SIZE : 131072; 17:19:00.371 INFO BaseRecalibratorSpark - Defaults.COMPRESSION_LEVEL : 1; 17:19:00.371 INFO BaseRecalibratorSpark - Defaults.CREATE_INDEX : false; 17:19:00.371 INFO BaseR",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2732:331,install,install,331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2732,2,['install'],['install']
Deployability,"When the MultiVariantWalker is integrated with VQSR, we need to make sure to update the code that populates the output header to match the way GATK3 did it with multiple inputs (mostly affects ApplyVQSR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2114#issuecomment-246357129:31,integrat,integrated,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2114#issuecomment-246357129,2,"['integrat', 'update']","['integrated', 'update']"
Deployability,When the changes from this https://github.com/broadinstitute/picard/pull/1442 go in and we update our picard dependency we should port the test and scaling factor from that branch.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6316:91,update,update,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6316,1,['update'],['update']
Deployability,"When to merge is your decision, but note that:. * Current production pipelines using bcftools are already broken by this; * Pysam currently misreads GT when given this header, so pysam-using analysis scripts are probably also already broken and/or contain workarounds. e.g. a basic `for v in pysam.VariantFile(fname): print(v)` loop produces the following (note the -65 instead of `.` for GT):; ```; 1	100	.	C	T	.	PASS	AN=4	GT:GQ	-65:245; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8621#issuecomment-1854598024:69,pipeline,pipelines,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8621#issuecomment-1854598024,1,['pipeline'],['pipelines']
Deployability,"When we make enhancements to the walker engine (eg., modify the `GATKTool` base class to support CRAM, or to validate the sequence dictionaries of the inputs), it would be good if Spark tools could also reap the benefits of these changes automatically. We may need to unify (or better integrate) the `GATKTool` and `SparkCommandLineProgram` base classes somehow to make this possible, as well as classes like `ReadsDataSource` (for walkers) and `ReadsSparkSource` (for Spark tools).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/680:285,integrat,integrate,285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/680,1,['integrat'],['integrate']
Deployability,When we refactored the docker image to no longer contain the source directory we found that the changes had the side effect of causing the tests inside of the docker image to execute more slowly (~10 minutes per docker test). We solved this problem by further splitting the tests up but this is only a temporary solution. It is worth figuring out what about this gradle configuration is slow to save everyone time.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4989:370,configurat,configuration,370,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4989,1,['configurat'],['configuration']
Deployability,"When you merge, be sure to update the commit comment and message to reflect the fact that it's been replaced instead of deprecated and that the default behavior is the opposite of what it used to be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318688481:27,update,update,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318688481,1,['update'],['update']
Deployability,"When you say that the samples have 0|0 calls, is that the GT call (as you; and Nils updated) or the PGT call? If it's PGT I don't really care as long; as GT is 0/0. If GT is 0|0 I have to think about it a little more and ask; around. On Fri, Mar 8, 2019 at 10:35 AM Tim Fennell <notifications@github.com>; wrote:. > Ok, so I ran in multi-sample mode with three samples. The results are IMHO; > a little odd, but not wrong. The reason I say a little odd is that (and; > this makes total sense thinking about it) when one sample has phased; > genotypes, all the samples get phasing information. This follows from the; > fact that the FORMAT field has to contain PS (and also PID and PGT) in; > order to emit phasing for one sample, so then the other samples have to do; > something.; >; > What happens then is that phase sets get created for all the samples, and; > you end up with some samples having e.g. pairs of 0|0 genotypes phased.; > Strictly speaking that isn't wrong .. but it is a little funny looking.; >; > I could see three options:; >; > 1. Decide that multi-sample calling to VCF with phasing enabled is too; > weird, and change the existing prohibition to be ""if emitting VCF *and*; > multi-sample disable phasing); > 2. Decide it's all ok, and just remove the existing prohibition; > 3. Split the difference and emit a warning if emitting a multi-sample; > VCF with phasing.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470969817>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdFesDdjKnEXqk2x0JVi2f7MZtcr9ks5vUoMngaJpZM4bjw8U>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470972598:84,update,updated,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470972598,1,['update'],['updated']
Deployability,"When/If this gets merged and dockers are regenerated, I'll update https://github.com/broadinstitute/gatk/pull/7611 as needed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7617#issuecomment-998215347:59,update,update,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7617#issuecomment-998215347,1,['update'],['update']
Deployability,"While searching the error, I found this github issue! I'm having the same error with gatk 4.2.0.0… GP is trying to incorporate Funcotator into the clinical pipeline, it would be great if this fix can be made as soon as possible. Thanks!; cc: @NiallJLennon @CarrieCibulskis",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-913014699:156,pipeline,pipeline,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-913014699,1,['pipeline'],['pipeline']
Deployability,"While testing BwaSpark on a yarn cluster, I noticed that only a single executor (the driver) was being created and running only on the master node. The worker nodes were idle. This happened when running the following command . ```; spark-submit \; --deploy-mode client \; --class org.broadinstitute.hellbender.Main \; --master yarn \; /home/hadoop/gatk-package-4.alpha.2-269-gdce8abc-SNAPSHOT-spark.jar BwaSpark \; --bwamemIndexImage /var/tmp/hs38DH-V.fasta.img \; -I hdfs:///unaligned.bam \; -O hdfs:///aligned.bam \; -R hdfs:///hg38/hs38DH-V.fasta \; --disableSequenceDictionaryValidation true; ```. I checked the spark environment settings in the spark web UI and found that `spark.master` was set to `local` despite the `--master yarn` cmd-line argument. Next I checked the gatk source and found a suspicious call to `SparkConf.setMaster()` at line 138 in ; `src/main/java/org/broadinstitute/hellbender/engine/spark/SparkContextFactory.java`. I commented out this call, recompiled, and tried again, and the issue went away. I suspect that `setMaster()` was overriding the `--master yarn` cmd-line argument. I believe this is a bug and propose somehow avoiding `setMaster()` when the app is run with `spark-submit`. Thanks,; David",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2718:250,deploy,deploy-mode,250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2718,1,['deploy'],['deploy-mode']
Deployability,"While we're waiting on the gcloud release, @lbergelson could you please review the changes to `gatk-launch` in this branch?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-256431585:34,release,release,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-256431585,1,['release'],['release']
Deployability,While working on #9012 I tried to update the gencode v28 datasource snippets in the Funcotator integration tests to V43. In doing so I found that it broke the MAF vs. VCF output render tests with errors of the following nature: . ```; java.lang.AssertionError: Failed Matching VCF and MAF fields:; 	VCF (Gencode_43_variantClassification): 	RNA[0]	RNA[1]	RNA[2]	RNA[3]	RNA[4]	RNA[5]	RNA[6]	RNA[7]	RNA[8]	RNA[9]	RNA[10]; 	MAF (Variant_Classification): 	LINCRNA[0]	LINCRNA[1]	LINCRNA[2]	LINCRNA[3]	LINCRNA[4]	LINCRNA[5]	LINCRNA[6]	LINCRNA[7]	LINCRNA[8]	LINCRNA[9]	LINCRNA[10]; ----; 	VCF (Gencode_43_otherTranscripts): 	[0]	[1]	[2]	[3]	[4]	[5]	[6]	[7]	[8]	[9]	[10]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK/PIK3CA-DT_ENST00000435560.1_RNA[11]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK/PIK3CA-DT_ENST00000435560.1_RNA[12]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK/PIK3CA-DT_ENST00000435560.1_RNA[13]	PIK3CA_ENST00000643187.1_INTRON/PIK3CA-DT_ENST00000435560.1_FIVE_PRIME_FLANK[14]	[48]	[49]	[50]	[51]	[52]	[53]	[54]	[55]	[56]	[57]	[58]	[59]	[60]	[61]	[62]	[63]	[64]	[65]	[66]	[67]	[68]	[69]	[70]	[71]	[72]	[73]	[74]	[75]	[76]	[77]	[78]	[79]	[80]	[81]	[82]	[83]	[84]	[85]	[86]	[87]	[88]	[89]	[90]	[91]	[92]	[93]	[94]	[95]	[96]	[97]	[98]	[99]	[100]	[101]	[102]	[103]; 	MAF (Other_Transcripts): 	[0]	[1]	[2]	[3]	[4]	[5]	[6]	[7]	[8]	[9]	[10]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK|PIK3CA-DT_ENST00000435560.1_LINCRNA[11]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK|PIK3CA-DT_ENST00000435560.1_LINCRNA[12]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK|PIK3CA-DT_ENST00000435560.1_LINCRNA[13]	PIK3CA_ENST00000643187.1_INTRON|PIK3CA-DT_ENST00000435560.1_FIVE_PRIME_FLANK[14]	[48]	[49]	[50]	[51]	[52]	[53]	[54]	[55]	[56]	[57]	[58]	[59]	[60]	[61]	[62]	[63]	[64]	[65]	[66]	[67]	[68]	[69]	[70]	[71]	[72]	[73]	[74]	[75]	[76]	[77]	[78]	[79]	[80]	[81]	[82]	[83]	[84]	[85]	[86]	[87]	[88]	[89]	[90]	[91]	[92]	[93]	[94]	[95]	[96]	[97]	[98]	[99]	[100]	[101]	[102]	[103]; ----; ```. Its unclear what is the most correct output ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9013:34,update,update,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9013,2,"['integrat', 'update']","['integration', 'update']"
Deployability,"Whole pipeline working now with updated way of running the alignment step, which is reflected in the PR #2435",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2376#issuecomment-284933374:6,pipeline,pipeline,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2376#issuecomment-284933374,2,"['pipeline', 'update']","['pipeline', 'updated']"
Deployability,"Whoops sorry @magicDGS, I've been out doing workshops. Kicking myself now for not doing this in time for the new beta release. Putting this on my todo for the next few days.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3128#issuecomment-316838737:118,release,release,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3128#issuecomment-316838737,1,['release'],['release']
Deployability,"Why SGA, the currently used assembler for SV pipeline, generates slightly diff results on different runs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1805:45,pipeline,pipeline,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1805,1,['pipeline'],['pipeline']
Deployability,Will add a variable to our Protobuf configuration object - the JSON already an option to set this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2687#issuecomment-300298863:36,configurat,configuration,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2687#issuecomment-300298863,1,['configurat'],['configuration']
Deployability,Will fail until the Barclay upgrade.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4523:28,upgrade,upgrade,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4523,1,['upgrade'],['upgrade']
Deployability,"Will look into this, seems quite strange. . About the exception on Ubuntu I think that is due to a ""low level"" Java issue. Are you using the same JDK version? Currently gatk is compiled using Java 8.... I think the latest revision should do. If ""java -version"" return something that is not 1.8.??? the that is the probable cause. At any rate this is not a programming bug in GATK. At worst it would be caused by a binary building issue when that binary was compiled and package. If your SDK is 1.8.??? I would suggest that you try to compile and install it from source code instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6045#issuecomment-517027140:546,install,install,546,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6045#issuecomment-517027140,1,['install'],['install']
Deployability,Will your workflow be ready for the Jan 9 release?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3769:42,release,release,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769,1,['release'],['release']
Deployability,"With a service account key set, it worked like a charm:. ```; $ ./gatk-launch PrintReadsSpark -I gs://jpmartin-testing-project/hellbender-test-inputs/CEUTrio.HiSeq.WGS.b37.ch20.1m-2m.NA12878.bam -O gs://jpmartin-testing-project/test-output/readcount --shardedOutput true -- --sparkRunner GCS --cluster jps-test-cluster; (...); [November 20, 2017 6:17:08 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.72 minutes.; Runtime.totalMemory()=670040064; Job [13c93a62-96d0-456e-91d1-ef7b20f1236b] finished successfully.; ```. Though I understand that [this is expected](https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894). So next I tried it without any `HELLBEND*` environment variable and it worked as well!. ```; Job [6e2f2c6b-921a-4fdf-a42e-0706216b2098] finished successfully.; (...); $ gsutil ls -lh gs://jpmartin-testing-project/test-output/readcount/; 0 B 2017-11-20T18:28:27Z gs://jpmartin-testing-project/test-output/readcount/; 0 B 2017-11-20T18:28:52Z gs://jpmartin-testing-project/test-output/readcount/_SUCCESS; 120.25 MiB 2017-11-20T18:28:51Z gs://jpmartin-testing-project/test-output/readcount/part-r-00000.bam; ```. This is with `GOOGLE_APPLICATION_CREDENTIALS` set, as I believe is part of the GATK README instructions. Next I went to my repro code and tried it again with v30. It failed (`StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account.`) I'm not sure why but the new version is certainly an improvement over the previous one since it fixes `PrintReadsSpark`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-345788205:404,pipeline,pipelines,404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-345788205,1,['pipeline'],['pipelines']
Deployability,"With allele-specific annotations and filtering in the new exome pipeline, this should be helpful. (I was using it for debugging merging Mutect2 perAlleleAnnotations for MT data.)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5697:64,pipeline,pipeline,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5697,1,['pipeline'],['pipeline']
Deployability,"With the GATK gCNV having great performance results on the first round of evaluations it is ready to be used to call on ExAC. The following things need to be done first:. - Set up gCNV workflow to run on SGE (since exome samples are stored on prem). - Decide on target filtering strategy. . - Decide on the number of samples to use to learn the model (PoN). - Get some truth data to do QC, for example CNV calls from Genome STRiP on matched genome samples in gnomAD. - Design an interval list for samples in ExAC that do not mention one in their metadata. One possible solution could be to use cluster assignment of a sample to choose the interval list pertaining to that cluster. - (Optional) Consider importing list of common CNV regions into gCNV. To make job of gCNV inference easier we could use the list of common CNV regions that was obtained from Genome STRiP calls. To start @ldgauthier suggested using samples sequenced using latest Illumina capture protocol (Standard_Exome_Sequencing_v4) to get the ball rolling",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4738:1016,rolling,rolling,1016,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4738,1,['rolling'],['rolling']
Deployability,"With the addition of denoised-copy-ratio output in #5823, there are probably enough outputs to warrant this. Might also check other CNV tools (I've personally been thinking we should do this in DenoiseReadCounts as well). Should highlight in release notes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6128:242,release,release,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6128,1,['release'],['release']
Deployability,"With the addition of the Owner configuration mechanism to GATK, we're going to need to fold (most of) `gatk-launch` into Java, so that the Spark settings can be loaded from Owner before `spark-submit` or `gcloud` are invoked. Note that we'll still need to have a thin GATK launcher script for the sake of the tab completion, which requires that we invoke GATK using a unique command name.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3503:31,configurat,configuration,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3503,1,['configurat'],['configuration']
Deployability,With updated command:. > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb-0.8.1-proto-3.0.0-beta-1+uuid-static-jar-with-dependencies.jar libtiledbgenomicsdb.so; > + jar xf genomicsdb-0.8.1-proto-3.0.0-beta-1+uuid-static-jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: warning: you do not have execution permission for `./libtiledbgenomicsdb.so'; > linux-vdso.so.1 (0x00007ffca79df000); > libpthread.so.0 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libpthread.so.0 (0x00007f146cb0c000); > libz.so.1 => not found; > libuuid.so.1 => not found; > librt.so.1 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/librt.so.1 (0x00007f146c902000); > libm.so.6 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libm.so.6 (0x00007f146c5fd000); > libc.so.6 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libc.so.6 (0x00007f146c25f000); > /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib64/ld-linux-x86-64.so.2 (0x000055ddfd95d000); > + md5sum libtiledbgenomicsdb.so; > 83007be5ce8b0c832b539b21b6c0d68d libtiledbgenomicsdb.so,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357064392:5,update,updated,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357064392,1,['update'],['updated']
Deployability,With which frequency will you make point-releases? I'm afraid that incompatibilities will make me stick to an unreleased GATK4 dependency!. I am preparing a PR at this moment to try to get it in!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356297676:41,release,releases,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356297676,1,['release'],['releases']
Deployability,Without JCenter the retrieval of this artifact is failing like:. ```; #16 21.85 A problem occurred evaluating root project 'gatk'.; #16 21.85 > Could not resolve all files for configuration ':runtimeClasspath'.; #16 21.85 > Could not find biz.k11i:xgboost-predictor:0.3.0.; #16 21.85 Searched in the following locations:; #16 21.85 - https://repo.maven.apache.org/maven2/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; #16 21.85 - https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; #16 21.85 - https://oss.sonatype.org/content/repositories/snapshots/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; #16 21.85 - file:/root/.m2/repository/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; #16 21.85 Required by:; #16 21.85 project :; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7830:176,configurat,configuration,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7830,1,['configurat'],['configuration']
Deployability,"Without the curl command, gcloud build failed with this error message: The command '/bin/sh -c apt-get --assume-yes install git-lfs' returned a non-zero code: 100",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6842#issuecomment-696904831:116,install,install,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6842#issuecomment-696904831,1,['install'],['install']
Deployability,"Wonderful! It run through as you instructed. And then I run into R script error as following:. >13:10:07.074 INFO VariantRecalibratorEngine - Evaluating full set of 3600 variants...; > 13:10:07.367 INFO VariantRecalibrator - Executing: Rscript /dsguser/xhong/llfs_workdir/refinement/VQSR/gatk4100v2/c1joint_c1.snp.plots.R; > 13:10:10.758 INFO VariantRecalibrator - Shutting down engine; > [April 17, 2019 1:10:10 PM CDT] org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator done. Elapsed time: 5.48 minutes.; > Runtime.totalMemory()=2298478592; > org.broadinstitute.hellbender.utils.R.RScriptExecutorException:; > Rscript exited with 1; > Command Line: Rscript -e tempLibDir = '/tmp/Rlib.4429476854635893449';source('/llfs_workdir/refinement/VQSR/gatk4100v2/c1joint_c1.snp.plots.; > R');; > Stdout:; > Stderr: Error in library(ggplot2) : there is no package called ‘ggplot2’; > Calls: source -> withVisible -> eval -> eval -> library; > Execution halted; >. Besides ggplot2, grid, and tools, any other R package I need? And also any instruction about R version and installation specified for GATK 4100 that I can follow?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2199#issuecomment-484232588:1081,install,installation,1081,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2199#issuecomment-484232588,1,['install'],['installation']
Deployability,Work is split into two commits:. - Removed undocumented mid-p correction to p-values in exact test of Hardy-Weinberg equilibrium and updated corresponding unit tests.; - Updated expected ExcessHet values in integration test resources and added an update toggle to GnarlyGenotyperIntegrationTest. Various scout cleanups as well. We now report the same value as ExcHet in bcftools. Note that previous values of 3.0103 (corresponding to mid-p values of 0.5) will now be 0.0000. See discussion below and in linked issue for additional details. Closes #7392.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394:133,update,updated,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394,5,"['Update', 'integrat', 'toggle', 'update']","['Updated', 'integration', 'toggle', 'update', 'updated']"
Deployability,Workspace updates in release docs [VS-1202],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8661:10,update,updates,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8661,2,"['release', 'update']","['release', 'updates']"
Deployability,"Would be awesome to implement this in a way that allows running the annotator again with a new resource callset to update the set annotation. . The one limitation of this approach I can think of, compared to the combineVariants functionality, is that it is callset-centric, ie it won't tell us what is present in the resources (and potentially common to multiple resources) but not in our input callset. But I can live with that as long as it is well documented.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2489#issuecomment-287836682:115,update,update,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2489#issuecomment-287836682,1,['update'],['update']
Deployability,Would it be difficult to write a test for this with `numKnown` and `numNovel` > `Integer.MAX_VALUE` just to make sure all the required spots have been updated?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7864#issuecomment-1134849049:151,update,updated,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7864#issuecomment-1134849049,1,['update'],['updated']
Deployability,Would it be possible to update the `gatktool` bioconda repo to ensure that all python dependencies are well installed to run CNNScoreVariants ? It would be really helpful and easier to manage a GATK conda environment.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1735565877:24,update,update,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1735565877,2,"['install', 'update']","['installed', 'update']"
Deployability,Would love to get this into Friday's release. @cmnbroad do you think it's possible?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367392708:37,release,release,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367392708,1,['release'],['release']
Deployability,"Wow, thanks for the detailed comments so far, @davidbenjamin! But perhaps let's quickly chat before you go any further?. There are a lot of things you commented on---temporary integration tests using local files, lots of code/arguments/etc. intentionally copied verbatim over from VQSR/tranches, and entire tools (the ""monolithic"" GMMVariantTrain and ScikitLearnVariantTrain)---that are rather in flux or will be scrapped/cleaned up shortly. That said, the comments on the code inherited from VQSR will certainly be useful in this process!. But it might save you some time if we could chat so I can give you a rough orientation and perhaps point out where the vestigial VQSR code remains. I think focusing discussion on the high level design of the tools that are likely to stay would also be most useful at this stage. Feel free to throw something on my calendar!. In the end, I think we will probably just retain the BGMM backend + the versions of the tools in the ""scalable"" package. I left the ""monolithic"" GMMVariantTrain and ScikitLearnVariantTrain tools in this branch so I could do one round of tieout. That tieout came out OK, so I think we'll abandon the monolithic tools, along with all the associated code outside of the scalable package. If it helps, I can go ahead and remove that stuff from this draft PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7659#issuecomment-1029393942:176,integrat,integration,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7659#issuecomment-1029393942,1,['integrat'],['integration']
Deployability,"Wow. How on Earth did we avoid this for so long?. On Wed, Jan 24, 2018 at 4:39 PM droazen <notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> @yfarjoun; > <https://github.com/yfarjoun> We have an update on this! We've identified; > the bug:; >; > - When AbstractFeatureReader.getFeatureReader() tries to open a .vcf.gz; > that doesn't have an index, it returns a TribbleIndexedFeatureReader; > instead of a TabixFeatureReader, because methods.isTabix() returns; > false when an index is not present.; > - TribbleIndexedFeatureReader, in turn, opens a Java vanilla; > GZIPInputStream, instead of the BlockCompressedInputStream that gets; > opened when you create a TabixFeatureReader.; > - GZIPInputStream, in turn, has a *confirmed bug* filed against it in; > Oracle's bug tracker (see; > https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that; > it inappropriately relies on the available() method to detect; > end-of-file, which is never safe to do given the contract of; > available(); > - As the final piece in the ghastly puzzle, implementations of; > SeekableStream in htsjdk do not implement available() at all, instead; > using the default implementation which always returns 0.; >; > As a result of this combination of bugs in Java's GZIPInputStream itself; > and bugs in htsjdk's SeekableStream classes, end-of-file can be detected; > prematurely when within 26 bytes of the end of a block, due to the; > following code in GZIPInputStream.readTrailer():; >; > if (this.in.available() > 0 || n > 26) {; > ....; > }; > return true; // EOF; >; > Where n is the number of bytes left to inflate in the current block.; >; > The solution is to replace all usages of the bugged GZIPInputStream with; > BlockCompressedInputStream in tribble in htsjdk (at least, for points in; > the code where the input is known to be block-gzipped rather than regular; > gzipped). For due diligence we should also implement available(); > correctly for all implementations",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725:225,update,update,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725,1,['update'],['update']
Deployability,Write a hardcoded one-off pipeline with stubs for each tool in the read pre-processing pipeline.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/459:26,pipeline,pipeline,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/459,2,['pipeline'],['pipeline']
Deployability,Write a stub end-to-end integration test for the ReadsPreprocessingPipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/761:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/761,1,['integrat'],['integration']
Deployability,Write a tribble codec for parsing Picard interval_list format (+ integration tests in GATK),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5788:65,integrat,integration,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5788,1,['integrat'],['integration']
Deployability,Write basic integration tests for CRAM support using PrintReads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/675:12,integrat,integration,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/675,1,['integrat'],['integration']
Deployability,Write common interfaces for the different kinds of transforms we identify in the dataflow read pre-processing pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/463:110,pipeline,pipeline,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/463,1,['pipeline'],['pipeline']
Deployability,Write integration test for GermlineCNVCaller for single sample calling,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3002:6,integrat,integration,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3002,1,['integrat'],['integration']
Deployability,Write stub implementations of all tools in the dataflow reads pre-processing pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/464:77,pipeline,pipeline,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/464,1,['pipeline'],['pipeline']
Deployability,"Writing output via NIO is currently broken, as reported by @jean-philippe-martin:. ```; /home/jpmartin/build/install/gatk/bin/gatk PrintReads -I inputs/CEUTrio.HiSeq.WEx.b37.NA12892.bam -L 10:1000000-2000000 -O gs://jpmartin/staging/out_tmp.bam; htsjdk.samtools.util.RuntimeIOException: Error opening file: /home/jpmartin/gs:/jpmartin/staging/out_tmp.bam; at htsjdk.samtools.SAMFileWriterFactory.makeBAMWriter(SAMFileWriterFactory.java:246); ```. Now that the read support is in good shape, let's get the writing end working -- should hopefully be an easy fix.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2422:109,install,install,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2422,1,['install'],['install']
Deployability,"Writing reads was fixed in https://github.com/broadinstitute/gatk/commit/73f2a62bee52518b57a985717770ed3a64d83243, but unfortunately the same problem occurs with variants. This commit (https://github.com/broadinstitute/gatk/commit/a861a23b544012fb8f69358a3999dd587d343547) fixes the problem for variants, when deployed with a Hadoop-BAM fix (https://github.com/HadoopGenomics/Hadoop-BAM/pull/143).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3485:310,deploy,deployed,310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3485,1,['deploy'],['deployed']
Deployability,"X). ![unnamed](https://cloud.githubusercontent.com/assets/15305869/26426249/ce3ffb68-40a5-11e7-8002-6ea4f8513eea.png). A naive calculation of the relative X ploidy, i.e. calculating X_pcov = (X_total_read_counts / autosome_total_read_count) for all samples, performing a 2-mean clustering, and dividing the X_pcov by the lower ploidy cluster mean reveals that indeed, the X conting has twice more coverage on _average_ in XX samples:; ![image](https://cloud.githubusercontent.com/assets/15305869/26426348/2b2d6982-40a6-11e7-8eca-e93916bfc80c.png). Further investigation shows that the wrong behavior of TargetCoverageSexGenotyper stems from the lack of robustness of Poisson regression to outliers: there are a number of targets in the X contig with anomalously high coverage (200x median!). In the absence of Y coverage data (and bias adjustment), higher ploidy genotypes are always favored (in this case, XX). Solution: either filter read counts for outliers before calculating Poisson log likelihoods, or simply use the naive median-based ploidy estimates and perform genotyping on the estimated ploidies (rather than target-resolved read counts). The latter is proven to be robust to outliers. Update: it turns out that the issue can be fixed by simply taking into account bait count as a multiplicative bias. Otherwise, the distribution of raw read counts is multimodal and far from Poisson:; ![image](https://cloud.githubusercontent.com/assets/15305869/26516437/54da4930-4254-11e7-9093-5e5fe1e0e28e.png). Correcting for bait count yields a neat over-dispersed Poisson:; ![image](https://cloud.githubusercontent.com/assets/15305869/26516442/68d9ba4c-4254-11e7-82f0-c182f2485d67.png). Todo:; - [x] bait count target annotations; - [x] take bait count into account in TargetCoverageSexGenotyper model; - [x] PAR region blacklisting via command line in TargetCoverageSexGenotyper; - [ ] unit test for bait count functionality of TargetAnnotator; - [x] unit tests for genotyping with only X coverage",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3015:1736,Update,Update,1736,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3015,1,['Update'],['Update']
Deployability,"Y. On Mon, Nov 14, 2016 at 6:19 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > From what I understand of the referenced thread, the ""incorrect"" interval; > list may always be around, so we may never be able to just blow up on it.; > Would it perhaps be more viable to add an option to toggle the level of; > stringency, ie choose in the command line whether to blow up or skip on; > these invalid intervals?; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260495927,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0uvegvUmCq7_G7U2PSuTpvIYl0wQks5q-Ox0gaJpZM4JNjE-; > . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260519118). So, would adding a toggle be acceptable? And more importantly, can we make stringent validation default, with the option to not blow up on silly exome files? Will production accept that?. ---. @yfarjoun commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260617185). let me talk with production to see if we can post-facto change the exome; file... On Mon, Nov 14, 2016 at 8:27 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > So, would adding a toggle be acceptable? And more importantly, can we make; > stringent validation default, with the option to not blow up on silly exome; > files? Will production accept that?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260519118,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0tUTNAAyuk3m_2cJ8j_3KYroaqB1ks5q-QpsgaJpZM4JNjE-; > . ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broad",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2520:2493,toggle,toggle,2493,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2520,1,['toggle'],['toggle']
Deployability,"Yea, I believe the header mismatching has to do with the canonical header lines in the gatk being updated in the middle of this work. htsjdk doesn't discriminate between bad header line count fields so there are a number of sloppy header lines like this. I will update my genomicsDB branch to perform a proper check of the allele specific annotations based on the new version now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355645211:98,update,updated,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355645211,2,['update'],"['update', 'updated']"
Deployability,Yeah - the integration tests cover this case. I had some trouble adding unit tests for this because of #5356 .,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5357#issuecomment-432873687:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5357#issuecomment-432873687,1,['integrat'],['integration']
Deployability,"Yeah - there is a limited set of allowed values for `GeneTranscriptType` and the one in this particular Mouse transcript (`IG_D_pseudogene`) is not among them. The values for `GeneTranscriptType` were modeled off the human Gencode files, but the GTF spec allows for arbitrary values in that field. I talked with @jamesemery about this and it ultimately comes down to my want for Funcotator to fail rather than produce bad / erroneous annotations. The parsers / codecs will need to be updated to allow for arbitrary values in this field, and the parser should be reviewed for other fields that allow for this as well. It may be beneficial in the medium-term to switch the codec over to the GFF3 codec that @kachulis wrote.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7054#issuecomment-767748314:484,update,updated,484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7054#issuecomment-767748314,1,['update'],['updated']
Deployability,"Yeah - this makes 2 assumptions: the data are evenly distributed and that progress is constant. This isn't the most accurate way to do this, but something is better than nothing. . There is another implementation that I considered - base the remaining time on the time it has taken for the last `N` updates. This would account for bursty processing times, but would also result in wildly fluctuating estimates (because it would still assume a uniform distribution of data). We cam also do something like this with a sliding window average to smooth it out. If you prefer another implementation I can change it, but again - something is better than nothing. . I don't want to have to scan the input data to make the progress bar work - that seems way too heavy-handed and would slow everything down. The tradeoff doesn't seem worth it. . For small files it doesn't matter anyway, so I'm not too concerned. . This arose for me because I've been needing to wait many hours for jobs to finish and I would like an estimate of when I cam expect it to finish.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684488371:299,update,updates,299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684488371,2,['update'],['updates']
Deployability,Yeah we really should be updating the changelog / making releases regularly for user-facing changes... The three items Kylee lists above were in fact added since the previous release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8883#issuecomment-2183523818:57,release,releases,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8883#issuecomment-2183523818,2,['release'],"['release', 'releases']"
Deployability,"Yeah, apparently some of these tests weren't running before (maybe because of the VariantContext equality failures caused by the global source setting) ? Anyway, there is an old [ticket](https://github.com/broadinstitute/gatk/issues/6997) to update AlleleFrequencyQC to embrace `VariantEvalEngine` once this PR goes in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827893191:242,update,update,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827893191,1,['update'],['update']
Deployability,"Yeah, the goofy name is just a placeholder, as is the separate tool itself. Unless there are any objections (@fleharty @mwalker174?) or I run into any unforeseen snafus or parameter ambiguities along the way, I am going to roll the multisample-segmentation functionality into ModelSegments. We can toggle this functionality by passing multiple `--denoised-copy-ratios` and `--allelic-counts` arguments, e.g.:. ```; gatk ModelSegments ; --normal-allelic-counts normal.allelicCounts.tsv (this is only used for het genotyping); --denoised-copy-ratios normal.denoisedCR.tsv; --denoised-copy-ratios tumor-1.denoisedCR.tsv; ...; --denoised-copy-ratios tumor-N.denoisedCR.tsv; --allelic-counts normal.allelicCounts.tsv; --allelic-counts tumor-1.allelicCounts.tsv; ...; --allelic-counts tumor-N.allelicCounts.tsv \; -O .; --output-prefix joint-segmentation; ```. This will perform both het genotyping and joint segmentation, but will yield a Picard interval-list `joint-segmentation.interval_list` as its sole output. (Although we could proceed to perform MCMC model inference on each sample in series, we'll stop at segmentation to enforce the scattering of inference across samples, which will be quicker.) We can also allow for copy-ratio-only and allelic-count-only modes. Users can use this joint segmentation in their own downstream tools, but we can also allow ModelSegments to ingest it via in a new `--segments` argument:. ```; gatk ModelSegments; --normal-allelic-counts normal.allelicCounts.tsv (equivalently, we could omit this and adjust minimum-total-allele-count-case, as is done in the WDL); --allelic-counts normal.allelicCounts.tsv; --denoised-copy-ratios normal.denoisedCR.tsv; --segments joint-segmentation.interval_list; -O .; --output-prefix normal. gatk ModelSegments; --normal-allelic-counts normal.allelicCounts.tsv; --allelic-counts tumor-1.allelicCounts.tsv; --denoised-copy-ratios tumor-1.denoisedCR.tsv; --segments joint-segmentation.interval_list; -O .; --output-prefix tumor-1. ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607313549:298,toggle,toggle,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607313549,1,['toggle'],['toggle']
Deployability,"Yeah, the workaround was simply to add the library jar to the classpath and not try to compile them together. I created the issue to soon, Sorry. . As for the NIO library, it is for AWS S3. We are adapting this one https://github.com/Upplication/Amazon-S3-FileSystem-NIO2 to meet our needs. We didn't like the way it handles s3 endpoints because AWS EMR Spark clusters don't support s3 uri's with that particular syntax. Our version modifies it to support normal s3 uri's without endpoints, instead setting the endpoint with a configuration parameter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431:527,configurat,configuration,527,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431,2,['configurat'],['configuration']
Deployability,"Yeah, there are a few stackoverflow and github threads about this issue.; https://stackoverflow.com/questions/21784641/installation-issue-with-matplotlib-python. I tried the suggestion there, and it resolved it. I wish I knew what introduced it though, because I previously was able to import gcnvkernel without doing this (though I don't recall when the last time I did so was):. Create a file ~/.matplotlib/matplotlibrc there and add the following code: backend: TkAgg",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356110333:119,install,installation-issue-with-matplotlib-python,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356110333,1,['install'],['installation-issue-with-matplotlib-python']
Deployability,"Yeah, there is a reblocking bug in 4.2.5.0. It's fixed in master, but we are waiting on a Google NIO fix for requester-pays buckets before we release a new version. If the number of samples you have works with GenotypeGVCFs, then there's certainly nothing wrong with that. I also plan on taking a look at haploid genotypes in Gnarly this week, but I understand if you don't have a lot of faith in that considering how long the other fix has taken. :-D",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1068422151:142,release,release,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1068422151,1,['release'],['release']
Deployability,"Yeah, this should be updated to mirror the final version of the test we put in for GATK3.7.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2323#issuecomment-271640684:21,update,updated,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2323#issuecomment-271640684,1,['update'],['updated']
Deployability,"Yeah, we'd obviously like to fix any bugs, and having the test case will be really useful. We might be able to get to it before the release, but it won't be for a little bit.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3528#issuecomment-332945722:132,release,release,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3528#issuecomment-332945722,1,['release'],['release']
Deployability,"Yep, right now that's what would happen. The previous behavior was that GenomicsDB would return likelihoods for up to 50 alts and then no likelihoods for more than 50 and GenotypeGVCFs I think would subset 7-49 ALTs down to 6 and drop sites with more than 50 ALTs, which is sort of the computational efficiency compromise. I personally don't trust a diploid site with 50 ALTs. I believe the old CombineGVCFs behavior capped the number of likelihoods, so ploidy 1 could have more than 50 ALTs, but higher ploidies would have fewer. So the current plan is to separate the max alts for GGVCFs and GenomicsDB so that the GenomicsDB max alts to combine can be greater and thus convey enough information for GGVCFs to subset down to its max alts, if desired. But if you want to be conservative with memory, you could set them to be equal and low. Should we filter sites with too many alts, which is the recommendation for the GnarlyGenotyper pipeline, rather than drop them, like GGVCFs used to do?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023521998:936,pipeline,pipeline,936,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023521998,1,['pipeline'],['pipeline']
Deployability,"Yes - Funcotator supports this out of the box right now (including for MT chromosomes). Funcotator is still a beta tool, but will be out of beta _very_ soon. There is some documentation on the [forums](https://gatkforums.broadinstitute.org/dsde/discussion/11193/funcotator-information-and-tutorial/) as well as in the GATK Docs. All the documentation needs to be updated but none of it should be wrong. If you run the HaplotypeCaller output VCF through Funcotator you'll get many annotations. Protein position is one of them. However, this is the position of the actual change in the protein sequence, rather than the variant locus. The distinction is that there can be indels that change bases in position X and the protein sequence doesn't differ until position X+Z (for example in short tandem repeats, if one repeat is deleted).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5431#issuecomment-439981502:363,update,updated,363,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5431#issuecomment-439981502,1,['update'],['updated']
Deployability,"Yes - trying to run the integration test so that I can update the outputs, but keep getting transient docker pull errors.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8655#issuecomment-1898811668:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8655#issuecomment-1898811668,2,"['integrat', 'update']","['integration', 'update']"
Deployability,"Yes @rong923, go with >= 4.1.1.0 and you are safe. I ve been running hundreds of pipelines without a problem now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-487724137:81,pipeline,pipelines,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-487724137,1,['pipeline'],['pipelines']
Deployability,"Yes I think we can get rid of these. > On Sep 26, 2017, at 7:34 AM, tedsharpe <notifications@github.com> wrote:; > ; > I'm fine with it.; > If the skipped tests are the primary irritant let's just delete them.; > ; > > On Sep 25, 2017, at 8:47 PM, Steve Huang <notifications@github.com> wrote:; > > ; > > I am OK with removing it, since our pipeline seems to have been stabilized without it for almost 6 months now. What do you think @cwhelan @tedsharpe ?; > > ; > > —; > > You are receiving this because you were mentioned.; > > Reply to this email directly, view it on GitHub, or mute the thread.; > > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3612#issuecomment-332184271:341,pipeline,pipeline,341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3612#issuecomment-332184271,1,['pipeline'],['pipeline']
Deployability,"Yes PathSeq has generally been used with longer reads in the past and also with BWA. I suspect with the shorter reads, novel splice sites are getting missed by PathSeq. You could turn down the match threshold to 16 (half the read length) to help this further, or even hard-filter any aligned read, but you do risk losing some microbial reads at this length. . You're also right that in your case, using the mate information would be useful, but this would not be appropriate, for example, when there are host-pathogen chimeras, such as virus integration events.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6687#issuecomment-652638341:542,integrat,integration,542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6687#issuecomment-652638341,1,['integrat'],['integration']
Deployability,"Yes our cluster had this version. I asked them to upgrade it to 2.27.5 and tried that one. Still same error at the same exact chromosome location:. `ERROR	2023-02-01 16:32:52	Slice	Reference MD5 mismatch for slice 0:248735807-248774361, AAGATTTGTG...AAGTCTAAGC; [Wed Feb 01 16:32:52 CST 2023] picard.analysis.CollectInsertSizeMetrics done. Elapsed time: 4.70 minutes.; Runtime.totalMemory()=5790236672; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; Exception in thread ""main"" htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248735807, span 38555, expected MD5 51a4da6ed30bd549660b19193faae437; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:592); 	at picard.analysis.SinglePassSamProgram.makeItSo(SinglePassSamProgram.java:129); 	at picard.analysis.SinglePassSamProgram.doWork(SinglePassSamProgram.java:77); 	at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:205); 	at picard.cmdline.PicardCommandLine.instanceMain(PicardCommandLine.java:94); 	at picard.cmdline.PicardCommandLine.main(PicardCommandLine.java:104)`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1413949994:50,upgrade,upgrade,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1413949994,1,['upgrade'],['upgrade']
Deployability,"Yes, ./gradlew shadowJar did work. I have the full JDK installed. I checked. ./gradlew javadoc FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-592746838:55,install,installed,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-592746838,1,['install'],['installed']
Deployability,"Yes, @jamesemery and myself will get a patch for this in time for the 4.2 release. Since it works when you pass `-Dsamjdk.reference_fasta`, it's almost certainly just a wiring issue in the tool where the reference is not being propagated to htsjdk correctly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7060#issuecomment-769411561:39,patch,patch,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7060#issuecomment-769411561,2,"['patch', 'release']","['patch', 'release']"
Deployability,"Yes, @magicDGS I have answered a continuous stream of questions on indel realignment in the forum and these questions are ongoing. Here's one I answered just last week: http://gatkforums.broadinstitute.org/gatk/discussion/comment/39359#Comment_39359. So it appears that it is a step that folks continue to use. . I would add that indel realignment is especially important for Mutect1 pipelines, which continues as the standard in somatic calling, pending performance of Mutect2. Even if Mutect2 were to outperform Mutect1 calling, because of the extreme difference in compute between the two, I conjecture folks will continue to use Mutect1. In fact, the only sane way to output a BAM for the entirety of a somatic sample set is via indel realignment. Somatic folks are keen on manual review and indel realignment is the cheapest way to get there. Here's another scenerio for which indel realignment is useful: the case of a low coverage site where multiple haplotypes are present. These cannot be resolved by HaplotypeCaller if the difference in allele depth between reads supporting either haplotype does not pass some threshold. In this case, sites receive `./.` no calls. Indel realignment using a known sites resource can aid in the resolution of haplotypes at sites that correspond to common population variants. One could argue that the cohort-level analysis could aid in resolution of these, but it may be that large cohorts are a luxury that cannot be afforded by many research groups. ### I vote yes please to porting the indel realignment pipeline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307895094:33,continuous,continuous,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307895094,3,"['continuous', 'pipeline']","['continuous', 'pipeline', 'pipelines']"
Deployability,"Yes, Hadoop-BAM uses the NIO API to do file merging, whereas in GATK we were using the Hadoop APIs (and therefore the GCS<->HDFS adapter) to do it. It looks like there are a couple of things needed in GCS-NIO to use the NIO API for this.; 1. https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1450 so that we don't have to special-case `gs` URIs to remove everything except the scheme and host when looking up the filesystem (see https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L40); 2. https://github.com/GoogleCloudPlatform/google-cloud-java/issues/813 to support path matching (https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L90). There may be more, as I stopped there. The best way forward is probably to go back to the old code in GATK while the deficiencies in GCS-NIO are fixed and then released. The stacktrace I got for 1 was:. ```; java.lang.IllegalArgumentException: GCS FileSystem URIs mustn't have: port, userinfo, path, query, or fragment: gs://gatk-demo-tom/TEST/markdups.parts/_SUCCESS; 	at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:192); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:83); 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:336); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:40); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:54); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); ```. And for 2:. ```; java.lang.UnsupportedOperationException; 	at com.google.cloud.s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265132050:944,release,released,944,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265132050,1,['release'],['released']
Deployability,"Yes, I would like to move to 17 since it's the newest long term support release. There are some changes between 8 and 17 though which will require additional work, particularly rewriting our documentation system. I'm worried there are issue around restricted reflection which will be problematic or require rewriting to use SPI instead of direct reflection. If it's working for you though thats' a good sign. . I haven' really looked into the jvm variants much. I think our goal would be to be compatible with all 17 jdks, but if Corretto is faster than other jdk variants it's very possible we could use it. (Assuming it has a sane license).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7842#issuecomment-1123038041:72,release,release,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7842#issuecomment-1123038041,1,['release'],['release']
Deployability,"Yes, also recall that @asmirnov239 tried to address #4397, but that led to #5217, so we reverted. We can try to address all of these issues again correctly if it's low-hanging fruit (which it probably is) and if it'll bring the overall cost of the pipeline down significantly. However, for the most part, I think bringing down costs in the gCNV step will have more impact. Thanks for diagnosing and pointing out these issues. You should feel free to open PRs against the gCNV code as well!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5382#issuecomment-435050904:248,pipeline,pipeline,248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5382#issuecomment-435050904,1,['pipeline'],['pipeline']
Deployability,"Yes, if you have Version Control integration enabled, you can select the branch, and then any commit, or group of commits, in order to see the diffs. So once its read, I'll be able to look at just the diffs between the initial GATK3 commit and your commit(s) right from within IntelliJ.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-416341795:33,integrat,integration,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-416341795,1,['integrat'],['integration']
Deployability,"Yes, that is easy to do. The guidance on how much memory to leave wasnt clear on the docs. Is there a rule of thumb on how much we should leave? We can do whatever makes sense. the command is something like:. ```. /home/exacloud/gscratch/prime-seq/java/java8/bin/java \; -Djava.io.tmpdir=/mnt/scratch/prime-seq/tmp.5E76utMagnGenomicsDB_Append_Merge_2020-11-04_09-17-56-Job1 \; -Xmx104g \; -Xms104g \; -Xss2m \; -jar /home/exacloud/gscratch/prime-seq/bin/GenomeAnalysisTK4.jar GenomicsDBImport \; -V <Repeated 183 times for gVCFs> \ ; --genomicsdb-update-workspace-path /home/exacloud/gscratch/prime-seq/workDir/9a2611e8-0112-1039-8c80-f8f3fc869aa5/Job1.work/WGS_Nov_1300.gdb \; --batch-size 50 \; --consolidate \; --genomicsdb-shared-posixfs-optimizations. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-724293565:547,update,update-workspace-path,547,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-724293565,2,['update'],['update-workspace-path']
Deployability,"Yes, the count of the 30x cram took a very fast 1.67 minutes. . .```; /gatk-4.1.0.0/gatk CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn --num-executors 20 --executor-cores 6 --driver-memory 6g; Using GATK jar /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-package-4.1.0.0-spark.jar; Running:; /share/pkg/spark/2.1.0/install/bin/spark-submit --master yarn --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --num-executors 20 --executor-cores 6 --driver-memory 6g /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-package-4.1.0.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; ^C[farrell@scc-hadoop gatk.sv]$ ^C; [farrell@scc-hadoop gatk.sv]$ ./gatk-4.1.0.0/gatk CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn --num-executors 20 --executor-cores 6 --executor-memory 6g; Using GATK jar /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-pac",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:501,install,install,501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912,1,['install'],['install']
Deployability,"Yes, the return value for Picard tools are not propagated properly when run through GATK. We'll try to get the fix in for the next release. Closing as a dup of https://github.com/broadinstitute/gatk/issues/4329.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4433#issuecomment-367324573:131,release,release,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4433#issuecomment-367324573,1,['release'],['release']
Deployability,"Yes, the same error message was reported in https://github.com/broadinstitute/gatk/issues/5094. It was supposedly fixed by a patch to the Pipelines API. GCS-NIO has support for a list of retriable codes in the `CloudStorageConfiguration`, see there:. https://github.com/googleapis/google-cloud-java/blob/master/google-cloud-clients/google-cloud-contrib/google-cloud-nio/src/main/java/com/google/cloud/storage/contrib/nio/CloudStorageConfiguration.java. I think GATK calls this somewhere. It certainly should.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548517465:125,patch,patch,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548517465,2,"['Pipeline', 'patch']","['Pipelines', 'patch']"
Deployability,"Yes, this issue is not yet fully resolved. We intend to make additional progress in reducing vulnerabilities in our dependencies in the next GATK release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1546114646:146,release,release,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1546114646,1,['release'],['release']
Deployability,"Yes, you need to use java 8 at the moment. You don't have to remove your existing java installation, you can add a second one. It's annoying, which is why we're finally updating to java 17 (the newest long term release). You'll have the opposite problem then though... Sorry!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452502399:87,install,installation,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452502399,2,"['install', 'release']","['installation', 'release']"
Deployability,"You can currently specify additional spark configuration with the --conf argument, so you could override the registrator that way. I think you'd have to update gatk-launch as well as build.gradle to get it to work, and currently gatk-launch is shared with gatk-protected. Probably the best solution is going to be to extract all the hardcoded configurations into a configuration file that can be changed on a per project basis. There's some movement to this in gatk public at the moment, but we haven't settled on a solution yet I think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2337#issuecomment-272484533:43,configurat,configuration,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2337#issuecomment-272484533,4,"['configurat', 'update']","['configuration', 'configurations', 'update']"
Deployability,"You found a bug! It looks like the code is expecting a reference or interval to be provided and since there wasn't one it's falling over. This is definitely a bug and we'll try to fix it for the next release. In the mean time, providing an interval or reference will allow it to run.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6212#issuecomment-541181909:200,release,release,200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6212#issuecomment-541181909,1,['release'],['release']
Deployability,You need to use the versions suggested above. If it is not possible to downgrade your R environment then the only solution would be to use the Conda environment for GATK which installs all the necessary components. Or you may use the docker image we provide.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-2210208499:176,install,installs,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-2210208499,1,['install'],['installs']
Deployability,"You promise? I'm angling for the oldest PR award and I don't want any; competition from you. On Tue, Mar 26, 2019 at 12:35 PM Samuel Friedman <notifications@github.com>; wrote:. > @ldgauthier <https://github.com/ldgauthier> sorry for the delay! Tests; > pass and I addressed all the easy comments. Would it be alright with you if; > we merge this in time for the upcoming release and then do a separate PR; > for the R code cleanups and cumulative Ti/Tv plot?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5251#issuecomment-476735064>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdPjsFog2NhJBJxubcBWjaPU18LIwks5vakxJgaJpZM4XE0cP>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5251#issuecomment-476760922:372,release,release,372,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5251#issuecomment-476760922,1,['release'],['release']
Deployability,You should see `v4.1.4.1-8-g828e2bf-SNAPSHOT` with the `genomicsdb_120_6275_fix`. . Try doing a `git checkout genomicsdb_120_6275_fix` in your git repository and then building again with `./gradlew installDist`. Then run the test again.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-575375379:198,install,installDist,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-575375379,1,['install'],['installDist']
Deployability,You would not have access to docker container options when using the Google backend because the running of your image is all controlled by Pipelines API. You would be able to set that value when running on a local backend but thats probably not portable enough for your workflow.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357313468:139,Pipeline,Pipelines,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357313468,1,['Pipeline'],['Pipelines']
Deployability,"You're totally right about the assembly failures. As we talked about in person yesterday, I worry about biasing the; likelihoods when genotyping positions near homVar variants. For the; record, the conclusion of that conversation was to inject the GGA allele; into the five best assembled haplotypes, though I'm open to something less; heuristic than ""best five"" if anyone has a good idea. (I don't want to; double the number of haplotypes by adding the GGA allele into all of them). On Thu, Apr 4, 2019 at 2:19 PM David Benjamin <notifications@github.com>; wrote:. > Update: I wrote an integration test in my branch that runs M2 with; > --kmer-size 1 --dont-increase-kmer-sizes-for-cycles. It still calls the; > given alleles, whereas in master it does not.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdF1sCpAlqKNa6S_qlL_ypNX_A0eGks5vdkI7gaJpZM4cbxVV>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626:568,Update,Update,568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626,2,"['Update', 'integrat']","['Update', 'integration']"
Deployability,You're using an old version of ojAlgo. I upgraded it for you. There has been improvements to the SVD implementations. (Significant improvements to some users.). Also added a dependency to ojalgo-commons-math3 which gives you wrapper classes to convert back and forth between ojAlgo and Commons Math matrix classes. You no longer need to copy the resulting matrices.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3970:41,upgrade,upgraded,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3970,1,['upgrade'],['upgraded']
Deployability,"Your interpretation sounds right, although I wish the language in the SAM spec were clearer - something like ""if 0x1 is unset, fields 0x2, 0x8, 0x20, 0x40, and 0x80 have no meaning and are ignored by the tools"". SAMRecord.IsValid() returns errors not only for 0x8(mate unmapped)/unpaired read, but also for the other four fields, so all of these errors would need to be removed. IsValid() also triggers an error when an unpaired read has RNEXT set, but the spec. ; doesn't appear to exclude this error. No error is triggered for the unpaired/PNEXT case. . So I agree that it looks like IsValid() should be changed to align with the spec. But I can also imagine potential pitfalls of leaving the GenomicsConverter code the way it is. The code adds spurious information to the bam that might cause problems with legacy versions of the tools. I don't know what the plans are for the state of the existing tool distribution once gatk4 is released. Is it possible that bam files produced in the cloud could make their way into gatk3 workflows, maybe via the sharing of bams between groups? If this happens, then unpaired reads processed in the cloud, with their mate unpaired flags set by the converter, could trigger validation errors when they are fed to the legacy tools. Is there a downside to altering the converter code as well as modifying the ; validator (I don't know what altering google packages entails...)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114510392:934,release,released,934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114510392,1,['release'],['released']
Deployability,"Yup, as you might recall from some discussions with @bhanugandham and @mwalker174, getting automated pipeline-level CNV evaluations up and running was highest on my list before I handed over the role and went on paternity leave. I think these tests would be more useful than unit/integration tests for correctness, but they would almost certainly have to run on CARROT. That said, the current level of unit/integration test coverage is a bit different from that for the somatic tools, because 1) it's difficult to run gCNV in any useful way on Travis infrastructure, and 2) we hadn't decided on a framework/convention for python unit tests at the time the production code went in (although I think @ldgauthier has added some python unit tests by now). So we currently only have plumbing WDL/integration tests on very small data for gCNV---and these only test that the tools run, not for correctness. For somatic CNV, we have unit tests for correctness on small simulated data (e.g., for things like segmentation and modeling classes), but integration tests don't cover correctness (and it would be pretty redundant to use the same simulated data for integration, so I'd rather put effort towards pipeline-level tests on real data). It might be good for you and @mwalker174 to review the current level of testing coverage and understand where things need to be shored up---happy to discuss more.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7261#issuecomment-859563124:101,pipeline,pipeline-level,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7261#issuecomment-859563124,7,"['integrat', 'pipeline']","['integration', 'pipeline-level']"
Deployability,"Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002731707Z 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 2019-10-29T18:18:04.002740306Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 2019-10-29T18:18:04.002745164Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 2019-10-29T18:18:04.002777218Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 2019-10-29T18:18:04.002785268Z 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 2019-10-29T18:18:04.002855927Z 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 2019-10-29T18:18:04.002867030Z 	at org.broadinstitute.hellbender.Main.main(Main.java:291); ```; I am using ExAC lifted to hg38 as a germline resource in mutect2 with only a tumor sample, and getting the above error in filtermutectcalls. I recently updated to v4.1.3.0 to have the latest changes to mutect2. I was not having this issue with v4.0.5.1. Here is extracted information from the VCF which caused the issue. . ```; DP=1;ECNT=2;FS=0.000;MBQ=0,20;MFRL=0,91;MMQ=60,46;MPOS=6;MQ=46.00;POPAF=5.08;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11155815_C_T:11155815:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,20;MFRL=0,91;MMQ=60,46;MPOS=16;MQ=46.00;POPAF=5.08;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11155815_C_T:11155815:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,34;MFRL=0,272;MMQ=60,30;MPOS=25;MQ=30.00;POPAF=4.13;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11350899_C_T:11350899:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,32;MFRL=0,272;MMQ=60,30;MPOS=15;MQ=30.00;POPAF=4.23;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11350899_C_T:11350899:0,0,1,0; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:5318,update,updated,5318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300,1,['update'],['updated']
Deployability,"ZE : 131072; > > 15:10:22.793 INFO PrintReadsSpark - Defaults.REFERENCE_FASTA : null; > > 15:10:22.793 INFO PrintReadsSpark - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; > > 15:10:22.793 INFO PrintReadsSpark - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; > > 15:10:22.793 INFO PrintReadsSpark - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; > > 15:10:22.793 INFO PrintReadsSpark - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; > > 15:10:22.793 INFO PrintReadsSpark - Defaults.USE_CRAM_REF_DOWNLOAD : false; > > 15:10:22.794 INFO PrintReadsSpark - Deflater IntelDeflater; > > 15:10:22.794 INFO PrintReadsSpark - Initializing engine; > > 15:10:22.794 INFO PrintReadsSpark - Done initializing engine; > > 15:10:23.180 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; > > 15:10:25.800 INFO PrintReadsSpark - Shutting down engine; > > [October 18, 2016 3:10:25 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.05 minutes.; > > Runtime.totalMemory()=467140608; > > org.broadinstitute.hellbender.exceptions.GATKException: unable to write bam: java.io.IOException: Invalid splitting BAM index: should contain at least 1 offset and the file size; > > at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:252); > > at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:35); > > at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:348); > > at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); > > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); > > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); > > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2219:3412,pipeline,pipelines,3412,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2219,1,['pipeline'],['pipelines']
Deployability,[10 sample run](https://app.terra.bio/#workspaces/gvs-dev/GVS_190k_Exomes/job_history/10d083c7-2c20-4339-aa2b-70945056de44); [5k sample run](https://app.terra.bio/#workspaces/gvs-dev/GVS_190k_Exomes/job_history/60325b52-7040-492b-82e1-23a58850fb59); [20k sample run](https://app.terra.bio/#workspaces/gvs-dev/GVS_190k_Exomes/job_history/7fee1590-d00c-4038-a575-fd06a9edba1a); [50k sample run](https://app.terra.bio/#workspaces/gvs-dev/GVS_190k_Exomes/job_history/2efb51a2-105a-4f62-a1fe-26b7350706ed); [100k sample run](https://app.terra.bio/#workspaces/gvs-dev/GVS_190k_Exomes/job_history/dba1e793-51e4-47cc-9016-c478628e7252); [integration run](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/19c865ab-69bc-45a3-a897-ff4e5f3d2a53),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8615:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8615,1,['integrat'],['integration']
Deployability,"[GenomicsDB]. As part of our pipeline, we are running the below mentioned command.; What this step does is, reads the vcf files in batch of 50 so in total 4 batches will run for 156 samples, and then for each batch it writes the tables/data to the “genomicsdb” folder. ; ; Parent Command : python /gatk/gatk --java-options -Xmx4g -Xms4g GenomicsDBImport --genomicsdb-workspace-path genomicsdb --batch-size 50 -L chrX:51630606-68003941 --sample-name-map inputs.list --reader-threads 5 -ip 500 --gcs-project-for-requester-pays broad-dsde-methods; ; Child Process : java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx4g -Xms4g -jar /gatk/gatk-package-4.1.8.1-local.jar GenomicsDBImport --genomicsdb-workspace-path genomicsdb --batch-size 50 -L chrX:51630606-68003941 --sample-name-map inputs.list --reader-threads 5 -ip 500 --gcs-project-for-requester-pays broad-dsde-methods; ; The above command took approx. 3.5 hrs to run while writing to local mount of ec2 i.e. EBS volume.; The same command took 8+ hrs (still running as of this email) to run while writing to FSx for luster mount. And surprisingly through AWS Batch – EC2 as part of complete batch/pipeline, took 40+ hrs.; ; The files being read by this process are already cached into FSx as we have been using this same FSx for 5+ days now and these jobs already succeeded with 30-40 hrs of runtime.; ; While we were testing the below manual execution, nothing was running from batch or FSx perspective. Only the 2 manual jobs - one for writing it to local (EBS) and other for FSx. The FSx we are using is the scratch system type with 16.8 TB of space, which gives us a total throughput of 3.3 GB/s.; ; Below is the snapshot of batch 1 executions.; ; EBS Mount Run : Took a total of 1 hr in batch 1; ![EBS Mount Run Batch 1](https://user-images.githubusercontent.com/64221390/151032847-b0bfc418-c2c4-4d8f-a95a-ab0fc0b8eeee.png). FSX ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7646:29,pipeline,pipeline,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7646,1,['pipeline'],['pipeline']
Deployability,[Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/5eb30da2-4afe-4f8e-ad72-e96ac647c588) is a passing Integration test (note - updated truth).; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/7ab3d8de-4325-4ca1-b507-1546f9b89986) is a run of GvsJointCalling using this code.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/494b9661-b5d2-4d4e-8da7-8df84d52e162) is a run of GvsExtractCalset extracting from tables created by this code (with phasing fields in the prepare tables) ; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/dddfefce-f4c7-49bf-aabb-d9b92720b809) is a run of GvsExtractCallset extracing from (OLD) tables created before this code (without phasing fields in the prepare tables).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8655:130,Integrat,Integration,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8655,2,"['Integrat', 'update']","['Integration', 'updated']"
Deployability,[Integration run](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/dfeb564d-5b4d-4b6b-9ffd-88e618acf5e0) in progress,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8454:1,Integrat,Integration,1,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8454,1,['Integrat'],['Integration']
Deployability,"[Release 4.6.0.0](https://github.com/broadinstitute/gatk/releases/tag/4.6.0.0). > By overwhelming popular demand, we've switched back to using the standard ./. representation for no-calls in GenotypeGVCFs and GenomicsDB instead of 0/0 with DP=0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-2224037924:1,Release,Release,1,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-2224037924,2,"['Release', 'release']","['Release', 'releases']"
Deployability,"[Tag 4.2.4.0](https://github.com/broadinstitute/gatk/releases/tag/) doesn't appear to address the fact that WDLs still reference older GATK Docker images and therefore are still vulnerable. This is a quick replacement of all references to outdated GATK images that I could find in this repo's WDLs and WDL-specific JSONs. Note that these changes may be breaking, especially for older workflows; I do not have the bandwidth to individually test each one. The following images were not updated as I couldn't find a suitable replacement, although I suspect several could be replaced with the standard GATK image; * pkrusche/hap.py (I'm not sure this would even be affected by the vulnerability); * broad-gotc-prod/genomes-in-the-cloud; * gatksv/sv-base-mini -- referenced as gatksv/sv-base-mini:b3af2e3 in joint_call_exome_cnvs.wdl; * broadinstitute/oncotator -- referenced as broadinstitute/oncotator:1.9.5.0-eval-gatk-protected in cnv_somatic_oncotator_workflow.wdl, but is a fallback option; * us.gcr.io/broad-dsde-methods/haplochecker; * us.gcr.io/broad-gotc-prod/genomes-in-the-cloud:2.4.2-1552931386. If this PR is accepted, note that all affected WDLs should also have their default tag on Dockstore changed -- only [MitochondriaPipeline](https://dockstore.org/workflows/github.com/broadinstitute/gatk/MitochondriaPipeline:master?tab=files) defaults to master in Dockstore if I recall correctly. [gatk4-rnaseq-germline-snps-indels](https://dockstore.org/workflows/github.com/gatk-workflows/gatk4-rnaseq-germline-snps-indels/gatk4-rnaseq-germline-snps-indels:master?tab=versions) defaults to master but is in the gatk-workflows repo, not this one.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7611:53,release,releases,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7611,2,"['release', 'update']","['releases', 'updated']"
Deployability,[org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:31); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:67); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:8102,Continuous,ContinuousBuildActionExecuter,8102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['Continuous'],['ContinuousBuildActionExecuter']
Deployability,[org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 22:05:55.977 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:47); 22:05:55.979 [ERROR] [org.gradle.i,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:7250,Continuous,ContinuousBuildActionExecuter,7250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['Continuous'],['ContinuousBuildActionExecuter']
Deployability,"\* Opening on behalf of a user on an HPC cluster, my knowledge in this field is a bit limited. ### Affected tool(s) or class(es); gatk HaplotypeCaller. ### Affected version(s); Latest 4.6.0.0 release. ### Description ; When running command, ~16 hours into the run the program crashes. Below is the start of the Java error report file. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f06ed243291, pid=1058615, tid=1058616; #; # JRE version: OpenJDK Runtime Environment (17.0.2+8) (build 17.0.2+8-86); # Java VM: OpenJDK 64-Bit Server VM (17.0.2+8-86, mixed mode, sharing, tiered, compressed oops, compressed class ptrs, g1 gc, linux-amd64); # Problematic frame:; # C [libc.so.6+0xcf291] __memset_avx2_erms+0x11; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/lib/systemd/systemd-coredump %P %u %g %s %t %c %h %e"" (or dumping to /bigdata/ramadugulab/luy/SNPcallingBreeding/core.1058615); #; # If you would like to submit a bug report, please visit:; # https://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. --------------- S U M M A R Y ------------. Command Line: -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /bigdata/operations/pkgadmin/opt/linux/centos/8.x/x86_64/pkgs/gatk/4.6.0.0/gatk-package-4.6.0.0-local.jar HaplotypeCaller -R /rhome/luy/bigdata/genomes/Cclementina_182_v1_2.fa -I AlignedCalToCcl_Scaffolds_MarkDupOut.bam -O AlignedCalToCcl_Scaffolds.vcf.gz -ERC GVCF. Host: Intel(R) Xeon(R) CPU E5-2683 v4 @ 2.10GHz, 64 cores, 20G, Rocky Linux release 8.8 (Green Obsidian); Time: Sat Sep 28 04:11:19 2024 PDT elapsed time: 58592.788414 seconds (0d 16h 16m 32s). --------------- T H R E A D ---------------. Current thread (0x00007f06e4025b70): JavaThread ""main""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8988:192,release,release,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8988,1,['release'],['release']
Deployability,\5.2.6.RELEASE\spring-webmvc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\repository\org\springframework\spring-core\5.2.6.RELEASE\spring-core-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-jcl\5.2.6.RELEASE\spring-jcl-5.2.6.RELEASE.jar;E:\repository\com\google\firebase\firebase-admin\6.8.1\firebase-admin-6.8.1.jar;E:\repository\com\google\api-client\google-api-client\1.25.0\google-api-client-1.25.0.jar;E:\repository\com\google\oauth-client\google-oauth-client\1.25.0\google-oauth-client-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-jackson2\1.25.0\google-http-client-jackson2-1.25.0.jar;E:\repository\com\google\api-client\google-api-client-gson\1.25.0\google-api-client-gson-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-gson\1.25.0\google-http-client-gson-1.25.0.jar;E:\repository\com\google\code\gson\gson\2.8.6\gson-2.8.6.jar;E:\repository\com\google\http-client\google-http-client\1.25.0\google-http-client-1.25.0.jar;E:\repository\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;E:\repository\org\apache\httpcomponents\httpclient\4.5.12\httpclient-4.5.12.jar;E:\repository\org\apa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:5628,RELEASE,RELEASE,5628,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,\Java\jdk1.8.0_121\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\rt.jar;C:\project\push\target\classes;E:\repository\org\springframework\boot\spring-boot-starter-jdbc\2.3.0.RELEASE\spring-boot-starter-jdbc-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter\2.3.0.RELEASE\spring-boot-starter-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot\2.3.0.RELEASE\spring-boot-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-autoconfigure\2.3.0.RELEASE\spring-boot-autoconfigure-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-logging\2.3.0.RELEASE\spring-boot-starter-logging-2.3.0.RELEASE.jar;E:\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\repository\org\apache\logging\log4j\log4j-to-slf4j\2.13.2\log4j-to-slf4j-2.13.2.jar;E:\repository\org\apache\logging\log4j\log4j-api\2.13.2\log4j-api-2.13.2.jar;E:\repository\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;E:\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;E:\repository\org\yaml\snakeyaml\1.26\snakeyaml-1.26.jar;E:\repository\com\zaxxer\HikariCP\3.4.5\HikariCP-3.4.5.jar;E:\repository\org\springframework\spring-jdbc\5.2.6.RELEASE\spring-jdbc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-beans\5.2.6.RELEASE\,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:2133,RELEASE,RELEASE,2133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,\jackson-databind-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-annotations\2.11.0\jackson-annotations-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-core\2.11.0\jackson-core-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.11.0\jackson-datatype-jdk8-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.11.0\jackson-datatype-jsr310-2.11.0.jar;E:\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.11.0\jackson-module-parameter-names-2.11.0.jar;E:\repository\org\springframework\boot\spring-boot-starter-tomcat\2.3.0.RELEASE\spring-boot-starter-tomcat-2.3.0.RELEASE.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.35\tomcat-embed-core-9.0.35.jar;E:\repository\org\glassfish\jakarta.el\3.0.3\jakarta.el-3.0.3.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.35\tomcat-embed-websocket-9.0.35.jar;E:\repository\org\springframework\spring-web\5.2.6.RELEASE\spring-web-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-webmvc\5.2.6.RELEASE\spring-webmvc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\reposi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:4548,RELEASE,RELEASE,4548,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,"\netty\netty-buffer\4.1.49.Final\netty-buffer-4.1.49.Final.jar;E:\repository\io\netty\netty-codec\4.1.49.Final\netty-codec-4.1.49.Final.jar;E:\repository\io\netty\netty-handler\4.1.49.Final\netty-handler-4.1.49.Final.jar;E:\repository\io\netty\netty-resolver\4.1.49.Final\netty-resolver-4.1.49.Final.jar;E:\repository\io\netty\netty-transport\4.1.49.Final\netty-transport-4.1.49.Final.jar;E:\repository\com\alibaba\druid\1.1.6\druid-1.1.6.jar;E:\repository\redis\clients\jedis\3.1.0\jedis-3.1.0.jar;E:\repository\org\apache\commons\commons-pool2\2.8.0\commons-pool2-2.8.0.jar;C:\Program Files\JetBrains\IntelliJ IDEA 2020.1\lib\idea_rt.jar"" com.luz.push.PushApplication; Connected to the target VM, address: '127.0.0.1:62530', transport: 'socket'. . ____ _ __ _ _; /\\ / ___'_ __ _ _(_)_ __ __ _ \ \ \ \; ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \; \\/ ___)| |_)| | | | | || (_| | ) ) ) ); ' |____| .__|_| |_|_| |_\__, | / / / /; =========|_|==============|___/=/_/_/_/; :: Spring Boot :: (v2.3.0.RELEASE). 2020-05-29 15:14:30.695 INFO 12904 --- [ main] com.luz.push.PushApplication : Starting PushApplication on DESKTOP-05L3FQL with PID 12904 (C:\project\push\target\classes started by Sweet in C:\project\push); 2020-05-29 15:14:30.712 INFO 12904 --- [ main] com.luz.push.PushApplication : No active profile set, falling back to default profiles: default; 2020-05-29 15:14:32.088 WARN 12904 --- [ main] o.m.s.mapper.ClassPathMapperScanner : No MyBatis mapper was found in '[com.luz.push]' package. Please check your configuration.; 2020-05-29 15:14:32.662 INFO 12904 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8282 (http); 2020-05-29 15:14:32.675 INFO 12904 --- [ main] o.a.coyote.http11.Http11NioProtocol : Initializing ProtocolHandler [""http-nio-8282""]; 2020-05-29 15:14:32.676 INFO 12904 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat]; 2020-05-29 15:14:32.677 INFO 12904 --- [ main] org.apache.catalina.core.StandardEngin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:11171,RELEASE,RELEASE,11171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:55); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:573); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:125); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.TaskPathProjectEvaluator.configureHierarchy(TaskPathProjectEvaluator.java:42); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultBuildConfigurer.configure(DefaultBuildConfigurer.java:38); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$2.run(DefaultGradleLauncher.java:151); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:3387,configurat,configuration,3387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['configurat'],['configuration']
Deployability,](https://codecov.io/gh/broadinstitute/gatk/pull/4003?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...rg/broadinstitute/hellbender/tools/CountReads.java](https://codecov.io/gh/broadinstitute/gatk/pull/4003/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db3VudFJlYWRzLmphdmE=) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...rg/broadinstitute/hellbender/tools/CountBases.java](https://codecov.io/gh/broadinstitute/gatk/pull/4003/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db3VudEJhc2VzLmphdmE=) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4003/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrLmphdmE=) | `90% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountBasesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4003/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRCYXNlc1NwYXJrLmphdmE=) | `90% <ø> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...ellbender/tools/spark/pipelines/FlagStatSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4003/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvRmxhZ1N0YXRTcGFyay5qYXZh) | `90% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [.../org/broadinstitute/hellbender/tools/FlagStat.java](https://codecov.io/gh/broadinstitute/gatk/pull/4003/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GbGFnU3RhdC5qYXZh) | `76.404% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [.../markduplicates/EstimateLibraryComplexityGATK.java](https://codecov.io/gh/broadinstitute/gatk/pull/4003/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4003#issuecomment-353207913:1815,pipeline,pipelines,1815,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4003#issuecomment-353207913,1,['pipeline'],['pipelines']
Deployability,"_ACC5611A1_XXXXXX_consensusalign_ss_r2.bam -O mutect2/concatenated_ACC5611A1_XXXXXX_mutect2_unfiltered_ss_r2.vcf.gz; 09:39:55.358 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jul 03, 2020 9:39:55 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:39:55.559 INFO Mutect2 - ------------------------------------------------------------; 09:39:55.559 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.0; 09:39:55.559 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:39:55.559 INFO Mutect2 - Executing as ashwini.jeggari@hasta.scilifelab.se on Linux v3.10.0-1062.4.1.el7.x86_64 amd64; 09:39:55.560 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 09:39:55.560 INFO Mutect2 - Start Date/Time: July 3, 2020 9:39:55 AM CEST; 09:39:55.560 INFO Mutect2 - ------------------------------------------------------------; 09:39:55.560 INFO Mutect2 - ------------------------------------------------------------; 09:39:55.560 INFO Mutect2 - HTSJDK Version: 2.22.0; 09:39:55.561 INFO Mutect2 - Picard Version: 2.22.8; 09:39:55.561 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:39:55.561 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:39:55.561 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:39:55.561 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:39:55.561 INFO Mutect2 - Deflater: IntelDeflater; 09:39:55.561 INFO Mutect2 - Inflater: IntelInflater; 09:39:55.561 INFO Mutect2 - GCS max retries/reopens: 20; 09:39:55.561 INFO Mutect2 - Requester pays: disabled; 09:39:55.561 INFO Mutect2 - Initializing engine; 09:39:56.014 INFO FeatureManager - Using codec BE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695:1862,release,release-,1862,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695,1,['release'],['release-']
Deployability,_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:35:26.517 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 18:35:26.517 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 18:35:26.517 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 18:35:26.517 INFO MarkDuplicatesSpark - Requester pays: disabled; 18:35:26.517 INFO MarkDuplicatesSpark - Initializing engine; 18:35:26.517 INFO MarkDuplicatesSpark - Done initializing engine; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/user/wup/miniconda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Suc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875:2463,release,release,2463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875,1,['release'],['release']
Deployability,"_fixes) ; ; 12:52:16.269 INFO GenotypeGVCFs - Initializing engine ; ; terminate called after throwing an instance of 'VariantQueryProcessorException' ; ; what(): VariantQueryProcessorException : Could not open array genomicsdb\_array at workspace: /home/WES-VCFQC/S2\_GenomicsDBImport/temporary/tmp4. Hi, I used GenomicsDBImport to combined 2000 GVCFs. To speed up, I split the bed file and concatenated multiple intervals into a contig. I also met the file locking problem which can be solved by setting  TILEDB\_DISABLE\_FILE\_LOCKING=1 in my Linux system. Currently, I experience some issues with GenotypeGVCFs in GATK version 4.0.3.0. It cannot open ""genomicsdb\_array"" although the directory of genomicsdb\_array does exist. I found someone else has reported this issue here: [https://sites.google.com/a/broadinstitute.org/legacy-gatk-forum-discussions/2018-04-11-2017-12-02/11184-Could-not-open-array-genomicsdbarray-at-workspace-from-GenotypeGVCFs-in-GATK-4000](https://sites.google.com/a/broadinstitute.org/legacy-gatk-forum-discussions/2018-04-11-2017-12-02/11184-Could-not-open-array-genomicsdbarray-at-workspace-from-GenotypeGVCFs-in-GATK-4000) , but except for using the latest version of GATK, it seems like there are no other solutions. I was wondering that how do I fix the issues with GATK 4.0.3.0? Does anyone have a better solution?. I also tried GenotypeGVCFs in GATK 4.2.1.0, but there is a problem in terms of MQ calculation. So I think it's better to stick to the same GATK version in the whole workflow. A USER ERROR has occurred: Bad input: Presence of '-RAW\_MQ' annotation is detected. ; ; This GATK version expects key RAW\_MQandDP with a tuple of sum of squared MQ values and total reads over variant genotypes as the value. ; ; This could indicate that the provided input was produced with an older version of GATK. ; ; Use the argument '--allow-old-rms-mapping-quality-annotation-data' to override and attempt the deprecated MQ calculation. ; ; There may be differences i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7442:5395,a/b,a/broadinstitute,5395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7442,1,['a/b'],['a/broadinstitute']
Deployability,_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --executor-memory 25G --driver-memory 5G /home/genomics/Projects/TomWhitePatches/gatk/build/libs/gatk-package-4.alpha.2-230-g19db939-SNAPSHOT-spark.jar BaseRecalibratorSpark -I hdfs://n001:54310/GATK4TEST/LargeBroadData/WGS-G94982-NA12878.bam -knownSites hdfs://n001:54310/GATK4TEST/DBSNP/dbsnp_138.hg19.vcf.gz -R hdfs://n001:54310/GATK4TEST/OldData/human_g1k_v37.2bit -O hdfs://n001:54310/GATK4TEST/LargeOutput/WGS_BQSR --sparkMaster spark://n001:7077; Picked up JAVA_TOOL_OPTIONS: -XX:+UseG1GC -XX:ParallelGCThreads=4; Picked up JAVA_TOOL_OPTIONS: -XX:+UseG1GC -XX:ParallelGCThreads=4; java.lang.ClassNotFoundException: org.broadinstitute.hellbender.Main; at java.lang.ClassLoader.findClass(ClassLoader.java:530); at org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.scala:26); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.scala:34); at org.apache.spark.util.ChildFirstURLClassLoader.loadClass(MutableURLClassLoader.scala:55); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at java.lang.Class.forName0(Native Method); at java.lang.Class.forName(Class.java:348); at org.apache.spark.util.Utils$.classForName(Utils.scala:229); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:695); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2620#issuecomment-299259877:2414,deploy,deploy,2414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2620#issuecomment-299259877,6,['deploy'],['deploy']
Deployability,` | `78 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `82.759% <100%> (ø)` | `20 <1> (ø)` | :arrow_down: |; | [...e/spark/datasources/VariantsSparkSinkUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmtVbml0VGVzdC5qYXZh) | `83.212% <100%> (+1.041%)` | `28 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <100%> (ø)` | `2 <1> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.741% <100%> (ø)` | `13 <0> (ø)` | :arrow_down: |; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmsuamF2YQ==) | `78.125% <57.143%> (-11.53%)` | `8 <1> (-1)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5574#issuecomment-456044768:2182,pipeline,pipelines,2182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5574#issuecomment-456044768,1,['pipeline'],['pipelines']
Deployability,"`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2416 +/- ##; ===============================================; - Coverage 76.224% 76.218% -0.006% ; + Complexity 10820 10819 -1 ; ===============================================; Files 750 750 ; Lines 39422 39420 -2 ; Branches 6883 6883 ; ===============================================; - Hits 30049 30045 -4 ; - Misses 6755 6757 +2 ; Partials 2618 2618; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2416?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...alkers/genotyper/afcalc/CustomAFPriorProvider.java](https://codecov.io/gh/broadinstitute/gatk/compare/75f633135798145079ddb32c7dc2e884d47de4b3...3f2a04aa9723a86271120755e6be8945ff103532?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQ3VzdG9tQUZQcmlvclByb3ZpZGVyLmphdmE=) | `94.444% <ø> (-0.556%)` | `6 <ø> (-1)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/75f633135798145079ddb32c7dc2e884d47de4b3...3f2a04aa9723a86271120755e6be8945ff103532?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `66.667% <ø> (-3.333%)` | `10% <ø> (ø)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2416?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2416?src=pr&el=footer). Last update [75f6331...3f2a04a](https://codecov.io/gh/broadinstitute/gatk/compare/75f633135798145079ddb32c7dc2e884d47de4b3...3f2a04aa9723a86271120755e6be8945ff103532?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2416#issuecomment-281483092:2059,update,update,2059,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2416#issuecomment-281483092,2,['update'],['update']
Deployability,"`FuncotateSegments` currently uses `org.apache.commons:commons-configuration` for its configuration file(s). It should ideally be migrated to use Owner like the rest of the GATK. One way this could be done: have the user specify columns and their aliases uses a List of specially-formatted Strings, such as:. ```; Col1(Alias1, Alias2),Col2(Alias1),Col3(....etc.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5963:63,configurat,configuration,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5963,2,['configurat'],['configuration']
Deployability,"`GATKTool` uses stricter sequence dictionary validation settings for CRAM vs. reference than for non-CRAM vs. reference:. ```; if ( hasCramInput() ) {; // Use stricter validation for CRAM vs. the reference; SequenceDictionaryUtils.validateCRAMDictionaryAgainstReference(refDict, readDict);; }; else {; // Use standard validation settings for non-CRAM reads input vs. the reference; SequenceDictionaryUtils.validateDictionaries(""reference"", refDict, ""reads"", readDict);; }; ```. `GATKSparkTool.validateToolInputs()` should be patched to do the same, AFTER https://github.com/broadinstitute/gatk/issues/966 is done and cram support is in a usable state.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1179:525,patch,patched,525,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1179,1,['patch'],['patched']
Deployability,"`HaplotypeCallerIntegrationTest` has two kinds of tests: exact-match tests against prior output to let us know when ANYTHING changes, and looser concordance tests against GATK3 output. The exact-match tests should stay, and are not a problem now that we've implemented an `UPDATE_EXACT_MATCH_EXPECTED_OUTPUTS` toggle to update them all at once. The GATK3 concordance tests, however, are past their usefulness. We've now diverged sufficiently from GATK3 that we need a new truth set for `HaplotypeCaller`. We should change the tests to assert concordance against this new truth set (whatever it ends up being) rather than GATK 3 output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5532:310,toggle,toggle,310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5532,2,"['toggle', 'update']","['toggle', 'update']"
Deployability,"`HaplotypeCaller` works with unphased genotypes. The unphased genotype A/B represent the phased genotpyes A/B _and_ B/A, for a combinatorial factor of 2, in contrast to A/A, which has a combinatorial factor of 1. It does not appear that the genotype likelihoods emitted by `GenotypeLikelihoodCalculator` account for this. That is, the genotype likelihoods for heterozygous diploid genotypes are too small by a factor of 2. The relevant code in `GenotypeLikelihoodCalculator` is. ``` java; private double[] genotypeLikelihoods( [arguments]) {; ...; for (int g = 0; g < genotypeCount; g++) {; result[g] = MathUtils.sum(readLikelihoodsByGenotypeIndex[g], 0, readCount) - denominator;; [ we need result += (GenotypeAlleleCounts of genotype g).log10CombinationCount() ]; }; ...; ```. @ldgauthier @vruano do you agree?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2019:71,A/B,A/B,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2019,2,['A/B'],['A/B']
Deployability,"`IntegrationTestSpec` currently ignores leading/trailing whitespace by default when doing its comparison against expected outputs. This is problematic given that whitespace can include things like field delimiters, leading to bugs like the one fixed in https://github.com/broadinstitute/gatk/pull/7559. We should change the default to *not* ignore leading/trailing whitespace. Tests that have a legitimate reason for ignoring it can then explicitly opt-in by calling `setTrimWhiteSpace()`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7560:1,Integrat,IntegrationTestSpec,1,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7560,1,['Integrat'],['IntegrationTestSpec']
Deployability,`ReadBAMTransform.getReadsFromBAMFilesSharded()` (which we rely upon to produce initial `PCollection<Read>`s in our pipelines) relies on flawed conversion from `SAMRecord` to `Read` (`ReadConverter.makeRead()`) that (among other things) does not encode attributes correctly. It also does not support unmapped reads. We should fix these issues.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/509:116,pipeline,pipelines,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/509,1,['pipeline'],['pipelines']
Deployability,"`ReadsPipelineSpark` should override `GATKSparkTool.getRecommendedNumReducers()` to provide an appropriate default value for the `numReducers` argument. The default gives us one partition per 10MB of input, which may be too small for this pipeline (it was kept small on purpose due to memory issues, but perhaps these have been resolved?)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1660:239,pipeline,pipeline,239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1660,1,['pipeline'],['pipeline']
Deployability,"`SortReadFileSpark` gives a log message like this:; ```; 17:31:00.062 INFO SortReadFileSpark - Using %s reducers2744; ```; It's trivial, but I think the [logger](https://github.com/broadinstitute/gatk/blob/c18e7800ed85c55f81387cf02fdcbf6cb3aaaf5e/src/main/java/org/broadinstitute/hellbender/tools/spark/pipelines/SortReadFileSpark.java#L41) needs a small fix.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3095:303,pipeline,pipelines,303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3095,1,['pipeline'],['pipelines']
Deployability,"`TableReader` and `TableWriter` only work on `java.io.File`, and need to be updated to accept `java.nio.Path` so we can Path-enable the tools that have code paths that depend on this package, like FilterByOrientationBias.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5747:76,update,updated,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5747,1,['update'],['updated']
Deployability,"`Tribble` codecs can only read data from `Locatable` data sources (those with contig + start + end position). Recently we have found a need for reading in files that do not have locatable data (e.g. tabular data that has a `Gene Name` and a set of attributes, but no start/stop location). Tribble should be updated to have a baseline `Interface` that is generic (and not necessarily `Locatable`). Our current interface / infrastructure can inherit from that for data sources that are `Locatable`. Then a new `Codec` can be created for data sources that are not Locatable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3760:307,update,updated,307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3760,1,['update'],['updated']
Deployability,"`ValidateVariants` performs several checks that go above and beyond what the VCF spec requires for VCF files (e.g. throwing an exception if a variant has an alt allele but has a genotype of hom ref [as found by this user](https://gatk.broadinstitute.org/hc/en-us/community/posts/360061452132-GATK4-RNAseq-short-variant-discovery-SNPs-Indels-)). This is good - it helps catch logic errors in our and others' pipelines. . However, we should add a flag to `ValidateVariants` that will cause it to validate solely based on the VCF spec and not the more strict guidelines.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6553:407,pipeline,pipelines,407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6553,1,['pipeline'],['pipelines']
Deployability,"`ValidateVariants` requires a large amount of memory (>16Gb) to validate a GVCF when another GVCF is used as the interval list. This is not the case if a regular interval list is used instead. This comes up in the production `ReblockGVCFs` pipeline since we validate the reblocked GVCF using the input (unreblocked) GVCF as the interval list to validate over (with `-L`). For now we can just use larger memory machines to run this tool, but it is confusing to me why using a ~4Gb GVCF as an interval list would cause such a large increase in memory requirement.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8608:240,pipeline,pipeline,240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8608,1,['pipeline'],['pipeline']
Deployability,"``. 2. Using full path with non-ascii characters in base directory as tmp path and it failed:; ```; /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx8G -Djava.io.tmpdir=/data/xieduo/Łuksza_2022_Nature"" BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; Using GATK jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -Djava.io.tmpdir=/data/xieduo/Łuksza_2022_Nature -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; 13:36:33.528 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:36:33.547 WARN NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (No such file or directory); 13:36:33.550 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:5944,pipeline,pipeline,5944,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,``. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5021?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [.../org/broadinstitute/hellbender/tools/FlagStat.java](https://codecov.io/gh/broadinstitute/gatk/pull/5021/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GbGFnU3RhdC5qYXZh) | `76.404% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...rg/broadinstitute/hellbender/tools/SplitReads.java](https://codecov.io/gh/broadinstitute/gatk/pull/5021/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9TcGxpdFJlYWRzLmphdmE=) | `90% <ø> (ø)` | `20 <0> (ø)` | :arrow_down: |; | [...broadinstitute/hellbender/tools/GetSampleName.java](https://codecov.io/gh/broadinstitute/gatk/pull/5021/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9HZXRTYW1wbGVOYW1lLmphdmE=) | `66.667% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...ellbender/tools/spark/pipelines/FlagStatSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5021/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvRmxhZ1N0YXRTcGFyay5qYXZh) | `90% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...tools/walkers/haplotypecaller/HaplotypeCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/5021/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXIuamF2YQ==) | `0% <0%> (-76.923%)` | `0% <0%> (-17%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5021/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5021#issuecomment-405986092:1806,pipeline,pipelines,1806,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5021#issuecomment-405986092,1,['pipeline'],['pipelines']
Deployability,"``; #!/bin/bash. export HADOOP_CONF_DIR=/etc/hadoop; export HADOOP_HOME=/mnt/hadoop-latest; export JAVA_HOME=/mnt/jre1.8.0_192; export SPARK_HOME=/mnt/spark-2.3.1-bin-without-hadoop; export HADOOP_USER_NAME=hadoop. # export SPARK_DIST_CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath). TEST_DIR=""hdfs://cromwellhadooptest:8020/user/hadoop/gatk/small""; COMMON_DIR=""hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common""; INPUT_DIR=""$TEST_DIR/input""; OUTPUT_DIR=""$TEST_DIR/output"". input_bam=""$INPUT_DIR/small_CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam""; output_vcf_basename=""$OUTPUT_DIR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21"". ref_fasta=""$COMMON_DIR/human_g1k_v37.20.21.fasta""; known_sites=""$COMMON_DIR/dbsnp_138.b37.20.21.vcf"". gatk ReadsPipelineSpark \; -R ${ref_fasta} \; -I ${input_bam} \; -O ${output_vcf_basename}.vcf \; --known-sites ${known_sites} \; -pairHMM AVX_LOGLESS_CACHING \; --spark-verbosity DEBUG \; -- --spark-runner SPARK --spark-master yarn-cluster \; # --conf 'spark.submit.deployMode=cluster'; ```. #### Expected behavior. ReadsPipelineSpark should be able to resolve the hdfs file path: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. #### Actual behavior; The tool tries to access: `file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta` even when the input is: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. Verified that the file is accesible through hdfs:; ```; (gatk) root@2e738717b9c1:/gatk/mnt# $HADOOP_HOME/bin/hdfs dfs -ls hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; -rw-r--r-- 3 hadoop supergroup 113008112 2020-07-29 15:54 hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; ```; When I specify input as: `hdfs://cromwellhadooptest/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`, (i.e. without the port) I get the same error. **Stack trace for this**:; ```; *******************************************************************",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6730:1414,deploy,deployMode,1414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730,1,['deploy'],['deployMode']
Deployability,"``; #### Actual behavior. Extra 'C'. ---. @ldgauthier commented on [Thu Oct 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-252063664). I think this happened when there was a AC ->C deletion originally called that got subset out because it didn't meet the QUAL threshold, but the trimming that was done on the final allele set didn't work right because of the *. ---. @vdauwera commented on [Fri Oct 07 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-252204232). Do we have GVCF snippets to reproduce this? . ---. @ldgauthier commented on [Fri Oct 07 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-252247496). I don't know what intermediates we save on the cloud but maybe @yfarjoun is willing to help. ---. @yfarjoun commented on [Fri Oct 07 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-252258477). I don't have special privileges on the cloud...requests like this need to; go through pipeline-help...sorry. Y. On Fri, Oct 7, 2016 at 9:08 AM, ldgauthier notifications@github.com wrote:. > I don't know what intermediates we save on the cloud but maybe @yfarjoun; > https://github.com/yfarjoun is willing to help.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-252247496,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0lAsJd9NECpPP0JYVp2ziDhga0B9ks5qxkRUgaJpZM4KQT_3; > . ---. @vdauwera commented on [Wed Oct 26 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-256499771). Writing pipeline-help now and cc'ing everyone involved in this thread. Will try to get some kind of protocol set up for debugging things that happen in the cloud pipeline, because I expect this will happen again. But if it gets too complicated we could also mock up some fake records that would re",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2959:1772,pipeline,pipeline-help,1772,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2959,1,['pipeline'],['pipeline-help']
Deployability,"```; ......AAAAAAAAAA......; ```; Here we have a homology of exactly 10A's.; When we detect the deletion by studying the alignment signature, the alt haplotype would have two alignments mapped to the reference, one ends just before the G-block, one starts just after the G-block, with the A-block on the alt haplotype mapped to two places.; We follow the left-align/left-justify convention, and place the POS 1-bp before the left most A (hence saying `10A10G` was deleted, as opposed to right-justify which would say `10G10A` deleted, in fact without the convention any contiguous substring of 20 bp long of `10A10G10A` would be correct). However, it can be imagined the homologous sequences flanking the G's are not exactly the same, or may not be the same length (small indels), and the alignments would contain small gaps in their CIGARs. By assuming the homologous sequence are of the same length, which is what we are doing now, we could get the breakpoint location wrong. This is generally not a serious problem, but when the accumulated gap sizes are large enough, we can end up too-far off. A similar issue is when inferring SVLEN for small tandem duplications, where we are assuming the extra copies have the same length. This is not always true and when the `DUP_SEQ_CIGARS` annotation is available, it should be easily fixable. When it is not available, one could use the difference between `SEQ_ALT_HAPLOTYPE` and END-POS for that. #### Steps to reproduce; Run the `StructuralVariationDiscoveryPipelineSpark` pipeline on a site with SV event having different homology length around the breakpoints. #### Expected behavior; Breakpoint inference taking into account of small indels in the micro-homology surrounding the breakpoints. #### Actual behavior; Breakpoint inference assuming homologous sequence surrounding the breakpoints having the same length. #### What could be done:; The inference code could use CIGAR's in the alignment to infer how much to left adjust the breakpoint. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4883:2089,pipeline,pipeline,2089,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4883,1,['pipeline'],['pipeline']
Deployability,"```; ./gatk --version; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk --version; The Genome Analysis Toolkit (GATK) v4.0.12.0-1-g10aa8c7-SNAPSHOT; ```. This is different than the output of the tool --version...; ```; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk PrintReads --version; Version:4.0.12.0-1-g10aa8c7-SNAPSHOT; Tool returned:; 0; ```. I can change this to be that version, or we can change barclay to do it differently and provide more info. It might be useful to print the library versions with both commands as well.. that's printed during the normal run...; ```; 14:19:57.172 INFO PrintReads - HTSJDK Version: 2.18.1; 14:19:57.173 INFO PrintReads - Picard Version: 2.18.16; ```. @cmnbroad What do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272:84,install,install,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272,4,['install'],['install']
Deployability,```; ./gatk-launch FlagStat; ```. gives me this. ```; Running:; /local/dev/akiezun/alphaTesting/gatk/build/install/gatk/bin/gatk FlagStat; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument input was missing: Argument 'input' must be specified at least once.; ```. it needs to add something about -h to see all arguments,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1285:107,install,install,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1285,1,['install'],['install']
Deployability,```; ./gatk-launch PrintReadsSpark -I gs://hellbender/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam -O output -- --sparkRunner GCS --cluster dataproc-cluster-3 --project broad-dsde-dev; ```. fails with . ```; 16/04/27 18:49:12 ERROR org.apache.spark.SparkContext: Error initializing SparkContext.; java.io.FileNotFoundException: File file:/Users/louisb/Workspace/gatk-protected/build/libIntelDeflater.so does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:609); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:822); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:599); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:337); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289); at org.apache.spark.deploy.yarn.Client.copyFileToRemote(Client.scala:317); at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:407); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:471); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:470); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:470); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:468); at scala.collection.immutable.List.foreach(List.scala:318); at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:468); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:727); at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:142); at org.apache.spark,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:937,deploy,deploy,937,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,1,['deploy'],['deploy']
Deployability,```; // Suggested by the akka devs to make sure that we do not get the spark configuration error.; // http://doc.akka.io/docs/akka/snapshot/general/configuration.html#When_using_JarJar__OneJar__Assembly_or_any_jar-bundler; transform(com.github.jengelman.gradle.plugins.shadow.transformers.AppendingTransformer) {; resource = 'reference.conf'; }; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1447:77,configurat,configuration,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1447,2,['configurat'],['configuration']
Deployability,```; 18/01/17 08:24:55 INFO org.bdgenomics.adam.serialization.ADAMKryoRegistrator: Did not find Spark internal class. This is expected for Spark 1.; ``` . Appears hundreds of times in the log output since we upgraded ADAM. This is despite the fact that we're not using spark 1. Maybe there's a way to silence a specific logger?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4186:208,upgrade,upgraded,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4186,1,['upgrade'],['upgraded']
Deployability,"```; ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; ```. shows up at the top of every run, we should fix this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/216:34,configurat,configuration,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/216,2,['configurat'],['configuration']
Deployability,```; build/install/hellbender/bin/hellbender CollectWgsMetrics -I src//test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam -R src//test/resources/org/broadinstitute/hellbender/tools/exome/test_reference.fasta -O CollectWGSMetrics.txt; ```. ```; java.lang.ArrayIndexOutOfBoundsException: 1000; at org.broadinstitute.hellbender.tools.picard.analysis.directed.CollectWgsMetrics.doWork(CollectWgsMetrics.java:161); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:151); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:51); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.main(Main.java:86); ```. note: same bug is present in picard 1.138,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/918:11,install,install,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/918,1,['install'],['install']
Deployability,```; gradle clean installSpark; ./gatk-launch FlagStatSpark -I src/test/resources/org/broadinstitute/hellbender/tools/count_bases.bam ; Missing GATK wrapper script: /Users/droazen/src/hellbender/build/install/gatk/bin/gatk; To generate the wrapper run:. /Users/droazen/src/hellbender/gradlew installDist; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1314:18,install,installSpark,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1314,3,['install'],"['install', 'installDist', 'installSpark']"
Deployability,"```; spark-submit --class org.broadinstitute.hellbender.Main \; --deploy-mode client \; --master yarn-client \; --driver-memory 8G \; --conf spark.driver.maxResultSize=0 \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; --conf spark.yarn.executor.memoryOverhead=600 \; --executor-memory ${execMem}g \; --num-executors $execs \; --executor-cores $cores \; bin/cleanHellbender/gatk/build/libs/gatk-all-*-spark.jar \; ReadsPipelineSpark \; --sparkMaster yarn-client \; -I hdfs:///user/akiezun/CEUTrio.HiSeq.WEx.b37.NA12892.bam \; -R hdfs:///user/droazen/bqsr/human_g1k_v37.2bit \; --programName ${name} \; -O $bamout \; --knownSites hdfs:////user/akiezun/dbsnp_138.b37.excluding_sites_after_129.vcf \; --emit_original_quals \; --duplicates_scoring_strategy SUM_OF_BASE_QUALITIES; ```. exec=24; cores=5; execMem=25. fails with . ```; java.lang.IllegalArgumentException: SimpleInterval is 1 based, so start must be >= 1, start: 0; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:58); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.baq.BAQ.getReferenceWindowForRead(BAQ.java:525); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine$BQSRReferenceWindowFunction.apply(BaseRecalibrationEngine.java:46); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine$BQSRReferenceWindowFunction.apply(BaseRecalibrationEngine.java:41); at org.broadinstitute.hellbender.engine.spark.BroadcastJoinReadsWithRefBases.lambda$addBases$c54addeb$1(BroadcastJoinReadsWithRefBases.java:52); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.coll",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1234:66,deploy,deploy-mode,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1234,1,['deploy'],['deploy-mode']
Deployability,"`ah_var_store` edition: Allows hard-filtering based on a maximum number of alt alleles [VS-1334], as well as fixing GATK Docker image building to use image IDs rather than git hashes [VS-1357]. Integration test _mostly_ successful [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/5d021859-5971-4fd7-8451-086c224fdb00). `GvsQuickstartIntegration` failed with:. ```; The bytes observed (89733530) for 'ExtractFilterTask.GvsCreateFilterSet.BigQuery Query Scanned' differ from those expected (85119360); FAIL!!! The relative difference between these is 0.0514208, which is greater than the allowed tolerance (0.05); ```. Successful tieout run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/04b840f9-9779-48d6-8faa-4425d67ddadb). [VS-1334]: https://broadworkbench.atlassian.net/browse/VS-1334?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ; [VS-1357]: https://broadworkbench.atlassian.net/browse/VS-1357?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8806:194,Integrat,Integration,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8806,1,['Integrat'],['Integration']
Deployability,`com.google.cloud:google-cloud-nio:0.20.4-alpha-20171031.194208-5:shaded` -> `org.broadinstitute:google-cloud-nio-GATK4-custom-patch:0.20.4-alpha-GCS-RETRY-FIX:shaded`; This artifact should be functionally identical to our previous artifact but it's hosted in maven central instead of our artifactory. closes #4008,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4108:127,patch,patch,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4108,1,['patch'],['patch']
Deployability,"`gatk-launch DownsampleSam --help`. ```; /local/dev/akiezun/alphaTesting/gatk/build/install/gatk/bin/gatk DownsampleSam --help |; org.broadinstitute.hellbender.exceptions.GATKException$CommandLineParserInternalException: [R, reference] has already been used. |; at org.broadinstitute.hellbender.cmdline.CommandLineParser.handleArgumentAnnotation(CommandLineParser.java:620) |; at org.broadinstitute.hellbender.cmdline.CommandLineParser.createArgumentDefinitions(CommandLineParser.java:149) |; at org.broadinstitute.hellbender.cmdline.CommandLineParser.<init>(CommandLineParser.java:134) |; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.parseArgs(CommandLineProgram.java:186) |; at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:41) |; at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66) |; at org.broadinstitute.hellbender.Main.main(Main.java:81); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1303:84,install,install,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1303,1,['install'],['install']
Deployability,`testGetReadsFromHadoopBam` broke when we updated dataflow. I've placed this test into the new group 'broken-spark` which will be ignored in travis. When https://github.com/cloudera/spark-dataflow/issues/49 is complete we should re-enable this test.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/581:42,update,updated,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/581,1,['update'],['updated']
Deployability,"a bug fix suggested by Louis.; @lbergelson I don't know how to add a test. Without this you'd see. ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 45 in stage 9.0 failed 8 times, most recent failure: Lost task 45.7 in stage 9.0 (TID 734, shuang-svdps-ceu-w-1.c.broad-dsde-methods.internal, executor 2): java.nio.file.FileSystemNotFoundException: Provider ""gs"" not installed; 	at java.nio.file.Paths.get(Paths.java:147); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferencePath(ReferenceFileSparkSource.java:53); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferenceBases(ReferenceFileSparkSource.java:60); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceMultiSparkSource.getReferenceBases(ReferenceMultiSparkSource.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.getRefBaseString(BreakEndVariantType.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.access$200(BreakEndVariantType.java:20); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType$InterChromosomeBreakend.<init>(BreakEndVariantType.java:253); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType$InterChromosomeBreakend.getOrderedMates(BreakEndVariantType.java:261); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyAndAltHaplotype.toSimpleOrBNDTypes(NovelAdjacencyAndAltHaplotype.java:246); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.SimpleNovelAdjacencyInterpreter.inferType(SimpleNovelAdjacencyInterpreter.java:129); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.SimpleNovelAdjacencyInterpreter.lambda$inferTypeFromSingleContigSimpleChimera$24ddc343$1(SimpleNovelAdjacencyInterpreter.java:107); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:393,install,installed,393,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['install'],['installed']
Deployability,"a commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-260457641). @ldgauthier Now that we have allele-specific VQSR, do we still need this ticket? . ---. @ldgauthier commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-260462851). Yes we do. Sad but true. It's something we've been focusing on with the new VQSR model work, though. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-260467426). Ah, ok. So keep it in the GATK3 repo then, for now? . ---. @ldgauthier commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-260642385). Yes. I believe @lucidtronix is doing VQSR development in GATK3 and we'll port later. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-287837505). @ldgauthier @lucidtronix Any update on this since I heard VQSR got ported to GATK4?. ---. @ldgauthier commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-287905381). It's unlikely the behavior has changed. For gnomad we used hard filters to; address the problem, which is probably a good global recommendation. On Mar 20, 2017 1:35 PM, ""Geraldine Van der Auwera"" <; notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> @lucidtronix; > <https://github.com/lucidtronix> Any update on this since I heard VQSR; > got ported to GATK4?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-287837505>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdLRwdezIkmt3uPqIABWLggVjRN3yks5rnrjegaJpZM4Dt4t7>; > .; >. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/iss",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2508:8205,update,update,8205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2508,1,['update'],['update']
Deployability,"a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :white_check_mark: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.694% <0%> (+2.083%)` | `36% <0%> (ø)` | :x: |; | [...oadinstitute/hellbender/utils/GenomeLocParser.java](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2NQYXJzZXIuamF2YQ==) | `90.083% <0%> (+4.132%)` | `57% <0%> (+2%)` | :white_check_mark: |; | [...ellbender/utils/test/CommandLineProgramTester.java](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0NvbW1hbmRMaW5lUHJvZ3JhbVRlc3Rlci5qYXZh) | `90.476% <0%> (+4.762%)` | `8% <0%> (+1%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2423?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2423?src=pr&el=footer). Last update [5211285...cab0d17](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282342687:3198,update,update,3198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282342687,2,['update'],['update']
Deployability,"a80384b70a8685cc; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Oct 30 15:17:06 2023 -0400. use model.rvs_to_values for registry; inference completes but numerical tests seem off!. commit 5d2062f3301f682dbf427d898521ec6da8338944; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Oct 30 15:03:40 2023 -0400. VarMap and transformed name in register, exact match error to warn. commit 3dca890329396c9afae52aa8779cdfb97c18fa7c; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Oct 25 23:28:32 2023 -0400. inference works! oh wow. commit d056855608fdf222a38a25d8de41f11fa1e82c22; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Oct 24 22:11:30 2023 -0400. past full denoising instantiation and through to first calling epoch before hitting another shape error. commit fcfdb29e79e0652d24a5f509ade6e941f84293c2; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Oct 24 00:17:46 2023 -0400. revert pytensorf. commit 2ec79b362bdfcd34b3ca1736e6327ecbbe2269ad; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Oct 24 00:16:04 2023 -0400. HalfFlat typo. commit 6eb1594d62ed62b992db04c523ffc598845d3b4c; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Oct 23 23:46:42 2023 -0400. added TODOs for nontrivial changes. commit c01754082991c006c8d56f0027138948d792ce75; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Oct 23 23:33:43 2023 -0400. warmup denoising inference runs, a minor miracle! probably incorrect after some nontrivial changes, though. commit 3bf1c5b65d12fe76e499d1b43e58736e31f25f33; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Oct 23 17:13:04 2023 -0400. find and replace, some version bumps. commit 3039e1f01579003518200b9033c5674c3d1de156; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Oct 23 14:30:32 2023 -0400. python 3.10.9, pymc3 3.11.2. commit 4a2c86391990fb01d2e67fc7cf823495eef1ba99; Author: Andrey Smirnov <asmirnov2009@gmail.com>; Date: Sun Oct 23 03:58:36 2022 +0000. Updates to gCNV code for pymc3 upgrades. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322:8351,Update,Updates,8351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322,2,"['Update', 'upgrade']","['Updates', 'upgrades']"
Deployability,a:109); at org.seqdoop.hadoop_bam.BCFSplitGuesser.<init>(BCFSplitGuesser.java:89); at org.seqdoop.hadoop_bam.VCFInputFormat.addGuessedSplits(VCFInputFormat.java:254); at org.seqdoop.hadoop_bam.VCFInputFormat.fixBCFSplits(VCFInputFormat.java:242); at org.seqdoop.hadoop_bam.VCFInputFormat.getSplits(VCFInputFormat.java:221); at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:95); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.rdd.RDD.partitions(RDD.scala:237); at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.rdd.RDD.partitions(RDD.scala:237); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1910); at org.apache.spark.rdd.RDD.count(RDD.scala:1121); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:445); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:47); at org.broadinstitute.hellbender.tools.spark.pipelines.CountVariantsSpark.runTool(CountVariantsSpark.java:39); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:313); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:69); at org.broadinstitute.hellbender.Main.main(Main.java:84),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1815:1858,pipeline,pipelines,1858,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1815,1,['pipeline'],['pipelines']
Deployability,aGVsbGJlbmRlci90b29scy9Db3VudFJlYWRzLmphdmE=) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...rg/broadinstitute/hellbender/tools/CountBases.java](https://codecov.io/gh/broadinstitute/gatk/pull/4003/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db3VudEJhc2VzLmphdmE=) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4003/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrLmphdmE=) | `90% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountBasesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4003/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRCYXNlc1NwYXJrLmphdmE=) | `90% <ø> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...ellbender/tools/spark/pipelines/FlagStatSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4003/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvRmxhZ1N0YXRTcGFyay5qYXZh) | `90% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [.../org/broadinstitute/hellbender/tools/FlagStat.java](https://codecov.io/gh/broadinstitute/gatk/pull/4003/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GbGFnU3RhdC5qYXZh) | `76.404% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [.../markduplicates/EstimateLibraryComplexityGATK.java](https://codecov.io/gh/broadinstitute/gatk/pull/4003/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL21hcmtkdXBsaWNhdGVzL0VzdGltYXRlTGlicmFyeUNvbXBsZXhpdHlHQVRLLmphdmE=) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...broadinstitute/hellbender/tools/GetSampleName.java](https://codecov.io/gh/broadinstitute/gatk/pull/4003/diff?src=pr&el=tree#,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4003#issuecomment-353207913:2118,pipeline,pipelines,2118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4003#issuecomment-353207913,1,['pipeline'],['pipelines']
Deployability,"aJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 ,spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 ,spark.kryoserializer.buffer.max=512m,spark.yarn.executor.memoryOverhead=600 --jar gs://hellbender-test-logs/staging/gatk-package-4.1.0.0-24-g18a95c7-SNAPSHOT-spark_3e9078b7e67707952fa12a0c5c4d2b71.jar -- PrintVariantsSpark --V gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --output gs://hellbender-test-logs/staging/12dc38b0-0b40-49d5-a98e-fe83ca658003.vcf --spark-master yarn; Job [654b5b8e01de4c60bd87d941d4ec8831] submitted.; Waiting for job output...; 19/02/18 16:58:03 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 16:58:09.526 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 16:58:09.705 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/654b5b8e01de4c60bd87d941d4ec8831/gatk-package-4.1.0.0-24-g18a95c7-SNAPSHOT-spark_3e9078b7e67707952fa12a0c5c4d2b71.jar!/com/intel/gkl/native/libgkl_compression.so; 16:58:10.112 INFO PrintVariantsSpark - ------------------------------------------------------------; 16:58:10.113 INFO PrintVariantsSpark - The Genome Analysis Toolkit (GATK) v4.1.0.0-24-g18a95c7-SNAPSHOT; 16:58:10.113 INFO PrintVariantsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:58:10.113 INFO PrintVariantsSpark - E",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:1272,configurat,configuration,1272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['configurat'],['configuration']
Deployability,aW9uVGVzdC5qYXZh) | `1.031% <0.000%> (-98.969%)` | :arrow_down: |; | [...tion/ReferenceBlockConcordanceIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7806/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vUmVmZXJlbmNlQmxvY2tDb25jb3JkYW5jZUludGVncmF0aW9uVGVzdC5qYXZh) | `0.840% <0.000%> (-98.599%)` | :arrow_down: |; | [...tute/hellbender/tools/FlagStatIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7806/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GbGFnU3RhdEludGVncmF0aW9uVGVzdC5qYXZh) | `1.724% <0.000%> (-98.276%)` | :arrow_down: |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7806/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.754% <0.000%> (-98.246%)` | :arrow_down: |; | [...park/pipelines/CountReadsSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7806/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.786% <0.000%> (-98.214%)` | :arrow_down: |; | ... and [190 more](https://codecov.io/gh/broadinstitute/gatk/pull/7806/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7806#issuecomment-1108721366:5196,pipeline,pipelines,5196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7806#issuecomment-1108721366,1,['pipeline'],['pipelines']
Deployability,"ab"" as of scales 0.3.0. This parameter is used repeatedly in the generated R-script via. ```R; scale_fill_gradient(high=""green"", low=""red"", space=""rgb""); ```. #### Steps to reproduce. ```shell; $ R --version; R version 4.1.2 (2021-11-01) -- ""Bird Hippie""; $ rm -rf ~/R; $ R; > install.packages(""ggplot2"", repos=""https://cloud.r-project.org/""); > packageVersion(""scales""); [1] ‘1.3.0’; > quit(); $ gatk --version; The Genome Analysis Toolkit (GATK) v4.5.0.0; HTSJDK Version: 4.1.0; Picard Version: 3.1.1; $ gatk VariantRecalibrator [arguments omitted for brevity]; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.9339186078473502558';source('/path/to/rscript.r');; Stdout: ; Stderr: Error:; ! The `space` argument of `pal_gradient_n()` only supports be ""Lab"" as; of scales 0.3.0.; Backtrace:; ▆; 1. ├─base::source(""/path/to/rscript.r""); 2. │ ├─base::withVisible(eval(ei, envir)); 3. │ └─base::eval(ei, envir); 4. │ └─base::eval(ei, envir); 5. └─ggplot2::scale_fill_gradient(high = ""green"", low = ""red"", space = ""rgb""); 6. ├─ggplot2::continuous_scale(...); 7. │ └─ggplot2::ggproto(...); 8. │ └─rlang::list2(...); 9. └─scales::seq_gradient_pal(low, high, space); 10. └─scales::pal_gradient_n(c(low, high), space = space); 11. └─lifecycle::deprecate_stop(""0.3.0"", ""pal_gradient_n(space = 'only supports be \""Lab\""')""); 12. └─lifecycle:::deprecate_stop0(msg); 13. └─rlang::cnd_signal(...); Execution halted; $ R; > install.packages(""remotes"", repos=""https://cloud.r-project.org/""); > library(remotes); > install_version(""scales"", version=""1.2.1"", repos=""https://cloud.r-project.org/""); > packageVersion(""scales""); [1] ‘1.2.1’; > quit(); $ gatk VariantRecalibrator [arguments omitted for brevity]; $; ```. #### Expected behavior; The output rscript file is used to generate a PDF. #### Actual behavior; Generation of the PDF fails due to an deprecation in the `scales` library causing the `Rscript` command to abort.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664:1978,install,install,1978,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664,1,['install'],['install']
Deployability,"abadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 01:42:05 2017 -0500. hybrid ADVI abstract argument collection w/ flexible default values; hybrid ADVI argument collection for contig ploidy model; hybrid ADVI argument collection for germline denoising and calling model. commit 56e21bf955d3dc0c52aceb384f28cf6173959de0; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 23:18:39 2017 -0500. rewritten python-side coverage metadata table reader using pandas to fix the issues with comment line; change criterion for cohort/case based on whether a contig-ploidy model is provided or not; simulated test files for ploidy determination tool; proper integration test for ploidy determination tool and all edge cases; updated docs for ploidy determination tool. commit 7fa104b2e9170770cfc5b338835e41215d7fd39c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 18:43:17 2017 -0500. kabab case for gCNV-related tools; removed short args (this also partially affected PlotDenoisedCopyRatios and PlotModeledSegments and their integration tests). commit f02cb024331a986213cfd9fae2da706bbc5ddbd9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 18:02:40 2017 -0500. synced with mb_gcnv_python_kernel. commit 2963bbf8c90418d9b88545c93771ae51cf542db9; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 11:38:05 2017 -0500. Fixing typo in travis.yml. commit 6cf589999c716ec66404eb0a2ae4310dd130a772; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 11:13:58 2017 -0500. editable, full path. commit d998f2d5c2b33dd41e291be9bfeaea72fe479b8a; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:56:24 2017 -0500. revert Dockerfile, change yml. commit 930d7486b7d2cf918fcb16dd03394bb9c9f0611b; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:34:46 2017 -0500. more Dockerfile. commit 94112131526b514ef254bcc2c50a239dbae35aa1; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:25:13 2017",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:8122,integrat,integration,8122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['integrat'],['integration']
Deployability,"adPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-ed279998-3783-4f41-8fe5-f44a4fac3ee4; ```. CountReads runs fine..... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 11:36:23.022 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 11:36:25.027 INFO CountReads - ------------------------------------------------------------; 11:36:25.028 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.0.12.0; 11:36:25.028 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:36:25.029 INFO CountReads - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 11:36:25.029 INFO CountReads - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 11:36:25.030 INFO CountReads - Start Date/Time: January 7, 2019 11:36:22 AM EST; 11:36:25.030 INFO CountReads -",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:44007,install,install,44007,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['install'],['install']
Deployability,add CreateVariantIngestFiles integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7071:29,integrat,integration,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7071,1,['integrat'],['integration']
Deployability,add a continuous test in jenkins to ensure that BQSR will continue to run in < 3.5 GB,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1594:6,continuous,continuous,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1594,1,['continuous'],['continuous']
Deployability,add bwa to reads pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1981:17,pipeline,pipeline,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1981,1,['pipeline'],['pipeline']
Deployability,add echocallset as an option for integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8757:33,integrat,integration,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8757,1,['integrat'],['integration']
Deployability,add in service account auth for aou; localize with service account in same vm; update disk size; fix input_vcf to work with manual localization and streaming,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7140:79,update,update,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7140,1,['update'],['update']
Deployability,add scoring strategy for mark dups in Spark. Thus fixes 1 integration…,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1156:58,integrat,integration,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1156,1,['integrat'],['integration']
Deployability,add some metrics to the pipeline to see how well that scales. Metrics should come cheaply because the data RDD is loaded at that point.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1237:24,pipeline,pipeline,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1237,1,['pipeline'],['pipeline']
Deployability,"add-output-sam-program-record false -bam-output. The log of the command that generated the error was :. Using GATK jar /data/genepattern/patches/gatk-4.1.4.0/gatk-package-4.1.4.0-local.jar. Running:. java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /data/genepattern/patches/gatk-4.1.4.0/gatk-package-4.1.4.0-local.jar FilterAlignmentArtifacts --variant tumor.recalibrated.filtered.vcf --input tumor.recalibrated.realigned.bam --reference /data/genepattern/users/.cache/uploads/cache/data.gp.vib.be/pub/genome/Homo_sapiens.UCSC.hg38.fa --bwa-mem-index-image /data/genepattern/users/.cache/uploads/cache/data.gp.vib.be/pub/bwa_index_img/Homo_sapiens.UCSC.hg38.img --output tumor.recalibrated.filtered2.vcf --bam-output tumor.recalibrated.realigned2.bam --verbosity ERROR --tmp-dir TMP --QUIET true. 14:38:44.077 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/data/genepattern/patches/gatk-4.1.4.0/gatk-package-4.1.4.0-local.jar!/com/intel/gkl/native/libgkl_utils.so. 14:38:44.103 INFO SmithWatermanAligner - AVX accelerated SmithWaterman implementation is not supported, falling back to the Java implementation. java.lang.IllegalArgumentException: Program record with group id HalpotypeBAMWriter already exists in SAMFileHeader!. at htsjdk.samtools.SAMFileHeader.addProgramRecord(SAMFileHeader.java:202). at htsjdk.samtools.SAMTextHeaderCodec.parsePGLine(SAMTextHeaderCodec.java:158). at htsjdk.samtools.SAMTextHeaderCodec.decode(SAMTextHeaderCodec.java:107). at htsjdk.samtools.SAMFileHeader.clone(SAMFileHeader.java:398). at org.broadinstitute.hellbender.utils.read.ReadUtils.createCommonSAMWriterFromFactory(ReadUtils.java:1215). at org.broadinstitute.hellbender.utils.read.ReadUtils.createCommonSAMWriter(ReadUtils.java:1163). at org.broadinstitute.hellbender.utils.haplotype.SAMFileDestination.(SAMFileDestination.java:35). at org.broadinstitute.hellbender.util",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6287:1754,patch,patches,1754,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6287,1,['patch'],['patches']
Deployability,"added bcftools, upgraded gcloud version",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7369:16,upgrade,upgraded,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7369,1,['upgrade'],['upgraded']
Deployability,"added to the instructions on the GATK Github README.md. If gcc is not installed, HaplotypeCaller complains that the AVX instruction set is not available, even when it is. It falls back to slower LOGLESS_CACHING PairHMM. The fault is missing libgomp1, which is a required dependency of gcc. Since this documentation request is related to a ""bug"" that comes about from not installing necessary libraries, I'll include the bug report format below, in case someone else searches for solutions to this problem, as suggested by @lbergelson. ### Affected tool(s) or class(es); _HaplotypeCaller_, or any other tool that uses _PairHMM_. ### Affected version(s); -I think all as of _2019-06-20_. I tested on release version _4.1.2.0_. #### Steps to reproduce; Run HaplotypeCaller from a released jar on an Ubuntu VM that supports the AVX instruction set. Critically, do *NOT* install gcc on the VM. Installing gcc fixes this problem. #### Expected behavior; If you install gcc, that results in the installation of libgomp1, which allows the Intel library to load and use AVX acceleration. You could probably install libgomp1 on its own, but I did not test that.; > 14:51:01.013 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/ubuntu/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; > 14:51:01.015 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/ubuntu/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; > 14:51:01.053 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; > 14:51:01.053 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; > 14:51:01.054 INFO IntelPairHmm - Available threads: 16; > 14:51:01.054 INFO IntelPairHmm - Requested threads: 8; > 14:51:01.054 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation. #### Actual behavior; Without libgomp1, AVX acceleration doesn't work:; > 19:43:36.387 INFO Nat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6012:1037,install,install,1037,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6012,2,['install'],"['install', 'installation']"
Deployability,adding snappy.disable=true to prevent htsjdk from using snappy; this is a temporary solution for #2026 until we can patch htsjdk to fix incompatibilities with more modern snappy. fixes #2026,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2028:116,patch,patch,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2028,1,['patch'],['patch']
Deployability,"addresses specops issues:; - #268 https://github.com/broadinstitute/dsp-spec-ops/issues/268; - #270 https://github.com/broadinstitute/dsp-spec-ops/issues/270. similar changes as the PR for ExtractCohort:; - added custom classes `ExtractFeaturesRecord` that implements `Locatable`; - refactored attribute building from these records; - now that the records are `Locatable`s, can use `OverlapDetector` to filter locations down to only desired intervals (including excluded sites). also:; - enable using intervals input (-L) rather than specifying min-location and max-location. updated WDL to support scattering using SplitIntervals (based off of CohortExtract); - add back AS_QD to headers (currently headers are shared between ExtractCohort and ExtractFeatures - AS_QD not needed for cohort but is needed for features)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7184:576,update,updated,576,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7184,1,['update'],['updated']
Deployability,"ader.getFeatureReader(AbstractFeatureReader.java:110); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:74); 	at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:58); 	at org.broadinstitute.hellbender.tools.walkers.mutect.CreateSomaticPanelOfNormals.doWork(CreateSomaticPanelOfNormals.java:122); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); Caused by: htsjdk.tribble.TribbleException$InvalidHeader: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file; 	at htsjdk.variant.vcf.VCFCodec.readActualHeader(VCFCodec.java:115); 	at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:83); 	at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:36); 	at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:251); 	... 12 more; ```. Either we should update the documentation to point users to use the `--arguments_file` instead (let me know) or we should update the functionality to accept a list of files. Currently, the option is described as:. > --vcfsListFile,-vcfs:File VCFs for samples to include. May be specified either one at a time, or as one or more .list file containing multiple VCFs, one per line. This argument must be specified at least once. Required. . Here is the test data:; [createsomaticpanelofnormals_testcase_shlee.zip](https://github.com/broadinstitute/gatk/files/1251993/createsomaticpanelofnormals_testcase_shlee.zip)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3510:4685,update,update,4685,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3510,2,['update'],['update']
Deployability,advanced isn't integrated either,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2130#issuecomment-248046609:15,integrat,integrated,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2130#issuecomment-248046609,1,['integrat'],['integrated']
Deployability,"after the addition of travis_wait gradle check travis was executing gradle check twice; with ./gradlew and one with gradle. This was happening because it was being run onces explicitly in the install phase and once implicitly in the script phase. this was causing some strange issues. instead of using travis_wait, I made the dataflow cloud tests output status information as they go; this similarly prevents travis from timing out due to lack of output, but doesn't need the travis_wait; if we add any really long running dataflow tests, or really highly spammy ones we'll have to revisit this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/853:192,install,install,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/853,1,['install'],['install']
Deployability,"age](https://user-images.githubusercontent.com/45641912/139333822-aa0b3adc-b92e-4317-a75e-da322f96822f.png). This is using the dictionary defined earlier called **standard_runtime**. ![image](https://user-images.githubusercontent.com/45641912/139333917-0d97ef00-88e6-4340-8cee-e3295127eab8.png). This dictionary uses a variable called **machine_mem** which is calculated using the workflow's **small_task_mem** input, which is configurable. ![image](https://user-images.githubusercontent.com/45641912/139333959-4465b06d-b2ce-4ab2-bae9-285e25168c1d.png); ![image](https://user-images.githubusercontent.com/45641912/139333973-c8e2c1f6-0efd-4f45-9d1e-10f6c4a2baac.png). To allocate more memory for the Funcotate task, one has to define this **small_task_mem** variable at the workflow level. This effectively changes the amount of memory for all tasks that make use of this dictionary, rather than just the Funcotate task. Funcotate has two input variables **default_ram_mb** and **default_disk_space_gb** which have no bearing on the memory and disk space configuration for the task.; ![image](https://user-images.githubusercontent.com/45641912/139334343-8e614e17-27ef-4fef-815d-fe6e8c39ffef.png). This leads to user confusion when they see these variables in the method configuration page, put values in, and don't see their Funcotate task use the specified values.; ![image](https://user-images.githubusercontent.com/45641912/139334535-4b9a0353-910e-4764-a6d2-a454f4d344aa.png). #### Steps to reproduce; Define the input variables **default_ram_mb** and **default_disk_space_gb** for a run of the Mutect2 workflow to be different from the amounts defined by [*small_task_mem*](https://github.com/broadinstitute/gatk/blob/4.1.8.1/scripts/mutect2_wdl/mutect2.wdl#L140) and [**disk_space**](https://github.com/broadinstitute/gatk/blob/4.1.8.1/scripts/mutect2_wdl/mutect2.wdl#L407). #### Expected behavior; Defining the input variables **default_ram_mb** and **default_disk_space_gb** allows you to speci",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7532:1515,configurat,configuration,1515,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7532,1,['configurat'],['configuration']
Deployability,ah update array extract tool,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6827:3,update,update,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6827,1,['update'],['update']
Deployability,"ah, well, ok, I could have pushed the updated version now though. Now that the branch's deleted I guess I'll have to redo that in a different PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2387#issuecomment-277358564:38,update,updated,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2387#issuecomment-277358564,1,['update'],['updated']
Deployability,"ah---this is what I get for making an example inputs file when we really didn't need one and for choosing the full AoU 1k release (vat_kc_vat_1) as the default. I wanted to run the validations here because it is the largest dataset and it is the AoU data (not just Anvil data) BUT it has no values for gvs_all_ac or gvs_all_an yet because that step wasn't implemented by the time of creation. (Validation #9 was added by Lee recently) The table vat_jul18 does have those values as it was created just last week, but may get cleaned up...so this might be a good best practices question for what we run this on in the future if there is ever an automated version?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7365#issuecomment-886085289:122,release,release,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7365#issuecomment-886085289,1,['release'],['release']
Deployability,ah-mito-update,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6867:8,update,update,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6867,1,['update'],['update']
Deployability,"ail.com>; Date: Wed Dec 6 10:25:13 2017 -0500. more Dockerfile. commit 7d2646240a65f5c0f09f5f25f3e19e9d9bf004d9; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:06:11 2017 -0500. more Dockerfile. commit f1235c25aeba85570b5ce389a34975f1b7b5ec3c; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 09:39:46 2017 -0500. Dockerfile edit. commit 3df84dd4693f28e4e8b34fd33f877e99749dffce; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 16:08:06 2017 -0500. Update test PoNs. commit 2c3b20e62a1cba7af24c0b0846eb1629422f51e6; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 15:49:38 2017 -0500. Update test files. commit c65c6e9144ef396792364ab2e06b7b436bb97684; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 15:30:59 2017 -0500. Adding no-GC/do-GC WDL tests. commit 56451843066a456d9cf8e6eac55ae4df2c518ec3; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 12:51:17 2017 -0500. Updates to handle SAM header changes from sl_wgs_acnv_headers and updates to mb_gcnv_python_kernel. commit d02d04df684a2820308a1d1c2bfda4b7d1c5f05e; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Nov 13 12:52:33 2017 -0500. Added CLIs and WDL for python gCNV pipeline. commit 66ed74b68375d43514ef84658e7a6c771ed9053c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Nov 15 01:50:03 2017 -0500. Polished code, ready for review; ; gCNV computational kernel (initial release); ; renaming gammas_s to psi_s to uniformity (sample-specific unexplained variance); ; renamed determine_ploidy_and_depth.py to cohort_determine_ploidy_and_depth.py; finite-temperature forward-backward algorithm; in the ploidy model, replaced alpha_j (NB over-dispersion) with psi_j (unexplained variance) for uniformity. Also, added the possibility of sample-specific unexplained variance in the germline contig ploidy model; ; updated I/O routines and CLIs according to team discussion; ; updated I/O routines and CLIs according to team discussion; ;",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:10039,update,updates,10039,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,3,"['Update', 'update']","['Updates', 'updates']"
Deployability,alFileSystem.java:609); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:822); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:599); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:337); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289); at org.apache.spark.deploy.yarn.Client.copyFileToRemote(Client.scala:317); at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:407); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:471); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:470); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:470); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:468); at scala.collection.immutable.List.foreach(List.scala:318); at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:468); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:727); at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:142); at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:57); at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144); at org.apache.spark.SparkContext.<init>(SparkContext.scala:530); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSpa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:1505,deploy,deploy,1505,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,2,['deploy'],['deploy']
Deployability,alibratorIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6036/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQmFzZVJlY2FsaWJyYXRvckludGVncmF0aW9uVGVzdC5qYXZh) | `1.031% <0%> (-98.969%)` | `1% <0%> (-7%)` | |; | [...s/variantutils/VariantsToTableIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6036/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGVJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.042% <0%> (-98.958%)` | `1% <0%> (-21%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6036/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.754% <0%> (-98.246%)` | `1% <0%> (-6%)` | |; | [...park/pipelines/CountReadsSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6036/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.786% <0%> (-98.214%)` | `1% <0%> (-8%)` | |; | [...bender/tools/spark/PileupSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6036/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QaWxldXBTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `2.041% <0%> (-97.959%)` | `2% <0%> (-13%)` | |; | [...tute/hellbender/tools/FlagStatIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6036/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GbGFnU3RhdEludGVncmF0aW9uVGVzdC5qYXZh) | `2.083% <0%> (-97.917%)` | `1% <0%> (-5%)` | |; | [...ariationDiscoveryPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6036/d,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6036#issuecomment-511048249:2935,pipeline,pipelines,2935,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6036#issuecomment-511048249,1,['pipeline'],['pipelines']
Deployability,all picard tools should be synched before we go to alpha release. We are now at some version and need to sync to the latest available by the alpha release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/705:57,release,release,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/705,2,['release'],['release']
Deployability,allerSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:01:43.730 INFO HaplotypeCallerSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:01:43.730 INFO HaplotypeCallerSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 19:01:43.730 INFO HaplotypeCallerSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:01:43.730 INFO HaplotypeCallerSpark - Deflater: IntelDeflater; 19:01:43.730 INFO HaplotypeCallerSpark - Inflater: IntelInflater; 19:01:43.730 INFO HaplotypeCallerSpark - GCS max retries/reopens: 20; 19:01:43.730 INFO HaplotypeCallerSpark - Requester pays: disabled; 19:01:43.730 WARN HaplotypeCallerSpark - . !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: HaplotypeCallerSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 19:01:43.730 INFO HaplotypeCallerSpark - Initializing engine; 19:01:43.730 INFO HaplotypeCallerSpark - Done initializing engine; 19/04/08 19:01:43 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19/04/08 19:01:43 INFO SparkContext: Running Spark version 2.3.0; 19/04/08 19:01:43 INFO SparkContext: Submitted application: HaplotypeCallerSpark; 19/04/08 19:01:43 INFO SecurityManager: Changing view acls to: hadoop; 19/04/08 19:01:43 INFO SecurityManager: Changing modify acls to: hadoop; 19/04/08 19:01:43 INFO SecurityManager: Changing view acls groups to: ; 19/04/08 19:01:43 INFO SecurityManager: Changing modify acls groups to: ; 19/04/08 19:01:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hadoop); groups with view permissions: Set(); users with modify permissions: Set(hadoop); groups with modify permissions: Set(); 19/04/08 19:01:44 INFO Utils: Successfully started service 'sparkDriver' on,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869:4062,configurat,configuration,4062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869,1,['configurat'],['configuration']
Deployability,"allow for gatk to be overridden, update with known good jar",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7758:33,update,update,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7758,1,['update'],['update']
Deployability,"alls - Start Date/Time: March 7, 2018 10:00:20 AM GMT; 10:00:21.083 INFO FilterMutectCalls - ------------------------------------------------------------; 10:00:21.083 INFO FilterMutectCalls - ------------------------------------------------------------; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Version: 2.14.3; 10:00:21.084 INFO FilterMutectCalls - Picard Version: 2.17.2; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:00:21.084 INFO FilterMutectCalls - Deflater: IntelDeflater; 10:00:21.084 INFO FilterMutectCalls - Inflater: IntelInflater; 10:00:21.084 INFO FilterMutectCalls - GCS max retries/reopens: 20; 10:00:21.084 INFO FilterMutectCalls - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 10:00:21.084 INFO FilterMutectCalls - Initializing engine; 10:00:21.437 INFO FeatureManager - Using codec VCFCodec to read file file:///scratch/dberaldi/projects/20170918_sgp_oesophageal/20171002_mutect/gatk4/WW00274.vep.vcf.gz; 10:00:21.673 INFO FilterMutectCalls - Done initializing engine; 10:00:21.734 INFO ProgressMeter - Starting traversal; 10:00:21.734 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 10:00:22.290 INFO FilterMutectCalls - Shutting down engine; [March 7, 2018 10:00:22 AM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=934805504; org.broadinstitute.hellbender.exceptions.GATKException: INFO annotation 'MFRL' contains a non-int value '2.1472e+08'; 	at org.broadinstitute.hellbender.utils.GATKProtectedVariantContextUtils.lambda$attributeValu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787:2360,patch,patch,2360,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787,1,['patch'],['patch']
Deployability,also updating build to extract the intelDeflater from the jar instead of downloading it; removed the htsjdkVersion property I had recently added since it was no longer necessary with the update to include the .so in the jar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1706:187,update,update,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1706,1,['update'],['update']
Deployability,"am.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.NoSuchFileException: /user/yaron/output.bam.parts/_SUCCESS: Unable to find _SUCCESS file; at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:53); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:152); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:250); ... 18 more; ```; However, I can find that _SUCCESS file exists in output.bam.parts. Could someone tell me what may be the cause? Thanks!; ```; $ hdfs dfs -ls output.bam.parts; Found 3 items; -rw-r--r-- 3 yaron yaron 0 2017-06-08 09:14 output.bam.parts/_SUCCESS; -rw-r--r-- 3 yaron yaron 62019 2017-06-08 09:14 output.bam.parts/part-r-00000.bam; -rw-r--r-- 3 yaron yaron 16 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:6305,deploy,deploy,6305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['deploy'],['deploy']
Deployability,am.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:743); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)Caused by: java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2722); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1565); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2227); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2151); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2009); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1533); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:420); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:298); at java.util.concurrent.ThreadPo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:10091,deploy,deploy,10091,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['deploy'],['deploy']
Deployability,am.java:119); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:233); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:5864,deploy,deploy,5864,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,1,['deploy'],['deploy']
Deployability,am.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@3e0a9b1d: java.net.BindException: Address already in use; java.net.BindException: Address already in use; at sun.nio.ch.Net.bind0(Native Method); at sun.nio.ch.Net.bind(Net.java:433); at sun.nio.ch.Net.bind(Net.java:425); at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223); at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74); at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:321); at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80); at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:236); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.eclipse.jetty.server.Server.doStart(Server.java:366); at org.eclipse.jetty.util.compo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:7507,deploy,deploy,7507,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725,1,['deploy'],['deploy']
Deployability,am.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaR,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:43732,deploy,deploy,43732,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['deploy'],['deploy']
Deployability,am.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaR,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:44478,deploy,deploy,44478,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['deploy'],['deploy']
Deployability,am.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:153); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:277); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.GATKException: Erred when inferring breakpoint location and event type from chimeric alignment:; asm010450:tig00000 1_189_chrUn_JTFH01000312v1_decoy:663-851_-_189M512H_60_8_149_O 153_701_chrUn_JTFH01000312v1_decoy:1-549_+_152S549M_60_0_549_O; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignmentsSAMSpark.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:11551,deploy,deploy,11551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['deploy'],['deploy']
Deployability,"am.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:17562,deploy,deploy,17562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['deploy'],['deploy']
Deployability,amF2YQ==) | `50.649% <0%> (-42.454%)` | `4% <0%> (-2%)` | |; | [...ender/tools/spark/transforms/ApplyBQSRSparkFn.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL0FwcGx5QlFTUlNwYXJrRm4uamF2YQ==) | `44.444% <0%> (-38.889%)` | `2% <0%> (-2%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `51.807% <0%> (-35.23%)` | `11% <0%> (-6%)` | |; | [...ls/spark/BaseRecalibratorSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `23.626% <0%> (-27.453%)` | `5% <0%> (-1%)` | |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `73.864% <0%> (-18.783%)` | `8% <0%> (+2%)` | |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `70.13% <0%> (-9.87%)` | `31% <0%> (+5%)` | |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `79.835% <0%> (-4.462%)` | `95% <0%> (+32%)` | |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/5248/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5248#issuecomment-426337698:3123,pipeline,pipelines,3123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5248#issuecomment-426337698,1,['pipeline'],['pipelines']
Deployability,"amjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:48:31.261 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:48:31.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:48:31.693 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.693 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.3.0; 13:48:31.693 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:48:31.694 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:48:31.694 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:48:31.694 INFO CountReadsSpark - Start Date/Time: December 21, 2018 1:48:31 PM EST; 13:48:31.694 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.694 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.695 INFO CountReadsSpark - HTSJDK Version: 2.14.3; 13:48:31.695 INFO CountReadsSpark - Picard Version: 2.17.2; 13:48:31.6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:1946,install,install,1946,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725,1,['install'],['install']
Deployability,"ample. An alternative approach would be to use branching and cherry-picking to do this kind of selective release, or split the GATK into even more repositories, but I'm not sure those approaches would be preferable. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215491991). This came out of a discussion between myself and @LeeTL1220 . ---. @lbergelson commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215493945). So a gatk release would contain different sets of tools sometimes? Wouldn't that be confusing? It seems like it would be better to always release different jars, or version sets of tools independently and release jars with the latest good release of each individual set of tools. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215494432). @lbergelson Well, we definitely still want there to be releases of the GATK toolkit in its entirety. If the CNV tools need to be released more frequently than this, they could be versioned/released separately and periodically incorporated into the toolkit-wide releases. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215495326). To be clear, though, this is very much still in the ""throwing out ideas for discussion"" phase, and alternate proposals are welcome provided they include the concept of a GATK-wide release, and make some provision for the situation where the CNV tools (or some other sub-category) are ready for release but other tools are not. ---. @vdauwera commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215498517). Frankly on the face of it I hate the idea of toolset-specific jars, because it increases entropy on the distribution & support side of things. I would much prefer to see this resolved by proj",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:1601,release,releases,1601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,1,['release'],['releases']
Deployability,"and likely to require some iteration so I'd be ok with starting with just the minimal ""porting"" changes to keep things simple, and then doing a code hygiene pass at the end. The ""porting"" changes should include things like updated javadoc, GATK4-style command line arguments, updating of outdated GATK3 terminology such as ""ROD"", Utils.nonNull assertions, etc. The finals and curly braces can wait for a separate pass (we will want to do those in this PR though). If you're not sure what to include or not just ask. I like the idea of keeping the GATK3 tests working as we go along. We should make a clear distinction between the old and new tests though. Ideally the GATK3 tests would be in a separate commit that we can just delete at the end, but that can get unwieldy if the files in the commit need to change as we go along. Alternatively you could isolate them into a separate directory. They should either be disabled or made dependent on a test method (see the `@Test` annotation properties `enabled` and `dependsOn`) that is easily toggled so they can be run locally, but don't run on the CI server. Otherwise the CI server build will always fail. In general, its really helpful to have the first commit in the PR contain the completely unmodified GATK3 source files. It makes it much easier for the reviewer to see what changed for the port. I noticed that you have 2 new plugins included in this. I'm not sure if that was suggested by someone on the GATK team (I'm wondering if we want to go down that path...) but I can tell you that the existing plugins required an enormous amount of test development and review iteration. If we do decide to make them plugins, I think it would be a good idea to do so in a separate PR. Also, if we choose to make an AbstractPlugin base class, we may want that to live in the Barclay repo. As @magicdgs points out, master already has your previous commits, so you should start by rebasing on that. Ideally, the branch would have the following commits bef",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352:1263,toggle,toggled,1263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352,2,['toggle'],['toggled']
Deployability,"andard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; Using GATK jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -Djava.io.tmpdir=/data/xieduo/gatktest -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; 13:35:32.710 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:32.890 INFO BaseRecalibrator - ------------------------------------------------------------; 13:35:32.891 INFO BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.2.6.1; 13:35:32.891 INFO BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:35:32.891 INFO BaseRecalibrator - Executing as xieduo@pbs-master on Linux v3.10.0-1160.41.1.el7.x86_64 amd64; 13:35:32.891 INFO BaseRecalibrator - Java runtime: Java HotSpot(TM) 64-Bit Server VM v18+36-2087; 13:35:32.891 INFO BaseRecalibrator - Start Date/Time: September 22, 2022 at 1:35:32 PM CST; 13:35:32.891 INFO BaseRecalibrator - ------------------------------------------------------------; 13:35:32.892 INFO BaseRecalibrator - ------------------------------------------------------------; 13:35:32.892 INFO BaseRecalibrator - HTSJDK Version: 2.24.1; 13:35:32.892 INFO BaseRecalibr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:1798,pipeline,pipeline,1798,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,"ang.reflect.InvocationTargetException; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at java.lang.invoke.SerializedLambda.readResolve(SerializedLambda.java:230); at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at java.io.ObjectStreamClass.invokeReadResolve(ObjectStreamClass.java:1104); ... 31 more; Caused by: java.lang.IllegalAccessError: no such method: org.broadinstitute.hellbender.tools.FlagStat$FlagStatus.add(GATKRead)FlagStatus/invokeVirtual; at java.lang.invoke.MethodHandleNatives.linkMethodHandleConstant(MethodHandleNatives.java:448); at org.broadinstitute.hellbender.tools.spark.pipelines.FlagStatSpark.$deserializeLambda$(FlagStatSpark.java:20); ... 40 more; Caused by: java.lang.LinkageError: loader constraint violation: when resolving method ""org.broadinstitute.hellbender.tools.FlagStat$FlagStatus.add(Lorg/broadinstitute/hellbender/utils/read/GATKRead;)Lorg/broadinstitute/hellbender/tools/FlagStat$FlagStatus;"" the class loader (instance of org/apache/spark/util/ChildFirstURLClassLoader) of the current class, org/broadinstitute/hellbender/tools/spark/pipelines/FlagStatSpark, and the class loader (instance of org/apache/spark/util/ChildFirstURLClassLoader) for the method's defining class, org/broadinstitute/hellbender/tools/FlagStat$FlagStatus, have different Class objects for the type org/broadinstitute/hellbender/utils/read/GATKRead used in the signature; at java.lang.invoke.MethodHandleNatives.resolve(Native Method); at java.lang.invoke.MemberName$Factory.resolve(MemberName.java:965); at java.lang.invoke.MemberName$Factory.resolveOrFail(MemberName.java:990); at j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1315:3744,pipeline,pipelines,3744,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1315,1,['pipeline'],['pipelines']
Deployability,"annoyingly, spark UI and Hadoop UI claim the job succeeds. see output here: https://console.cloud.google.com/dataproc/jobs/813fba95-8b19-4b4d-9cd1-b5bb94e4e52c?project=broad-dsde-dev&authuser=1&graph=GCE_CPU&duration=PT1H&tab=output. ```; java.lang.ArrayIndexOutOfBoundsException: 18; at org.broadinstitute.hellbender.utils.recalibration.EventType.eventFrom(EventType.java:35); at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.generateReportTables(RecalUtils.java:255); at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.apply(BaseRecalibratorSparkFn.java:50); at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.runTool(ReadsPipelineSpark.java:109); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:313); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1723:650,pipeline,pipelines,650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1723,1,['pipeline'],['pipelines']
Deployability,anonfun$13.apply(PairRDDFunctions.scala:1190); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). **This is the stack I get when the test completes but fails (note that the expected line count appears to not match the line count of the expected output file in the repo): **. java.lang.AssertionError: line counts expected [2629] but found [507]; 	at org.testng.Assert.fail(Assert.java:94); 	at org.testng.Assert.failNotEquals(Assert.java:496); 	at org.testng.Assert.assertEquals(Assert.java:125); 	at org.testng.Assert.assertEquals(Assert.java:372); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:211); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:190); 	at org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.testExampleAssemblyRegionWalker(ExampleAssemblyRegionWalkerSparkIntegrationTest.java:29); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.j,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:3501,Integrat,IntegrationTestSpec,3501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['Integrat'],['IntegrationTestSpec']
Deployability,"anonical (or otherwise reasonable) usage of our standard Docker takes precedence over edge cases.; # If you break the environment, you are responsible for fixing it and also owe the last developer who left this in a reasonable state a beverage of their choice.; # (This may be yourself, and you'll appreciate that beverage while you tinker with dependencies!); #; # When changing dependencies or versions in this file, check to see if the ""supportedPythonPackages"" DataProvider; # used by the testGATKPythonEnvironmentPackagePresent test in PythonEnvironmentIntegrationTest needs to be updated; # to reflect the changes.; #; name: gatk; channels:; # if channels other than conda-forge are added and the channel order is changed (note that conda channel_priority is currently set to flexible),; # verify that key dependencies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not upd",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:1486,update,update,1486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['update'],['update']
Deployability,"antWalker` that inputs a bam and a vcf and outputs the bases of all alt reads in the `ReadsContext` at each variant; 2) send these to an external alignment program; 3) read in the alignments in a GATK tool and filter accordingly. The ambitious version is to write our own simple aligner, eg a kmer-based method like BLAT or BBMap but with all the messy parts for handling big indels, RNA, and proteins removed. Writing our own BWA aligner would be wildly impractical. @takutosato @LeeTL1220 keeping you in the loop. ---. @davidbenjamin commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gatk-protected/issues/844#issuecomment-275483449). *Even better*: rely on someone else in the group, such as Ted, to write a Java binding for BWA in memory. See broadinstitute/gatk#2367. ---. @davidbenjamin commented on [Sun Apr 23 2017](https://github.com/broadinstitute/gatk-protected/issues/844#issuecomment-296515266). So. . . given that our pipeline aligns with BWA, it might seem like this is just a redundant and laborious rehashing of the mapping quality score. *However*, the mapping quality only considers multi-mapping within the reference, and therefore doesn't account for mapping errors due to incompleteness of the reference. That is, reads from genomic regions that are not part of the reference (because they're hard to assemble, like centromeres etc) might map well to a unique regions within the reference, and therefore will have fine mapping quality even though they are artifacts. There are published ""decoy genomes"" -- essentially pseudo-contigs of regions missing from the reference, and mapping with BWA in memory to *those* might be very helpful. So, we need to: 1) get our hands on a decoy genome that will play nicely with BWA, and 2) talk to the SV team. ---. @ldgauthier commented on [Mon Apr 24 2017](https://github.com/broadinstitute/gatk-protected/issues/844#issuecomment-296675311). To be pedantic, the mapping quality also considers how well the read aligns; to its",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2930:1330,pipeline,pipeline,1330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2930,1,['pipeline'],['pipeline']
Deployability,"any updates on this? I have the same question as is listed here; https://gatk.broadinstitute.org/hc/en-us/articles/360035890811/comments/5494691282203. > I know that `Homo_sapiens_assembly38.fasta.64.amb` is one of the bwa index file, but what does `.64` mean in the file name while the original fasta file DOES NOT have `.64`. Why add `.64`?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3768#issuecomment-2313467368:4,update,updates,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3768#issuecomment-2313467368,1,['update'],['updates']
Deployability,aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\repository\org\springframework\spring-core\5.2.6.RELEASE\spring-core-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-jcl\5.2.6.RELEASE\spring-jcl-5.2.6.RELEASE.jar;E:\repository\com\google\firebase\firebase-admin\6.8.1\firebase-admin-6.8.1.jar;E:\repository\com\google\api-client\google-api-client\1.25.0\google-api-client-1.25.0.jar;E:\repository\com\google\oauth-client\google-oauth-client\1.25.0\google-oauth-client-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-jackson2\1.25.0\google-http-client-jackson2-1.25.0.jar;E:\repository\com\google\api-client\google-api-client-gson\1.25.0\google-api-client-gson-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-gson\1.25.0\google-http-client-gson-1.25.0.jar;E:\repository\com\google\code\gson\gson\2.8.6\gson-2.8.6.jar;E:\repository\com\google\http-client\google-http-client\1.25.0\google-http-client-1.25.0.jar;E:\repository\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;E:\repository\org\apache\httpcomponents\httpclient\4.5.12\httpclient-4.5.12.jar;E:\repository\org\apache\httpcomponents\httpcore\4.4.13\httpcore-4.4.13.jar;E:\repository\commons-codec\commo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:5716,RELEASE,RELEASE,5716,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,"apPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 17/10/18 17:35:58 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 10.131.101.159, 35676),broadcast_4_piece167,StorageLevel(1 replicas),0,0)); 17/10/18 17:35:58 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 10.131.101.159, 35676),broadcast_4_piece173,StorageLevel(1 replicas),0,0)); 17/10/18 17:35:58 WARN Executor: Issue communicating with driver in heartbeater; java.lang.NullPointerException; 	at org.apache.spark.storage.BlockManagerMaster.updateBlockInfo(BlockManagerMaster.scala:67); 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$tryToReportBlockStatus(BlockManager.scala:363); 	at org.apache.spark.storage.BlockManager$$anonfun$reportAllBlocks$3.apply(BlockManager.scala:219); 	at org.apache.spark.storage.BlockManager$$anonfun$reportAllBlocks$3.apply(BlockManager.scala:217); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at org.apache.spark.storage.BlockManager.reportAllBlocks(BlockManager.scala:217); 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:236); 	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:522); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); 	at org.apache.spark.executor.Executor$$anon$1$$anon",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:4099,update,updateBlockInfo,4099,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['update'],['updateBlockInfo']
Deployability,"apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-0bd07e00-4f6d-43bd-b9d2-b1999376c72b; ```. Just to verify, the non-spark version still runs fine with the compressed fasta.... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; 13:38:54.168 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:38:55.869 INFO CountReads - ------------------------------------------------------------; 13:38:55.870 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:38:55.870 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:38:55.871 INFO CountReads - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:43537,install,install,43537,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['install'],['install']
Deployability,"aps pushing a fresh branch to this repo might make it a little easier for us to check it out for review---again, not a big deal, so I'll leave it up to you. 2) We try to adhere to the Google style guide https://google.github.io/styleguide/javaguide.html, so the review may yield a lot of seemingly minor and nitpicky change requests. Don't take these personally---the goal is just to make the code base as uniform and easy to maintain as possible! If you prefer, I'm sure we can find a GATK developer to take a quick once over of your branch and make these minor changes. 3) Since the new tool borrows so heavily from CollectAllelicCounts, I think it might be worth consolidating shared code and reducing code duplication---again, with the goal of making future maintenance more straightforward. I'll try to identify some places this can be done during my review. Again, we can make these changes on our end during the once over, or you can address them after the review (or we could also do this on our end in a separate PR after this one goes in). 4) In the near future, I think we should finally make the effort to replace both GetPileupSummaries and CollectAllelicCounts with this new tool. As mentioned in our email thread, @davidbenjamin and I discussed this long ago, e.g. https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386734926. From a methods perspective, we'd simply need expand the current functionality of your tool to also report the reference allele and do some quick sanity checks to make sure that the differences in count definition and read filtering don't have any undesired downstream effects. However, as we also discussed, this will come with some additional overhead---we'll need to update documentation, workshop slides, tutorials, WDLs, and make sure that any changes in output formats are clearly highlighted in the release notes. I'll leave this effort to @davidbenjamin and @mwalker174. Thanks again for doing this. Let us know how you'd like to proceed!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6543#issuecomment-610462293:2075,update,update,2075,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6543#issuecomment-610462293,4,"['release', 'update']","['release', 'update']"
Deployability,ar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\rt.jar;C:\project\push\target\classes;E:\repository\org\springframework\boot\spring-boot-starter-jdbc\2.3.0.RELEASE\spring-boot-starter-jdbc-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter\2.3.0.RELEASE\spring-boot-starter-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot\2.3.0.RELEASE\spring-boot-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-autoconfigure\2.3.0.RELEASE\spring-boot-autoconfigure-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-logging\2.3.0.RELEASE\spring-boot-starter-logging-2.3.0.RELEASE.jar;E:\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\repository\org\apache\logging\log4j\log4j-to-slf4j\2.13.2\log4j-to-slf4j-2.13.2.jar;E:\repository\org\apache\logging\log4j\log4j-api\2.13.2\log4j-api-2.13.2.jar;E:\repository\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;E:\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;E:\repository\org\yaml\snakeyaml\1.26\snakeyaml-1.26.jar;E:\repository\com\zaxxer\HikariCP\3.4.5\HikariCP-3.4.5.jar;E:\repository\org\springframework\spring-jdbc\5.2.6.RELEASE\spring-jdbc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-b,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:2107,RELEASE,RELEASE,2107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,"ariants based on QC in ArrayExtractCohort (#6844); - switch from ExcessHet back to HWE (#6848); - resolved rebase conflicts; - initial cohort extract; - minor changes; - wip; - get genotypes working; - clarify sample -> sample_id; - add mode; - mode is mandatory, uses location instead of position; - add query mode; - fix contig name; - fix location bug; - Ingest wip to be added to other var db code (#6582); - ingest arrays refactored; - add filter, change sample to sample_id; - fix bugs; - wip; - major refactor splitting ingest for arrays from exomes/genomes; - create output files for actual raw array tables; - change site_name to rsid; - change GT encoding, change output file names and remove dir structure, get probe metadata; - fix prefix; - update GT encoding; - remove filter, rename columns, allow sample id as input; - array cohort extract (#6666); - new bit-compression (#6691); - refactored to common ProbeInfo, support compressed data on ingest, support local CSV probe info; - update exome ingest; - minor mods; - change structure, add compressed option to ingest; - add imputed tsv creator and refactor; - Adding a test and small features to var store branch (#6761); - upgraded to new google bigquery libraries and storage api v1; used storage api for probe info; synced encoded gt definitions; - added support for probe_id ranges (#6806); - ah - use new GT encoding (#6822); - updating ArrayCalculateMetrics for new genotype counts table (#6843); - Ability to filter variants based on QC in ArrayExtractCohort (#6844); - switch from ExcessHet back to HWE (#6848); - Moving the WDL for importing array manifest to BQ (#6860); - fix up after rebase; - Moving and testing ingest scripts from variantstore (#6881); - optionally provide sample-map-file instead of sample-map-table (#6872); - Moving extract wdls from variantstore repo (#6902); - update for genomes (#6918); - update paths; - update field name; - consolidate exome and genome code; - missing comma; - allow null for d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:2545,update,update,2545,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,['update'],['update']
Deployability,ark.RangePartitioner.<init>(Partitioner.scala:152); at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:62); at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:61); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.OrderedRDDFunctions.sortByKey(OrderedRDDFunctions.scala:61); at org.apache.spark.api.java.JavaPairRDD.sortByKey(JavaPairRDD.scala:936); at org.broadinstitute.hellbender.utils.spark.SparkUtils.sortReads(SparkUtils.java:153); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:228); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:153); at org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark.runTool(BwaAndMarkDuplicatesPipelineSpark.java:62); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:230); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:4037,pipeline,pipelines,4037,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['pipeline'],['pipelines']
Deployability,"ark.driver.userClassPathFirst=false,spark.io.compression.codec=lzf,spark.yarn.executor.memoryOverhead=600,spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 ,spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --jar gs://broad-dsde-methods/shuang/tmp/gatk-jars/gatk-spark_5710525a8758807e46bbb660ac998e63.jar -- PrintReadsSpark -I hdfs://shuang-small-m:8020/data/HG00512.cram.samtools1_9.bam -O hdfs://shuang-small-m:8020/results/temp.bam -L hdfs://shuang-small-m:8020/data/intervals.bed --spark-master yarn; Job [5838bd7dec2d4533ad090ce03ecc7c0c] submitted.; Waiting for job output...; 18/07/24 21:02:03 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 21:02:08.430 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 21:02:08.594 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/5838bd7dec2d4533ad090ce03ecc7c0c/gatk-spark_5710525a8758807e46bbb660ac998e63.jar!/com/intel/gkl/native/libgkl_compression.so; 21:02:08.889 INFO PrintReadsSpark - ------------------------------------------------------------; 21:02:08.890 INFO PrintReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.6.0-26-g3979bdb-SNAPSHOT; 21:02:08.890 INFO PrintReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 21:02:08.890 INFO PrintReadsSpark - Executing as root@shuang-small-m on Linux v3.16.0-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:3591,configurat,configuration,3591,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['configurat'],['configuration']
Deployability,"ark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --num-executors 5 --executor-cores 2 --executor-memory 1g /home/yaron/gatk/build/libs/gatk-spark.jar PrintReadsSpark -I NA12878.chr17_69k_70k.dictFix.bam -O /user/yaron/output.bam --sparkMaster yarn; 09:14:13.551 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yaron/gatk/build/libs/gatk-spark.jar!/com/intel/gkl/native/libgkl_compression.so; [June 8, 2017 9:14:13 AM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark --output /user/yaron/output.bam --input NA12878.chr17_69k_70k.dictFix.bam --sparkMaster yarn --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [June 8, 2017 9:14:13 AM CST] Executing as yaron@dn1 on Linux 4.4.0-31-generic amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.alpha.2-281-g752d020-SNAPSHOT; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_W",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:1568,pipeline,pipelines,1568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['pipeline'],['pipelines']
Deployability,"ark/conf/spark-defaults.conf.template /spark/conf/spark-defaults.conf && \; echo ""spark.eventLog.enabled true"" >> /spark/conf/spark-defaults.conf && \; echo ""spark.eventLog.dir file:///spark/logs/"" >> /spark/conf/spark-defaults.conf. ENV PATH=""$PATH:/spark/bin""; ```; I have this configurations for docker-compose:; - Spark. ```; version: '3'; services:; spark-master:; image: atahualpa/spark-master:GATK4.0.4; networks:; - workbench; deploy:; replicas: 1; mode: replicated; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8080; env_file:; - ./hadoop.env; ports:; - 8333:8080; - 4040:4040; - 6066:6066; - 7077:7077; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/fastq/:/fastq/; - /data0/NGS-SparkGATK/NGS-SparkGATK/:/NGS-SparkGATK/; - /data/ngs/:/ngs/; - /data0/output/:/output/; spark-worker:; image: bde2020/spark-worker:2.2.0-hadoop2.8-hive-java8; networks:; - workbench; environment:; - SPARK_MASTER=spark://spark-master:7077; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8081. env_file:; - ./hadoop.env; volumes:; - reference-image:/reference_image. reference:; image: vzzarr/reference:hg19_img; networks:; - workbench; deploy:; mode: global; restart_policy:; condition: on-failure; tty: true #keeps the container alive; volumes:; - reference-image:/reference_image. volumes:; reference-image:. networks:; workbench:; external: true; ```; - Hadoop:; ```; version: '3'; services:; namenode:; image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - namenode:/hadoop/dfs/name; environment:; - CLUSTER_NAME=test; env_file:; - ./hadoop.env; deploy:; mode: replicated; replicas: 1; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50070; ports:; - 8334:50070; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/output/:/output/; - /data/ngs/:/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:1828,deploy,deploy,1828,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['deploy'],['deploy']
Deployability,arkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@3e0a9b1d: java.net.BindException: Address already in use; java.net.BindException: Address already in use; at sun.nio.ch.Net.bind0(Native Method); at sun.nio.ch.Net.bind(Net.java:433); at sun.nio.ch.Net.bind(Net.java:425); at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223); at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74); at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:321); at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80); at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:236); at org.eclipse.jetty.util.compone,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:7360,deploy,deploy,7360,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725,1,['deploy'],['deploy']
Deployability,arkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15);,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:43585,deploy,deploy,43585,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['deploy'],['deploy']
Deployability,arkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15);,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:44331,deploy,deploy,44331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['deploy'],['deploy']
Deployability,arkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:153); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:277); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.GATKException: Erred when inferring breakpoint location and event type from chimeric alignment:; asm010450:tig00000 1_189_chrUn_JTFH01000312v1_decoy:663-851_-_189M512H_60_8_149_O 153_701_chrUn_JTFH01000312v1_decoy:1-549_+_152S549M_60_0_549_O; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignmentsSAMSpark.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.try,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:11404,deploy,deploy,11404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['deploy'],['deploy']
Deployability,"arkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:17415,deploy,deploy,17415,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['deploy'],['deploy']
Deployability,"arkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.NoSuchFileException: /user/yaron/output.bam.parts/_SUCCESS: Unable to find _SUCCESS file; at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:53); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:152); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:250); ... 18 more; ```; However, I can find that _SUCCESS file exists in output.bam.parts. Could someone tell me what may be the cause? Thanks!; ```; $ hdfs dfs -ls output.bam.parts; Found 3 items; -rw-r--r-- 3 yaron yaron 0 2017-06-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:6158,deploy,deploy,6158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['deploy'],['deploy']
Deployability,arkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:743); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)Caused by: java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2722); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1565); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2227); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2151); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2009); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1533); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:420); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstanc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:9944,deploy,deploy,9944,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['deploy'],['deploy']
Deployability,arkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:233); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLik,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:5717,deploy,deploy,5717,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,1,['deploy'],['deploy']
Deployability,"arkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66); at org.broadinstitute.hellbender.Main.main(Main.java:81); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/01/21 14:55:33 INFO ShutdownHookManager: Shutdown hook called; ```. Attached is a small BAM file that I used to reproduce the error (If memory serves, I've seen this issue on other BAM files as well):. [NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip](https://github.com/broadinstitute/gatk/files/101575/NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip). (This issue may be related to one posted here: https://github.com/broadinstitute/gatk/issues/1417.). Here is some information on what I installed:. ```; echo ""Installing Java""; sudo add-apt-repository -y ppa:webupd8team/java; sudo apt-get -qq update; echo debconf shared/accepted-oracle-license-v1-1 select true | sudo debconf-set-selections; echo debconf shared/accepted-oracle-license-v1-1 seen true | sudo debconf-set-selections; su",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1444:3154,deploy,deploy,3154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1444,1,['deploy'],['deploy']
Deployability,asa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz -- --spark-runner SPARK --spark-master yarn. Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:1363,install,install,1363,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['install'],['install']
Deployability,at org.gradle.internal.service.DefaultServiceRegistry$OwnServices.stop(DefaultServiceRegistry.java:519); at org.gradle.internal.concurrent.CompositeStoppable.stop(CompositeStoppable.java:98); at org.gradle.internal.service.DefaultServiceRegistry$CompositeProvider.stop(DefaultServiceRegistry.java:920); at org.gradle.internal.concurrent.CompositeStoppable.stop(CompositeStoppable.java:98); at org.gradle.internal.service.DefaultServiceRegistry.close(DefaultServiceRegistry.java:326); at org.gradle.internal.concurrent.CompositeStoppable$2.stop(CompositeStoppable.java:83); at org.gradle.internal.concurrent.CompositeStoppable.stop(CompositeStoppable.java:98); at org.gradle.initialization.DefaultGradleLauncher.stop(DefaultGradleLauncher.java:199); at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:46); at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:28); at org.gradle.launcher.exec.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:77); at org.gradle.launcher.exec.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:47); at org.gradle.launcher.exec.DaemonUsageSuggestingBuildActionExecuter.execute(DaemonUsageSuggestingBuildActionExecuter.java:51); at org.gradle.launcher.exec.DaemonUsageSuggestingBuildActionExecuter.execute(DaemonUsageSuggestingBuildActionExecuter.java:28); at org.gradle.launcher.cli.RunBuildAction.run(RunBuildAction.java:43); at org.gradle.internal.Actions$RunnableActionAdapter.execute(Actions.java:170); at org.gradle.launcher.cli.CommandLineActionFactory$ParseAndBuildAction.execute(CommandLineActionFactory.java:237); at org.gradle.launcher.cli.CommandLineActionFactory$ParseAndBuildAction.execute(CommandLineActionFactory.java:210); at org.gradle.launcher.cli.JavaRuntimeValidationAction.execute(JavaRuntimeValidationAction.java:35); at org.gradle.launcher.cli.JavaRuntimeValidationAction.execute(JavaRuntimeValidationAction.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:4793,Continuous,ContinuousBuildActionExecuter,4793,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,3,['Continuous'],['ContinuousBuildActionExecuter']
Deployability,ata/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz  -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.table --tmp-dir /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam ; ; Using GATK jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar ; ; Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx30G -jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.table --tmp-dir /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam ; ; 00:11:11.683 INFO  NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 00:11:11.697 WARN  NativeLibraryLoader - Unable to load libgkl\_compression.so from native/libgkl\_compression.so (No such file or directory) ; ; 00:11:11.700 INFO  NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 00:11:11.700 WARN  Nat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:8662,pipeline,pipeline,8662,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability,"ated a new SpanningDeletionRecord as a subclass of ReferenceRecord but allows us to store GT and GQ; 2. in handlePotentialSpanningDeletion when processing a deletion, we create a new SpanningDeletionRecord with the correct GT and GQ based on the deletion; 3. When processing reference data at a variant site, return ReferenceRecords/SpanningDeletionRecord instead of just a string ""state"" since we need more than just state now; 4. Because of the above, we are now returning an object for the inferred state instead of just a string. Since the inferred state is so, so common a singleton InferredReferenceRecord was created; 5. Processing of spanning deletions beyond. **Ugly**; 1. The construction of the singleton is ugly because it _requires_ a location even though we don't for this case. We could go to an tagging interface (like Cloneable) these all implement, but that seems ugly also. *Refactoring Changes*; One of the challenges with this PR was testing as the work is really done in the lower-level methods and it would be nice to have this as a unit test rather than an integration/end-to-end test. This motivated the following changes:. 1. don't write to VCF directly, instead have take a Consumer<VariantContext> to emit VariantContexts. This let's us provide a different consumer in unit tests to collect our result.; 2. we previously had a chain of calls createVariantsFromSortedRanges -> processSampleRecordsForLocation -> finalizeCurrentVariant that returned void and as a side effect wrote to VCF. These deeper methods now return a VariantContext and the writing (via consumer) is done higher up in the call stack; 3. made some private methods package-private so we could call them from tests. **Thinking Out Loud**. We have three different sets of datastructures for the same data, some of this is history, some is performance/memory, but could use some rethinking; 1. GenericRecord (pulling from BQ); 2. ReferenceRecord/SpanningDeletionRecord (in memory data structure for referenc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7857:1118,integrat,integration,1118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7857,1,['integrat'],['integration']
Deployability,"ated; # to reflect the changes.; #; name: gatk; channels:; # if channels other than conda-forge are added and the channel order is changed (note that conda channel_priority is currently set to flexible),; # verify that key dependencies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # conda-installed 2.2.4 appears to be the most recent version with a consistent API and without conflicts/clobbers; # if you wish to update, note that versions of conda-forge::keras after 2.2.5; # undesirably set the environment variable KERAS_BACKEND = theano by default; - defaults::intel-ope",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:2071,release,released,2071,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['release'],['released']
Deployability,"ation - Start Date/Time: June 15, 2018 3:42:33 PM PDT; 15:42:34.116 INFO VariantFiltration - ------------------------------------------------------------; 15:42:34.116 INFO VariantFiltration - ------------------------------------------------------------; 15:42:34.117 INFO VariantFiltration - HTSJDK Version: 2.15.1; 15:42:34.118 INFO VariantFiltration - Picard Version: 2.18.2; 15:42:34.118 INFO VariantFiltration - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 15:42:34.118 INFO VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:42:34.118 INFO VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:42:34.118 INFO VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:42:34.118 INFO VariantFiltration - Deflater: IntelDeflater; 15:42:34.119 INFO VariantFiltration - Inflater: IntelInflater; 15:42:34.119 INFO VariantFiltration - GCS max retries/reopens: 20; 15:42:34.119 INFO VariantFiltration - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 15:42:34.119 INFO VariantFiltration - Initializing engine; 15:42:34.634 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/sherlock/dev/Bhatt_lab/crassphage/variants/6753_12-15-2015_first_pass_filtered.vcf; 15:42:34.663 INFO VariantFiltration - Done initializing engine; 15:42:34.750 INFO ProgressMeter - Starting traversal; 15:42:34.750 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 15:42:34.781 INFO VariantFiltration - Shutting down engine; [June 15, 2018 3:42:34 PM PDT] org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=342884352; java.lang.NumberFormatException: For input string: ""26.67""; 	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65); 	at java.lang.Long.parseLong(Long.java:589); 	at java.lang.Long.parseLo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4921:2885,patch,patch,2885,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4921,1,['patch'],['patch']
Deployability,atk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; Using GATK jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -Djava.io.tmpdir=/data/xieduo/Łuksza_2022_Nature -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; 13:36:33.528 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:36:33.547 WARN NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (No such file or directory); 13:36:33.550 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:36:33.551 WARN NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (No such file or directory); 13:36:33.669 INFO BaseRecalibrator - --,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:6188,pipeline,pipeline,6188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,"ator). \--. REQUIRED for all errors and issues: ; ; a) GATK version used:v4.2.6.1  ; ; b) Exact command used: see below ; ; c) Entire program log: see below ; ; **How can I assign a temp directory and won't get the bug?**. I always got error when I assigned the temp directory:. /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx8G -Djava.io.tmpdir=/data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/shell/temp"" BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz  -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test.table ; ; Using GATK jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar ; ; Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx8G -Djava.io.tmpdir=/data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/shell/temp -jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test.table ; ; 00:09:41.541 INFO  Native",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:1322,pipeline,pipeline,1322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability,"atureManager.<init>(FeatureManager.java:155); 	at org.broadinstitute.hellbender.engine.ReadWalker.initializeFeatures(ReadWalker.java:72); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:726); 	at org.broadinstitute.hellbender.engine.ReadWalker.onStartup(ReadWalker.java:51); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; 3. Change work directory into `/data/xieduo/Immun_genomics/data/Łuksza2022Nature` and used `./` as tmp directory. It also failed:; ```; cd /data/xieduo/Immun_genomics/data/Łuksza2022Nature; /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx8G -Djava.io.tmpdir=./"" BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; Using GATK jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -Djava.io.tmpdir=./ -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapien",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:11409,pipeline,pipeline,11409,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,aultServiceRegistry$OwnServices.stop(DefaultServiceRegistry.java:519); at org.gradle.internal.concurrent.CompositeStoppable.stop(CompositeStoppable.java:98); at org.gradle.internal.service.DefaultServiceRegistry$CompositeProvider.stop(DefaultServiceRegistry.java:920); at org.gradle.internal.concurrent.CompositeStoppable.stop(CompositeStoppable.java:98); at org.gradle.internal.service.DefaultServiceRegistry.close(DefaultServiceRegistry.java:326); at org.gradle.internal.concurrent.CompositeStoppable$2.stop(CompositeStoppable.java:83); at org.gradle.internal.concurrent.CompositeStoppable.stop(CompositeStoppable.java:98); at org.gradle.initialization.DefaultGradleLauncher.stop(DefaultGradleLauncher.java:199); at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:46); at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:28); at org.gradle.launcher.exec.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:77); at org.gradle.launcher.exec.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:47); at org.gradle.launcher.exec.DaemonUsageSuggestingBuildActionExecuter.execute(DaemonUsageSuggestingBuildActionExecuter.java:51); at org.gradle.launcher.exec.DaemonUsageSuggestingBuildActionExecuter.execute(DaemonUsageSuggestingBuildActionExecuter.java:28); at org.gradle.launcher.cli.RunBuildAction.run(RunBuildAction.java:43); at org.gradle.internal.Actions$RunnableActionAdapter.execute(Actions.java:170); at org.gradle.launcher.cli.CommandLineActionFactory$ParseAndBuildAction.execute(CommandLineActionFactory.java:237); at org.gradle.launcher.cli.CommandLineActionFactory$ParseAndBuildAction.execute(CommandLineActionFactory.java:210); at org.gradle.launcher.cli.JavaRuntimeValidationAction.execute(JavaRuntimeValidationAction.java:35); at org.gradle.launcher.cli.JavaRuntimeValidationAction.execute(JavaRuntimeValidationAction.java:24); at org.gradle.launcher.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:4831,Continuous,ContinuousBuildActionExecuter,4831,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,3,['Continuous'],['ContinuousBuildActionExecuter']
Deployability,b succeeds. see output here: https://console.cloud.google.com/dataproc/jobs/813fba95-8b19-4b4d-9cd1-b5bb94e4e52c?project=broad-dsde-dev&authuser=1&graph=GCE_CPU&duration=PT1H&tab=output. ```; java.lang.ArrayIndexOutOfBoundsException: 18; at org.broadinstitute.hellbender.utils.recalibration.EventType.eventFrom(EventType.java:35); at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.generateReportTables(RecalUtils.java:255); at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.apply(BaseRecalibratorSparkFn.java:50); at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.runTool(ReadsPipelineSpark.java:109); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:313); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1723:1675,deploy,deploy,1675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1723,6,['deploy'],['deploy']
Deployability,b0a564ef6595?src=pr&el=desc) will **decrease** coverage by `0.399%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4293 +/- ##; ===============================================; - Coverage 79.092% 78.693% -0.399% ; + Complexity 16611 16541 -70 ; ===============================================; Files 1048 1049 +1 ; Lines 59579 59580 +1 ; Branches 9730 9730 ; ===============================================; - Hits 47122 46885 -237 ; - Misses 8679 8927 +248 ; + Partials 3778 3768 -10; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4293?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4293#issuecomment-361362648:1257,pipeline,pipelines,1257,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4293#issuecomment-361362648,1,['pipeline'],['pipelines']
Deployability,"b10; 05:06:55.410 INFO SelectVariants - Start Date/Time: November 6, 2019 5:06:54 AM EST; 05:06:55.410 INFO SelectVariants - ------------------------------------------------------------; 05:06:55.410 INFO SelectVariants - ------------------------------------------------------------; 05:06:55.411 INFO SelectVariants - HTSJDK Version: 2.16.0; 05:06:55.411 INFO SelectVariants - Picard Version: 2.18.7; 05:06:55.411 INFO SelectVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 05:06:55.411 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:06:55.412 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 05:06:55.412 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:06:55.412 INFO SelectVariants - Deflater: IntelDeflater; 05:06:55.412 INFO SelectVariants - Inflater: IntelInflater; 05:06:55.412 INFO SelectVariants - GCS max retries/reopens: 20; 05:06:55.412 INFO SelectVariants - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:06:55.412 INFO SelectVariants - Initializing engine; 05:06:55.796 INFO FeatureManager - Using codec VCFCodec to read file file:///disk/juntong/huada/V300029595_results/mutect_outputs/V300029595.merged.vcf.gatk.somatic.vcf.gz; 05:06:55.962 INFO SelectVariants - Done initializing engine; 05:06:56.099 INFO ProgressMeter - Starting traversal; 05:06:56.099 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 06:39:06.894 INFO SelectVariants - Shutting down engine; [November 6, 2019 6:39:06 AM EST] org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants done. Elapsed time: 92.20 minutes.; Runtime.totalMemory()=29215424512; Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; at java.util.Arrays.copyOf(Arrays.java:3181); at java.util.ArrayList.grow(ArrayList.java:265); at java.util.ArrayList.ensureExplicitCapacit",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6254:2954,patch,patch,2954,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6254,1,['patch'],['patch']
Deployability,"b15 01:13:16.076 INFO HaplotypeCaller - Start Date/Time: January 18, 2020 1:13:15 AM IST 01:13:16.076 INFO HaplotypeCaller - ------------------------------------------------------------ 01:13:16.076 INFO HaplotypeCaller - ------------------------------------------------------------ 01:13:16.077 INFO HaplotypeCaller - HTSJDK Version: 2.13.2 01:13:16.077 INFO HaplotypeCaller - Picard Version: 2.17.2 01:13:16.077 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false 01:13:16.078 INFO HaplotypeCaller - Deflater: IntelDeflater 01:13:16.078 INFO HaplotypeCaller - Inflater: IntelInflater 01:13:16.078 INFO HaplotypeCaller - GCS max retries/reopens: 20 01:13:16.078 INFO HaplotypeCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes 01:13:16.078 INFO HaplotypeCaller - Initializing engine 01:13:17.087 INFO HaplotypeCaller - Shutting down engine [January 18, 2020 1:13:17 AM IST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.02 minutes. Runtime.totalMemory()=2216689664 java.lang.NullPointerException at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:463) at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:457) at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234) at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150) at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionar",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-1605272955:1790,patch,patch,1790,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-1605272955,1,['patch'],['patch']
Deployability,b6bec8152472fe62c8791881d84cd07?src=pr&el=desc) will **increase** coverage by `0.001%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #5991 +/- ##; ===============================================; + Coverage 86.926% 86.927% +0.001% ; + Complexity 32732 32731 -1 ; ===============================================; Files 2014 2014 ; Lines 151333 151333 ; Branches 16612 16612 ; ===============================================; + Hits 131548 131549 +1 ; Misses 13724 13724 ; + Partials 6061 6060 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5991?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...lbender/tools/spark/pipelines/CountReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrLmphdmE=) | `90.909% <ø> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...ellbender/tools/spark/pipelines/FlagStatSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvRmxhZ1N0YXRTcGFyay5qYXZh) | `90% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountBasesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRCYXNlc1NwYXJrLmphdmE=) | `90% <ø> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/CountVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5991#issuecomment-500387504:1243,pipeline,pipelines,1243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5991#issuecomment-500387504,1,['pipeline'],['pipelines']
Deployability,"b9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9MaWJyYXJ5UmVhZEZpbHRlci5qYXZh) | `100% <ø> (ø)` | `4 <ø> (ø)` | :x: |; | [...institute/hellbender/tools/picard/sam/SortSam.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9waWNhcmQvc2FtL1NvcnRTYW0uamF2YQ==) | `94.118% <ø> (ø)` | `3 <ø> (ø)` | :x: |; | [...adinstitute/hellbender/tools/IndexFeatureFile.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9JbmRleEZlYXR1cmVGaWxlLmphdmE=) | `90.323% <ø> (ø)` | `12 <ø> (ø)` | :x: |; | [...org/broadinstitute/hellbender/tools/ClipReads.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9DbGlwUmVhZHMuamF2YQ==) | `90.385% <ø> (ø)` | `35 <ø> (ø)` | :x: |; | ... and [81 more](https://codecov.io/gh/broadinstitute/gatk/pull/2327/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2327?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2327?src=pr&el=footer). Last update [10b16a6...d4483e8](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-268877705:5070,update,update,5070,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-268877705,2,['update'],['update']
Deployability,"bWVudENvbGxlY3Rpb24uamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...tools/examples/ExampleStreamingPythonExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlU3RyZWFtaW5nUHl0aG9uRXhlY3V0b3IuamF2YQ==) | `0% <0%> (-96.67%)` | `0% <0%> (-8%)` | |; | [.../walkers/vqsr/CNNScoreVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `4.16% <0%> (-95.84%)` | `2% <0%> (-8%)` | |; | [...der/utils/python/PythonScriptExecutorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9weXRob24vUHl0aG9uU2NyaXB0RXhlY3V0b3JVbml0VGVzdC5qYXZh) | `3.84% <0%> (-94.24%)` | `1% <0%> (-11%)` | |; | [...number/arguments/HybridADVIArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2FyZ3VtZW50cy9IeWJyaWRBRFZJQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `0% <0%> (-94.12%)` | `0% <0%> (-3%)` | |; | ... and [36 more](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5329?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5329?src=pr&el=footer). Last update [f95b6fe...1c00f72](https://codecov.io/gh/broadinstitute/gatk/pull/5329?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5329#issuecomment-431146563:4841,update,update,4841,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5329#issuecomment-431146563,2,['update'],['update']
Deployability,bWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4881/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `60.714% <0%> (-5.258%)` | `41% <0%> (+4%)` | |; | [...bender/tools/walkers/annotator/StrandBiasTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4881/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRCaWFzVGVzdC5qYXZh) | `90.226% <0%> (-0.2%)` | `52% <0%> (+10%)` | |; | [...oadinstitute/hellbender/utils/read/CigarUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4881/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL0NpZ2FyVXRpbHMuamF2YQ==) | `93.827% <0%> (-0.112%)` | `159% <0%> (+68%)` | |; | [...lbender/tools/spark/pipelines/PrintReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4881/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRSZWFkc1NwYXJrLmphdmE=) | `100% <0%> (ø)` | `5% <0%> (+1%)` | :arrow_up: |; | [...bender/utils/runtime/AsynchronousStreamWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4881/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL0FzeW5jaHJvbm91c1N0cmVhbVdyaXRlci5qYXZh) | `83.673% <0%> (ø)` | `11% <0%> (?)` | |; | [...er/utils/python/StreamingPythonScriptExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/4881/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9weXRob24vU3RyZWFtaW5nUHl0aG9uU2NyaXB0RXhlY3V0b3IuamF2YQ==) | `84.028% <0%> (+0.028%)` | `34% <0%> (+19%)` | :arrow_up: |; | ... and [10 more](https://codecov.io/gh/broadinstitute/gatk/pull/4881/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4881#issuecomment-396381499:3139,pipeline,pipelines,3139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4881#issuecomment-396381499,1,['pipeline'],['pipelines']
Deployability,"bam_index, and normal_sample_name: BAM, index and sample name for the normal sample (optional if running tumor-only); ##; ## ** Primary resources ** (optional but strongly recommended); ## pon, pon_index: optional panel of normals in VCF format containing probable technical artifacts (false positves); ## gnomad, gnomad_index: optional database of known germline variants (see http://gnomad.broadinstitute.org/downloads); ## variants_for_contamination, variants_for_contamination_index: VCF of common variants with allele frequencies fo calculating contamination; ##; ## ** Secondary resources ** (for optional tasks); ## onco_ds_tar_gz, default_config_file: Oncotator datasources and config file; ## sequencing_center, sequence_source: metadata for Oncotator; ##; ## Outputs :; ## - One VCF file and its index with primary filtering applied; secondary filtering and functional annotation if requested.; ##; ## Cromwell version support ; ## - Successfully tested on v27; ##; ## LICENSING : ; ## This script is released under the WDL source code license (BSD-3) (see LICENSE in ; ## https://github.com/broadinstitute/wdl). Note however that the programs it calls may ; ## be subject to different licenses. Users are responsible for checking that they are; ## authorized to run all programs before running this script. Please see the docker ; ## pages at https://hub.docker.com/r/broadinstitute/* for detailed licensing information ; ## pertaining to the included programs. workflow Mutect2 {; # Runtime; String gatk4_jar; File picard_jar; String m2_docker; String oncotator_docker; Int preemptible_attempts; # Workflow options; Int scatter_count; File? intervals ; Array[String] artifact_modes; String? m2_extra_args; String? m2_extra_filtering_args; Boolean is_run_orientation_bias_filter; Boolean is_run_oncotator; # Primary inputs ; File ref_fasta; File ref_fasta_index; File ref_dict; File tumor_bam; File tumor_bam_index; String tumor_sample_name; File? normal_bam; File? normal_bam_index; String",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3341:2853,release,released,2853,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3341,1,['release'],['released']
Deployability,bb71c154c6f087?src=pr&el=desc) will **decrease** coverage by `0.25%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4664 +/- ##; ==============================================; - Coverage 79.823% 79.573% -0.25% ; + Complexity 17328 17280 -48 ; ==============================================; Files 1075 1074 -1 ; Lines 62917 62907 -10 ; Branches 10181 10181 ; ==============================================; - Hits 50222 50057 -165 ; - Misses 8714 8875 +161 ; + Partials 3981 3975 -6; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4664?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4664/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4664/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4664/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4664/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-10%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4664/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4664#issuecomment-381982668:1255,pipeline,pipelines,1255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4664#issuecomment-381982668,1,['pipeline'],['pipelines']
Deployability,"bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `90% <0%> (-1.429%)` | `23% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `87.2% <0%> (+0.8%)` | `36% <0%> (+1%)` | :arrow_up: |; | [...ellbender/tools/walkers/annotator/RankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SYW5rU3VtVGVzdC5qYXZh) | `86.957% <0%> (+6.401%)` | `14% <0%> (+1%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.385% <0%> (+7.168%)` | `49% <0%> (+16%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2500?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2500?src=pr&el=footer). Last update [58cb99e...2a7f196](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2500#issuecomment-288139597:2778,update,update,2778,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2500#issuecomment-288139597,2,['update'],['update']
Deployability,"bender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:110); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 18/12/21 13:48:33 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 18/12/21 13:48:37 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 14:54:41.938 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 2:54:41 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 66.18 minutes. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:10682,deploy,deploy,10682,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725,7,"['deploy', 'pipeline']","['deploy', 'pipelines']"
Deployability,"ber 2, 2018 3:00:35 PM JST; 15:00:35.945 INFO GenomicsDBImport - ------------------------------------------------------------; 15:00:35.945 INFO GenomicsDBImport - ------------------------------------------------------------; 15:00:35.946 INFO GenomicsDBImport - HTSJDK Version: 2.16.0; 15:00:35.946 INFO GenomicsDBImport - Picard Version: 2.18.7; 15:00:35.946 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 15:00:35.946 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:00:35.946 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:00:35.946 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:00:35.946 INFO GenomicsDBImport - Deflater: IntelDeflater; 15:00:35.946 INFO GenomicsDBImport - Inflater: IntelInflater; 15:00:35.946 INFO GenomicsDBImport - GCS max retries/reopens: 20; 15:00:35.946 INFO GenomicsDBImport - Using google-cloud-java fork https://github.com/broadinstitute/google-cloud-java/releases/tag/0.20.5-alpha-GCS-RETRY-FIX; 15:00:35.946 INFO GenomicsDBImport - Initializing engine; 15:00:38.360 INFO IntervalArgumentCollection - Processing 58617616 bp from intervals; 15:00:38.366 INFO GenomicsDBImport - Done initializing engine; Created workspace /work/Analysis/wgs_chr19; 15:00:38.849 INFO GenomicsDBImport - Vid Map JSON file will be written to /work/Analysis/wgs_chr19/vidmap.json; 15:00:38.849 INFO GenomicsDBImport - Callset Map JSON file will be written to /work/Analysis/wgs_chr19/callset.json; 15:00:38.849 INFO GenomicsDBImport - Complete VCF Header will be written to /work/Analysis/wgs_chr19/vcfheader.vcf; 15:00:38.850 INFO GenomicsDBImport - Importing to array - /work/Analysis/wgs_chr19/genomicsdb_array; 15:00:38.850 INFO ProgressMeter - Starting traversal; 15:00:38.850 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 15:00:39.771 INFO GenomicsDBImport - Importing batch 1 with 5 samples; Buffer resized from 28469byt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5342:2300,release,releases,2300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5342,1,['release'],['releases']
Deployability,biz.k11i:xgboost-predictor:0.3.0 is now ported to the h2oai repo and released to Maven Central?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7839:69,release,released,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7839,1,['release'],['released']
Deployability,"bly well without this, though.; - [x] Evaluate algorithm on simulated data.; - Implemented simple Queue pipeline for running CLI on simulated ACNV segment files. Takes <2 minutes for ~1000 iterations for each sample, can run 100s of samples in parallel on the gsa clusters.; - Need to write up some scripts to automatically calculate and plot metrics.; - [x] Evaluate algorithm on real data; - Some initial runs on HCC1143 purity series show reasonable results for the clonal model, i.e., purity is recovered within credible intervals (question: what are the error bars on the purities of the samples?). Subclonal performance is a little less clear due to 1) no real ground truth, 2) events in the normal, and 3) lack of outlier absorption.; - Can we get a hold of some cleaner purity series?; - [ ] Document algorithm in technical whitepaper. ---. @samuelklee commented on [Thu Dec 08 2016](https://github.com/broadinstitute/gatk-protected/issues/750#issuecomment-265798051). The first release of this tool will most likely include the following:. - Some refactoring to MCMC package and addition of an EnsembleSampler, which implements affine-invariant ensemble sampling from Goodman & Weare 2010 (this is the same method used by the emcee python package). This method is critical for sampling our highly multimodal posterior well. - Output of 1) all population fraction / ploidy MCMC samples, and 2) average variant profile and 3) posterior summaries at the posterior mode (determined by naive binning of samples). - No plotting. Early next quarter:. - [ ] Unit tests for EnsembleSampler. - [ ] Allowing for >1 tumor population. The model already allows for this, but some performance optimization of the variant-profile sampling step will probably be required. - [ ] Evaluation on BAMs prepared with mixing scripts. - [ ] Writeup of model in technical white paper. - [ ] Tool to produce interactive plots. I think this is necessary to represent the uncertainty in ""solutions"" produced by the tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2909:2507,release,release,2507,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2909,1,['release'],['release']
Deployability,bmRlci91dGlscy9SL1JTY3JpcHRFeGVjdXRvci5qYXZh) | `80.282% <0%> (-8.451%)` | `17% <0%> (-3%)` | |; | [...g/broadinstitute/hellbender/utils/io/Resource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9SZXNvdXJjZS5qYXZh) | `55.556% <0%> (-7.407%)` | `6% <0%> (-1%)` | |; | [...llbender/tools/walkers/bqsr/AnalyzeCovariates.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQW5hbHl6ZUNvdmFyaWF0ZXMuamF2YQ==) | `67.593% <0%> (-4.63%)` | `29% <0%> (-1%)` | |; | [...ute/hellbender/utils/recalibration/RecalUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL1JlY2FsVXRpbHMuamF2YQ==) | `89.407% <0%> (-3.814%)` | `52% <0%> (-1%)` | |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `90.909% <0%> (-3.209%)` | `2% <0%> (+1%)` | |; | [...te/hellbender/tools/spark/sv/utils/SVInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVkludGVydmFsLmphdmE=) | `85.507% <0%> (-1.993%)` | `64% <0%> (+28%)` | |; | [...walkers/bqsr/AnalyzeCovariatesIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQW5hbHl6ZUNvdmFyaWF0ZXNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `92.063% <0%> (-1.783%)` | `22% <0%> (-2%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/b,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-404596846:2425,integrat,integration,2425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-404596846,1,['integrat'],['integration']
Deployability,"both of these are updates to the ImportGenomes wdl:; - reduce memory/cpus for the CreateImportTsvs task from 10GB to 3.75GB and 2 CPU to 1 CPU. these settings were tested on 3000 gvcfs and none errored out because of memory. this ties out spec-ops issues #211 and #233; - before loading files using `bq load`, check for existing files in the gs bucket. only run `bq load` if there are matching files in the bucket. this will prevent an error if you run a subset of samples corresponding to a larger sample map such that you've created a pet_002 table but there aren't any samples to load for pet_002 yet. this was tested in Terra and worked as expected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7121:18,update,updates,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7121,1,['update'],['updates']
Deployability,"broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `84% <100%> (+0.66%)` | `43 <4> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/PathSpecifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUGF0aFNwZWNpZmllci5qYXZh) | `67.1% <0%> (+1.31%)` | `21% <0%> (+1%)` | :arrow_up: |; | [...institute/hellbender/engine/GATKPathSpecifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1BhdGhTcGVjaWZpZXIuamF2YQ==) | `48.21% <0%> (+1.78%)` | `16% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=footer). Last update [aa8e807...d462900](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5832#issuecomment-476229094:2975,update,update,2975,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5832#issuecomment-476229094,2,['update'],['update']
Deployability,"bug reported on `AF=.`, _FilterMutectCalls_ seems to complain about MPOS fields having a value of `.`. No intermediate processing was done between _Mutect2_ and _FilterMutectCalls_. Below the error stack trace :. ```; 17:13:28.491 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data-ddn/home/anthony/sbx/mutect2/work/conda/gatk4-mutect2-nf-bcf605d6af4c0524a368d3d105898641/share/gatk4-4.1.0.0-0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 17:13:30.503 INFO FilterMutectCalls - ------------------------------------------------------------; 17:13:30.503 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.1.0.0; 17:13:30.504 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:13:30.504 INFO FilterMutectCalls - Executing as anthony@node063 on Linux v2.6.32-220.el6.x86_64 amd64; 17:13:30.504 INFO FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 17:13:30.504 INFO FilterMutectCalls - Start Date/Time: February 17, 2019 5:13:28 PM CET; 17:13:30.504 INFO FilterMutectCalls - ------------------------------------------------------------; 17:13:30.505 INFO FilterMutectCalls - ------------------------------------------------------------; 17:13:30.505 INFO FilterMutectCalls - HTSJDK Version: 2.18.2; 17:13:30.505 INFO FilterMutectCalls - Picard Version: 2.18.25; 17:13:30.505 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:13:30.505 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:13:30.505 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:13:30.506 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:13:30.506 INFO FilterMutectCalls - Deflater: IntelDeflater; 17:13:30.506 INFO FilterMutectCalls - Inflater: IntelInflater; 17:13:30.506 INFO FilterMutectCalls - GCS max retries/reopens: 20; 17:13:30.506 INFO FilterMut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5684:1194,release,release-,1194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5684,1,['release'],['release-']
Deployability,"build will break because genomicsdb-0.6.0 hasn't been released yet and dependence on protobuf-java-format needs to be fixed!. @droazen, remember now that I added the dependence on protobuf-java-format to use protobuf.JsonFormat.printToString() method which converts a protobuf structure to JSON string. I want to use import configuration protocol buffers in this code which means this dependence will be back to bite us! Need to fix this cause I don't want to break the Spark build again",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2634:54,release,released,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2634,2,"['configurat', 'release']","['configuration', 'released']"
Deployability,build.gradle finds the tool provider with the following line:. ```; final javadocJDKFiles = files(((URLClassLoader) ToolProvider.getSystemToolClassLoader()).getURLs()); ```; ToolPrivider.getSystemToolClassLoader() returns null on jre and certain other java installations. This causes a confusing null pointer exceptions. We should have a better error message when this happens.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4532:257,install,installations,257,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4532,1,['install'],['installations']
Deployability,"by a quirk of travis this includes pull request builds, so if you need a snapshot you can open a pull request and the head of it will be build into a snapshot on artifactory. the version identifier should will appear in the output of the ""after_sucess"" block on travis; this will only package the linux version of the pairHmm library, to package both versions you must do a manual snapshot. also upgrades gradle to 2.13 to use the new findProperty function. DON'T MERGE UNTIL THE NEW ARTIFACT IS CONFIRMED TO BE IN ARTIFACTORY FOR THIS PR",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1828:396,upgrade,upgrades,396,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1828,1,['upgrade'],['upgrades']
Deployability,"by delegating work to ; `FindBreakpointEvidenceSpark` and `DiscoverVariantsFromContigAlignmentsSpark`, ; so we have a single tool running the whole pipeline. This PR also does:; * refactoring of `FindBreakpointEvidenceSpark` and `DiscoverVariantsFromContigAlignmentsSpark` to accommodate the new tool; * added three integration test (dummy in the sense that it only makes sure they run, and no correctness check on the output) for the three tools. Known differences:. * For NA12878 test sample: The `FindBreakpointEvidenceSpark`->`DiscoverVariantsFromContigAlignmentsSpark` generated VCF and `StructuralVariationDiscoveryPipelineSpark` generated VCF differ by how supplementary alignment's soft clipping is treated. The `FindBreakpointEvidenceSpark`->`DiscoverVariantsFromContigAlignmentsSpark` path has an optimization turned on that soft clipped bases for supplementary alignments are hard clipped away (no contig sequence is lost as it is always saved in the primary alignment), so the CIGARs are a little different. As a consequence, the SAM file generated by the two routes also differ in this CIGAR and sequence part.; * For CHM test sample: The differences are more delicate and even master version yields slightly different results from run to run. So I summarized them in the attached zip. @tedsharpe and @cwhelan please take a look, as `FindBreakpointEvidenceSpark` is modified (no change of logic, but how code is called).; [chm.zip](https://github.com/broadinstitute/gatk/files/919925/chm.zip)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2595:148,pipeline,pipeline,148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2595,2,"['integrat', 'pipeline']","['integration', 'pipeline']"
Deployability,"c 5 12:51:17 2017 -0500. Updates to handle SAM header changes from sl_wgs_acnv_headers and updates to mb_gcnv_python_kernel. commit d02d04df684a2820308a1d1c2bfda4b7d1c5f05e; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Nov 13 12:52:33 2017 -0500. Added CLIs and WDL for python gCNV pipeline. commit 66ed74b68375d43514ef84658e7a6c771ed9053c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Nov 15 01:50:03 2017 -0500. Polished code, ready for review; ; gCNV computational kernel (initial release); ; renaming gammas_s to psi_s to uniformity (sample-specific unexplained variance); ; renamed determine_ploidy_and_depth.py to cohort_determine_ploidy_and_depth.py; finite-temperature forward-backward algorithm; in the ploidy model, replaced alpha_j (NB over-dispersion) with psi_j (unexplained variance) for uniformity. Also, added the possibility of sample-specific unexplained variance in the germline contig ploidy model; ; updated I/O routines and CLIs according to team discussion; ; updated I/O routines and CLIs according to team discussion; ; changed the output layout of the ploidy determination tool; refactored parts of io.py; upped the version to 0.3 as it is not backwards compatible anymore; ; case ploidy determination tool from a given ploidy model; major code cleanup and refactoring of I/O module; refactoring of common CLI script snippets; ; removed all ""targets""; some code cleanup; ; pad flat class bitmask w/ a given padding value in the hybrid q_c_expectation_mode; option to disable annealing and keep the temperature fixed; ; bugfix in finite-temperature forward-backward; further refactoring of model I/O; ; the option to take a previously trained model as starting point in cohort CLI; the option to take previous calls as a starting point in cohort CLI; ; option to save and load adamax moments; ; import/export adamax bias correction tensor; ; refactoring related to fancy opt I/O; added average ploidy column to read depth; updated docs of hybrid ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:10899,update,updated,10899,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,4,['update'],['updated']
Deployability,"c facing evaluations.; - Some hyperparameter tweaking was necessary to achieve good performance. Hyperparameters changed were contained mostly only to `psi_t` parameter.; - We developed a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The following items are necessary done for automatic evaluation:** ; - Dataset + truth. We need an access to a high quality public cohort with matched whole genomes. These genomes have to have a corresponding high quality truth set generated from split-read/read-pair methods. From that cohort we need to find 50-200 relatively homogeneous samples.; - An established vali",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:1302,Pipeline,Pipeline,1302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502,1,['Pipeline'],['Pipeline']
Deployability,"c resources, it seems to me this is a full capitulation of the GATK developer team given a serious bug, especially in light of the fact that the team seems to have enough resources to continue working on Mutect3. Mutect2 has been one of the best performing variant callers of the last years and is a major reason for the Broad's good reputation in the oncology bioinformatics field. GATK and Mutect2 are used by hundreds of institutions in clinical practice, affecting thousands of real patients' lives. Almost all of these institutions are likely to use clinical WES assays due to cost reasons and will thus have been directly affected by this issue _for the last three years_. Also, almost all of these institutions will never learn of this bug since they likely trusted in the developers to have proper functional regression tests in place. If this is indeed the best the Broad can do as an institution, then I will take your offer of providing a build of Mutect2 4.1.8.1 with the log4j vulnerability patched out - thank you. The one thing that I am asking for in addition (for the sake of the overall oncology bioinformatics community), however, is that you conduct a best effort to notify organizations (universities, hospitals, and biotechs/pharmaceuticals that you know are using Mutect2) and best-practise workflow owners (Nextflow, Snakemake, WDL, CWL etc. that include Mutect2) of the forced downgrade. Also, I think it makes sense to include a very prominent warning into the Mutect2 READMEs and GATK best practice documentations and guides. I know that this is work, too, but with success comes responsibility, and I can just hope that providing proper warnings uses less developer bandwidth than applying binary search to find out which of these [10 commits between 4.1.8.1 and 4.1.9.0 that are touching variant filtering (see below)](https://github.com/broadinstitute/gatk/compare/4.1.8.1...4.1.9.0) broke your flagship product enough to abandon it. (For anyone looking at this issue lat",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1535909226:1088,patch,patched,1088,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1535909226,2,['patch'],['patched']
Deployability,c) will **increase** coverage by `0.003%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #5616 +/- ##; ===============================================; + Coverage 87.035% 87.038% +0.003% ; - Complexity 31726 31730 +4 ; ===============================================; Files 1943 1943 ; Lines 146193 146199 +6 ; Branches 16141 16144 +3 ; ===============================================; + Hits 127239 127249 +10 ; + Misses 13067 13064 -3 ; + Partials 5887 5886 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5616?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5616/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `92.632% <100%> (+0.24%)` | `70 <0> (+1)` | :arrow_up: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5616/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.741% <0%> (ø)` | `13% <0%> (ø)` | :arrow_down: |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5616/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/5616/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.861% <0%> (+0.253%)` | `145% <0%> (+1%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntel,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5616#issuecomment-458329538:1283,pipeline,pipelines,1283,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5616#issuecomment-458329538,1,['pipeline'],['pipelines']
Deployability,c-1.2.3.jar;E:\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\repository\org\apache\logging\log4j\log4j-to-slf4j\2.13.2\log4j-to-slf4j-2.13.2.jar;E:\repository\org\apache\logging\log4j\log4j-api\2.13.2\log4j-api-2.13.2.jar;E:\repository\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;E:\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;E:\repository\org\yaml\snakeyaml\1.26\snakeyaml-1.26.jar;E:\repository\com\zaxxer\HikariCP\3.4.5\HikariCP-3.4.5.jar;E:\repository\org\springframework\spring-jdbc\5.2.6.RELEASE\spring-jdbc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-beans\5.2.6.RELEASE\spring-beans-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-tx\5.2.6.RELEASE\spring-tx-5.2.6.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-web\2.3.0.RELEASE\spring-boot-starter-web-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-json\2.3.0.RELEASE\spring-boot-starter-json-2.3.0.RELEASE.jar;E:\repository\com\fasterxml\jackson\core\jackson-databind\2.11.0\jackson-databind-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-annotations\2.11.0\jackson-annotations-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-core\2.11.0\jackson-core-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.11.0\jackson-datatype-jdk8-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.11.0\jackson-datatype-jsr310-2.11.0.jar;E:\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.11.0\jackson-module-parameter-names-2.11.0.jar;E:\repository\org\springframework\boot\spring-boot-starter-tomcat\2.3.0.RELEASE\spring-boot-starter-tomcat-2.3.0.RELEASE.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.35\tomcat-embed-core-9.0.35.jar;E:\repository\org\glassfish\jakarta.el\3.0.3\jakarta.el-3.0.3.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:3443,RELEASE,RELEASE,3443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,"c. to `pytensor`/`pt`/etc. However, there were some more nontrivial changes, including to 1) model priors (since some of the distributions previously used were removed or are now supported differently), 2) the implementation of posterior sampling, 3) some shape/dimshuffle operations, and other things along these lines. Using a single test shard of 20 1kGP WES samples x 1000 intervals, I have verified determinism/reproducibility for DetermineGermlineContigPloidy COHORT/CASE modes, GermlineCNVCaller COHORT/CASE modes, and PostprocessGermlineCNVCalls. Numerical results are also relatively close to those from 4.4.0.0 for all identifiable call and model quantities (albeit far outside any reasonable exact-match thresholds, most likely due to differences in RNG, sampling, and the aforementioned priors). Some remaining TODOs:. - [x] Rebuild and push the base Docker. EDIT: Mostly covered by #8610, but this also includes an addition of `libblas-dev`.; - [x] Update expected results for integration tests, perhaps add any that might be missing. EDIT: These were generated on WSL Ubuntu 20.04.2, we'll see if things pass on 22.04. Note that changing the ARD priors does change the *names* of the expected files, since the transform is appended to the corresponding variable name. DetermineGermlineContigPloidy and PostprocessGermlineCNVCalls are missing exact-match tests and should probably have some, but I'll leave that to someone else.; - [x] Update other python integration tests.; - [x] Clean up some of the changes to the priors.; - [x] Clean up some TODO comments that I left to track code changes that might result in changed numerics. I'll try to go through and convert these to PR comments in an initial review pass.; - [x] Test over multiple shards on WGS and WES. Probably some scientific tests on ~100 samples in both cohort and case mode would do the trick. We should also double check runtime/memory performance (I noted ~1.5x speedups, but didn't measure carefully; I also want to m",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285:1927,Update,Update,1927,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285,2,"['Update', 'integrat']","['Update', 'integration']"
Deployability,"c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9HQVRLU1ZWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...ute/hellbender/tools/spark/sv/AlignmentRegion.java](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9BbGlnbm1lbnRSZWdpb24uamF2YQ==) | `63.265% <100%> (+1.16%)` | `16 <2> (ø)` | :arrow_down: |; | [...lbender/tools/spark/sv/SVVariantConsensusCall.java](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlZhcmlhbnRDb25zZW5zdXNDYWxsLmphdmE=) | `85.556% <80%> (ø)` | `21 <4> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2512?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2512?src=pr&el=footer). Last update [9c1d1fb...f1380fe](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2512#issuecomment-288291739:2816,update,update,2816,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2512#issuecomment-288291739,2,['update'],['update']
Deployability,"c=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwZUNhbGN1bGF0aW9uQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <ø> (ø)` | `2 <0> (ø)` | :x: |; | [...nder/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `46.903% <33.333%> (ø)` | `32 <0> (ø)` | :x: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :white_check_mark: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :x: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2314?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2314?src=pr&el=footer). Last update [5d2f859...ed0b8ca](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2314#issuecomment-267118800:2835,update,update,2835,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2314#issuecomment-267118800,2,['update'],['update']
Deployability,cala:802); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1651); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1606); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1595); > 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); > 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); > 	at org.apache.spark.rdd.RDD.count(RDD.scala:1158); > 	at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); > 	at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); > 	at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:38); > 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); > 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); > 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); > 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); > 	at org.broadinstitute.hellbender.Main.main(Main.java:239); > 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); > 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); > 	at sun.reflect.DelegatingMethodAccessorImp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936:2441,pipeline,pipelines,2441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936,1,['pipeline'],['pipelines']
Deployability,"calibrator - Done initializing engine; 13:35:34.285 INFO BaseRecalibrationEngine - The covariates being used here:; 13:35:34.285 INFO BaseRecalibrationEngine - 	ReadGroupCovariate; 13:35:34.285 INFO BaseRecalibrationEngine - 	QualityScoreCovariate; 13:35:34.285 INFO BaseRecalibrationEngine - 	ContextCovariate; 13:35:34.285 INFO BaseRecalibrationEngine - 	CycleCovariate; 13:35:34.344 INFO ProgressMeter - Starting traversal; 13:35:34.344 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 13:35:44.363 INFO ProgressMeter - chr1:5384544 0.2 214000 1281820.9; ```. 2. Using full path with non-ascii characters in base directory as tmp path and it failed:; ```; /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx8G -Djava.io.tmpdir=/data/xieduo/Łuksza_2022_Nature"" BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; Using GATK jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -Djava.io.tmpdir=/data/xieduo/Łuksza_2022_Nature -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:5334,pipeline,pipeline,5334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,"can be done naively by chunking and writing to multiple HDF5 subdirectories. This will allow for smaller bin sizes. (EDIT: I implemented this in a way that allows one to set the maximum number of values allowed per chunk, so that heap usage can be controlled, but the downside is that this translates into a corresponding limit on the number of columns (i.e., intervals). On the other hand, you could theoretically crank this number up to Integer.MAX_VALUE, as long as you set -Xmx high enough... In practice, it's very unlikely that we'll need to go to bins smaller than a read length.); - [ ] <s>Check that CreatePanelOfNormals works correctly on Spark cluster.</s> Implement Randomized SVD, which should give better performance on large matrices. See https://arxiv.org/pdf/1007.5510.pdf and https://research.fb.com/fast-randomized-svd/. For now, I'll require that the coverage matrix can fit in RAM, but more sophisticated versions of the algorithm could be implemented in the future.; - [ ] Update methods doc. Note that some of the CNV section is out of date and incorrect. In particular, we have been taking in PCOV as input to CreatePanelOfNormals for some time now, but the doc states that we take integer read counts. This already yields different results by the first filtering step (on intervals by interval median). @LeeTL1220 @davidbenjamin what is the ""official ReCapSeg"" behavior, and do we want to keep the current behavior? In general, I think all of the standardization (i.e., filtering/imputation/truncation/transformation) steps could stand some revisiting. Evaluation:. - [ ] Revisit standardization procedure by checking with simulated data. We should make sure that the centering of the data does not rescale the true copy ratio.; - [x] <s>Investigate the effect of keeping duplicates. I am still not sure why we do this, and it may have a more drastic impact on WGS data.</s> Turns out we don't keep duplicates for WGS; see #3367.; - [ ] Check that GC-bias-correction+PCA and P",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316894351:3659,Update,Update,3659,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316894351,1,['Update'],['Update']
Deployability,can i haz integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8757:10,integrat,integration,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8757,1,['integrat'],['integration']
Deployability,catesSpark.java:65); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:348); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.main(Main.java:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: org.apache.spark.Logging; at java.lang.ClassLoader.findClass(ClassLoader.java:530); at org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.scala:26); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.scala:34); at org.apache.spark.util.ChildFirstURLClassLoader.loadClass(MutableURLClassLoader.scala:55); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); ... 56 more; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [16ec1fd0-9528-4249-971e-f1447314bde4] entered state [ERROR] while waiting for [DONE]. ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2183:4976,deploy,deploy,4976,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2183,5,['deploy'],['deploy']
Deployability,"ccurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 105, in <module>; actual_version, force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/bin/theano-nose"", line 11, in <module>; load_entry_point('Theano==1.0.4', 'console_scripts', 'theano-nose')(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 207, in main; result = main_function(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 45, in main_function; from theano import config; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/__init__.py"", line 110, in <module>; from theano.compile import (; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/__init__.py"", line 12, in <module>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 140, in <module>; preargs=args); File ${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2396, in compile_str; (status, compile_stderr.replace('\n', '. '))); Exception: Compilation failed (return status=1): /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_deregisterTMCloneTable. /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:2234,INSTALL,INSTALLDIRGATK,2234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['INSTALL'],['INSTALLDIRGATK']
Deployability,"ce/GRCh37/variants/dbsnp_grch37_b138.vcf.gz -O mutect2/concatenated_ACC5611A5_XXXXXX_mutect2_unfiltered_ss_r2.vcf.gz; 11:47:50.850 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jul 02, 2020 11:47:51 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 11:47:51.054 INFO Mutect2 - ------------------------------------------------------------; 11:47:51.055 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.0; 11:47:51.055 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:47:51.055 INFO Mutect2 - Executing as ashwini.jeggari@compute-0-0.local on Linux v3.10.0-1062.4.1.el7.x86_64 amd64; 11:47:51.055 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 11:47:51.055 INFO Mutect2 - Start Date/Time: July 2, 2020 11:47:50 AM CEST; 11:47:51.056 INFO Mutect2 - ------------------------------------------------------------; 11:47:51.056 INFO Mutect2 - ------------------------------------------------------------; 11:47:51.056 INFO Mutect2 - HTSJDK Version: 2.22.0; 11:47:51.056 INFO Mutect2 - Picard Version: 2.22.8; 11:47:51.056 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:47:51.056 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:47:51.056 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 11:47:51.057 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:47:51.057 INFO Mutect2 - Deflater: IntelDeflater; 11:47:51.057 INFO Mutect2 - Inflater: IntelInflater; 11:47:51.057 INFO Mutect2 - GCS max retries/reopens: 20; 11:47:51.057 INFO Mutect2 - Requester pays: disabled; 11:47:51.057 INFO Mutect2 - Initializing engine; 11:47:51.372 INFO FeatureManager - Using codec V",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-652912482:2177,release,release-,2177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-652912482,1,['release'],['release-']
Deployability,"cf.reblock_gq20/GARDWGSN00001.autosome.g.vcf.gz`. #### Expected behavior; Should run to completion and create reblocked GVCF. #### Actual behavior; ```; Reblocking gvcf.gather/GARDWGSN00001.autosome.g.vcf.gz to gvcf.reblock_gq20/GARDWGSN00001.autosome.g.vcf.gz; Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar ReblockGVCF -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -V gvcf.gather/GARDWGSN00001.autosome.g.vcf.gz -drop-low-quals -rgq-threshold 20 -do-qual-approx -O gvcf.reblock_gq20/GARDWGSN00001.autosome.g.vcf.gz; 11:25:55.531 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jun 30, 2021 11:25:55 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 11:25:55.708 INFO ReblockGVCF - ------------------------------------------------------------; 11:25:55.709 INFO ReblockGVCF - The Genome Analysis Toolkit (GATK) v4.2.0.0; 11:25:55.709 INFO ReblockGVCF - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:25:55.709 INFO ReblockGVCF - Executing as farrell@scc-hadoop.bu.edu on Linux v3.10.0-1160.25.1.el7.x86_64 amd64; 11:25:55.709 INFO ReblockGVCF - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 11:25:55.709 INFO ReblockGVCF - Start Date/Time: June 30, 2021 11:25:55 AM EDT; 11:25:55.710 INFO ReblockGVCF - ------------------------------------------------------------; 11:25:55.710 INFO ReblockGVCF - --------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7334:1555,install,install,1555,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7334,1,['install'],['install']
Deployability,"cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZU1hbmFnZXIuamF2YQ==) | `86.592% <ø> (+1.025%)` | `78% <ø> (+34%)` | :white_check_mark: |; | [...tute/hellbender/engine/MultiVariantDataSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTXVsdGlWYXJpYW50RGF0YVNvdXJjZS5qYXZh) | `84.106% <ø> (+2.001%)` | `52% <ø> (+18%)` | :white_check_mark: |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `72.105% <ø> (+2.54%)` | `4% <ø> (ø)` | :x: |; | [...rg/broadinstitute/hellbender/utils/io/IOUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9JT1V0aWxzLmphdmE=) | `65.704% <ø> (+8.146%)` | `88% <ø> (+45%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2391?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2391?src=pr&el=footer). Last update [6f9de16...7247260](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2391#issuecomment-278096683:3939,update,update,3939,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2391#issuecomment-278096683,2,['update'],['update']
Deployability,ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\repository\org\apache\logging\log4j\log4j-to-slf4j\2.13.2\log4j-to-slf4j-2.13.2.jar;E:\repository\org\apache\logging\log4j\log4j-api\2.13.2\log4j-api-2.13.2.jar;E:\repository\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;E:\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;E:\repository\org\yaml\snakeyaml\1.26\snakeyaml-1.26.jar;E:\repository\com\zaxxer\HikariCP\3.4.5\HikariCP-3.4.5.jar;E:\repository\org\springframework\spring-jdbc\5.2.6.RELEASE\spring-jdbc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-beans\5.2.6.RELEASE\spring-beans-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-tx\5.2.6.RELEASE\spring-tx-5.2.6.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-web\2.3.0.RELEASE\spring-boot-starter-web-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-json\2.3.0.RELEASE\spring-boot-starter-json-2.3.0.RELEASE.jar;E:\repository\com\fasterxml\jackson\core\jackson-databind\2.11.0\jackson-databind-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-annotations\2.11.0\jackson-annotations-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-core\2.11.0\jackson-core-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.11.0\jackson-datatype-jdk8-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.11.0\jackson-datatype-jsr310-2.11.0.jar;E:\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.11.0\jackson-module-parameter-names-2.11.0.jar;E:\repository\org\springframework\boot\spring-boot-starter-tomcat\2.3.0.RELEASE\spring-boot-starter-tomcat-2.3.0.RELEASE.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.35\tomcat-embed-core-9.0.35.jar;E:\repository\org\glassfish\jakarta.el\3.0.3\jakarta.el-3.0.3.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.35\tomcat-embed-websocket-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:3482,RELEASE,RELEASE,3482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,"changes to build.gradle; R package installation is now part of the gradle build; install_R_packages.R no longer reinstalls existing packages; a warning will be emitted if this fails. compilation no longer depends on R installation, installation does. test run in parallel now; this is set to use 2 cores on travis and 4 locally. adding a note about our R dependency to the readme. travis changes; adding caching to travis for dramatic R installation speedup; updating gradle download because it was using an out of date link. misc changes:; adding an additional flag to mark duplicates to avoid the garbage collection statistics while integration testing; tagging tests that depend on R for future use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/296:35,install,installation,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/296,5,"['install', 'integrat']","['installation', 'integration']"
Deployability,changing cran repo for R installation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3443:25,install,installation,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3443,1,['install'],['installation']
Deployability,changing cran repo for R installation -- sol. 2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3451:25,install,installation,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3451,1,['install'],['installation']
Deployability,"che.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 09:14:26.202 INFO PrintReadsSpark - Shutting down engine; [June 8, 2017 9:14:26 AM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=494927872; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /user/yaron/output.bam because writing failed with exception /user/yaron/output.bam.parts/_SUCCESS: Unable to find _SUCCESS file. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file /user/yaron/output.bam because writing failed with exception /user/yaron/output.bam.parts/_SUCCESS: Unable to find _SUCCESS file; at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:255); at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:37); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandL",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:4167,pipeline,pipelines,4167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['pipeline'],['pipelines']
Deployability,"chedulerBackend: Granted executor ID app-20180424175501-0004/5 on hostPort xx.xx.xx.23:49023 with 16 cores, 1024.0 MB RAM; 18/04/24 17:55:01 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180424175501-0004/6 on worker-20180424173107-xx.xx.xx.25-33478 (xx.xx.xx.25:33478) with 16 cores; 18/04/24 17:55:01 INFO NettyBlockTransferService: Server created on xx.xx.xx.16:49734; 18/04/24 17:55:01 INFO StandaloneSchedulerBackend: Granted executor ID app-20180424175501-0004/6 on hostPort xx.xx.xx.25:33478 with 16 cores, 1024.0 MB RAM; 18/04/24 17:55:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 18/04/24 17:55:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, xx.xx.xx.16, 49734, None); 18/04/24 17:55:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/1 is now RUNNING; 18/04/24 17:55:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/2 is now RUNNING; 18/04/24 17:55:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/3 is now RUNNING; 18/04/24 17:55:01 INFO BlockManagerMasterEndpoint: Registering block manager xx.xx.xx.16:49734 with 366.3 MB RAM, BlockManagerId(driver, xx.xx.xx.16, 49734, None); 18/04/24 17:55:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, xx.xx.xx.16, 49734, None); 18/04/24 17:55:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, xx.xx.xx.16, 49734, None); 18/04/24 17:55:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/4 is now RUNNING; 18/04/24 17:55:03 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0; 18/04/24 17:55:03 INFO GoogleHadoopFileSystemBase: GHFS version: 1.6.3-hadoop2; 18/04/24 17:55:04 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/5 is now ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:12806,update,updated,12806,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,3,['update'],['updated']
Deployability,"ci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `46.491% <0%> (-2.632%)` | `32% <0%> (-9%)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `77.996% <0%> (-0.179%)` | `175% <0%> (-1%)` | |; | [...ellbender/tools/walkers/annotator/QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9RdWFsQnlEZXB0aC5qYXZh) | `94.444% <0%> (-0.15%)` | `16% <0%> (-1%)` | |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `85.484% <0%> (-0.116%)` | `49% <0%> (-1%)` | |; | [...ender/tools/walkers/annotator/InbreedingCoeff.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9JbmJyZWVkaW5nQ29lZmYuamF2YQ==) | `82.759% <0%> (ø)` | `11% <0%> (ø)` | :arrow_down: |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=footer). Last update [62d58c5...0492c9c](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2559#issuecomment-290845420:4418,update,update,4418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2559#issuecomment-290845420,2,['update'],['update']
Deployability,"ck broadcast_0 stored as values in memory (estimated size 285.6 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 26.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.131.101.159:34044 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.5 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:34044 (size: 2.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 1 from broadcast at ReadsSparkSink.java:195; 17/10/11 14:19:18 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of fi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:10468,Configurat,Configuration,10468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['Configurat'],['Configuration']
Deployability,clarify expected behavior with test (and update WGS joint; calling WDL in appropriate repos) and update tool docs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6423:41,update,update,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6423,2,['update'],['update']
Deployability,clarify javadoc in BucketUtils regarding PipelineOptions,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/923:41,Pipeline,PipelineOptions,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/923,1,['Pipeline'],['PipelineOptions']
Deployability,clone deep to fix continuous snapshots,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1996:18,continuous,continuous,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1996,1,['continuous'],['continuous']
Deployability,closed by the last PR-8. Flowchart to be updated for documentation purposes.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2703#issuecomment-361073074:41,update,updated,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2703#issuecomment-361073074,1,['update'],['updated']
Deployability,closes #329 . Removed our copy of `Locatable`; updated `getChr()` and `getSequence()` to standardized `getContig()`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/330:47,update,updated,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/330,1,['update'],['updated']
Deployability,"closing at request, and we have an improved pipeline now somewhere else, and a plan for big improvements there.; Thanks for keeping an eye on this, @droazen!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-454980969:44,pipeline,pipeline,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-454980969,1,['pipeline'],['pipeline']
Deployability,closing since google released 208.0.1 before I could get this passing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5004#issuecomment-404305209:21,release,released,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5004#issuecomment-404305209,1,['release'],['released']
Deployability,closing this then in favor of waiting for nio updates,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2333#issuecomment-272010098:46,update,updates,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2333#issuecomment-272010098,1,['update'],['updates']
Deployability,closing. `invalid source release: 1.8` is pretty clear,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/489#issuecomment-119218019:25,release,release,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489#issuecomment-119218019,1,['release'],['release']
Deployability,"cmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `66.667% <0%> (+3.252%)` | `4% <0%> (ø)` | :arrow_down: |; | [...g/broadinstitute/hellbender/engine/AuthHolder.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXV0aEhvbGRlci5qYXZh) | `15.254% <0%> (+5.085%)` | `2% <0%> (ø)` | :arrow_down: |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `77.703% <0%> (+6.757%)` | `22% <0%> (+4%)` | :arrow_up: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `86.4% <0%> (+8.8%)` | `35% <0%> (+7%)` | :arrow_up: |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `23.729% <0%> (+13.559%)` | `2% <0%> (+1%)` | :arrow_up: |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=footer). Last update [5ccfd00...8360cbe](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2573#issuecomment-291977600:4071,update,update,4071,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2573#issuecomment-291977600,2,['update'],['update']
Deployability,cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:201); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.seek(BlockCompressedInputStream.java:380); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:977); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:19744,deploy,deploy,19744,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['deploy'],['deploy']
Deployability,"cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.FileSystemNotFoundException: Provider ""gs"" not installed; 	at java.nio.file.Paths.get(Paths.java:147); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferencePath(ReferenceFileSparkSource.java:53); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferenceBases(ReferenceFileSparkSource.java:60); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceMultiSparkSource.getReferenceBases(ReferenceMultiSparkSource.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.getRefBaseString(BreakEndVariantType.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.access$200(BreakEndVariantType.java:20); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType$InterChromosomeBreakend.<init>(BreakEndVariantType.java:253); 	at org.broadinstitute.hellbender",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:7954,deploy,deploy,7954,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['deploy'],['deploy']
Deployability,code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:2468,configurat,configuration,2468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['configurat'],['configuration']
Deployability,"consider combining this code (along with `AllelicCount`/`PileupSummary`) at some point.; - [x] Added option to use matched normal.; - [ ] Rather than port over the old modeling code, I would rather expand the allele-fraction model to allow for the modeling of hom sites. I wrote up such a model in some notes I sent around a few months back. This model allows for an allelic PoN that uses all sites to learn reference bias, not just hets. Depending on how our python development proceeds, I may try to implement this model using the old `GibbsSampler` code instead.; - [x] In the meantime, we can try to speed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed the mode and highest density credible interval (because of the below item).; - [x] Some residual bias remains in the estimate of the minor-allele fraction posterior mode. This is simply because we are performing kernel density estimation of a bounded quantity. One possibility would be to logit transform to an unbounded support, perform the estimation, then transform back. EDIT: Just removed kernel density estimation for now, partly due to #3599 as well.; - Hmm, actually still a tiny bit of residual bias. This is apparent e.g. in WGS normals. I think focusing on a new allele-fraction model rather than t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:5988,Integrat,Integration,5988,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['Integrat'],['Integration']
Deployability,"consistency loops. For example, consider the mean-field treatment of two coupled Markov chains: the mean-field decoupling of the two chains yields two independent Markov chains with effective emission, transition, and prior probabilities, all of which must be self-consistency determined. The internal admixing rate would be used to admix the old and new self-consistent fields across the two chains in order to dampen oscillations and improve convergence properties. Once internal convergence is achieved, the converged posteriors must be saved to a workspace in order to be consumed by the continuous sub-model. The new internally converged posteriors will be admixed with the old internally converged posteriors from the previous epoch with the _external_ admixing rate. - Introduced two-stage inference for cohort denoising and calling. In the first (""warm-up"") stage, discrete variables are marginalized out, yielding an effective continuous-only model. The warm-up stage calculates continuous posteriors based on the marginalized model. Once convergence is achieved, continuous and discrete variables are decoupled for the second (""main"") stage. The second stage starts with a discrete calling step (crucial), using continuous posteriors from the warm-up stage as the starting point. The motivation behind the two-stage inference strategy is to avoid getting trapped in spurious local minima that are potentially introduced by mean-field decoupling of discrete and continuous RVs. Note that mean-field decoupling has a tendency to stabilize local minima, most of which will disappear or turn into saddle points once correlations are taken into account. While the marginalized model is free of such spurious local minima, it does not yield discrete posteriors in a tractable way; hence, the necessity of ultimately decoupling in the ""main"" stage. - Capped phred-scaled qualities to maximum values permitted by machine precision in order to avoid NaNs and overflows. - Took a first step toward tr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4720:1327,continuous,continuous,1327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4720,1,['continuous'],['continuous']
Deployability,"container for gatk-4.1.4.0. while preparing the gatk conda environment numpy-1.13.3 ins installed but biopython==1.70 requirement from the pip section of the gatkcondaenv.yml. removes it and install numpy-1.18.1. see relevant part of conda env create -n gatk -f gatk-4.1.4.0/gatkcondaenv.yml 2>&1 | tee log; NB full log is attached : [log.txt](https://github.com/broadinstitute/gatk/files/4091802/log.txt). ```; Collecting package metadata (repodata.json): ...working... done; Solving environment: ...working... done. Downloading and Extracting Packages. keras-preprocessing- | 36 KB | ########## | 100%; astor-0.8.0 | 46 KB | ########## | 100%; setuptools-36.4.0 | 563 KB | ########## | 100%; termcolor-1.1.0 | 8 KB | ########## | 100%; protobuf-3.11.2 | 635 KB | ########## | 100%; keras-applications-1 | 33 KB | ########## | 100%; readline-6.2 | 606 KB | ########## | 100%; libgfortran-ng-7.3.0 | 1006 KB | ########## | 100%; numpy-1.13.3 | 3.1 MB | ########## | 100%; ```. numpy-1.13.3 is corectly installed . but then . ```; Collecting numpy (from biopython==1.70->-r /root/gatk-4.1.4.0/condaenv.g1uyq0ce.requirements.txt (line 1)); Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB); ```. that does . ```; Found existing installation: numpy 1.13.3; Uninstalling numpy-1.13.3:; Successfully uninstalled numpy-1.13.3; ```. this causes ```gatk DetermineGermlineContigPloidy ```; to exit with an error related to numpy.testing.decorators which is deprecated since numpy 1.15.0 see https://docs.scipy.org/doc/numpy-1.15.0/release.html. ```; Deprecations. Aliases of builtin pickle functions are deprecated, in favor of their unaliased pickle.<func> names:; numpy.loads; numpy.core.numeric.load; numpy.core.numeric.loads; numpy.ma.loads, numpy.ma.dumps; numpy.ma.load, numpy.ma.dump - these functions already failed on python 3 when called with a string.; Multidimensional index",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6396:1033,install,installed,1033,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6396,1,['install'],['installed']
Deployability,count reads in spark + integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/920:23,integrat,integration,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/920,1,['integrat'],['integration']
Deployability,"create a ""smoke test"" for cluster upgrades",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1392:34,upgrade,upgrades,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1392,1,['upgrade'],['upgrades']
Deployability,"created the google group (gatk-release@broadinstitute.org), populated it and transferred ownership to the team. Created the google project: broad-gatk enabled container registry. Made Geraldine and David Owners. Added gatk-release google group as Editors. Could someone test out pushing to GCR:. docker pull broadinstitute/gatk:someTAG. docker tag broadinstitute/gatk:someTAG us.gcr.io/broad-gatk/gatk:someTAG. gcloud docker -- push us.gcr.io/broad-gatk/gatk:someTAG. Then you should browse to the Google project: https://console.cloud.google.com/gcr/images/broad-gatk?project=broad-gatk&organizationId=548622027621; and see the image",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3793#issuecomment-341801603:31,release,release,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3793#issuecomment-341801603,2,['release'],['release']
Deployability,"cription . Running SV program generates a Java exception...; java.lang.IllegalArgumentException: provided start is negative: -1. #### Steps to reproduce; ```; gatk --java-options ""-Djava.io.tmpdir=tmp"" StructuralVariationDiscoveryPipelineSpark \; -R $REF \; --aligner-index-image GRCh38_full_analysis_set_plus_decoy_hla.fa.img \; --kmers-to-ignore GRCh38_ignored_kmers.txt \; --contig-sam-file hdfs:///project/casa/gcad/$CENTER/sv//$SAMPLE.contig-sam-file\; -I $CRAM_DIR/$SAMPLE.cram \; -O hdfs:///project/casa/gcad/$CENTER/sv/$SAMPLE.sv.vcf \; -- \; --spark-runner SPARK --spark-master yarn --deploy-mode client \; --executor-memory 80G\; --driver-memory 30g\; --num-executors 40\; --executor-cores 4\; --conf spark.yarn.submit.waitAppCompletion=false\; --name ""$SAMPLE"" \; --files $REF.img,$KMER \; --conf spark.yarn.executor.memoryOverhead=5000 \; --conf spark.network.timeout=600 \; --conf spark.executor.heartbeatInterval=120. ```. ```; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Djava.io.tmpdir=tmp --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Djava.io.tmpdir=tmp --deploy-mode client --executor-memory 80G --driver-memory 30g --num-executors 40 --executor-cores 4 --conf spark.yarn.submit.waitAppCompletion=false --name A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr --files file:///restricted/projectnb/casa/ref/GRCh38_full_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:1114,install,install,1114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['install'],['install']
Deployability,cs11.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\rt.jar;C:\project\push\target\classes;E:\repository\org\springframework\boot\spring-boot-starter-jdbc\2.3.0.RELEASE\spring-boot-starter-jdbc-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter\2.3.0.RELEASE\spring-boot-starter-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot\2.3.0.RELEASE\spring-boot-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-autoconfigure\2.3.0.RELEASE\spring-boot-autoconfigure-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-logging\2.3.0.RELEASE\spring-boot-starter-logging-2.3.0.RELEASE.jar;E:\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\repository\org\apache\logging\log4j\log4j-to-slf4j\2.13.2\log4j-to-slf4j-2.13.2.jar;E:\repository\org\apache\logging\log4j\log4j-api\2.13.2\log4j-api-2.13.2.jar;E:\repository\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;E:\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;E:\repository\org\yaml\snakeyaml\1.26\snakeyaml-1.26.jar;E:\repository\com\zaxxer\HikariCP\3.4.5\HikariCP-3.4.5.jar;E:\repository\org\springframework\spring-jdbc\5.2.6.RELEASE\spring-jdbc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-beans\5.2.6.RELEASE\spring-beans-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-tx\5.2.6.RELEASE\spring-t,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:2216,RELEASE,RELEASE,2216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,"cted version(s); - \[x] Latest master branch as of 8/3/18. ### Description ; I am running UpdateVCFSequenceDictionary on a vcf which should have a hg38 header but which (for unrelated unpleasant reasons) instead has a hg19 header. Using an hg38 dictionary as source dict to try to fix the header. If I ask to output a .vcf file, everything works fine. If I ask to output a .vcf.gz file, gatk crashes with; ```; java.lang.ArrayIndexOutOfBoundsException: 12922; 	at htsjdk.samtools.BinningIndexBuilder.processFeature(BinningIndexBuilder.java:89); 	at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeFeature(TabixIndexCreator.java:106); 	at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeIndex(TabixIndexCreator.java:129); 	at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.close(IndexingVariantContextWriter.java:146); 	at htsjdk.variant.variantcontext.writer.VCFWriter.close(VCFWriter.java:212); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.UpdateVCFSequenceDictionary.closeTool(UpdateVCFSequenceDictionary.java:174); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:983); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:182); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:201); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ``` . #### Steps to reproduce; Works: ``gatk UpdateVCFSequenceDictionary -V /dsde/working/ckachulis/UpdateVCFSequenceDictionary_Bug/na12878_hg38_giab_pg_hybrid_happy.vcf.gz -O corrected.dictionary.vcf --source-dictionary /seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.dict --replace ``. Crashes: ``gatk UpdateVCFSequen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5087:1073,Update,UpdateVCFSequenceDictionary,1073,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5087,1,['Update'],['UpdateVCFSequenceDictionary']
Deployability,"ction accept that?. ---. @yfarjoun commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260617185). let me talk with production to see if we can post-facto change the exome; file... On Mon, Nov 14, 2016 at 8:27 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > So, would adding a toggle be acceptable? And more importantly, can we make; > stringent validation default, with the option to not blow up on silly exome; > files? Will production accept that?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260519118,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0tUTNAAyuk3m_2cJ8j_3KYroaqB1ks5q-QpsgaJpZM4JNjE-; > . ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-287821154). Any update on this, @yfarjoun ?. ---. @yfarjoun commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-287826525). I think we will only fix the interval list when we move exomes to; hg38....so, no. On Mon, Mar 20, 2017 at 12:45 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > Any update on this, @yfarjoun <https://github.com/yfarjoun> ?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-287821154>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0hMTukUGLtk1oTOse4Oj3awHf_exks5rnq1CgaJpZM4JNjE->; > .; >. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-287828851). OK well this workaround should really be moved to a ""validation stringency"" level decision, not a hardcoded hack. . @ronlevine Do you know i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2520:3631,update,update,3631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2520,1,['update'],['update']
Deployability,"ctory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run.; CollectIlluminaLaneMetrics (Picard) Collects Illumina lane metrics for the given BaseCalling analysis directory.; ExtractIlluminaBarcodes (Picard) Tool determines the barcode for each read in an Illumina lane.; IlluminaBasecallsToFastq (Picard) Generate FASTQ file(s) from Illumina basecall read data. ...; ```. With this change it instead prints the gatk launcher help, which is not the intended result. ; ```; Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after --; GCS: run using Google cloud dataproc; commands after the -- will be passed to dataproc; --cluster <your-cluster> must be specified after the --; spark properties and some common spark-submit parameters will be translated; to dataproc equivalents. --dry-run may be specified to output the generated command line without running it; --java-options 'OPTION1[ OPTION2=Y ... ]' optional - pass the given string of options to the; java JVM at runtime.; Java options MUST be passed inside a single string with space-separated values.; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030:1429,Configurat,Configuration,1429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030,1,['Configurat'],['Configuration']
Deployability,"ctures with gatk or 2) make sure gatk docker images include the native libraries and are set to use them. Logs for `MarkDuplicatesSpark` without and with native libraries, running on a Broad login server:. Without:. ```; $ ${GATK_DIR}/gatk MarkDuplicatesSpark -I CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -O CEUTrio.HiSeq.WEx37; .NA12892.readnamesort.dupmarked.bam -- --spark-runner LOCAL --spark-master local[8]; Using GATK wrapper script ${GATK_DIR}/gatk/build/install/gatk/bin/gatk; Running:; ${GATK_DIR}/gatk/build/install/gatk/bin/gatk MarkDuplicatesSpark -I CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -O CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.dupmarked.bam --spark; -master local[8]; 14:40:21.800 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 14:40:21.889 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:${GATK_DIR}/gatk/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.so; 14:40:21.989 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 14:40:21.990 INFO MarkDuplicatesSpark - The Genome Analysis Toolkit (GATK) v4.0.4.0-7-g46a8661-SNAPSHOT; 14:40:21.990 INFO MarkDuplicatesSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:40:21.991 INFO MarkDuplicatesSpark - Executing as cwhelan@gsa6.broadinstitute.org on Linux v2.6.32-696.16.1.el6.x86_64 amd64; 14:40:21.991 INFO MarkDuplicatesSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 14:40:21.992 INFO MarkDuplicatesSpark - Start Date/Time: May 7, 2018 2:40:21 PM EDT; 14:40:21.992 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 14:40:21.992 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 14:40:21.992 INFO MarkDuplicatesSpark - HTSJDK Version: 2.14.3; 14:4",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4746:1650,install,install,1650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4746,1,['install'],['install']
Deployability,"currently the travis build is at ~10minutes. There are several options, and we should probably do all of them:; 1. Speedup individual tests:; The top offenders are:; `SplitNCigarReadsIntegrationTest`: this 1 test takes a minute, we can probably do something about this; `MarkDuplicatesIntegrationTest`: 56 tests each taking ~1 second, unclear what we could do; `AnalyzeCovariatesIntegrationTests` 13 tests taking ~40 seconds. Some take longer than others, not sure what we can do about these; `CachingIndexedFastaSequenceFileUnitTest` 21 tests taking a minute. Lets push this to htsjdk.; 2. We lose several minutes installing R libraries (2-3). We could parallelize our travis build and split it into 2 builds, so that 1 branch of the build installs R libraries and then runs the tests that depend on those, and the other branch runs all the other tests. This would probably make the R installation effectively free provided we have sufficient worker nodes.; 3. Run tests in parallel. Travis gives us more than 1 core. I tested running with cores set to 2, and the actual test time dropped nearly in half.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/221:615,install,installing,615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/221,3,['install'],"['installation', 'installing', 'installs']"
Deployability,"currently we only do this for the variants discovered by the tool that is about to be replaced. -----. **UPDATE**; to be more specific, the attributes are `SPLIT_READS `, `READ_PAIRS` and `EXTERNAL_CNV_CALLS`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4228:105,UPDATE,UPDATE,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4228,1,['UPDATE'],['UPDATE']
Deployability,cutor.java:91); at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:63); at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106); at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:92); at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:47); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); at org.gradle.launcher.daemon.server.exec.ResetDeprecationLogger.execute(ResetDeprecationLogger.java:26); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.java:34); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); at org.gradle.launcher.daemon.server.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155:5180,Continuous,ContinuousBuildActionExecuter,5180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155,2,['Continuous'],['ContinuousBuildActionExecuter']
Deployability,cutor.run(DefaultBuildOperationExecutor.java:91); at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:63); at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106); at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:92); at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:47); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); at org.gradle.launcher.daemon.server.exec.ResetDeprecationLogger.execute(ResetDeprecationLogger.java:26); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.java:34); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); at ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155:5142,Continuous,ContinuousBuildActionExecuter,5142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155,2,['Continuous'],['ContinuousBuildActionExecuter']
Deployability,cvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `96.296% <0.000%> (-3.704%)` | :arrow_down: |; | [...rg/broadinstitute/hellbender/utils/SVInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/7951/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TVkludGVydmFsLmphdmE=) | `90.000% <0.000%> (-2.857%)` | :arrow_down: |; | [...ute/hellbender/tools/spark/utils/IntHistogram.java](https://codecov.io/gh/broadinstitute/gatk/pull/7951/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay91dGlscy9JbnRIaXN0b2dyYW0uamF2YQ==) | `86.335% <0.000%> (-2.484%)` | :arrow_down: |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/7951/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `93.333% <0.000%> (-0.784%)` | :arrow_down: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/7951/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `66.818% <0.000%> (-0.455%)` | :arrow_down: |; | [...tructuralVariationDiscoveryArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/7951/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=com,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7951#issuecomment-1189612695:3418,integrat,integration,3418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7951#issuecomment-1189612695,1,['integrat'],['integration']
Deployability,"d evaluating root project 'gatk'.; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvalua",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:2273,configurat,configuration,2273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['configurat'],['configuration']
Deployability,"d from ApplyVQSR. See https://github.com/broadinstitute/gatk/pull/7954#discussion_r933570228.; - [ ] Add behavior for dealing with mixed SNP/INDEL sites in separate passes (and note that the current WDL currently does this, to allow for the use of different annotations across SNPs and INDELs). This might include rescuing previously filtered sites, etc. (e.g., by using the option to ignore the first-pass filter in the second pass). Alternatively, one could use a different FILTER name in each pass, which downstream hard-filtering steps could utilize intelligently. Or one might just split multiallelics upstream. In any case, I would hope that we could move towards running both SNPs and INDELs in a single pass with the same annotations as the default mode of operation.; - [ ] Clean up borrowed code in the `VariantType` class for classifying sites as SNP or INDEL. We mostly retained the VQSR code and logic to make head-to-head comparisons easier. Note also that we converted some switch statements to conditionals, etc. (which I think was done properly, but maybe I missed an edge case). See https://github.com/broadinstitute/gatk/pull/7954#discussion_r934776584.; - [ ] Think more about how to treat empty HDF5 arrays. It's possible we should handle this at the WDL level with optional inputs/outputs. Likely only relevant for atypical edge cases. See https://github.com/broadinstitute/gatk/pull/7954#discussion_r934845337. Next steps:. - [ ] I'll update the BGMM branch and open a PR.; - [ ] I'll start looking at implementing a simple CARROT test. We can just replicate the Cromwell/WDL test for now.; - [ ] Update that initial implementation with non-trivial data and evaluation scripts. EDIT: I see that #7982 was just filed.; - [ ] Implement a CARROT test with malaria data. We already have some evaluation scripts.; - [x] Expand the WDL to enable additional workflow modes (positive-negative, etc.) and the tests to cover them. Right now only vanilla positive-only is enabled/covered.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1209555008:1989,update,update,1989,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1209555008,3,"['Update', 'update']","['Update', 'update']"
Deployability,"d in [section 1.3 of the VCF specification](https://samtools.github.io/hts-specs/VCFv4.3.pdf). I've had a quick look at the code, and think the dubious value may be generated in [ReadPosition::getValueForRead](https://github.com/broadinstitute/gatk/blob/946f39/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/ReadPosition.java#L57) when the result from [ReadPosRankSumTest.getReadPosition](https://github.com/broadinstitute/gatk/blob/946f39/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/ReadPosRankSumTest.java#L53) is cast to an `int`. Looking at that function, it can [return `INVALID_ELEMENT_FROM_READ`](https://github.com/broadinstitute/gatk/blob/946f39/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/ReadPosRankSumTest.java#L62) which is [defined as `Double.NEGATIVE_INFINITY`](https://github.com/broadinstitute/gatk/blob/946f39/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/RankSumTest.java#L23). According to the [java documentation](https://docs.oracle.com/javase/specs/jls/se7/html/jls-5.html#jls-5.1.3), casting NEGATIVE_INFINITY to int will result in a value of `INT_MIN`. (Disclaimer: I haven't tested this, so it may be completely wrong...). #### Steps to reproduce; See attached .zip file which includes a smallish bam file that shows the problem. I ran mutect2 on it in the Docker container for the latest GATK release:; ```sh; unzip mpos_issue.zip; cd mpos_issue; ../gatk Mutect2 --input input/small.bam --reference input/small.fa --output small.vcf; grep MPOS=- small.vcf; ```. #### Expected behavior; `MPOS` should have a sensible value. #### Actual behavior; ```; ref|NC_001224|	12835	.	A	AATAT	.	.	DP=2810;ECNT=5;MBQ=20,34;MFRL=185,202;MMQ=60,29;MPOS=-2147483648;POPAF=7.30;TLOD=3.04	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:2804,3:1.431e-03:2807:1316,3:1412,0:0|1:12828_AATAC_A:12828:1200,1604,2,1; ```. ----. [mpos_issue.zip](https://github.com/broadinstitute/gatk/files/4014487/mpos_issue.zip)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6342:1785,release,release,1785,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6342,1,['release'],['release']
Deployability,d on GCS.; at org.broadinstitute.hellbender.utils.gcs.BucketUtils.dirSize(BucketUtils.java:301); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.getRecommendedNumReducers(GATKSparkTool.java:255); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:237); at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:35); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:313); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. example commandline:. ```; ./gatk-launch PrintReadsSpark -I gs://hellbender/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam -O output --apiKey $HELLBENDER_TEST_APIKEY -- --sparkRunner GCS --cluster dataproc-cluster-3 --project broad-dsde-dev; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1785:1646,deploy,deploy,1646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1785,6,['deploy'],['deploy']
Deployability,d on [Wed Dec 07 2016](https://github.com/broadinstitute/gsa-unstable/issues/1530#issuecomment-265535122). Also increase the kmer size to 35 does the job (-kmerSize 35) I guess that that prevents non-ref paths merge back into the reference between events thus resulting in less complex graphs. ---. @vruano commented on [Wed Dec 07 2016](https://github.com/broadinstitute/gsa-unstable/issues/1530#issuecomment-265535498). The user can be inform of using these work arounds (change the max number of haplotypes or kmersize) but those are not good solutions in general as he would pay a CPU and sensitivity penalty in other places. . ---. @vruano commented on [Wed Dec 07 2016](https://github.com/broadinstitute/gsa-unstable/issues/1530#issuecomment-265551340). I can see how the current best-path selection algorithm may fail to produce a good coverage of events across the active region depending on the weights on edges .... for some configurations the algorithm may dedicate too much time in exploring alternatives in one section of the graph because these are nearly equaly likely disregarding other possibilities other section just because they can only result in a relatively larger drop in the likelihood of the path. . I quick but elegant solution would be to simulate passes across the graph... first iterations would produce a quickly growing set of haplotypes but eventually repeated sampling would not produce new haplotypes. if after 100 subsequent simulations there is no new discovery or we have reached a limit (128?) we would stop there. This simulation approach could be implemented only in situations the graphs are too complex for an analytical solution. We can determine the maximum number of paths in a graph with a quick deep first traversal to decide whether to use the analytical-exact or the simulation-proximate approach. . ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1530#issuecomment-287813366). To be done in GATK4.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2954:4673,configurat,configurations,4673,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2954,1,['configurat'],['configurations']
Deployability,"d try to do it, as that is a relatively expensive resource to create. For example, some very naive hard filtering (red) of the histogram yields a peak that is easily fit by a negative binomial (green)---even a Poisson fit does not appear to bias the depth estimates, and certainly does not result in incorrect ploidy estimates:. ![masked_fit](https://user-images.githubusercontent.com/11076296/37863641-827a6e8a-2f37-11e8-83d5-cb4af32a898b.png). (Incidentally, it is helpful to plot on a log scale when checking the fit of these distributions.). This strategy also gives us a way to ignore low-level mosaicism or large germline events, which filtering on mappability may not address:. ![mosaic](https://user-images.githubusercontent.com/11076296/37863649-d0ac378c-2f37-11e8-8e98-45e1fa9a3d7a.png). So let's try to encapsulate changes to the ploidy tool. I agree that the histogram creation can be easily done on the Java side, to save on intermediate file writing. We can probably just cap the maximum bin to `k` and pass a samples x contig TSV where each entry is a vector with `k + 1` elements. I agree that there is still a lot of important work to be done in exploring our best practices for coverage collection, and I know that you have been interested in improving them for a while. Ultimately, we may want to consider incorporating mappability or other informative metadata, as we've discussed. However, this will require some non-trivial investment in method/tool development time. Since our preliminary evaluations show that even with the current, naive strategies the tool is performing reasonably well, I am prioritizing cutting a release and improving/automating the evaluations. As we discussed, this will both allow users to start using the tool (which will hopefully result in useful feedback) and establish a baseline for us. This will ultimately provide the necessary foundation for future exploratory work and method development---which always takes more time than we think it will!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040:2209,release,release,2209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040,2,['release'],['release']
Deployability,"d!; 17/10/13 18:11:54 INFO spark.SparkContext: Successfully stopped SparkContext; 18:11:54.552 INFO PrintReadsSpark - Shutting down engine; [October 13, 2017 6:11:54 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.35 minutes.; Runtime.totalMemory()=806354944; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /gatk4/output_3.bam because writing failed with exception /gatk4/output_3.bam.parts/_SUCCESS: Unable to find _SUCCESS file. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file /gatk4/output_3.bam because writing failed with exception /gatk4/output_3.bam.parts/_SUCCESS: Unable to find _SUCCESS file; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:264); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:39); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMet",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:23840,pipeline,pipelines,23840,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['pipeline'],['pipelines']
Deployability,"d:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Uti",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:36301,pipeline,pipelines,36301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['pipeline'],['pipelines']
Deployability,dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `2.970% <0.000%> (-71.287%)` | :arrow_down: |; | [...nder/utils/codecs/copynumber/SimpleCountCodec.java](https://codecov.io/gh/broadinstitute/gatk/pull/7810/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2RlY3MvY29weW51bWJlci9TaW1wbGVDb3VudENvZGVjLmphdmE=) | `21.875% <0.000%> (-53.125%)` | :arrow_down: |; | [...nder/utils/nio/NioFileCopierWithProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/7810/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyLmphdmE=) | `17.085% <0.000%> (-52.764%)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/7810/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `16.667% <0.000%> (-50.000%)` | :arrow_down: |; | [...ols/funcotator/FuncotatorDataSourceDownloader.java](https://codecov.io/gh/broadinstitute/gatk/pull/7810/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JEYXRhU291cmNlRG93bmxvYWRlci5qYXZh) | `20.833% <0.000%> (-45.833%)` | :arrow_down: |; | [...tute/hellbender/utils/bigquery/TableReference.java](https://codecov.io/gh/broadinstitute/gatk/pull/7810/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7810#issuecomment-1109049263:3830,pipeline,pipelines,3830,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7810#issuecomment-1109049263,1,['pipeline'],['pipelines']
Deployability,dGUvaGVsbGJlbmRlci9lbmdpbmUvTG9jYWxSZWFkU2hhcmQuamF2YQ==) | `100% <100%> (ø)` | `13 <1> (-4)` | :arrow_down: |; | [...va/org/broadinstitute/hellbender/engine/Shard.java](https://codecov.io/gh/broadinstitute/gatk/pull/2372?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvU2hhcmQuamF2YQ==) | `100% <100%> (ø)` | `15 <5> (+5)` | :arrow_up: |; | [.../hellbender/utils/iterators/FilteringIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2372?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pdGVyYXRvcnMvRmlsdGVyaW5nSXRlcmF0b3IuamF2YQ==) | `90% <90%> (ø)` | `8 <8> (?)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2372?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2372?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/2372?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> (ø)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2372?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/2372?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvY,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2372#issuecomment-307349042:2660,pipeline,pipelines,2660,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2372#issuecomment-307349042,1,['pipeline'],['pipelines']
Deployability,"dMateCigar Reverts the original base qualities and adds the mate cigar tag to read-group BAMs; RevertSam Reverts SAM/BAM files to a previous state; SamFormatConverter Convert a SAM/BAM/CRAM file to a SAM/BAM/CRAM file; SamToFastq Converts a SAM/BAM file into a FASTQ; SortSam Sorts a SAM/BAM/CRAM file; SplitNCigarReads Split Reads with N in Cigar; SplitReads Outputs reads from a SAM/BAM/CRAM by read group, sample and library name; UnmarkDuplicates Unmark duplicates in a SAM/BAM/CRAM file; ValidateSamFile Validates a SAM/BAM/CRAM file. --------------------------------------------------------------------------------------; Spark Validation tools: Tools written in Spark to compare aspects of two different files; CompareBaseQualitiesSpark Diff qs of the BAMs; CompareDuplicatesSpark Compares two BAMs for duplicates. --------------------------------------------------------------------------------------; Spark pipelines: Pipelines that combine tools and use Apache Spark for scaling out (experimental); BQSRPipelineSpark Both steps of BQSR (BaseRecalibrator and ApplyBQSR) on Spark; ReadsPipelineSpark Takes aligned reads (likely from BWA) and runs MarkDuplicates and BQSR. The final result is analysis-ready reads. --------------------------------------------------------------------------------------; Spark tools: Tools that use Apache Spark for scaling out (experimental); ApplyBQSRSpark ApplyBQSR on Spark; BaseRecalibratorSpark BaseRecalibrator on Spark; BaseRecalibratorSparkSharded BaseRecalibrator on Spark (experimental sharded implementation); CollectBaseDistributionByCycleSpark CollectBaseDistributionByCycle on Spark; CollectQualityYieldMetricsSpark CollectQualityYieldMetrics on Spark; CountBasesSpark CountBases on Spark; CountReadsSpark CountReads on Spark; CountVariantsSpark CountVariants on Spark; CreateHadoopBamSplittingIndex create a hadoop-bam splitting index; FindBadGenomicKmersSpark find ref kmers with high copy number; FindSVBreakpointsSpark Produce small FASTQs of",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1669:6713,pipeline,pipelines,6713,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1669,2,"['Pipeline', 'pipeline']","['Pipelines', 'pipelines']"
Deployability,"dPosRankSum=0.433	GT:AD:DP:GQ:PL:SB	0/2:414,2,357,0:773:99:14672,11361,50781,0,41338,45124,13972,52387,44158,56529:206,208,177,182; chr13	32944608	.	T	A,*,<NON_REF>	0	.	BaseQRankSum=5.453;DP=797;ExcessHet=3.0103;MLEAC=0,1,0;MLEAF=0.00,0.500,0.00;MQRankSum=0.000;RAW_MQandDP=2869200,797;ReadPosRankSum=0.386	GT:AD:DP:GQ:PL:SB	0/2:413,2,357,0:772:99:14840,11462,50871,0,41338,45112,14111,52486,44158,56658:203,210,177,182; chr13	32944609	.	T	A,*,TAAAA,<NON_REF>	0	.	BaseQRankSum=4.278;DP=787;ExcessHet=3.0103;MLEAC=0,1,0,0;MLEAF=0.00,0.500,0.00,0.00;MQRankSum=0.000;RAW_MQandDP=2833200,787;ReadPosRankSum=0.252	GT:AD:DP:GQ:PL:SB	0/2:411,2,357,0,0:770:99:14840,11462,50871,0,41338,45112,17297,53328,47568,2147483647,16108,52933,46273,64838,62381:201,210,177,182; chr13	32944610	.	T	<NON_REF>	.	.	END=32944794	GT:DP:GQ:MIN_DP:PL	0/0:627:99:265:0,120,1800; ```. #### Steps to reproduce; * init; ```; hg19=pipeline/hg19/hg19_chM_male_mask.fa; ```; * reproduce of 4.0.8.1; ```; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.gvcf -ERC GVCF && tail target.4.0.8.1.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.vcf && tail target.4.0.8.1.vcf; ```; * reproduce of 4.0.9.0; ```; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.gvcf -ERC GVCF && tail target.4.0.9.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.vcf && tail target.4.0.9.0.vcf; ```; * reproduce of 4.1.2.0; ```; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.gvcf -ERC GVCF && tail target.4.1.2.0.gvcf; github.com/broadinst",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5975:5941,release,releases,5941,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5975,1,['release'],['releases']
Deployability,"data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar ; ; Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx30G -jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test.table ; ; 00:12:20.992 INFO  NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 00:12:21.140 INFO  BaseRecalibrator - ------------------------------------------------------------ ; ; 00:12:21.141 INFO  BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.2.6.1 ; ; 00:12:21.141 INFO  BaseRecalibrator - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 00:12:21.141 INFO  BaseRecalibrator - Executing as xieduo@pbs-master on Linux v3.10.0-1160.41.1.el7.x86\_64 amd64 ; ; 00:12:21.141 INFO  BaseRecalibrator - Java runtime: Java HotSpot(TM) 64-Bit Server VM v18+36-2087 ; ; 00:12:21.142 INFO  BaseRecalibrator - Start Date/Time: August 21, 2022 at 12:12:20 AM CST ; ; 00:12:21.142 INFO  BaseRecalibrator - ------------------------------------------------------------ ; ; 00:12:21.142 INFO  BaseRecalibrator - ------------------------------------------------------------ ; ; 00:12:21.1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:15814,pipeline,pipeline,15814,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability,data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz  -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test.table ; ; Using GATK jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar ; ; Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx30G -jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test.table ; ; 00:12:20.992 INFO  NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 00:12:21.140 INFO  BaseRecalibrator - ------------------------------------------------------------ ; ; 00:12:21.141 INFO  BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.2.6.1 ; ; 00:12:21.141 INFO  BaseRecalibrator - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 00:12:21.141 INFO  BaseRecalibrator - Executing as xieduo@pbs-master on Linux v3.10.0-1160.41,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:15370,pipeline,pipeline,15370,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability,"dbSNP build, it throws this error:. \[Fri Jul 23 13:25:03 CEST 2021\] picard.vcf.CollectVariantCallingMetrics done. Elapsed time: 70.55 minutes. Runtime.totalMemory()=1623195648. To get help, see [http://broadinstitute.github.io/picard/index.html#GettingHelp](http://broadinstitute.github.io/picard/index.html#GettingHelp). java.lang.NullPointerException: Cannot invoke ""htsjdk.samtools.SAMSequenceRecord.getSequenceLength()"" because the return value of ""htsjdk.samtools.SAMSequenceDictionary.getSequence(String)"" is null. at picard.util.DbSnpBitSetUtil.loadVcf(DbSnpBitSetUtil.java:163). at picard.util.DbSnpBitSetUtil.createSnpAndIndelBitSets(DbSnpBitSetUtil.java:131). at picard.vcf.CollectVariantCallingMetrics.doWork(CollectVariantCallingMetrics.java:101). at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:308). at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:37). at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160). at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203). at org.broadinstitute.hellbender.Main.main(Main.java:289). As a bit of a background, I am trying to use the latest dbSNP release (build 155, GRCh38, GCF\_000001405.39) and have tried using GATK version 4.1.9.0 and the latest 4.2.0.0, both having the same problem. To prepare the dbSNP file for use with the best practices workflow, I renamed the NCBI chromosome accession numbers  to UCSC style names using bcftools annotate, updated the vcf headers using UpdateVcfSequenceDictionary, and indexed the file using IndexFeatureFile. The dbSNP file worked well with both HaplotypeCaller and GenotypeGVCFs, with the rsids overlapping perfectly with those obtained when using the dbSNP resource bundle version. Any help with this would be greatly appreciated!<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/171466'>Zendesk ticket #171466</a>)<br>gz#171466</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7383:2185,release,release,2185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7383,3,"['Update', 'release', 'update']","['UpdateVcfSequenceDictionary', 'release', 'updated']"
Deployability,"deOverlapAlignments(final List<AlignmentInterval> originalAlignments,; > + final SAMSequenceDictionary refSequenceDictionary) {; > + final List<AlignmentInterval> result = new ArrayList<>(originalAlignments.size());; > + final Iterator<AlignmentInterval> iterator = originalAlignments.iterator();; > + AlignmentInterval one = iterator.next();; > + while (iterator.hasNext()) {; > + final AlignmentInterval two = iterator.next();; > + // TODO: 11/5/17 an edge case is possible where the best configuration contains two alignments,; > + // one of which contains a large gap, and since the gap split happens after the configuration scoring,; > I agree it is backwards. But...; > ; > The reason was that the (naive) alignment configuration scoring module rightnow uses MQ and AS (aligner score) for picking the ""best"" configuration (i.e. sub-list of the alignments given by aligner), which would be technically wrong if we were to split the gap and to simply grab the originating alignment's values.; > ; > This is especially true for AS, whose recomputing takes more time, and code, and forces us to know how AS are computed in the aligner so that there's no bias in computing the scores of naive alignments vs gap-split alignments (may not matter in practice, but still takes more code to compute).; > ; > Lots of the code in the discovery stage was devoted actually to alignment related acrobatics and edge cases so that the breakpoints we could resolve are as accurate as possible.; > I've kept in mind your wisdom that different aligners may be experimented with, but it seems unlikely in the near future (their own quirkiness, lack of API for JNI, etc); it seems more and more likely to me that eventually it's inevitable to have a custom alignment module in a high-quality SV pipeline, but again, the near future has other top priorities.; > ; > What do you think?; > ; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-350618009:2797,pipeline,pipeline,2797,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-350618009,2,['pipeline'],['pipeline']
Deployability,"ded. A previous user already found a similar error in ValidateVariants (https://gatk.broadinstitute.org/hc/en-us/community/posts/360061452132-GATK4-RNAseq-short-variant-discovery-SNPs-Indels-), but then for Haplotypecaller, and you have opened a bugreport to add a feature to ValidateVariants: https://github.com/broadinstitute/gatk/issues/6553. However, it would be nice if you could actually investigate the formatting error. Unfortunately my formatting error isn't the same as reported in the other post. I have 105 error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position chr\_1:1088200 are not observed at all in the sample genotypes \*\*\*\*\* ; ; chr\_1 1088200 . T \*,TAAAAAAAAAAAA 64.39 . AC=8,0;AF=0.667,0.00;AN=12;DP=118;ExcessHet=3.0103;FS=0.000;InbreedingCoeff=0.4286;MLEAC=7,7;MLEAF=0.583,0.583;MQ=58.73;QD=32.19;SOR=2.303 GT:AD:DP:GQ:PL ./.:9,0,0:9:.:0,0,0,0,0,0 0/0:9,0,0:9:0:0,0,113,0,113,113 ./.:10,0,0:10:.:0,0,0,0,0,0 ./.:5,0,0:5:.:0,0,0,0,0,0 1/1:0,0,1:1:0:225,15,0,15,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:12,0,0:12:.:0,0,0,0,0,0 ./.:8,0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:1527,pipeline,pipeline,1527,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['pipeline'],['pipeline']
Deployability,default configuration rather than the path. Fixes #1324.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1433:8,configurat,configuration,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1433,1,['configurat'],['configuration']
Deployability,"dependency-name=commons-io:commons-io&package-manager=gradle&previous-version=2.7&new-version=2.14.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/broadinstitute/gatk/network/alerts). </details>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9003:1624,upgrade,upgrade,1624,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9003,3,['upgrade'],['upgrade']
Deployability,"der.tools.dragstr.ComposeSTRTableFile done. Elapsed time: 10.52 minutes.; Runtime.totalMemory()=1128792064; Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16G -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar CalibrateDragstrModel -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --str-table-path gvcf.STR/ADNI_002_S_0413.hg38.realign.bqsr/ADNI_002_S_0413.hg38.realign.bqsr.STR.table -O gvcf.STR/ADNI_002_S_0413.hg38.realign.bqsr/ADNI_002_S_0413.hg38.realign.bqsr.Dragstr.model -I /restricted/projectnb/casa/wgs.hg38/adni/cram/ADNI_002_S_0413.hg38.realign.bqsr.cram; 13:55:30.890 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Apr 04, 2021 1:55:31 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:55:31.182 INFO CalibrateDragstrModel - ------------------------------------------------------------; 13:55:31.183 INFO CalibrateDragstrModel - The Genome Analysis Toolkit (GATK) v4.2.0.0; 13:55:31.183 INFO CalibrateDragstrModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:55:31.183 INFO CalibrateDragstrModel - Executing as farrell@scc-hadoop.bu.edu on Linux v3.10.0-1160.15.2.el7.x86_64 amd64; 13:55:31.184 INFO CalibrateDragstrModel - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:55:31.184 INFO CalibrateDragstrModel - Start Date/Time: April 4, 2021 1:55:30 PM EDT; 13:55:31.184 INFO CalibrateDragstrModel - ------------------------------------------------------------; 13",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182:12051,install,install,12051,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182,1,['install'],['install']
Deployability,"der/tools/spark/sv/RunSGAViaProcessBuilderOnSpark/assembly4.pp.ec.filter.pass.fa (8); > A src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/RunSGAViaProcessBuilderOnSpark/assembly4.pp.ec.filter.pass.merged.fa (84); > A src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/RunSGAViaProcessBuilderOnSpark/assembly4.pp.ec.filter.pass.merged.rmdup-contigs.fa (30); > A src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/RunSGAViaProcessBuilderOnSpark/assembly4.pp.ec.filter.pass.merged.rmdup.fa (84); > R src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/RunSGAViaProcessBuilderOnSpark/assembly4.pp.fq (0); > R src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/RunSGAViaProcessBuilderOnSpark/assembly9.fastq (0); > R src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/RunSGAViaProcessBuilderOnSpark/assembly9.pp.ec.fa (2); > R src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/RunSGAViaProcessBuilderOnSpark/assembly9.pp.ec.filter.pass.fa (4); > A src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/RunSGAViaProcessBuilderOnSpark/assembly9.pp.ec.filter.pass.merged.fa (46); > A src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/RunSGAViaProcessBuilderOnSpark/assembly9.pp.ec.filter.pass.merged.rmdup-contigs.fa (14); > R src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/RunSGAViaProcessBuilderOnSpark/assembly9.pp.ec.filter.pass.merged.rmdup.fa (20); > R src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/RunSGAViaProcessBuilderOnSpark/assembly9.pp.fq (0); > A src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/SingleDiploidSampleBiallelicSVGenotyperSpark/inversions.vcf (25); > Patch Links:; > ; > https://github.com/broadinstitute/gatk/pull/2189.patch; > https://github.com/broadinstitute/gatk/pull/2189.diff; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2189#issuecomment-250052886:6470,Patch,Patch,6470,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2189#issuecomment-250052886,2,"['Patch', 'patch']","['Patch', 'patch']"
Deployability,"der/utils/MannWhitneyU.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9NYW5uV2hpdG5leVUuamF2YQ==) | `92.793% <92.593%> (+17.237%)` | `48 <48> (+21)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `72.078% <0%> (-1.948%)` | `35% <0%> (ø)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `93.75% <0%> (-1.563%)` | `21% <0%> (-1%)` | |; | [...titute/hellbender/tools/spark/sv/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkTWV0YWRhdGEuamF2YQ==) | `84.104% <0%> (+2.358%)` | `36% <0%> (+11%)` | :arrow_up: |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `42.989% <0%> (+4.441%)` | `46% <0%> (+18%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=footer). Last update [c350a09...3b4f53e](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2605#issuecomment-294213579:3358,update,update,3358,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2605#issuecomment-294213579,2,['update'],['update']
Deployability,"dian count is significantly away from the main peak (due to the abundance of low mappability bins with small counts). . Also, the second peak of chrX coverage in XY samples that you show above is not a large germline event -- it is simply a low mappable PAR-like region that borrows reads from chrY. Here's how the X coverage distribution looks like on an XY sample after mappability filtering (which removes most of all approximate homologies):; ![chrx](https://user-images.githubusercontent.com/15305869/37867778-54e3d196-2f73-11e8-8345-d8964b39a17e.png). **The second spurious peak is gone and range of NB-like behavior is pretty much perfect. Without mappability filtering, all of the bins on the second mode _will_ show up as CN = 2 events (in fact, if you look at gCNV calls on a typical XY samples, there are tons of CN = 2 calls).**. Most, if not all, of the non-NB-like coverage before/after the main peak in your plots are reads from unmappable regions, many of which show up as real CNV events if we do not filter them (reads in these regions do not follow from the coverage model and we are at the mercy of BWA). I strongly believe Genome STRiP has achieved ~ 99% experimental validation accuracy because of aggressive filtering, not because of a superior model (it's an elementary Gaussian mixture mix). Garbage in, garbage out. Anyhow, I am not comfortable at all with cutting a non-Beta release without taking care of about:. 1. Mappability-based bin/read filtering (for WGS), and; 2. Trying out and evaluating a bait-based coverage collection (for WES), so that the raw coverage distribution is more NB-like to begin with. These are both perfectly achievable goals before May 15. I'd be happy to leave stuff such as different coverage collection strategies (e.g. base call coverage) and fragment-based per-sample GC content estimation for later. These are other areas where significant improvements come from. For the record -- I am working full steam on evaluations, as we discussed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375917669:1604,release,release,1604,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375917669,2,['release'],['release']
Deployability,diff engine port and added hookup for our integration tests; +added PrintVariants as an example variant walker,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/619:42,integrat,integration,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/619,1,['integrat'],['integration']
Deployability,dinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.runTool(ReadsPipelineSpark.java:224); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:148); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:189); 	at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSparkIntegrationTest.testReadsPipelineSpark(ReadsPipelineSparkIntegrationTest.java:125); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5680:7698,pipeline,pipelines,7698,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680,1,['pipeline'],['pipelines']
Deployability,"directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260495927,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0uvegvUmCq7_G7U2PSuTpvIYl0wQks5q-Ox0gaJpZM4JNjE-; > . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260519118). So, would adding a toggle be acceptable? And more importantly, can we make stringent validation default, with the option to not blow up on silly exome files? Will production accept that?. ---. @yfarjoun commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260617185). let me talk with production to see if we can post-facto change the exome; file... On Mon, Nov 14, 2016 at 8:27 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > So, would adding a toggle be acceptable? And more importantly, can we make; > stringent validation default, with the option to not blow up on silly exome; > files? Will production accept that?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260519118,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0tUTNAAyuk3m_2cJ8j_3KYroaqB1ks5q-QpsgaJpZM4JNjE-; > . ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-287821154). Any update on this, @yfarjoun ?. ---. @yfarjoun commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-287826525). I think we will only fix the interval list when we move exomes to; hg38....so, no. On Mon, Mar 20, 2017 at 12:45 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > Any update on this, @yfarjoun <https://github.com/yfarjoun> ?; >; > —; > You are receiving this because you were mentioned.; >",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2520:2990,toggle,toggle,2990,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2520,1,['toggle'],['toggle']
Deployability,"directory /tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-0bd07e00-4f6d-43bd-b9d2-b1999376c72b; ```. Just to verify, the non-spark version still runs fine with the compressed fasta.... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; 13:38:54.168 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:38:55.869 INFO CountReads - ------------------------------------------------------------; 13:38:55.870 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:38:55.870 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:38:55.871 INFO CountReads - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:38:55.871 INFO CountReads - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:38:55.871 INFO CountReads - Start Date/Time: January 9, 2019 1:38:54 PM EST; 13:38:55.871 INFO CountReads - ------------------------------------------------------------; 13:38:55.871 INFO CountReads - ------------------------------------------------------------; 13:38:55.872 INFO CountReads - HTSJDK Version: 2.18.1; 13:38:55.873 INFO CountReads - Picard Version: 2.18.16; 13:38:55.873 INFO CountReads - HTSJDK Defaults.COMPRESSION_",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:44072,install,install,44072,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['install'],['install']
Deployability,dk8\2.11.0\jackson-datatype-jdk8-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.11.0\jackson-datatype-jsr310-2.11.0.jar;E:\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.11.0\jackson-module-parameter-names-2.11.0.jar;E:\repository\org\springframework\boot\spring-boot-starter-tomcat\2.3.0.RELEASE\spring-boot-starter-tomcat-2.3.0.RELEASE.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.35\tomcat-embed-core-9.0.35.jar;E:\repository\org\glassfish\jakarta.el\3.0.3\jakarta.el-3.0.3.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.35\tomcat-embed-websocket-9.0.35.jar;E:\repository\org\springframework\spring-web\5.2.6.RELEASE\spring-web-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-webmvc\5.2.6.RELEASE\spring-webmvc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\repository\org\springframework\spring-core\5.2.6.RELEASE\spring-core-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-jcl\5.2.6.RELEASE\spring-jcl-5.2.6.RELEASE.jar;E:\repository\com\google\firebase\firebase-admin\6.8.1\firebase-admin-6.8.1.jar;E:\repository\com\google\ap,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:4822,RELEASE,RELEASE,4822,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,doesn't need to be this PR but I believe we also need to update [this](https://github.com/broadinstitute/gatk/blob/8813ed0fca9f98af8991db27ee3e8f95c5aeeec7/scripts/variantstore/wdl/GvsJointVariantCalling.wdl#L42) (and maybe somewhere similar for Quickstart?),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8401#issuecomment-1621814615:57,update,update,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8401#issuecomment-1621814615,1,['update'],['update']
Deployability,dont we also need to update ; scripts/variantstore/wdl/extract/run_gvs_tieout_extract.sh ? ; might be worth rebasing to make sure you have Kris' latest changes to that script,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7196#issuecomment-816865790:21,update,update,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7196#issuecomment-816865790,1,['update'],['update']
Deployability,"down all executors; 17/10/13 18:11:54 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 17/10/13 18:11:54 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/13 18:11:54 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/13 18:11:54 INFO memory.MemoryStore: MemoryStore cleared; 17/10/13 18:11:54 INFO storage.BlockManager: BlockManager stopped; 17/10/13 18:11:54 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/13 18:11:54 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/13 18:11:54 INFO spark.SparkContext: Successfully stopped SparkContext; 18:11:54.552 INFO PrintReadsSpark - Shutting down engine; [October 13, 2017 6:11:54 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.35 minutes.; Runtime.totalMemory()=806354944; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /gatk4/output_3.bam because writing failed with exception /gatk4/output_3.bam.parts/_SUCCESS: Unable to find _SUCCESS file. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file /gatk4/output_3.bam because writing failed with exception /gatk4/output_3.bam.parts/_SUCCESS: Unable to find _SUCCESS file; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:264); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:39); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:23061,pipeline,pipelines,23061,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['pipeline'],['pipelines']
Deployability,"ds but `VariantAnnotator` only has the reads. Several annotations had fallback code to annotate a likelihoods object that had no likelihoods. @vruano This is the class that you disliked so much in your recent code review of #5783 . A few issues with this state of things:. * Torturing the definition of `AlleleLikelihoods`, which forced the class to have methods like `hasLikelihoods()`.; * `VariantAnnotator` only applied the few annotations that had custom pileup-based fallback code.; * Lots more annotation code for the fallback mode. So the first step was the option that @lbergelson and @jamesemery liked most: create a regular likelihoods object in `VariantAnnotator` by hard-assigning of each read to the allele it best matches. This is exactly what all the custom fallback modes were doing in effect, but now it's implemented in one place instead of six or so. This lets us delete `UnfilledLikelihoods` and also lets `VariantAnnotator` apply any annotation. @ldgauthier Since the most non-trivial aspect is the new integration test I'm inclined to assign you the review, but a case could be made for someone on the engine team. This completely broke the `VariantAnnotator` tests, which were based on exact matches. This had been an issue before and has always been a bit of a nuisance, but now overhauling the tests became completely unavoidable. So, I rewrote all the tests and wrote a rigorous test based on concordance with annotations from `Mutect2`. If I were reviewing I would start with the new code in `VariantAnnotator` that constructs the likelihoods object from the reads and verify that it is just a more polished version of the fallback code that several annotations used to have. Then I would look at the new `VariantAnnotator` integration tests. Some of the tolerances are fairly liberal but it's worth noting that much of the old exact match ""truth"" annotations were completely bogus. This is better than what we had before by a long shot but it's still use at your own risk.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6172:1269,integrat,integration,1269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6172,2,['integrat'],['integration']
Deployability,"dsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `93.103% <100%> (+1.103%)` | `8 <1> (+1)` | :arrow_up: |; | [...adinstitute/hellbender/utils/spark/SparkUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zcGFyay9TcGFya1V0aWxzLmphdmE=) | `71.154% <63.158%> (-4.604%)` | `9 <5> (+5)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `95.313% <0%> (+1.563%)` | `22% <0%> (+1%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.909% <0%> (+3.831%)` | `46% <0%> (+11%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=footer). Last update [2ecdef4...71a1b94](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2419#issuecomment-293289091:3377,update,update,3377,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2419#issuecomment-293289091,2,['update'],['update']
Deployability,"due to recursive implementation of Legendre abscissas in Apache Commons. @vdauwera @takutosato this is very simple; it just caps the number of subdivisions of the integral to avoid the recursive stack overflow. I tested it on absurdly high coverage (100,000) and reproduced the error with the old code. Whichever one of you gets to this first should review. While this isn't the most beautiful thing in the world, it will work reasonably while new integration code is pending.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3335:448,integrat,integration,448,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3335,1,['integrat'],['integration']
Deployability,"dules, and still being able to publish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and remove if required, without any major version bump.; * `testing`: this will contain the testing framework. It is related with #1481 and #3567. ; * `documentation`: this might be useful for code dependent on `com.sun.javadoc` to do not interact with other classes if code for documenting a downstream project is not necessary.; * Other modules might be useful for concrete components: e.g, ., the gCNV python computati",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3900:1462,pipeline,pipeline,1462,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900,1,['pipeline'],['pipeline']
Deployability,"duo/Łuksza_2022_Nature -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; 13:36:33.528 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:36:33.547 WARN NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (No such file or directory); 13:36:33.550 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:36:33.551 WARN NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (No such file or directory); 13:36:33.669 INFO BaseRecalibrator - ------------------------------------------------------------; 13:36:33.670 INFO BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.2.6.1; 13:36:33.670 INFO BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:36:33.670 INFO BaseRecalibrator - Executing as xieduo@pbs-master on Linux v3.10.0-1160.41.1.el7.x86_64 amd64; 13:36:33.670 INFO BaseRecalibrator - Java runtime: Java HotSpot(TM) 64-Bit Server VM v18+36-2087; 13:36:33.671 INFO BaseRecalibrator - Start Date/Time: September 22, 2022 at 1:36:33 PM CST; 13:36:33.671 INFO BaseRecalibrator - ------------------------------------------------------------; 13:36:33.671 INFO BaseRecalibrator - -------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:6904,pipeline,pipeline,6904,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,"duplicate key error. Ted Brookings identified how to solve this issue:; -The exact problem is in AlleleFrequencyUtils.java, line 30.; -The solution is to skip collecting as a map, have getMaxMinorAlleleFreq take a stream and return an optional float, then return false if the float is missing, otherwise value <= maxMaf. Don't ever call allFrequenciesFiltered. This request was created from a contribution made by Azza Ahmed on October 14, 2021 10:53 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4408348163227-FilterFuncotations-Duplicate-key-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/4408348163227-FilterFuncotations-Duplicate-key-error). \--. Hello,. I'm using the `FilterFuncotations` to process the output from the `Functotator` as per this WARP \[pipeline\]( [warp/AnnotationFiltration.wdl at cec97750e3819fd88ba382534aaede8e05ec52df · broadinstitute/warp (github.com)](https://github.com/broadinstitute/warp/blob/cec97750e3819fd88ba382534aaede8e05ec52df/pipelines/broad/annotation_filtration/AnnotationFiltration.wdl)). . ; ; ; ; /home/azzaea/software/gatk/gatk-4.2.2.0/gatk --java-options ""-Xmx3072m"" \ ; FilterFuncotations \ ; --variant /scratch/FPTVM/src/warp/pipelines/broad/annotation\_filtration/cromwell-executions/AnnotationFiltration/4e3bd06b-3018-4c94-ac98-feb78b924d1f/call-FilterFuncotations/shard-0/inputs/1333115969/104566-001-001.filtered.vcf.funcotated.vcf.gz \ ; --output 104566-001-001.filtered.vcf.filtered.vcf.gz \ ; --ref-version hg38 \ ; --allele-frequency-data-source gnomad --lenient true; ; ; ; ; . However, the command fails with the error message below:. ; ; ; ; [October 14, 2021 at 12:20:24 PM CEST] org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations done. Elapsed time: 16.57 minutes. ; Runtime.totalMemory()=1134559232 ; java.lang.IllegalStateException: Duplicate key Gencode\_34\_annotationTranscript (attempted merging values ENST00000450305.2 and ENST00000456328.2) ; at java.base/java.util.stream.Co",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:1147,pipeline,pipelines,1147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['pipeline'],['pipelines']
Deployability,"e > Gradle test > org.broadinstitute.hellbender.BwaMemIntegrationTest > testChimericUnpairedMapping SKIPPED; Running Test: Test method testPerfectUnpairedMapping(org.broadinstitute.hellbender.BwaMemIntegrationTest). Gradle suite > Gradle test > org.broadinstitute.hellbender.BwaMemIntegrationTest > testPerfectUnpairedMapping SKIPPED; ```. This test fails because some JAR wasn't built:; ```; Running Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest); Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: No local jar was found, please build one by running. Gradle suite > Gradle test > org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest > testPipeForPicardTools STANDARD_ERROR; No local jar was found, please build one by running; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err:. Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: /disk-samsung/ports/biology/gatk/work/gatk-4.6.0.0/gradlew localJar. /disk-samsung/ports/biology/gatk/work/gatk-4.6.0.0/gradlew localJar; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: or. or; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: export GATK_LOCAL_JAR=<path_to_local_jar>. export GATK_LOCAL_JAR=<path_to_local_jar>; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: No local jar was found, please build one by running. No local jar was found, please build one by running; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.Pipeli",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8940:3820,Pipeline,PipelineSupportIntegrationTest,3820,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8940,1,['Pipeline'],['PipelineSupportIntegrationTest']
Deployability,"e AVX instruction set is not available, even when it is. It falls back to slower LOGLESS_CACHING PairHMM. The fault is missing libgomp1, which is a required dependency of gcc. Since this documentation request is related to a ""bug"" that comes about from not installing necessary libraries, I'll include the bug report format below, in case someone else searches for solutions to this problem, as suggested by @lbergelson. ### Affected tool(s) or class(es); _HaplotypeCaller_, or any other tool that uses _PairHMM_. ### Affected version(s); -I think all as of _2019-06-20_. I tested on release version _4.1.2.0_. #### Steps to reproduce; Run HaplotypeCaller from a released jar on an Ubuntu VM that supports the AVX instruction set. Critically, do *NOT* install gcc on the VM. Installing gcc fixes this problem. #### Expected behavior; If you install gcc, that results in the installation of libgomp1, which allows the Intel library to load and use AVX acceleration. You could probably install libgomp1 on its own, but I did not test that.; > 14:51:01.013 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/ubuntu/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; > 14:51:01.015 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/ubuntu/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; > 14:51:01.053 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; > 14:51:01.053 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; > 14:51:01.054 INFO IntelPairHmm - Available threads: 16; > 14:51:01.054 INFO IntelPairHmm - Requested threads: 8; > 14:51:01.054 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation. #### Actual behavior; Without libgomp1, AVX acceleration doesn't work:; > 19:43:36.387 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/ubuntu/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6012:1180,install,install,1180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6012,1,['install'],['install']
Deployability,"e GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be passed to the CLP on construction (in `Main`) and defaults to whatever base class is chosen. This will allow custom toolkits to override in their `Main` the formatter and thus make consistent the output of every tool. Another option is to use directly something like the Spring framework, but I think that it is quite complicated for API users without knowledge of Spring (like me).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:2071,configurat,configuration,2071,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646,1,['configurat'],['configuration']
Deployability,"e Germline Contig Ploidy step, I stumble upon this error. Please guide me to solve this problem. ### Affected tool(s) or class(es); ```; gatk DetermineGermlineContigPloidy \; -L /home/nguyen/RB1/RB1.cohort.gc.filtered.interval_list \; --interval-merging-rule OVERLAPPING_ONLY \; -I ... (63 tsv files output from CollectReadCounts); ```. ### Affected version(s); - GATK 4.1.6.1; ### Description ; Full error log:; ```; Traceback (most recent call last):; File ""/tmp/cohort_determine_ploidy_and_depth.380621677219090732.py"", line 119, in <module>; ploidy_task.engage(); File ""/home/nguyen/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/tasks/inference_task_base.py"", line 339, in engage; converged_continuous = self._update_continuous_posteriors(); File ""/home/nguyen/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/tasks/inference_task_base.py"", line 395, in _update_continuous_posteriors; assert not np.isnan(loss), ""The optimization step for ELBO update returned a NaN""; AssertionError: The optimization step for ELBO update returned a NaN; 11:09:59.446 DEBUG ScriptExecutor - Result: 1; 11:09:59.447 INFO DetermineGermlineContigPloidy - Shutting down engine; [April 28, 2020 11:09:59 AM ICT] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 0.17 minutes.; Runtime.totalMemory()=623902720; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python /tmp/cohort_determine_ploidy_and_depth.380621677219090732.py --sample_coverage_metadata=/tmp/samples-by-coverage-per-contig8606344533091962323.tsv --output_calls_path=/home/nguyen/Exec/gatk-4.1.6.0/ploidy-calls --mapping_error_rate=1.000000e-02 --psi_s_scale=1.000000e-04 --mean_bias_sd=1.000000e-02 --psi_j_scale=1.000000e-03 --learning_rate=5.000000e-02 --adamax_beta1=9.000000e-01 --adamax_beta2=9.990000e-01 --log_emission_samples_per_round=2000 --log_emission_sampling_rounds=100 --log_emission_sampling_median_rel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6573:1145,update,update,1145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6573,2,['update'],['update']
Deployability,"e VM ubuntu. ; I downloaded gatk-4.4.0.0. Step by step, I tried to build GATK4. (https://github.com/broadinstitute/gatk/blob/master/README.md#building). I made a gitclone using ; wget https://github.com/broadinstitute/gatk. and entered gatk folder. ; there was a gradlew.; and I entered ; ./gradlew bundle ; or; ./gradlew. but it failed to build GATK4 with following errors. . ====================================; OpenJDK 64-Bit Server VM warning: Insufficient space for shared memory file:; 30934; Try using the -Djava.io.tmpdir= option to select an alternate temp location. FAILURE: Build failed with an exception. * What went wrong:; Gradle could not start your build.; > Cannot create service of type DependencyLockingHandler using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyLockingHandler() as there is a problem with parameter #2 of type ConfigurationContainerInternal.; > Cannot create service of type ConfigurationContainerInternal using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createConfigurationContainer() as there is a problem with parameter #13 of type DefaultConfigurationFactory.; > Cannot create service of type DefaultConfigurationFactory using DefaultConfigurationFactory constructor as there is a problem with parameter #2 of type ConfigurationResolver.; > Cannot create service of type ConfigurationResolver using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyResolver() as there is a problem with parameter #1 of type ArtifactDependencyResolver.; > Cannot create service of type ArtifactDependencyResolver using method DependencyManagementBuildScopeServices.createArtifactDependencyResolver() as there is a problem with parameter #4 of type List<ResolverProviderFactory>.; > Could not create service of type VersionControlRepositoryConnectionFactory using VersionControlBuildSessionServices.createVersionControlSystemFactory().; > Failed to cre",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8346:1066,Configurat,ConfigurationContainerInternal,1066,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8346,1,['Configurat'],['ConfigurationContainerInternal']
Deployability,"e a bad idea to have these incomplete jars floating out in the wild.; 3. Everyone develops on separate branches, and merges to master only when everything in a branch is ""release-ready"". In this scenario master itself is always (theoretically, at least) ready for release. This solves the original problem of release of some tools being blocked by others, but creates some other problems: last-minute merge conflicts across dev teams, large amounts of code being held back for months while it undergoes testing, harder to share code across groups, more complex git workflows for everyone.; 4. Everyone is free to merge development versions of tools to master (as is currently the case), and most of the time we try to release everything in the GATK together. On rare occasions when, eg., CNV needs a release now and HC is not ready, we create a branch off of the last tagged release, cherry-pick the CNV tools (or whatever) into it, and release that. Then when the HC stabilizes and master is once again releasable, we do the next release from master. I've renamed this issue to make the problem we're trying to solve clearer. @akiezun @lbergelson @LeeTL1220 @vdauwera would you vote for any of the above options? Do you have alternate proposals that solve the same problem and you think are better? Should we seek professional (release engineering) help?. ---. @akiezun commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215761749). only 4 seems remotely sane to me. ---. @vdauwera commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215779225). 3 and 4 both produce an acceptable result for me but I could see 3 being too hard on the dev team. So I'll go with 4. I think the inconvenience of cutting a special cherry picked release is enough to dissuade casual/unnecessary releases, but low enough to not be a blocker if we really do need to release a hot fix. ---. @LeeTL1220 commented on [Fri",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:4605,release,release,4605,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,1,['release'],['release']
Deployability,"e adopt a new default branch name and retire the use of 'master'.*. The use of 'master' as the default branch is quickly tipping into the realm of being archaic, and present the image of being increasingly tone deaf. 'main' is the commonly accepted replacement on GitHub, but I'm stopping short of suggesting the replacement name, just asking ""please retire master"". . ### 'master has a specific technical meaning' . It does. And is also an example of structural racism, which; > refers to the complex interactions of large scale societal systems, practices, ideologies, and programs that produce and and perpetuate inequities for racial minorities. The key aspect of structural or systematic racism is that these macro-level mechanisms operate independent of the intentions and actions of individuals, so that even if individual racism is not present, the adverse conditions and inequalities for racial minorities will continue to exist - [Gee & Ford, 2011](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4306458/). _And if you just felt as if you were accused of being a racist, please re-read the above definition again_ I'm addressing the bureaucracy ( which I can not realistically effect much change with, but some of you can).; ; Ultimately, a fair number of people are to varying degrees uncomfortable or threatened by this trope. And on these merits alone are a good reason to ditch master. [The process is straight forward and documentation abounds](https://www.git-tower.com/learn/git/faq/git-rename-master-to-main), [there are even tools to help automate the conversion](https://github.com/dsyer/main-branch-switch). But it will take time, and is not the most exciting work in the world. . Perhaps it's a sticky change as part of all major releases, or otherwise planned for? So, that's my vote, if I were to be asked to vote that is. And, if there are detailed plans in place to make this change, horray! Link them here, and now you have a(nother?) nice honeypot for this topic. John Major",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7621:2323,release,releases,2323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7621,1,['release'],['releases']
Deployability,e blows up:. ```; ./bin/gatk/gatk-launch PrintReadsSpark -I hdfs:///user/akiezun/data/CEUTrio.HiSeq.WEx.b37.NA12892.small.bam -O hdfs:///user/akiezun/data/CEUTrio.HiSeq.WEx.b37.NA12892.small.out.bam \; -- \; --sparkRunner SPARK --sparkMaster yarn-client \; --num-executors 5 --executor-cores 2 --executor-memory 4g \; --conf spark.yarn.executor.memoryOverhead=600; ```. blows up with . ```; java.lang.ClassCastException: org.apache.hadoop.fs.RawLocalFileSystem cannot be cast to org.apache.hadoop.fs.LocalFileSystem; at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:350); at org.apache.spark.deploy.yarn.Client$.org$apache$spark$deploy$yarn$Client$$getQualifiedLocalPath(Client.scala:1373); at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:329); at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:422); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:635); at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:124); at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:56); at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144); at org.apache.spark.SparkContext.<init>(SparkContext.scala:523); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1389:1080,deploy,deploy,1080,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1389,1,['deploy'],['deploy']
Deployability,"e from master. I've renamed this issue to make the problem we're trying to solve clearer. @akiezun @lbergelson @LeeTL1220 @vdauwera would you vote for any of the above options? Do you have alternate proposals that solve the same problem and you think are better? Should we seek professional (release engineering) help?. ---. @akiezun commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215761749). only 4 seems remotely sane to me. ---. @vdauwera commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215779225). 3 and 4 both produce an acceptable result for me but I could see 3 being too hard on the dev team. So I'll go with 4. I think the inconvenience of cutting a special cherry picked release is enough to dissuade casual/unnecessary releases, but low enough to not be a blocker if we really do need to release a hot fix. ---. @LeeTL1220 commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215793338). Cherry-picking sounds awful to me, but not as awful as the others... I could do number three. ---. @akiezun commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215801993). To clarify my position though - I think we should just never need it and simply coordinate between the various tool teams on a common release schedule. The toolkit would then be released because all tool are ready. ---. @droazen commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215816252). @akiezun We should strive for this, but in practice there will be times when Lee needs a release and we're not ready for one, and we need to have a plan in place to deal with that scenario. Since options 3 and 4 seem to be the only options with votes, let's sit down next week and discuss in detail the pain points of these two options, and make a choice between them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:6032,release,release,6032,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,3,['release'],"['release', 'released']"
Deployability,"e mapping quality also considers how well the read aligns; to its best mapping. In places where a sample has a lot of nearby SNPs; compared to the reference the mapping qualities of the reads are low; compared to reads that contain fewer SNPs. I've been mulling over the; conflation of these two aspects of mapping quality for a while because it; biases our VQSR results, but maybe the new filtering models will be able to; figure it out. The b37 reference with decoy contigs is here:; /humgen/1kg/reference/human_g1k_v37_decoy.fasta.I believe that the; reference issue that required the decoy in the b37 1000G work was resolved; in the hg38 reference. This is an excellent topic to discuss with Heng; during his office hours when he gets back from China in a few weeks, but I; expect the SV team will also be helpful in the meantime. On Sun, Apr 23, 2017 at 11:14 PM, David Benjamin <notifications@github.com>; wrote:. > So. . . given that our pipeline aligns with BWA, it might seem like this; > is just a redundant and laborious rehashing of the mapping quality score.; >; > *However*, the mapping quality only considers multi-mapping within the; > reference, and therefore doesn't account for mapping errors due to; > incompleteness of the reference. That is, reads from genomic regions that; > are not part of the reference (because they're hard to assemble, like; > centromeres etc) might map well to a unique regions within the reference,; > and therefore will have fine mapping quality even though they are artifacts.; >; > There are published ""decoy genomes"" -- essentially pseudo-contigs of; > regions missing from the reference, and mapping with BWA in memory to; > *those* might be very helpful.; >; > So, we need to: 1) get our hands on a decoy genome that will play nicely; > with BWA, and 2) talk to the SV team.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk-p",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2930:3264,pipeline,pipeline,3264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2930,1,['pipeline'],['pipeline']
Deployability,"e node, 32 cores/node, 1002GB node memory) NOTE that I am able to successfully run JointGenotyping on a set of 80 gvcfs, also produced by ExomeGermlineSingleSample, in this HPC/Singularity environment with 248GB memory, 24 cores/node - this doesn't seem to be a resource issue. The only difference appears to be the number of input gvcfs, which is still quite small (345 vs 80).  The number of reader threads for GenomicsDBImport has been hard-coded to 1 because these are exome sequences; scatter count = 10, batch size = 50, gather\_vcfs = false. GenomicsDBImport appears to succeed on all 10 shards but workflow execution fails with exactly the same c++ error, see below. REQUIRED for all errors and issues: ; ; a) GATK version used: v4.2.6.1. b) Exact command used:. java -Dconfig.file=/scratch.global/lee04110/config/sing-cache.conf -jar /home/pankrat2/public/bin/gatk4/cromwell-81.jar run -i /scratch.global/lee04110/config/jg.ca\_defects.json /home/pankrat2/public/bin/gatk4/warp/pipelines/broad/dna\_seq/germline/joint\_genotyping/JointGenotyping.wdl -o  <(echo '{""final\_workflow\_outputs\_dir"" : ""/scratch.global/lee04110/tmp\_jg"", ""use\_relative\_output\_paths"" : true, ""workflow-log-temporary"" : true}'). c) Entire program log: (too big to include the whole thing). (From main process stderr, picking from SplitInterval setting status to Done). \[2022-10-18 15:38:20,88\] \[info\] BackgroundConfigAsyncJobExecutionActor \[9743b28aJointGenotyping.SplitIntervalList:NA:1\]: Status change from WaitingForReturnCode to Done. \[2022-10-18 15:38:25,47\] \[info\] WorkflowExecutionActor-9743b28a-3819-49a7-8598-b0c5267647ee \[9743b28a\]: Starting JointGenotyping.ImportGVCFs (10 shards). \[2022-10-18 15:38:33,03\] \[info\] Assigned new job execution tokens to the following groups: 9743b28a: 10. \[2022-10-18 15:38:33,14\] \[warn\] BackgroundConfigAsyncJobExecutionActor \[9743b28aJointGenotyping.ImportGVCFs:3:1\]: Unrecognized runtime attribute keys: preemptible, bootDiskSizeGb, disks, cpu, ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076:1722,pipeline,pipelines,1722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076,1,['pipeline'],['pipelines']
Deployability,"e two chains in order to dampen oscillations and improve convergence properties. Once internal convergence is achieved, the converged posteriors must be saved to a workspace in order to be consumed by the continuous sub-model. The new internally converged posteriors will be admixed with the old internally converged posteriors from the previous epoch with the _external_ admixing rate. - Introduced two-stage inference for cohort denoising and calling. In the first (""warm-up"") stage, discrete variables are marginalized out, yielding an effective continuous-only model. The warm-up stage calculates continuous posteriors based on the marginalized model. Once convergence is achieved, continuous and discrete variables are decoupled for the second (""main"") stage. The second stage starts with a discrete calling step (crucial), using continuous posteriors from the warm-up stage as the starting point. The motivation behind the two-stage inference strategy is to avoid getting trapped in spurious local minima that are potentially introduced by mean-field decoupling of discrete and continuous RVs. Note that mean-field decoupling has a tendency to stabilize local minima, most of which will disappear or turn into saddle points once correlations are taken into account. While the marginalized model is free of such spurious local minima, it does not yield discrete posteriors in a tractable way; hence, the necessity of ultimately decoupling in the ""main"" stage. - Capped phred-scaled qualities to maximum values permitted by machine precision in order to avoid NaNs and overflows. - Took a first step toward tracking and logging parameters during inference, starting with the ELBO history. In the future, it may be desirable to allow tracking of arbitrary RVs and deterministics via command line args (for debugging and exploratory work). Notes:. - We still need to decide about `GermlineCNVCaller` default arguments. See issue #4719.; - The case denoising and calling is unlikely to benefit from t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4720:1810,continuous,continuous,1810,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4720,1,['continuous'],['continuous']
Deployability,e Δ | Complexity Δ | |; |---|---|---|---|; | [...e/hellbender/utils/variant/GATKVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/5792/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `94.944% <100%> (ø)` | `11 <0> (ø)` | :arrow_down: |; | [...ils/nio/NioFileCopierWithProgressMeterResults.java](https://codecov.io/gh/broadinstitute/gatk/pull/5792/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyUmVzdWx0cy5qYXZh) | `0% <0%> (-94.737%)` | `0% <0%> (-9%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5792/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5792/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...ols/funcotator/FuncotatorDataSourceDownloader.java](https://codecov.io/gh/broadinstitute/gatk/pull/5792/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JEYXRhU291cmNlRG93bmxvYWRlci5qYXZh) | `0% <0%> (-66.197%)` | `0% <0%> (-14%)` | |; | [...nder/utils/nio/NioFileCopierWithProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5792/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyLmphdmE=) | `17% <0%> (-52.5%)` | `9% <0%> (-30%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5792/d,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5792#issuecomment-472254584:1873,pipeline,pipelines,1873,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5792#issuecomment-472254584,1,['pipeline'],['pipelines']
Deployability,"e(GATKSparkTool.java:348); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.main(Main.java:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.NotSerializableException: java.nio.HeapByteBuffer; Serialization stack:; **\- object not serializable (class: java.nio.HeapByteBuffer, value: java.nio.HeapByteBuffer[pos=0 lim=775456500 cap=775456500])**; - field (class: org.bdgenomics.adam.util.TwoBitFile, name: bytes, type: class java.nio.ByteBuffer); - object (class org.bdgenomics.adam.util.TwoBitFile, org.bdgenomics.adam.util.TwoBitFile@863c31e); - field (class: org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource, name: twoBitFile, type: class org.bdgenomics.adam.util.TwoBitFile); - object (class org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource, org.broadinstitute.hellbender.engine.spark.datasources.ReferenceT",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2216:2683,deploy,deploy,2683,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2216,1,['deploy'],['deploy']
Deployability,"e-map-file instead of sample-map-table (#6872); - Moving extract wdls from variantstore repo (#6902); - update for genomes (#6918); - update paths; - update field name; - consolidate exome and genome code; - missing comma; - allow null for drop state. add to wdl; - fix when NON-REF has value (drop it anyway). add memory to wdl; - fix order of columns in vet; - Making ingest work on gvcfs without allele specific annotations (#6934); - fix partitioning (#6939); - more fixes for non-allele-specific gvcfs (#6945); - fix GT for ./.; - add in feature extract code. resulting vcf still has bugs (#6947); - Rudimentary support for other output types, support for scattering extract cohort (#6949); - added batch/interactive flag, removed samples (#6953); - WIP for Feature Extract code (#6958); - move wdl and cromwell_tests dirs under variantstore (#6961); - WDL to run feature extract, VQSR, and upload (#6966); - support for multiple PET/VETs (#6969); - Add filtering to ExtractCohort (#6971); - support for non-AS called data (#6975); - fixing bug in filtering (#6976); - Updating extract wdls to apply filtering (#6977); - moving from specops repo (#6983); - optimized TSV experiment, and range GQ dropping (#6987); - back to 30x defaults; - allow no filtering to be applied (#7004); - Separate bigquery table creation and data loading in LoadData (#7056); - WIP; - tieout scripts; - notes files; - updated diff scripts; - fixed bug...; - add wdl and inputs file for warp pipeline; - reverting logging; - included top level WDL; - use gnarly with BQ extract cohort; - remove unused file; - cleaning up; - tidy; - tidy up before PR; - tidy up before PR; - PR comments; - merge conflict misfires; - added example SQL to create alt allele table from VET; - option to remove PLs; - fixed and enhanced unit test; - removing unused config, causing travis to fail; - add CreateVariantIngestFiles integration test (#7071); - add sampleName (instead of NULL) to error message (#7074); - Update To handle if",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:4710,update,updated,4710,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,['update'],['updated']
Deployability,"e.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx3000m -jar /root/gatk.jar Mutect2 -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://cclebams/hg38_wes/CDS-ce3y1s.hg38.bam -tumor HAP1_1 --germline-resource gs://gatk-best-practices/somatic-hg38/af-only-gnomad.hg38.vcf.gz -pon gs://gatk-best-practices/somatic-hg38/1000g_pon.hg38.vcf.gz -L gs://fc-secure-76d1542e-1c49-4411-8268-e41e92f9f311/729d209c-0ef4-409f-b3af-2e84ff45ee36/omics_mutect2/16911ef5-efb2-4e12-86f2-f3d5a54b28c0/call-mutect2/Mutect2/4e4a27e2-6c57-40e9-8ddc-1024bdcc50c1/call-SplitIntervals/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list -O output.vcf.gz --f1r2-tar-gz f1r2.tar.gz --genotype-germline-sites true --genotype-pon-sites true --emit-ref-confidence GVCF --gcs-project-for-requester-pays broad-firecloud-ccle; ```. #### Steps to reproduce. running the same pipeline as described in previous issues: #7492. But I have added ""--genotype-germline-sites true --genotype-pon-sites true --emit-ref-confidence GVCF"" as additional args. the rest of the arguments are defaults/basic from the mutect2.wdl pipeline.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7849:8220,pipeline,pipeline,8220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7849,2,['pipeline'],['pipeline']
Deployability,"e.com/apt cloud-sdk-bionic InRelease [6786 B] ; Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1426 kB] ; Err:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease ; The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; Get:7 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2295 kB] ; Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] ; Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] ; Get:10 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] ; Get:11 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]; Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] ; Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB] ; Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2200 kB]; Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.4 kB]; Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [575 kB]; Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2731 kB]; Get:18 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [11.4 kB]; Get:19 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [11.3 kB]; Reading package lists... Done ; W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; E: The repository 'http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease' is not signed.; N: Updating from such a repository can't be done securely, and is therefore disabled by default.; N: See apt-secure(8) manpage for repository creation and user configuration details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7447:2150,update,updates,2150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7447,4,"['configurat', 'update']","['configuration', 'updates']"
Deployability,e.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://st,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084:1333,integrat,integration,1333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084,1,['integrat'],['integration']
Deployability,"e.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-45f7a9f3-b94f-4040-bf32-0dbfe44f8f68; 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-70db8953-5dec-4eb8-910d-f0abd7e1c42b. real 41m12.118s; user 83m41.069s; sys 10m15.403s. #### Steps to reproduce; atk --java-options ""-Djava.io.tmpdir=tmp"" StructuralVariationDiscoveryPipelineSpark \; -R $REF \; --aligner-index-image GRCh38_full_analysis_set_plus_decoy_hla.fa.img \; --kmers-to-ignore GRCh38_ignored_kmers.txt \; --contig-sam-file hdfs:///project/casa/gcad/$CENTER/sv/$SAMPLE.contig-sam-file.sam\; -I $CRAM_DIR/$SAMPLE.cram \; -O hdfs:///project/casa/gcad/$CENTER/sv/$SAMPLE.sv.vcf.gz \; -- \; --spark-runner SPARK --spark-master yarn --deploy-mode client \; --executor-memory 85G\;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942:4828,deploy,deploy,4828,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942,1,['deploy'],['deploy']
Deployability,e.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Stream closed; at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:829); at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:889); at java.io.DataInputStream.read(DataInputStream.java:149); at org.disq_bio.disq.impl.file.HadoopFileSystemWrapper$SeekableHadoopStream.read(HadoopFileSystemWrapper.java:232); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(BufferedInputStream.java:345); at htsjdk.samtools.seekablestream.SeekableBufferedStream.read(SeekableBufferedStream.java:133); at htsjdk.samtools.IndexStreamBuffer.readFully(IndexStreamBuffer.java:21); ... 31 more; 2019-06-03 22:34:49 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-06-03 22:34:49 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spar,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:4707,deploy,deploy,4707,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,2,['deploy'],['deploy']
Deployability,e.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: provided start is negative: -1; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:53867,deploy,deploy,53867,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['deploy'],['deploy']
Deployability,"e.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:41677,deploy,deploy,41677,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,['deploy'],['deploy']
Deployability,"e.hellbender.engine.FeatureManager.<init>(FeatureManager.java:155) ; ;     at org.broadinstitute.hellbender.engine.ReadWalker.initializeFeatures(ReadWalker.java:72) ; ;     at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:726) ; ;     at org.broadinstitute.hellbender.engine.ReadWalker.onStartup(ReadWalker.java:51) ; ;     at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138) ; ;     at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; ;     at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211) ; ;     at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160) ; ;     at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203) ; ;     at org.broadinstitute.hellbender.Main.main(Main.java:289). And I will get the same error when I assign the temp directory in another way:. /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx30G"" BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz  -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.table --tmp-dir /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam ; ; Using GATK jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar ; ; Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx30G -jar /data/xieduo/WES\_pipe/pipeline/bin/gatk",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:7424,pipeline,pipeline,7424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability,e.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: provided start is negative: -1; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:53542,deploy,deploy,53542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['deploy'],['deploy']
Deployability,"e.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:41352,deploy,deploy,41352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,['deploy'],['deploy']
Deployability,"e.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-45f7a9f3-b94f-4040-bf32-0dbfe44f8f68; 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-70db8953-5dec-4eb8-910d-f0abd7e1c42b. real 41m12.118s; user 83m41.069s; sys 10m15.403s. #### Steps to reproduce; atk --java-options ""-Djava.io.tmpdir=tmp"" StructuralVariationDiscoveryPipelineSpark \; -R $REF \; --aligner-index-image GRCh38_full_analysis_set_plus_decoy_hla.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942:4503,deploy,deploy,4503,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942,1,['deploy'],['deploy']
Deployability,e.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Stream closed; at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:829); at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:889); at java.io.DataInputStream.read(DataInputStream.java:149); at org.disq_bio.disq.impl.file.HadoopFileSystemWrapper$SeekableHadoopStream.read(HadoopFileSystemWrapper.java:232); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(BufferedInputStream.java:345); at htsjdk.samtools.seekablestream.SeekableBufferedStrea,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:4382,deploy,deploy,4382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,2,['deploy'],['deploy']
Deployability,e.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:153); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:247); at org.broadinstitute.hellbender.tools.spark.ApplyBQSRSpark.runTool(ApplyBQSRSpark.java:49); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:348); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.main(Main.java:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/11/29 23:44:27 INFO akka.remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.; 16/11/29 23:44:27 INFO akka.remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [155c3731-4071-4aa9-bed8-f0eb3426b805] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287:2199,deploy,deploy,2199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287,6,['deploy'],['deploy']
Deployability,e.spark.deploy.yarn.Client.copyFileToRemote(Client.scala:317); at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:407); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:471); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:470); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:470); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:468); at scala.collection.immutable.List.foreach(List.scala:318); at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:468); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:727); at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:142); at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:57); at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144); at org.apache.spark.SparkContext.<init>(SparkContext.scala:530); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProg,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:1926,deploy,deploy,1926,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,2,['deploy'],['deploy']
Deployability,"e0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); 	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826); 	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000); 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); 	... 20 more; 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGSchedule",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:8052,pipeline,pipelines,8052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['pipeline'],['pipelines']
Deployability,e3860943bcccd44fea40ce3?src=pr&el=desc) will **decrease** coverage by `0.266%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4590 +/- ##; ==============================================; - Coverage 79.84% 79.574% -0.266% ; + Complexity 16958 16911 -47 ; ==============================================; Files 1062 1062 ; Lines 61677 61677 ; Branches 9983 9983 ; ==============================================; - Hits 49243 49079 -164 ; - Misses 8539 8708 +169 ; + Partials 3895 3890 -5; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4590?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4590/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4590/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4590/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4590/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4590/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcm,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4590#issuecomment-376423720:1246,pipeline,pipelines,1246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4590#issuecomment-376423720,1,['pipeline'],['pipelines']
Deployability,eArgs(CommandLineProgram.java:182); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:201); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.seek(BlockCompressedInputStream.java:380); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:977); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at hts,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:19674,deploy,deploy,19674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['deploy'],['deploy']
Deployability,"eArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.FileSystemNotFoundException: Provider ""gs"" not installed; 	at java.nio.file.Paths.get(Paths.java:147); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferencePath(ReferenceFileSparkSource.java:53); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferenceBases(ReferenceFileSparkSource.java:60); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceMultiSparkSource.getReferenceBases(ReferenceMultiSparkSource.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.getRefBaseString(BreakEndVariantType.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.access$200(BreakEndVariantType.java:20); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType$InterChromosomeBreakend.<",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:7884,deploy,deploy,7884,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['deploy'],['deploy']
Deployability,eCNVCaller - HTSJDK Defaults.CREATE_MD5 : false; 21:05:38.391 INFO GermlineCNVCaller - HTSJDK Defaults.CUSTOM_READER_FACTORY :; 21:05:38.391 INFO GermlineCNVCaller - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 21:05:38.391 INFO GermlineCNVCaller - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 21:05:38.391 INFO GermlineCNVCaller - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 21:05:38.391 INFO GermlineCNVCaller - HTSJDK Defaults.REFERENCE_FASTA : null; 21:05:38.391 INFO GermlineCNVCaller - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 21:05:38.391 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 21:05:38.391 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 21:05:38.391 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 21:05:38.391 INFO GermlineCNVCaller - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 21:05:38.392 DEBUG ConfigFactory - Configuration file values:; 21:05:38.395 DEBUG ConfigFactory - gcsMaxRetries = 20; 21:05:38.395 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 21:05:38.395 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 21:05:38.395 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 21:05:38.395 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 21:05:38.395 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 21:05:38.395 DEBUG ConfigFactory - samjdk.compression_level = 2; 21:05:38.395 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 21:05:38.395 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 21:05:38.395 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 21:05:38.395 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 21:05:38.395 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 21:05:38.395 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 21:05:38.395 DEBUG ConfigFactory - spark.executor.extra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8952:3213,Configurat,Configuration,3213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8952,1,['Configurat'],['Configuration']
Deployability,"eHadoopBamSplittingIndex - ------------------------------------------------------------; 11:47:53.456 INFO CreateHadoopBamSplittingIndex - ------------------------------------------------------------; 11:47:53.457 INFO CreateHadoopBamSplittingIndex - HTSJDK Version: 2.14.1; 11:47:53.457 INFO CreateHadoopBamSplittingIndex - Picard Version: 2.17.2; 11:47:53.457 INFO CreateHadoopBamSplittingIndex - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 11:47:53.457 INFO CreateHadoopBamSplittingIndex - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:47:53.457 INFO CreateHadoopBamSplittingIndex - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 11:47:53.457 INFO CreateHadoopBamSplittingIndex - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:47:53.457 INFO CreateHadoopBamSplittingIndex - Deflater: IntelDeflater; 11:47:53.457 INFO CreateHadoopBamSplittingIndex - Inflater: IntelInflater; 11:47:53.457 INFO CreateHadoopBamSplittingIndex - GCS max retries/reopens: 20; 11:47:53.457 INFO CreateHadoopBamSplittingIndex - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 11:47:53.457 INFO CreateHadoopBamSplittingIndex - Initializing engine; 11:47:53.458 INFO CreateHadoopBamSplittingIndex - Done initializing engine; 11:47:53.463 INFO CreateHadoopBamSplittingIndex - Shutting down engine; [March 7, 2018 11:47:53 AM EST] org.broadinstitute.hellbender.tools.spark.CreateHadoopBamSplittingIndex done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=1115160576; ***********************************************************************. A USER ERROR has occurred: Bad input: A splitting index is only relevant for a bam file, but a file with extension cram was specified. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506:2726,patch,patch,2726,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506,1,['patch'],['patch']
Deployability,"eMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-45f7a9f3-b94f-4040-bf32-0dbfe44f8f68; 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-70db8953-5dec-4eb8-910d-f0abd7e1c42b. real 41m12.118s; user 83m41.069s; sys 10m15.403s. #### Steps to reproduce; atk --java-options ""-Djava.io.tmpdir=tmp"" StructuralVariationDiscoveryPipelineSpark \; -R $REF \; --aligner-index-image GRCh38_full_analysis_set_plus_decoy_hla.fa.img \; --kmers-to-ignore GRCh38_ignored_kmers.txt \; --contig-sam-file hdfs:///project/casa/gcad/$CENTER/sv/$SAMPLE.contig-sam-file.sam\; -I $CRAM_DIR/$SAMPLE.cram \; -O hdfs:///project/casa/gcad/$CENTER/sv/$SAMPLE.sv.vcf.gz \; -- \; --spark-runner SPAR",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942:4759,deploy,deploy,4759,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942,1,['deploy'],['deploy']
Deployability,eMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Stream closed; at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:829); at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:889); at java.io.DataInputStream.read(DataInputStream.java:149); at org.disq_bio.disq.impl.file.HadoopFileSystemWrapper$SeekableHadoopStream.read(HadoopFileSystemWrapper.java:232); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(BufferedInputStream.java:345); at htsjdk.samtools.seekablestream.SeekableBufferedStream.read(SeekableBufferedStream.java:133); at htsjdk.samtools.IndexStreamBuffer.readFully(IndexStreamBuffer.java:21); ... 31 more; 2019-06-03 22:34:49 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-06-03 22:34:49 INFO ShutdownHookManager:54 - Delet,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:4638,deploy,deploy,4638,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,2,['deploy'],['deploy']
Deployability,eMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: provided start is negative: -1; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:53798,deploy,deploy,53798,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['deploy'],['deploy']
Deployability,"eMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:41608,deploy,deploy,41608,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,['deploy'],['deploy']
Deployability,"ePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred deletion calls, which currently output as `DEL` with `INSSEQ` annotation, to one of these; - [x] `INS`/`DEL`, when deleted/inserted bases are < 50 bp and annotate accordingly; when type is determined as`INS`, the `POS` will be 1 base before the micro-deleted range and `END` will be end of the micro-deleted range, where the `REF` allele will be the corresponding reference bases.; - [x] two records `INS` and `DEL` when both are >= 50, share the same `POS`, and link by `EVENT`; - [ ] we are making a choice that treats duplication expansion as insertion. If decide to treat `DUP` as a separate 1st class type, we need to ; - [ ] shift the left breakpoint to the ri",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:2183,integrat,integration,2183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021,2,['integrat'],['integration']
Deployability,eProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/04/27 18:49:12 ERROR org.apache.spark.util.Utils: Uncaught exception in thread main; java.lang.NullPointerException; at org.apache.spark.network.shuffle.ExternalShuffleClient.close(ExternalShuffleClient.java:152); at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1231); at org.apache.spark.SparkEnv.stop(SparkEnv.scala:96); at org.apache.spark.SparkContext$$anonfun$stop$12.apply$mcV$sp(SparkContext.scala:1756); at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1229); at org.apache.spark.SparkContext.stop(SparkContext.scala:1755); at org.apache.spark.SparkContext.<init>(SparkContext.scala:602); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:3735,deploy,deploy,3735,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,1,['deploy'],['deploy']
Deployability,"eProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18:49:12.567 INFO PrintReadsSpark - Shutting down engine; [April 27, 2016 6:49:12 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=3858759680; java.io.FileNotFoundException: File file:/Users/louisb/Workspace/gatk-protected/build/libIntelDeflater.so does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:609); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:822); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:599); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:337); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289); at org.apache.spark.deploy.yarn.Client.copyFileToRemote(Client.scala:317); at org.apache.spark.deploy.yarn.Client.org$apache$spar",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:5906,deploy,deploy,5906,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,1,['deploy'],['deploy']
Deployability,"eProgram.java:109); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.main(Main.java:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.NotSerializableException: java.nio.HeapByteBuffer; Serialization stack:; **\- object not serializable (class: java.nio.HeapByteBuffer, value: java.nio.HeapByteBuffer[pos=0 lim=775456500 cap=775456500])**; - field (class: org.bdgenomics.adam.util.TwoBitFile, name: bytes, type: class java.nio.ByteBuffer); - object (class org.bdgenomics.adam.util.TwoBitFile, org.bdgenomics.adam.util.TwoBitFile@863c31e); - field (class: org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource, name: twoBitFile, type: class org.bdgenomics.adam.util.TwoBitFile); - object (class org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource, org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource@3c82e6f4); - field (class: org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource, name: referenceSource, type: interface org.broadinstitute.hellbender.engine.datasources.ReferenceSource); ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2216:2899,deploy,deploy,2899,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2216,1,['deploy'],['deploy']
Deployability,eUtil.java:337); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289); at org.apache.spark.deploy.yarn.Client.copyFileToRemote(Client.scala:317); at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:407); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:471); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:470); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:470); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:468); at scala.collection.immutable.List.foreach(List.scala:318); at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:468); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:727); at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:142); at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:57); at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144); at org.apache.spark.SparkContext.<init>(SparkContext.scala:530); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:1839,deploy,deploy,1839,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,2,['deploy'],['deploy']
Deployability,"eblocking step***. . It also seems as if we lose the PL field for these variants when working with reblocked gvcfs (which could explain why GenotypeGVCF isn’t giving us calls for these variants). I've heard that support for hom-refs with no PLs was implemented in CombineGVCFs as of Sept 2021, but I'm still seeing the issue with CombineGVCFs 4.3.0.0. To provide more info:. - We are seeing these issues regardless of if reblocked gvcfs are analyzed together with or separate from non-reblocked gvcfs. (For reference, the downstream steps in our pipeline are GenomicsDBImport & GenotypeGVCFs, but we’re seeing the same results with CombineGVCFs & GenotypeGVCFs on a smaller set of test gvcfs.); - I have a test set of samples that I've run with and without ReblockGVCF, and have used CombineGVCFs 4.3.0.0 & GenotypeGVCFs 4.3.0.0, and we're still seeing this issue.; - I have rerun ReblockGVCF including the `--allow-missing-home-ref-data` and `--all-site-pls` flags, but neither of these seem to solve the issue either. . #### Steps to reproduce. Run WARP's [ExomeGermlineSingleSample 3.1.7](https://github.com/broadinstitute/warp/releases/tag/ExomeGermlineSingleSample_v3.1.7) pipeline. With the relocked gvcfs, run CombineGVCFs, then GenotypeGVCFs. ; Running WARP's [ExomeGermlineSingleSample 3.1.7](https://github.com/broadinstitute/warp/releases/tag/ExomeGermlineSingleSample_v3.1.7) pipeline ***but skipping the reblocking step*** and running CombineGVCFs and GenotypeGVCFs results in these same variants being called as hom-ref (which makes me think that reblocking is messing these up somehow). . Note that so far, I've only tested on our own samples. If this is something you can't reproduce, I could potentially rerun on publicly available samples to demonstrate the issue. Let me know if this is needed. . #### Expected behavior; A large number of variants should be called as hom ref (`0/0`). #### Actual behavior; Many of these variants are left as not called / missing genotypes (`./.`).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8208:2054,release,releases,2054,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8208,4,"['pipeline', 'release']","['pipeline', 'releases']"
Deployability,"ed and the underlying backend has been updated again, from Aesara to PyTensor.; > 10. So if we are going to update the environment to support Python 3.10+, it probably makes sense to go all the way to PyMC 5.9. I've made some strides in this PR; as of [6b08f3a](https://github.com/broadinstitute/gatk/pull/8561/commits/6b08f3af205cb9af1f5c63a0786f9a5a52cd78c1), I've made enough updates to accommodate API changes so that cohort-mode inference for both GermlineCNVCaller and DetermineGermlineContigPloidy runs successfully under Python 3.10 and PyMC 5.9.0---although note that 5.9.1 has been released in the interim!. However, our work has just begun. Results now produced in the numerical tests mentioned above are quite far off from the original expected results. It remains to be seen whether this is due to the randomness of inference, some slight changes to the model prior that were necessitated by the API changes, or some bugs introduced in other code updates. (Also note that I believe Andrey's PR in item 4 already broke these tests, although the numerical differences were much smaller and more reasonable---but perhaps he can confirm. Also noting here that I think determinism is still currently broken as of this commit---there have been some changes to PyTensor/PyMC seeding so that our previous theano/PyMC3 hack no longer applies.). So I think the next step is to just go to scientific-level testing and see what the fallout is. Ideally, we'd still get good performance (or perhaps better! at least on the runtime side, hopefully...) and we can just update the numerical tests. But if performance tanks, then we might need to see whether I've introduced any bugs. @mwalker174 @asmirnov239 perhaps you can comment on what might be the appropriate test suite here----1kGP?. I'll also highlight again that this PR will remove TensorFlow and might require that the corresponding CNN implementations be supported by an alternate strategy, at least until the PyTorch implementation goes in.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561:3028,update,update,3028,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561,1,['update'],['update']
Deployability,ed array size exceeds VM limit; at java.util.Properties$LineReader.readLine(Properties.java:485); at java.util.Properties.load0(Properties.java:353); at java.util.Properties.load(Properties.java:317); at org.aeonbits.owner.loaders.PropertiesLoader.load(PropertiesLoader.java:50); at org.aeonbits.owner.loaders.PropertiesLoader.load(PropertiesLoader.java:43); at org.aeonbits.owner.LoadersManager.load(LoadersManager.java:46); at org.aeonbits.owner.Config$LoadType$2.load(Config.java:129); at org.aeonbits.owner.PropertiesManager.doLoad(PropertiesManager.java:290); at org.aeonbits.owner.PropertiesManager.load(PropertiesManager.java:163); at org.aeonbits.owner.PropertiesManager.load(PropertiesManager.java:153); at org.aeonbits.owner.PropertiesInvocationHandler.<init>(PropertiesInvocationHandler.java:54); at org.aeonbits.owner.DefaultFactory.create(DefaultFactory.java:46); at org.aeonbits.owner.ConfigCache.getOrCreate(ConfigCache.java:87); at org.aeonbits.owner.ConfigCache.getOrCreate(ConfigCache.java:40); at org.broadinstitute.hellbender.utils.config.ConfigFactory.getOrCreate(ConfigFactory.java:268); at org.broadinstitute.hellbender.utils.config.ConfigFactory.getOrCreateConfigFromFile(ConfigFactory.java:454); at org.broadinstitute.hellbender.utils.config.ConfigFactory.initializeConfigurationsFromCommandLineArgs(ConfigFactory.java:439); at org.broadinstitute.hellbender.utils.config.ConfigFactory.initializeConfigurationsFromCommandLineArgs(ConfigFactory.java:414); at org.broadinstitute.hellbender.Main.parseArgsForConfigSetup(Main.java:121); at org.broadinstitute.hellbender.Main.setupConfigAndExtractProgram(Main.java:179); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:204); at org.broadinstitute.hellbender.Main.main(Main.java:291); ```. ### Affected version(s); - [x] Latest public release version [version?]; Yes. 4.1.2.0. - [ ] Latest master branch as of [date of test?]; Not tested. #### Steps to reproduce; Yet not clear.; maybe the call stack above will help. ----,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6050:2145,release,release,2145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6050,1,['release'],['release']
Deployability,"ed for a variant in terms of alignment overlap are different for taking part of PL calculation and AD/DP calculation. . Where is not totally clear what is the best way to go in practice. It seems to me that we should be consistent here and both PL and AD/DP should use the same criterion. The offending code lines:. **HaplotypeCallerGenotypingEngine.java ln171**:. ```java; ReadLikelihoods<Allele> readAlleleLikelihoods = readLikelihoods.marginalize(alleleMapper, ; new SimpleInterval(mergedVC).expandWithinContig(ALLELE_EXTENSION, header.getSequenceDictionary()));; if (configuration.isSampleContaminationPresent()) {; readAlleleLikelihoods.contaminationDownsampling(configuration.getSampleContamination());; }. ```; The code above decides the involvement in PL calculations. Notice that ```ALLELE_EXTENSION``` is set to ```2```. . For the AD/DP and so on the code responsible is in **AssemblyBasedCallerGenotypingEngine.java ln366**:. ```; // Otherwise (else part) we need to do it again.; if (configuration.useFilteredReadMapForAnnotations || !configuration.isSampleContaminationPresent()) {; readAlleleLikelihoodsForAnnotations = readAlleleLikelihoodsForGenotyping;; readAlleleLikelihoodsForAnnotations.filterToOnlyOverlappingReads(loc);; } else {; readAlleleLikelihoodsForAnnotations = readHaplotypeLikelihoods.marginalize(alleleMapper, loc);; if (emitReferenceConfidence) {; readAlleleLikelihoodsForAnnotations.addNonReferenceAllele(Allele.NON_REF_ALLELE);; }; }. ```. The ```filterToOnlyOverlappingReads(loc)``` is called then the overlap criterion is strict. (e.g. 0bp padding). This is also the case for the ```marginalize``` call if the conditional is false as the loc passed has not been padded. It seems to me that setting the ```ALLELE_EXTENSION == 2``` is a very deliberative action (so it was done for a reason) and perhaps this is the way to go... but in deed if the read really does not overlap the variant should be considered at all. . This come from a more complex discussion whet",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5434:1380,configurat,configuration,1380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5434,1,['configurat'],['configuration']
Deployability,"ed for this tool by default ; ; 22:06:39.337 WARN  GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default ; ; 22:06:39.383 INFO  NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/gvandeweyer/miniconda3/envs/ELPREP/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Mar 12, 2022 10:06:39 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 22:06:39.543 INFO  HaplotypeCaller - ------------------------------------------------------------ ; ; 22:06:39.543 INFO  HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.2.5.0 ; ; 22:06:39.543 INFO  HaplotypeCaller - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 22:06:39.543 INFO  HaplotypeCaller - Executing as [gvandeweyer@ngsvm-pipelines.uza.be](mailto:gvandeweyer@ngsvm-pipelines.uza.be) on Linux v4.4.0-210-generic amd64 ; ; 22:06:39.543 INFO  HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_312-b07 ; ; 22:06:39.544 INFO  HaplotypeCaller - Start Date/Time: March 12, 2022 10:06:39 PM CET ; ; 22:06:39.544 INFO  HaplotypeCaller - ------------------------------------------------------------ ; ; 22:06:39.544 INFO  HaplotypeCaller - ------------------------------------------------------------ ; ; 22:06:39.544 INFO  HaplotypeCaller - HTSJDK Version: 2.24.1 ; ; 22:06:39.544 INFO  HaplotypeCaller - Picard Version: 2.25.4 ; ; 22:06:39.544 INFO  HaplotypeCaller - Built for Spark Version: 2.4.5 ; ; 22:06:39.544 INFO  HaplotypeCaller - HTSJDK Defaults.COMPRESSION\_LEVEL : 2 ; ; 22:06:39.545 INFO  HaplotypeCaller - HTSJDK Defaults.USE\_ASYNC\_IO\_READ\_FOR\_SAMTOOLS : false ; ; 22:06:39.545 INFO  HaplotypeCaller - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true ; ; 22:06",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7741:5222,pipeline,pipelines,5222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7741,1,['pipeline'],['pipelines']
Deployability,ed-websocket\9.0.35\tomcat-embed-websocket-9.0.35.jar;E:\repository\org\springframework\spring-web\5.2.6.RELEASE\spring-web-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-webmvc\5.2.6.RELEASE\spring-webmvc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\repository\org\springframework\spring-core\5.2.6.RELEASE\spring-core-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-jcl\5.2.6.RELEASE\spring-jcl-5.2.6.RELEASE.jar;E:\repository\com\google\firebase\firebase-admin\6.8.1\firebase-admin-6.8.1.jar;E:\repository\com\google\api-client\google-api-client\1.25.0\google-api-client-1.25.0.jar;E:\repository\com\google\oauth-client\google-oauth-client\1.25.0\google-oauth-client-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-jackson2\1.25.0\google-http-client-jackson2-1.25.0.jar;E:\repository\com\google\api-client\google-api-client-gson\1.25.0\google-api-client-gson-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-gson\1.25.0\google-http-client-gson-1.25.0.jar;E:\repository\com\google\code\gson\gson\2.8.6\gson-2.8.6.jar;E:\repository\com\google\http-client\google-http-client\1.25.0\google-http-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:5458,configurat,configuration-processor,5458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['configurat'],['configuration-processor']
Deployability,"ed; 12:57:16.776 INFO AnalyzeCovariates - Initializing engine; 12:57:16.776 INFO AnalyzeCovariates - Done initializing engine; 12:57:17.333 INFO AnalyzeCovariates - Generating csv file '/tmp/AnalyzeCovariates17353441228865531235.csv'; 12:57:17.414 INFO AnalyzeCovariates - Generating plots file '/home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf'; 12:57:17.829 INFO AnalyzeCovariates - Shutting down engine; [December 17, 2020 at 12:57:17 PM TRT] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=633339904; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.10272183847736955081';source('/tmp/BQSR.16251220439562120273.R'); /tmp/AnalyzeCovariates17353441228865531235.csv /home/detagen/Desktop/pipeline/playground/BACKUP/FMF-248_Backup/before.recal.FMF-248.table /home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Stdout: ; Stderr: Error in library(gplots) : there is no package called ‘gplots’; Calls: source -> withVisible -> eval -> eval -> library; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:80); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:19); 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:130); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.generatePlots(RecalUtils.java:360); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.generatePlots(AnalyzeCovariates.java:329); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.doWork(AnalyzeCovariates.java:341); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.r",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7006:4025,pipeline,pipeline,4025,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006,1,['pipeline'],['pipeline']
Deployability,edFileSystem.java:641); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:641); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.deleteHadoopFile(ReadsSparkSink.java:200); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:191); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:106); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.runTool(MarkDuplicatesSpark.java:94); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:257); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66); at org.broadinstitute.hellbender.Main.main(Main.java:81); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1451:2411,deploy,deploy,2411,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1451,6,['deploy'],['deploy']
Deployability,"ed](https://github.com/googlegenomics/dataflow-java/blob/master/src/main/java/com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform.java#L104) we get a **java.lang.VerifyError**. The full error looks like this:. ```; Exception in thread ""main"" java.lang.VerifyError: Bad type on operand stack; Exception Details:; Location:; com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform.getReadsFromBAMFilesSharded(Lcom/google/cloud/dataflow/sdk/Pipeline;Lcom/google/cloud/genomics/utils/GenomicsFactory$OfflineAuth;Ljava/lang/Iterable;Lcom/google/cloud/genomics/dataflow/readers/bam/ReaderOptions;Ljava/util/List;)Lcom/google/cloud/dataflow/sdk/values/PCollection; @25: invokevirtual; Reason:; Type 'com/google/cloud/dataflow/sdk/transforms/Create' (current frame, stack[2]) is not assignable to 'com/google/cloud/dataflow/sdk/transforms/PTransform'; Current Frame:; bci: @25; flags: { }; locals: { 'com/google/cloud/dataflow/sdk/Pipeline', 'com/google/cloud/genomics/utils/GenomicsFactory$OfflineAuth', 'java/lang/Iterable', 'com/google/cloud/genomics/dataflow/readers/bam/ReaderOptions', 'java/util/List', 'com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform' }; stack: { 'com/google/cloud/dataflow/sdk/values/TupleTag', 'com/google/cloud/dataflow/sdk/Pipeline', 'com/google/cloud/dataflow/sdk/transforms/Create' }; Bytecode:; 0x0000000: bb00 0159 2db7 0002 3a05 1905 2bb6 0003; 0x0000010: b200 042a 1904 b800 05b6 0006 c000 07b8; 0x0000020: 0008 b600 09b8 000a b200 0b2a 2cb8 0005; 0x0000030: b600 06c0 0007 120c b800 0db6 0009 b600; 0x0000040: 0e3a 0619 0519 06b6 000f b0 . at org.broadinstitute.hellbender.engine.dataflow.datasources.ReadsDataflowSource.getReadPCollection(ReadsDataflowSource.java:130); at org.broadinstitute.hellbender.dev.tools.walkers.bqsr.BadTypeRepro.ingestReadsAndGrabHeader(BadTypeRepro.java:100); at org.broadinstitute.hellbender.dev.tools.walkers.bqsr.BadTypeRepro.setupPipeline(BadTypeRepro.java:74); ```. This is the same error I saw when upgr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/791:731,Pipeline,Pipeline,731,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/791,3,['Pipeline'],['Pipeline']
Deployability,"ee#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9mZXJtaS9GZXJtaUxpdGVBc3NlbWJsZXIuamF2YQ==) | `80.645% <80.645%> (ø)` | `8 <8> (?)` | |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `92.308% <ø> (+0.447%)` | `28% <ø> (+28%)` | :white_check_mark: |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `87.097% <ø> (+0.986%)` | `59% <ø> (+59%)` | :white_check_mark: |; | [...adinstitute/hellbender/tools/spark/sv/SVUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlV0aWxzLmphdmE=) | `38.462% <ø> (+5.52%)` | `12% <ø> (+12%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2381?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2381?src=pr&el=footer). Last update [8a42977...d6fb1ba](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2381#issuecomment-276803321:3530,update,update,3530,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2381#issuecomment-276803321,2,['update'],['update']
Deployability,ee#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `73.95% <ø> (+0.84%)` | `26% <ø> (ø)` | :x: |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `77.477% <ø> (+0.901%)` | `38% <ø> (+2%)` | :white_check_mark: |; | [...tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9BbGxlbGVTdWJzZXR0aW5nVXRpbHMuamF2YQ==) | `87.037% <ø> (+0.926%)` | `40% <ø> (+1%)` | :white_check_mark: |; | [...ark/pipelines/metrics/MeanQualityByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZWFuUXVhbGl0eUJ5Q3ljbGVTcGFyay5qYXZh) | `91.667% <ø> (+1.042%)` | `10% <ø> (ø)` | :x: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `74.194% <ø> (+1.075%)` | `26% <ø> (+1%)` | :white_check_mark: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2404/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2404?src=pr&el=continue).; > **Leg,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2404#issuecomment-279082842:3944,pipeline,pipelines,3944,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2404#issuecomment-279082842,2,['pipeline'],['pipelines']
Deployability,ee) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...itute/hellbender/utils/report/GATKReportTable.java](https://codecov.io/gh/broadinstitute/gatk/pull/5443/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZXBvcnQvR0FUS1JlcG9ydFRhYmxlLmphdmE=) | `70.412% <0%> (-0.265%)` | `67 <0> (ø)` | |; | [...ils/nio/NioFileCopierWithProgressMeterResults.java](https://codecov.io/gh/broadinstitute/gatk/pull/5443/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyUmVzdWx0cy5qYXZh) | `0% <0%> (-94.737%)` | `0% <0%> (-9%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5443/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5443/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...ols/funcotator/FuncotatorDataSourceDownloader.java](https://codecov.io/gh/broadinstitute/gatk/pull/5443/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JEYXRhU291cmNlRG93bmxvYWRlci5qYXZh) | `0% <0%> (-66.197%)` | `0% <0%> (-14%)` | |; | [...nder/utils/nio/NioFileCopierWithProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5443/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyLmphdmE=) | `17% <0%> (-52.5%)` | `9% <0%> (-30%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5443/d,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5443#issuecomment-440888980:1861,pipeline,pipelines,1861,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5443#issuecomment-440888980,1,['pipeline'],['pipelines']
Deployability,eference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; Using GATK jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -Djava.io.tmpdir=/data/xieduo/gatktest -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; 13:35:32.710 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:32.890 INFO BaseRecalibrator - ------------------------------------------------------------; 13:35:32.891 INFO BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.2.6.1; 13:35:32.891 INFO BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:35:32.891 INFO BaseRecalibrator - Executing as xieduo@pbs-master on Linux v3.10.0-1160.41.1.el7.x86_64 amd64; 13:35:32.891 INFO BaseRecalibrator - Java runtime: Java HotSpot(TM) 64-Bit Server VM v18+36-2087; 13:35:32.891 INFO B,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:1430,pipeline,pipeline,1430,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,"ehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --with-mpfr=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --with-mpc=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --with-isl=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --with-cloog=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --with-boot-ldflags='-Wl,-headerpad_max_install_names -Wl,-L/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac/lib -Wl,-L/usr/lib' --with-stage1-ldflags='-Wl,-headerpad_max_install_names -Wl,-L/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac/lib -Wl,-L/usr/lib' --enable-checking=release --with-tune=generic --disable-multilib; Thread model: posix; gcc version 4.8.5 (GCC); `; Perhaps using the Xcode version would fix things?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-391065177:3700,release,release,3700,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-391065177,1,['release'],['release']
Deployability,"el=desc) will **decrease** coverage by `-<.001%`.; > The diff coverage is `75%`. ```diff; @@ Coverage Diff @@; ## master #2366 +/- ##; ===============================================; - Coverage 76.201% 76.201% -<.001% ; - Complexity 10808 10812 +4 ; ===============================================; Files 750 750 ; Lines 39417 39421 +4 ; Branches 6858 6859 +1 ; ===============================================; + Hits 30036 30039 +3 ; Misses 6775 6775 ; - Partials 2606 2607 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2366?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...75c14f4c17c957aa969a69a94c966fad3d5c8f1d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1N0YW5kYXJkQXJndW1lbnREZWZpbml0aW9ucy5qYXZh) | `0% <ø> (ø)` | `0 <ø> (ø)` | :x: |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...75c14f4c17c957aa969a69a94c966fad3d5c8f1d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `92.568% <75%> (-0.488%)` | `74 <2> (+3)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2366?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2366?src=pr&el=footer). Last update [f45f6a5...75c14f4](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...75c14f4c17c957aa969a69a94c966fad3d5c8f1d?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2366#issuecomment-276527211:2012,update,update,2012,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2366#issuecomment-276527211,2,['update'],['update']
Deployability,el=desc) will **increase** coverage by `0.064%`.; > The diff coverage is `96%`. ```diff; @@ Coverage Diff @@; ## master #2327 +/- ##; ===============================================; + Coverage 76.136% 76.201% +0.064% ; - Complexity 10787 10810 +23 ; ===============================================; Files 748 750 +2 ; Lines 39378 39417 +39 ; Branches 6857 6858 +1 ; ===============================================; + Hits 29981 30036 +55 ; + Misses 6791 6775 -16 ; Partials 2606 2606; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2327?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [.../org/broadinstitute/hellbender/tools/FlagStat.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GbGFnU3RhdC5qYXZh) | `76.404% <ø> (ø)` | `3 <ø> (ø)` | :x: |; | [...lbender/tools/spark/pipelines/CountBasesSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRCYXNlc1NwYXJrLmphdmE=) | `90% <ø> (ø)` | `5 <ø> (ø)` | :x: |; | [...rg/broadinstitute/hellbender/tools/CountReads.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db3VudFJlYWRzLmphdmE=) | `100% <ø> (ø)` | `3 <ø> (ø)` | :x: |; | [...s/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZW,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-268877705:1280,pipeline,pipelines,1280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-268877705,2,['pipeline'],['pipelines']
Deployability,"el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnMuamF2YQ==) | `90.71% <0%> (-0.43%)` | `100% <0%> (-1%)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `87.3% <0%> (-0.31%)` | `244% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (+0.47%)` | `33% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `80% <0%> (+30%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=footer). Last update [7c24e67...43708f1](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5844#issuecomment-477765576:3688,update,update,3688,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5844#issuecomment-477765576,2,['update'],['update']
Deployability,"elease but other tools are not. ---. @vdauwera commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215498517). Frankly on the face of it I hate the idea of toolset-specific jars, because it increases entropy on the distribution & support side of things. I would much prefer to see this resolved by project development branches. With the possibility of making project-specific nightly builds off of those branches, to enable pointing people to hot fixes for a specific toolset without taking in whatever else is going on in other projects. ---. @droazen commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215757315). Alright, to give an overview of where this stands, we have several options on the table for solving this problem:; 1. Split the GATK into even more repos (a CNV-only repo, a HaplotypeCaller repo) that are versioned separately. GATK release X would then consist of CNV version Y, HaplotypeCaller version Z, gatk-public version P, etc. This is probably the most ""correct"" solution from a software engineering perspective, but might be a nightmare to work with.; 2. Have the ability to release jars with a subset of the tools exposed to the user (eg., CNV-only jars). Geraldine hates this one, and it does seem like a bad idea to have these incomplete jars floating out in the wild.; 3. Everyone develops on separate branches, and merges to master only when everything in a branch is ""release-ready"". In this scenario master itself is always (theoretically, at least) ready for release. This solves the original problem of release of some tools being blocked by others, but creates some other problems: last-minute merge conflicts across dev teams, large amounts of code being held back for months while it undergoes testing, harder to share code across groups, more complex git workflows for everyone.; 4. Everyone is free to merge development versions of tools to master (as is cur",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:3195,release,release,3195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,1,['release'],['release']
Deployability,"elease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1192,Install,Install,1192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['Install'],['Install']
Deployability,"ellFormedReadFilter because they do not have read groups or base qualities. [test_pathseq_unmapped.bam.zip](https://github.com/broadinstitute/gatk/files/537153/test_pathseq_unmapped.bam.zip). > > ./gatk-launch PrintReadsSpark -I ~/Work/gatk/tests/test_pathseq_unmapped.bam -O ~/Work/gatk/tests/test_pathseq_unmapped.output.bam; > > Using GATK wrapper script /Users/markw/IdeaProjects/gatk/build/install/gatk/bin/gatk; > > Running:; > > /Users/markw/IdeaProjects/gatk/build/install/gatk/bin/gatk PrintReadsSpark -I /Users/markw/Work/gatk/tests/test_pathseq_unmapped.bam -O /Users/markw/Work/gatk/tests/test_pathseq_unmapped.output.bam; > > 15:10:22.765 INFO IntelGKLUtils - Trying to load Intel GKL library from:; > > jar:file:/Users/markw/IdeaProjects/gatk/build/install/gatk/lib/gkl-0.1.2.jar!/com/intel/gkl/native/libIntelGKL.dylib; > > 15:10:22.790 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; > > [October 18, 2016 3:10:22 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark --output /Users/markw/Work/gatk/tests/test_pathseq_unmapped.output.bam --input /Users/markw/Work/gatk/tests/test_pathseq_unmapped.bam --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false --disableAllReadFilters false; > > [October 18, 2016 3:10:22 PM EDT] Executing as markw@WMC9F-819 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_91-b14; Version: Version:4.alpha.1-318-gcdc484c-SNAPSHOT; > > 15:10:22.793 INFO PrintReadsSpark - Defaults.BUFFER_SIZE : 131072; > > 15:10:22.793 INFO PrintReadsSpark - Defaults.COMPRESSION_LEVEL : 1; > > 15:10:22.793 INFO PrintReadsSpark - Defaults.CREATE_INDEX : false; > > 15:10:22.793 INFO PrintReadsSpark - Defaults.CREATE_MD5 : false; > > 15:10:22.79",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2219:1166,pipeline,pipelines,1166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2219,1,['pipeline'],['pipelines']
Deployability,"ellbender.Main.main(Main.java:292); Caused by: org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python -c import gcnvkernel. Stdout: ; Stderr: Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/home/gamer456148/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/home/gamer456148/anaconda3/envs/gatk/lib/python3.6/site-packages/pymc3/__init__.py"", line 5, in <module>; from .distributions import *; File ""/home/gamer456148/anaconda3/envs/gatk/lib/python3.6/site-packages/pymc3/distributions/__init__.py"", line 1, in <module>; from . import timeseries; File ""/home/gamer456148/anaconda3/envs/gatk/lib/python3.6/site-packages/pymc3/distributions/timeseries.py"", line 5, in <module>; from .continuous import get_tau_sd, Normal, Flat; File ""/home/gamer456148/anaconda3/envs/gatk/lib/python3.6/site-packages/pymc3/distributions/continuous.py"", line 12, in <module>; from scipy import stats; File ""/home/gamer456148/anaconda3/envs/gatk/lib/python3.6/site-packages/scipy/stats/__init__.py"", line 345, in <module>; from .morestats import *; File ""/home/gamer456148/anaconda3/envs/gatk/lib/python3.6/site-packages/scipy/stats/morestats.py"", line 12, in <module>; from numpy.testing.decorators import setastest; ModuleNotFoundError: No module named 'numpy.testing.decorators'. 	at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeCommand(PythonScriptExecutor.java:79); 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.checkPythonEnvironmentForPac",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6467:5195,continuous,continuous,5195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6467,1,['continuous'],['continuous']
Deployability,"ellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. The user mentioned that this didn't happen on GATK 4.1, so I've been comparing both versions of the code. It turns out that the implementation of ""GenotypingEngine.java"" has changed since then, and after some digging, I noticed that the issue is that the newer versions have uninitialized instances of the class ""OneShotLogger"". The fix is simple, I've added the change myself and built GATK again. The user reports that the issue is gone. Just add the following code inside the constructor method:. ``` ; protected GenotypingEngine(final Config configuration,; final SampleList samples,; final boolean doAlleleSpecificCalcs) {; this.configuration = Utils.nonNull(configuration, ""the configuration cannot be null"");; Utils.validate(!samples.asListOfSamples().isEmpty(), ""the sample list cannot be null or empty"");; this.samples = samples;; this.doAlleleSpecificCalcs = doAlleleSpecificCalcs;; logger = LogManager.getLogger(getClass());; this.oneShotLogger = new OneShotLogger(logger); // <------ ADD THIS LINE; numberOfGenomes = this.samples.numberOfSamples() * configuration.genotypeArgs.samplePloidy;; alleleFrequencyCalculator = AlleleFrequencyCalculator.makeCalculator(configuration.genotypeArgs);; }; ```. #### Steps to reproduce; See description, but I can't provide the exact inputs used for it. #### Expected behavior; The null pointer exception shouldn't occur, there should be a warning only. #### Actual behavior; Program crashes with null pointer exception for high enough values of ploidy.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8158:3686,configurat,configuration,3686,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8158,6,['configurat'],['configuration']
Deployability,ellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:464); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:458); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.validateToolInputs(GATKSparkTool.java:402); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:312); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:108); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:166); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:185); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.main(Main.java:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2020:2129,deploy,deploy,2129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2020,6,['deploy'],['deploy']
Deployability,els.hg38.vcf.gz -O PAAD11N.recal_data.test.table; Using GATK jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -Djava.io.tmpdir=/data/xieduo/Łuksza_2022_Nature -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; 13:36:33.528 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:36:33.547 WARN NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (No such file or directory); 13:36:33.550 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:36:33.551 WARN NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (No such file or directory); 13:36:33.669 INFO BaseRecalibrator - ------------------------------------------------------------; 13:36:33.670 INFO BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.2.6.1; 13:36:33.670 INFO BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:36:33.670 INFO BaseRecalibrator - Executing as xieduo@pbs-master on Linux v3.10.0-1160.41.1.el7.x86_6,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:6556,pipeline,pipeline,6556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,"emIntegrationTest.java:49); Running Test: Test method testChimericUnpairedMapping(org.broadinstitute.hellbender.BwaMemIntegrationTest). Gradle suite > Gradle test > org.broadinstitute.hellbender.BwaMemIntegrationTest > testChimericUnpairedMapping SKIPPED; Running Test: Test method testPerfectUnpairedMapping(org.broadinstitute.hellbender.BwaMemIntegrationTest). Gradle suite > Gradle test > org.broadinstitute.hellbender.BwaMemIntegrationTest > testPerfectUnpairedMapping SKIPPED; ```. This test fails because some JAR wasn't built:; ```; Running Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest); Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: No local jar was found, please build one by running. Gradle suite > Gradle test > org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest > testPipeForPicardTools STANDARD_ERROR; No local jar was found, please build one by running; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err:. Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: /disk-samsung/ports/biology/gatk/work/gatk-4.6.0.0/gradlew localJar. /disk-samsung/ports/biology/gatk/work/gatk-4.6.0.0/gradlew localJar; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: or. or; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: export GATK_LOCAL_JAR=<path_to_local_jar>. export GATK_LOCAL_JAR=<path_to_local_jar>; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: No local jar was found, please build one b",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8940:3617,Pipeline,PipelineSupportIntegrationTest,3617,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8940,1,['Pipeline'],['PipelineSupportIntegrationTest']
Deployability,"end:54 - Shutting down all executors; 2019-06-03 22:34:48 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-06-03 22:34:48 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-06-03 22:34:48 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-06-03 22:34:48 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-06-03 22:34:49 INFO MemoryStore:54 - MemoryStore cleared; 2019-06-03 22:34:49 INFO BlockManager:54 - BlockManager stopped; 2019-06-03 22:34:49 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-06-03 22:34:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-06-03 22:34:49 INFO SparkContext:54 - Successfully stopped SparkContext; 22:34:49.027 INFO PrintReadsSpark - Shutting down engine; [June 3, 2019 10:34:49 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 3.72 minutes.; Runtime.totalMemory()=3829923840; htsjdk.samtools.util.RuntimeIOException: java.io.IOException: Stream closed; at htsjdk.samtools.IndexStreamBuffer.readFully(IndexStreamBuffer.java:23); at htsjdk.samtools.IndexStreamBuffer.readInteger(IndexStreamBuffer.java:56); at htsjdk.samtools.AbstractBAMFileIndex.readInteger(AbstractBAMFileIndex.java:432); at htsjdk.samtools.AbstractBAMFileIndex.query(AbstractBAMFileIndex.java:272); at htsjdk.samtools.CachingBAMFileIndex.getQueryResults(CachingBAMFileIndex.java:159); at htsjdk.samtools.BAMIndexMerger.processIndex(BAMIndexMerger.java:43); at htsjdk.samtools.BAMIndexMerger.processIndex(BAMIndexMerger.java:16); at org.disq_bio.disq.impl.file.IndexFileMerger.mergeParts(IndexFileMerger.java:90); at org.disq_bio.disq.impl.formats.bam.BamSink.save(BamSink.java:132); at org.disq_bio.disq.HtsjdkReadsRddStorage.write(HtsjdkReadsRddStorage.java:225); at org.broadinstitute.hellbender.engine.spark.datasou",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:1895,pipeline,pipelines,1895,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,2,['pipeline'],['pipelines']
Deployability,"end:54 - Shutting down all executors; 2019-06-03 22:45:35 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-06-03 22:45:35 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-06-03 22:45:35 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-06-03 22:45:35 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-06-03 22:45:35 INFO MemoryStore:54 - MemoryStore cleared; 2019-06-03 22:45:35 INFO BlockManager:54 - BlockManager stopped; 2019-06-03 22:45:35 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-06-03 22:45:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-06-03 22:45:35 INFO SparkContext:54 - Successfully stopped SparkContext; 22:45:35.933 INFO PrintReadsSpark - Shutting down engine; [June 3, 2019 10:45:35 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 5.79 minutes.; Runtime.totalMemory()=4147118080; 2019-06-03 22:45:35 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-06-03 22:45:35 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-423d02dc-cbc1-4c83-907d-ca315ca231bc; 2019-06-03 22:45:35 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-c035847e-6113-48f1-b5d1-66184925be7d; ```. $ hadoop fs -ls /project/casa/gcad/adsp.cc/sv/*. -rw-r--r-- 3 farrell casa 1684348 2019-06-03 22:34 /project/casa/gcad/adsp.cc/sv/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.bam.sbi; -rw-r--r-- 3 farrell casa 27494132363 2019-06-03 22:45 /project/casa/gcad/adsp.cc/sv/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.cram. Writing to a sam worked without triggering error.... ```; 2019-06-03 22:59:08 INFO TaskSetManager:54 - Finished task 183.0 in stage 0.0 (TID 181) in 106230 ms on scc-q04.scc.b",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:9393,pipeline,pipelines,9393,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,2,['pipeline'],['pipelines']
Deployability,"endencies to the conda environment in a branch and rebased on that. A few issues that I've run into or that came up in discussion with @jamesemery and @cmnbroad:. -I moved all tests that depend on R into the `python` test group (which should perhaps be renamed to `conda`). Note that some of these also fall into the `spark` test group---not sure if there is any special Spark setup done for that group, but we should make sure that they don't fail if they're not run with the conda environment. -@cmnbroad mentioned that some Picard tools that depend on R may break outside of the conda environment if the user does not have the R dependencies. -When we install R in the base image, we pull in a lot of basic dependencies (e.g., build-essential, various libraries and compilers, etc.) So when the R install is removed, it looks like many tests begin failing or hanging, perhaps because they are falling back on Java implementations (e.g., AVX PairHMM tests). We need to determine the dependencies for these tests and install them separately. Here is the list of packages that get pulled in by the R install: ```autoconf automake autotools-dev binutils bsdmainutils build-essential; bzip2-doc cdbs cpp cpp-5 debhelper dh-strip-nondeterminism dh-translations; dpkg-dev fakeroot g++ g++-5 gcc gcc-5 gettext gettext-base gfortran; gfortran-5 groff-base ifupdown intltool intltool-debian iproute2; isc-dhcp-client isc-dhcp-common libalgorithm-diff-perl; libalgorithm-diff-xs-perl libalgorithm-merge-perl libarchive-zip-perl; libasan2 libasprintf-dev libasprintf0v5 libatm1 libatomic1; libauthen-sasl-perl libblas-common libblas-dev libblas3 libbz2-dev; libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libcroco3 libcurl3; libdns-export162 libdpkg-perl libencode-locale-perl libfakeroot; libfile-basedir-perl libfile-desktopentry-perl libfile-fcntllock-perl; libfile-listing-perl libfile-mimeinfo-perl libfile-stripnondeterminism-perl; libfont-afm-perl libfontenc1 libgcc-5-dev libgdbm3 libgettextpo-dev; libget",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954:1111,install,install,1111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954,2,['install'],['install']
Deployability,"ent overlap are different for taking part of PL calculation and AD/DP calculation. . Where is not totally clear what is the best way to go in practice. It seems to me that we should be consistent here and both PL and AD/DP should use the same criterion. The offending code lines:. **HaplotypeCallerGenotypingEngine.java ln171**:. ```java; ReadLikelihoods<Allele> readAlleleLikelihoods = readLikelihoods.marginalize(alleleMapper, ; new SimpleInterval(mergedVC).expandWithinContig(ALLELE_EXTENSION, header.getSequenceDictionary()));; if (configuration.isSampleContaminationPresent()) {; readAlleleLikelihoods.contaminationDownsampling(configuration.getSampleContamination());; }. ```; The code above decides the involvement in PL calculations. Notice that ```ALLELE_EXTENSION``` is set to ```2```. . For the AD/DP and so on the code responsible is in **AssemblyBasedCallerGenotypingEngine.java ln366**:. ```; // Otherwise (else part) we need to do it again.; if (configuration.useFilteredReadMapForAnnotations || !configuration.isSampleContaminationPresent()) {; readAlleleLikelihoodsForAnnotations = readAlleleLikelihoodsForGenotyping;; readAlleleLikelihoodsForAnnotations.filterToOnlyOverlappingReads(loc);; } else {; readAlleleLikelihoodsForAnnotations = readHaplotypeLikelihoods.marginalize(alleleMapper, loc);; if (emitReferenceConfidence) {; readAlleleLikelihoodsForAnnotations.addNonReferenceAllele(Allele.NON_REF_ALLELE);; }; }. ```. The ```filterToOnlyOverlappingReads(loc)``` is called then the overlap criterion is strict. (e.g. 0bp padding). This is also the case for the ```marginalize``` call if the conditional is false as the loc passed has not been padded. It seems to me that setting the ```ALLELE_EXTENSION == 2``` is a very deliberative action (so it was done for a reason) and perhaps this is the way to go... but in deed if the read really does not overlap the variant should be considered at all. . This come from a more complex discussion whether the in cases whether variants ar",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5434:1431,configurat,configuration,1431,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5434,1,['configurat'],['configuration']
Deployability,ent&utm_campaign=pr+comments&utm_term=broadinstitute) | Coverage Δ | |; |---|---|---|; | [...tructuralVariationDiscoveryArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/7950/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5QXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `94.595% <ø> (-0.142%)` | :arrow_down: |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7950/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `96.296% <ø> (-3.704%)` | :arrow_down: |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/7950/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `93.333% <ø> (-0.784%)` | :arrow_down: |; | [...spark/sv/evidence/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/7950/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `69.710% <100.000%> (+0.225%)` | :arrow_up: |; | [...er/tools/spark/sv/evidence/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/7950/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7950#issuecomment-1188387745:2253,integrat,integration,2253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7950#issuecomment-1188387745,1,['integrat'],['integration']
Deployability,"entUtils`). There are still some improvements that can be made (especially in segment union and the subsequent modeling), but we should be ready to go for a first validation. Some notes:. WDL:; - I've moved the old pipeline to `somatic_old` folders.; - There is now just a matched-pair workflow and a panel workflow. We can add a single BAM case workflow or expand the matched-pair workflow to handle this, depending on the discussion at https://github.com/broadinstitute/gatk/issues/3657.; - WES/WGS is toggled by providing an optional target-file input.; - For all workflows, we always collect integer read counts; for WGS, these are output as both HDF5 and TSV and the HDF5 is used for subsequent input.; - For the case workflow, we always collect allelic counts at all sites and output as TSV.; - [x] We should output all data files as HDF5 by default and as TSV optionally. EDIT: This is done for `CollectFragmentCounts`.; - [x] We will need to update the workflows when @MartonKN and @asmirnov239 get `PreprocessIntervals` and `CollectReadCounts` merged, respectively. These tools will remove the awkwardness required by `PadTargets` and `CalculateTargetCoverage`/`SparkGenomeReadCounts`. Denoising:; - All parameters are exposed in the PoN creation tool (#3356).; - Without a PoN, standardization and optional GC correction are performed (#3570).; - Other than the minor point about sample mean/median being used inconsistently noted above, the denoising process is essentially exactly the same mathematically as before (""superficial"" differences include the vastly improved memory and I/O optimizations, the ability to adjust number of principal components used, the removal of redundant SVDs, the enforcement of consistent GC-bias correction).; - [ ] That said, I'll carry over this TODO from above: Revisit standardization procedure by checking with simulated data. We should make sure that the centering of the data does not rescale the true copy ratio.; - The only major difference is we ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:1159,update,update,1159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,2,['update'],['update']
Deployability,"ential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:7945,release,released,7945,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['release'],['released']
Deployability,"enty of coverage and no obvious reason for such a low GQ score. Often the GQ should be 99 as the DP >40. This seems to be primarily an issue with homozygous reference calls. . The GT is accurate for the high DP sites but the inaccurate GQ is problematic for any genotype level qc on the pVCF. If the site is recoded from 0/0 to './.' for GQ <20, the result is higher missing rate due to the inaccurate GQ=0. . Directly calling the VCF with HaplotypeCaller without the gVCF intermediate gVCF file calculates the correct GQ score. Freebayes also calculates a correct GQ on these samples.; [rs429358_gq_dp.pdf](https://github.com/broadinstitute/gatk/files/2612419/rs429358_gq_dp.pdf). #### Steps to reproduce. I am seeing this bug for 57 samples of 5000 crams at snp rs429358 but I would expect it is not unique to this site. . Select two crams with a Passed site with:; cram 1. Call with GT='0/0, GQ=0 and DP >40.; cram 2. Call with GT='0/1' or '1/1' and DP>20. . Create vcf with two approaches:. Pipeline 1. HaplotypeCaller-->vcf. module load gatk/4.0.11.0; gatk HaplotypeCaller -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa\; -I gq0_cram.list\; -L chr19:44907684-44909822\; --use-new-qual-calculator\; -O good.vcf.gz. Good GQ scores were also estimated with Freebayes on these samples also. Pipeline 2 HaplotypeCaller --> bvcf--->ImportVCF-->GenotypeVCF-->VCF with 2 samples. gatk HaplotypeCaller -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa\; -I $sample.cram\; --use-new-qual-calculator\; -L chr19:44907684-44909822\; -ERC GVCF\; -O bad.g.vcf.gz. Followed by import and GenotypeVCF. . #### Expected behavior; Pipeline 2 should generate accurate GQ scores that match the GQ in the HaplotypeCaller vcf output of pipeline 1. Instead GQ=0. . This is the output for the 57 GQ=0 samples with pipeline 1 which is accurate. AC=7;AF=0.061;AN=114;BaseQRankSum=-6.147;DP=1846;ExcessHet=3.8592;FS=0.000;InbreedingCoeff=-0.0640;MLEAC=6;MLEAF=0.053;M",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5445:1254,Pipeline,Pipeline,1254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5445,1,['Pipeline'],['Pipeline']
Deployability,"environment for gCNV. Even taking out TensorFlow (assuming that the CNN will not be supported by this environment), it's a difficult task:; > 1. The goal is to update Python from 3.6 to 3.10+, since Terra now requires the latter for officially supported images.; > 2. However, gCNV relies on the PyMC3 package. PyMC3 3.1 is currently used in GATK master. 3.1 was released in 2017, not long before our release of gCNV in 2018, but it's very old now.; > 3. The latest version of Python that is supported by PyMC3 3.1 in conda is Python 3.6.; > 4. @asmirnov239 has a draft PR (#8094) that updates PyMC3 to 3.5 and Python to 3.7, which clearly still falls short of Python 3.10+. This PR also updated some gCNV code to make it compatible with PyMC3 3.5. (It also removed TensorFlow and added PyTorch.); > 5. @asmirnov239 also merged a PR that added tests for numerical reproducibility of GermlineCNVCaller in cohort mode in #7889.; > 6. The earliest version of PyMC that supports Python 3.10+ is PyMC 4, released in 2022.; > 7. However, PyMC 4 introduces API changes, which will also require additional gCNV code changes and numerical testing.; > 8. These API changes are because the underlying computational backend for PyMC was updated from Theano (think of this as an old alternative to TensorFlow) to Aesara.; > 9. Since then, PyMC 5.9 has been released and the underlying backend has been updated again, from Aesara to PyTensor.; > 10. So if we are going to update the environment to support Python 3.10+, it probably makes sense to go all the way to PyMC 5.9. I've made some strides in this PR; as of [6b08f3a](https://github.com/broadinstitute/gatk/pull/8561/commits/6b08f3af205cb9af1f5c63a0786f9a5a52cd78c1), I've made enough updates to accommodate API changes so that cohort-mode inference for both GermlineCNVCaller and DetermineGermlineContigPloidy runs successfully under Python 3.10 and PyMC 5.9.0---although note that 5.9.1 has been released in the interim!. However, our work has just begun",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561:1111,release,released,1111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561,1,['release'],['released']
Deployability,"epare, factored out sample name (#7288); - Remove training sites only param from ExtractFeatures broadinstitute/dsp-spec-ops#261; - add param for mem for indels (#7282); - Ah prepare localize option (#7299); - Export sites only vcf STEP 1-- 317 add AC, AN, AF to the final VCF (#7279); - AoU GVS Cohort Extract wdl (#7242); - reliability (#7310); - bump to include FT tag filtering (#7316); - First pass at a Terra QuickStart (#7267); - Ah fix timestamp query (#7319); - 313 Cleanup Extract Cohort params (#7293); - bump bq storage version. See GVS-332 (#7330); - Variant Store extraction - Add VCF size to output (#7329); - add WARP-style scattering to SNPsVariantRecalibrator in GvsCreateFilterSet (#7320); - added ref ranges support (#7337); - 318 Sites only filtered vcf then annotate wdl (#7305); - Replace service_account_json (file) with service_account_json_path (string) to allow call-caching (#7347); - Parallelize create filterset by breaking out the 3 filter set file creation/loads into separate tasks (#7342); - Create WDL to validate VAT and add first test (#7352); - Add task for VAT validation #3 (#7360); - Add task for VAT validation #4 (#7363); - Instructions on how to download BQ Metadata and visualize results (#7359); - don't mix contigs, rightsize memory (#7361); - Add custom annotations as ac an af (#7351); - Add task for VAT validation #8 & 9 (#7364); - added bcftools, upgraded gcloud version (#7369); - fix wdl (#7378); - Update .dockstore.yml; - Add VAT validation rule #5 [VS-16] (#7365); - Add VAT validation rule #7 [VS-14] and validation rule #6 [VS-15] (#7379); - Batching of samples for create import TSVs (#7382); - Add VAT validation rule #2 [VS-19] (#7374); - Create VAT scripts directory (#7386); - fixing SA change from file to string (#7371); - add extract_subpop script (#7387); - Add is_loaded column to sample_info and logic to populate after ingest [VS-158] (#7389); - Add Gnomad subpopulation info into the VAT (#7381); - implement GVS ID assignment (#",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:16328,upgrade,upgraded,16328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,"['Update', 'upgrade']","['Update', 'upgraded']"
Deployability,"ependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # conda-installed 2.2.4 appears to be the most recent version with a consistent API and without conflicts/clobbers; # if you wish to update, note that versions of conda-forge::keras after 2.2.5; # undesirably set the environment variable KERAS_BACKEND = theano by default; - defaults::intel-openmp=2019.4; - conda-forge::scikit-learn=0.22.2; - conda-forge::matplotlib=3.2.1; - conda-forge::pandas=1.0.3. # core R dependencies; these should only be used for plotting and do not take precedence over core python dependencies!; - r-base=3.6.2; - r-data.table=1.12.8; - r-dplyr=0.8.5; - r-getopt=1.20.3; - r-ggplot2=3.3.0; - r-gplots=3.0.3; - r-gsalib=2.1; - r-optparse=1.6.4. # other python dependencies; these should be removed after functionality is moved into Java code; - biopython=1.76; - pyvcf=0.6.8; - bioconda::pysam=0.15.3 # using older conda-installed versions may result in libcrypto / openssl bugs. # ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:2681,update,updated,2681,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,4,"['install', 'update']","['installed', 'updated']"
Deployability,"eport; > Merging [#2550](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/c8ede6ef810a3d9a05c7deb8052e27ca724ce8ba?src=pr&el=desc) will **increase** coverage by `0.003%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #2550 +/- ##; ===============================================; + Coverage 76.279% 76.282% +0.003% ; - Complexity 10891 10892 +1 ; ===============================================; Files 752 752 ; Lines 39590 39590 ; Branches 6925 6925 ; ===============================================; + Hits 30199 30200 +1 ; Misses 6768 6768 ; + Partials 2623 2622 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...recalibration/RecalibrationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL1JlY2FsaWJyYXRpb25Bcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `93.827% <100%> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=footer). Last update [c8ede6e...f810842](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2550#issuecomment-290461016:1900,update,update,1900,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2550#issuecomment-290461016,2,['update'],['update']
Deployability,"eported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. After sourcing the tab-completion script, some tools shown cannot be run. Maybe they exist somewhere in an experimental dev version but are not bundled for public release?. ### Affected version(s); - [x ] Latest public release version [4.1.7.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. After trying to tab complete the DepthOfCoverage, I saw a few tools not listed in the documentation. I tried running them and sure enough, there were errors:. `A USER ERROR has occurred: '*' is not a valid command.`; (* is one of the tools listed below). #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. ```; cd gatk-4.1.7.0; source gatk-completion.sh; ./gatk Depth<tab>; #>DepthOfCoverage DepthPerAlleleBySample DepthPerSampleHC; ./gatk DepthPerSampleHC -h; ...; ***********************************************************************; A USER E",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6615:1424,release,release,1424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6615,1,['release'],['release']
Deployability,"er it's worth consolidating some of the parameter sets at this stage? I think there's an argument for having at least two sets (haplotype-to-reference + read-to-haplotype), but I'm not sure how to justify having a separate set for dangling heads/tails. But also not sure which set the latter should be consolidated with---@jamesemery thoughts? Again, let me reiterate that it seems that many of these parameter values were chosen arbitrarily (or, if not, that the procedure for choosing them has been lost). As a start, you can see the results of some optimizations I did on the CHM mix on slide 15 at https://docs.google.com/presentation/d/1zGuquAZWSUQ-wNxp8D6HhGNjIaFcV0_X9WAS4LODbEo/edit?usp=sharing Here, I optimized over haplotype-to-reference + read-to-haplotype SW parameters on various metrics after variant normalization using vcfeval. These optimizations were done using the Bayesian optimization framework I prototyped long ago (see https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer and https://docs.google.com/presentation/d/1t5WOAEOMp0xAzJgpKbP68BUnclNYfIVRrDSL9wl1-3A/edit?usp=sharing); this entailed running parameter scans using a local Cromwell on my desktop. Probably this optimization work could be redone relatively easily using the Neptune framework put together by @dalessioluca, which was still in development at the time I did this work. Happy to share the resources and scripts I used if we go down this route; they are pretty lightweight. See more discussion starting here: https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566. Alternatively, we could merge this branch to expose the parameters now and punt on consolidating/optimizing them. I'm not completely convinced we should even do the former unless we are going to follow through on the latter, but happy to defer to others. Finally, note also there is one code optimization that I removed, since it makes assumptions on the SW parameter values that might not be va",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471:1974,pipeline,pipeline-optimizer,1974,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471,1,['pipeline'],['pipeline-optimizer']
Deployability,"er-images.githubusercontent.com/45641912/139333959-4465b06d-b2ce-4ab2-bae9-285e25168c1d.png); ![image](https://user-images.githubusercontent.com/45641912/139333973-c8e2c1f6-0efd-4f45-9d1e-10f6c4a2baac.png). To allocate more memory for the Funcotate task, one has to define this **small_task_mem** variable at the workflow level. This effectively changes the amount of memory for all tasks that make use of this dictionary, rather than just the Funcotate task. Funcotate has two input variables **default_ram_mb** and **default_disk_space_gb** which have no bearing on the memory and disk space configuration for the task.; ![image](https://user-images.githubusercontent.com/45641912/139334343-8e614e17-27ef-4fef-815d-fe6e8c39ffef.png). This leads to user confusion when they see these variables in the method configuration page, put values in, and don't see their Funcotate task use the specified values.; ![image](https://user-images.githubusercontent.com/45641912/139334535-4b9a0353-910e-4764-a6d2-a454f4d344aa.png). #### Steps to reproduce; Define the input variables **default_ram_mb** and **default_disk_space_gb** for a run of the Mutect2 workflow to be different from the amounts defined by [*small_task_mem*](https://github.com/broadinstitute/gatk/blob/4.1.8.1/scripts/mutect2_wdl/mutect2.wdl#L140) and [**disk_space**](https://github.com/broadinstitute/gatk/blob/4.1.8.1/scripts/mutect2_wdl/mutect2.wdl#L407). #### Expected behavior; Defining the input variables **default_ram_mb** and **default_disk_space_gb** allows you to specify your preferred memory and disk space configuration for the Funcotate task. #### Actual behavior; These variables do not define the runtime configuration for the task. Memory is defined by a workflow-level input that isn't clearly connected to Funcotate. #### Suggestion; Utilize the variables **default_ram_mb** and **default_disk_space_gb** that already exist in the task in such a way that modifying them has an impact on the configuration of the task VM.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7532:2501,configurat,configuration,2501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7532,3,['configurat'],['configuration']
Deployability,er.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:182); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:201); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.seek(BlockCompressedInputStream.java:380); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:977); 	at htsjdk.samtools.B,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:19525,deploy,deploy,19525,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['deploy'],['deploy']
Deployability,"er.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.FileSystemNotFoundException: Provider ""gs"" not installed; 	at java.nio.file.Paths.get(Paths.java:147); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferencePath(ReferenceFileSparkSource.java:53); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferenceBases(ReferenceFileSparkSource.java:60); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceMultiSparkSource.getReferenceBases(ReferenceMultiSparkSource.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.getRefBaseString(BreakEndVariantType.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantT",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:7735,deploy,deploy,7735,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['deploy'],['deploy']
Deployability,"erage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2521 +/- ##; ===============================================; + Coverage 76.256% 76.261% +0.005% ; Complexity 10864 10864 ; ===============================================; Files 750 750 ; Lines 39543 39543 ; Branches 6915 6915 ; ===============================================; + Hits 30154 30156 +2 ; + Misses 6771 6769 -2 ; Partials 2618 2618; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2521?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...notyper/GenotypeCalculationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/compare/7ad3c91b96448c4a867451b40b7ce6ae41cef690...2622598137d07ee362c7d98cb67e89862df0276e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwZUNhbGN1bGF0aW9uQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/7ad3c91b96448c4a867451b40b7ce6ae41cef690...2622598137d07ee362c7d98cb67e89862df0276e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2521?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2521?src=pr&el=footer). Last update [7ad3c91...2622598](https://codecov.io/gh/broadinstitute/gatk/compare/7ad3c91b96448c4a867451b40b7ce6ae41cef690...2622598137d07ee362c7d98cb67e89862df0276e?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2521#issuecomment-288757656:2076,update,update,2076,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2521#issuecomment-288757656,2,['update'],['update']
Deployability,erage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/tools/spark/pathseq/PathSeqPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4874/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFQaXBlbGluZVNwYXJrLmphdmE=) | `81.25% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...lbender/tools/spark/pathseq/PathSeqScoreSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4874/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFTY29yZVNwYXJrLmphdmE=) | `57.407% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...llbender/engine/spark/DataprocIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4874/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvRGF0YXByb2NJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.786% <0%> (+0.062%)` | `1 <0> (ø)` | :arrow_down: |; | [...hellbender/tools/spark/pipelines/SortSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4874/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFNhbVNwYXJrLmphdmE=) | `100% <100%> (ø)` | `5 <0> (-1)` | :arrow_down: |; | [...ellbender/tools/spark/pathseq/PathSeqBwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4874/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFCd2FTcGFyay5qYXZh) | `67.391% <100%> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...ls/ExtractOriginalAlignmentRecordsByNameSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4874/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9FeHRyYWN0T3JpZ2luYWxBbGlnbm1lbnRSZWNvcmRzQnlOYW1lU3BhcmsuamF2YQ==) | `90.909% <100%> (ø)` | `10 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/tools/spark/RevertSamSpark.java](https://codecov.io/g,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4874#issuecomment-461951346:1870,pipeline,pipelines,1870,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4874#issuecomment-461951346,1,['pipeline'],['pipelines']
Deployability,"erent results by the first filtering step (on intervals by interval median). @LeeTL1220 @davidbenjamin what is the ""official ReCapSeg"" behavior, and do we want to keep the current behavior? In general, I think all of the standardization (i.e., filtering/imputation/truncation/transformation) steps could stand some revisiting. Evaluation:. - [ ] Revisit standardization procedure by checking with simulated data. We should make sure that the centering of the data does not rescale the true copy ratio.; - [x] <s>Investigate the effect of keeping duplicates. I am still not sure why we do this, and it may have a more drastic impact on WGS data.</s> Turns out we don't keep duplicates for WGS; see #3367.; - [ ] Check that GC-bias-correction+PCA and PCA-only perform comparably, even at small bin sizes (~300bp). From what I've seen, this is true for larger bin sizes (~3kbp), so explicit GC-bias correction may not be necessary. (That is, even at these (purportedly) large bin sizes, the effect of the read-based GC-bias correction is obvious for those samples where it is important. However, the end result is not very different from PCA-only denoising with no GC-bias correction performed.); - [x] <s>Check that changing CBS alpha parameter sufficiently reduces hypersegmentation.</s> <s>Looks like the hybrid p-value calculation in DNACopy is not accurate enough to handle WGS-size data. (Also, it's relatively slow, taking ~30 minutes on ~10M intervals.) Even if I set alpha to 0, I still get a ridiculous number of segments! So I think it's finally time to scrap CBS. I'll look into other R segmentation packages that might give us a quick drop-in solution, but we may want to roll our own simple algorithm (which we will scrap anyway once the coverage model is in for somatic).</s> I've implemented a fast kernel-segmentation method that seems very promising, see below.; - [ ] Investigate performance vs. CGA ReCapSeg pipeline on THCA samples.; - [ ] Investigate concordance with Genome STRiP.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316894351:5840,pipeline,pipeline,5840,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316894351,2,['pipeline'],['pipeline']
Deployability,"erfile. commit f1235c25aeba85570b5ce389a34975f1b7b5ec3c; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 09:39:46 2017 -0500. Dockerfile edit. commit 3df84dd4693f28e4e8b34fd33f877e99749dffce; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 16:08:06 2017 -0500. Update test PoNs. commit 2c3b20e62a1cba7af24c0b0846eb1629422f51e6; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 15:49:38 2017 -0500. Update test files. commit c65c6e9144ef396792364ab2e06b7b436bb97684; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 15:30:59 2017 -0500. Adding no-GC/do-GC WDL tests. commit 56451843066a456d9cf8e6eac55ae4df2c518ec3; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 5 12:51:17 2017 -0500. Updates to handle SAM header changes from sl_wgs_acnv_headers and updates to mb_gcnv_python_kernel. commit d02d04df684a2820308a1d1c2bfda4b7d1c5f05e; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Nov 13 12:52:33 2017 -0500. Added CLIs and WDL for python gCNV pipeline. commit 66ed74b68375d43514ef84658e7a6c771ed9053c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Nov 15 01:50:03 2017 -0500. Polished code, ready for review; ; gCNV computational kernel (initial release); ; renaming gammas_s to psi_s to uniformity (sample-specific unexplained variance); ; renamed determine_ploidy_and_depth.py to cohort_determine_ploidy_and_depth.py; finite-temperature forward-backward algorithm; in the ploidy model, replaced alpha_j (NB over-dispersion) with psi_j (unexplained variance) for uniformity. Also, added the possibility of sample-specific unexplained variance in the germline contig ploidy model; ; updated I/O routines and CLIs according to team discussion; ; updated I/O routines and CLIs according to team discussion; ; changed the output layout of the ploidy determination tool; refactored parts of io.py; upped the version to 0.3 as it is not backwards compatible anymore; ; case ploidy determination tool from a given plo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:10240,pipeline,pipeline,10240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['pipeline'],['pipeline']
Deployability,erlapping(SparkSharder.java:128); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.shard(SparkSharder.java:101); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.getVariants(VariantWalkerSpark.java:129); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runTool(VariantWalkerSpark.java:160); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.runPipeline(VariantWalkerSpark.java:57); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [dfac787d-19aa-4296-8078-c033cd9f440d] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:12394,deploy,deploy,12394,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,6,['deploy'],['deploy']
Deployability,erm=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zdi9TaXRlRGVwdGh0b0JBRi5qYXZh) | `82.418% <0.000%> (+1.099%)` | :arrow_up: |; | [...lkers/validation/EvaluateInfoFieldConcordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/7992/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vRXZhbHVhdGVJbmZvRmllbGRDb25jb3JkYW5jZS5qYXZh) | `72.581% <0.000%> (+1.613%)` | :arrow_up: |; | [...va/org/broadinstitute/hellbender/GATKBaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7992/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9HQVRLQmFzZVRlc3QuamF2YQ==) | `98.333% <0.000%> (+1.667%)` | :arrow_up: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/7992/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `86.207% <0.000%> (+1.724%)` | :arrow_up: |; | [...ute/hellbender/tools/sv/CondenseDepthEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/7992/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zdi9Db25kZW5zZURlcHRoRXZpZGVuY2UuamF2YQ==) | `80.488% <0.000%> (+2.439%)` | :arrow_up: |; | ... and [208 more](https://codecov.io/gh/broadinstitute/gatk/pull/7992/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinst,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7992#issuecomment-1218381617:4704,Update,UpdateVCFSequenceDictionary,4704,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7992#issuecomment-1218381617,1,['Update'],['UpdateVCFSequenceDictionary']
Deployability,"ervals; reorganized copynumber packages.; -For motivation of changes in CallCopyRatioSegments, see #3825.; -I added the ability to turn off binning in PreprocessIntervals by specifying bin_length = 0.; -I removed the separation between coverage and allelic packages to make the package structure a bit simpler.; -@MartonKN should review, since he wrote PreprocessIntervals and is updating the caller. Added segmentation classes and tests for ModelSegments CNV pipeline.; -I added implementations of copy-ratio, allele-fraction, and ""multidimensional"" (joint) segmentation. All implementations are pretty boilerplate; they simply partition by contig and then call out to KernelSegmenter. Note that there is some logic in multidimensional segmentation that only uses the first het in each copy-ratio interval and if any are available, and imputes the alt-allele fraction to 0.5 if not.; -Makes sense for @mbabadi to review this, since he reviewed the KernelSegmenter PR. Added modeling classes and tests for ModelSegments CNV pipeline.; -Most of this code is copied from the old MCMC code. However, I've done some overall code cleanup and refactoring, especially to remove some overextraction of methods in the allele-fraction likelihoods (see #2860). I also added downsampling and scaling of likelihoods to cut down on runtime. Tests have been simplified and rewritten to use simulated data.; -@LeeTL1220 do you think you could take a look?. Added ModelSegments CLI.; -Mostly control flow to handle optional inputs and validation, but there is some ugly and not well documented code that essentially does the GetHetCoverage step. We'll refactor later, I filed #3915.; -@asmirnov239 can review. This is lower priority than the gCNV VCF writing. Deleted gCNV WDL and Cromwell tests.; -Trivial to review. Added WDL and Cromwell tests for ModelSegments CNV pipeline.; -This includes the cost optimizations from @meganshand and @jsotobroad (sorry guys, I wasn't sure how to track your contributions while fi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3913:1106,pipeline,pipeline,1106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3913,1,['pipeline'],['pipeline']
Deployability,"es - GCS max retries/reopens: 20; 12:57:16.776 INFO AnalyzeCovariates - Requester pays: disabled; 12:57:16.776 INFO AnalyzeCovariates - Initializing engine; 12:57:16.776 INFO AnalyzeCovariates - Done initializing engine; 12:57:17.333 INFO AnalyzeCovariates - Generating csv file '/tmp/AnalyzeCovariates17353441228865531235.csv'; 12:57:17.414 INFO AnalyzeCovariates - Generating plots file '/home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf'; 12:57:17.829 INFO AnalyzeCovariates - Shutting down engine; [December 17, 2020 at 12:57:17 PM TRT] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=633339904; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.10272183847736955081';source('/tmp/BQSR.16251220439562120273.R'); /tmp/AnalyzeCovariates17353441228865531235.csv /home/detagen/Desktop/pipeline/playground/BACKUP/FMF-248_Backup/before.recal.FMF-248.table /home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Stdout: ; Stderr: Error in library(gplots) : there is no package called ‘gplots’; Calls: source -> withVisible -> eval -> eval -> library; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:80); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:19); 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:130); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.generatePlots(RecalUtils.java:360); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.generatePlots(AnalyzeCovariates.java:329); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.doWor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7006:3934,pipeline,pipeline,3934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006,1,['pipeline'],['pipeline']
Deployability,es 1915 1918 +3 ; Lines 144130 144650 +520 ; Branches 15901 15992 +91 ; ===============================================; + Hits 10005 125981 +115976 ; + Misses 133410 12859 -120551 ; - Partials 715 5810 +5095; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5395?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/5395/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1N0YW5kYXJkQXJndW1lbnREZWZpbml0aW9ucy5qYXZh) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...er/utils/haplotype/HaplotypeBAMWriterUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5395/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvSGFwbG90eXBlQkFNV3JpdGVyVW5pdFRlc3QuamF2YQ==) | `89.076% <ø> (+86.555%)` | `23 <0> (+22)` | :arrow_up: |; | [...hellbender/tools/spark/pipelines/SortSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5395/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFNhbVNwYXJrLmphdmE=) | `100% <100%> (+100%)` | `6 <0> (+6)` | :arrow_up: |; | [.../AbstractMarkDuplicatesCommandLineProgramTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5395/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL21hcmtkdXBsaWNhdGVzL0Fic3RyYWN0TWFya0R1cGxpY2F0ZXNDb21tYW5kTGluZVByb2dyYW1UZXN0LmphdmE=) | `96.241% <100%> (+95.865%)` | `92 <0> (+90)` | :arrow_up: |; | [...lbender/utils/read/SAMRecordToGATKReadAdapter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5395/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL1NBTVJlY29yZFRvR0FUS1JlYWRBZGFwdGVyLmphdmE=) | `92.806% <100%> (+87.331%)` | `146 <1> (+135)` | :arrow_up: |; | [...rkduplicates/MarkDuplicatesSparkUtils,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5395#issuecomment-451266508:1589,pipeline,pipelines,1589,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5395#issuecomment-451266508,1,['pipeline'],['pipelines']
Deployability,"es on the read bases for each position on the read when it seems that it must be possible to accomplish the same just doing at most one pass per possible STR length. This task is to fix the PCR artifact modeling issues evaluating whether there is at least no a drop in calling accuracy all. Also try to make the code more efficient. ---. @ldgauthier commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-123431158). @yfarjoun and I just added a Palantir issue for this this morning -- should the analysis wait until you're done updating the code?. ---. @vruano commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-123431971). Just waiting for test to pass...; So you knew about this issue already?. ---. @ldgauthier commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-123432816). We were talking about it because the PCR-free option doesn't get used in production (on PCR-free data) and we didn't know how much difference it actually makes. ---. @vruano commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-123481297). Merged. ; I think that you can go ahead with the analysis and I would borrow your set up to see if the eventual code update improves things for PCR-plus. . ---. @vruano commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-123481614). Sorry for the confusion, that merge doesn't solve this issue but one one related to the comp. performance of the existing code. . ---. @eitanbanks commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-123482433). @ldgauthier that's a different issue. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-260465303). Moving to GATK4; decide there whether it's still applicable or not.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2915:1799,update,update,1799,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2915,1,['update'],['update']
Deployability,"es to CreateFilterSet and ExtractCallset from 30K run (#7423); - Also changed file size from Int to Float in SumBytes task python (#7429); - Adding the subpopulation calculations to the VAT creation WDL (#7399); - 154 De obfuscate (#7435); - filter on gvs_ids for workflow (#7428); - update for assign ids and changes in import (#7439); - need to loop through sets when moving to done (#7440); - add option for create filter set to use sample_info with is_loaded (#7434); - remove dead branch (#7443); - Scaling the VAT -- switch the input to take in a file of vcf shard file names (#7446); - dockstore testing: move validate vat inputs (#7449); - Update GVS sample QC to support multiple callsets per datasset [VS-177] (#7451); - Update GvsImportGenomes.wdl (#7462); - Add extraction uuid BQ label to GvsPrepareCallstep from GvsExtractCohortFromSampleNames (#7458); - Add manifest summary file to GvsExtractCallset (#7457); - Create workflow to create and populate alt_allele table [VS-51] (#7426); - Added additional workflow and README updates for Quickstart [VS-183] (#7463); - formatting on sample QC README; - formatting change #2 to sample QC README; - address VS-152, remove extra headers from extract (#7466); - Update GvsExtractCallset.example.inputs.json (#7469); - Add ability to copy interval list files to gs directory [VS-191] (#7467); - add an expiration date to the temp tables (#7455); - fix the check for duplicates in import genomes (#7470); - added job ID to alt_allele population call output [VS-194] (#7473); - added steps and deliverables to GVS README [VS-181] (#7452); - Ah check the is loaded field in feature extract (#7475); - changes to put pet data directly into data table (#7478); - added override for ExtractTasks' preemptible value (#7477); - bcftools to the rescue (#7456); - execute_with_retry() refactor and error handling improvements [VS-159] (#7480); - Small updates to GvsExtractCallset from beta callset, new workflow for re-scattered shards (#7493); - add f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:18211,update,updates,18211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,"['Update', 'update']","['Update', 'updates']"
Deployability,es.ReferenceFileSource.<init>(ReferenceFileSource.java:31); 	at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:49); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:394); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:360); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:351); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [1c0c33a8-53ac-4407-a452-bb8622fd3060] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2382:10337,deploy,deploy,10337,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2382,6,['deploy'],['deploy']
Deployability,"es.sorted.BQSR.bam -O /juffowup2/malaria/haplotypecaller_arg_testing/PG0004-CW.haplotype_caller.fixed_bam_file.with_pileup.g.vcf.gz --bam-output /juffowup2/malaria/haplotypecaller_arg_testing/PG0004-CW.haplotype_caller.fixed_bam_file.with_pileup.bamout.bam -contamination 0 --sample-ploidy 2 --linked-de-bruijn-graph --pileup-detection true --pileup-detection-enable-indel-pileup-calling true --max-reads-per-alignment-start 20 --annotate-with-num-discovered-alleles -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -G StandardAnnotation -G StandardHCAnnotation -ERC GVCF --verbosity INFO; 14:14:15.323 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 14:14:15.328 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 14:14:15.388 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/juffowup/gatk/build/install/gatk/lib/gkl-0.8.11.jar!/com/intel/gkl/native/libgkl_compression.so; 14:14:15.435 INFO HaplotypeCaller - ------------------------------------------------------------; 14:14:15.439 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.4.0.0-44-g1529aa1-SNAPSHOT; 14:14:15.439 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:14:15.439 INFO HaplotypeCaller - Executing as jonn@dsde-methods-jonn-juffowup on Linux v5.4.0-1104-gcp amd64; 14:14:15.439 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v17.0.7+7; 14:14:15.440 INFO HaplotypeCaller - Start Date/Time: July 26, 2023 at 2:14:15 PM UTC; ...; 22:15:34.977 INFO HaplotypeCaller - Shutting down engine; [July 26, 2023 at 10:15:34 PM UTC] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 481.33 minutes.; Runtime.totalMemory()=47982837760; java.lang.NegativeArraySizeException: -896617256; at org.broadinstitut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8440:1422,install,install,1422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8440,1,['install'],['install']
Deployability,es/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/vcfMask.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/ad-bug-input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/CEUTrio.20.21.missingIndel.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/chr21.bad.pl.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combined_genotype_gvcf_exception.nocall.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combined_genotype_gvcf_exception.original.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/gvcf.basepairResolution.gvcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/leadingDeletion.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.combined.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.depr.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/testUpdatePGT.gvcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.markedDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.unmarkedDups.bam.bai,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:57206,pipeline,pipeline,57206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['pipeline'],['pipeline']
Deployability,"esPipelineSpark - ------------------------------------------------------------; 13:47:29.831 INFO BwaAndMarkDuplicatesPipelineSpark - The Genome Analysis Toolkit (GATK) v4.0.4.0-23-g6e1cc8c-SNAPSHOT; 13:47:29.831 INFO BwaAndMarkDuplicatesPipelineSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:47:29.832 INFO BwaAndMarkDuplicatesPipelineSpark - Executing as root@973f3a3a3407 on Linux v4.4.0-124-generic amd64; 13:47:29.832 INFO BwaAndMarkDuplicatesPipelineSpark - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_131-8u131-b11-1~bpo8+1-b11; 13:47:29.832 INFO BwaAndMarkDuplicatesPipelineSpark - Start Date/Time: May 21, 2018 1:47:29 PM UTC; 13:47:29.832 INFO BwaAndMarkDuplicatesPipelineSpark - ------------------------------------------------------------; 13:47:29.832 INFO BwaAndMarkDuplicatesPipelineSpark - ------------------------------------------------------------; 13:47:29.833 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Version: 2.14.3; 13:47:29.833 INFO BwaAndMarkDuplicatesPipelineSpark - Picard Version: 2.18.2; 13:47:29.833 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:47:29.833 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:47:29.834 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 13:47:29.834 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:47:29.834 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 13:47:29.834 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 13:47:29.834 INFO BwaAndMarkDuplicatesPipelineSpark - GCS max retries/reopens: 20; 13:47:29.834 INFO BwaAndMarkDuplicatesPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 13:47:29.834 WARN BwaAndMarkDuplicatesPipelineSpark - ; ```; thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:20559,patch,patch,20559,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['patch'],['patch']
Deployability,"etting the following error. However, the chr6.raw.excessHet.vcf.gz does not contain that multiallelic variant site. This variant is the nearest at that location but the error is for a variant at chr6:26914009 with different alleles =[G*, GTGTA, GTGTATA, GTGTGTA] . . `chr6 26914005 . A ATG,G 15390.7 PASS AC=278,2;AF=0.04,0.0002879;AN=6948;AS_BaseQRankSum=-0.2,0.4;AS_FS=0.522,0;AS_InbreedingCoeff=-0.0012,0.1805;AS_MQ=58.75,59.2;AS_MQRankSum=0,-3.2;AS_QD=2.56,0.02;AS_ReadPosRankSum=0.1,0.3;AS_SOR=0.652,0.724;BaseQRankSum=-0.152;DP=118313;ExcessHet=2.9774;FS=0.518;InbreedingCoeff=0.0016;MLEAC=278,2;MLEAF=0.04,0.0002879;MQ=56.9;MQRankSum=-0.962;QD=2.57;ReadPosRankSum=0.193;SOR=0.712; `. ```; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chr6:26914009 [VC chr6.raw.excessHet.vcf.gz @ chr6:26914009 Q276902.75 of type=INDEL alleles=[G*, GTGTA, GTGTATA, GTGTGTA] attr={AC=[4269, 29, 5], AF=[0.620, 4.209e-03, ; #### Steps to reproduce; /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk --java-options -Xms5g ApplyVQSR -O indel.recalibrated.vcf.gz -V chr6.raw.excessHet.vcf.gz -AS --recal-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.recal --use-allele-specific-annotations --tranches-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.tranches --truth-sensitivity-filter-level 99.0 --create-output-variant-index true -mode INDEL; ```. #### Expected behavior; Create recalibrated vcf file. #### Actual behavior; ```; Caused by:; Process `ApplyRecalibrationIndels` terminated with an error exit status (3). Command executed:. #!/bin/bash; /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk --java-options -Xms5g ApplyVQSR -O indel.recalibrated.vcf.gz -V chr6.raw.excessHet.vcf.gz -AS --recal-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.recal --use-allele-specific-annotations --tranches-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.tranches --truth-sensitivity-filter-level 99.0 --create-output-variant-index true -mode I",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8054:1114,install,install,1114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8054,1,['install'],['install']
Deployability,ework\spring-webmvc\5.2.6.RELEASE\spring-webmvc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\repository\org\springframework\spring-core\5.2.6.RELEASE\spring-core-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-jcl\5.2.6.RELEASE\spring-jcl-5.2.6.RELEASE.jar;E:\repository\com\google\firebase\firebase-admin\6.8.1\firebase-admin-6.8.1.jar;E:\repository\com\google\api-client\google-api-client\1.25.0\google-api-client-1.25.0.jar;E:\repository\com\google\oauth-client\google-oauth-client\1.25.0\google-oauth-client-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-jackson2\1.25.0\google-http-client-jackson2-1.25.0.jar;E:\repository\com\google\api-client\google-api-client-gson\1.25.0\google-api-client-gson-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-gson\1.25.0\google-http-client-gson-1.25.0.jar;E:\repository\com\google\code\gson\gson\2.8.6\gson-2.8.6.jar;E:\repository\com\google\http-client\google-http-client\1.25.0\google-http-client-1.25.0.jar;E:\repository\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;E:\repository\org\apache\httpcomponents\httpclient\4.5.12\httpclient-4.5.12.jar;E:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:5602,RELEASE,RELEASE,5602,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,"exFeatureFile - Start Date/Time: January 26, 2018 12:17:06 AM GMT; 00:17:06.846 INFO IndexFeatureFile - ------------------------------------------------------------; 00:17:06.846 INFO IndexFeatureFile - ------------------------------------------------------------; 00:17:06.847 INFO IndexFeatureFile - HTSJDK Version: 2.13.2; 00:17:06.847 INFO IndexFeatureFile - Picard Version: 2.17.2; 00:17:06.848 INFO IndexFeatureFile - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 00:17:06.849 INFO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 00:17:06.849 INFO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 00:17:06.850 INFO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 00:17:06.850 INFO IndexFeatureFile - Deflater: IntelDeflater; 00:17:06.855 INFO IndexFeatureFile - Inflater: IntelInflater; 00:17:06.856 INFO IndexFeatureFile - GCS max retries/reopens: 20; 00:17:06.858 INFO IndexFeatureFile - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 00:17:06.859 INFO IndexFeatureFile - Initializing engine; 00:17:06.860 INFO IndexFeatureFile - Done initializing engine; 00:17:07.292 INFO FeatureManager - Using codec VCFCodec to read file file://bad.vcf; 00:17:07.310 INFO IndexFeatureFile - Shutting down engine; [January 26, 2018 12:17:07 AM GMT] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=512229376; java.lang.IllegalStateException: the progress meter has not been started yet; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:697); at org.broadinstitute.hellbender.engine.ProgressMeter.stop(ProgressMeter.java:230); at org.broadinstitute.hellbender.utils.codecs.ProgressReportingDelegatingCodec.isDone(ProgressReportingDelegatingCodec.java:104); at htsjdk.tribble.index.IndexFactory$FeatureIterator.readNextFeature(IndexFactory.java:522); at htsjdk.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4269:2304,patch,patch,2304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4269,1,['patch'],['patch']
Deployability,"existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); GATK GenotypeGVCFs. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I conducted joint-call with GATK GenotypeGVCfs for two samples (proband, and mother). I have identified the maternal variant information filled with ""."" in jointcall.vcf which is the output file of GTAK GenotypeGVCfs (see, figure 1). For chromosome MT, all variant information field values were fileld with ""."", instead of mother's g.vcf. . ; ![image](https://user-images.githubusercontent.com/45510932/207542098-cd4af866-c209-405f-9553-3810275f7d8e.png); Figure 1. Jointcall.vcf of proband, and mother. redbox refers to maternal variant information. . . Except for chromosomes X, Y, and MT, these issues did not occur. In addition, I suspected the false positive variants filtering which is the advantage of GATK jointcall. however, the variants which have ""."" values do not seem to be false positive variants considering AD, DP, and variant allele frequency (VAF). #### Steps to reproduce; GATK version used: 3.8.1; ``",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8129:1283,release,release,1283,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8129,1,['release'],['release']
Deployability,"f the CNV tools to be blocked for a long time because something else in the toolkit (like the `HaplotypeCaller`) is not ready for release. . There could be a `properties` file in the jar that controls which tools are exposed via the command-line -- this way we could publish a jar that exposes only the CNV tools, for example. An alternative approach would be to use branching and cherry-picking to do this kind of selective release, or split the GATK into even more repositories, but I'm not sure those approaches would be preferable. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215491991). This came out of a discussion between myself and @LeeTL1220 . ---. @lbergelson commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215493945). So a gatk release would contain different sets of tools sometimes? Wouldn't that be confusing? It seems like it would be better to always release different jars, or version sets of tools independently and release jars with the latest good release of each individual set of tools. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215494432). @lbergelson Well, we definitely still want there to be releases of the GATK toolkit in its entirety. If the CNV tools need to be released more frequently than this, they could be versioned/released separately and periodically incorporated into the toolkit-wide releases. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215495326). To be clear, though, this is very much still in the ""throwing out ideas for discussion"" phase, and alternate proposals are welcome provided they include the concept of a GATK-wide release, and make some provision for the situation where the CNV tools (or some other sub-category) are ready for release but other tools are not. -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:1146,release,release,1146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,4,['release'],['release']
Deployability,"f-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `53.247% <0%> (-18.071%)` | `28% <0%> (-6%)` | |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `40.469% <0%> (-18.009%)` | `28% <0%> (ø)` | |; | ... and [42 more](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=footer). Last update [781db35...13a10e2](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2574#issuecomment-292193941:4334,update,update,4334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2574#issuecomment-292193941,2,['update'],['update']
Deployability,fail travis build if before_install / install blocks fail,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3444:38,install,install,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3444,1,['install'],['install']
Deployability,faultGradleLauncher$1.create(DefaultGradleLauncher.java:106); at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:63); at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106); at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:92); at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:47); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); at org.gradle.launcher.daemon.server.exec.ResetDeprecationLogger.execute(ResetDeprecationLogger.java:26); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.j,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155:5024,Continuous,ContinuousBuildActionExecuter,5024,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155,2,['Continuous'],['ContinuousBuildActionExecuter']
Deployability,fe053c62266decf848fdebda56a372ed12704?src=pr&el=desc) will **decrease** coverage by `0.001%`.; > The diff coverage is `90.476%`. ```diff; @@ Coverage Diff @@; ## master #5093 +/- ##; ===============================================; - Coverage 87.037% 87.036% -0.001% ; - Complexity 31728 31735 +7 ; ===============================================; Files 1943 1943 ; Lines 146193 146213 +20 ; Branches 16141 16145 +4 ; ===============================================; + Hits 127242 127258 +16 ; - Misses 13064 13068 +4 ; Partials 5887 5887; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5093?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...institute/hellbender/engine/VariantWalkerBase.java](https://codecov.io/gh/broadinstitute/gatk/pull/5093/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvVmFyaWFudFdhbGtlckJhc2UuamF2YQ==) | `100% <ø> (ø)` | `14 <0> (ø)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/5093/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `88.462% <85.714%> (+1.505%)` | `16 <5> (+2)` | :arrow_up: |; | [...ls/UpdateVCFSequenceDictionaryIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5093/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnlJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `92.727% <92.857%> (+0.044%)` | `16 <6> (+7)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5093/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/S,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5093#issuecomment-411427321:1233,Update,UpdateVCFSequenceDictionary,1233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5093#issuecomment-411427321,1,['Update'],['UpdateVCFSequenceDictionary']
Deployability,"fea6bf874e0b62262a3b1d239ce4d76792d5c416; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 09:31:43 2017 -0500. revert. commit 456c53f88d01b603f4175d8896a0dac036af03f8; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 08:17:22 2017 -0500. enabled openmp g++ linking in theano. commit e2afef14ddb957f2dbdea76fd783d3bfb8d7a64e; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 08:04:19 2017 -0500. mkl. commit 43e2a65201286161fcd5bfe7dbb21ae888e19dac; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 06:56:20 2017 -0500. added cpu argument for germline tasks. commit 4433a62c2173c7f29d0f264c084bbaf2f6738782; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 02:45:38 2017 -0500. revert travis yml forks; verbose logging germline wdl. commit ae05801e33c37b3bf2685fba202032a270804873; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 00:55:14 2017 -0500. updated somatic PoNs for PreprocessIntervals drop Ns. commit cff64984d9fb42364001bda4c73d54cf68d85a5c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 00:37:24 2017 -0500. sudo travis yml. commit 89025941febd2089d426cfa1e0f0aa6a6712e2a9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 00:23:22 2017 -0500. travis/Docker config update (g++-6, Miniconda3); python test group assignment. commit 31f96398106c2b8577b8c25d110abea3ebe7f836; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:44:53 2017 -0500. WDL test bugfix. commit 9b2fb820536ec355bea0256471bd093d547f5c99; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:20:36 2017 -0500. update WDL test JSON files. commit e3d97644d1a2c40a5c364a96f8b67246154179c9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:18:14 2017 -0500. assertions in inference task base; removed a ASCII > 128 character in log messages. commit 526cf92e623a3bbd5f9d375132b6ca046fc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:3839,update,updated,3839,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['update'],['updated']
Deployability,ference/Homo_sapiens_assembly38.2bit --aligner-index-image /mnt/1/reference/Homo_sapiens_assembly38.fasta.img --exclusion-intervals hdfs://cw-test-m:8020/reference/Homo_sapiens_assembly38.kill.intervals --kmers-to-ignore hdfs://cw-test-m:8020/reference/Homo_sapiens_assembly38.kill.kmers --cross-contigs-to-ignore hdfs://cw-test-m:8020/reference/Homo_sapiens_assembly38.kill.alts --breakpoint-intervals hdfs://cw-test-m:8020/output/intervals --fastq-dir hdfs://cw-test-m:8020/output/fastq --contig-sam-file hdfs://cw-test-m:8020/output/assemblies.sam --target-link-file hdfs://cw-test-m:8020/output/target_links.bedpe --exp-variants-out-dir hdfs://cw-test-m:8020/output/experimentalVariantInterpretations -- --spark-runner GCS --cluster cw-test --num-executors 20 --driver-memory 30G --executor-memory 30G --conf spark.yarn.executor.memoryOverhead=5000 --conf spark.network.timeout=600 --conf spark.executor.heartbeatInterval=120 --conf spark.driver.userClassPathFirst=false; ```. It failed near the end of the pipeline. Here is the tail of the log:. ```; 20:38:14.368 INFO StructuralVariationDiscoveryPipelineSpark - Used 3549 evidence target links to annotate assembled breakpoints; 20:38:14.462 INFO StructuralVariationDiscoveryPipelineSpark - Called 662 imprecise deletion variants; 20:38:14.492 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 7234 variants.; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - INV: 184; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4486; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1170; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1394; 18/01/12 20:38:16 WARN org.apache.spark.scheduler.TaskSetManager: Stage 17 contains a task of very large size (2518 KB). The maximum recommended task size is 100 KB.; 18/01/12 20:38:22 WARN org.apache.spark.scheduler.TaskSetManager: Stage 18 contains a task of very large size (2307 KB). The maximum recommended task size is 100 KB.;,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:1333,pipeline,pipeline,1333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['pipeline'],['pipeline']
Deployability,"ference/ReferenceBases.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWZlcmVuY2UvUmVmZXJlbmNlQmFzZXMuamF2YQ==) | `38.46% <0%> (-19.24%)` | `4% <0%> (-2%)` | |; | [...oadinstitute/hellbender/engine/ReferenceShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlU2hhcmQuamF2YQ==) | `62.5% <0%> (-18.75%)` | `6% <0%> (-1%)` | |; | [...broadinstitute/hellbender/engine/VariantShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvVmFyaWFudFNoYXJkLmphdmE=) | `63.63% <0%> (-13.64%)` | `7% <0%> (-1%)` | |; | [...ne/spark/datasources/ReferenceWindowFunctions.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVmZXJlbmNlV2luZG93RnVuY3Rpb25zLmphdmE=) | `12.5% <0%> (-12.5%)` | `1% <0%> (ø)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (+1.21%)` | `42% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5292?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5292?src=pr&el=footer). Last update [a74e571...3768ba2](https://codecov.io/gh/broadinstitute/gatk/pull/5292?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5292#issuecomment-427904892:4436,update,update,4436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5292#issuecomment-427904892,2,['update'],['update']
Deployability,figure out how spark-submit --files works:; - [x] does it send files like it promises **yes**; - [x] where does it put them?; **I believe it puts them in the working directory of the executor.**; - [ ] does cache them between runs?; - [ ] how do updates to the files work if it caches them?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1689:246,update,updates,246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1689,1,['update'],['updates']
Deployability,figure we should upgrade to the latest before we release,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2100#issuecomment-240551478:17,upgrade,upgrade,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2100#issuecomment-240551478,2,"['release', 'upgrade']","['release', 'upgrade']"
Deployability,"filename output in GvsRescatterCallsetInterval (#7539); - Reference block storage and query support (#7498); - update docs (#7540); - Kc fix rr load bug (#7550); - Update .dockstore.yml (#7553); - Ah add reblocking wdl (#7544); - Scatter over all interval files, not just scatter count (#7551); - fixed docker (#7558); - take advantage of fixed version of SplitIntervals (#7566); - Document AoU-specific tieout [VS-233] (#7552); - bad param assignment in aou reblocking (#7572); - Small fixes to ImportGenomes (non-write api version) (#7574); - Ah change output of reblocking wdl to external path (#7575); - close BQ Readers (#7583); - Ah spike writeapi (#7530); - bump WDL jar (#7593); - read api bytes logging, upgrade bigquery client versions (#7601); - bump (#7610); - upgrade log4j to 2.17 (#7616); - Add drop_state default of Forty to extract (#7619); - Kc fix type (#7620); - VAT cleanup and documentation (#7531); - fix empty flush (#7627); - presorted avro files, fix performance issue (#7635); - WIP extract for ranges (#7640); - VS-268 import more samples at once (#7629); - clustering vqsr tables by location (#7656); - First Version of a weight-based splitter (#7643); - Update GvsExtractCallset.wdl; - Quoting of table names (#7666); - docs for analysis of shard runtimes for balanced sharding (#7645); - Wire through GvsExtractCohortFromSampleNames with new prepare/extract [VS-283] (#7654); - Update GvsExtractCallset.wdl (#7678); - cherry pick lb_lfs_force change (#7683); - Tweak ingest messaging and failure mode [VS-267] (#7680); - Additional tweaks for GvsExtractCohortFromSampleNames [VS-283] (#7698); - VS-280 Create a VAT intermediary (#7657); - There something about split intervals [VS-306] (#7694); - VS 284 Add prepare step to Quick Start (#7685); - VS-222 dont hard code the dataset name! (#7704); - fixed bug; added tests (#7717); - Clean up optional and inconsistently named inputs [VS-294] [VS-218] (#7715); - VS-263 notes on ingest and beyond (#7618); - Add task to Ex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:21072,Update,Update,21072,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['Update'],['Update']
Deployability,"finally here. closing the main feature requests made in #2703 . Need to wait for #3752 and #3770 . Will generate a separate dummy PR about how to run the whole prototyping holistic SV interpretation tool. Some small patches need to be applied after this PR, basically for dumpster diving into ; * ambiguous events; * events where assembly contigs clearly couldn't tell a complete picture. but all parts of the diving suit are all available after this PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3805:216,patch,patches,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3805,1,['patch'],['patches']
Deployability,"fix #4649 . The cause of the exception is a new edge case that was not imagined when the reference region segmenting logic was initially written.; It is now covered, with updated tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4677:171,update,updated,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4677,1,['update'],['updated']
Deployability,fix SV pipeline default init script handling,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3467:7,pipeline,pipeline,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3467,1,['pipeline'],['pipeline']
Deployability,fix the script to validate-reads-spark-pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1921:39,pipeline,pipeline,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1921,1,['pipeline'],['pipeline']
Deployability,"fixed it by forcing the installation of numpy in the pip section, in order to bypass biopython dependencies resolution that grabs the last numpy available. patch is trivial. ```; gatkcondaenv.yml 2019-10-08 15:34:52.000000000 +0000; +++ gatkcondaenv2.yml 2020-01-21 16:17:06.777123115 +0000; @@ -21,6 +21,7 @@; - xz=5.2.3=0; - zlib=1.2.11=0; - pip:; + - numpy==1.13.3; - biopython==1.70; - bleach==1.5.0; - cycler==0.10.0; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6396#issuecomment-576770330:24,install,installation,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6396#issuecomment-576770330,2,"['install', 'patch']","['installation', 'patch']"
Deployability,fixes #1448. MarkDuplicates spark was not writing an output bam when running with a standalone spark instance if the output path was a relative file path.; This fixes the problem by making any relative file paths into absolute file paths.; Added a check to see if no part files can be found so that errors like this will crash in the future instead of silently failing. No tests are added because it's still unclear how to test errors that only occur in certain spark configurations. `makeFilePathAbsolute()` should be redundant once #958 is finished,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1450:468,configurat,configurations,468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1450,1,['configurat'],['configurations']
Deployability,"fixes #1585 - getting IntelDeflater from htsjdk zipfile (it's not part of the jar!) and then putting the path to it as a default JVM argument. @lbergelson can you review? this is a bit of a hack, improvements welcome; Do check that, out of the box (on linux) you get the IntelDeflater. I run this:. ```; ./gradlew clean installDist; ./gatk-launch CountReads -I src/test/resources/large/NA12878.RNAseq.bam; ```. and check output for `IntelDeflater`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1587:320,install,installDist,320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1587,1,['install'],['installDist']
Deployability,fixes #1784 and #1780 which both caused problems with the intel deflater. note: this incorporates the changes in https://github.com/broadinstitute/gatk/pull/1717 because without them it fails with. ```; java.lang.UnsupportedOperationException: Directory size listing not supported on GCS.; at org.broadinstitute.hellbender.utils.gcs.BucketUtils.dirSize(BucketUtils.java:301); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.getRecommendedNumReducers(GATKSparkTool.java:255); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:237); at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:35); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:313); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1785:628,pipeline,pipelines,628,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1785,1,['pipeline'],['pipelines']
Deployability,fixes https://github.com/broadinstitute/gatk/issues/1903. also updated the system properties in build.gradle and gatk-launch,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1964:63,update,updated,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1964,1,['update'],['updated']
Deployability,"fixes https://github.com/broadinstitute/gatk/issues/1904. 2 hacks needed to be done for now:; 1) bwa loses tags so we keep track of which original read corresponds to which aligned read by creating a subclass of `ShortRead` (the class that jBWA uses for JNI) and putting the original read in a pointer in there.; 2) bwa requires a fasta reference while reads pipeline wants a 2bit reference (in the BROADCAST mode, which is the default). The workaround for now is to pass two reference files one of each kind",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1981:359,pipeline,pipeline,359,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1981,1,['pipeline'],['pipeline']
Deployability,"follow deletion of prototype tools. (all, PR issued by 12/15)~~; - ~~(Reach) Collect all legacy code in a new package.~~; - [x] Delete old pipelines. (SL, #3935 awaiting review). ModelSegments pipeline:; - [x] Review and merge denoising PR (#3820).; - [x] Add WDL changes from @LeeTL1220, @meganshand, and @jsotobroad to dev branch. (Note that we exposed PreprocessIntervals.bin_length in these WDLs; I'm assuming that https://github.com/broadinstitute/cromwell/issues/2912 will allow this to be specified via the json, so I reverted this change.); - [x] Make simple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (@samuelklee); - [x] CLI for calling (cohort). (@samuelklee); - [x] CLI for calling (case). (@samuelklee); - [ ] CLI for post-processing calls. (@asmirnov239) (AS, PR issued by 12/4); - [x] Python environment. (Update: I've verified that gCNV works on the gsa server with a manual setup of conda (python=3.6) + @mbabadi's pip install---altho",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3826:1365,Update,Update,1365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826,1,['Update'],['Update']
Deployability,"for demonstrating how to using the prototyping tool. To run the tool:. ```bash; ./gradlew clean installAll. ./gatk-launch SvDiscoverFromLocalAssemblyContigAlignmentsSpark \; -I PATH_TO_LOCAL_ASSEMBLY_SAM \; -O OUTPUT_DIR \; -R PATH_TO_2BIT_REF \; --writeSAM; ```. This will scan through the assembly sam file, search for split alignments and output in a directory several VCF files, each for one raw type of variant.; This does not output VCF records for interpreted complex variant yet (see #3805 ), but put them in a more human-friendly format.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3806:96,install,installAll,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3806,1,['install'],['installAll']
Deployability,for the tieout of the VCF origin VAT and the VDS origin VAT we want to compare apples to apples (or at least run them both on the same nirvana version with the same nirvana annotations). TODO:; This is the branch I will want to tag so that future users can start here if they want to run VCFs thru the VAT pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8117:306,pipeline,pipeline,306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8117,1,['pipeline'],['pipeline']
Deployability,"for writing BAM files. This reduces memory usage since the reads; don't need to all be stored in memory. Also add some missing calls to addDataflowRunnerArgs in the integration; tests to ensure the correct dataflow runner is being picked up. This is related to https://github.com/broadinstitute/hellbender/issues/771, for the Spark/Hadoop side.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/845:165,integrat,integration,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/845,1,['integrat'],['integration']
Deployability,"force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 105, in <module>; actual_version, force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/bin/theano-nose"", line 11, in <module>; load_entry_point('Theano==1.0.4', 'console_scripts', 'theano-nose')(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 207, in main; result = main_function(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 45, in main_function; from theano import config; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/__init__.py"", line 110, in <module>; from theano.compile import (; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/__init__.py"", line 12, in <module>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 140, in <module>; preargs=args); File ${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2396, in compile_str; (status, compile_stderr.replace('\n', '. '))); Exception: Compilation failed (return status=1): /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:1981,INSTALL,INSTALLDIRGATK,1981,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['INSTALL'],['INSTALLDIRGATK']
Deployability,"form(name='psi_t', lower=psi_min, upper=psi_max, shape=T); depth_s = Uniform(name='depth_s', lower=depth_min, upper=depth_max, shape=N); ; z_su = Normal(name='z_us', mu=0., sd=1., shape=(N, D)); W_tu = Normal(name='W_tu', mu=0., sd=1. / sqrt(alpha_u), shape=(T, D)); mu_st = Deterministic(name='mu_st', var=z_su.dot(W_tu.T) + m_t); b_st = Normal(name='b_st', mu=mu_st, sd=sqrt(psi_t), shape=(N, T)); n_ts = Poisson(name='n_ts', mu=depth_s * exp(b_st).T, observed=n_ts_data); ; fit_pm = pm.variational.advi(model=model, n=num_iterations, learning_rate=learning_rate, random_seed=random_seed, eval_elbo=eval_elbo_iterations); ```. @eitanbanks @droazen @lbergelson @LeeTL1220 @ldgauthier @yfarjoun This is just one example of how using recently developed ML frameworks could make our lives orders of magnitude easier. The sooner we can develop a strategy to leverage these in Java land, the better!. I'd expect that roughly the same amount of code would be needed to specify this model using Stan. Interfaces for Stan exist for many other languages, so it might be relatively easy to come up with some Java bindings. However, one downside is that Stan is not built on top of a computational graph (e.g., theano/tensorflow), so we don't get GPU/distributed computing for free. I don't think this is a deal breaker, but it's something we should consider. ---. @samuelklee commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1038#issuecomment-302429919). It should be said that I consider this a major blocker for the CNV team. I don't think it makes sense to rebuild the somatic pipeline to include the new coverage model until we move to this ADVI framework or something like it. I do think @mbabadi should continue adding features (such as common CNV calling) to his non-ADVI germline implementation, so that we can be in a position to start calling on gnomAD or other large cohorts, but that we should eventually move the germline tool over to this framework as well.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2984:4137,pipeline,pipeline,4137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2984,1,['pipeline'],['pipeline']
Deployability,"from GvsValidateVAT.wdl (#7937); - refactoring for testablity (#7946); - More import retries [VS-532] (#7953); - A few last doc changes (#7927); - WDL to extract a single callset cost (BQ only, not Terra) (#7940); - Temporarily swap in Corretto for Temurin as we can't download Temurin. (#7969); - GL-548 - Update CreateVat code to handle samples that do not contain all population groups. (#7965); - Restore Temurin 11 [VS-570] (#7972); - Add table size check to quickstart integration test [VS-501] (#7970); - Consolidate various docs for AoU callset generation into one to rule them all [VS-553] (#7971); - VS-567. Removing usage of ServiceAccount from CreateVat related WDLs (#7974); - WDL to extract Avro files for Hail import [VS-579] (#7981); - Removed usage of service account from WDLs (#7985); - Document steps for GVS cleanup for base use case [VS-586] (#7989); - Change backticks to single quotes in several error messages - causing shell to attempt to execute. (#7995); - VS-598 - Minor update to AoU Documentation. (#7994); - Allow for incremental addition of data to alt_allele [VS-52] (#7993); - Minor AoU Documentation Update (#7999); - Batch population of alt_allele table from vet_ tables [VS-265] (#7998); - Change drop_state to NONE for Ingest/Extract [VS-607] (#8000); - python -> python3 (#8001); - Generate Hail import/export script [VS-605] (#8002); - clearer error when values are missing (#7939); - Ah [VS-565] output intervals and sample list (#8010); - make CreateAltAlleleTable task volatile (#8011); - Restore withdrawn [VS-581] (#8006); - Km gvs add storage cost and cleanup doc (#8012); - Updating documentation to reflect the changed outputs [VS-565] (#8014); - File of callset samples -> samples marked as 'withdrawn' in GVS [VS-436] (#8009); - fix quota guidelines for CPUs (#8016); - Add in ability to tweak sample-every-Nth-variant parameter for SNP model creation (#8019); - add initial notebook copy pasta (#8008); - add sample_table_timestamp to GetNumSamplesL",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:27422,update,update,27422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['update'],['update']
Deployability,from snapshots to released versions.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3127:18,release,released,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3127,1,['release'],['released']
Deployability,"ft/gatk-4.4.0.0# conda --version; conda 23.9.0; root@d12ac7710afc:/soft/gatk-4.4.0.0# ""$CONDA"" env create -n gatk -f ""$SOFT/gatk-${GATK_VERSION}/gatkcondaenv.yml""; ...; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Installing pip dependencies: - Ran pip subprocess with arguments:; ['/opt/miniconda/envs/gatk/bin/python', '-m', 'pip', 'install', '-U', '-r', '/soft/gatk-4.4.0.0/condaenv.vn0sukco.requirements.txt', '--exists-action=b']; Pip subprocess output:; Processing ./gatkPythonPackageArchive.zip; Building wheels for collected packages: gatkpythonpackages; Building wheel for gatkpythonpackages (setup.py): started; Building wheel for gatkpythonpackages (setup.py): finished with status 'done'; Created wheel for gatkpythonpackages: filename=gatkpythonpackages-0.1-py3-none-any.whl size=117686 sha256=8095375e139fa0729c7a41c8f5e8a43281fc1b6859b6d3951d3bfba7296ee349; Stored in directory: /tmp/pip-ephem-wheel-cache-ecx6e_m0/wheels/06/f7/e1/87cb7da6f705baa602256a58c9514b47dc313aade8809a01da; Successfully built gatkpythonpackages; Installing collected packages: gatkpythonpackages; Successfully installed gatkpythonpackages-0.1. done; #; # To activate this environment, use; #; # $ conda activate gatk; #; # To deactivate an active environment, use; #; # $ conda deactivate. ```. #### Actual behavior; ```sh; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda --version; conda 23.10.0; root@d12ac7710afc:/soft/gatk-4.4.0.0# ""$CONDA"" env create -n gatk -f ""$SOFT/gatk-${GATK_VERSION}/gatkcondaenv.yml""; ...; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Installing pip dependencies: | Ran pip subprocess with arguments:; ['/opt/miniconda/envs/gatk/bin/python', '-m', 'pip', 'install', '-U', '-r', '/soft/gatk-4.4.0.0/condaenv.i9brvcrk.requirements.txt', '--exists-action=b']; Pip subprocess output:. Pip subprocess error:; /opt/miniconda/envs/gatk/bin/python: No module named pip. failed. CondaEnvException: Pip failed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8618:1483,Install,Installing,1483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8618,2,"['Install', 'install']","['Installing', 'installed']"
Deployability,"fter which the usual modelling and smoothing steps are performed. For the 75% tumor + 25% normal mixture, this yields 122 segments (up from 83):; ![N-25-T-75-SJS modeled](https://user-images.githubusercontent.com/11076296/76558618-015bd180-6474-11ea-996a-48d39770149b.png). For the 25% tumor + 75% normal mixture, this yields 105 segments (up from 50):; ![N-75-T-25-SJS modeled](https://user-images.githubusercontent.com/11076296/76560726-34a05f80-6478-11ea-9027-a54726c46b9e.png). One could imagine that smoothing could be disabled (so that all samples retain the common segmentation after modeling) or made more aggressive (so that private events don't get inadvertently introduced into other samples due to noise, perhaps), depending on the use case. It looks like the joint segmentation allows some additional events to be resolved, although I haven't done any rigorous evaluations. We could probably cook up some evaluations using simulated toy data or in silico mixtures, but there's really no reason why this shouldn't work decently well, especially if the kernel-segmentation method works well on a single sample for your data. It would also be interesting to understand at which point changing segmentation parameters on a single sample can no longer yield the same performance as joint segmentation on a fixed number of samples; however, this is probably a function of various S/N ratios, and it might not be easy to characterize this behavior outside of toy data. The segmentation parameter space is big enough to make this unwieldy even for toy data, too. Perhaps we can get some feedback from test users---not only on performance, but also on the structure of the new workflow. It might also be worth gauging whether a new WDL is warranted. Otherwise, we just need to add some unit tests for correctness of the multisample-segmentation backend class, integration tests for plumbing of the new tool, and perhaps address some of the issues mentioned above. Then I'd say this is good to go.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598386823:2996,integrat,integration,2996,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598386823,2,['integrat'],['integration']
Deployability,ftp://ftp.ensemblgenomes.org/pub/bacteria/release-44/gtf/bacteria_0_collection/escherichia_coli_str_k_12_substr_mg1655/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6180#issuecomment-534657046:42,release,release-,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6180#issuecomment-534657046,1,['release'],['release-']
Deployability,"g to gsutil mv step (#7129); - ah_var_store : Add sample file argument to cohort extract (#7117); - wip; - initial cohort extract; - minor changes; - wip; - get genotypes working; - clarify sample -> sample_id; - add mode; - mode is mandatory, uses location instead of position; - add query mode; - fix contig name; - forgot this file; - fix location bug; - Ingest wip to be added to other var db code (#6582); - ingest arrays refactored; - add filter, change sample to sample_id; - fix bugs; - wip; - major refactor splitting ingest for arrays from exomes/genomes; - create output files for actual raw array tables; - change site_name to rsid; - change GT encoding, change output file names and remove dir structure, get probe metadata; - fix prefix; - update GT encoding; - remove filter, rename columns, allow sample id as input; - array cohort extract (#6666); - new bit-compression (#6691); - refactored to common ProbeInfo, support compressed data on ingest, support local CSV probe info; - update exome ingest; - minor mods; - change structure, add compressed option to ingest; - add imputed tsv creator and refactor; - add fields for uncompressed imputed data; - Adding a test and small features to var store branch (#6761); - upgraded to new google bigquery libraries and storage api v1; used storage api for probe info; synced encoded gt definitions; - added support for probe_id ranges (#6806); - ah - use new GT encoding (#6822); - Tool for arrays QC metrics calculations (#6812); - ah update array extract tool (#6827); - fix enum (#6834); - updating ArrayCalculateMetrics for new genotype counts table (#6843); - Ability to filter variants based on QC in ArrayExtractCohort (#6844); - switch from ExcessHet back to HWE (#6848); - resolved rebase conflicts; - initial cohort extract; - minor changes; - wip; - get genotypes working; - clarify sample -> sample_id; - add mode; - mode is mandatory, uses location instead of position; - add query mode; - fix contig name; - fix location bug;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:6871,update,update,6871,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['update'],['update']
Deployability,"g ~3.5k training), and 3) the Mills training/truth VCF (yielding ~500 training). Incidentally, VariantRecalibrator SNP and INDEL runs both fail to converge on these small training sets without the #7709 fix, but do converge with it. I still need to check if enough multiallelics are included here; if not, I'll choose a different snippet. EDITEDIT: Now using gs://broad-gotc-test-storage/joint_genotyping/exome/scientific/truth/master/gather_vcfs_high_memory/small_callset_low_threshold.vcf.gz provided by @ldgauthier, which does have AS annotations.; ; We'll use expected outputs here as inputs to downstream steps, but rather than provide the expected outputs directly, we'll create copies of them and provide those as inputs. This will make the tests better encapsulated. However, it should be relatively easy to update the whole chain of test files, should one choose to do so. EDIT: Let's just provide the expected outputs directly. So it'll be even easier to update the whole chain---just set the flags for all three tools to overwrite the expected results.; ; We test the Cartesian product of the following options: 1) non-allele-specific vs. allele-specific, 2) SNP vs. indel vs. both, and 3) positive vs. positive-unlabeled. Downstream, we'll further subset to a subset of these options, since training/scoring functionality shouldn't really change across some of them.; ; I'm currently just using call outs to system commands to diff and h5diff the VCFs and HDF5s, respectively. I think the latter command should be available in the GATK Conda environment. This will be a bit awkward, in the sense that the tests for this tool will require the Conda environment, but the tool itself will not. But I think this is probably preferable to writing test code to compare HDF5s, minimal though that might be, since the schema might change in the future.; - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs. Could perhaps expand on the `resources` parameter once the required labels ar",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948059:2108,update,update,2108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948059,1,['update'],['update']
Deployability,g.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2735); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:522); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:150); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:82); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [42925293-731b-47bb-8e5e-7f375d9c3490] entered state [ERROR] while waiting for [DONE]. ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-264212007:6744,deploy,deploy,6744,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-264212007,6,['deploy'],['deploy']
Deployability,"g.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289). My command looks like this:; ~/bioinformatics/programs/GATK/gatk-4.0.3.0/gatk --java-options ""-Xmx4g"" Mutect2 -R /Users/loeblabm11/bioinformatics/reference/human/hg19/hg19.fa -I 20171027_BN31_python.dcs.filt.no_overlap.bam -tumor BN31 -O 20171027_BN31_python.dcs.MuTect2.vcf -bamout 20171027_BN31_python.dcs.MuTect2.bam --max-reads-per-alignment-start 0 --max-population-af 1 --disable-tool-default-read-filters. and I'm running on MacOSX Sierra (10.12.6). java -version returns ; java version ""1.8.0_151""; Java(TM) SE Runtime Environment (build 1.8.0_151-b12); Java HotSpot(TM) 64-Bit Server VM (build 25.151-b12, mixed mode). The input file is position-sorted output from Duplex Sequencing pipelines, and has been through IndelRealigner (from GATK 3.7), and ClipOverlappingReads from FgBio. It has been indexed. . I can put together a full bug report, complete with my input file, if necessary; I just want an idea of what might be happening. . Brendan. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/11790/error-in-mutect2/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4665:7199,pipeline,pipelines,7199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4665,1,['pipeline'],['pipelines']
Deployability,"g.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:255); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66); at org.broadinstitute.hellbender.Main.main(Main.java:81); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/01/21 14:55:33 INFO ShutdownHookManager: Shutdown hook called; ```. Attached is a small BAM file that I used to reproduce the error (If memory serves, I've seen this issue on other BAM files as well):. [NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip](https://github.com/broadinstitute/gatk/files/101575/NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip). (This issue may be related to one posted here: https://github.com/broadinstitute/gatk/issues/1417.). Here is some information on what I installed:. ```; echo ""Installing Java""; sudo add-apt-repository -y ppa:webupd8team/java; sudo apt-get -qq update; echo debconf shared/accepted-oracle-license-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1444:3006,deploy,deploy,3006,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1444,1,['deploy'],['deploy']
Deployability,g/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/selectVariantsInfoField.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/test.dup.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/tetra-diploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/tetraploid-multisample-sac.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/tetraploid-multisample.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample2DiscordanceConcordance.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/UpdateVCFSequenceDictionary/exampleBAM.sam; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/UpdateVCFSequenceDictionary/exampleFASTA.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/expected.soap_gatk_annotated.AMD.table; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/multiallelic_gt.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/multiallelic.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/soap_gatk_annotated.noChr_lines.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/soap_gatk_annotated.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/vcfexample2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/vcfexample.noSamples.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:65684,Update,UpdateVCFSequenceDictionary,65684,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['Update'],['UpdateVCFSequenceDictionary']
Deployability,gCNV in the CASE mode now fills in all hidden DenoisingModelConfig and CopyNumberCallingConfig arguments from the input model configuration. . This addresses issue #6994,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7464:126,configurat,configuration,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7464,1,['configurat'],['configuration']
Deployability,"gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); GATK CalibrateDragstrModel. ### Affected version(s); - [x] Latest public release version [4.3.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; When running CalibrateDragstrModel in parallel mode, the supplied reference isn't detected correctly causing the following error stack trace:. ```bash; Using GATK jar /usr/local/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx72g -jar /usr/local/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar CalibrateDragstrModel --input input.cram --output input.txt --reference hg38.fa --str-table-path hg38.zip --threads 12 --intervals fasta_bed.bed --tmp-dir .; 10:24:21.117 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/local/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 10:24:21.289 INFO CalibrateDragstrModel - --------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8139:1291,release,release,1291,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8139,1,['release'],['release']
Deployability,"gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6772:1306,release,release,1306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6772,8,['release'],['release']
Deployability,"gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5719:1306,release,release,1306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5719,1,['release'],['release']
Deployability,gatk-launch complains when running a spark tool if installSpark has been run but installDist hasn't,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1314:51,install,installSpark,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1314,2,['install'],"['installDist', 'installSpark']"
Deployability,"gatk-package-4.4.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/athchu/bin/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar --help; Error: Invalid or corrupt jarfile /home/athchu/bin/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; `; Next, I moved on to git clone the gatk repository, trying to build gatk. Again, I stay in the java ""1.7.0_91"" gatk env that I already created. But I got this error msg this time:; `; ./gradlew localJar; Gradle 7.5.1 requires Java 1.8 or later to run. You are currently using Java 1.7.; `; When I switch back to the server default java (1.8.0_292-b10), i got another error msg.; `; java -version; openjdk version ""1.8.0_292""; OpenJDK Runtime Environment (build 1.8.0_292-b10); OpenJDK 64-Bit Server VM (build 25.292-b10, mixed mode). ./gradlew localJar. > Configure project :; Warning: using Java 1.8 but only Java 17 has been tested. FAILURE: Build failed with an exception. * Where:; Build file '/home/athchu/bin/gatk/build.gradle' line: 141. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > A Java 17 compatible (Java 17 or later) version is required to build GATK, but 1.8 was found. See https://github.com/broadinstitute/gatk#building for information on how to build GATK. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org; `; So to sum up, my issues are :; 1) downloaded gatk-4.4.0.0 but it contained invalid jar file and i cannot run GATK; 2) following the github instruction, I cannot build gatk under java1.7.0_91, because it is incompatible to GRADLE7.5.1.; 3) built gatk using java 1.8.0_292 failed because gatk is java 17 compatible. Would you please advise on what I shall do? The docker installed in my sever doesn't not work....",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8432:2272,install,installed,2272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8432,1,['install'],['installed']
Deployability,gatk-protected should tag releases using annotated tags rather than unannotated tags.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2953:26,release,releases,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2953,1,['release'],['releases']
Deployability,gatkcondaenv.yml ; - uses python 3.6.10. how to update the python version?. I did try with:; conda update --all. but it does not work. . Thankyou,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8127:48,update,update,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8127,2,['update'],['update']
Deployability,ge of ServiceAccount from CreateVat related WDLs (#7974); - WDL to extract Avro files for Hail import [VS-579] (#7981); - Removed usage of service account from WDLs (#7985); - Document steps for GVS cleanup for base use case [VS-586] (#7989); - Change backticks to single quotes in several error messages - causing shell to attempt to execute. (#7995); - VS-598 - Minor update to AoU Documentation. (#7994); - Allow for incremental addition of data to alt_allele [VS-52] (#7993); - Minor AoU Documentation Update (#7999); - Batch population of alt_allele table from vet_ tables [VS-265] (#7998); - Change drop_state to NONE for Ingest/Extract [VS-607] (#8000); - python -> python3 (#8001); - Generate Hail import/export script [VS-605] (#8002); - clearer error when values are missing (#7939); - Ah [VS-565] output intervals and sample list (#8010); - make CreateAltAlleleTable task volatile (#8011); - Restore withdrawn [VS-581] (#8006); - Km gvs add storage cost and cleanup doc (#8012); - Updating documentation to reflect the changed outputs [VS-565] (#8014); - File of callset samples -> samples marked as 'withdrawn' in GVS [VS-436] (#8009); - fix quota guidelines for CPUs (#8016); - Add in ability to tweak sample-every-Nth-variant parameter for SNP model creation (#8019); - add initial notebook copy pasta (#8008); - add sample_table_timestamp to GetNumSamplesLoaded (#8022); - Batched Avro export [VS-630] (#8020); - Updating references to old GATK for VS-620 (#8023); - VS-517 Use standard version of GetBQTableLastModifiedDatetime in GvsValidateVat (#8024); - Fix bug in GvsWithdrawSamples.wdl (#8026); - Ah 617 exposing the drop_state parameter to the GvsJointVariantCalling wdl used for beta (and internal customer) (#8032); - Expose maximum-training-variants VQSR parameter [VS-634] (#8029); - Callset statistics [VS-560] (#8018); - Check for withdrawn before exporting to AVRO files [VS-646] (#8039); - Small updates to GVS Integration WDL [VS-618] (#8042); - Rework Hail script gener,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:27558,Update,Update,27558,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['Update'],['Update']
Deployability,"ge tested against the workflow (#8062); - VS-637 Address a couple of issues in SampleLoadStatus handling in GVSImportGenomes. (#8052); - Revert Alpinizing of apt dependent task [VS-688] (#8065); - Fix missing vat schema JSONs [VS-699] (#8072); - Fix integration expectations for fixed AD [VS-689] (#8066); - VS-698 Remove unnecessary columns from Call set statistics (#8073); - Fix Dockerfile nits that break 20.10.21 (#8078); - Nirvana 3.18.1 Docker images support [VS-661] (#8082); - Add option to not prepare __REF_DATA or __SAMPLES tables to Prepare [VS-697] (#8079); - ""build-base"" Docker image for faster variantstore image builds [VS-712] (#8085); - GVS / Hail VDS integration test [VS-639] (#8086); - Remove AI/AN from VDS docs [VS-726] (#8096); - Add flag for cost_observability table writing to support sub-cohort use case [VS-521] (#8093); - Document STS delivery process for VDS [VS-727] (#8101); - delete obsolete callset_QC directory and its contents [VS-318] (#8108); - doc link typo and add check for control samples in AVRO export (#8110); - Add defaults for scatter_count in GvsExtractCohortFromSampleNames [VS-496] (#8109); - Escape table names properly in ValidateVat WDL (#8116); - Vs 741 fix indefinite freeze in split intervals task when using exome data (#8113); - VAT Readme updates (#8090); - WDL and python scripts to use the VDS in the VAT (#8077); - VS-757 - Use JASIX to make sub-jsons of annotated output of Nirvana (#8133); - add note about permissions for P&S workflow to work (#8135); - VS-759 (and VS-760) (#8137); - VS-765. Scatter the RemoveDuplicates task. (#8144); - update delivery docs based on latest VDS delivery run [VS-770] (#8150); - Add monitoring to index vcf (#8151); - Make some noise when VDS validation succeeds (#8155); - Handle empty genes annotation file. (#8153); - Add escapes for otherwise problematic dataset / table names. (#8162); - New WDL to create VAT tsvs from previously generated BigQuery table. (#8165); - Treat withdrawn samples in ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:30397,integrat,integration,30397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,"['integrat', 'update']","['integration', 'updates']"
Deployability,"genomics/data/Łuksza2022Nature` and used `./` as tmp directory. It also failed:; ```; cd /data/xieduo/Immun_genomics/data/Łuksza2022Nature; /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx8G -Djava.io.tmpdir=./"" BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; Using GATK jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -Djava.io.tmpdir=./ -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; 13:46:24.742 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:46:24.761 WARN NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (No such file or directory); 13:46:24.764 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-packa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:12252,pipeline,pipeline,12252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,genomicsdb-0.5.0-proto-3.0.0-beta-1.jar is released to maven central,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293718157:43,release,released,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293718157,1,['release'],['released']
Deployability,ger.scala:1029); 	at org.apache.spark.storage.BlockManager.putIterator(BlockManager.scala:792); 	at org.apache.spark.storage.BlockManager.putSingle(BlockManager.scala:1350); 	at org.apache.spark.broadcast.TorrentBroadcast.writeBlocks(TorrentBroadcast.scala:122); 	at org.apache.spark.broadcast.TorrentBroadcast.<init>(TorrentBroadcast.scala:88); 	at org.apache.spark.broadcast.TorrentBroadcastFactory.newBroadcast(TorrentBroadcastFactory.scala:34); 	at org.apache.spark.broadcast.BroadcastManager.newBroadcast(BroadcastManager.scala:56); 	at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1488); 	at org.apache.spark.api.java.JavaSparkContext.broadcast(JavaSparkContext.scala:650); 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.processAssemblyRegions(HaplotypeCallerSpark.java:191); 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.callVariantsWithHaplotypeCallerAndWriteOutput(HaplotypeCallerSpark.java:316); 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.runTool(ReadsPipelineSpark.java:224); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:148); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:189); 	at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSparkIntegrationTest.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5680:6737,pipeline,pipelines,6737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680,1,['pipeline'],['pipelines']
Deployability,gh/broadinstitute/gatk/pull/4068/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9tZXRyaWNzL1F1YWxpdHlZaWVsZE1ldHJpY3NBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <100%> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...dinstitute/hellbender/tools/spark/PileupSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4068/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QaWxldXBTcGFyay5qYXZh) | `98.148% <100%> (ø)` | `15 <0> (ø)` | :arrow_down: |; | [...lines/metrics/InsertSizeMetricsCollectorSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4068/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9JbnNlcnRTaXplTWV0cmljc0NvbGxlY3RvclNwYXJrLmphdmE=) | `86.364% <100%> (ø)` | `7 <1> (ø)` | :arrow_down: |; | [...ons/MetricAccumulationLevelArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4068/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvTWV0cmljQWNjdW11bGF0aW9uTGV2ZWxBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <100%> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...pipelines/metrics/CollectMultipleMetricsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4068/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0TXVsdGlwbGVNZXRyaWNzU3BhcmsuamF2YQ==) | `92.593% <100%> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...s/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4068/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0QmFzZURpc3RyaWJ1dGlvbkJ5Q3ljbGVTcGFyay5qYXZh) | `87.037% <100%> (ø)` | `9 <0> (ø)` | :arrow_down: |; | ... and [110 more](https://codecov.io/gh/broadinstitute/gatk/pull/4068/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4068#issuecomment-355848563:3505,pipeline,pipelines,3505,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4068#issuecomment-355848563,1,['pipeline'],['pipelines']
Deployability,"gistering block manager xx.xx.xx.xx:42081 with 366.3 MB RAM, BlockManagerId(driver, xx.xx.xx.xx, 42081, None); 18/04/24 17:39:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/0 is now RUNNING; 18/04/24 17:39:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/1 is now RUNNING; 18/04/24 17:39:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/2 is now RUNNING; 18/04/24 17:39:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, xx.xx.xx.xx, 42081, None); 18/04/24 17:39:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, xx.xx.xx.xx, 42081, None); 18/04/24 17:39:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/6 is now RUNNING; 18/04/24 17:39:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/4 is now RUNNING; 18/04/24 17:39:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/3 is now RUNNING; 18/04/24 17:39:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/5 is now RUNNING; 18/04/24 17:39:22 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0; 18/04/24 17:39:22 INFO GoogleHadoopFileSystemBase: GHFS version: 1.6.3-hadoop2; 18/04/24 17:39:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 276.0 KB, free 366.0 MB); 00:08 DEBUG: [kryo] Write: SerializableConfiguration; 18/04/24 17:39:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.1 KB, free 366.0 MB); 18/04/24 17:39:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.xx:42081 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:39:27 INFO SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:113; 18/04/24 17:39:27 INFO FileInputFormat: Total input p",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:12936,update,updated,12936,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,8,['update'],['updated']
Deployability,"gments` optionally takes denoised copy ratio and/or allelic counts, `PlotModeledSegments` outputs only the corresponding plots appropriately.; - I added a dependency on the R package `data.table` to slightly speed up the reading of input files.; - Setting `pch="".""` also sped up the generation of scatter plots.; - Plotting now takes a couple of minutes, most of which is I/O (#3554).; - AAF (rather than MAF) is now plotted for allele fraction (#2957). Other:; - I've introduced a `LocatableCollection` class to unify how allelic counts, copy ratios, and segments are stored and read/written from/to TSV (#2836). Intervals are always output in lexicographical order for now, to be consistent with the old coverage collection (#2951). Once @asmirnov239's `CollectReadCounts` is in, we can change everything over to ordering determined by the sequence dictionary.; - Column headers and log2 copy ratio output have been standardized throughout (#2886).; - [x] I've also introduced a `NamedSampleFile` abstract class to tag files that have `#SAMPLE_NAME=...` as the first comment line. For `CollectAllelicCounts`, this simply uses code borrowed from `GetSampleName`. We should unify the reading and storing of sample names at some point (#2910).; - [x] We will need to replace `SimpleReadCountCollection` (which currently serves as the interface between the old coverage collection files and the new code) with one of these subclasses when `CollectReadCounts` is in. We can also change `NamedSampleFile` depending on what he's implemented.; - [x] We should eventually write proper SAM headers with useful tags to all TSV and HDF5 files generated by our tools that represent annotated intervals that can be associated with a single sample. Documentation:; - [x] I need to update class javadoc and example invocations throughout. The initial PR will already be quite massive, so I'll leave this until later. Perhaps @sooheelee might want to be involved?; - [ ] I will update the white paper at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:10751,update,update,10751,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,4,['update'],['update']
Deployability,"google-cloud-java: update to the official 0.59.0 release, and move off of our custom fork",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5135:19,update,update,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5135,2,"['release', 'update']","['release', 'update']"
Deployability,googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://stor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084:1557,integrat,integration,1557,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084,1,['integrat'],['integration']
Deployability,gradle people are also saying that you should upgrade to the latest version of gradle: https://github.com/gradle/gradle/issues/7973,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446254485:46,upgrade,upgrade,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446254485,1,['upgrade'],['upgrade']
Deployability,"gradle uploadArchives will perform a maven release (currently a snapshot release). Unfortunately the maven plugin has an ""install"" task which installs to the local repo, so it's now necessary to specify `installApp` or `installDist` instead of just `gradle install`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/482:43,release,release,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/482,7,"['install', 'release']","['install', 'installApp', 'installDist', 'installs', 'release']"
Deployability,"gradlew install script failed ungracefully with ""disk quota exceeded""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:8,install,install,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,1,['install'],['install']
Deployability,gram Files\Java\jdk1.8.0_121\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\rt.jar;C:\project\push\target\classes;E:\repository\org\springframework\boot\spring-boot-starter-jdbc\2.3.0.RELEASE\spring-boot-starter-jdbc-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter\2.3.0.RELEASE\spring-boot-starter-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot\2.3.0.RELEASE\spring-boot-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-autoconfigure\2.3.0.RELEASE\spring-boot-autoconfigure-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-logging\2.3.0.RELEASE\spring-boot-starter-logging-2.3.0.RELEASE.jar;E:\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\repository\org\apache\logging\log4j\log4j-to-slf4j\2.13.2\log4j-to-slf4j-2.13.2.jar;E:\repository\org\apache\logging\log4j\log4j-api\2.13.2\log4j-api-2.13.2.jar;E:\repository\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;E:\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;E:\repository\org\yaml\snakeyaml\1.26\snakeyaml-1.26.jar;E:\repository\com\zaxxer\HikariCP\3.4.5\HikariCP-3.4.5.jar;E:\repository\org\springframework\spring-jdbc\5.2.6.RELEASE\spring-jdbc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-beans\5.2.6.RELEASE\spring-beans-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-tx\5.2.6.RELEASE\spring-tx-5.2.6.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-web\2.3.0.RELEASE\spring-boot-starter-web-2.3.0,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:2341,RELEASE,RELEASE,2341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,gram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: provided start is negative: -1; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:53579,deploy,deploy,53579,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['deploy'],['deploy']
Deployability,"gram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(I",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:41389,deploy,deploy,41389,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,['deploy'],['deploy']
Deployability,"gram.doWork(SparkCommandLineProgram.java:31); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-45f7a9f3-b94f-4040-bf32-0dbfe44f8f68; 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-70db8953-5dec-4eb8-910d-f0abd7e1c42b. real 41m12.118s; user 83m41.069s; sys 10m15.403s. #### Steps to reproduce; atk --java-options ""-Djava.io.tmpdir=tmp"" StructuralVariationDiscoveryPipelineSpark \; -R $REF \; --aligner-index-image GRCh38_full_analysis_set_plus_decoy_hla.fa.img \; --kmers-to-ignore GRCh38_ignored_km",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942:4540,deploy,deploy,4540,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942,1,['deploy'],['deploy']
Deployability,gram.doWork(SparkCommandLineProgram.java:31); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Stream closed; at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:829); at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:889); at java.io.DataInputStream.read(DataInputStream.java:149); at org.disq_bio.disq.impl.file.HadoopFileSystemWrapper$SeekableHadoopStream.read(HadoopFileSystemWrapper.java:232); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(BufferedInputStream.java:345); at htsjdk.samtools.seekablestream.SeekableBufferedStream.read(SeekableBufferedStream.java:133); at h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:4419,deploy,deploy,4419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,2,['deploy'],['deploy']
Deployability,"gram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); 	at org.broadinstitute.hellbender.Main.main(Main.java:221); ```; and; ```; java.lang.IllegalStateException: Allele in genotype G* not in the variant context [C*, T]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.tools.exome.orientationbiasvariantfilter.OrientationBiasFilterer.annotateVariantContextsWithFilterResults(OrientationBiasFilterer.java:216); 	at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalSuccess(FilterByOrientationBias.java:211); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:840); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); ```. I tested using `gatk-package-4.beta.1-local.jar` and pre-release alpha version `gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT/gatk-package-4.alpha.2-1134-ga9d9d91-SNAPSHOT-local.jar`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3291:3587,release,release,3587,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3291,1,['release'],['release']
Deployability,"gram.instanceMainPostParseArgs(CommandLineProgram.java:171); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.NoSuchFileException: /user/yaron/output.bam.parts/_SUCCESS: Unable to find _SUCCESS file; at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:53); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:152); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:250); ... 18 more; ```; However, I can find that _SUCCESS file exists in output.bam.parts. Could someone tell me what may be the cause? Thanks!; ```; $ hdfs dfs -ls output.bam.parts; Found 3 items; -rw-r--r-- 3 yaron yaron 0 2017-06-08 09:14 output.bam.parts/_SUCCESS; -rw-r--r-- 3 yaron yaron 62019 2017-06-08 09:14 output.bam.parts/part-r-00000.bam; -rw-r--r-- 3 yaron yaron 16 2017-06-08 09:14 output.bam.parts/part-r-00000.bam.splitting-bai; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:6374,deploy,deploy,6374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['deploy'],['deploy']
Deployability,gram.instanceMainPostParseArgs(CommandLineProgram.java:171); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:743); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)Caused by: java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2722); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1565); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2227); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2151); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2009); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1533); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:420); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:298); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145); at java.util.conc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:10160,deploy,deploy,10160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['deploy'],['deploy']
Deployability,gram.instanceMainPostParseArgs(CommandLineProgram.java:176); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:233); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.appl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:5933,deploy,deploy,5933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,1,['deploy'],['deploy']
Deployability,gram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:153); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:277); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.GATKException: Erred when inferring breakpoint location and event type from chimeric alignment:; asm010450:tig00000 1_189_chrUn_JTFH01000312v1_decoy:663-851_-_189M512H_60_8_149_O 153_701_chrUn_JTFH01000312v1_decoy:1-549_+_152S549M_60_0_549_O; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignmentsSAMSpark.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliter,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:11620,deploy,deploy,11620,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['deploy'],['deploy']
Deployability,gram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@3e0a9b1d: java.net.BindException: Address already in use; java.net.BindException: Address already in use; at sun.nio.ch.Net.bind0(Native Method); at sun.nio.ch.Net.bind(Net.java:433); at sun.nio.ch.Net.bind(Net.java:425); at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223); at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74); at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:321); at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80); at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:236); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.eclipse.jetty.server.Server.doStart(Server.java:366); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.apach,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:7576,deploy,deploy,7576,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725,1,['deploy'],['deploy']
Deployability,gram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:43801,deploy,deploy,43801,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['deploy'],['deploy']
Deployability,gram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:44547,deploy,deploy,44547,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['deploy'],['deploy']
Deployability,"gram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:17631,deploy,deploy,17631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['deploy'],['deploy']
Deployability,"gram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /opt/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx56g -Djava.io.tmpdir=./tmp -jar /opt/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar GenotypeGVCFs -R ../../01.ref/MS/genome.fasta -V gendb://genomeDB.Chr23 -all-sites -O Chr23.raw.vcf.gz. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [ ] Latest public release version [version?] V4.2.0.0; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._; There are no results generated.; ![image](https://github.com/broadinstitute/gatk/assets/103233242/2c505328-c0a0-473a-bd64-63b2137e0f06). #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. 1:singularity exec ~/biosoft/resequence/Reseq_genek.sif gatk --java-options ""-Xmx48g -Djava.io.tmpdir=./tmp"" HaplotypeCaller -R ../../01.ref/MS/genome.fasta -I ../../02.mapping/MS/F10.sort.markdup.bam -L Chr01 -ERC GVCF -O F10/F10.Chr01.g.vcf.gz ; 2:singularity exec ~/biosoft/resequence/Reseq_genek.sif gatk --java-options ""-Xmx56g -Djava.io.tmpdir=./tmp -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" GenomicsDBImport --sample-name-map gvcf",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8415:6453,release,release,6453,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8415,1,['release'],['release']
Deployability,"great, thanks for the update",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-437071849:22,update,update,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-437071849,1,['update'],['update']
Deployability,"gs://depmapomicsdata/1000g_pon.hg38.vcf.gz; 20:59:55.629 INFO Mutect2 - Shutting down engine; [October 4, 2021 8:59:55 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=876609536; code: 403; message: pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket.; reason: forbidden; location: null; retryable: false; com.google.cloud.storage.StorageException: pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:406); at com.google.cloud.storage.StorageImpl$4.call(StorageImpl.java:217); ...; ```. This happens while it runs the command:. ```; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx15500m\ ; -jar /root/gatk.jar Mutect2 -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta\ ; -I gs://cclebams/hg38_wes/CDS-00rz9N.hg38.bam -tumor BC1_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE --germline-resource gs://gcp-public-data--gnomad/release/3.0/vcf/genomes/gnomad.genomes.r3.0.sites.vcf.bgz\ ; -pon gs://gatk-best-practices/somatic-hg38/1000g_pon.hg38.vcf.gz\ ; -L gs://fc-secure-d2a2d895-a7af-4117-bdc7-652d7d268324/7a157f4a-7d93-4a3e-aaf4-c41833463f5a/Mutect2/3be8ce8e-1075-4063-bc43-6f61e386c3f5/call-SplitIntervals/cacheCopy/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list\ ; -O output.vcf.gz --f1r2-tar-gz f1r2.tar.gz --gcs-project-for-requester-pays broad-firecloud-ccle; ```. But I gave read (both regular and legacy) access to gs://cclebams (this is a requester pays bucket). This was done on GATK 4.2.2 docker. Best,",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7492:1992,release,release,1992,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7492,1,['release'],['release']
Deployability,"gumentParser.java:384); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.parseArgs(CommandLineProgram.java:217); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:191); > 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); > 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); > 	at org.broadinstitute.hellbender.Main.main(Main.java:239); > 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); > 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); > 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); > 	at java.lang.reflect.Method.invoke(Method.java:498); > 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:733); > 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177); > 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202); > 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116); > 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala). Actually, I just re-checked and i'm not sure my solution `--conf 'spark.submit.deployMode=cluster'` works well. I'm currently testing it. My current command is:; > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input hdfs://spark01:7222/user/axverdier/data/710-PE-G1.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_CountReadsSpark --sparkRunner SPARK --sparkMaster yarn --conf 'spark.submit.deployMode=cluster' --javaOptions -Dmapr.library.flatclass. I need the `-Dmapr.library.flatclass` because our spark is using a mapr filesystem and I was getting error about JNI library linkage.; However, the paths of files are given with `hdfs://spark01:7222` because I get a protocol error when I set `maprfs://` instead. Don't bother with it right now, I'm going to open another issue about it :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350038452:1642,deploy,deploy,1642,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350038452,4,['deploy'],"['deploy', 'deployMode']"
Deployability,"gumentParser.parseArguments(CommandLineArgumentParser.java:384); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.parseArgs(CommandLineProgram.java:217); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:191); > 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); > 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); > 	at org.broadinstitute.hellbender.Main.main(Main.java:239); > 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); > 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); > 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); > 	at java.lang.reflect.Method.invoke(Method.java:498); > 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:733); > 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177); > 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202); > 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116); > 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala). Actually, I just re-checked and i'm not sure my solution `--conf 'spark.submit.deployMode=cluster'` works well. I'm currently testing it. My current command is:; > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input hdfs://spark01:7222/user/axverdier/data/710-PE-G1.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_CountReadsSpark --sparkRunner SPARK --sparkMaster yarn --conf 'spark.submit.deployMode=cluster' --javaOptions -Dmapr.library.flatclass. I need the `-Dmapr.library.flatclass` because our spark is using a mapr filesystem and I was getting error about JNI library linkage.; However, the paths of files are given with `hdfs://spark01:7222` because I get a protocol error when I set `maprfs://` instead. Don't bother with it right now, I'm",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350038452:1568,deploy,deploy,1568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350038452,1,['deploy'],['deploy']
Deployability,"guments:; ['/opt/miniconda/envs/gatk/bin/python', '-m', 'pip', 'install', '-U', '-r', '/soft/gatk-4.4.0.0/condaenv.i9brvcrk.requirements.txt', '--exists-action=b']; Pip subprocess output:. Pip subprocess error:; /opt/miniconda/envs/gatk/bin/python: No module named pip. failed. CondaEnvException: Pip failed. ```; ---; It can be fixed with setting classic colver:; ```; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda --version; conda 23.10.0; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda config --set solver classic; root@d12ac7710afc:/soft/gatk-4.4.0.0# ""$CONDA"" env create -n gatk -f ""$SOFT/gatk-${GATK_VERSION}/gatkcondaenv.yml""; ...; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Installing pip dependencies: \ Ran pip subprocess with arguments:; ['/opt/miniconda/envs/gatk/bin/python', '-m', 'pip', 'install', '-U', '-r', '/soft/gatk-4.4.0.0/condaenv.rtsyg5rl.requirements.txt', '--exists-action=b']; Pip subprocess output:; Processing ./gatkPythonPackageArchive.zip; Building wheels for collected packages: gatkpythonpackages; Building wheel for gatkpythonpackages (setup.py): started; Building wheel for gatkpythonpackages (setup.py): finished with status 'done'; Created wheel for gatkpythonpackages: filename=gatkpythonpackages-0.1-py3-none-any.whl size=117686 sha256=f2165b43e412c95ff9a788022d355279e5434032fb8c9cf82fbd71779acd1a76; Stored in directory: /tmp/pip-ephem-wheel-cache-5a9zdytx/wheels/06/f7/e1/87cb7da6f705baa602256a58c9514b47dc313aade8809a01da; Successfully built gatkpythonpackages; Installing collected packages: gatkpythonpackages; Successfully installed gatkpythonpackages-0.1. done; #; # To activate this environment, use; #; # $ conda activate gatk; #; # To deactivate an active environment, use; #; # $ conda deactivate. ```. I see some changed in master (probably fixing this issue too), but no description: https://github.com/broadinstitute/gatk/pull/8610/files#diff-5c3c54d49d09fd7ab0957b7c3185e22c6161e225b9e3ed65e72716fa2a635a96",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8618:3640,Install,Installing,3640,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8618,2,"['Install', 'install']","['Installing', 'installed']"
Deployability,"h/supportingMultiA.vcf; > ; > which outputs:; > INFO field at 1:768589 .. INFO tag [AC=1] expected different number of; > values (expected 2, found 1),INFO tag [AF=0.00047] expected different; > number of values (expected 2, found 1); > Notes; > ; > Currently, all the validation modes call out to HTSJDK. Do we want to put; > the new functionality there as well?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1053. ---. @ldgauthier commented on [Fri Jul 17 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122308040). Today I learned that the way we currently build GATK, you can't point to a local htsjdk jar anymore, so this task will be two-fold:; 1) Make a PR to htsjdk with a new function in the VariantContext class for validateInfoFieldCounts(VCFInfoHeaderLine headerLine) or similar; add a test to VariantContextUnitTest.java; 2) After change 1) is merged, update ValidateVariants accordingly to use the new function and add a test to its integration tests. ---. @vdauwera commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222213763). @ldgauthier is this still a thing? (in the sense of not having been addressed in htsjdk). ---. @ldgauthier commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222214083). Still a thing. No work has been done here AFAIK. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-260465013). This seems like fairly low-hanging fruit -- @ronlevine . ---. @ronlevine commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262613152). @ldgauthier Shouldn't a locus without genotypes bypass `AC` validation, given it's defined as: `Allele count in genotypes, for each ALT allele, in the same order as listed`?. ---. @ldgauthier commented on [Wed No",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:4514,update,update,4514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,2,"['integrat', 'update']","['integration', 'update']"
Deployability,"haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...ark/sv/CallVariantsFromAlignedContigsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9DYWxsVmFyaWFudHNGcm9tQWxpZ25lZENvbnRpZ3NTQU1TcGFyay5qYXZh) | `0% <0%> (-26.087%)` | `0% <0%> (-5%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `48.837% <0%> (-24.774%)` | `27% <0%> (-9%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (ø)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | ... and [27 more](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=footer). Last update [5d2f859...7a651b7](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-287020306:4406,update,update,4406,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-287020306,2,['update'],['update']
Deployability,hail updates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8762:5,update,updates,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8762,1,['update'],['updates']
Deployability,hardcode in less partitions so that we can test where things are slowing down/breaking in the VAT pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8780:98,pipeline,pipeline,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8780,1,['pipeline'],['pipeline']
Deployability,hardening standard quickstart pipeline against errors when a location is specified,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8047:30,pipeline,pipeline,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8047,1,['pipeline'],['pipeline']
Deployability,"hbmRMaW5lUHJvZ3JhbS5qYXZh) | `95.714% <0%> (+2.456%)` | `38% <0%> (+9%)` | :arrow_up: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `87.156% <0%> (+2.945%)` | `66% <0%> (+13%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `70.47% <0%> (+4.154%)` | `46% <0%> (+18%)` | :arrow_up: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2495?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2495?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2495?src=pr&el=footer). Last update [88c181d...298212c](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2495#issuecomment-287912625:5269,update,update,5269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2495#issuecomment-287912625,2,['update'],['update']
Deployability,"he RDD:. ``` Java; JavaRDD<Variant> rddParallelVariants =; variantsSparkSource.getParallelVariants(output);. System.out.println( rddParallelVariants.first().toString() );; ```. And after re-compiling GATK and running `PrintVCFSpark`, I got the following to print the first element of the RDD:. ``` Bash; $ ./gatk-launch PrintVCFSpark --input test.vcf --output test.vcf. Running:; /home/pgrosu/me/hellbender_broad_institute/gatk/build/install/gatk/bin/gatk PrintVCFSpark --input test.vcf --output test.vcf; [February 14, 2016 7:04:16 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVCFSpark --output test.vcf --input test.vcf --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false; [February 14, 2016 7:04:16 PM EST] Executing as pgrosu on Linux 2.6.32-358.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_05-b13; Version: Version:4.alpha-86-g154d0a8-SNAPSHOT JdkDeflater; 19:04:16.098 INFO PrintVCFSpark - Initializing engine; 19:04:16.100 INFO PrintVCFSpark - Done initializing engine; 2016-02-14 19:04:17 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 2016-02-14 19:04:19 WARN MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.; MinimalVariant -- interval(1:737406-737411), snp(false), indel(true); 19:04:24.266 INFO PrintVCFSpark - Shutting down engine; [February 14, 2016 7:04:24 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVCFSpark done. Elapsed time: 0.14 minutes.; Runtime.totalMemory()=90177536; ```. This seems to have the ability to load a VCF as a JavaRDD. Let me know if this is what you were looking for, and sorry if I am assuming this solves the problem. Thanks and hope you're keeping warm :); Paul",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1486#issuecomment-184011857:2599,pipeline,pipelines,2599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1486#issuecomment-184011857,1,['pipeline'],['pipelines']
Deployability,"he per-contig coverage histograms (unfiltered bins in blue, bins retained after filtering in red, and negative-binomial fit in green) and a heatmap of per-contig ploidy probabilities. Both the panel (first 20) and case (remaining) samples are shown:. ![prototype-result](https://user-images.githubusercontent.com/11076296/37938642-e9fbd804-312c-11e8-8a6c-02ea4e4fa704.png). Although the prototype model is clearly a good fit to the filtered data, some care in choosing the optimizer and its learning parameters is required to achieve convergence to the correct solution. This is because the problem is inherently multimodal and thus there are many local minima. I found that using AdaMax with a naive strategy of warm restarts (to help kick us out of local minima) worked decently; we can achieve convergence in <10 minutes for 60 samples x 24 contigs x 250 count bins:. ![elbo](https://user-images.githubusercontent.com/11076296/37938658-fc176f12-312c-11e8-89e2-40c68e0f9953.png). I expect that @mbabadi's annealing implementation in the gcnvkernel package will handle the local minima much better. The course of action needed to implement this model should be as follows:. 1) Alter Java code to emit per-contig histograms. Change python code to consume histograms, perform filtering, and fit using the above model (or some variation).; 2) Choose learning parameters appropriate with annealing and check that results are still good.; 3) Update gCNV model to consume the depth emitted by this model properly, if necessary, and rerun evaluations. Other improvements enabled by mappability filtering (as discussed in #4558) or coverage collection can follow this initial model revision. In the meantime, we will continue the first round of evaluations using the old ploidy model, spot checking genotype calls as necessary. This will allow us to tune gCNV parameters (which will hopefully be largely unaffected by any changes to the ploidy model). How does this sound, @ldgauthier @mbabadi @asmirnov239?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271:3460,Update,Update,3460,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271,1,['Update'],['Update']
Deployability,"hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); > 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); > 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); > 	at org.broadinstitute.hellbender.Main.main(Main.java:239); > 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); > 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); > 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); > 	at java.lang.reflect.Method.invoke(Method.java:498); > 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:733); > 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177); > 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202); > 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116); > 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); > Caused by: java.nio.file.ProviderNotFoundException: Provider ""maprfs"" not found; > 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:341); > 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:40); > 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:143); > 	at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:226); > 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); > 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:178); > 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:177); > 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:134); > 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:69); > 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); > 	at org.a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936:3838,deploy,deploy,3838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936,1,['deploy'],['deploy']
Deployability,"help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilter; s false --minimumMappingQuality 20; [16 November 2017 4:51:50 PM] Executing as vlad@spartan.hpc.unimelb.edu.au on Linux 4.13.12-1.el7.elrepo.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_121-b15; Version: 4.beta.5; 16:51:50.648 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:51:50.648 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:51:50.649 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:51:50.649 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:51:50.649 INFO HaplotypeCaller - Deflater: IntelDeflater; 16:51:50.649 INFO HaplotypeCaller - Inflater: IntelInflater; 16:51:50.649 INFO HaplotypeCaller - GCS max retries/reopens: 20; 16:51:50.649 INFO HaplotypeCaller - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 16:51:50.649 INFO HaplotypeCaller - Initializing engine; 16:51:51.056 INFO FeatureManager - Using codec BEDCodec to read file file:///home/vlad/tmp/debug_gatk/bad_87-88.bed; 16:51:51.063 INFO IntervalArgumentCollection - Processing 1 bp from intervals; 16:51:51.068 INFO HaplotypeCaller - Done initializing engine; 16:51:51.075 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 16:51:51.293 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 16:51:51.509 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 16:51:51.762 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3845:7462,patch,patch,7462,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845,1,['patch'],['patch']
Deployability,"her missing rate due to the inaccurate GQ=0. . Directly calling the VCF with HaplotypeCaller without the gVCF intermediate gVCF file calculates the correct GQ score. Freebayes also calculates a correct GQ on these samples.; [rs429358_gq_dp.pdf](https://github.com/broadinstitute/gatk/files/2612419/rs429358_gq_dp.pdf). #### Steps to reproduce. I am seeing this bug for 57 samples of 5000 crams at snp rs429358 but I would expect it is not unique to this site. . Select two crams with a Passed site with:; cram 1. Call with GT='0/0, GQ=0 and DP >40.; cram 2. Call with GT='0/1' or '1/1' and DP>20. . Create vcf with two approaches:. Pipeline 1. HaplotypeCaller-->vcf. module load gatk/4.0.11.0; gatk HaplotypeCaller -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa\; -I gq0_cram.list\; -L chr19:44907684-44909822\; --use-new-qual-calculator\; -O good.vcf.gz. Good GQ scores were also estimated with Freebayes on these samples also. Pipeline 2 HaplotypeCaller --> bvcf--->ImportVCF-->GenotypeVCF-->VCF with 2 samples. gatk HaplotypeCaller -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa\; -I $sample.cram\; --use-new-qual-calculator\; -L chr19:44907684-44909822\; -ERC GVCF\; -O bad.g.vcf.gz. Followed by import and GenotypeVCF. . #### Expected behavior; Pipeline 2 should generate accurate GQ scores that match the GQ in the HaplotypeCaller vcf output of pipeline 1. Instead GQ=0. . This is the output for the 57 GQ=0 samples with pipeline 1 which is accurate. AC=7;AF=0.061;AN=114;BaseQRankSum=-6.147;DP=1846;ExcessHet=3.8592;FS=0.000;InbreedingCoeff=-0.0640;MLEAC=6;MLEAF=0.053;MQ=60.00;MQRankSum=0.000;QD=4.52;ReadPosRankSum=-0.781;SOR=2.833; GT:AD:DP:GQ:PL; 0/0:37,0:37:99:0,111,1236; 0/0:40,0:40:99:0,120,1357; 0/0:34,0:34:99:0,102,1161; 0/0:49,0:49:99:0,147,1673; 0/0:33,0:33:99:0,99,1036; 0/0:48,0:48:99:0,144,1728; 0/0:42,0:42:99:0,126,1410; 0/0:37,0:37:99:0,111,1215; 0/0:39,0:39:99:0,117,1311; 0/0:42,0:42:99:0,126,1419; 0/0:53,0:53:99",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5445:1581,Pipeline,Pipeline,1581,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5445,1,['Pipeline'],['Pipeline']
Deployability,"hes, to enable pointing people to hot fixes for a specific toolset without taking in whatever else is going on in other projects. ---. @droazen commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215757315). Alright, to give an overview of where this stands, we have several options on the table for solving this problem:; 1. Split the GATK into even more repos (a CNV-only repo, a HaplotypeCaller repo) that are versioned separately. GATK release X would then consist of CNV version Y, HaplotypeCaller version Z, gatk-public version P, etc. This is probably the most ""correct"" solution from a software engineering perspective, but might be a nightmare to work with.; 2. Have the ability to release jars with a subset of the tools exposed to the user (eg., CNV-only jars). Geraldine hates this one, and it does seem like a bad idea to have these incomplete jars floating out in the wild.; 3. Everyone develops on separate branches, and merges to master only when everything in a branch is ""release-ready"". In this scenario master itself is always (theoretically, at least) ready for release. This solves the original problem of release of some tools being blocked by others, but creates some other problems: last-minute merge conflicts across dev teams, large amounts of code being held back for months while it undergoes testing, harder to share code across groups, more complex git workflows for everyone.; 4. Everyone is free to merge development versions of tools to master (as is currently the case), and most of the time we try to release everything in the GATK together. On rare occasions when, eg., CNV needs a release now and HC is not ready, we create a branch off of the last tagged release, cherry-pick the CNV tools (or whatever) into it, and release that. Then when the HC stabilizes and master is once again releasable, we do the next release from master. I've renamed this issue to make the problem we're trying to solve clearer. @a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:3745,release,release-ready,3745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,1,['release'],['release-ready']
Deployability,"hg38.vcf.gz; 13:35:34.129 WARN IndexUtils - Feature file ""file:///data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 13:35:34.232 WARN IntelInflater - Zero Bytes Written : 0; 13:35:34.282 INFO BaseRecalibrator - Done initializing engine; 13:35:34.285 INFO BaseRecalibrationEngine - The covariates being used here:; 13:35:34.285 INFO BaseRecalibrationEngine - 	ReadGroupCovariate; 13:35:34.285 INFO BaseRecalibrationEngine - 	QualityScoreCovariate; 13:35:34.285 INFO BaseRecalibrationEngine - 	ContextCovariate; 13:35:34.285 INFO BaseRecalibrationEngine - 	CycleCovariate; 13:35:34.344 INFO ProgressMeter - Starting traversal; 13:35:34.344 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 13:35:44.363 INFO ProgressMeter - chr1:5384544 0.2 214000 1281820.9; ```. 2. Using full path with non-ascii characters in base directory as tmp path and it failed:; ```; /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx8G -Djava.io.tmpdir=/data/xieduo/Łuksza_2022_Nature"" BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; Using GATK jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -Djava.io.tmpdir=/data/xieduo/Łuksza_2022_Nature -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-loca",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:5043,pipeline,pipeline,5043,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,"hhaW5QcnVuZXIuamF2YQ==) | `83.33% <0%> (-12.23%)` | `5% <0%> (-15%)` | |; | [...r/arguments/CopyNumberArgumentValidationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2FyZ3VtZW50cy9Db3B5TnVtYmVyQXJndW1lbnRWYWxpZGF0aW9uVXRpbHMuamF2YQ==) | `66.66% <0%> (-11.12%)` | `19% <0%> (-1%)` | |; | [...tools/funcotator/DataSourceFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0RhdGFTb3VyY2VGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `75.92% <0%> (-11.04%)` | `17% <0%> (ø)` | |; | [...ools/walkers/haplotypecaller/graphs/SeqVertex.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvU2VxVmVydGV4LmphdmE=) | `92.85% <0%> (-7.15%)` | `10% <0%> (-1%)` | |; | [...te/hellbender/tools/funcotator/OutputRenderer.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL091dHB1dFJlbmRlcmVyLmphdmE=) | `92.85% <0%> (-7.15%)` | `4% <0%> (ø)` | |; | ... and [170 more](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5475?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5475?src=pr&el=footer). Last update [1f6a172...623830b](https://codecov.io/gh/broadinstitute/gatk/pull/5475?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5475#issuecomment-443759397:4713,update,update,4713,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5475#issuecomment-443759397,2,['update'],['update']
Deployability,"hi @KevinCLydon, @davidbenjamin , thanks for this fix. I am preparing a custom version of 4.1.4.1 with just this patch on top of it. One question I had is: is this a safe patch to have on its own, or does it need to go in tandem with any other patch to form a proper release (and not break anything else)? Given this fix is now ~7 months old, I'm hoping insiders can maybe tell me if any other patch ended up being needed after this one, either to deal with the same issue, or to deal with any new issues introduced by it (if any).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6327#issuecomment-659117371:113,patch,patch,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6327#issuecomment-659117371,5,"['patch', 'release']","['patch', 'release']"
Deployability,"hi, I downloaded the hg38 database from the following URL two months ago, which contains some known sites of vcf files such as snp and indel;; https://gatk.broadinstitute.org/hc/en-us/articles/360035890811；GATK resource bundle; But now I found that the contents of these vcf files cannot be viewed. I think the vcf files should be viewed under normal circumstances; now I want to restart download the data; but the official website was updated two days ago, can you give me a website to download the data?; thanks. the error for view is:; 1000G_phase1.snps.high_confidence.hg38.vcf may be a binary file;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6988:436,update,updated,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6988,1,['update'],['updated']
Deployability,"hs37d5cs.reads.sorted.bam.bai; 17/02/06 21:42:53 INFO com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream: uriToStorageObject mw-pathseq-test/hs37d5cs.reads.sorted.bam.bai=mw-pathseq-test:hs37d5cs.reads.sorted.bam.bai; 17/02/06 21:42:54 INFO com.google.cloud.genomics.dataflow.readers.bam.BAMIO: No index for gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam.bai; 17/02/06 21:42:54 INFO com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream: Creating SeekableGCSStream: gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam; 17/02/06 21:42:54 INFO com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream: uriToStorageObject mw-pathseq-test/hs37d5cs.reads.sorted.bam=mw-pathseq-test:hs37d5cs.reads.sorted.bam; 17/02/06 21:42:54 INFO org.spark_project.jetty.server.ServerConnector: Stopped ServerConnector@5148cf20{HTTP/1.1}{0.0.0.0:4040}; 21:42:54.861 INFO PrintReadsSpark - Shutting down engine; [February 6, 2017 9:42:54 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.15 minutes.; Runtime.totalMemory()=573571072; ***********************************************************************. A USER ERROR has occurred: Failed to read bam header from gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam; Caused by:Error reading null at position 0. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: A USER ERROR has occurred: Failed to read bam header from gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam; Caused by:Error reading null at position 0; 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:376); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:357); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929:6617,pipeline,pipelines,6617,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929,1,['pipeline'],['pipelines']
Deployability,"htsjdk does not support the latest VCF/BCF specs, and it's starting to hurt us (see, eg., https://github.com/broadinstitute/gatk/issues/2056). Let's fix this. The changes to the spec from 4.2 -> 4.3 can be seen by cloning https://github.com/samtools/hts-specs and running:. ```; latexdiff VCFv4.2.tex VCFv4.3.tex > diff.tex; pdflatex diff.tex; ```. and then examining `diff.pdf` (note that you must have latex installed for this to work). . To build full pdfs of all the specs documents, run `make`. The major htsjdk classes involved are:. `VCFCodec` (handles VCF reading -- must be updated while retaining backwards compatibility with previous VCF 4.x versions). `VCFWriter` (handles VCF writing -- only needs to support writing the latest version of the spec). Note that `VCFCodec` shares a lot of code with `VCF3Codec` via the `AbstractVCFCodec` -- we may need to refactor this to better isolate the legacy v3 codec from the v4 codec. @cmnbroad has already started working on updating BCF support in the branch https://github.com/cmnbroad/htsjdk/tree/cn_bcf2. Before starting implementation, we should come up with an itemized summary of how we intend to deal with each change in the spec, and make sure we agree on the approach. This code is extremely performance-sensitive, so we need to trade off on performance vs. strict fidelity to the spec. For each spec change that requires a code change in htsjdk, we should be sure to add a good unit test. We should also add tests proving that support for older versions of the spec is not broken.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2092:410,install,installed,410,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2092,2,"['install', 'update']","['installed', 'updated']"
Deployability,"htsjdk has had a bug for a while where it permissively would read any BCF 2.x version if x was greater than or equal to 1 (it only supports BCF 2.1, not version 2.2). In practical terms this didn't matter because BCF 2.2 uses ""IDX"" fields in some header lines, and those were rejected by htsjdk anyway. However, a recently change in htsjdk causes it to accept additional fields in header lines, so BCF 2.2 is no longer rejected due to the presence of these fields. . IndexFeatureFile `testUncompressedBCF2_2Index` is a negative test that relies on the fact that BCF2.2 is rejected, so its currently disabled. The BCF version checking is fixed in later versions of htsjdk (https://github.com/samtools/htsjdk/issues/1323), so at the next htsjdk upgrade, `testUncompressedBCF2_2Index` should be reenabled (though it might throw a different exception).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5838:743,upgrade,upgrade,743,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5838,1,['upgrade'],['upgrade']
Deployability,htsjdk has updated to a newer version of snappy (https://github.com/samtools/htsjdk/pull/872) which makes it compatible with the rest of the world's snappy. this means we can re-enable snappy usage in htsjdk which should give performance improvements in tools that use `SortingCollection`. this is a permanent solution to #2026 that replaces the changes we made in #2028,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3635:11,update,updated,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3635,1,['update'],['updated']
Deployability,"htsjdk updated, so I changed this to refer to the snapshot and rebased. Seems to work:. ```; $ samtools view pr.bam | md5sum; c7f41be91031bea6d28d59d40b54f304 -; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-329891457:7,update,updated,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-329891457,1,['update'],['updated']
Deployability,"htsjdk versions older than 2.1.1 would remove NM and MD tags on bam->cram compression, and then automatically regenerate NM tags when reading cram. Starting with 2.1.1, in order to ensure lossless round-tripping, it no longer does either, and restores only the tags present in the compressed file . As a result, any cramfile read with 2.1.1+ that was generated with older htsjdk versions (or samtools) will fail validation due to missing NM tags. So this PR contains an updated cram file that contains NM tags for the SAMFileValidation tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1551:470,update,updated,470,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1551,1,['update'],['updated']
Deployability,"http://www.hammerlab.org/2015/02/27/monitoring-spark-with-graphite-and-grafana/. the task here to set this up and, if it's useful, update the readme on how to set it up and use. @laserson do you have experience with Graphite and Grafana",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1377:131,update,update,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1377,1,['update'],['update']
Deployability,"http://www.hammerlab.org/2015/07/25/spree-58-a-live-updating-web-ui-for-spark/. the task is to set this up and, if it's useful, update the readme on how to set it up and use. @laserson do you have experience with Spree?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1376:128,update,update,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1376,1,['update'],['update']
Deployability,"https://docs.gradle.org/7.5.1/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; Executing: git lfs pull --include src/main/resources/large. FAILURE: Build failed with an exception. * Where:; Build file '/build/gatk/src/gatk/build.gradle' line: 104. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. BUILD FAILED in 17s; ```; However, I already install git-lfs; ```; git-lfs usr/; git-lfs usr/bin/; git-lfs usr/bin/git-lfs; git-lfs usr/share/; git-lfs usr/share/licenses/; git-lfs usr/share/licenses/git-lfs/; git-lfs usr/share/licenses/git-lfs/LICENSE; git-lfs usr/share/man/; git-lfs usr/share/man/man1/; git-lfs usr/share/man/man1/git-lfs-checkout.1.gz; git-lfs usr/share/man/man1/git-lfs-clean.1.gz; git-lfs usr/share/man/man1/git-lfs-clone.1.gz; git-lfs usr/share/man/man1/git-lfs-dedup.1.gz; git-lfs usr/share/man/man1/git-lfs-env.1.gz; git-lfs usr/share/man/man1/git-lfs-ext.1.gz; git-lfs usr/share/man/man1/git-lfs-fetch.1.gz; git-lfs usr/share/man/man1/git-lfs-filter-process.1.gz; git-lfs usr/share/man/man1/git-lfs-fsck.1.gz; git-lfs usr/share/man/man1/git-lfs-install.1.gz; git-lfs usr/share/man/man1/git-lfs-lock.1.gz; git-lfs usr/share/man/man1/git-lfs-locks.1.gz; git-lfs usr/share/man/man1/git-lfs-logs.1.gz; git-lfs usr/share/man/man1/git-lfs-ls-files.1.gz; git-lfs usr/share/man/man1/git-lfs-merge-driver.1.gz; git-lfs usr/share/man/man1/git-lfs-migrate.1.gz; git-lfs usr/share/man/man1/git-lfs-pointer.1.gz; git-lfs usr/share/man/man1/git-lfs-post-checkout",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8320:1513,install,install,1513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8320,1,['install'],['install']
Deployability,https://github.com/GoogleCloudPlatform/google-cloud-java/releases/tag/v0.19.0,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3044#issuecomment-306581247:57,release,releases,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3044#issuecomment-306581247,1,['release'],['releases']
Deployability,https://github.com/broadinstitute/gatk/blob/b4cba377e0aff179dbff615783506913e7fe3aa4/src/main/java/org/broadinstitute/hellbender/tools/LocalAssembler.java#L1272. The program can potentially fail to release a system resource.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7377:198,release,release,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7377,1,['release'],['release']
Deployability,"https://github.com/broadinstitute/gatk/blob/c6daf7dd02b866907fbfebad150baeb540c35bce/src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/JointGermlineCNVSegmentation.java#L701. I'm running into a recurrent issue in JointGermlineCNVSegmentation, running after PostprocessGermlineCNVCalls in a gCNV pipeline. A number of batches are being merged in parallel - some of those succeed, some fail. It's not clear just yet if this is a deterministic failure, I'll re-run a few times and see if I can answer that. . ```text; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chrX:6383391 [VC SAMPLE_ID.segments.vcf.gz @ chrX:6383391-17732942 Q3076.53 of type=NO_VARIATION alleles=[N*] attr={END=17732942} GT=GT:CN:NP:QA:QS:QSE:QSS	0:1:581:1:3077:4:20 filters=. ... Caused by: java.lang.IllegalStateException: Encountered genotype with ploidy 1 but 2 alleles.; 	at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); 	at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.correctGenotypePloidy(JointGermlineCNVSegmentation.java:701); 	at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.prepareGenotype(JointGermlineCNVSegmentation.java:682); ```. The VCF row in question is . ```text; chrX	6383391	CNV_chrX_6383391_17732942	N	.	3076.53	.	END=17732942	GT:CN:NP:QA:QS:QSE:QSS	0:1:581:1:3077:4:20; ```. The characterisation of this row as `type=NO_VARIATION alleles=[N*]` seems... partially correct? There is no variation at this locus, but I'm not sure why alleles is `N*`. In this situation, as I read it, the first clause should be satisfied: 1 allele, and allele is no-call. Instead the variant process is dying in the else side of the condition. Could you clarify if I'm interpreting this correctly?. Relevant versioning:; ```; 13:18:38.320 INFO JointGermlineCNVSegmentation - ------------------------------------------------------------; 13:18:38.321 INFO JointGermlineCNVSegmentation - The Genome Analy",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8834:306,pipeline,pipeline,306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8834,1,['pipeline'],['pipeline']
Deployability,"https://github.com/broadinstitute/gatk/issues/1411. The pipeline takes an readname sorted BAM and does MarkDuplicates and 2 steps of BQSR and saves sharded output. ; - legacy: SortSam + MarkDuplicates + BaseRecalibrator + PrintReads; - new: ReadsPipelineSpark. The test file is 35GB, readname sorted.; - [x] make a querynamesorted file and copy to cluster; `hdfs:///user/akiezun/data/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam`; - [x] run new code on it, measure time; - [x] run legacy code (picard + gatk3) on coordinate sorted bam, pinned to 1 CPU, 7GB ram",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1559:56,pipeline,pipeline,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1559,1,['pipeline'],['pipeline']
Deployability,https://github.com/broadinstitute/gatk/issues/1673 was fixed with the htsjdk update; this re-enables the test.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1962:77,update,update,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1962,1,['update'],['update']
Deployability,"https://github.com/broadinstitute/picard/pull/913 is finally merged, so we can make this swap the next time we upgrade picard.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3632#issuecomment-481232489:111,upgrade,upgrade,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3632#issuecomment-481232489,1,['upgrade'],['upgrade']
Deployability,"hutting down engine; [April 27, 2016 6:49:12 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=3858759680; java.io.FileNotFoundException: File file:/Users/louisb/Workspace/gatk-protected/build/libIntelDeflater.so does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:609); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:822); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:599); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:337); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289); at org.apache.spark.deploy.yarn.Client.copyFileToRemote(Client.scala:317); at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:407); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:471); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:470); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:470); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:468); at scala.collection.immutable.List.foreach(List.scala:318); at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:468); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:727); at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:142); at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:57); at org.apache.spark.scheduler.Tas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:6984,deploy,deploy,6984,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,1,['deploy'],['deploy']
Deployability,"i <mehrtash@broadinstitute.org>; Date: Fri Dec 8 02:45:38 2017 -0500. revert travis yml forks; verbose logging germline wdl. commit ae05801e33c37b3bf2685fba202032a270804873; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 00:55:14 2017 -0500. updated somatic PoNs for PreprocessIntervals drop Ns. commit cff64984d9fb42364001bda4c73d54cf68d85a5c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 00:37:24 2017 -0500. sudo travis yml. commit 89025941febd2089d426cfa1e0f0aa6a6712e2a9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 00:23:22 2017 -0500. travis/Docker config update (g++-6, Miniconda3); python test group assignment. commit 31f96398106c2b8577b8c25d110abea3ebe7f836; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:44:53 2017 -0500. WDL test bugfix. commit 9b2fb820536ec355bea0256471bd093d547f5c99; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:20:36 2017 -0500. update WDL test JSON files. commit e3d97644d1a2c40a5c364a96f8b67246154179c9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:18:14 2017 -0500. assertions in inference task base; removed a ASCII > 128 character in log messages. commit 526cf92e623a3bbd5f9d375132b6ca046fc47620; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:03:04 2017 -0500. redirect tqdm progress bar to python logger. commit 2e45bd30968b921fae225de3901fb97ece690b0c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 19:45:49 2017 -0500. more arg related fixes. commit bb89a3bb338d88199881e8aca65f656f2acd7c0a; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 19:41:20 2017 -0500. arg related bugfixes in WDL, python, and java CLIs. commit 23569787ee2c8cc6c9227a44170cbbd02fe4427f; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 17:21:05 2017 -0500. fixed issue with python boolean argparse (they use weird semantics). commit",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:4570,update,update,4570,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['update'],['update']
Deployability,i just installed pysam and a few softwares in the list but `mamba env create -n gatk -f gatkcondaenv.yml` still fails.; am i missing something?; ```; mamba env create -n pysam install pysam; mamba activate pysam; mamba install -c conda-forge typing_extensions=4.1.1; mamba install -c conda-forge python=3.6.10; mamba install -c conda-forge pymc3==3.1 -y; mamba install -c conda-forge pip=21.3.1; mamba install -c conda-forge scipy=1.0.0; mamba install -c conda-forge numpy=1.17.5; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8838#issuecomment-2118282347:7,install,installed,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8838#issuecomment-2118282347,8,['install'],"['install', 'installed']"
Deployability,"ian release (buster). Trying to run gatk with an OpenJDK11 install fails. I anticipate a WONTFIX since this is dependency related, but I figured it would be good to let people know. ### Affected tool(s) or class(es); GATKRead, probably others too. ### Affected version(s); - [x] Latest public release version [4.1.2.0]; - [ ] Latest master branch as of [didn't test]. ### Description ; ```; Exception in thread ""main"" java.lang.IncompatibleClassChangeError: Inconsistent constant pool data in classfile for class org/broadinstitute/hellbender/transformers/ReadTransformer. Method 'org.broadinstitute.hellbender.utils.read.GATKRead lambda$identity$d67512bf$1(org.broadinstitute.hellbender.utils.read.GATKRead)' at index 65 is CONSTANT_MethodRef and should be CONSTANT_InterfaceMethodRef; 	at org.broadinstitute.hellbender.transformers.ReadTransformer.identity(ReadTransformer.java:30); 	at org.broadinstitute.hellbender.engine.GATKTool.makePreReadFilterTransformer(GATKTool.java:345); 	at org.broadinstitute.hellbender.engine.GATKTool.getTransformedReadStream(GATKTool.java:374); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:93); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); ```. This error seems related to the JRE version. You can still install JDK8 manually but that's not ideal for many users. #### Steps to reproduce; Run GATK on OpenJDK11. #### Expected behavior; Program runs :). #### Actual behavior; Error",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6053:1894,install,install,1894,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6053,1,['install'],['install']
Deployability,"ies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # conda-installed 2.2.4 appears to be the most recent version with a consistent API and without conflicts/clobbers; # if you wish to update, note that versions of conda-forge::keras after 2.2.5; # undesirably set the environment variable KERAS_BACKEND = theano by default; - defaults::intel-openmp=2019.4; - conda-forge::scikit-learn=0.22.2; - conda-forge::matplotlib=3.2.1; - conda-forge::pandas=1.0.3. # core R dependencies; these should only be used for plotting and do not take precedence over core python dependencies!; -",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:2235,update,update,2235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['update'],['update']
Deployability,"iff coverage is `66.667%`. ```diff; @@ Coverage Diff @@; ## master #2515 +/- ##; ===============================================; - Coverage 76.273% 76.268% -0.004% ; - Complexity 10876 10878 +2 ; ===============================================; Files 752 752 ; Lines 39583 39584 +1 ; Branches 6922 6922 ; ===============================================; - Hits 30191 30190 -1 ; - Misses 6772 6774 +2 ; Partials 2620 2620; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tute/hellbender/tools/spark/sv/ReadClassifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkQ2xhc3NpZmllci5qYXZh) | `82.813% <66.667%> (-1.314%)` | `30 <0> (-1)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `66.667% <0%> (-3.333%)` | `10% <0%> (ø)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=footer). Last update [d40ccc2...d5c85bb](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2515#issuecomment-288529799:2161,update,update,2161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2515#issuecomment-288529799,2,['update'],['update']
Deployability,"iff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `90.476% <0%> (+1.587%)` | `61% <0%> (+2%)` | :arrow_up: |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `66.667% <0%> (+3.252%)` | `4% <0%> (ø)` | :arrow_down: |; | [...g/broadinstitute/hellbender/engine/AuthHolder.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXV0aEhvbGRlci5qYXZh) | `15.254% <0%> (+5.085%)` | `2% <0%> (ø)` | :arrow_down: |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `77.703% <0%> (+6.757%)` | `22% <0%> (+4%)` | :arrow_up: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `86.4% <0%> (+8.8%)` | `35% <0%> (+7%)` | :arrow_up: |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=footer). Last update [5ccfd00...b1d407f](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2540#issuecomment-290122549:4065,update,update,4065,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2540#issuecomment-290122549,2,['update'],['update']
Deployability,"igFactory - 	createOutputBamIndex = true; 23:43:52.477 INFO GermlineCNVCaller - Deflater: IntelDeflater; 23:43:52.477 INFO GermlineCNVCaller - Inflater: IntelInflater; 23:43:52.477 INFO GermlineCNVCaller - GCS max retries/reopens: 20; 23:43:52.477 INFO GermlineCNVCaller - Requester pays: disabled; 23:43:52.477 INFO GermlineCNVCaller - Initializing engine; 23:43:52.479 DEBUG ScriptExecutor - Executing:; 23:43:52.479 DEBUG ScriptExecutor - python; 23:43:52.479 DEBUG ScriptExecutor - -c; 23:43:52.480 DEBUG ScriptExecutor - import gcnvkernel. INFO (theano.gof.compilelock): Waiting for existing lock by process '11848' (I am process '19216'); INFO (theano.gof.compilelock): To manually release the lock, delete /gpfs/hpc/home/lijc/xiangxud/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.9.2009-Core-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '11848' (I am process '19216'); INFO (theano.gof.compilelock): To manually release the lock, delete /gpfs/hpc/home/lijc/xiangxud/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.9.2009-Core-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '11848' (I am process '19216'); INFO (theano.gof.compilelock): To manually release the lock, delete /gpfs/hpc/home/lijc/xiangxud/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.9.2009-Core-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '18570' (I am process '19216'); INFO (theano.gof.compilelock): To manually release the lock, delete /gpfs/hpc/home/lijc/xiangxud/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.9.2009-Core-x86_64-3.6.10-64/lock_dir; 23:44:42.124 DEBUG ScriptExecutor - Result: 0; 23:44:42.124 INFO GermlineCNVCaller - Done initializing engine; 23:44:42.126 INFO GermlineCNVCaller - Intervals specified...; 23:44:42.534 DEBUG GenomeLocParser - Prepared reference sequence contig dictionary; 23:44:4",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8938:5356,release,release,5356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8938,1,['release'],['release']
Deployability,"igarReads done. Elapsed time: 99.33 minutes.; Runtime.totalMemory()=5453119488; htsjdk.samtools.util.RuntimeIOException: Attempt to add record to closed writer.; at htsjdk.samtools.util.AbstractAsyncWriter.write(AbstractAsyncWriter.java:57); at htsjdk.samtools.AsyncSAMFileWriter.addAlignment(AsyncSAMFileWriter.java:53); at org.broadinstitute.hellbender.utils.read.SAMFileGATKReadWriter.addRead(SAMFileGATKReadWriter.java:21); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.writeReads(OverhangFixingManager.java:358); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.flush(OverhangFixingManager.java:338); at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.closeTool(SplitNCigarReads.java:192); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1091); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289). This looks similar to issue #8232, but I've not been able to solve this using any of the fixes suggested on that page. I'm using Java version 8, the input BAMs were mapped using STAR via nfcore rnaseq without issue and I have plenty of space on my disk drive, even when specifying a temp directory. It also doesn't matter if I run the tool independently using the command above or as part of a pre-configured pipeline, and I get the same issue with SplitNCigarReads acting as if it has running out of space. . How do I fix this? I need this step to run variant calling on my rnaseq samples (I'm using the GATK best practices pipeline).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8522:10556,pipeline,pipeline,10556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8522,2,['pipeline'],['pipeline']
Deployability,"ignore, testing GitZen integration<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/4401'>Zendesk ticket #4401</a>)<br>gz#4401</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6380:23,integrat,integration,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6380,1,['integrat'],['integration']
Deployability,ileup - Defaults.CUSTOM_READER_FACTORY : ; 15:04:36.349 INFO Pileup - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 15:04:36.349 INFO Pileup - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 15:04:36.349 INFO Pileup - Defaults.REFERENCE_FASTA : null; 15:04:36.349 INFO Pileup - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 15:04:36.349 INFO Pileup - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:04:36.349 INFO Pileup - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 15:04:36.350 INFO Pileup - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:04:36.350 INFO Pileup - Defaults.USE_CRAM_REF_DOWNLOAD : false; 15:04:36.350 INFO Pileup - Deflater IntelDeflater; 15:04:36.350 INFO Pileup - Initializing engine; WARNING: BAM index file /home/lichtens/broad_oncotator_configs/hcc_purity/SM-74NEG.bai is older than BAM /home/lichtens/broad_oncotator_configs/hcc_purity/SM-74NEG.bam; 15:04:38.560 INFO IntervalArgumentCollection - Processing 999914 bp from intervals; 15:04:38.630 INFO Pileup - Done initializing engine; 15:04:38.635 INFO ProgressMeter - Starting traversal; 15:04:38.636 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; JProfiler> Protocol version 49; JProfiler> Using JVMTI; JProfiler> JVMTI version 1.1 detected.; JProfiler> 64-bit library; JProfiler> Listening on port: 31757.; JProfiler> Attach mode initialized; JProfiler> Instrumenting native methods.; JProfiler> Can retransform classes.; JProfiler> Can retransform any class.; JProfiler> Retransforming 8 base class files.; JProfiler> Base classes instrumented.; JProfiler> Native library initialized; JProfiler> Using dynamic instrumentation; JProfiler> Time measurement: elapsed time; JProfiler> CPU profiling enabled; JProfiler> Initializing configuration.; JProfiler> Retransforming 3697 class files.; JProfiler> Configuration updated. ```. ![oncobuntu_mk3](https://cloud.githubusercontent.com/assets/2152339/22307273/583f61a8-e310-11e6-87ef-e87eaba7cf93.png),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2356:3935,configurat,configuration,3935,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2356,3,"['Configurat', 'configurat', 'update']","['Configuration', 'configuration', 'updated']"
Deployability,"ility to tweak sample-every-Nth-variant parameter for SNP model creation (#8019); - add initial notebook copy pasta (#8008); - add sample_table_timestamp to GetNumSamplesLoaded (#8022); - Batched Avro export [VS-630] (#8020); - Updating references to old GATK for VS-620 (#8023); - VS-517 Use standard version of GetBQTableLastModifiedDatetime in GvsValidateVat (#8024); - Fix bug in GvsWithdrawSamples.wdl (#8026); - Ah 617 exposing the drop_state parameter to the GvsJointVariantCalling wdl used for beta (and internal customer) (#8032); - Expose maximum-training-variants VQSR parameter [VS-634] (#8029); - Callset statistics [VS-560] (#8018); - Check for withdrawn before exporting to AVRO files [VS-646] (#8039); - Small updates to GVS Integration WDL [VS-618] (#8042); - Rework Hail script generation [VS-616] (#8034); - Alpine based Variant Store Docker image [VS-648] (#8044); - update warp version (#7906); - Fail Avro extract and callset stats on bad filter name [VS-655] (#8046); - Vs 629 failure to retrieve job information during ingest (#8047); - Restore accidentally removed bcftools [VS-661] (#8051); - Allowing our pipeline to function with a sample size of one (#8055); - Vs 665 re create vcf for cd 68 po 52339 with ad padding fixed (#8057); - VS-665 and VS-620 updating code to use latest docker images containing Rori's AD calculation changes in extract (#8061); - updating the beta workflow to use the latest jar, representing the version of GATK George tested against the workflow (#8062); - VS-637 Address a couple of issues in SampleLoadStatus handling in GVSImportGenomes. (#8052); - Revert Alpinizing of apt dependent task [VS-688] (#8065); - Fix missing vat schema JSONs [VS-699] (#8072); - Fix integration expectations for fixed AD [VS-689] (#8066); - VS-698 Remove unnecessary columns from Call set statistics (#8073); - Fix Dockerfile nits that break 20.10.21 (#8078); - Nirvana 3.18.1 Docker images support [VS-661] (#8082); - Add option to not prepare __REF_DATA or __",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:28978,update,updates,28978,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,8,"['Integrat', 'pipeline', 'update']","['Integration', 'pipeline', 'update', 'updates']"
Deployability,"ility). Costs for this branch ($10.92) and 4.5.0.0 ($10.96) were quite comparable. Note that a small portion of these costs derives from Pf7-specific genotyping steps, which I did not bother to remove from the workflow. Runtime for the ploidy modeling and postprocessing steps were comparable. Interestingly, **runtime for the gCNV was ~20-25% longer with this branch than with 4.5.0.0, but memory usage fell by a factor of ~3 (~6GB to ~2GB)!** I am not sure if we could recoup the runtime with some more tweaking of the environment (perhaps double checking that optimized BLAS/MKL/etc. packages are properly used, changing environment variables/flags, etc.), but I think the decrease in memory usage is quite nice. Concordance was checked for the following quantities (4.5.0.0 is on the x-axis and this branch is on the y-axis in all plots below):. 1) Variational posterior means (`mu_*`) and standard deviations (`std_*`) for all analogous variables in the ploidy and gCNV models. There were some slight changes to the gCNV model in this branch (e.g., the functional form of the ARD prior was changed), which means some variables are no longer directly comparable. Furthermore, some variables (such as the bias factors W) are degenerate and cannot be immediately compared. Otherwise, there is good concordance between the remaining variables, e.g.:. ![image](https://github.com/broadinstitute/gatk/assets/11076296/614cf501-ca31-4199-badb-3194b7f78154); ![image](https://github.com/broadinstitute/gatk/assets/11076296/f615084d-d0bf-44e9-bcf5-98abd26ceb06); ![image](https://github.com/broadinstitute/gatk/assets/11076296/48570e53-024c-44b5-8835-3fd40b4c5866); ![image](https://github.com/broadinstitute/gatk/assets/11076296/99100e5d-05e2-4a5c-9d68-57db1b734029); ![image](https://github.com/broadinstitute/gatk/assets/11076296/abae09e1-70a5-4213-95a2-0cb10f9db192); ![image](https://github.com/broadinstitute/gatk/assets/11076296/ef68d0da-90df-4c4b-9802-97988a498280). 2) ... Will update more later!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2079695268:2431,update,update,2431,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2079695268,1,['update'],['update']
Deployability,"ils/genotyper/SampleList.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvU2FtcGxlTGlzdC5qYXZh) | `75.676% <0%> (ø)` | `8% <0%> (?)` | |; | [...hellbender/tools/walkers/annotator/SampleList.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TYW1wbGVMaXN0LmphdmE=) | `81.25% <0%> (+1.658%)` | `9% <0%> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |; | [.../broadinstitute/hellbender/tools/exome/Sample.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9TYW1wbGUuamF2YQ==) | `100% <0%> (+12.308%)` | `5% <0%> (-21%)` | :arrow_down: |; | [...stitute/hellbender/engine/ReferenceFileSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlRmlsZVNvdXJjZS5qYXZh) | `72.727% <0%> (+15.584%)` | `4% <0%> (-4%)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=footer). Last update [62d58c5...fde9d36](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2556#issuecomment-290787479:3610,update,update,3610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2556#issuecomment-290787479,2,['update'],['update']
Deployability,"imple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (@samuelklee); - [x] CLI for calling (cohort). (@samuelklee); - [x] CLI for calling (case). (@samuelklee); - [ ] CLI for post-processing calls. (@asmirnov239) (AS, PR issued by 12/4); - [x] Python environment. (Update: I've verified that gCNV works on the gsa server with a manual setup of conda (python=3.6) + @mbabadi's pip install---although I do get an ""install mkl"" warning from theano. We can discuss autoloading of this environment after release, but should at least have some clear documentation.); - [x] WDL and Cromwell tests. (SL, PR issued by 12/1); - [x] Preliminary evaluation. (MB, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PE #3925 awaiting review.). Miscellaneous:; - [x] Update PreprocessIntervals behavior for WES. (Issue #3981, PR #4027 awaiting review.)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3826:2211,Update,Update,2211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826,6,"['Update', 'install', 'release']","['Update', 'install', 'install---although', 'release']"
Deployability,"implementation is different from the one in `ReadWindowWalker`: first, the overlap between windows is only in one direction; second, `SlidingWindowWalker` is more like a reference/interval walker, from the beginning of the reference (or interval) till the end, it walks in overlapping windows. One example is the following (window-size 10, window-step 5, the - represent the window):. ```; Reference: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; Windows1: _ _ _ _ _ _ _ _ _ _; Windows2: _ _ _ _ _ _ _ _ _ _; Windows3: _ _ _ _ _ _ _ _ _ _; Windows4: _ _ _ _ _ _ _ _ _ _; Windows5: _ _ _ _ _ _ _ _ _ _; ```. Of course, after having a look to `ReadWindowWalker` I think that several things could be improved in my implementation for a general `SlidingWindowWalker`:; - Apply function similar to the `ReadWindowWalker`, with `ReadWindow` being empty if reads are not provided.; - Three window options: `windowSize` (the actual size of the window), `windowStep` (how much advance for the following window) and `windowPadding` (how much extend the window in both directions). Using this abstraction, `ReadWindowWalker` could be implemented setting `windowSize=windowStep`, and the problem that I need to solve could be implemented setting `windowPadding=0`. The simplest way to acomplish this is to use the current implementation of `ReadWindowWalker` to develop a `SlidingWindowWalker` adding three abstract methods for the three parameters (`getWindowSize()`, `getWindowStep()` and `getWindowPadding()`, and implement `ReadWindowWalker` as a extension of this interface setting `getWindowStep()` to return `getWindowSize()` and `requiresReads()` to true. I can do this once the PR #1567 is accepted and generate the two interfaces (to be sure that the integration with the HC engine is working as expected with the changes), or just implement the `SlidingWindowWalker` and you can include it in the HC PR, or update afterwards to avoid redundancy in the code. What do you think, @droazen?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-198438775:2346,integrat,integration,2346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-198438775,2,"['integrat', 'update']","['integration', 'update']"
Deployability,"in <module>; actual_version, force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/bin/theano-nose"", line 11, in <module>; load_entry_point('Theano==1.0.4', 'console_scripts', 'theano-nose')(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 207, in main; result = main_function(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 45, in main_function; from theano import config; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/__init__.py"", line 110, in <module>; from theano.compile import (; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/__init__.py"", line 12, in <module>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 140, in <module>; preargs=args); File ${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2396, in compile_str; (status, compile_stderr.replace('\n', '. '))); Exception: Compilation failed (return status=1): /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_deregisterTMCloneTable. /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_registerTMCloneTable. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x1a): error: unsupported reloc 42. ${INS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:2372,INSTALL,INSTALLDIRGATK,2372,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['INSTALL'],['INSTALLDIRGATK']
Deployability,"in htsjdk 2.5.0, the deflater factory needs to be set up by hand. Hadoop-BAM needs to be updated to allow this and when it is (https://github.com/HadoopGenomics/Hadoop-BAM/issues/109), gatk should use the API to specify the IntelDeflater",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1969:89,update,updated,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1969,1,['update'],['updated']
Deployability,in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://stor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084:1112,integrat,integration,1112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084,1,['integrat'],['integration']
Deployability,"ine.CommandLineProgram.instanceMain(CommandLineProgram.java:211) ; ;     at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160) ; ;     at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203) ; ;     at org.broadinstitute.hellbender.Main.main(Main.java:289). However, the bug wasn't reported when I didn't assign the temp directory:. /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx30G"" BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz  -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test.table ; ; Using GATK jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar ; ; Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx30G -jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test.table ; ; 00:12:20.992 INFO  NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pip",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:14826,pipeline,pipeline,14826,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability,"ine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.NoSuchFileException: /user/yaron/output.bam.parts/_SUCCESS: Unable to find _SUCCESS file; at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:53); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:152); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:250); ... 18 more; ```; However, I can find that _SUCCESS file exists in output.bam.parts. Could someone tell me what may be",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:6049,deploy,deploy,6049,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['deploy'],['deploy']
Deployability,ine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:743); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)Caused by: java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2722); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1565); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2227); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2151); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2009); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1533); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:420); at org.apache.spark.serializer.JavaDe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:9835,deploy,deploy,9835,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['deploy'],['deploy']
Deployability,ine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:233); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:5608,deploy,deploy,5608,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,1,['deploy'],['deploy']
Deployability,ine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:387); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:43476,deploy,deploy,43476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['deploy'],['deploy']
Deployability,ine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:387); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadin,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:44222,deploy,deploy,44222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['deploy'],['deploy']
Deployability,ine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:387); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:153); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:277); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.GATKException: Erred when inferring breakpoint location and event type from chimeric alignment:; asm010450:tig00000 1_189_chrUn_JTFH01000312v1_decoy:663-851_-_189M512H_60_8_149_O 153_701_chrUn_JTFH01000312v1_decoy:1-549_+_152S549M_60_0_549_O; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignmentsSAMSpark.java:175); at java.util.str,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:11295,deploy,deploy,11295,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['deploy'],['deploy']
Deployability,"ine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:470); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:41271,deploy,deploy,41271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,['deploy'],['deploy']
Deployability,"ine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:470); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:17306,deploy,deploy,17306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['deploy'],['deploy']
Deployability,ine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: provided start is negative: -1; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:53461,deploy,deploy,53461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['deploy'],['deploy']
Deployability,"ine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-45f7a9f3-b94f-4040-bf32-0dbfe44f8f68; 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-70db8953-5dec-4eb8-910d-f0abd7e1c42b. real 41m12.118s; user 83m41.069s; sys 10m15.403s. #### Steps to reproduce; atk --java-options ""-Djava.io.tmpdir=tmp"" StructuralVariationDiscoveryPipelineS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942:4422,deploy,deploy,4422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942,1,['deploy'],['deploy']
Deployability,ine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Stream closed; at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:829); at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:889); at java.io.DataInputStream.read(DataInputStream.java:149); at org.disq_bio.disq.impl.file.HadoopFileSystemWrapper$SeekableHadoopStream.read(HadoopFileSystemWrapper.java:232); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(Buffe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:4301,deploy,deploy,4301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,2,['deploy'],['deploy']
Deployability,"ine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:546); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$4.run(ApplicationMaster.scala:721) ; ```. When I specify input as: `hdfs:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`, the tool tries to access `hdfs://cromwellhadooptest:-1/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. **Stack trace for this:**; ```; java.lang.IllegalArgumentException: Wrong FS: hdfs://cromwellhadooptest:-1/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta, expected: hdfs://cromwellhadooptest; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:776); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:247); at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1725); at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1722); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1737); at org.apa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6730:4724,deploy,deploy,4724,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730,1,['deploy'],['deploy']
Deployability,"ineProgram.java:176); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); > 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); > 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); > 	at org.broadinstitute.hellbender.Main.main(Main.java:239); > 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); > 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); > 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); > 	at java.lang.reflect.Method.invoke(Method.java:498); > 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:733); > 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177); > 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202); > 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116); > 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); > Caused by: java.nio.file.ProviderNotFoundException: Provider ""maprfs"" not found; > 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:341); > 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:40); > 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:143); > 	at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:226); > 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); > 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:178); > 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:177); > 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:134); > 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:69); > 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); > 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); > 	at org.apache.spark.rdd.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936:3910,deploy,deploy,3910,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936,1,['deploy'],['deploy']
Deployability,"ineProgram.runTool(CommandLineProgram.java:119); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); > 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); > 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); > 	at org.broadinstitute.hellbender.Main.main(Main.java:239); > 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); > 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); > 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); > 	at java.lang.reflect.Method.invoke(Method.java:498); > 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:733); > 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177); > 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202); > 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116); > 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); > Caused by: java.nio.file.ProviderNotFoundException: Provider ""maprfs"" not found; > 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:341); > 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:40); > 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:143); > 	at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:226); > 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); > 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:178); > 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:177); > 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:134); > 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:69); > 	at or",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936:3764,deploy,deploy,3764,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936,1,['deploy'],['deploy']
Deployability,"info: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072797951--GenomicsDBException-Duplicate-sample-name-found-?page=1#community_comment_360012681791. `gatk --java-options ""-Xmx16g -Xms16g"" GenomicsDBImport --batch-size 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz`. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16g -Xms16g -jar /afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar GenomicsDBImport --batch-size 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz; 16:16:35.954 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 16:16:36.003 DEBUG NativeLibraryLoader - Extracting libgkl_compression.so to /tmp/libgkl_compression5245166187604030095.so; Aug 28, 2020 4:16:36 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 16:16:36.284 INFO GenomicsDBImport - ------------------------------------------------------------; 16:16:36.285 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.6.0; 16:16:36.285 INFO GenomicsDBImport - For support and documentation go to https://software.br",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793:1345,update,update-workspace-path,1345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793,1,['update'],['update-workspace-path']
Deployability,"ing https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1248,Install,Install,1248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['Install'],['Install']
Deployability,"ing wheel for gatkpythonpackages (setup.py): finished with status 'done'; Created wheel for gatkpythonpackages: filename=gatkpythonpackages-0.1-py3-none-any.whl size=117686 sha256=8095375e139fa0729c7a41c8f5e8a43281fc1b6859b6d3951d3bfba7296ee349; Stored in directory: /tmp/pip-ephem-wheel-cache-ecx6e_m0/wheels/06/f7/e1/87cb7da6f705baa602256a58c9514b47dc313aade8809a01da; Successfully built gatkpythonpackages; Installing collected packages: gatkpythonpackages; Successfully installed gatkpythonpackages-0.1. done; #; # To activate this environment, use; #; # $ conda activate gatk; #; # To deactivate an active environment, use; #; # $ conda deactivate. ```. #### Actual behavior; ```sh; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda --version; conda 23.10.0; root@d12ac7710afc:/soft/gatk-4.4.0.0# ""$CONDA"" env create -n gatk -f ""$SOFT/gatk-${GATK_VERSION}/gatkcondaenv.yml""; ...; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Installing pip dependencies: | Ran pip subprocess with arguments:; ['/opt/miniconda/envs/gatk/bin/python', '-m', 'pip', 'install', '-U', '-r', '/soft/gatk-4.4.0.0/condaenv.i9brvcrk.requirements.txt', '--exists-action=b']; Pip subprocess output:. Pip subprocess error:; /opt/miniconda/envs/gatk/bin/python: No module named pip. failed. CondaEnvException: Pip failed. ```; ---; It can be fixed with setting classic colver:; ```; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda --version; conda 23.10.0; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda config --set solver classic; root@d12ac7710afc:/soft/gatk-4.4.0.0# ""$CONDA"" env create -n gatk -f ""$SOFT/gatk-${GATK_VERSION}/gatkcondaenv.yml""; ...; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Installing pip dependencies: \ Ran pip subprocess with arguments:; ['/opt/miniconda/envs/gatk/bin/python', '-m', 'pip', 'install', '-U', '-r', '/soft/gatk-4.4.0.0/condaenv.rtsyg5rl.requirements.txt', '--exists-action=b']; Pip subprocess output:; Processing",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8618:2039,Install,Installing,2039,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8618,2,"['Install', 'install']","['Installing', 'install']"
Deployability,ing-tx-5.2.6.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-web\2.3.0.RELEASE\spring-boot-starter-web-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-json\2.3.0.RELEASE\spring-boot-starter-json-2.3.0.RELEASE.jar;E:\repository\com\fasterxml\jackson\core\jackson-databind\2.11.0\jackson-databind-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-annotations\2.11.0\jackson-annotations-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-core\2.11.0\jackson-core-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.11.0\jackson-datatype-jdk8-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.11.0\jackson-datatype-jsr310-2.11.0.jar;E:\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.11.0\jackson-module-parameter-names-2.11.0.jar;E:\repository\org\springframework\boot\spring-boot-starter-tomcat\2.3.0.RELEASE\spring-boot-starter-tomcat-2.3.0.RELEASE.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.35\tomcat-embed-core-9.0.35.jar;E:\repository\org\glassfish\jakarta.el\3.0.3\jakarta.el-3.0.3.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.35\tomcat-embed-websocket-9.0.35.jar;E:\repository\org\springframework\spring-web\5.2.6.RELEASE\spring-web-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-webmvc\5.2.6.RELEASE\spring-webmvc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybati,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:4225,RELEASE,RELEASE,4225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,"ining CachingIndexedFastaSequenceFile/overloads; - [ ] Update tools in the pathseq package (PathSeqBwaSpark, PathSeqScoreSpark) that do directory manipulation. [Edit] Somewhat tangentially, PathSeqBwaSpark currently rejects read inputs specified through `--inputs` and uses separate args to allow the user to identify inputs as paired or unpaired. Once this is using `GATKPathSpecifier` this could be changed to use ""--inputs"" annotated with tags instead. Might be a problem for WDL gen though (which doesn't support tags).; - [ ] Test utilities (createTempFile/Dir, etc. that return GATKPath); - [ ] Add a `toHadoopPath` method to `GATKPath` that returns a `org.apache.hadoop.fs.Path`.; - [ ] Change tools that generate multiple output files using a stem (SplitReads, etc) to use the `resolve` methods listed above once they're available.; - [ ] All usages of `PrintStream` should be replaced with `OutputStreamWriter` (code that requires printf-style formatting can use `write` with `String.format` instead of the `printf` methods). `PrintStream` doesn't propagate IOExceptions and instead requires calls to `checkError`, but almost all usages of `PrintStream` don't call it.; - [ ] Update `org.broadinstitute.hellbender.utils.report` (`GATKReport` and friends) to eliminate `File` references and `PrintStream` usages.; - [ ] Update `org.broadinstitute.hellbender.utils.recalibration` (`RecalUtils` and friends) to eliminate `File` references and `PrintStream` usages.; - [ ] Fix cases where we have a tool with a `File` that needs to be accessible to R code (determine if the code can handle non-local file paths). i.e.`VariantRecalibrator` TRANCHES_FILE.; - [ ] Fix cases where we have a tool with a `File` that needs to be accessible to Python (determine if the code can handle non-local file paths).; - [ ] `FeatureInput` should have all of it's String constructors removed, and only take GATKPath inputs. The constructor overloads that take tag Maps can be removed, and all call sites updated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6610:1935,Update,Update,1935,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6610,3,"['Update', 'update']","['Update', 'updated']"
Deployability,initial documentation update,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4019:22,update,update,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4019,1,['update'],['update']
Deployability,install lfs with --force,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7682:0,install,install,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7682,1,['install'],['install']
Deployability,"install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:11.507 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.508 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:35:11.508 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:35:11.508 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:35:11.508 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:35:11.509 INFO CountReadsSpark - Start Date/Time: January 9, 2019 1:35:09 PM EST; 13:35:11.509 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.509 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.510 INFO CountReadsSpark - HTSJDK Version: 2.18.1; 13:35:11.511 INFO CountReadsSpark - Picard Version: 2.18.16; 13:35:11.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:2351,install,install,2351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['install'],['install']
Deployability,installing git-lfs and downloading large files on travis,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/907:0,install,installing,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/907,1,['install'],['installing']
Deployability,"installing libuuid manually by `brew install ossp-uuid` solves the problem, but we really want this statically linked into it so users aren't expected to do it themselves",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4062#issuecomment-355663626:0,install,installing,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4062#issuecomment-355663626,2,['install'],"['install', 'installing']"
Deployability,"institute.barclay.argparser.CommandLineException: deploy-mode is not a recognized option; > 	at org.broadinstitute.barclay.argparser.CommandLineArgumentParser.parseArguments(CommandLineArgumentParser.java:384); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.parseArgs(CommandLineProgram.java:217); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:191); > 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); > 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); > 	at org.broadinstitute.hellbender.Main.main(Main.java:239); > 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); > 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); > 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); > 	at java.lang.reflect.Method.invoke(Method.java:498); > 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:733); > 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177); > 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202); > 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116); > 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala). Actually, I just re-checked and i'm not sure my solution `--conf 'spark.submit.deployMode=cluster'` works well. I'm currently testing it. My current command is:; > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input hdfs://spark01:7222/user/axverdier/data/710-PE-G1.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_CountReadsSpark --sparkRunner SPARK --sparkMaster yarn --conf 'spark.submit.deployMode=cluster' --javaOptions -Dmapr.library.flatclass. I need the `-Dmapr.library.flatclass` because our spark is using a mapr filesystem and I was getting error about JNI library linkage.; However, the path",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350038452:1414,deploy,deploy,1414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350038452,1,['deploy'],['deploy']
Deployability,"institute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated once. Or, we can decide that none of this is required at all and just delete `CommandLineProgramTest.java`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/69:1379,update,update,1379,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69,2,['update'],"['update', 'updated']"
Deployability,intEvidenceSpark.gatherEvidenceAndWriteContigSamFile(FindBreakpointEvidenceSpark.java:199); at org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark.runTool(StructuralVariationDiscoveryPipelineSpark.java:164); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.FileSystemException: /restricted/projectnb/casa/wgs.hg38/pipelines/sv/gatk.sv/temp/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.contig-sam-file.sam: Not a directory; at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-494014590:6702,deploy,deploy,6702,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-494014590,16,"['deploy', 'pipeline']","['deploy', 'pipelines']"
Deployability,integration run: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/534011af-6909-49b4-b451-a0604eafb447,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7901#issuecomment-1155658697:0,integrat,integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7901#issuecomment-1155658697,1,['integrat'],['integration']
Deployability,integration test for BQSR Plotting,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/420:0,integrat,integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/420,1,['integrat'],['integration']
Deployability,integration test for CollectQualityYieldMetrics,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/842:0,integrat,integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/842,1,['integrat'],['integration']
Deployability,integration tests for SplitNCigarReads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1378:0,integrat,integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1378,1,['integrat'],['integration']
Deployability,integration tests to check min-bq argument is hooked up to HC and M2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4192:0,integrat,integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4192,1,['integrat'],['integration']
Deployability,integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084:1781,integrat,integration,1781,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084,4,['integrat'],['integration']
Deployability,"ion of PyMC that supports Python 3.10+ is PyMC 4, released in 2022.; > 7. However, PyMC 4 introduces API changes, which will also require additional gCNV code changes and numerical testing.; > 8. These API changes are because the underlying computational backend for PyMC was updated from Theano (think of this as an old alternative to TensorFlow) to Aesara.; > 9. Since then, PyMC 5.9 has been released and the underlying backend has been updated again, from Aesara to PyTensor.; > 10. So if we are going to update the environment to support Python 3.10+, it probably makes sense to go all the way to PyMC 5.9. I've made some strides in this PR; as of [6b08f3a](https://github.com/broadinstitute/gatk/pull/8561/commits/6b08f3af205cb9af1f5c63a0786f9a5a52cd78c1), I've made enough updates to accommodate API changes so that cohort-mode inference for both GermlineCNVCaller and DetermineGermlineContigPloidy runs successfully under Python 3.10 and PyMC 5.9.0---although note that 5.9.1 has been released in the interim!. However, our work has just begun. Results now produced in the numerical tests mentioned above are quite far off from the original expected results. It remains to be seen whether this is due to the randomness of inference, some slight changes to the model prior that were necessitated by the API changes, or some bugs introduced in other code updates. (Also note that I believe Andrey's PR in item 4 already broke these tests, although the numerical differences were much smaller and more reasonable---but perhaps he can confirm. Also noting here that I think determinism is still currently broken as of this commit---there have been some changes to PyTensor/PyMC seeding so that our previous theano/PyMC3 hack no longer applies.). So I think the next step is to just go to scientific-level testing and see what the fallout is. Ideally, we'd still get good performance (or perhaps better! at least on the runtime side, hopefully...) and we can just update the numerical tests. But i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561:2054,release,released,2054,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561,1,['release'],['released']
Deployability,"ior probabilities, all of which must be self-consistency determined. The internal admixing rate would be used to admix the old and new self-consistent fields across the two chains in order to dampen oscillations and improve convergence properties. Once internal convergence is achieved, the converged posteriors must be saved to a workspace in order to be consumed by the continuous sub-model. The new internally converged posteriors will be admixed with the old internally converged posteriors from the previous epoch with the _external_ admixing rate. - Introduced two-stage inference for cohort denoising and calling. In the first (""warm-up"") stage, discrete variables are marginalized out, yielding an effective continuous-only model. The warm-up stage calculates continuous posteriors based on the marginalized model. Once convergence is achieved, continuous and discrete variables are decoupled for the second (""main"") stage. The second stage starts with a discrete calling step (crucial), using continuous posteriors from the warm-up stage as the starting point. The motivation behind the two-stage inference strategy is to avoid getting trapped in spurious local minima that are potentially introduced by mean-field decoupling of discrete and continuous RVs. Note that mean-field decoupling has a tendency to stabilize local minima, most of which will disappear or turn into saddle points once correlations are taken into account. While the marginalized model is free of such spurious local minima, it does not yield discrete posteriors in a tractable way; hence, the necessity of ultimately decoupling in the ""main"" stage. - Capped phred-scaled qualities to maximum values permitted by machine precision in order to avoid NaNs and overflows. - Took a first step toward tracking and logging parameters during inference, starting with the ELBO history. In the future, it may be desirable to allow tracking of arbitrary RVs and deterministics via command line args (for debugging and explorator",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4720:1561,continuous,continuous,1561,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4720,1,['continuous'],['continuous']
Deployability,"ire count file for all samples a determining factor? If we can drastically reduce this cost, then we can dedicate more to increasing resolution, etc. Here is a minimal set of fixes that could enable the querying of intervals for GermlineCNVCaller (and also for DetermineGermlineContigPloidy without too much extra work, since we also subset intervals there) *only in the gCNV WGS pipeline*, without disrupting other interfaces:. 1) Write a Tribble SimpleCountCodec for the `counts.tsv` extension. I've already done this in a branch.; 2) Change GermlineCNVCaller and DetermineGermlineContigPloidy tools to accept paths.; 3) If an index is present for each count path, create a FeatureDataSource, merge the requested -L/-XL intervals, and query to perform the subset. We will also need to stream the SAM header metadata. It should not require much code to extract all this to a temporary IndexedSimpleCountCollection class. (Caveat: for now, this will work with the current gCNV convention of providing bins via -L/-XL. Technically, it will also work with the more conventional use of -L/-XL to denote contiguous regions, but we may have to perform checks that bins are not duplicated in adjacent shards if they overlap both, since querying a FeatureDataSource will return any bins that overlap the interval---rather than only those that are completely contained within it.); 4) Index read-count TSVs in the gCNV WGS pipeline after collection and modify the DetermineGermlineContigPloidy and GermlineCNVCaller tasks to take read-count paths and indices, if necessary. These changes could be confined in the gCNV WGS WDL for now. I think that should do the trick. If this is high priority, I can implement now. In the future, we might be able to promote all Locatable CNV Records to Features and write code to automatically pass the columns/encoders/decoders (currently held in the Collection corresponding to each Record) to a single Tribble codec. This codec should not depend upon the file extension.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082:1567,pipeline,pipeline,1567,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082,1,['pipeline'],['pipeline']
Deployability,is this how a gradle update is done?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1586:21,update,update,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1586,1,['update'],['update']
Deployability,iscovery/BreakEndVariantType.java](https://codecov.io/gh/broadinstitute/gatk/pull/3655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQnJlYWtFbmRWYXJpYW50VHlwZS5qYXZh) | `0% <0%> (-92.381%)` | `0% <0%> (-14%)` | |; | [...pleNovelAdjacencyAndChimericAlignmentEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/3655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5QW5kQ2hpbWVyaWNBbGlnbm1lbnRFdmlkZW5jZS5qYXZh) | `24.324% <0%> (-63.176%)` | `5% <0%> (-5%)` | |; | [...walkers/genotyper/GenotypingGivenAllelesUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nR2l2ZW5BbGxlbGVzVXRpbHMuamF2YQ==) | `28.571% <0%> (-32.967%)` | `2% <0%> (ø)` | |; | [...hellbender/tools/spark/pipelines/SortSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFNhbVNwYXJrLmphdmE=) | `70.588% <0%> (-29.412%)` | `4% <0%> (-2%)` | |; | [...ignment/AssemblyContigWithFineTunedAlignments.java](https://codecov.io/gh/broadinstitute/gatk/pull/3655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0Fzc2VtYmx5Q29udGlnV2l0aEZpbmVUdW5lZEFsaWdubWVudHMuamF2YQ==) | `70% <0%> (-22.248%)` | `33% <0%> (-26%)` | |; | [...itute/hellbender/tools/funcotator/Funcotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/3655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0aW9uLmphdmE=) | `33.333% <0%> (-22.222%)` | `3% <0%> (-2%)` | |; | [...decs/xsvLocatableTable/XsvLocatableTableCodec.java](https://codecov.io/gh/broadin,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3655#issuecomment-333907184:2887,pipeline,pipelines,2887,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3655#issuecomment-333907184,1,['pipeline'],['pipelines']
Deployability,"issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_; MarkDuplicates. ### Affected version(s); - [ ] Latest public release version [version?]; 4.6.0.0 GATK and Picard 3.2.0; - [ ] Latest master branch as of [date of test?]; 3 Jul 2023. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._; I'm trying to use gatk for finding snps in exome capture project. I get an error when trying to use MarkDuplicates - I tried using it from picard and from gatk. The screen output is:; ```; picard MarkDuplicates I=WA02_i5-537_i7-98_S11819_L004.bam O=test.dup.bam M=marked_dup_metrics.txt; INFO 2024-07-03 15:25:31 MarkDuplicates. ********** NOTE: Picard's command line syntax is changing.; **********; ********** For more information, please see:; **********; https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition); **********; ********** The command line looks like this in the new syntax:; **********; ********** MarkDuplicates -I WA02_i5-537_i7-98_S11819_L004.bam -O test.dup.bam -M marked_dup_metric",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8904:1322,release,release,1322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8904,1,['release'],['release']
Deployability,"ithub.com/broadinstitute/gsa-unstable/issues/1376#issuecomment-287822737). @SHuang-Broad @vruano Status update on this?. ---. @vruano commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1376#issuecomment-287916452). @SHuang-Broad this is not fixed by #1377 as this makes reference to the selection executed by the AFCalculator... it might be that @davidbenjamin now AF calculator addressed the issue, but is also possible that he avoid it it entirely and just focused in the new QUAL calculation. . ---. @vruano commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1376#issuecomment-287921195). Looking at the code I made reference in GATK3, it seem that it is still faulty... I guess we need to take a look on whether in GATK4 has been fixed and then back-ported if people are interested. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1376#issuecomment-287952396). Alright, thanks for the update. At this point we don't care too much about fixing it in GATK3; we're all about moving forward with GATK4. Do you want me to move this issue to GATK or do you already have an issue for this there?. ---. @davidbenjamin commented on [Wed Mar 22 2017](https://github.com/broadinstitute/gatk-protected/issues/950#issuecomment-288598906). The new qual score doesn't subset alleles at all because it doesn't need to. `AlleleSubsettingUtils` handles this upstream of the new qual. We're waiting on the HaplotypeCaller tie-out to eliminate the old qual from GATK 4, however. ---. @vdauwera commented on [Wed Mar 22 2017](https://github.com/broadinstitute/gatk-protected/issues/950#issuecomment-288599388). Ah, do I understand correctly that if the new qual checks out and the old one can be eliminated, this issue no longer applies?. ---. @davidbenjamin commented on [Wed Mar 22 2017](https://github.com/broadinstitute/gatk-protected/issues/950#issuecomment-288601472). Well, it's possible th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2958:4787,update,update,4787,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2958,1,['update'],['update']
Deployability,"itute/gatk/pull/2594?src=pr&el=h1) Report; > Merging [#2594](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/2ecdef4fba1658930c388676be3e388efd67b6a3?src=pr&el=desc) will **increase** coverage by `0.002%`.; > The diff coverage is `0%`. ```diff; @@ Coverage Diff @@; ## master #2594 +/- ##; ===============================================; + Coverage 75.985% 75.987% +0.003% ; - Complexity 11033 11034 +1 ; ===============================================; Files 769 769 ; Lines 40058 40058 ; Branches 6979 6979 ; ===============================================; + Hits 30438 30439 +1 ; Misses 6981 6981 ; + Partials 2639 2638 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tute/hellbender/tools/BwaMemIndexImageCreator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Cd2FNZW1JbmRleEltYWdlQ3JlYXRvci5qYXZh) | `71.429% <0%> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `95.313% <0%> (+1.563%)` | `22% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=footer). Last update [2ecdef4...a853f7c](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2594#issuecomment-293665515:1864,update,update,1864,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2594#issuecomment-293665515,2,['update'],['update']
Deployability,"itute/hellbender/tools/spark/pipelines/PrintReadsSpark.java) and performed following updates:; - Copied `./src/test/resources/org/broadinstitute/hellbender/utils/SequenceDictionaryUtils/test.vcf` into the local directory.; - Renamed the copy of `PrintReadsSpark.java` as `PrintVCFSpark.java`; - Added `import org.broadinstitute.hellbender.utils.variant.Variant;`; - Added `import org.broadinstitute.hellbender.engine.spark.datasources.VariantsSparkSource;`; - As a test, I changed to the `runTool` method with the following to print the information in the first element in the RDD:. ``` Java; JavaRDD<Variant> rddParallelVariants =; variantsSparkSource.getParallelVariants(output);. System.out.println( rddParallelVariants.first().toString() );; ```. And after re-compiling GATK and running `PrintVCFSpark`, I got the following to print the first element of the RDD:. ``` Bash; $ ./gatk-launch PrintVCFSpark --input test.vcf --output test.vcf. Running:; /home/pgrosu/me/hellbender_broad_institute/gatk/build/install/gatk/bin/gatk PrintVCFSpark --input test.vcf --output test.vcf; [February 14, 2016 7:04:16 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVCFSpark --output test.vcf --input test.vcf --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false; [February 14, 2016 7:04:16 PM EST] Executing as pgrosu on Linux 2.6.32-358.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_05-b13; Version: Version:4.alpha-86-g154d0a8-SNAPSHOT JdkDeflater; 19:04:16.098 INFO PrintVCFSpark - Initializing engine; 19:04:16.100 INFO PrintVCFSpark - Done initializing engine; 2016-02-14 19:04:17 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 2016-02-14 19:04:19 WARN MetricsSystem:71 - Using d",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1486#issuecomment-184011857:1334,install,install,1334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1486#issuecomment-184011857,1,['install'],['install']
Deployability,"iver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:39:19.246 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:39:19.246 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:39:19.246 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:39:19.246 INFO PathSeqPipelineSpark - Initializing engine; 17:39:19.246 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/04/24 17:39:19 INFO SparkContext: Running Spark version 2.2.0; 18/04/24 17:39:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/04/24 17:39:19 INFO SparkContext: Submitted application: PathSeqPipelineSpark; 18/04/24 17:39:20 INFO SecurityManager: Changing view acls to: username; 18/04/24 17:39:20 INFO SecurityManager: Changing modify acls to: username; 18/04/24 17:39:20 INFO SecurityManager: Changing view acls groups to:; 18/04/24 17:39:20 INFO SecurityManager: Changing modify acls groups to:; 18/04/24 17:39:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls di",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:6631,patch,patch,6631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['patch'],['patch']
Deployability,"iver.extraJavaOptions =; 17:54:55.320 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:54:55.320 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:54:55.321 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:54:55.321 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:54:55.321 DEBUG ConfigFactory - createOutputBamIndex = true; 17:54:55.321 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:54:55.321 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:54:55.321 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:54:55.321 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:54:55.321 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:54:55.321 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:54:55.321 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:54:55.321 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:54:55.321 INFO PathSeqPipelineSpark - Initializing engine; 17:54:55.321 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/04/24 17:54:55 INFO SparkContext: Running Spark version 2.2.0; 18/04/24 17:54:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/04/24 17:54:56 INFO SparkContext: Submitted application: PathSeqPipelineSpark; 18/04/24 17:54:56 INFO SecurityManager: Changing view acls to: userx; 18/04/24 17:54:56 INFO SecurityManager: Changing modify acls to: userx; 18/04/24 17:54:56 INFO SecurityManager: Changing view acls groups to:; 18/04/24 17:54:56 INFO SecurityManager: Changing modify acls groups to:; 18/04/24 17:54:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:7270,patch,patch,7270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['patch'],['patch']
Deployability,"jars, because it increases entropy on the distribution & support side of things. I would much prefer to see this resolved by project development branches. With the possibility of making project-specific nightly builds off of those branches, to enable pointing people to hot fixes for a specific toolset without taking in whatever else is going on in other projects. ---. @droazen commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215757315). Alright, to give an overview of where this stands, we have several options on the table for solving this problem:; 1. Split the GATK into even more repos (a CNV-only repo, a HaplotypeCaller repo) that are versioned separately. GATK release X would then consist of CNV version Y, HaplotypeCaller version Z, gatk-public version P, etc. This is probably the most ""correct"" solution from a software engineering perspective, but might be a nightmare to work with.; 2. Have the ability to release jars with a subset of the tools exposed to the user (eg., CNV-only jars). Geraldine hates this one, and it does seem like a bad idea to have these incomplete jars floating out in the wild.; 3. Everyone develops on separate branches, and merges to master only when everything in a branch is ""release-ready"". In this scenario master itself is always (theoretically, at least) ready for release. This solves the original problem of release of some tools being blocked by others, but creates some other problems: last-minute merge conflicts across dev teams, large amounts of code being held back for months while it undergoes testing, harder to share code across groups, more complex git workflows for everyone.; 4. Everyone is free to merge development versions of tools to master (as is currently the case), and most of the time we try to release everything in the GATK together. On rare occasions when, eg., CNV needs a release now and HC is not ready, we create a branch off of the last tagged release, cherry-pic",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:3446,release,release,3446,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,1,['release'],['release']
Deployability,java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19TdHJhbmRCaWFzVGVzdC5qYXZh) | `86.179% <0%> (+0.813%)` | `44% <0%> (+1%)` | :arrow_up: |; | [...spark/sv/evidence/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `69.583% <0%> (+0.833%)` | `60% <0%> (+1%)` | :arrow_up: |; | [...utils/test/ReadsPreprocessingPipelineTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRzUHJlcHJvY2Vzc2luZ1BpcGVsaW5lVGVzdERhdGEuamF2YQ==) | `0.862% <0%> (+0.862%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `93.194% <0%> (+1.047%)` | `61% <0%> (+2%)` | :arrow_up: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `73.118% <0%> (+1.075%)` | `25% <0%> (ø)` | :arrow_down: |; | [...e/hellbender/tools/spark/sv/utils/SVFileUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVkZpbGVVdGlscy5qYXZh) | `29.67% <0%> (+1.099%)` | `7% <0%> (ø)` | :arrow_down: |; | ... and [506 more](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4621#issuecomment-378027085:3674,Integrat,IntegrationTestSpec,3674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4621#issuecomment-378027085,1,['Integrat'],['IntegrationTestSpec']
Deployability,javadoc checks in `./gradlew install` should be turned off for now because it's just cluttering the output.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1955:29,install,install,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1955,1,['install'],['install']
Deployability,jbwa updates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1914:5,update,updates,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1914,1,['update'],['updates']
Deployability,"jdk.samtools.util.TempStreamFactory.wrapTempOutputStream(TempStreamFactory.java:74); at htsjdk.samtools.util.SortingCollection.spillToDisk(SortingCollection.java:223); at htsjdk.samtools.util.SortingCollection.add(SortingCollection.java:166); at htsjdk.samtools.SAMFileWriterImpl.addAlignment(SAMFileWriterImpl.java:192); at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:36); at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:16); at htsjdk.samtools.util.AbstractAsyncWriter$WriterRunnable.run(AbstractAsyncWriter.java:117); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.ClassNotFoundException: org.xerial.snappy.LoadSnappy; at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); ... 11 more. We can find snappy-java in <INST_DIR>/build/install/gatk/lib/snappy-java-1.1.1.7.jar, but it does not have a LoadSnappy class. Renaming the snappy-java jar file so gatk cannot find it allows FastqToSam to run through. ---. @akiezun commented on [Thu Jun 30 2016](https://github.com/broadinstitute/gatk-protected/issues/587#issuecomment-229843043). thanks for the report. Can you provide the whole commandline you used?. ---. @huangk3 commented on [Thu Sep 15 2016](https://github.com/broadinstitute/gatk-protected/issues/587#issuecomment-247467619). Hi @akiezun I experience the same error when running gate-launch FastqToSam. My command line is:; ""./gatk_launch FastqToSam -SM ""test"" -F1 $fq1 -F2 $fq2 -O test.spark.sam -SO coordinate -R $ref --STRIP_UNPAIRED_MATE_NUMBER true --VALIDATION_STRINGENCY LENIENT -PL ILLUMINA --CREATE_INDEX true"". My Spark version is 2.0.0; Thanks!. ---. @lbergelson commented on [Mon Sep 19 2016](https://github.com/broadinstitute/gatk-protected/issues/587#issuecomment-248086238). @huangk3 Unfortunately ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2868:2145,install,install,2145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2868,1,['install'],['install']
Deployability,jdk1.8.0_121\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\rt.jar;C:\project\push\target\classes;E:\repository\org\springframework\boot\spring-boot-starter-jdbc\2.3.0.RELEASE\spring-boot-starter-jdbc-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter\2.3.0.RELEASE\spring-boot-starter-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot\2.3.0.RELEASE\spring-boot-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-autoconfigure\2.3.0.RELEASE\spring-boot-autoconfigure-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-logging\2.3.0.RELEASE\spring-boot-starter-logging-2.3.0.RELEASE.jar;E:\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\repository\org\apache\logging\log4j\log4j-to-slf4j\2.13.2\log4j-to-slf4j-2.13.2.jar;E:\repository\org\apache\logging\log4j\log4j-api\2.13.2\log4j-api-2.13.2.jar;E:\repository\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;E:\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;E:\repository\org\yaml\snakeyaml\1.26\snakeyaml-1.26.jar;E:\repository\com\zaxxer\HikariCP\3.4.5\HikariCP-3.4.5.jar;E:\repository\org\springframework,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:2004,RELEASE,RELEASE,2004,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,"just curious, is deTin model already part of the GATK4 MuTect2 algorithm, or it has not been integrated yet?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3088#issuecomment-1887867443:93,integrat,integrated,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3088#issuecomment-1887867443,1,['integrat'],['integrated']
Deployability,"just curious, what's the reasoning for changing all the arguments from camel case to snake case (which seems to be the standard now)? that seems like a big swap across tools, without a lot of benefit, that's going to cause a lot of people to need to update existing scripts if they try to migrate from GATK3 to 4?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-433419539:250,update,update,250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-433419539,1,['update'],['update']
Deployability,"just to clarify, the weird mosaic examples are the bottom two plots out of the four above---you can see the shifted (non-X, in one of the examples) single peaks. However, it's interesting that the PARs are still showing up in XY---I'm pretty sure I used the blacklist you provided, although I will double check. Did that only include the ""official"" PARs, or also the additional ones you found?. In any case, are we comfortable calling in those regions (here I'm talking about gCNV, not ploidy)? As I show above, I don't think we need mappability to nail the baseline ploidy. Can we then rely on the per-bin bias to account for these regions in gCNV (pinning them back to the correct CN) without mappability filtering? And with mappability filtering, how substantial is the hit to coverage in these regions? Should we blacklist them for the time being?. To summarize, I think the order of events I'd like to see is this:. 1. Cut an **initial Beta** release that incorporates CollectReadCounts, streamline evaluations for the AACR poster, do a bit of tuning, establish a baseline. Hopefully the current ploidy calls suffice, if not, maybe issue a quick PR that implements the naive bin filtering (or whatever is necessary to get good ploidy calls). At the same time, get preliminary feedback from some users running on *small test cohorts* after we have some parameter recommendations.; 2. Do a round of method/model improvement. Start with quick and dirty fixes (e.g., blacklisting PARs) and work our way to more non-trivial changes. This will include many of the suggestions you have brought up, but we should also review user feedback and prioritize accordingly---they may find something that is not even on our radar. Demonstrate improvement (hopefully substantial!) over baseline, cut **second Beta** release.; 3. Run on larger cohorts, iron out remaining minor issues, and then productionize. By this time, @asmirnov239 will have hopefully made some progress on the PoN clustering front as well. *",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639:2352,release,release,2352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639,2,['release'],['release']
Deployability,"k - Initializing engine; 21:02:08.892 INFO PrintReadsSpark - Done initializing engine; 18/07/24 21:02:08 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 18/07/24 21:02:09 INFO org.spark_project.jetty.util.log: Logging initialized @6492ms; 18/07/24 21:02:09 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 18/07/24 21:02:09 INFO org.spark_project.jetty.server.Server: Started @6584ms; 18/07/24 21:02:09 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@42ecc554{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/07/24 21:02:09 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 18/07/24 21:02:09 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.9.0-hadoop2; 18/07/24 21:02:10 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at shuang-small-m/10.128.5.217:8032; 18/07/24 21:02:10 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at shuang-small-m/10.128.5.217:10200; 18/07/24 21:02:12 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1532457503538_0038; 21:02:16.702 INFO FeatureManager - Using codec BEDCodec to read file hdfs://shuang-small-m:8020/data/intervals.bed; 21:02:16.863 INFO IntervalArgumentCollection - Processing 1219 bp from intervals; 18/07/24 21:02:17 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1; 18/07/24 21:02:25 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 1.0 in stage 0.0 (TID 1, shuang-small-m.c.broad-dsde-methods.internal, exec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:7126,configurat,configuration,7126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['configurat'],['configuration']
Deployability,"k --java-options ""-Xmx48g -Xms48G"" GenomicsDBImport -V C1_sentieon_gvcf.gz .......... -V SCAU-106.gvcf.gz -V SCAU-107.gvcf.gz -V SCAU-108.gvcf.gz -V SCAU-128.gvcf.gz --genomicsdb-workspace-path my_database.chr01 -R IRGSP-1.0_genome.fasta --genomicsdb-vcf-buffer-size 16384000 --intervals chr01. 11:48:08.245 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/ayu/anaconda3/share/gatk4-4.0.5.1-0/gatk-package-4.0.5.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 11:48:09.327 INFO GenomicsDBImport - ------------------------------------------------------------; 11:48:09.327 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.0.5.1; 11:48:09.327 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:48:09.327 INFO GenomicsDBImport - Executing as ayu@ayu on Linux v5.15.90.1-microsoft-standard-WSL2 amd64; 11:48:09.327 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 11:48:09.327 INFO GenomicsDBImport - Start Date/Time: November 26, 2023 11:48:08 AM CST; 11:48:09.327 INFO GenomicsDBImport - ------------------------------------------------------------; 11:48:09.327 INFO GenomicsDBImport - ------------------------------------------------------------; 11:48:09.327 INFO GenomicsDBImport - HTSJDK Version: 2.15.1; 11:48:09.327 INFO GenomicsDBImport - Picard Version: 2.18.2; 11:48:09.327 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:48:09.327 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:48:09.327 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 11:48:09.327 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:48:09.327 INFO GenomicsDBImport - Deflater: IntelDeflater; 11:48:09.327 INFO GenomicsDBImport - Inflater: IntelInflater; 11:48:09.327 INFO GenomicsDBImport - GCS max retries/reopens: 20; 11:48:09.327 INFO GenomicsDBImport - Us",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8593:1887,release,release-,1887,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8593,1,['release'],['release-']
Deployability,k.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). **This is the stack I get when the test completes but fails (note that the expected line count appears to not match the line count of the expected output file in the repo): **. java.lang.AssertionError: line counts expected [2629] but found [507]; 	at org.testng.Assert.fail(Assert.java:94); 	at org.testng.Assert.failNotEquals(Assert.java:496); 	at org.testng.Assert.assertEquals(Assert.java:125); 	at org.testng.Assert.assertEquals(Assert.java:372); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:211); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:190); 	at org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.testExampleAssemblyRegionWalker(ExampleAssemblyRegionWalkerSparkIntegrationTest.java:29); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:3577,Integrat,IntegrationTestSpec,3577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['Integrat'],['IntegrationTestSpec']
Deployability,k/build/libs/gatk-spark.jar; Running:; /usr/lib/spark/bin/spark-submit --master yarn --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /home/hadoop/gatk/build/libs/gatk-spark.jar HaplotypeCallerSpark -I hdfs:///user/hadoop/testdata/TestData -R hdfs:///user/hadoop/reference/hg38.fasta -O hdfs:///user/hadoop/output/testgatkvcf.vcf --spark-master yarn; 19/04/08 19:01:40 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19:01:43.413 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:01:43.565 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/hadoop/gatk/build/libs/gatk-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 19:01:43.728 INFO HaplotypeCallerSpark - ------------------------------------------------------------; 19:01:43.729 INFO HaplotypeCallerSpark - The Genome Analysis Toolkit (GATK) v4.1.1.0-10-g554a0e8-SNAPSHOT; 19:01:43.729 INFO HaplotypeCallerSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:01:43.729 INFO HaplotypeCallerSpark - Executing as hadoop@ip-xx.xx.xx.xx on Linux v4.9,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869:1467,configurat,configuration,1467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869,1,['configurat'],['configuration']
Deployability,k/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...g/broadinstitute/hellbender/utils/NativeUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9OYXRpdmVVdGlscy5qYXZh) | `25% <0%> (-43.75%)` | `3% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `43.75% <0%> (-29.861%)` | `27% <0%> (-9%)` | |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `76.471% <0%> (-23.529%)` | `4% <0%> (ø)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (ø)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-279424649:3504,pipeline,pipelines,3504,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-279424649,2,['pipeline'],['pipelines']
Deployability,"k/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `86.025% <0%> (+4.561%)` | `30% <0%> (+6%)` | :arrow_up: |; | [...ute/hellbender/tools/spark/bwa/BwaSparkEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmtFbmdpbmUuamF2YQ==) | `94.805% <0%> (+4.805%)` | `8% <0%> (+3%)` | :arrow_up: |; | [...titute/hellbender/tools/spark/sv/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkTWV0YWRhdGEuamF2YQ==) | `89.297% <0%> (+7.018%)` | `33% <0%> (+11%)` | :arrow_up: |; | [...ute/hellbender/utils/bwa/BwaMemAlignmentUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9id2EvQndhTWVtQWxpZ25tZW50VXRpbHMuamF2YQ==) | `85.507% <0%> (+13.093%)` | `17% <0%> (+1%)` | :arrow_up: |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `55.233% <0%> (+14.764%)` | `38% <0%> (+10%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=footer). Last update [d054e7a...8ecb688](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2581#issuecomment-292631877:4004,update,update,4004,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2581#issuecomment-292631877,2,['update'],['update']
Deployability,kDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `94.872% <100%> (+0.427%)` | `38 <9> (+4)` | :arrow_up: |; | [...pipelines/metrics/CollectMultipleMetricsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0TXVsdGlwbGVNZXRyaWNzU3BhcmsuamF2YQ==) | `92.593% <100%> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...k/pipelines/metrics/MetricsCollectorSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZXRyaWNzQ29sbGVjdG9yU3BhcmtUb29sLmphdmE=) | `75% <100%> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...ark/pipelines/metrics/MeanQualityByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZWFuUXVhbGl0eUJ5Q3ljbGVTcGFyay5qYXZh) | `90.816% <100%> (ø)` | `11 <0> (ø)` | :arrow_down: |; | [...s/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0QmFzZURpc3RyaWJ1dGlvbkJ5Q3ljbGVTcGFyay5qYXZh) | `87.037% <100%> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `82.286% <76.923%> (-0.147%)` | `78 <9> (+10)` | |; | [.../pipelines/MarkDuplicatesSparkIntegrationTest.java](https:/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5430#issuecomment-442613021:2282,pipeline,pipelines,2282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5430#issuecomment-442613021,1,['pipeline'],['pipelines']
Deployability,"ker.traverse(VariantWalker.java:102); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); ```; ### User Question [(LINK)](https://gatkforums.broadinstitute.org/gatk/discussion/24446/genomicsdbimport-not-completing-for-mixed-ploidy-samples/p1); ----------; I'm attempting to call variants on whole genomes for about 500 illumina paired-end samples with varying ploidy (haploid to tetraploid). I'm running a fairly standard uBam to GVCF pipeline with HaplotypeCaller passed the ploidy information (1,2,3, or 4) in -ERC GVCF mode. I then try to collect the GVCFs using GenomicsDBImport in a batch size of 50 and use GenotypeGVCFs on the combined database. My interval list that is passed to GenomicsDBImport is just each chromosome on a separate line. I'm using GATK v4.1.1.0<br />; <br />; Command:<br />; ```<br />; ${GATK_DIR}/gatk GenomicsDBImport \<br />; --java-options ""-Xmx110g -Xms110g"" \<br />; -R ${REF} \<br />; --variant ${FILE_LIST} \<br />; -L ${SCRIPT_DIR}/GATK_Style_Interval.list \<br />; --genomicsdb-workspace-path ${WORK_DIR}/GenomicsDB_20190912 \<br />; --batch-size 50 \<br />; --tmp-dir=${WORK_DIR}/<br />; ```<br />; <br />; GenomicsDBImport appears to run without error, but only shows progress for the first 6000 bp before moving onto the next batch. When I run select variants on the created database, I only get variants up to position 6716 in the first interval. When I try to run GenotypeGVCF on it, I get a strange error:<br />; h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275:3232,pipeline,pipeline,3232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275,1,['pipeline'],['pipeline']
Deployability,killed. Any suggestions for this? . Below is some stage info.... Stage 7	. collect at FindBreakpointEvidenceSpark.java:738 +details. org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45); org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.getKmerIntervals(FindBreakpointEvidenceSpark.java:738); org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.getKmerAndIntervalsSet(FindBreakpointEvidenceSpark.java:532); org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.addAssemblyQNames(FindBreakpointEvidenceSpark.java:489); org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.gatherEvidenceAndWriteContigSamFile(FindBreakpointEvidenceSpark.java:174); org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark.runTool(StructuralVariationDiscoveryPipelineSpark.java:147); org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:387); org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:159); org.broadinstitute.hellbender.Main.mainEntry(Main.java:202); org.broadinstitute.hellbender.Main.main(Main.java:288); sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); java.lang.reflect.Method.invoke(Method.java:498); org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:637),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4635:2131,deploy,deploy,2131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4635,1,['deploy'],['deploy']
Deployability,"kka.frameSize=512 --conf spark.akka.threads=10 --conf spark.executor.memory=50g --conf spark.driver.memory=150g --conf spark.local.dir=/gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2Spark/1024cores/tmp --class org.broadinstitute.hellbender.Main /gpfs/software/genomics/GATK/4b.2/gatk/build/libs/hellbender-spark.jar HaplotypeCaller --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa --input /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2/bam//NA12892.recal.bam --dbsnp /gpfs/projects/NAGA/naga/SparkTest/SPARKCALLER/REF/dbsnp_138.vcf --emitRefConfidence GVCF --readValidationStringency LENIENT --nativePairHmmThreads 1024 --createOutputVariantIndex true --output NA12892.raw.snps.indels.g.vcf; [August 9, 2017 10:13:02 AM AST] HaplotypeCaller --nativePairHmmThreads 1024 --dbsnp /gpfs/projects/NAGA/naga/SparkTest/SPARKCALLER/REF/dbsnp_138.vcf --emitRefConfidence GVCF --output NA12892.raw.snps.indels.g.vcf --input /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2/bam//NA12892.recal.bam --readValidationStringency LENIENT --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa --createOutputVariantIndex true --group StandardAnnotation --group StandardHCAnnotation --GVCFGQBands 1 --GVCFGQBands 2 --GVCFGQBands 3 --GVCFGQBands 4 --GVCFGQBands 5 --GVCFGQBands 6 --GVCFGQBands 7 --GVCFGQBands 8 --GVCFGQBands 9 --GVCFGQBands 10 --GVCFGQBands 11 --GVCFGQBands 12 --GVCFGQBands 13 --GVCFGQBands 14 --GVCFGQBands 15 --GVCFGQBands 16 --GVCFGQBands 17 --GVCFGQBands 18 --GVCFGQBands 19 --GVCFGQBands 20 --GVCFGQBands 21 --GVCFGQBands 22 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3631:3577,pipeline,pipeline,3577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631,1,['pipeline'],['pipeline']
Deployability,"known problem: doesn't generate a VCF yet, but a custom file format for demonstration purpose. ; Translating from the custom file format to annotated VCF records is no difficult task, if the reported format is agreed to. **UPDATE**; now emits an VCF after commit 9110a5aef8ad60ba30a032567c64b0e7e406e59f",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-342524770:223,UPDATE,UPDATE,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-342524770,1,['UPDATE'],['UPDATE']
Deployability,kson-datatype-jsr310-2.11.0.jar;E:\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.11.0\jackson-module-parameter-names-2.11.0.jar;E:\repository\org\springframework\boot\spring-boot-starter-tomcat\2.3.0.RELEASE\spring-boot-starter-tomcat-2.3.0.RELEASE.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.35\tomcat-embed-core-9.0.35.jar;E:\repository\org\glassfish\jakarta.el\3.0.3\jakarta.el-3.0.3.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.35\tomcat-embed-websocket-9.0.35.jar;E:\repository\org\springframework\spring-web\5.2.6.RELEASE\spring-web-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-webmvc\5.2.6.RELEASE\spring-webmvc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\repository\org\springframework\spring-core\5.2.6.RELEASE\spring-core-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-jcl\5.2.6.RELEASE\spring-jcl-5.2.6.RELEASE.jar;E:\repository\com\google\firebase\firebase-admin\6.8.1\firebase-admin-6.8.1.jar;E:\repository\com\google\api-client\google-api-client\1.25.0\google-api-client-1.25.0.jar;E:\repository\com\google\oauth-client\google-oauth-client\1,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:4953,RELEASE,RELEASE,4953,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,"l clock 76 hours); Test 1 ran slower and required more memory 40-50% of 256GB (Wall Clock 94 hours); Test 3 ran initially faster with less memory than test 1 but by batch 65 it was using 75% of 384 GB. This job has not finished and appears stuck on importing batch 65. So the consolidate option appears to have a memory leak or using just requiring too much memory. The -consolidate option was the culprit. So rerunning chr1-3 with just the --bypass-feature-reader option (test2) ran fine without lots of memory being used. Below is the time output from chr1. The output shows the Maximum resident set size (kbytes): **2630440**. Using GATK jar /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar defined in environment variable GATK_LOCAL_JAR; ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx200g -Xms16g -jar /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenomicsDBImport --sample-name-map sample_map.chr1 --genomicsdb-workspace-path genomicsDB.rb.bypass.time.chr1 --genomicsdb-shared-posixfs-optimizations True --tmp-dir tmp --bypass-feature-reader --L chr1 --batch-size 50 --reader-threads 4 --overwrite-existing-genomicsdb-workspace; Command being timed: ""gatk --java-options -Xmx200g -Xms16g GenomicsDBImport --sample-name-map sample_map.chr1 --genomicsdb-workspace-path genomicsDB.rb.bypass.time.chr1 --genomicsdb-shared-posixfs-optimizations True --tmp-dir tmp --bypass-feature-reader --L chr1 --batch-size 50 --reader-threads 4 --overwrite-existing-genomicsdb-workspace""; User time (seconds): 270716.45; System time (seconds): 1723.34; Percent of CPU this job got: 99%; Elapsed (wall clock) time (h:mm:ss or m:ss): 76:08:24; Average shared text size (kbytes): 0; Average unshared data size (kbytes): 0; Average stack size (kbytes): 0; Average total size (kbytes): 0; Maximum resident set size (kbytes): ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1252598687:1722,install,install,1722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1252598687,2,['install'],['install']
Deployability,"l.ServiceLoader;. @CommandLineProgramProperties(summary = ""test"", oneLineSummary = ""testthing"", programGroup = SparkProgramGroup.class); public class TestGCS extends GATKSparkTool {; private static final long serialVersionUID = 1L;. @Override; protected void runTool(JavaSparkContext ctx) {; try {; modifyProviders();; } catch (IllegalAccessException | NoSuchFieldException e) {; throw new RuntimeException(""Couldn't reset FilesystemProviders"");; }; try {; final Path index = Paths.get(new URI(""gs://hellbender/test/build_reports/1626.1/tests/index.html""));; System.out.println(""Count:"" + Files.lines(index).count());; } catch (URISyntaxException | IOException e) {; throw new RuntimeException(""Couldn't read file"");; }; }; }. private void modifyProviders() throws IllegalAccessException, NoSuchFieldException {; final Field installedProviders = FileSystemProvider.class.getDeclaredField(""installedProviders"");; installedProviders.setAccessible(true);; installedProviders.set(null, loadInstalledProviders());; installedProviders.setAccessible(false);; }. //copied from FileSystemProvider, modified to use TestGCS.classLoader() instead of systemClassloader; private static List<FileSystemProvider> loadInstalledProviders() {; List<FileSystemProvider> list = new ArrayList<FileSystemProvider>();. ServiceLoader<FileSystemProvider> sl = ServiceLoader; .load(FileSystemProvider.class, TestGCS.class.getClassLoader());. // ServiceConfigurationError may be throw here; for (FileSystemProvider provider: sl) {; String scheme = provider.getScheme();. // add to list if the provider is not ""file"" and isn't a duplicate; if (!scheme.equalsIgnoreCase(""file"")) {; boolean found = false;; for (FileSystemProvider p: list) {; if (p.getScheme().equalsIgnoreCase(scheme)) {; found = true;; break;; }; }; if (!found) {; list.add(provider);; }; }; }; return list;; }; }; ```. We'd have to add an initial action to GATKSparkTool that would run `modifyProviders` once on each executor which may be a bit of a trick on it'",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2312:1998,install,installedProviders,1998,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2312,1,['install'],['installedProviders']
Deployability,"l.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); ```. ### Second Example; This user is running multiple chromosomes at a time in parallel; Please see this link for more info: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072732791-Import-GVCFs-using-GenomicsDBImport-one-chromosome-at-a-time-and-parallel-the-jobs-encounter-a-Duplicate-Sample-Name-Error?page=1#community_comment_360012681711. `time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport --tmp-dir /paedwy/disk1/yangyxt/test_tmp --genomicsdb-update-workspace-path ${probe_dir}/genomicdbimport_chr${1} -R ${ref_gen}/ucsc.hg19.fasta --batch-size 0 --sample-name-map ${gvcf}/batch_cohort.sample_map --reader-threads 5 --intervals chr${1}`. ```; 01:07:01.704 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 29, 2020 1:07:01 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 01:07:02.001 INFO GenomicsDBImport - ------------------------------------------------------------; 01:07:02.002 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.8.1; 01:07:02.002 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 01:07:02.002 INFO GenomicsDBImport - Executing as yangyxt@paedwy01 on Linux v3.10.0-957.10.1.el7.x86_6",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793:10049,update,update-workspace-path,10049,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793,1,['update'],['update-workspace-path']
Deployability,l.writeReads(GATKSparkTool.java:259); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:39); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:730); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Shutdown hook called; 17/10/11 14:19:38 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.; 17/10/11 14:19:38 INFO util.ShutdownHookManager: Deleting directory /tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:37916,deploy,deploy,37916,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,6,['deploy'],['deploy']
Deployability,"l=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50cy5qYXZh) | `80% <100%> (ø)` | `119 <0> (ø)` | :arrow_down: |; | [...nder/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `46.491% <20%> (-0.411%)` | `32 <0> (ø)` | |; | [...ls/walkers/genotyper/afcalc/ExactAFCalculator.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `81.818% <50%> (-8.182%)` | `6 <3> (+3)` | |; | [...stitute/hellbender/utils/genotyper/AlleleList.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvQWxsZWxlTGlzdC5qYXZh) | `89.744% <0%> (+1.282%)` | `16% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2528?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2528?src=pr&el=footer). Last update [c62914a...cc1b2b9](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2528#issuecomment-288859643:4067,update,update,4067,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2528#issuecomment-288859643,2,['update'],['update']
Deployability,l=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9tY21jL1BhcmFtZXRlcldyaXRlci5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | [...roadinstitute/hellbender/utils/svd/SVDFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zdmQvU1ZERmFjdG9yeS5qYXZh) | `0% <0%> (-85.714%)` | `0% <0%> (-3%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...broadinstitute/hellbender/utils/read/GATKRead.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL0dBVEtSZWFkLmphdmE=) | `31.25% <0%> (-68.75%)` | `7% <0%> (-6%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...titute/hellbender/engine/spark/JsonSerializer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvSnNvblNlcmlhbGl6ZXIuamF2YQ==) | `0% <0%> (-63.636%)` | `0% <0%> (-4%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | ... and [890 more](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3494#issuecomment-324476830:2964,pipeline,pipelines,2964,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3494#issuecomment-324476830,1,['pipeline'],['pipelines']
Deployability,laria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/callset.json; 01:25:02.077 INFO GenomicsDBImport - Complete VCF Header will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vcfheader.vcf; 01:25:02.077 INFO GenomicsDBImport - Importing to workspace - /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb; 01:25:02.078 INFO ProgressMeter - Starting traversal; 01:25:02.078 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); 01:25:43.661 INFO GenomicsDBImport - Starting batch input file preload; 01:26:19.244 INFO GenomicsDBImport - Finished batch preload; 01:26:19.244 INFO GenomicsDBImport - Importing batch 1 with 2 samples; 01:30:20.226 INFO ProgressMeter - unmapped 5.3 1 0.2; 01:30:20.226 INFO GenomicsDBImport - Done importing batch 1/1; 01:30:20.227 INFO ProgressMeter - unmapped 5.3 1 0.2; 01:30:20.227 INFO ProgressMeter - Traversal complete. Processed 1 total batches in 5.3 minutes.; 01:30:20.227 INFO GenomicsDBImport - Import of all batches to GenomicsDB completed!; 01:30:20.227 INFO GenomicsDBImport - Shutting down engine; [10 December 2021 01:30:20 UTC] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 7.76 minutes.; Runtime.totalMemory()=16078340096; ```. #### Steps to reproduce. Not sure if it repr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7598:4478,update,update,4478,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7598,1,['update'],['update']
Deployability,"latest master 4353d54fd2d64ea1b4c8429986f83eb873a4d687. `/gatk-launch CountReadsSpark -I src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam`. ```; [May 18, 2016 5:10:55 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=318242816; java.net.BindException: Failed to bind to: /10.1.5.39:0: Service 'sparkDriver' failed after 16 retries!; at org.jboss.netty.bootstrap.ServerBootstrap.bind(ServerBootstrap.java:272); at akka.remote.transport.netty.NettyTransport$$anonfun$listen$1.apply(NettyTransport.scala:393); at akka.remote.transport.netty.NettyTransport$$anonfun$listen$1.apply(NettyTransport.scala:389); at scala.util.Success$$anonfun$map$1.apply(Try.scala:206); at scala.util.Try$.apply(Try.scala:161); at scala.util.Success.map(Try.scala:206); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.co",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1839:233,pipeline,pipelines,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1839,1,['pipeline'],['pipelines']
Deployability,"lbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `88% <86.667%> (-12%)` | `7 <2> (+7)` | |; | [...ute/hellbender/tools/spark/bwa/BwaSparkEngine.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmtFbmdpbmUuamF2YQ==) | `89.286% <88%> (+18.697%)` | `5 <5> (+5)` | :white_check_mark: |; | [...itute/hellbender/tools/spark/sv/ContigAligner.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9Db250aWdBbGlnbmVyLmphdmE=) | `88.462% <88.889%> (+6.643%)` | `8 <4> (+8)` | :white_check_mark: |; | [...g/broadinstitute/hellbender/utils/NativeUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9OYXRpdmVVdGlscy5qYXZh) | `25% <ø> (-43.75%)` | `3% <ø> (+3%)` | |; | ... and [96 more](https://codecov.io/gh/broadinstitute/gatk/pull/2367/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2367?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2367?src=pr&el=footer). Last update [9d82097...975121e](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2367#issuecomment-276460872:5165,update,update,5165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2367#issuecomment-276460872,2,['update'],['update']
Deployability,lbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:111); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:169); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:120); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:141); 	at org.broadinstitute.hellbender.Main.main(Main.java:196); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:728); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Invalid splitting BAM index: should contain at least 1 offset and the file size; 	at org.seqdoop.hadoop_bam.SplittingBAMIndex.readIndex(SplittingBAMIndex.java:69); 	at org.seqdoop.hadoop_bam.SplittingBAMIndex.<init>(SplittingBAMIndex.java:49); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeSplittingBaiFiles(SAMFileMerger.java:117); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:152); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:119); 	at org.broadinstitute.hellb,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2503:1406,deploy,deploy,1406,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2503,1,['deploy'],['deploy']
Deployability,"lbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:111); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:169); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:218); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: GCS FileSystem URIs mustn't have: port, userinfo, path, query, or fragment: gs://broad-gatk-test-jenkins/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam; 	at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:192); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:83); 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:336); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:40); 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:140); 	at org.seqdoop.hadoop_bam.BAMInputFormat.cre",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337:4109,deploy,deploy,4109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337,1,['deploy'],['deploy']
Deployability,lbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.NegativeArraySizeException; 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.resize(IdentityObjectIntMap.java:447); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.putStash(IdentityObjectIntMap.java:245); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:239); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:135); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.putStash(IdentityObjectIntMap.java:246); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:239); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:135); 	at com.esotericsoftware.kryo.util.MapReferenceResolver.addWrittenObject(MapReferenceResolver.java:41); 	at co,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3303:4574,deploy,deploy,4574,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3303,1,['deploy'],['deploy']
Deployability,lbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:220); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.NoSuchFileException: jonn-test-bucket/foo.bam.parts; 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:575); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219); 	at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276); 	at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322); 	at java.nio.file.FileTreeIterator.<init>(FileTreeIterator.java:72); 	at java.nio.file.Files.walk(Files.java:3574); 	at java.nio.file.Files.walk(Files.java:3625); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.getFilesMatching(NIOFileUtil.java:91); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:61); 	at org.broadinstitute.he,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2793:2231,deploy,deploy,2231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2793,1,['deploy'],['deploy']
Deployability,lbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:218); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: No enum constant com.google.cloud.storage.StorageClass.DURABLE_REDUCED_AVAILABILITY; 	at java.lang.Enum.valueOf(Enum.java:238); 	at com.google.cloud.storage.StorageClass.valueOf(StorageClass.java:22); 	at com.google.cloud.storage.BlobInfo.fromPb(BlobInfo.java:940); 	at com.google.cloud.storage.Blob.fromPb(Blob.java:779); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:189); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:197); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:571); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.Files.isDirectory(Files.java:2192); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346); 	,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2517:2128,deploy,deploy,2128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2517,1,['deploy'],['deploy']
Deployability,lbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.htt,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591:3402,deploy,deploy,3402,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591,1,['deploy'],['deploy']
Deployability,lbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:152); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:175); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:161); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.htt,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994:8968,deploy,deploy,8968,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994,1,['deploy'],['deploy']
Deployability,lbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadinstitute.hellbender.Main.main(Main.java:275); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.ContigAlignmentsModifier.removeOverlap(ContigAlignmentsModifier.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.AssemblyContigAlignmentSignatureClassifier.lambda$processContigsWithTwoAlignments$e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.ne,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:12643,deploy,deploy,12643,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['deploy'],['deploy']
Deployability,"lbmRlci91dGlscy9waWxldXAvUGlsZXVwRWxlbWVudC5qYXZh) | `96.04% <0%> (+1.865%)` | `76 <0> (ø)` | :arrow_down: |; | [...bender/tools/exome/HashedListTargetCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9IYXNoZWRMaXN0VGFyZ2V0Q29sbGVjdGlvbi5qYXZh) | `90.741% <0%> (+1.65%)` | `43 <0> (ø)` | :arrow_down: |; | [.../utils/read/markduplicates/DuplicationMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL0R1cGxpY2F0aW9uTWV0cmljcy5qYXZh) | `85.366% <0%> (+2.033%)` | `13 <0> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/read/CigarUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL0NpZ2FyVXRpbHMuamF2YQ==) | `89.404% <0%> (+0.588%)` | `68 <0> (ø)` | :arrow_down: |; | [...der/utils/locusiterator/AlignmentStateMachine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9sb2N1c2l0ZXJhdG9yL0FsaWdubWVudFN0YXRlTWFjaGluZS5qYXZh) | `87.879% <0%> (+1.312%)` | `27 <1> (ø)` | :arrow_down: |; | ... and [22 more](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=footer). Last update [62d58c5...cd59cde](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2543#issuecomment-290171890:4428,update,update,4428,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2543#issuecomment-290171890,2,['update'],['update']
Deployability,"le ""${INSTALLDIRGATK}/bin/theano-nose"", line 11, in <module>; load_entry_point('Theano==1.0.4', 'console_scripts', 'theano-nose')(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 207, in main; result = main_function(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 45, in main_function; from theano import config; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/__init__.py"", line 110, in <module>; from theano.compile import (; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/__init__.py"", line 12, in <module>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 140, in <module>; preargs=args); File ${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2396, in compile_str; (status, compile_stderr.replace('\n', '. '))); Exception: Compilation failed (return status=1): /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_deregisterTMCloneTable. /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_registerTMCloneTable. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x1a): error: unsupported reloc 42. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x6b): error: unsupported reloc 42. collect2: error: ld returned 1 exit status. ```. Then I have installed theano with python 3.6.6 which is compiled with gcc 5.4.0, and it was giving me no errors. ```sh. $ theano-nose . -------------------------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:2733,INSTALL,INSTALLDIRGATK,2733,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['INSTALL'],['INSTALLDIRGATK']
Deployability,"le.map -R /scratch/PI/boip/Reference/Human_genome/GRCh37/hs37d5.fa --batch-size 400 --reader-threads 5; 14:48:08.923 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/hcaoad/miniconda2/share/gatk4-4.2.0.0-0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Apr 16, 2021 2:48:09 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:48:09.080 INFO GenomicsDBImport - ------------------------------------------------------------; 14:48:09.081 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.2.0.0; 14:48:09.081 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:48:09.081 INFO GenomicsDBImport - Executing as hcaoad@hhnode-ib-46 on Linux v3.10.0-1062.el7.x86_64 amd64; 14:48:09.081 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 14:48:09.081 INFO GenomicsDBImport - Start Date/Time: April 16, 2021 2:48:08 PM HKT; 14:48:09.081 INFO GenomicsDBImport - ------------------------------------------------------------; 14:48:09.081 INFO GenomicsDBImport - ------------------------------------------------------------; 14:48:09.081 INFO GenomicsDBImport - HTSJDK Version: 2.24.0; 14:48:09.081 INFO GenomicsDBImport - Picard Version: 2.25.0; 14:48:09.081 INFO GenomicsDBImport - Built for Spark Version: 2.4.5; 14:48:09.081 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:48:09.081 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:48:09.081 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:48:09.082 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:48:09.082 INFO GenomicsDBImport - Deflater: IntelDeflater; 14:48:09.082 INFO GenomicsDBImport - Inflater: IntelInflater; 14:48:09.082 INFO GenomicsDBImport - GCS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7218:5673,release,release-,5673,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7218,1,['release'],['release-']
Deployability,"ledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '62379' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3633423' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3633419' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3633423' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3633419' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; `. And there isn't a `lock_dir` under the specified path, but there are a bunch of tmp dirs like . `; tmp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7411#issuecomment-905060709:2218,release,release,2218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7411#issuecomment-905060709,1,['release'],['release']
Deployability,"ler - Start Date/Time: July 25, 2018 10:56:24 AM CEST; 10:56:25.348 INFO GermlineCNVCaller - ------------------------------------------------------------; 10:56:25.349 INFO GermlineCNVCaller - ------------------------------------------------------------; 10:56:25.350 INFO GermlineCNVCaller - HTSJDK Version: 2.15.1; 10:56:25.351 INFO GermlineCNVCaller - Picard Version: 2.18.2; 10:56:25.352 INFO GermlineCNVCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:56:25.353 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:56:25.354 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:56:25.355 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:56:25.356 INFO GermlineCNVCaller - Deflater: IntelDeflater; 10:56:25.357 INFO GermlineCNVCaller - Inflater: IntelInflater; 10:56:25.358 INFO GermlineCNVCaller - GCS max retries/reopens: 20; 10:56:25.358 INFO GermlineCNVCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 10:56:25.360 WARN GermlineCNVCaller -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: GermlineCNVCaller is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 10:56:25.361 INFO GermlineCNVCaller - Initializing engine; 10:56:54.347 INFO GermlineCNVCaller - Done initializing engine; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 10:56:55.287 INFO GermlineCNVCaller - Retrieving intervals from first read-count file (hdf5/grexome0426.hdf5)...; 10:56:55.384 INFO GermlineCNVCaller - No GC-content annotations for intervals found; explicit GC-bias correction will not be performed...; 10:56:55.482 INFO GermlineCNVC",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053:2367,patch,patch,2367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053,1,['patch'],['patch']
Deployability,les 1930 1930 ; Lines 145233 145355 +122 ; Branches 16095 16142 +47 ; ==============================================; - Hits 126483 126297 -186 ; - Misses 12898 13237 +339 ; + Partials 5852 5821 -31; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3866?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ils/nio/NioFileCopierWithProgressMeterResults.java](https://codecov.io/gh/broadinstitute/gatk/pull/3866/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyUmVzdWx0cy5qYXZh) | `0% <0%> (-94.737%)` | `0% <0%> (-9%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3866/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3866/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...ols/funcotator/FuncotatorDataSourceDownloader.java](https://codecov.io/gh/broadinstitute/gatk/pull/3866/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JEYXRhU291cmNlRG93bmxvYWRlci5qYXZh) | `0% <0%> (-66.197%)` | `0% <0%> (-14%)` | |; | [...nder/utils/nio/NioFileCopierWithProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3866/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyLmphdmE=) | `17% <0%> (-52.5%)` | `9% <0%> (-30%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3866/d,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3866#issuecomment-346238168:1576,pipeline,pipelines,1576,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3866#issuecomment-346238168,1,['pipeline'],['pipelines']
Deployability,"librator - ------------------------------------------------------------; 13:35:32.892 INFO BaseRecalibrator - HTSJDK Version: 2.24.1; 13:35:32.892 INFO BaseRecalibrator - Picard Version: 2.27.1; 13:35:32.893 INFO BaseRecalibrator - Built for Spark Version: 2.4.5; 13:35:32.893 INFO BaseRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:35:32.893 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:35:32.893 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:35:32.893 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:35:32.893 INFO BaseRecalibrator - Deflater: IntelDeflater; 13:35:32.893 INFO BaseRecalibrator - Inflater: IntelInflater; 13:35:32.894 INFO BaseRecalibrator - GCS max retries/reopens: 20; 13:35:32.894 INFO BaseRecalibrator - Requester pays: disabled; 13:35:32.894 INFO BaseRecalibrator - Initializing engine; 13:35:33.276 INFO FeatureManager - Using codec VCFCodec to read file file:///data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz; 13:35:33.545 INFO FeatureManager - Using codec VCFCodec to read file file:///data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz; 13:35:33.884 INFO FeatureManager - Using codec VCFCodec to read file file:///data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz; 13:35:34.129 WARN IndexUtils - Feature file ""file:///data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 13:35:34.232 WARN IntelInflater - Zero Bytes Written : 0; 13:35:34.282 INFO BaseRecalibrator - Done initializing engine; 13:35:34.285 INFO BaseRecalibrationEngine - The covariates being used here:; 13:35:34.285 INFO BaseRecalibrationEngine - 	ReadGroupCovariate; 13:35:34.285 INFO BaseRecalibrationEngine - 	QualityScoreCovariate; 13:35:34.285 INFO BaseRecalibrationEngine - 	C",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:3653,pipeline,pipeline,3653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,librator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; Using GATK jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -Djava.io.tmpdir=./ -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; 13:46:24.742 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:46:24.761 WARN NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (No such file or directory); 13:46:24.764 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:46:24.764 WARN NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (No such file or directory); 13:46:24.884 INFO BaseRecalibrator - --,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:12496,pipeline,pipeline,12496,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,"lizeToolInputs(GATKSparkTool.java:264); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:255); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66); at org.broadinstitute.hellbender.Main.main(Main.java:81); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/01/21 14:55:33 INFO ShutdownHookManager: Shutdown hook called; ```. Attached is a small BAM file that I used to reproduce the error (If memory serves, I've seen this issue on other BAM files as well):. [NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip](https://github.com/broadinstitute/gatk/files/101575/NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip). (This issue may be related to one posted here: https://github.com/broadinstitute/gatk/issues/1417.). Here is some information on what I installed:. ```; echo ""Installing Java""; sudo add-apt-repository -y ppa:webupd8team/java; sudo apt-get -qq update;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1444:2969,deploy,deploy,2969,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1444,1,['deploy'],['deploy']
Deployability,lizer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:11.507 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.508 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:35:11.508 INFO CountReadsSpark - For support and documentat,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:1703,configurat,configuration,1703,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['configurat'],['configuration']
Deployability,"llbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; #### Steps to reproduce; `gatk HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz`. The cram is HG0096.final.cram found here:. https://www.internationalgenome.org/data-portal/data-collection/30x-grch38. #### Expected behavior; When I run an earlier version v4.1.7.0, it runs without an error.... ```; gatk HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz; Using GATK jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz; 14:40:45.497 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 10, 2021 2:40:45 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:40:45.786 INFO HaplotypeCaller - ------------------------------------------------------------; 14:40:45.787 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.7.0; 14:40:45.787 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7076:5487,install,install,5487,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7076,1,['install'],['install']
Deployability,"llectFragmentOverlaps - same filters as CollectFragmentCounts, but adding counts to all bins overlapping each fragment. Note that we need to implement a filter on maximum fragment length, otherwise we get some strange artifacts from (incorrectly mapped?) extremely long fragments; I arbitrarily chose a cutoff of 10000bp. This recovered events 1 and 2. Event 3 seemed to be the most difficult to recover. Plotting the copy ratios surrounding this event (which spans ~15 100bp bins) yields some insights:. CollectFragmentCounts:; ![image](https://user-images.githubusercontent.com/11076296/37244188-317a7f1e-2453-11e8-937d-f7239354316e.png). CollectReadCounts:; ![image](https://user-images.githubusercontent.com/11076296/37244228-ad24908c-2453-11e8-91dd-a978578e77f4.png). CollectFragmentOverlaps:; ![image](https://user-images.githubusercontent.com/11076296/37244230-b25b9cee-2453-11e8-8646-f9c95365b355.png). The increased statistical noise in the CollectFragmentCounts result (due to the lower overall count because of the pairing of reads) probably causes us to miss this event. Also, although CollectFragmentOverlaps initially looks pretty good, I think the bin-to-bin correlations that are evident here negatively affect segmentation. This is not an extremely rigorous evaluation, but it suggests that we should consider switching over to a CollectReadCounts-like strategy. To appease CGA (in case they still feel strongly, which they might not), we can make this a separate tool, or perhaps just have a single tool called CollectCounts that can toggle between the two (we just have to be careful about filters in the latter case). We should evaluate further once more rigorous automatic evaluations are in place. @mbabadi @LeeTL1220 @asmirnov239 @sooheelee might find this of interest. Also, I have a question for engine team, @droazen. Is there a read filter I should be using for fragment length, and if not, can we add one (or is there already a preferred way to do this type of filtering)?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4519:3520,toggle,toggle,3520,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519,1,['toggle'],['toggle']
Deployability,"llegalArgumentException: Wrong FS: hdfs://user/local/print_reads.sorted.bam, expected: hdfs://dataflow01.broadinstitute.org:8020; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:654); at org.apache.hadoop.fs.FileSystem.makeQualified(FileSystem.java:474); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:163); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:281); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:261); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:252); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.main(Main.java:86); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. This `IllegalArgumentException` should be converted to a `UserException` instead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1257:2405,deploy,deploy,2405,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1257,6,['deploy'],['deploy']
Deployability,"ller/HaplotypeCallerArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <0%> (ø)` | `4% <0%> (+2%)` | :arrow_up: |; | [...efaultGATKVariantAnnotationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vRGVmYXVsdEdBVEtWYXJpYW50QW5ub3RhdGlvbkFyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `100% <0%> (ø)` | `11% <0%> (+6%)` | :arrow_up: |; | [...titute/hellbender/tools/walkers/GenotypeGVCFs.java](https://codecov.io/gh/broadinstitute/gatk/pull/4844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnMuamF2YQ==) | `90.55% <0%> (+0.46%)` | `50% <0%> (+3%)` | :arrow_up: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.47% <0%> (+0.68%)` | `25% <0%> (+11%)` | :arrow_up: |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `84.17% <0%> (+1.01%)` | `40% <0%> (+15%)` | :arrow_up: |; | ... and [10 more](https://codecov.io/gh/broadinstitute/gatk/pull/4844/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4844?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4844#issuecomment-393939720:3611,pipeline,pipelines,3611,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4844#issuecomment-393939720,2,['pipeline'],['pipelines']
Deployability,"lock): Waiting for existing lock by process '62379' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3633423' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3633419' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3633423' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3633419' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; `. And there isn't a `lock_dir` under the specified path, but there are a bunch of tmp dirs like . `; tmpxmako3mg; tmpxqfosn7p; tmpxsqfj_t1; `. Would you recommend deleting these folders to release the compiler lock?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7411#issuecomment-905060709:2580,release,release,2580,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7411#issuecomment-905060709,3,['release'],['release']
Deployability,"lot of threading output writers through the codebase and perhaps this is better handled by the ""--debug"" argument like it used to? Thoughts? . Notes: ; - It should be noted that by design all of the added changes to HaplotypeCaller are opt-in, barring errors in implementation.; - This code is measurably slower than vanilla HaplotypeCaller. In particular FRD is a very expensive step that corresponds to ~5-7% of the runtime. This is in part because it has to duplicate many of the steps in the genotyper based on the number of unique mapping qualities present at a site as well as the fact that it performs an O(n^2) number of operations at sites with many possible alleles. There are options to cut down on the cost of this algorithm that moderately impact the results relative to DRAGEN. . This implementation is intended to produce results close to the results on DRAGEN 3.4.12 without stripping away the major improvements made in GATK4, as a result there are a number of areas in which we know we are producing different results: ; - In GATK4 variants that overlap with an upstream deletion will have added to their alleles list a sybmolic '*' deletion alleles which are genotyped as part of the allele array in the genotyeper. This is not the case in DRAGEN and it interacts with FRD in such a way as to produce a number of variants that in DRAGEN would have been called as 0/1 heterozygous calls with capped QUAL scores, in gatk they are called as 1/2 calls with uncapped quality scores.; - While we have added the option to use the legacy assembly region creation code, it is not part of the expected pipeline for running DRAGEN. This includes a number of arguments that were done away with in the recent refactoring pass. ; - I have added hooks to revert the assembly engine to approximately its state in gatk3. While I don't stand by that change I think we should bundle the minor assembly engine changes together with our other assembly engine work to try to make a more convincing case.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6634:5268,pipeline,pipeline,5268,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6634,1,['pipeline'],['pipeline']
Deployability,"lse --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false --minimumMappingQuality 20; [October 6, 2017 2:50:16 PM EDT] Executing as shlee@gsa5.broadinstitute.org on Linux 2.6.32-642.15.1.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.beta.5; 14:50:16.818 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 14:50:16.818 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:50:16.818 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:50:16.818 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:50:16.818 INFO HaplotypeCaller - Deflater: IntelDeflater; 14:50:16.818 INFO HaplotypeCaller - Inflater: IntelInflater; 14:50:16.818 INFO HaplotypeCaller - GCS max retries/reopens: 20; 14:50:16.818 INFO HaplotypeCaller - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:50:16.819 INFO HaplotypeCaller - Initializing engine; 14:50:18.950 INFO IntervalArgumentCollection - Processing 83257441 bp from intervals; 14:50:18.965 INFO HaplotypeCaller - Done initializing engine; 14:50:19.021 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 14:50:19.280 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 14:50:19.481 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 14:50:19.776 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_utils.so; 14:50:19.795 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/humgen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678:5865,patch,patch,5865,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678,1,['patch'],['patch']
Deployability,ltGradleLauncher.java:106); at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:63); at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106); at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:92); at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:47); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); at org.gradle.launcher.daemon.server.exec.ResetDeprecationLogger.execute(ResetDeprecationLogger.java:26); at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.java:34); at org.gradle.launcher.da,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155:5062,Continuous,ContinuousBuildActionExecuter,5062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155,2,['Continuous'],['ContinuousBuildActionExecuter']
Deployability,"ltiply (add in log space) this prior by the genotype likelihoods to get the posterior probabilities on genotypes. It appears to me that we have double-counted the input data, once to get its AC field and once to get its GLs. I believe the correct thing to do is use only the resources to define a prior which is then combined with the GLs to get the posterior. ---. @ldgauthier commented on [Tue May 17 2016](https://github.com/broadinstitute/gsa-unstable/issues/1185#issuecomment-219778100). I will take the blame (both figuratively and the literal git blame) for PosteriorLikelihoodsUtils nomenclature problems. I either initiated them or didn't fix them when I refactored. I also intuitively prefer resources only without using the input AC, but that being said we've seen better results using both, specifically for a Finnish cohort with 100 founders. In the DSDE/ATGU meetings the use of the input AC was discussed as being analogous to a single step of EM. Would the true EM apply a different update for each sample in the callset?. ---. @davidbenjamin commented on [Tue May 17 2016](https://github.com/broadinstitute/gsa-unstable/issues/1185#issuecomment-219833193). The better results using the double-counting might have something to do with the incorrect prior -- if the prior is skewing toward homozygosity, then double-counting your variant data might counteract this and rescue some variant genotypes, which will be mainly hets. The EM model that people implicitly seem to have in mind is alternating E steps on each sample to get genotype posteriors with M steps to learn the allele frequencies. So let's work out what happens if you do just one iterations:. 0) Initialize allele frequencies to the mean of the Dirichlet heterozygosity prior; i.e. ~1 for ref, ~1/1000 for each alt, plus any allele counts from the resources. Genotype priors come from the multinomial distribution (one genotype is a draw of 2 alleles) of these allele frequencies.; 1) (E step) genotype posteriors are th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2918:4059,update,update,4059,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2918,1,['update'],['update']
Deployability,"mE=) | `96.87% <85.71%> (-1.46%)` | `15 <1> (+1)` | |; | [...lotypecaller/AssemblyBasedCallerUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHNVbml0VGVzdC5qYXZh) | `95.77% <95.28%> (-4.23%)` | `45 <43> (+43)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...te/hellbender/utils/genotyper/ReadLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvUmVhZExpa2VsaWhvb2RzLmphdmE=) | `90.14% <0%> (+0.4%)` | `143% <0%> (ø)` | :arrow_down: |; | ... and [1 more](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5215?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5215?src=pr&el=footer). Last update [8103bde...7d53fb9](https://codecov.io/gh/broadinstitute/gatk/pull/5215?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5215#issuecomment-425465744:4814,update,update,4814,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5215#issuecomment-425465744,2,['update'],['update']
Deployability,"make a list of all Picard metrics tools used in the production pipeline (WGS, WES)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/422:63,pipeline,pipeline,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/422,1,['pipeline'],['pipeline']
Deployability,make sv pipeline script copy_sv_results.sh able to take bucket path that starts with gs://. currently the result-copying step would fail if I run the script by providing the `GCS_SAVE_PATH` argument that starts with `gs://`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4223:8,pipeline,pipeline,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4223,1,['pipeline'],['pipeline']
Deployability,making the version number depend on the git hash using a gradle git plugin from https://github.com/ajoberstar/gradle-git. It seems like the top gradle-git integration library. There are lots of pre-baked things in it to help with releases and such that we can grow into.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/196:155,integrat,integration,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/196,2,"['integrat', 'release']","['integration', 'releases']"
Deployability,manage_sv_pipeline checks version from gatk-spark.jar and compares it; to the current git hash (to ensure the correct version is run). Newer; gatk versions had a slightly different file name format and caused; errors parsing the hash. This updates the hash check and produces; more comprehensible error messages when it fails. Resolves: #3593,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3595:240,update,updates,240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3595,1,['update'],['updates']
Deployability,"mark duplicates in dataflow - based on the code by garrickevans . The main work is done in; `private static final class MarkDuplicatesDataflowTransform extends PTransform<PCollection<Read>, PCollection<Read>>` - the sigrature conforms to the main read processing pipeline. Limitations:; - no optical duplicates; - only integration tests (would be good to have unit tests that check dup detection logic on very specific reads - ideally those from picard's tests). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/541:263,pipeline,pipeline,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/541,2,"['integrat', 'pipeline']","['integration', 'pipeline']"
Deployability,mdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:218); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: No enum constant com.google.cloud.storage.StorageClass.DURABLE_REDUCED_AVAILABILITY; 	at java.lang.Enum.valueOf(Enum.java:238); 	at com.google.cloud.storage.StorageClass.valueOf(StorageClass.java:22); 	at com.google.cloud.storage.BlobInfo.fromPb(BlobInfo.java:940); 	at com.google.cloud.storage.Blob.fromPb(Blob.java:779); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:189); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:197); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:571); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.Files.isDirectory(Files.java:2192); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:205); 	... 23 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2517:2270,deploy,deploy,2270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2517,1,['deploy'],['deploy']
Deployability,"me: May 7, 2018 2:40:21 PM EDT; 14:40:21.992 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 14:40:21.992 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 14:40:21.992 INFO MarkDuplicatesSpark - HTSJDK Version: 2.14.3; 14:40:21.992 INFO MarkDuplicatesSpark - Picard Version: 2.18.2; 14:40:21.993 INFO MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:40:21.993 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:40:21.993 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:40:21.993 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:40:21.993 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 14:40:21.993 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 14:40:21.993 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 14:40:21.993 INFO MarkDuplicatesSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:40:21.994 WARN MarkDuplicatesSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: MarkDuplicatesSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 14:40:21.994 INFO MarkDuplicatesSpark - Initializing engine; 14:40:21.994 INFO MarkDuplicatesSpark - Done initializing engine; 14:40:22.338 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 15:24:12.735 INFO ReadsSparkSink - Finished sorting the bam file and dumping read shards to disk, proceeding to merge the shards into a single file using the master thread; 15:41:27.766 INFO ReadsSparkSink - Finished merging shards into a single output bam; 15:41:34.351 INFO MarkDuplicatesSpark - Shutting down engine; [May 7, 2018 3:41:34 PM EDT] org.broadinsti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4746:3332,patch,patch,3332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4746,1,['patch'],['patch']
Deployability,"me: May 7, 2018 9:47:47 PM EDT; 21:47:48.270 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 21:47:48.271 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 21:47:48.271 INFO MarkDuplicatesSpark - HTSJDK Version: 2.14.3; 21:47:48.271 INFO MarkDuplicatesSpark - Picard Version: 2.18.2; 21:47:48.271 INFO MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 21:47:48.271 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 21:47:48.272 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 21:47:48.272 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 21:47:48.272 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 21:47:48.272 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 21:47:48.272 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 21:47:48.272 INFO MarkDuplicatesSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 21:47:48.272 WARN MarkDuplicatesSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: MarkDuplicatesSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 21:47:48.273 INFO MarkDuplicatesSpark - Initializing engine; 21:47:48.273 INFO MarkDuplicatesSpark - Done initializing engine; 22:29:27.746 INFO ReadsSparkSink - Finished sorting the bam file and dumping read shards to disk, proceeding to merge the shards into a single file using the master thread; 22:43:29.758 INFO ReadsSparkSink - Finished merging shards into a single output bam; 22:43:36.475 INFO MarkDuplicatesSpark - Shutting down engine; [May 7, 2018 10:43:36 PM EDT] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 55.82 minutes.; Runtime.totalMemory()=1243086848",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4746:7178,patch,patch,7178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4746,1,['patch'],['patch']
Deployability,"mentations of copy-ratio, allele-fraction, and ""multidimensional"" (joint) segmentation. All implementations are pretty boilerplate; they simply partition by contig and then call out to KernelSegmenter. Note that there is some logic in multidimensional segmentation that only uses the first het in each copy-ratio interval and if any are available, and imputes the alt-allele fraction to 0.5 if not.; -Makes sense for @mbabadi to review this, since he reviewed the KernelSegmenter PR. Added modeling classes and tests for ModelSegments CNV pipeline.; -Most of this code is copied from the old MCMC code. However, I've done some overall code cleanup and refactoring, especially to remove some overextraction of methods in the allele-fraction likelihoods (see #2860). I also added downsampling and scaling of likelihoods to cut down on runtime. Tests have been simplified and rewritten to use simulated data.; -@LeeTL1220 do you think you could take a look?. Added ModelSegments CLI.; -Mostly control flow to handle optional inputs and validation, but there is some ugly and not well documented code that essentially does the GetHetCoverage step. We'll refactor later, I filed #3915.; -@asmirnov239 can review. This is lower priority than the gCNV VCF writing. Deleted gCNV WDL and Cromwell tests.; -Trivial to review. Added WDL and Cromwell tests for ModelSegments CNV pipeline.; -This includes the cost optimizations from @meganshand and @jsotobroad (sorry guys, I wasn't sure how to track your contributions while fixing up commits!) I also added tests for both GC/no-GC pair workflows.; -@MartonKN should review to gain familiarity with the WDL. Note that this WDL has already been through many revisions from @meganshand, @jsotobroad, and @LeeTL1220, so hopefully there shouldn't be too much for you to find serious fault with. Note that I punted on adding MultidimensionalKernelSegmenterUnitTest and ModelSegmentsIntegrationTest. Filed #3916. Closes #2858. (FINALLY!); Closes #3825.; Closes #3661.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3913:1934,pipeline,pipeline,1934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3913,1,['pipeline'],['pipeline']
Deployability,merge prototyping SV breakpoint and type inference tool into SV spark pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3890:70,pipeline,pipeline,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3890,2,['pipeline'],['pipeline']
Deployability,methods like BucketUtils.createFile take a PipelineOptions argument. That argument can be null if the path is not on a cloud but the doc does not mention that fact.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/923:43,Pipeline,PipelineOptions,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/923,1,['Pipeline'],['PipelineOptions']
Deployability,"metimes yield the homologuos sequence to a shorter alignment and take that away from a longer alignment; when it comes to a later filtering step that filters out alignments purely based on its unique read span, because of the deoverlapping step, those short alignment that received the homologuous sequence because of the left-aligning convention now survived, compared to if there were no upfront deoverlap. The drop in number of DUP is due to a similar reason:; the upfront overlap removal made some contigs that would be classified as having incomplete picture unfairly now becomes a contig with complete picture (see [this](http://www.genomeribbon.com/?perma=AvOvbThN4z) for example). IMO removal of the upfront deoverlapping step is good, because the number of calls would not be affected by which convention we follow (convention should only affect representation, not if a variant is real); on the other hand, the convention definitely hurts some other small alignments. -------. The drop in number of variants detected from stable-versioned tool to the experimental tool without this fix are mainly from the imprecise deletion calls that are not hooked up in the experiemental tool yet, and many deletion and duplications are now incoporated into CPX variants. -------. Alternatively, we can turn off the filter based on unique alignment length all together, and annotate the calls with unique alignment length for later stage filter. I did experiment with that, and as expected, the number of BND calls and deletion calls increased, whereas the numer of DUP calls dropped, when comparing only-turn-off-length-filter, turn-off-upfront-deoverlap-and-length-filter. The drop in number of DUP calls are due to the fact that without upfront deoverlap, more contigs are classified as having incomplete picture. -------; Also proposing an ""improvement"" to the script by adding more checks in the pipeline bash script:; the problem it is trying to address is documented in the changes to the script.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4282:6299,pipeline,pipeline,6299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4282,1,['pipeline'],['pipeline']
Deployability,"micsDBImport - Start Date/Time: November 26, 2023 11:48:08 AM CST; 11:48:09.327 INFO GenomicsDBImport - ------------------------------------------------------------; 11:48:09.327 INFO GenomicsDBImport - ------------------------------------------------------------; 11:48:09.327 INFO GenomicsDBImport - HTSJDK Version: 2.15.1; 11:48:09.327 INFO GenomicsDBImport - Picard Version: 2.18.2; 11:48:09.327 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:48:09.327 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:48:09.327 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 11:48:09.327 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:48:09.327 INFO GenomicsDBImport - Deflater: IntelDeflater; 11:48:09.327 INFO GenomicsDBImport - Inflater: IntelInflater; 11:48:09.327 INFO GenomicsDBImport - GCS max retries/reopens: 20; 11:48:09.327 INFO GenomicsDBImport - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 11:48:09.328 INFO GenomicsDBImport - Initializing engine; 11:48:14.819 INFO IntervalArgumentCollection - Processing 43270923 bp from intervals; 11:48:14.846 INFO GenomicsDBImport - Done initializing engine; Created workspace /mnt/g/ubuntushare/sequence/C271_sentieon_gvcf/my_database.chr01; 11:48:14.919 INFO GenomicsDBImport - Vid Map JSON file will be written to my_database.chr01/vidmap.json; 11:48:14.919 INFO GenomicsDBImport - Callset Map JSON file will be written to my_database.chr01/callset.json; 11:48:14.919 INFO GenomicsDBImport - Complete VCF Header will be written to my_database.chr01/vcfheader.vcf; 11:48:14.919 INFO GenomicsDBImport - Importing to array - my_database.chr01/genomicsdb_array; 11:48:14.924 INFO ProgressMeter - Starting traversal; 11:48:14.924 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 11:48:19.709 INFO GenomicsD",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8593:2920,patch,patch,2920,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8593,1,['patch'],['patch']
Deployability,migrate code from googlegenomics/genomics-pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/427:42,pipeline,pipeline,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/427,1,['pipeline'],['pipeline']
Deployability,mmandLineProgram.doWork(SparkCommandLineProgram.java:36); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/11/29 16:21:01 ERROR org.apache.spark.util.Utils: Uncaught exception in thread main; java.lang.NullPointerException; 	at org.apache.spark.network.shuffle.ExternalShuffleClient.close(ExternalShuffleClient.java:152); 	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1286); 	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:96); 	at org.apache.spark.SparkContext$$anonfun$stop$12.apply$mcV$sp(SparkContext.scala:1756); 	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1219); 	at org.apache.spark.SparkContext.stop(SparkContext.scala:1755); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:602); 	at org.apache.spark.api.java.JavaSpa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2289:2076,deploy,deploy,2076,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2289,1,['deploy'],['deploy']
Deployability,mmandLineProgram.doWork(SparkCommandLineProgram.java:36); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/11/29 16:21:01 ERROR org.apache.spark.util.Utils: Uncaught exception in thread main; java.lang.NullPointerException; 	at org.apache.spark.network.shuffle.ExternalShuffleClient.close(ExternalShuffleClient.java:152); 	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1286); 	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:96); 	at org.apache.spark.SparkContext$$anonfun$stop$12.apply$mcV$sp(SparkContext.scala:1756); 	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1219); 	at org.apache.spark.SparkContext.stop(SparkContext.scala:1755); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:602); 	at org.apache.spark.api.java.JavaSpa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-264212007:2259,deploy,deploy,2259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-264212007,1,['deploy'],['deploy']
Deployability,"mmandLineProgram.doWork(SparkCommandLineProgram.java:36); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16:21:01.561 INFO MarkDuplicatesSpark - Shutting down engine; [November 29, 2016 4:21:01 PM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=8232370176; org.apache.spark.SparkException: Could not parse Master URL: 'yarn'; 	at org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2735); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:522); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkCo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2289:4406,deploy,deploy,4406,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2289,1,['deploy'],['deploy']
Deployability,"mmandLineProgram.doWork(SparkCommandLineProgram.java:36); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16:21:01.561 INFO MarkDuplicatesSpark - Shutting down engine; [November 29, 2016 4:21:01 PM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=8232370176; org.apache.spark.SparkException: Could not parse Master URL: 'yarn'; 	at org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2735); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:522); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkCo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-264212007:4589,deploy,deploy,4589,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-264212007,1,['deploy'],['deploy']
Deployability,mmandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RD,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:23144,deploy,deploy,23144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['deploy'],['deploy']
Deployability,mmandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error reading null at position 0; 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.openStream(SeekableGCSStream.java:126); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.seek(SeekableGCSStream.java:103); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.<init>(SeekableGCSStream.java:59); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAMFile(BAMIO.java:67); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAM(BAMIO.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:178); 	... 20 more; ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-264909676:2650,deploy,deploy,2650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-264909676,1,['deploy'],['deploy']
Deployability,mmandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error reading null at position 0; 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.openStream(SeekableGCSStream.java:126); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.seek(SeekableGCSStream.java:103); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.<init>(SeekableGCSStream.java:59); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAMFile(BAMIO.java:67); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAM(BAMIO.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:178); 	... 20 more; ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929:8677,deploy,deploy,8677,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929,1,['deploy'],['deploy']
Deployability,mmandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Existing mirrorFile and resourceId don't match isDirectory status! '/hadoop_gcs_connector_metadata_cache/hellbender/test/output/gatk4-spark/recalibrated.bam' (dir: 'false') vs 'gs://hellbender/test/output/gatk4-spark/recalibrated.bam/' (dir: 'true'); 	at com.google.cloud.hadoop.gcsio.FileSystemBackedDirectoryListCache.getCacheEntryInternal(FileSystemBackedDirectoryListCache.java:198); 	at com.google.cloud.hadoop.gcsio.FileSystemBackedDirectoryListCache.putResourceId(FileSystemBackedDirectoryListCache.java:363); 	at com.google.cloud.hadoop.gcsio.CacheSupplementedGoogleCloudStorage.createEmptyObjects(CacheSupplementedGoogleCloudStorage.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271419191:1499,deploy,deploy,1499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271419191,1,['deploy'],['deploy']
Deployability,mmandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: Pathname /tmp/da63aa3c-e3bc-4893-9f40-42921719a343/hdfs:/svdev-caller-m:8020/reference/Homo_sapiens_assembly38.fasta from /tmp/da63aa3c-e3bc-4893-9f40-42921719a343/hdfs:/svdev-caller-m:8020/reference/Homo_sapiens_assembly38.fasta is not a valid DFS filename.; 	at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:213); 	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1436); 	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1433); 	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2382:2566,deploy,deploy,2566,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2382,1,['deploy'],['deploy']
Deployability,"mmandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.NullPointerException; 	at java.io.ByteArrayInputStream.<init>(ByteArrayInputStream.java:106); 	at org.broadinstitute.hellbender.engine.AuthHolder.getOfflineAuth(AuthHolder.java:79); 	at org.broadinstitute.hellbender.engine.AuthHolder.makeStorageClient(AuthHolder.java:94); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:177); 	... 20 more; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [bd000687-f538-4201-b888-668612d46bad] entered state [ERROR] while waiting for [DONE].; ```. =========================. On a third note, if the reference is also provided with a GCS path, we see this:. ```; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2382:7302,deploy,deploy,7302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2382,1,['deploy'],['deploy']
Deployability,"mmandLineProgram.java:38); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); > 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); > 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); > 	at org.broadinstitute.hellbender.Main.main(Main.java:239); > 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); > 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); > 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); > 	at java.lang.reflect.Method.invoke(Method.java:498); > 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:733); > 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177); > 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202); > 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116); > 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); > Caused by: java.nio.file.ProviderNotFoundException: Provider ""maprfs"" not found; > 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:341); > 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:40); > 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:143); > 	at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:226); > 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); > 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:178); > 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:177); > 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:134); >",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936:3685,deploy,deploy,3685,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936,1,['deploy'],['deploy']
Deployability,"model-based filtering, etc). If Mutect would employ this naive approach to haplotype calling, I suppose it would end up looking like the ""Platypus"" caller, _which_ again might be suited for our needs, but potentially makes option 3 more appealing. > Option 3 ( i.e. Quick-and-dirty (""FreeBayes-ian"") assembly:. This is interesting and would seem to solve my problems (I believe?) by creating a Haplotype-based, somatic variant caller with the Mutect perks/processing steps/output formats. Again, though, I could see the generation of many candidate haplotypes if things are really messy; however, could you not use a simple ""supporting reads""-based approach for haplotype selection. That would make the likelihood calculations fairly straight-forward. It would undeniably be less-sophisticated than the current De Bruijn Graph/Smith Waterman realignment-based approach but could be better for folks that want more control of the expected behaviors of the tool. > Option 5 (Disable realignment portion of assembly):. I'm going to go out on a limb with this one (feel free to shut this line of thought down quick if I'm really off-base). I've never been able to fully understand the code in the `findBestPaths` method (https://github.com/broadinstitute/gatk/blob/9ff3f8b180c063a3fa67dae129b0cbd04012448e/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java#L307) and I've had troubles figuring out the details of realignment from the official docs. It could be this part of the assembly process that causes me the most troubles in my pipeline, since this is where the original alignment information can really get disregarded as Mutect2 looks for better understandings of the input alignments. Admittedly, I find this feature to be really neat (particularly for the big ugly INDELs), but again the lose of the original alignment information has been troubling in certain cases. Could there be a potential approach to disabling realignment?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7064#issuecomment-771060817:2159,pipeline,pipeline,2159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7064#issuecomment-771060817,2,['pipeline'],['pipeline']
Deployability,"more concretely the private method getReferenceBases(SAMSeqRecord) should be syncronized or avoid it calling directly to the syncronized getReferenceBases(SSR, boolean) and getReferenceBasesByRegions should not update the cache fields.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8139#issuecomment-1376313615:211,update,update,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8139#issuecomment-1376313615,1,['update'],['update']
Deployability,"most recent call last):; File ""/gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/tmp.cd408023/cohort_denoising_calling.1650827882847090378.py"", line 143, in <module>; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/gcnvkernel/tasks/task_cohort_denoising_calling.py"", line 140, in __init__; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/pymc3/model.py"", line 197, in __call__; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/gcnvkernel/models/model_denoising_calling.py"", line 754, in __init__; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/pymc3/distributions/distribution.py"", line 39, in __new__; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/pymc3/model.py"", line 515, in Var; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/pymc3/model.py"", line 869, in __init__; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/pymc3/distributions/continuous.py"", line 250, in logp; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/tensor/var.py"", line 155, in __mul__; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/op.py"", line 670, in __call__; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/op.py"", line 935, in make_thunk; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/op.py"", line 839, in make_c_thunk; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/cc.py"", line 1190, in make_thunk; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/cc.py"", line 1131, in __compile__; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/cc.py"", line 1586, in cthunk_factory; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 1118, in module_from_key; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 1017, in _get_from_ke",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:19826,continuous,continuous,19826,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,1,['continuous'],['continuous']
Deployability,"moving settings from SparkCommandLineProgram to SparkContextFactory; the settings that were being applied to SparkContext.getConf were pointless since getConf is a copy of the configuration; instead they're applied to the SparkConfig in SparkContextFactory.getSparkContext. fixes #1096. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1097). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1097:176,configurat,configuration,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1097,1,['configurat'],['configuration']
Deployability,"mp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-ed279998-3783-4f41-8fe5-f44a4fac3ee4; ```. CountReads runs fine..... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 11:36:23.022 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 11:36:25.027 INFO CountReads - ------------------------------------------------------------; 11:36:25.028 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.0.12.0; 11:36:25.028 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:36:25.029 INFO CountReads - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 11:36:25.029 INFO CountReads - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 11:36:25.030 INFO CountReads - Start Date/Time: January 7, 2019 11:36:22 AM EST; 11:36:25.030 INFO CountReads - ------------------------------------------------------------; 11:36:25.031 INFO CountReads - ------------------------------------------------------------; 11:36:25.032 INFO CountReads - HTSJDK Version: 2.18.1; 11:36:25.033 INFO CountReads - Picard Version: 2.18.16; 11:36:25.033 INFO CountReads - HTSJDK Defaults.COMPRESSION",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:44332,install,install,44332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['install'],['install']
Deployability,"mpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/01/21 14:55:33 INFO ShutdownHookManager: Shutdown hook called; ```. Attached is a small BAM file that I used to reproduce the error (If memory serves, I've seen this issue on other BAM files as well):. [NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip](https://github.com/broadinstitute/gatk/files/101575/NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip). (This issue may be related to one posted here: https://github.com/broadinstitute/gatk/issues/1417.). Here is some information on what I installed:. ```; echo ""Installing Java""; sudo add-apt-repository -y ppa:webupd8team/java; sudo apt-get -qq update; echo debconf shared/accepted-oracle-license-v1-1 select true | sudo debconf-set-selections; echo debconf shared/accepted-oracle-license-v1-1 seen true | sudo debconf-set-selections; sudo apt-get -qq install -y oracle-java8-installer. java -version. echo ""Installing Gradle""; sudo add-apt-repository -y ppa:cwchien/gradle; sudo apt-get -qq update > /dev/null; sudo apt-get -qq install -y gradle. echo ""Downloading binaries for Spark""; wget http://d3kbcqa49mib13.cloudfront.net/spark-1.5.1-bin-hadoop2.6.tgz; tar -xzf spark-1.5.1-bin-hadoop2.6.tgz; export SPARK_HOME=spark-1.5.1-bin-hadoop2.6. echo ""Set up Spark for standalone mode processing""; $SPARK_HOME/sbin/start-master.sh -h localhost; $SPARK_HOME/sbin/start-slave.sh spark://localhost:7077. echo ""Downloading source for GATK4""; wget https://github.com/broadinstitute/gatk/archive/4.alpha.tar.gz; tar -xvzf 4.alpha.tar",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1444:3859,install,installed,3859,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1444,1,['install'],['installed']
Deployability,must contain active span.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:104); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:80); at org.broadinstitute.hellbender.utils.activityprofile.ActivityProfile.popNextReadyAssemblyRegion(ActivityProfile.java:332); at org.broadinstitute.hellbender.utils.activityprofile.ActivityProfile.popReadyAssemblyRegions(ActivityProfile.java:277); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:159); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:112); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:35); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:192); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1058); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. #### Steps to reproduce. see attachement. ```; gatk HaplotypeCaller -I jeter.bam -L jeter.bed --seconds-between-progress-updates 600 --minimum-mapping-quality 30 -R hs37d5_all_chr.fasta -O jeter.vcf.gz; ```. #### Expected behavior. no exception. #### Actual behavior. ```; java.lang.IllegalStateException: Padded span must contain active span; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7289:2122,update,updates,2122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7289,1,['update'],['updates']
Deployability,"my pipeline(from fastq ) is 👍 ; . 1. FastqToSam . 2. ConvertHeaderlessHadoopBamShardToBam. 3. BwaAndMarkDuplicatesPipelineSpark; ; ...... but in the step 3 （BwaAndMarkDuplicatesPipelineSpark），the pipeline crash; ```; Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, com1, executor 1): # **java.lang.IllegalArgumentException: Reference name for '1853452901' not found in sequence dictionary.; at htsjdk.samtools.SAMRecord.resolveNameFromIndex(SAMRecord.java:569); at htsjdk.samtools.SAMRecord.setMateReferenceIndex(SAMRecord.java:506); at htsjdk.samtools.BAMRecord.<init>(BAMRecord.java:94); at htsjdk.samtools.DefaultSAMRecordFactory.createBAMRecord(DefaultSAMRecordFactory.java:42); at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:210); at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.<init>(BAMFileReader.java:963); at htsjdk.samtools.BAMFileReader.getIterator(BAMFileReader.java:491)**; at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:182); at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:211); at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:180); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:179); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:134); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:69); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4179:3,pipeline,pipeline,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4179,2,['pipeline'],['pipeline']
Deployability,"n Tools; #; # Only update this environment if there is a *VERY* good reason to do so!; # If the build is broken but could be fixed by doing something else, then do that thing instead.; # Ensuring the correct environment for canonical (or otherwise reasonable) usage of our standard Docker takes precedence over edge cases.; # If you break the environment, you are responsible for fixing it and also owe the last developer who left this in a reasonable state a beverage of their choice.; # (This may be yourself, and you'll appreciate that beverage while you tinker with dependencies!); #; # When changing dependencies or versions in this file, check to see if the ""supportedPythonPackages"" DataProvider; # used by the testGATKPythonEnvironmentPackagePresent test in PythonEnvironmentIntegrationTest needs to be updated; # to reflect the changes.; #; name: gatk; channels:; # if channels other than conda-forge are added and the channel order is changed (note that conda channel_priority is currently set to flexible),; # verify that key dependencies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely nec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:1317,install,installed,1317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['install'],['installed']
Deployability,"n(CommandLineProgram.java:211) ; ;     at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160) ; ;     at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203) ; ;     at org.broadinstitute.hellbender.Main.main(Main.java:289). And I will get the same error when I assign the temp directory in another way:. /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx30G"" BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz  -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.table --tmp-dir /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam ; ; Using GATK jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar ; ; Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx30G -jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.table --tmp-dir /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam ; ; 00:11:11.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:8118,pipeline,pipeline,8118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability,"n(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; 3. Change work directory into `/data/xieduo/Immun_genomics/data/Łuksza2022Nature` and used `./` as tmp directory. It also failed:; ```; cd /data/xieduo/Immun_genomics/data/Łuksza2022Nature; /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx8G -Djava.io.tmpdir=./"" BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; Using GATK jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -Djava.io.tmpdir=./ -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; 13:46:24.742 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compress",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:11970,pipeline,pipeline,11970,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,1,['pipeline'],['pipeline']
Deployability,"n/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx60g -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar GenotypeGVCFs -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -G StandardAnnotation -G AS_StandardAnnotation -V gendb:///restricted/projectnb/kageproj/gatk/genomicsdb/genomicsDB.chr16 -L chr16:105582-211160 --use-new-qual-calculator --only-output-calls-starting-in-intervals TRUE --genomicsdb-shared-posixfs-optimizations TRUE --tmp-dir tmp -O chr16-105582-211160.vcf.gz; 07:46:18.893 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 07:46:18.944 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 25, 2021 7:46:19 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 07:46:19.128 INFO GenotypeGVCFs - ------------------------------------------------------------; 07:46:19.128 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.2.0.0; 07:46:19.128 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 07:46:19.129 INFO GenotypeGVCFs - Executing as farrell@scc-hadoop.bu.edu on Linux v3.10.0-1160.36.2.el7.x86_64 amd64; 07:46:19.129 INFO GenotypeGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 07:46:19.129 INFO GenotypeGVCFs - Start Date/Time: August 25, 2021 7:46:18 AM EDT; 07:46:19.129 INFO GenotypeGVCFs - ------------------------------------------------------------; 07:46:19.129 INFO GenotypeGVCFs - ----------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437#issuecomment-905431278:1387,install,install,1387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437#issuecomment-905431278,1,['install'],['install']
Deployability,"nScriptExecutor.checkPythonEnvironmentForPackage(PythonScriptExecutor.java:205); at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.start(StreamingPythonScriptExecutor.java:121); at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.onTraversalStart(CNNScoreVariants.java:302); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1046); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python -c import gatktool. Stdout: ; Stderr: Traceback (most recent call last):; File ""<string>"", line 1, in <module>; ModuleNotFoundError: No module named 'gatktool'. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeCommand(PythonScriptExecutor.java:79); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.checkPythonEnvironmentForPackage(PythonScriptExecutor.java:198); when I checked gatktool python package, it is installed in the python packages by conda. after activate gatk4 , I checked with pip install gatktool, and it says the package already installed. Anyone experienced this error?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7397:3400,install,installed,3400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7397,3,['install'],"['install', 'installed']"
Deployability,"nVja2V0VXRpbHMuamF2YQ==) | `43.75% <0%> (-29.861%)` | `27% <0%> (-9%)` | |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `76.471% <0%> (-23.529%)` | `4% <0%> (ø)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (ø)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | ... and [24 more](https://codecov.io/gh/broadinstitute/gatk/pull/2401?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2401?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2401?src=pr&el=footer). Last update [51360c7...51285dc](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-279424649:5149,update,update,5149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-279424649,2,['update'],['update']
Deployability,"nce context will give WINDOW bases before and after the; logical reference allele for a variant. This is NOT the allele in the; input VCF, but rather the allele that actually has changed. For; insertions, the logical allele is the SPACE BETWEEN TWO BASES (and; therefore the resulting string will always be 2xWINDOW bases long).; For deletions, the logical allele is the given ref allele without the; required preceding base. For MNPs the logical allele is the given ref; allele.; Updated some tests and test data to reflect this change. - Added a small HG38 regression test set. - Fixed a boundary bug with codon strings.; Now codon change strings have an alternate (correct) form for insertions; that involve the start codon on the - strand, and the stop codon on the; + strand. This form eliminates any overrun/out of bounds exceptions. - Fixed an issue involving variants that overrun the end of the coding sequence. - Added in additional required files for regression test gencode data source. - Added a helpful script and modified test data set to be correct. - Updated part of Gencode to prepare for fixing the exon boundary issue. - Updated FuncotatorIntegrationTests to use environment-variable paths; more safely. - Updated `FuncotatorUtils::getCodingSequenceChangeString` to use; base data types rather than those in `SequenceComparison`. - Refactored; `GencodeFuncotationFactory::createCodingRegionFuncotationForNonProteinCodingFeature`; to remove the use of `SequenceComparison` objects. - Updated test suite to use full, checked-in references. - Updated many tests to use regression test data sources rather than small data; sources specifically for PIK3CA and MUC16. - Removed some now unused data files (primarily old data sources). - Updated regression tests to work on local data sources and references. - Now `FuncotatorIntegrationTest::regressionTest` works on local, checked-out copies of the data sources so that; they can be run from any checkout. - Fixes #4344 ; - Fixes #5295",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5302:4526,Update,Updated,4526,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5302,6,['Update'],['Updated']
Deployability,nce file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar; Running:; /share/pkg/spark/2.1.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:48:31.261 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:48:31.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:48:31.693 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.693 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.3.0; 13:48:31.693 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:48:31.694 INFO CountReadsSpark - Executing as farrell,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:1371,install,install,1371,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725,1,['install'],['install']
Deployability,"nce increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # conda-installed 2.2.4 appears to be the most recent version with a consistent API and without conflicts/clobbers; # if you wish to update, note that versions of conda-forge::keras after 2.2.5; # undesirably set the environment variable KERAS_BACKEND = theano by default; - defaults::intel-openmp=2019.4; - conda-forge::scikit-learn=0.22.2; - conda-forge::matplotlib=3.2.1; - conda-forge::pandas=1.0.3. # core R dependencies; these should only be used for plotting and do not take precedence over core python dependencies!; - r-base=3.6.2; - r-data.table=1.12.8; - r-dplyr=0.8.5; - r-getopt=1.20.3; - r-ggplot2=3.3.0; - r-gplots=3.0.3; - r-gsalib=2.1; - r-optparse=1.6.4. # other python dependencies; these should be removed after functionality is moved into Java code; - biopython=1.76; - pyvcf=0.6.8; - bioconda::pysam=0.15.3 # using older conda-install",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:2616,update,update,2616,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['update'],['update']
Deployability,nch PrintReadsSpark -I gs://hellbender/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam -O output -- --sparkRunner GCS --cluster dataproc-cluster-3 --project broad-dsde-dev; ```. fails with . ```; 16/04/27 18:49:12 ERROR org.apache.spark.SparkContext: Error initializing SparkContext.; java.io.FileNotFoundException: File file:/Users/louisb/Workspace/gatk-protected/build/libIntelDeflater.so does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:609); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:822); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:599); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:337); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289); at org.apache.spark.deploy.yarn.Client.copyFileToRemote(Client.scala:317); at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:407); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:471); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:470); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:470); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:468); at scala.collection.immutable.List.foreach(List.scala:318); at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:468); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:727); at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:142); at org.apache.spark.scheduler.clus,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:1012,deploy,deploy,1012,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,1,['deploy'],['deploy']
Deployability,"nd other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # conda-installed 2.2.4 appears to be the most recent version with a consistent API and without conflicts/clobbers; # if you wish to update, note that versions of conda-forge::keras after 2.2.5; # undesirably set the environment variable KERAS_BACKEND = theano by default; - defaults::intel-openmp=2019.4; - conda-forge::scikit-learn=0.22.2; - conda-forge::matplotlib=3.2.1; - conda-forge::pandas=1.0.3. # core R dependencies; these should only be used for plotting and do not take precedence over core python dependencies!; - r-base=3.6.2; - r-data.table=1.12.8; - r-dplyr=0.8.5; - r-getopt=1.20.3; - r-ggplot2=3.3.0; - r-gplots=3.0.3; - r-gsalib=2.1; - r-optparse=1.6.4. # other python dependencies; these should be removed after functionality is moved into Java code; - biopython=1.76; - pyvcf=0.6.8; - bioconda::pysam=0.15.3 # using older conda-installed versions may result in libcrypto / openssl bugs. # pip installs should be avoided, as pip may not respect the dependencies found by the conda solver; - pip:; - gatkPythonPackageArchive.zip; ```. It seems to successfully create the environment. I'd still recommend updating the information on your README.md and the file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:3633,install,installed,3633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,4,['install'],"['installed', 'installs']"
Deployability,"nder.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.FileSystemNotFoundException: Provider ""gs"" not installed; 	at java.nio.file.Paths.get(Paths.java:147); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferencePath(ReferenceFileSparkSource.java:53); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferenceBases(ReferenceFileSparkSource.java:60); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceMultiSparkSource.getReferenceBases(ReferenceMultiSparkSource.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.getRefBaseString(BreakEndVariantType.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.access$200(BreakEndVariantType.java:20); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType$InterChromosomeBreakend.<init>(BreakEndVariantType.java:253); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType$InterChromosomeBreakend.getOrderedMates(BreakEndVaria",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:8070,install,installed,8070,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['install'],['installed']
Deployability,ne importing batch 51/65; 18:53:04.283 INFO  GenomicsDBImport - Done importing batch 52/65; 19:36:40.808 INFO  GenomicsDBImport - Done importing batch 53/65; 20:18:42.274 INFO  GenomicsDBImport - Done importing batch 54/65; 21:01:51.304 INFO  GenomicsDBImport - Done importing batch 55/65; 21:36:00.458 INFO  GenomicsDBImport - Done importing batch 56/65; 22:08:38.587 INFO  GenomicsDBImport - Done importing batch 57/65; 22:40:44.082 INFO  GenomicsDBImport - Done importing batch 58/65; 23:14:11.202 INFO  GenomicsDBImport - Done importing batch 59/65; 23:48:23.805 INFO  GenomicsDBImport - Done importing batch 60/65; 00:20:35.869 INFO  GenomicsDBImport - Done importing batch 61/65; 00:51:47.408 INFO  GenomicsDBImport - Done importing batch 62/65; 01:25:23.587 INFO  GenomicsDBImport - Done importing batch 63/65; 01:59:03.103 INFO  GenomicsDBImport - Done importing batch 64/65; Using GATK jar /share/pkg.7/gatk/[4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar](http://4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar) defined in environment variable GATK_LOCAL_JAR; Running:;     java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx150g -Xms16g -jar /share/pkg.7/gatk/[4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar](http://4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar) GenomicsDBImport --sample-name-map sample_map.chr3 --genomicsdb-workspace-path genomicsDB.rb.chr3 --genomicsdb-shared-posixfs-optimizations True --tmp-dir tmp --L chr3 --batch-size 50 --bypass-feature-reader --reader-threads 5 --merge-input-intervals --overwrite-existing-genomicsdb-workspace --consolidate; [farrell@scc-hadoop genomicsdb]$ ls genomicsDB.rb.chr3; __tiledb_workspace.tdb  chr3$1$198295559  vcfheader.vcf  vidmap.json. ```; It never indicates that it imported batch 65/65. No error and the  callset.json is missing which we found in chr4 to chr22.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1246785232:3562,install,install,3562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1246785232,1,['install'],['install']
Deployability,"ne(GATKSparkTool.java:255); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66); at org.broadinstitute.hellbender.Main.main(Main.java:81); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/01/21 14:55:33 INFO ShutdownHookManager: Shutdown hook called; ```. Attached is a small BAM file that I used to reproduce the error (If memory serves, I've seen this issue on other BAM files as well):. [NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip](https://github.com/broadinstitute/gatk/files/101575/NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip). (This issue may be related to one posted here: https://github.com/broadinstitute/gatk/issues/1417.). Here is some information on what I installed:. ```; echo ""Installing Java""; sudo add-apt-repository -y ppa:webupd8team/java; sudo apt-get -qq update; echo debconf shared/accepted-oracle-license-v1-1 select true | sudo debconf-set-selections; echo debconf sha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1444:3078,deploy,deploy,3078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1444,1,['deploy'],['deploy']
Deployability,"neProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; #### Steps to reproduce; `gatk HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz`. The cram is HG0096.final.cram found here:. https://www.internationalgenome.org/data-portal/data-collection/30x-grch38. #### Expected behavior; When I run an earlier version v4.1.7.0, it runs without an error.... ```; gatk HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz; Using GATK jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz; 14:40:45.497 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 10, 2021 2:40:45 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:40:45.786 INFO HaplotypeCaller - ------------------------------------------------------------; 14:40:45.787 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.7.0; 14:40:45.787 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:40:45.788 INFO HaplotypeCaller - Executing as farrell@scc-hadoop.bu.edu on Linux v3.10.0-1160.6.1.el7.x86_64 amd64; 14:40:45.788 INFO Haplotyp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7076:5732,install,install,5732,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7076,1,['install'],['install']
Deployability,neProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadinstitute.hellbender.Main.main(Main.java:275); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.ContigAlignmentsModifier.removeOverlap(ContigAlignmentsModifier.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.AssemblyContigAlignmentSignatureClassifier.lambda$processContigsWithTwoAlignments$e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFuncti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:12566,deploy,deploy,12566,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['deploy'],['deploy']
Deployability,neProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:111); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:169); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:120); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:141); 	at org.broadinstitute.hellbender.Main.main(Main.java:196); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:728); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Invalid splitting BAM index: should contain at least 1 offset and the file size; 	at org.seqdoop.hadoop_bam.SplittingBAMIndex.readIndex(SplittingBAMIndex.java:69); 	at org.seqdoop.hadoop_bam.SplittingBAMIndex.<init>(SplittingBAMIndex.java:49); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeSplittingBaiFiles(SAMFileMerger.java:117); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:152); 	at org.broadinstitute.hellbender.engine.spark.datasources.Rea,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2503:1329,deploy,deploy,1329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2503,1,['deploy'],['deploy']
Deployability,"neProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:111); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:169); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:218); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: GCS FileSystem URIs mustn't have: port, userinfo, path, query, or fragment: gs://broad-gatk-test-jenkins/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam; 	at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:192); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:83); 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:336); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:40); 	at org.seqdoop.hadoop_bam.BAMRecordReader.initia",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337:4032,deploy,deploy,4032,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337,1,['deploy'],['deploy']
Deployability,neProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.NegativeArraySizeException; 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.resize(IdentityObjectIntMap.java:447); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.putStash(IdentityObjectIntMap.java:245); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:239); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:135); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.putStash(IdentityObjectIntMap.java:246); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:239); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:135); 	at com.esotericsoftware.kryo.uti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3303:4497,deploy,deploy,4497,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3303,1,['deploy'],['deploy']
Deployability,neProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:220); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.NoSuchFileException: jonn-test-bucket/foo.bam.parts; 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:575); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219); 	at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276); 	at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322); 	at java.nio.file.FileTreeIterator.<init>(FileTreeIterator.java:72); 	at java.nio.file.Files.walk(Files.java:3574); 	at java.nio.file.Files.walk(Files.java:3625); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.getFilesMatching(NIOFileUtil.java:91); 	at org.seqdoop.hadoop_bam.ut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2793:2154,deploy,deploy,2154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2793,1,['deploy'],['deploy']
Deployability,neProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:218); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: No enum constant com.google.cloud.storage.StorageClass.DURABLE_REDUCED_AVAILABILITY; 	at java.lang.Enum.valueOf(Enum.java:238); 	at com.google.cloud.storage.StorageClass.valueOf(StorageClass.java:22); 	at com.google.cloud.storage.BlobInfo.fromPb(BlobInfo.java:940); 	at com.google.cloud.storage.Blob.fromPb(Blob.java:779); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:189); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:197); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:571); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.Files.isDirectory(Files.java:21,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2517:2051,deploy,deploy,2051,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2517,1,['deploy'],['deploy']
Deployability,neProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(H,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591:3325,deploy,deploy,3325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591,1,['deploy'],['deploy']
Deployability,neProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:152); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:175); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:161); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(H,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994:8891,deploy,deploy,8891,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994,1,['deploy'],['deploy']
Deployability,"neProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66); at org.broadinstitute.hellbender.Main.main(Main.java:81); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/01/21 14:55:33 INFO ShutdownHookManager: Shutdown hook called; ```. Attached is a small BAM file that I used to reproduce the error (If memory serves, I've seen this issue on other BAM files as well):. [NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip](https://github.com/broadinstitute/gatk/files/101575/NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip). (This issue may be related to one posted here: https://github.com/broadinstitute/gatk/issues/1417.). Here is some information on what I installed:. ```; echo ""Installing Java""; sudo add-apt-repository -y ppa:webupd8team/java; sudo apt-get -qq update; echo debconf shared/accepted-oracle-license-v1-1 select true | sudo debconf-set-selections; echo debconf shared/accepted-oracle-license-v1-1 seen true | sudo debconf-set-selections; sudo apt-get -qq install -y oracle-java8-installer. java -version. echo ""Installing Gradle""; sudo add-apt-repository -y ppa:cwchien/gradle; su",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1444:3294,deploy,deploy,3294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1444,1,['deploy'],['deploy']
Deployability,"nel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pymc3/__init__.py"", line 12, in <module>; from .sampling import *; File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pymc3/sampling.py"", line 14, in <module>; from .plots.traceplot import traceplot; File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pymc3/plots/__init__.py"", line 1, in <module>; from .autocorrplot import autocorrplot; File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pymc3/plots/autocorrplot.py"", line 2, in <module>; import matplotlib.pyplot as plt; File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/matplotlib/pyplot.py"", line 113, in <module>; _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup(); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/__init__.py"", line 60, in pylab_setup; [backend_name], 0); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/backend_macosx.py"", line 19, in <module>; from matplotlib.backends import _macosx; RuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are using (Ana)Conda please install python.app and replace the use of 'python' with 'pythonw'. See 'Working with Matplotlib on OSX' in the Matplotlib FAQ for more information.; ```; As it states, there is more information here: https://matplotlib.org/faq/osx_framework.html#osxframework-faq. I can resolve the issue by running `conda install -c anaconda python.app` and changing this line in `PythonExecutorBase.java`:; ```; PYTHON(""python""),; ```; to; ```; PYTHON(""pythonw""),; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4743:1625,install,installed,1625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4743,5,['install'],"['install', 'installed', 'installing']"
Deployability,nes 59099 59100 +1 ; Branches 9673 9673 ; ===============================================; - Hits 46374 46144 -230 ; - Misses 8983 9225 +242 ; + Partials 3742 3731 -11; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4213?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/haplotypecaller/graphs/CommonSuffixSplitter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQ29tbW9uU3VmZml4U3BsaXR0ZXIuamF2YQ==) | `91.045% <100%> (+0.136%)` | `21 <0> (ø)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4213#issuecomment-359306361:1597,pipeline,pipelines,1597,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4213#issuecomment-359306361,1,['pipeline'],['pipelines']
Deployability,"nfigFactory - spark.driver.maxResultSize = 0; > 21:13:04.230 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; > 21:13:04.230 DEBUG ConfigFactory - spark.io.compression.codec = lzf; > 21:13:04.230 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; > 21:13:04.230 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; > 21:13:04.230 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; > 21:13:04.230 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; > 21:13:04.230 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; > 21:13:04.231 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; > 21:13:04.231 DEBUG ConfigFactory - createOutputBamIndex = true; > 21:13:04.231 INFO GenotypeGVCFs - Deflater: IntelDeflater; > 21:13:04.231 INFO GenotypeGVCFs - Inflater: IntelInflater; > 21:13:04.231 INFO GenotypeGVCFs - GCS max retries/reopens: 20; > 21:13:04.231 INFO GenotypeGVCFs - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; > 21:13:04.231 INFO GenotypeGVCFs - Initializing engine; > 21:13:11.834 INFO GenotypeGVCFs - Done initializing engine; > 21:13:11.950 DEBUG MathUtils$Log10Cache - cache miss 2 > 0 expanding to 12; > 21:13:11.992 INFO ProgressMeter - Starting traversal; > 21:13:11.992 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; > 21:14:17.635 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:1->2; > 21:14:17.858 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:2->3; > 21:14:17.872 DEBUG MathUtils$Log10Cache - cache miss 13 > 12 expanding to 26; > 21:14:17.872 DEBUG MathUtils$Log10Cache - cache miss 27 > 26 expanding to 54; > 21:14:17.872 DEBUG MathUtils$Log10Cache - cache miss 55 > 54 expanding to 110; > 21:14:17.872 DEBUG MathUtils$Log10Cache - cache miss 111 > 110 expanding to 222; > 21:14:17.873 D",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4161:4914,patch,patch,4914,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4161,1,['patch'],['patch']
Deployability,"nflater; 16:36:22.399 INFO Funcotator - GCS max retries/reopens: 20; 16:36:22.399 INFO Funcotator - Requester pays: disabled; 16:36:22.399 INFO Funcotator - Initializing engine; 16:36:22.624 INFO FeatureManager - Using codec VCFCodec to read file file:///home/ppshah/shared/CAS_MOSAIC/mutect/mrn_2507919/WES/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC_filtered.vcf.gz; 16:36:22.842 INFO Funcotator - Done initializing engine; 16:36:22.842 INFO Funcotator - Validating sequence dictionaries...; 16:36:22.856 INFO Funcotator - Processing user transcripts/defaults/overrides...; 16:36:22.857 INFO Funcotator - Initializing data sources...; 16:36:22.859 INFO DataSourceUtils - Initializing data sources from directory: /home/ppshah/shared/pipelines/mutect/funcotator_dataSources.v1.7.20200521s; 16:36:22.871 INFO DataSourceUtils - Data sources version: 1.7.2020429s; 16:36:22.871 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; 16:36:22.871 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; 16:36:22.891 INFO Funcotator - Shutting down engine; [January 10, 2024 at 4:36:22 PM GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=285212672; ***********************************************************************. A USER ERROR has occurred: ERROR: Directory contains more than one config file: file:///home/ppshah/shared/pipelines/mutect/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg38/. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. Any guidance to resolve the issue is appreciated.; Thank you!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8647:4903,pipeline,pipelines,4903,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8647,1,['pipeline'],['pipelines']
Deployability,"ng libgkl\_compression.so from jar:file:/mnt/clinix1/Analysis/mongol/phenomata/Tools/Anaconda3/envs/gatk4/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so** ; **Mar 05, 2020 9:27:44 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine** ; **INFO: Failed to detect whether we are running on Google Compute Engine.** ; **09:27:44.733 INFO PathSeqPipelineSpark - ------------------------------------------------------------** ; **09:27:44.733 INFO PathSeqPipelineSpark - The Genome Analysis Toolkit (GATK) v4.1.4.1** ; **09:27:44.734 INFO PathSeqPipelineSpark - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/)** ; **09:27:44.734 INFO PathSeqPipelineSpark - Executing as phenomata@cm132 on Linux v2.6.32-573.18.1.el6.x86\_64 amd64** ; **09:27:44.734 INFO PathSeqPipelineSpark - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_152-release-1056-b12** ; **09:27:44.734 INFO PathSeqPipelineSpark - Start Date/Time: 2020년 3월 5일 (목) 오전 9시 27분 43초** ; **09:27:44.734 INFO PathSeqPipelineSpark - ------------------------------------------------------------** ; **09:27:44.734 INFO PathSeqPipelineSpark - ------------------------------------------------------------** ; **09:27:44.735 INFO PathSeqPipelineSpark - HTSJDK Version: 2.21.0** ; **09:27:44.735 INFO PathSeqPipelineSpark - Picard Version: 2.21.2** ; **09:27:44.735 INFO PathSeqPipelineSpark - HTSJDK Defaults.COMPRESSION\_LEVEL : 2** ; **09:27:44.735 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE\_ASYNC\_IO\_READ\_FOR\_SAMTOOLS : false** ; **09:27:44.735 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true** ; **09:27:44.735 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false** ; **09:27:44.735 INFO PathSeqPipelineSpark - Deflater: IntelDeflater** ; **09:27:44.735 INFO PathSeqPipelineSpark - Inflater: IntelInflat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:2762,release,release-,2762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['release'],['release-']
Deployability,"ng this bug for 57 samples of 5000 crams at snp rs429358 but I would expect it is not unique to this site. . Select two crams with a Passed site with:; cram 1. Call with GT='0/0, GQ=0 and DP >40.; cram 2. Call with GT='0/1' or '1/1' and DP>20. . Create vcf with two approaches:. Pipeline 1. HaplotypeCaller-->vcf. module load gatk/4.0.11.0; gatk HaplotypeCaller -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa\; -I gq0_cram.list\; -L chr19:44907684-44909822\; --use-new-qual-calculator\; -O good.vcf.gz. Good GQ scores were also estimated with Freebayes on these samples also. Pipeline 2 HaplotypeCaller --> bvcf--->ImportVCF-->GenotypeVCF-->VCF with 2 samples. gatk HaplotypeCaller -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa\; -I $sample.cram\; --use-new-qual-calculator\; -L chr19:44907684-44909822\; -ERC GVCF\; -O bad.g.vcf.gz. Followed by import and GenotypeVCF. . #### Expected behavior; Pipeline 2 should generate accurate GQ scores that match the GQ in the HaplotypeCaller vcf output of pipeline 1. Instead GQ=0. . This is the output for the 57 GQ=0 samples with pipeline 1 which is accurate. AC=7;AF=0.061;AN=114;BaseQRankSum=-6.147;DP=1846;ExcessHet=3.8592;FS=0.000;InbreedingCoeff=-0.0640;MLEAC=6;MLEAF=0.053;MQ=60.00;MQRankSum=0.000;QD=4.52;ReadPosRankSum=-0.781;SOR=2.833; GT:AD:DP:GQ:PL; 0/0:37,0:37:99:0,111,1236; 0/0:40,0:40:99:0,120,1357; 0/0:34,0:34:99:0,102,1161; 0/0:49,0:49:99:0,147,1673; 0/0:33,0:33:99:0,99,1036; 0/0:48,0:48:99:0,144,1728; 0/0:42,0:42:99:0,126,1410; 0/0:37,0:37:99:0,111,1215; 0/0:39,0:39:99:0,117,1311; 0/0:42,0:42:99:0,126,1419; 0/0:53,0:53:99:0,159,1744; 0/0:45,0:45:99:0,135,1529; 0/0:44,0:44:99:0,132,1419; 0/0:38,0:38:99:0,114,1299; 0/0:37,0:37:99:0,111,1205; 0/0:34,0:34:99:0,102,1151; 0/0:57,0:57:99:0,171,1826; 0/0:27,1:28:49:0,49,904; 0/0:41,0:41:99:0,123,1364; 0/0:28,0:28:84:0,84,933; 0/0:36,0:36:99:0,108,1171; 0/0:29,0:29:87:0,87,987; 0/0:31,0:31:93:0,93,997; 0/0:37,0:37:99:0,111,126",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5445:1932,Pipeline,Pipeline,1932,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5445,2,"['Pipeline', 'pipeline']","['Pipeline', 'pipeline']"
Deployability,ng-boot-autoconfigure-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-logging\2.3.0.RELEASE\spring-boot-starter-logging-2.3.0.RELEASE.jar;E:\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\repository\org\apache\logging\log4j\log4j-to-slf4j\2.13.2\log4j-to-slf4j-2.13.2.jar;E:\repository\org\apache\logging\log4j\log4j-api\2.13.2\log4j-api-2.13.2.jar;E:\repository\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;E:\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;E:\repository\org\yaml\snakeyaml\1.26\snakeyaml-1.26.jar;E:\repository\com\zaxxer\HikariCP\3.4.5\HikariCP-3.4.5.jar;E:\repository\org\springframework\spring-jdbc\5.2.6.RELEASE\spring-jdbc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-beans\5.2.6.RELEASE\spring-beans-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-tx\5.2.6.RELEASE\spring-tx-5.2.6.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-web\2.3.0.RELEASE\spring-boot-starter-web-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-json\2.3.0.RELEASE\spring-boot-starter-json-2.3.0.RELEASE.jar;E:\repository\com\fasterxml\jackson\core\jackson-databind\2.11.0\jackson-databind-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-annotations\2.11.0\jackson-annotations-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-core\2.11.0\jackson-core-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.11.0\jackson-datatype-jdk8-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.11.0\jackson-datatype-jsr310-2.11.0.jar;E:\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.11.0\jackson-module-parameter-names-2.11.0.jar;E:\repository\org\springframework\boot\spring-boot-starter-tomcat\2.3.0.RELEASE\spring-boot-starter-tomcat-2.3.0.REL,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:3218,RELEASE,RELEASE,3218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,ng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.doWork(DataflowCommandLineProgram.java:107); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:151); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:78); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:75); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:126); ... 33 more; Caused by: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.genomics.dataflow.readers.bam.Reader.process(Reader.java:93); at com.google.cloud.genomics.dataflow.readers.bam.ReadBAMTransform$ReadFn.processElement(ReadBAMTransform.java:68); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/866:3786,Integrat,IntegrationTestSpec,3786,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866,2,['Integrat'],['IntegrationTestSpec']
Deployability,"ng: PrintReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 21:02:08.892 INFO PrintReadsSpark - Initializing engine; 21:02:08.892 INFO PrintReadsSpark - Done initializing engine; 18/07/24 21:02:08 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 18/07/24 21:02:09 INFO org.spark_project.jetty.util.log: Logging initialized @6492ms; 18/07/24 21:02:09 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 18/07/24 21:02:09 INFO org.spark_project.jetty.server.Server: Started @6584ms; 18/07/24 21:02:09 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@42ecc554{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/07/24 21:02:09 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 18/07/24 21:02:09 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.9.0-hadoop2; 18/07/24 21:02:10 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at shuang-small-m/10.128.5.217:8032; 18/07/24 21:02:10 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at shuang-small-m/10.128.5.217:10200; 18/07/24 21:02:12 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1532457503538_0038; 21:02:16.702 INFO FeatureManager - Using codec BEDCodec to read file hdfs://shuang-small-m:8020/data/intervals.bed; 21:02:16.863 INFO IntervalArgumentCollection - Processing 1219 bp from intervals; 18/07/24 21:02:17 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:6928,configurat,configuration,6928,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['configurat'],['configuration']
Deployability,"nges from @LeeTL1220, @meganshand, and @jsotobroad to dev branch. (Note that we exposed PreprocessIntervals.bin_length in these WDLs; I'm assuming that https://github.com/broadinstitute/cromwell/issues/2912 will allow this to be specified via the json, so I reverted this change.); - [x] Make simple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (@samuelklee); - [x] CLI for calling (cohort). (@samuelklee); - [x] CLI for calling (case). (@samuelklee); - [ ] CLI for post-processing calls. (@asmirnov239) (AS, PR issued by 12/4); - [x] Python environment. (Update: I've verified that gCNV works on the gsa server with a manual setup of conda (python=3.6) + @mbabadi's pip install---although I do get an ""install mkl"" warning from theano. We can discuss autoloading of this environment after release, but should at least have some clear documentation.); - [x] WDL and Cromwell tests. (SL, PR issued by 12/1); - [x] Preliminary evaluation. (MB, should be do",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3826:1616,Update,Update,1616,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826,1,['Update'],['Update']
Deployability,ngframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\repository\org\springframework\spring-core\5.2.6.RELEASE\spring-core-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-jcl\5.2.6.RELEASE\spring-jcl-5.2.6.RELEASE.jar;E:\repository\com\google\firebase\firebase-admin\6.8.1\firebase-admin-6.8.1.jar;E:\repository\com\google\api-client\google-api-client\1.25.0\google-api-client-1.25.0.jar;E:\repository\com\google\oauth-client\google-oauth-client\1.25.0\google-oauth-client-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-jackson2\1.25.0\google-http-client-jackson2-1.25.0.jar;E:\repository\com\google\api-client\google-api-client-gson\1.25.0\google-api-client-gson-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-gson\1.25.0\google-http-client-gson-1.25.0.jar;E:\repository\com\google\code\gson\gson\2.8.6\gson-2.8.6.jar;E:\repository\com\google\http-client\google-http-client\1.25.0\google-http-client-1.25.0.jar;E:\repository\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;E:\repository\org\apache\httpcomponents\httpclient\4.5.12\httpclient-4.5.12.jar;E:\repository\org\apache\httpcomponents\httpcore\4.4.13\httpcore-4.4.13.jar;E:\repository\c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:5691,RELEASE,RELEASE,5691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,no reason to depend on spark when we depend on spark ML lib anyway. Simpler to update 1 dependency than two. @lbergelson wdyt?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2035:79,update,update,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2035,1,['update'],['update']
Deployability,no-one should be calling close() by themselves. All Closables are Autoclosables and all should be converted to the modern style. Code migrated from Java 6 is full of the old idiom and needs to be updated.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/340:196,update,updated,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/340,1,['update'],['updated']
Deployability,"no. I didn't have time to look at the integration tests :-(. On Tue, Jan 12, 2021 at 3:17 PM droazen <notifications@github.com> wrote:. > @yfarjoun <https://github.com/yfarjoun> What do you want to do with this; > one? Are the issues with the tests resolved?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/6453#issuecomment-758914892>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AAU6JUVKOVTKSAHQK3SROIDSZSU33ANCNFSM4KUTOOYA>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6453#issuecomment-758946298:38,integrat,integration,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6453#issuecomment-758946298,1,['integrat'],['integration']
Deployability,nomicsDBImport - Done importing batch 53/65; 20:18:42.274 INFO  GenomicsDBImport - Done importing batch 54/65; 21:01:51.304 INFO  GenomicsDBImport - Done importing batch 55/65; 21:36:00.458 INFO  GenomicsDBImport - Done importing batch 56/65; 22:08:38.587 INFO  GenomicsDBImport - Done importing batch 57/65; 22:40:44.082 INFO  GenomicsDBImport - Done importing batch 58/65; 23:14:11.202 INFO  GenomicsDBImport - Done importing batch 59/65; 23:48:23.805 INFO  GenomicsDBImport - Done importing batch 60/65; 00:20:35.869 INFO  GenomicsDBImport - Done importing batch 61/65; 00:51:47.408 INFO  GenomicsDBImport - Done importing batch 62/65; 01:25:23.587 INFO  GenomicsDBImport - Done importing batch 63/65; 01:59:03.103 INFO  GenomicsDBImport - Done importing batch 64/65; Using GATK jar /share/pkg.7/gatk/[4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar](http://4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar) defined in environment variable GATK_LOCAL_JAR; Running:;     java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx150g -Xms16g -jar /share/pkg.7/gatk/[4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar](http://4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar) GenomicsDBImport --sample-name-map sample_map.chr3 --genomicsdb-workspace-path genomicsDB.rb.chr3 --genomicsdb-shared-posixfs-optimizations True --tmp-dir tmp --L chr3 --batch-size 50 --bypass-feature-reader --reader-threads 5 --merge-input-intervals --overwrite-existing-genomicsdb-workspace --consolidate; [farrell@scc-hadoop genomicsdb]$ ls genomicsDB.rb.chr3; __tiledb_workspace.tdb  chr3$1$198295559  vcfheader.vcf  vidmap.json. ```; It never indicates that it imported batch 65/65. No error and the  callset.json is missing which we found in chr4 to chr22. ;   ; ls genomicsDB.rb.chr4. __tiledb_workspace.tdb  callset.json  chr4$1$190214555  vcfheader.vcf  vidmap.json,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1246785232:3886,install,install,3886,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1246785232,2,['install'],['install']
Deployability,"nomicsDBImport - Start Date/Time: January 10, 2018 7:29:01 PST PM; 19:29:01.392 INFO GenomicsDBImport - ------------------------------------------------------------; 19:29:01.392 INFO GenomicsDBImport - ------------------------------------------------------------; 19:29:01.392 INFO GenomicsDBImport - HTSJDK Version: 2.13.2; 19:29:01.392 INFO GenomicsDBImport - Picard Version: 2.17.2; 19:29:01.392 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 19:29:01.392 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:29:01.392 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:29:01.392 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:29:01.393 INFO GenomicsDBImport - Deflater: IntelDeflater; 19:29:01.393 INFO GenomicsDBImport - Inflater: IntelInflater; 19:29:01.393 INFO GenomicsDBImport - GCS max retries/reopens: 20; 19:29:01.393 INFO GenomicsDBImport - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 19:29:01.393 INFO GenomicsDBImport - Initializing engine; 19:29:23.214 INFO IntervalArgumentCollection - Processing 1000000 bp from intervals; 19:29:23.216 INFO GenomicsDBImport - Done initializing engine; 19:29:23.332 INFO GenomicsDBImport - Shutting down engine; [January 10, 2018 7:29:23 PST PM] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.37 minutes.; Runtime.totalMemory()=2804940800; Exception in thread ""main"" java.lang.ExceptionInInitializerError; at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.overwriteOrCreateWorkspace(GenomicsDBImport.java:706); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.onTraversalStart(GenomicsDBImport.java:448); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:891); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineP",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4124:1875,patch,patch,1875,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124,1,['patch'],['patch']
Deployability,nonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1190); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). **This is the stack I get when the test completes but fails (note that the expected line count appears to not match the line count of the expected output file in the repo): **. java.lang.AssertionError: line counts expected [2629] but found [507]; 	at org.testng.Assert.fail(Assert.java:94); 	at org.testng.Assert.failNotEquals(Assert.java:496); 	at org.testng.Assert.assertEquals(Assert.java:125); 	at org.testng.Assert.assertEquals(Assert.java:372); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:211); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:190); 	at org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.testExampleAssemblyRegionWalker(ExampleAssemblyRegionWalkerSparkIntegrationTest.java:29); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); 	at org.testng.internal.TestMethodWorker.invok,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:3460,Integrat,IntegrationTestSpec,3460,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['Integrat'],['IntegrationTestSpec']
Deployability,note I still need to update the docker image and utils,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8728:21,update,update,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8728,1,['update'],['update']
Deployability,"now that we have the logic updated for per-assembly-contig view when it comes to SV type and breakpoint location inference, the next step is to take the comprehensive view, that is. * inter-contig view, i.e. mappings of other contigs nearby a potential breakpoint when inferring types ; * depth/coverage information; * evidence target links, i.e pair and split read information. To illustrate: consider a dispersed duplication, where the reference has sequence blocks `A z B` and the sample has sequence blocks arranged as `A z A B`.; Having assembled across the novel adjacency across the `A B` block, simply looking at the contig's alignment may fool us into calling a deletion&mdash;exactly what we are doing now&mdash;while it apparently is the wrong type.; On the other hand, if we have assembled across the `z A` block, without checking depth information, we might be thinking the blocks `A z` is being duplicated (we are not currently, but rather emit `BND` novel adjacency between the reference locations instead of emitting a duplication).; In the better (but not best, which we would have assembled across the whole event and the code currently would correctly emit the correct interpretation) scenario, we could have assembled across both novel adjacencies, and the increased coverage at `A` block, as well as outties pair linking `B` and `A` block, would allow us to formulate the whole picture.; Though difficult, it is what we must do. This ticket is to remind us that when we code our logic in any of these units, be open to other units for a comprehensive model on inference.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4189:27,update,updated,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4189,1,['update'],['updated']
Deployability,now that we're on htsjdk 2.2.1 we should switch to asyncIO for bams (not tribble); - [x] switch to asyncIO for bams (build.gradle); - [x] switch tests to use asyncIO for bams (build.gradle); - [x] update readme to say that we're using async IO; - [x] update startup message to clarify which IO is sync/async. measure and report performance impact on (using JdkDeflater and IntelDeflater); - [x] PrintReads ; - [x] BaseRecalibrator,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1653:197,update,update,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1653,2,['update'],['update']
Deployability,"now that we've actually solved the full problem and someone has successfully run from this env on a mac. >>> import gcnvkernel; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/__init__.py"", line 12, in <module>; from .sampling import *; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/sampling.py"", line 14, in <module>; from .plots.traceplot import traceplot; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/plots/__init__.py"", line 1, in <module>; from .autocorrplot import autocorrplot; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/plots/autocorrplot.py"", line 2, in <module>; import matplotlib.pyplot as plt; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/pyplot.py"", line 116, in <module>; _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup(); File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/__init__.py"", line 60, in pylab_setup; [backend_name], 0); File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/backend_macosx.py"", line 17, in <module>; from matplotlib.backends import _macosx; RuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are using (Ana)Conda please install python.app and replace the use of 'python' with 'pythonw'. See 'Working with Matplotlib on OSX' in the Matplotlib FAQ for more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356079886:1896,install,installed,1896,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356079886,4,['install'],"['install', 'installed', 'installing']"
Deployability,"nstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.NoSuchFileException: /user/yaron/output.bam.parts/_SUCCESS: Unable to find _SUCCESS file; at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:53); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:152); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:250); ... 18 more; ```; However, I can find that _SUCCESS file exists in output.bam.parts. Could someone tell me what may be the cause? Thanks!; ```; $ hdfs dfs -ls output.bam.parts; Found 3 items; -rw-r--r-- 3 yaron yaron 0 2017-06-08 09:14 output.bam.parts/_SUCCESS; -rw-r--r-- 3 yaron yaron 62019 2017-06-0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:6234,deploy,deploy,6234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['deploy'],['deploy']
Deployability,nstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:743); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)Caused by: java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2722); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1565); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2227); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2151); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2009); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1533); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:420); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Execut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:10020,deploy,deploy,10020,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['deploy'],['deploy']
Deployability,nstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:233); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:5793,deploy,deploy,5793,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,1,['deploy'],['deploy']
Deployability,nstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@3e0a9b1d: java.net.BindException: Address already in use; java.net.BindException: Address already in use; at sun.nio.ch.Net.bind0(Native Method); at sun.nio.ch.Net.bind(Net.java:433); at sun.nio.ch.Net.bind(Net.java:425); at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223); at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74); at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:321); at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80); at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:236); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.eclipse.jetty.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:7436,deploy,deploy,7436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725,1,['deploy'],['deploy']
Deployability,nstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:43661,deploy,deploy,43661,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['deploy'],['deploy']
Deployability,nstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:44407,deploy,deploy,44407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['deploy'],['deploy']
Deployability,nstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:153); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:277); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.GATKException: Erred when inferring breakpoint location and event type from chimeric alignment:; asm010450:tig00000 1_189_chrUn_JTFH01000312v1_decoy:663-851_-_189M512H_60_8_149_O 153_701_chrUn_JTFH01000312v1_decoy:1-549_+_152S549M_60_0_549_O; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignmentsSAMSpark.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); at java.util.stream.StreamSpliterators$Wrappin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:11480,deploy,deploy,11480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['deploy'],['deploy']
Deployability,"nstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RD",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:17491,deploy,deploy,17491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['deploy'],['deploy']
Deployability,"ntainer for locus/ref/alt is required. Some of the diffs are big but trivial. (In `AssemblyRegionTrimmer` I also deleted the unused `nonVariantTargetRegions` method).; - `AlleleAndContext` and `LocationAndAlleles` were deleted as the new `Event` class makes them obsolete.; - `AlleleFiltering` is a big diff but it's just a bunch of replacing `AlleleAndContext` with `Event`.; - `HaplotypeCallerGenotypingEngine`: some trivial renaming and use of `Event` instead of `VariantContext`.; - `PileupDetectionArgumentCollection`: fixed a typo.; - `LeftAlignAndTrimVariants`: just some optimized imports.; - `Event`: this is the new class at the heart of the PR.; - `EventMap`: lighter than it was. Storing a haplotype and other state were replaced by a static method to extract events from a haplotype. Using `Event` instead of `VariantContext` allowed several things to be written more concisely, but no big-picture changes. I didn't like how `buildEventMapForHaplotypes` both returned the set of event positions and filled in the haplotype's events as a side efffect, so I split it into a void method for filling events and another method for extracting start positions.; - `AlleleFilteringUnitTest`, `AssemblyBasedCallerUtilsUnitTest`, `HaplotypeCallerGenotypingEngineUnitTest.java`, `PartiallyDeterminedHaplotypeComputationEngineUnitTest`, `EventMapUnitTest`: everything that was tested before is still tested now. Lots of replacing `VariantContext` with `Event`. Deleted tests for a few unused methods here and there.; - The exact match expected VCF outputs in `HaplotypeCallerIntegrationTest`: no changes to the calls. Slight changes in QUALs and QD annotation due to arbitrariness of selecting which pileup haplotypes to retain in case of ties in the read kmer support score. I checked these all very carefully. A bunch of VCF didn't change but their .idx files did when I turned on the update exact match toggle. That's it for the trivially-changed classes. Now for the few substantive changes. . .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574146393:2532,update,update,2532,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574146393,2,"['toggle', 'update']","['toggle', 'update']"
Deployability,nternal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:55); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:573); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:125); 22:05:55.971 [ERROR] [org.gradle.int,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:2837,configurat,configuration,2837,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['configurat'],['configuration']
Deployability,"nternally by discrete RV posterior update routines (""callers"") as a safety measure to stabilize self-consistency loops. For example, consider the mean-field treatment of two coupled Markov chains: the mean-field decoupling of the two chains yields two independent Markov chains with effective emission, transition, and prior probabilities, all of which must be self-consistency determined. The internal admixing rate would be used to admix the old and new self-consistent fields across the two chains in order to dampen oscillations and improve convergence properties. Once internal convergence is achieved, the converged posteriors must be saved to a workspace in order to be consumed by the continuous sub-model. The new internally converged posteriors will be admixed with the old internally converged posteriors from the previous epoch with the _external_ admixing rate. - Introduced two-stage inference for cohort denoising and calling. In the first (""warm-up"") stage, discrete variables are marginalized out, yielding an effective continuous-only model. The warm-up stage calculates continuous posteriors based on the marginalized model. Once convergence is achieved, continuous and discrete variables are decoupled for the second (""main"") stage. The second stage starts with a discrete calling step (crucial), using continuous posteriors from the warm-up stage as the starting point. The motivation behind the two-stage inference strategy is to avoid getting trapped in spurious local minima that are potentially introduced by mean-field decoupling of discrete and continuous RVs. Note that mean-field decoupling has a tendency to stabilize local minima, most of which will disappear or turn into saddle points once correlations are taken into account. While the marginalized model is free of such spurious local minima, it does not yield discrete posteriors in a tractable way; hence, the necessity of ultimately decoupling in the ""main"" stage. - Capped phred-scaled qualities to maximum valu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4720:1275,continuous,continuous-only,1275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4720,1,['continuous'],['continuous-only']
Deployability,ntextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/04/27 18:49:12 ERROR org.apache.spark.util.Utils: Uncaught exception in thread main; java.lang.NullPointerException; at org.apache.spark.network.shuffle.ExternalShuffleClient.close(ExternalShuffleClient.java:152); at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1231); at org.apache.spark.SparkEnv.stop(SparkEnv.scala:96); at org.apache.spark.SparkContext$$anonfun$stop$12.apply$mcV$sp(SparkContext.scala:1756); at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1229); at org.apache.spark.SparkContext.stop(SparkContext.scala:1755); at org.apache.spark.SparkContext.<init>(SparkContext.scala:602); at ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:3410,deploy,deploy,3410,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,1,['deploy'],['deploy']
Deployability,"ntextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18:49:12.567 INFO PrintReadsSpark - Shutting down engine; [April 27, 2016 6:49:12 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=3858759680; java.io.FileNotFoundException: File file:/Users/louisb/Workspace/gatk-protected/build/libIntelDeflater.so does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:609); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:822); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:599); at ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:5581,deploy,deploy,5581,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,1,['deploy'],['deploy']
Deployability,ntextSelector.createContext(ClassLoaderContextSelector.java:171); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.locateContext(ClassLoaderContextSelector.java:145); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.getContext(ClassLoaderContextSelector.java:70); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.getContext(ClassLoaderContextSelector.java:57); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:140); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:41); at org.apache.logging.log4j.LogManager.getContext(LogManager.java:182); at org.apache.logging.log4j.LogManager.getLogger(LogManager.java:455); at org.broadinstitute.hellbender.utils.Utils.<clinit>(Utils.java:77); at org.broadinstitute.hellbender.Main.<clinit>(Main.java:45); at java.lang.Class.forName0(Native Method); at java.lang.Class.forName(Class.java:348); at org.apache.spark.util.Utils$.classForName(Utils.scala:230); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:739); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: org.apache.logging.log4j.core.appender.AbstractAppender; at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); ... 43 more. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/12624/java-lang-noclassdeffounderror-org-apache-logging-log4j-core-appender-abstractappender/p1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5126:5540,deploy,deploy,5540,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5126,6,['deploy'],['deploy']
Deployability,"ntig-Ploidy/22.Contig_Ploidy_Dir --output-prefix ploidy --verbosity DEBUG. .............................................................(BUG 002)..........................................................; Stderr: Traceback (most recent call last):; File ""/tmp/segment_gcnv_calls.3402406683372415608.py"", line 9, in <module>; import gcnvkernel; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/__init__.py"", line 5, in <module>; from .distributions import *; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/distributions/__init__.py"", line 1, in <module>; from . import timeseries; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/distributions/timeseries.py"", line 5, in <module>; from .continuous import get_tau_sd, Normal, Flat; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/distributions/continuous.py"", line 16, in <module>; from pymc3.theanof import floatX; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/theanof.py"", line 89, in <module>; empty_gradient = tt.zeros(0, dtype='float32'); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/tensor/basic.py"", line 2558, in zeros; return alloc(np.array(0, dtype=dtype), *shape); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/tensor/basic.py"", line 3091, in __call__; ret = super(Alloc, self).__call__(val, *shapes, **kwargs); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/op.py"", line 670, in __call__; no_recycling=[]); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/op.py"", line 955, in make_thunk; no_recycling); File ""/usr/local/Anaconda/envs_app/gatk/4.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235:10214,continuous,continuous,10214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235,1,['continuous'],['continuous']
Deployability,"ntimes for balanced sharding (#7645); - Wire through GvsExtractCohortFromSampleNames with new prepare/extract [VS-283] (#7654); - Update GvsExtractCallset.wdl (#7678); - cherry pick lb_lfs_force change (#7683); - Tweak ingest messaging and failure mode [VS-267] (#7680); - Additional tweaks for GvsExtractCohortFromSampleNames [VS-283] (#7698); - VS-280 Create a VAT intermediary (#7657); - There something about split intervals [VS-306] (#7694); - VS 284 Add prepare step to Quick Start (#7685); - VS-222 dont hard code the dataset name! (#7704); - fixed bug; added tests (#7717); - Clean up optional and inconsistently named inputs [VS-294] [VS-218] (#7715); - VS-263 notes on ingest and beyond (#7618); - Add task to ExtractCallset that verifies filter_set_name exists in GVS dataset [VS-335] (#7734); - Clean up input json files to reflect changes inputs [VS-337] (#7733); - used constants; implemented non-AS transformation (#7718); - Pass dataset name to gatk ExtractFeatures (#7735); - Add withdrawn and is_control columns [VS-70] [VS-213] (#7736); - Allow interval lists that require the SA to see (#7743); - allow for gatk to be overridden, update with known good jar (#7758); - VS-361 Add GvsWithdrawSamples wdl (#7765); - Extract Performance Improvements (#7686); - Don't put withdrawn sample data in alt_allele table [VS-369] (#7762); - remove PET code (#7768); - Adding AD for scale testing VS 225 add AD (#7713); - Deterministic Sample ID assignments [VS-371] (#7770); - remove R scripts from filtering (#7781); - Remove an old ""temp table"" dataset (#7780); - Clean up LocalizeFile [VS-314] (#7771); - Remove pet code from CreateVariantIngestFiles and friends [VS-375] (#7773); - 317 remove excess header values in VCF extract (#7786); - correct auth in split intervals (#7790); - Add code to (optionally) zero pad the vcf filename. (#7783); - LoadData `maxRetries` parameterized, default increased [VS-383] (#7791); - Update to latest version of ah_var_store gatk override jar (#7793); ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:22317,update,update,22317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['update'],['update']
Deployability,"nv_pon --verbosity DEBUG --p-alt 1e-6 --p-active 1e-2 --cnv-coherence-length 10000.0 --class-coherence-length 10000.0 --max-copy-number 5 --max-bias-factors 5 --mapping-error-rate 0.01 --interval-psi-scale 0.001 --sample-psi-scale 0.0001 --depth-correction-tau 10000.0 --log-mean-bias-standard-deviation 0.1 --init-ard-rel-unexplained-variance 0.1 --num-gc-bins 20 --gc-curve-standard-deviation 1.0 --copy-number-posterior-expectation-mode HYBRID --enable-bias-factors true --active-class-padding-hybrid-mode 50000 --learning-rate 0.05 --adamax-beta-1 0.9 --adamax-beta-2 0.99 --log-emission-samples-per-round 50 --log-emission-sampling-median-rel-error 0.005 --log-emission-sampling-rounds 10 --max-advi-iter-first-epoch 5000 --max-advi-iter-subsequent-epochs 100 --min-training-epochs 10 --max-training-epochs 100 --initial-temperature 2.0 --num-thermal-advi-iters 2500 --convergence-snr-averaging-window 500 --convergence-snr-trigger-threshold 0.1 --convergence-snr-countdown-window 10 --max-calling-iters 10 --caller-update-convergence-threshold 0.001 --caller-internal-admixing-rate 0.75 --caller-external-admixing-rate 1.00 --disable-annealing false. [2019-02-22 23:49:20,42] [info] WorkflowManagerActor WorkflowActor-098a389e-b298-4324-8a8c-9f46f05708b5 is in a terminal state: WorkflowFailedState; [2019-02-22 23:50:01,65] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2019-02-22 23:50:02,38] [info] Workflow polling stopped; [2019-02-22 23:50:02,48] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2019-02-22 23:50:02,49] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2019-02-22 23:50:02,53] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2019-02-22 23:50:02,53] [info] Aborting all running workflows.; [2019-02-22 23:50:02,53] [info] JobExecutionTokenDispenser stopped; [2019-02-22 23:50:02,53] [info] WorkflowStoreActor stopped; [2019-02-22 23:50:02,61] [info] WorkflowLogCopyRouter stopped; [2019-0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:30206,update,update-convergence-threshold,30206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,1,['update'],['update-convergence-threshold']
Deployability,"o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/cram_samtools.o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/cram_stats.o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/files.o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/mFILE.o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/open_trace_file.o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/pooled_alloc.o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/rANS_static.o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/sam_header.o build/temp.macosx-10.7-x86_64-3.6/htslib/cram/string_alloc.o build/temp.macosx-10.7-x86_64-3.6/htslib/hfile_libcurl.o build/temp.macosx-10.7-x86_64-3.6/htslib/hfile_gcs.o build/temp.macosx-10.7-x86_64-3.6/htslib/hfile_s3.o -Lpysam -L. -Lbuild/lib.macosx-10.7-x86_64-3.6/pysam -Lbuild/lib.macosx-10.7-x86_64-3.6/pysam -L/Users/markw/anaconda/envs/gatk/lib -lz -llzma -lbz2 -lz -lcurl -o build/lib.macosx-10.7-x86_64-3.6/pysam/libchtslib.cpython-36m-darwin.so -dynamiclib -rpath @loader_path -Wl,-headerpad_max_install_names -Wl,-install_name,@rpath/libchtslib.cpython-36m-darwin.so -Wl,-x; gcc: error: @loader_path: No such file or directory; gcc: error: unrecognized command line option ‘-rpath’; error: command 'gcc' failed with exit status 1. ----------------------------------------; Command ""/Users/markw/anaconda/envs/gatk/bin/python -u -c ""import setuptools, tokenize;__file__='/private/var/folders/x6/k5tc9mwd2z7dm1dthy4hv9nxmt8q9j/T/pip-build-aybz1ucp/pysam/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /var/folders/x6/k5tc9mwd2z7dm1dthy4hv9nxmt8q9j/T/pip-z_8e2y_r-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /private/var/folders/x6/k5tc9mwd2z7dm1dthy4hv9nxmt8q9j/T/pip-build-aybz1ucp/pysam/. CondaValueError: pip returned an error; ```; This appears to have been an issue with pysam in the past: https://github.com/pysam-developers/pysam/issues/323",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4742:3476,install,install,3476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4742,2,['install'],"['install', 'install-record']"
Deployability,"o from jar:file:/master/xxxxxxx/local/pckg/python/miniconda3/envs/cerc_prod/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Mon Jun 22 16:48:58 CDT 2020] MergeVcfs --INPUT data/calling/cerc_prod2.SM_V7_1.vcf.gz --INPUT data/calling/cerc_prod2.SM_V7_ZW.vcf.gz --OUTPUT out.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 22, 2020 4:48:58 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Mon Jun 22 16:48:58 CDT 2020] Executing as xxxxxxx@yyyyyy on Linux 3.10.0-693.11.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_152-release-1056-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; [Mon Jun 22 16:48:58 CDT 2020] picard.vcf.MergeVcfs done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=1211105280; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to create BasicFeatureReader using feature file , for input source: file:///data/infectious/schistosome/tmp/test%20a/data/calling/cerc_prod2.SM_V7_1.vcf.gz; at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:124); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:81); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:148); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:98); at picard.vcf.MergeVcfs.doWork(MergeVcfs.java:174); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647808241:2178,release,release-,2178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647808241,1,['release'],['release-']
Deployability,o/gh/broadinstitute/gatk/pull/4750/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL21hcmtkdXBsaWNhdGVzL0VzdGltYXRlTGlicmFyeUNvbXBsZXhpdHlHQVRLLmphdmE=) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...hellbender/utils/read/markduplicates/ReadEnds.java](https://codecov.io/gh/broadinstitute/gatk/pull/4750/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL1JlYWRFbmRzLmphdmE=) | `92% <100%> (ø)` | `15 <5> (ø)` | :arrow_down: |; | [...r/utils/read/markduplicates/sparkrecords/Pair.java](https://codecov.io/gh/broadinstitute/gatk/pull/4750/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL3NwYXJrcmVjb3Jkcy9QYWlyLmphdmE=) | `93.333% <100%> (+1.199%)` | `23 <7> (+1)` | :arrow_up: |; | [...forms/markduplicates/MarkDuplicatesSparkUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4750/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmtVdGlscy5qYXZh) | `90% <100%> (+0.36%)` | `69 <8> (+4)` | :arrow_up: |; | [...ates/AbstractMarkDuplicatesCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/4750/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL0Fic3RyYWN0TWFya0R1cGxpY2F0ZXNDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `93.333% <100%> (ø)` | `24 <4> (ø)` | :arrow_down: |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4750/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `77.778% <100%> (ø)` | `4 <0> (ø)` | :arrow_down: |; | ... and [13 more](https://codecov.io/gh/broadinstitute/gatk/pull/4750/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4750#issuecomment-387898984:3937,pipeline,pipelines,3937,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4750#issuecomment-387898984,1,['pipeline'],['pipelines']
Deployability,oadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:23436,deploy,deploy,23436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['deploy'],['deploy']
Deployability,oadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/11/29 16:21:01 ERROR org.apache.spark.util.Utils: Uncaught exception in thread main; java.lang.NullPointerException; 	at org.apache.spark.network.shuffle.ExternalShuffleClient.close(ExternalShuffleClient.java:152); 	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1286); 	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:96); 	at org.apache.spark.SparkContext$$anonfun$stop$12.apply$mcV$sp(SparkContext.scala:1756); 	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1219); 	at org.apache.spark.SparkContext.stop(SparkContext.scala:1755); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:602); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:150); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:82); 	at org.b,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2289:2368,deploy,deploy,2368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2289,1,['deploy'],['deploy']
Deployability,oadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/11/29 16:21:01 ERROR org.apache.spark.util.Utils: Uncaught exception in thread main; java.lang.NullPointerException; 	at org.apache.spark.network.shuffle.ExternalShuffleClient.close(ExternalShuffleClient.java:152); 	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1286); 	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:96); 	at org.apache.spark.SparkContext$$anonfun$stop$12.apply$mcV$sp(SparkContext.scala:1756); 	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1219); 	at org.apache.spark.SparkContext.stop(SparkContext.scala:1755); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:602); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:150); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:82); 	at org.b,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-264212007:2551,deploy,deploy,2551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-264212007,1,['deploy'],['deploy']
Deployability,"oadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16:21:01.561 INFO MarkDuplicatesSpark - Shutting down engine; [November 29, 2016 4:21:01 PM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=8232370176; org.apache.spark.SparkException: Could not parse Master URL: 'yarn'; 	at org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2735); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:522); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:150); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:82); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); 	at org.broadinstitute.hellbender.c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2289:4698,deploy,deploy,4698,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2289,1,['deploy'],['deploy']
Deployability,"oadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16:21:01.561 INFO MarkDuplicatesSpark - Shutting down engine; [November 29, 2016 4:21:01 PM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=8232370176; org.apache.spark.SparkException: Could not parse Master URL: 'yarn'; 	at org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2735); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:522); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:150); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:82); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); 	at org.broadinstitute.hellbender.c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-264212007:4881,deploy,deploy,4881,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-264212007,1,['deploy'],['deploy']
Deployability,oadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error reading null at position 0; 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.openStream(SeekableGCSStream.java:126); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.seek(SeekableGCSStream.java:103); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.<init>(SeekableGCSStream.java:59); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAMFile(BAMIO.java:67); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAM(BAMIO.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:178); 	... 20 more; Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; Bad Request; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146); 	at com.google.api.client.googleapis.services.json.AbstractGoo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-264909676:2942,deploy,deploy,2942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-264909676,1,['deploy'],['deploy']
Deployability,oadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error reading null at position 0; 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.openStream(SeekableGCSStream.java:126); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.seek(SeekableGCSStream.java:103); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.<init>(SeekableGCSStream.java:59); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAMFile(BAMIO.java:67); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAM(BAMIO.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:178); 	... 20 more; Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 401 Unauthorized; Anonymous users does not have storage.objects.get access to object mw-pathseq-test/hs37d5cs.reads.sorted.bam.; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(Go,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929:8969,deploy,deploy,8969,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929,1,['deploy'],['deploy']
Deployability,oadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Existing mirrorFile and resourceId don't match isDirectory status! '/hadoop_gcs_connector_metadata_cache/hellbender/test/output/gatk4-spark/recalibrated.bam' (dir: 'false') vs 'gs://hellbender/test/output/gatk4-spark/recalibrated.bam/' (dir: 'true'); 	at com.google.cloud.hadoop.gcsio.FileSystemBackedDirectoryListCache.getCacheEntryInternal(FileSystemBackedDirectoryListCache.java:198); 	at com.google.cloud.hadoop.gcsio.FileSystemBackedDirectoryListCache.putResourceId(FileSystemBackedDirectoryListCache.java:363); 	at com.google.cloud.hadoop.gcsio.CacheSupplementedGoogleCloudStorage.createEmptyObjects(CacheSupplementedGoogleCloudStorage.java:150); 	at com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.mkdirs(GoogleCloudStorageFileSystem.java:578); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.mkdirs(GoogleHadoopFileSystemBase.java:1372); 	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271419191:1791,deploy,deploy,1791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271419191,1,['deploy'],['deploy']
Deployability,oadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: Pathname /tmp/da63aa3c-e3bc-4893-9f40-42921719a343/hdfs:/svdev-caller-m:8020/reference/Homo_sapiens_assembly38.fasta from /tmp/da63aa3c-e3bc-4893-9f40-42921719a343/hdfs:/svdev-caller-m:8020/reference/Homo_sapiens_assembly38.fasta is not a valid DFS filename.; 	at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:213); 	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1436); 	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1433); 	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); 	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1448); 	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1436); 	at org.broadinstitute.hellbender.utils.spark.SparkUtils.pathExists(SparkUtils.java:100); 	at org.broadinstitute.hellbend,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2382:2858,deploy,deploy,2858,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2382,1,['deploy'],['deploy']
Deployability,"oadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.NullPointerException; 	at java.io.ByteArrayInputStream.<init>(ByteArrayInputStream.java:106); 	at org.broadinstitute.hellbender.engine.AuthHolder.getOfflineAuth(AuthHolder.java:79); 	at org.broadinstitute.hellbender.engine.AuthHolder.makeStorageClient(AuthHolder.java:94); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:177); 	... 20 more; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [bd000687-f538-4201-b888-668612d46bad] entered state [ERROR] while waiting for [DONE].; ```. =========================. On a third note, if the reference is also provided with a GCS path, we see this:. ```; ***********************************************************************. A USER ERROR has occurred: The specified fasta file (gs://sv-data-dsde-dev/reference/Homo_sapiens_assembly38.fasta) does not exist. ***********************************************************************; org.br",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2382:7594,deploy,deploy,7594,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2382,1,['deploy'],['deploy']
Deployability,oadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/04/27 18:49:12 ERROR org.apache.spark.util.Utils: Uncaught exception in thread main; java.lang.NullPointerException; at org.apache.spark.network.shuffle.ExternalShuffleClient.close(ExternalShuffleClient.java:152); at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1231); at org.apache.spark.SparkEnv.stop(SparkEnv.scala:96); at org.apache.spark.SparkContext$$anonfun$stop$12.apply$mcV$sp(SparkContext.scala:1756); at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1229); at org.apache.spark.SparkContext.stop(SparkContext.scala:1755); at org.apache.spark.SparkContext.<init>(SparkContext.scala:602); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFact,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:3666,deploy,deploy,3666,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,1,['deploy'],['deploy']
Deployability,"oadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18:49:12.567 INFO PrintReadsSpark - Shutting down engine; [April 27, 2016 6:49:12 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=3858759680; java.io.FileNotFoundException: File file:/Users/louisb/Workspace/gatk-protected/build/libIntelDeflater.so does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:609); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:822); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:599); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:337); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289); at org.apache.spark.deploy.yarn.Client.copyFileToRemote(Clie",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:5837,deploy,deploy,5837,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,1,['deploy'],['deploy']
Deployability,"oadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.main(Main.java:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.NotSerializableException: java.nio.HeapByteBuffer; Serialization stack:; **\- object not serializable (class: java.nio.HeapByteBuffer, value: java.nio.HeapByteBuffer[pos=0 lim=775456500 cap=775456500])**; - field (class: org.bdgenomics.adam.util.TwoBitFile, name: bytes, type: class java.nio.ByteBuffer); - object (class org.bdgenomics.adam.util.TwoBitFile, org.bdgenomics.adam.util.TwoBitFile@863c31e); - field (class: org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource, name: twoBitFile, type: class org.bdgenomics.adam.util.TwoBitFile); - object (class org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource, org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource@3c82e6f4); - field (class: org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource, name: referenceSource, type: interfac",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2216:2830,deploy,deploy,2830,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2216,1,['deploy'],['deploy']
Deployability,oadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:204); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:381); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:361); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:351); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:108); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:128); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:28); at org.broadinstitute.hellbender.utils.test.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:88); at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSparkIntegrationTest.testNonExistentInputBam(CountReadsSparkIntegrationTest.java:111). Caused by:; java.io.FileNotFoundException: /Users/tom/workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/nonexistent.bam; at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:200); at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:344); at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:767); at org.seqdoop.hadoop_bam.util.SAMHeaderReader.readSAMHeaderFrom(SAMHeaderReader.java:51); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:202); ... 13 more; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2541#issuecomment-293293199:1809,pipeline,pipelines,1809,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2541#issuecomment-293293199,1,['pipeline'],['pipelines']
Deployability,oadinstitute/gatk/jobs/498538899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.13/tests/test/index.html) |; | integration | openjdk11 | [33752.12](https://travis-ci.com/broadinstitute/gatk/jobs/498538898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.12/tests/test/index.html) |; | variantcalling | openjdk8 | [33752.4](https://travis-ci.com/broadinstitute/gatk/jobs/498538890) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.4/tests/test/index.html) |; | unit | openjdk8 | [33752.3](https://travis-ci.com/broadinstitute/gatk/jobs/498538889) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.3/tests/test/index.html) |; | conda | openjdk8 | [33752.5](https://travis-ci.com/broadinstitute/gatk/jobs/498538891) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.5/tests/test/index.html) |; | integration | openjdk8 | [33752.2](https://travis-ci.com/broadinstitute/gatk/jobs/498538888) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.2/tests/test/index.html) |; | cloud | openjdk11 | [33752.14](https://travis-ci.com/broadinstitute/gatk/jobs/498538900) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.14/tests/test/index.html) |; | cloud | openjdk8 | [33752.1](https://travis-ci.com/broadinstitute/gatk/jobs/498538887) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.1/tests/test/index.html) |; | unit | openjdk11 | [33752.13](https://travis-ci.com/broadinstitute/gatk/jobs/498538899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.13/tests/test/index.html) |; | integration | openjdk11 | [33752.12](https://travis-ci.com/broadinstitute/gatk/jobs/498538898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_337,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-819750234:1675,integrat,integration,1675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-819750234,1,['integrat'],['integration']
Deployability,ocalFileSystem.java:822); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:599); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:337); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289); at org.apache.spark.deploy.yarn.Client.copyFileToRemote(Client.scala:317); at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:407); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:471); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:470); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:470); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:468); at scala.collection.immutable.List.foreach(List.scala:318); at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:468); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:727); at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:142); at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:57); at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144); at org.apache.spark.SparkContext.<init>(SparkContext.scala:530); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkComman,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:1602,deploy,deploy,1602,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,2,['deploy'],['deploy']
Deployability,"ocker image is this:; ```; FROM bde2020/spark-master:2.2.0-hadoop2.8-hive-java8. MAINTAINER Jhonattan Loza <toro.ryan.jcl@gmail.com>. COPY picard.jar /; COPY GenomeAnalysisTK_v3.8-0-ge9d806836.jar /. RUN curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash; RUN apt-get install -y git-lfs; RUN git lfs install; RUN apt-get install unzip; RUN apt-get install wget; RUN apt-get install git. RUN mkdir /gatk; RUN apt-get update && apt-get install -y python git mlocate htop && export JAVA_TOOL_OPTIONS=-Dfile.encoding=UTF8 && \; wget https://github.com/broadinstitute/gatk/releases/download/4.0.4.0/gatk-4.0.4.0.zip && unzip gatk-4.0.4.0.zip -d tmp && mv tmp/gatk-4.0.4.0/* /gatk && cp /spark/conf/spark-defaults.conf.template /spark/conf/spark-defaults.conf && \; echo ""spark.eventLog.enabled true"" >> /spark/conf/spark-defaults.conf && \; echo ""spark.eventLog.dir file:///spark/logs/"" >> /spark/conf/spark-defaults.conf. ENV PATH=""$PATH:/spark/bin""; ```; I have this configurations for docker-compose:; - Spark. ```; version: '3'; services:; spark-master:; image: atahualpa/spark-master:GATK4.0.4; networks:; - workbench; deploy:; replicas: 1; mode: replicated; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8080; env_file:; - ./hadoop.env; ports:; - 8333:8080; - 4040:4040; - 6066:6066; - 7077:7077; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/fastq/:/fastq/; - /data0/NGS-SparkGATK/NGS-SparkGATK/:/NGS-SparkGATK/; - /data/ngs/:/ngs/; - /data0/output/:/output/; spark-worker:; image: bde2020/spark-worker:2.2.0-hadoop2.8-hive-java8; networks:; - workbench; environment:; - SPARK_MASTER=spark://spark-master:7077; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8081. env_file:; - ./hadoop.env; volumes:; - reference-image:/reference_image. reference:; image: vzzarr/reference:hg19_img; networks:; - workbench; de",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:1101,configurat,configurations,1101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['configurat'],['configurations']
Deployability,"odule>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 140, in <module>; preargs=args); File ${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2396, in compile_str; (status, compile_stderr.replace('\n', '. '))); Exception: Compilation failed (return status=1): /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_deregisterTMCloneTable. /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_registerTMCloneTable. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x1a): error: unsupported reloc 42. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x6b): error: unsupported reloc 42. collect2: error: ld returned 1 exit status. ```. Then I have installed theano with python 3.6.6 which is compiled with gcc 5.4.0, and it was giving me no errors. ```sh. $ theano-nose . ----------------------------------------------------------------------; Ran 0 tests in 0.012s. OK; ```. The Theano toolchain issue might be caused by theano not being actively developed anymore. Probably they never tested it with newer toolchains.; See this message that is also on the Theano github page.; https://groups.google.com/d/msg/theano-users/7Poq8BZutbY/rNCIfvAEAwAJ. #### Steps to reproduce; see description. #### Expected behavior; see description. #### Actual behavior; see description. ----. ## Feature request; - Switch from pymc3/Theano to another framework that offers the same functionality; - Modify the depedencies of gcnvkernel. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:3372,INSTALL,INSTALLDIRGCC,3372,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,2,"['INSTALL', 'install']","['INSTALLDIRGCC', 'installed']"
Deployability,"of the expected files, since the transform is appended to the corresponding variable name. DetermineGermlineContigPloidy and PostprocessGermlineCNVCalls are missing exact-match tests and should probably have some, but I'll leave that to someone else.; - [x] Update other python integration tests.; - [x] Clean up some of the changes to the priors.; - [x] Clean up some TODO comments that I left to track code changes that might result in changed numerics. I'll try to go through and convert these to PR comments in an initial review pass.; - [x] Test over multiple shards on WGS and WES. Probably some scientific tests on ~100 samples in both cohort and case mode would do the trick. We should also double check runtime/memory performance (I noted ~1.5x speedups, but didn't measure carefully; I also want to make sure the changes to posterior sampling didn't introduce any memory issues). @mwalker174 will ping you when a Docker is ready! Might be good to loop in Isaac and/or Jack as well.; - [x] Perhaps add back the fix for 2-interval shards in https://github.com/broadinstitute/gatk/pull/8180, which I removed since the required functionality wasn't immediately available in Pytensor. Not sure if this actually broke things though---need to check. (However, I don't actually think this is a very important use case to support...); - [x] Delete/deprecate/etc. CNN tools/tests as appropriate. Note that this has to be done concurrently, since we remove Tensorflow. @droazen perhaps I can take a first stab at this in a subsequent commit to this PR once more of the gCNV dust settles and/or has undergone a preliminary review? EDIT: Disabled integration/WDL tests. We should add some deprecation messages to the tools---we can note that they should still work in previous environments but will be untested. I might set up a separate PR for deletion, to be done at the appropriate time (but I call dibs on this, can't have @davidbenjamin overtaking my all-time record for number of lines deleted 😛).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285:3800,integrat,integration,3800,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285,1,['integrat'],['integration']
Deployability,"oft/gatk-4.4.0.0# ""$CONDA"" env create -n gatk -f ""$SOFT/gatk-${GATK_VERSION}/gatkcondaenv.yml""; ...; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Installing pip dependencies: | Ran pip subprocess with arguments:; ['/opt/miniconda/envs/gatk/bin/python', '-m', 'pip', 'install', '-U', '-r', '/soft/gatk-4.4.0.0/condaenv.i9brvcrk.requirements.txt', '--exists-action=b']; Pip subprocess output:. Pip subprocess error:; /opt/miniconda/envs/gatk/bin/python: No module named pip. failed. CondaEnvException: Pip failed. ```; ---; It can be fixed with setting classic colver:; ```; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda --version; conda 23.10.0; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda config --set solver classic; root@d12ac7710afc:/soft/gatk-4.4.0.0# ""$CONDA"" env create -n gatk -f ""$SOFT/gatk-${GATK_VERSION}/gatkcondaenv.yml""; ...; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Installing pip dependencies: \ Ran pip subprocess with arguments:; ['/opt/miniconda/envs/gatk/bin/python', '-m', 'pip', 'install', '-U', '-r', '/soft/gatk-4.4.0.0/condaenv.rtsyg5rl.requirements.txt', '--exists-action=b']; Pip subprocess output:; Processing ./gatkPythonPackageArchive.zip; Building wheels for collected packages: gatkpythonpackages; Building wheel for gatkpythonpackages (setup.py): started; Building wheel for gatkpythonpackages (setup.py): finished with status 'done'; Created wheel for gatkpythonpackages: filename=gatkpythonpackages-0.1-py3-none-any.whl size=117686 sha256=f2165b43e412c95ff9a788022d355279e5434032fb8c9cf82fbd71779acd1a76; Stored in directory: /tmp/pip-ephem-wheel-cache-5a9zdytx/wheels/06/f7/e1/87cb7da6f705baa602256a58c9514b47dc313aade8809a01da; Successfully built gatkpythonpackages; Installing collected packages: gatkpythonpackages; Successfully installed gatkpythonpackages-0.1. done; #; # To activate this environment, use; #; # $ conda activate gatk; #; # To deactivate an active environmen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8618:2817,Install,Installing,2817,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8618,2,"['Install', 'install']","['Installing', 'install']"
Deployability,"ogress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. After sourcing the tab-completion script, some tools shown cannot be run. Maybe they exist somewhere in an experimental dev version but are not bundled for public release?. ### Affected version(s); - [x ] Latest public release version [4.1.7.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. After trying to tab complete the DepthOfCoverage, I saw a few tools not listed in the documentation. I tried running them and sure enough, there were errors:. `A USER ERROR has occurred: '*' is not a valid command.`; (* is one of the tools listed below). #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. ```; cd gatk-4.1.7.0; source gatk-completion.sh; ./gatk Depth<tab>; #>DepthOfCoverage DepthPerAlleleBySample DepthPerSampleHC; ./gatk DepthPerSampleHC -h; ...; ***********************************************************************; A USER ERROR has occurred: 'DepthPerSampleHC' is not a valid command.; *******************",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6615:1480,release,release,1480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6615,1,['release'],['release']
Deployability,"ok so we will want to set the limit to 100 and update the VCF header, but this is a start at what I want for the filter model creation update",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8843:47,update,update,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8843,2,['update'],['update']
Deployability,"ok, got it. sorry, i missed 'install' in that command. my initial impression is that VariantQC will be able to adapt fine to VariantEvalEngine. I wrote VariantEvalEngine with this is mind, but it's good to formally test it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759645374:29,install,install,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759645374,1,['install'],['install']
Deployability,"olicy; 18/04/24 17:55:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, xx.xx.xx.16, 49734, None); 18/04/24 17:55:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/1 is now RUNNING; 18/04/24 17:55:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/2 is now RUNNING; 18/04/24 17:55:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/3 is now RUNNING; 18/04/24 17:55:01 INFO BlockManagerMasterEndpoint: Registering block manager xx.xx.xx.16:49734 with 366.3 MB RAM, BlockManagerId(driver, xx.xx.xx.16, 49734, None); 18/04/24 17:55:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, xx.xx.xx.16, 49734, None); 18/04/24 17:55:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, xx.xx.xx.16, 49734, None); 18/04/24 17:55:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/4 is now RUNNING; 18/04/24 17:55:03 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0; 18/04/24 17:55:03 INFO GoogleHadoopFileSystemBase: GHFS version: 1.6.3-hadoop2; 18/04/24 17:55:04 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/5 is now RUNNING; 18/04/24 17:55:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 276.0 KB, free 366.0 MB); 00:10 DEBUG: [kryo] Write: SerializableConfiguration; 18/04/24 17:55:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.1 KB, free 366.0 MB); 18/04/24 17:55:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.16:49734 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:55:05 INFO SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:113; 18/04/24 17:55:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/0 is now RU",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:13557,update,updated,13557,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['update'],['updated']
Deployability,ollowing jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6016742374.11](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16321393716) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.11/tests/test/index.html) |; | integration | 11 | [6016742374.12](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16321393852) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.12/tests/test/index.html) |; | cloud | 11 | [6016742374.11](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16347530908) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.11/tests/test/index.html) |; | unit | 11 | [6016742374.13](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16347531468) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.13/tests/test/index.html) |; | integration | 11 | [6016742374.12](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16347531169) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.12/tests/test/index.html) |; | unit | 11 | [6016742374.13](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16362542517) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.13/tests/test/index.html) |; | cloud | 11 | [6016742374.11](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16362542090) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.11/tests/test/index.html) |; | integration | 11 | [6016742374.12](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16362542310) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8459#issuecomment-1698045984:1202,integrat,integration,1202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8459#issuecomment-1698045984,2,['integrat'],['integration']
Deployability,"ols.github.io/hts-specs/VCFv4.2.pdf) doesn't actually say what format should the SB field be, so overriding it seems to be a bug in htsjdk?. #### Steps to reproduce; ```; cat sb-good-tiny.vcf; ##fileformat=VCFv4.2; ##INFO=<ID=SB,Number=.,Type=Integer,Description="""">; ##contig=<ID=chr1,length=248956422,assembly=GRCh38>; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO; chr1	10146	.	AC	A	.	.	SB=5,2,18,29. gatk ApplyVQSR -O sb-recalibrated-tiny.vcf -V sb-good-tiny.vcf --recal-file recalibration. cat sb-recalibrated-tiny.vcf; ##fileformat=VCFv4.2; ##FILTER=<ID=LOW_VQSLOD,Description=""VQSLOD < 0.0"">; ##FILTER=<ID=PASS,Description=""Site contains at least one allele that passes filters"">; ##GATKCommandLine=<ID=ApplyVQSR,CommandLine=""ApplyVQSR --recal-file /Users/vlad/tmp/sb/recalibration --output sb-recalibrated-tiny-renamed4.vcf --variant sb-good-tiny-renamed4.vcf --use-allele-specific-annotations false --ignore-all-filters false --exclude-filtered false --mode SNP --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays --disable-tool-default-read-filters false"",Version=""4.1.9.0"",Date=""31 May 2021 12:07:54 PM"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""Stop position of the interval"">; ##INFO=<ID=NEGATIVE_TRAIN_SITE,Number=0,Type=Flag,Description=""This variant was used to build the negative",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7280:2358,update,updates,2358,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7280,1,['update'],['updates']
Deployability,"om intervals; 14:21:38.716 INFO PostprocessGermlineCNVCalls - Done initializing engine; 14:21:38.879 INFO PostprocessGermlineCNVCalls - Shutting down engine; [August 1, 2018 2:21:38 PM CEST] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=2267545600; java.lang.IllegalArgumentException: The specified allosomal contigs must be contained in the SAM sequence dictionary of the call-set (specified allosomal contigs: [Y], all contigs: [chr9, chr7, chr8, chr5, chr6, chr3, chr21, chr4, chr22, chr1, chr2, chr20, chrY, chrX, chr10, chr11, chr12, chr13, chrM, chr18, chr19, chr14, chr15, chr16, chr17]); at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:722); at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.onTraversalStart(PostprocessGermlineCNVCalls.java:277); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:992); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. ----. ## Notes. During all the procedures of the gCNV calling pipeline, I provided a target bed interval file with the 1,3,9,17,Y and M chromosomes, except for the DetermineGermlineContigPloidy were I provided a prior_contig_diploidy.tsv with all the infrerred ploidy. But the calls show only the requested chromosomes so I guessed it was fine but maybe not. It's like, in the PostprocessGermlineCNVCalls step, it's ignoring my filtered target (""-L"") or my reference (""-R). ----. Any solution ? . Thank you again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053#issuecomment-409558231:6055,pipeline,pipeline,6055,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053#issuecomment-409558231,1,['pipeline'],['pipeline']
Deployability,"omaticPanelOfNormals. ### Affected version; Tested on version 4.1.8.0 (likely commit 3e921c6, GenomicsDB 1.3.0 #6654). ### Description ; Panel of normals generated from version 4.1.8.0 has some ~28% less records (~52% less ALT alleles) than one created with 4.1.7.0 (tested at commit 9cc92e3) with all input data and arguments unchanged. The GenomicsDB version does not seem to matter as PoN created running CreateSomaticPanelOfNormals on 4.1.8.0 has the result is about the same regardless of whether GenomicsDBImport was run on 4.1.7.0 or 4.1.8.0. CreateSomaticPanelOfNormals on 4.1.7.0 fails to run on the new GenomicsDBs. |Mutect2|GenomicsDB|CreateSomaticPanelOfNormals|Output|; |---|---|---|---|; |4.1.7.0|4.1.7.0|4.1.7.0|100% alleles (reference)|; |4.1.8.0|4.1.8.0|4.1.7.0|expected error|; |4.1.7.0|4.1.7.0|4.1.8.0|48% alleles|; |4.1.8.0|4.1.8.0|4.1.8.0|48% alleles|. #### Steps to reproduce; The PoN was created with GRCh38, scattered over chromosomes. Mutect command:; ```; $gatk/gatk --java-options ""-Xmx4G"" Mutect2 \; 	-R $reference -L $chr \; 	-I $bam --max-mnp-distance 0 \; 	-O @out1@; ```. GenomicsDBImport command:; ```; $gatk/gatk --java-options ""-Xms8G -Xmx8G"" GenomicsDBImport \; 	-R $reference -L $chr \; 	--sample-name-map ${inputGenomicsDB.out1} \; 	--genomicsdb-workspace-path @folder1@; ```. CreateSomaticPanelOfNormals:; ```; $gatk/gatk --java-options ""-Xms8G"" CreateSomaticPanelOfNormals \; 	-R $reference -V gendb://@folder1@ -O @out1@ \; 	--germline-resource $gnomad \; 	--max-germline-probability 0.5; ```. #### Expected behavior; Based on description of the GenomicsDB 1.3.0 update, CreateSomaticPanelOfNormals is expected to behave similarly in 4.1.8.0 as before with the output PoN containing a similar number of variants. #### Actual behavior; 28% of PoN records (52% alleles) are missing in 4.1.8.0 compared to 4.1.7.0. Although all spanning deletions are dropped in the new version, they account for only a small portion of the loss (6.8% / 52% missing ALT alleles).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6744:1645,update,update,1645,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744,1,['update'],['update']
Deployability,"ome; - cds_end_NF: the coding region end could not be confirmed; - cds_start_NF: the coding region start could not be confirmed; - mRNA_end_NF: the mRNA end could not be confirmed; - mRNA_start_NF: the mRNA start could not be confirmed.; - basic: the transcript is part of the gencode basic geneset. Comments. Lines may be commented out by the addition of a single # character at the start. These; lines should be ignored by your parser. Pragmas/Metadata. GTF files can contain meta-data. In the case of experimental meta-data these are ; noted by a #!. Those which are stable are noted by a ##. Meta data is a single key,; a space and then the value. Current meta data keys are:. * genome-build - Build identifier of the assembly e.g. GRCh37.p11; * genome-version - Version of this assembly e.g. GRCh37; * genome-date - The date of this assembly's release e.g. 2009-02; * genome-build-accession - The accession and source of this accession e.g. NCBI:GCA_000001405.14; * genebuild-last-updated - The date of the last genebuild update e.g. 2013-09. ------------------; Example GTF output; ------------------. #!genome-build GRCh38; 11 ensembl_havana gene 5422111 5423206 . + . gene_id ""ENSG00000167360""; gene_version ""4""; gene_name ""OR51Q1""; gene_source ""ensembl_havana""; gene_biotype ""protein_coding"";; 11 ensembl_havana transcript 5422111 5423206 . + . gene_id ""ENSG00000167360""; gene_version ""4""; transcript_id ""ENST00000300778""; transcript_version ""4""; gene_name ""OR51Q1""; gene_source ""ensembl_havana""; gene_biotype ""protein_coding""; transcript_name ""OR51Q1-001""; transcript_source ""ensembl_havana""; transcript_biotype ""protein_coding""; tag ""CCDS""; ccds_id ""CCDS31381"";; 11 ensembl_havana exon 5422111 5423206 . + . gene_id ""ENSG00000167360""; gene_version ""4""; transcript_id ""ENST00000300778""; transcript_version ""4""; exon_number ""1""; gene_name ""OR51Q1""; gene_source ""ensembl_havana""; gene_biotype ""protein_coding""; transcript_name ""OR51Q1-001""; transcript_source ""ensembl_havana""; transcript_bioty",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6488:6208,update,updated,6208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6488,2,['update'],"['update', 'updated']"
Deployability,"omething similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); gatk-4.1.8.1; - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I was running Concordance analysis via:. gatk Concordance -R human_g1k_v37.fasta -eval new.vcf --truth old.vcf --summary summary.tsv. my summary.tsv contains only this:. type TP FP FN RECALL PRECISION; SNP 285 1876867 2535060 0.0 0.0; INDEL 0 0 8542 0.0 0.0. Can you please tell me how I can interpret this?. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentatio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6795:1320,release,release,1320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6795,1,['release'],['release']
Deployability,omicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 01:22:35.483 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 01:22:35.483 INFO GenomicsDBImport - Deflater: IntelDeflater; 01:22:35.483 INFO GenomicsDBImport - Inflater: IntelInflater; 01:22:35.483 INFO GenomicsDBImport - GCS max retries/reopens: 20; 01:22:35.483 INFO GenomicsDBImport - Requester pays: disabled; 01:22:35.484 INFO GenomicsDBImport - Initializing engine; 01:24:58.683 INFO FeatureManager - Using codec BEDCodec to read file file:///lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/intervals.bed; 01:24:58.801 INFO IntervalArgumentCollection - Processing 11500 bp from intervals; 01:24:58.803 INFO GenomicsDBImport - Done initializing engine; 01:24:59.055 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.2-e18fa63; 01:25:02.076 INFO GenomicsDBImport - Vid Map JSON file will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; 01:25:02.077 INFO GenomicsDBImport - Callset Map JSON file will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/callset.json; 01:25:02.077 INFO GenomicsDBImport - Complete VCF Header will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vcfheader.vcf; 01:25:02.077 INFO GenomicsDBImport - Importing to workspace - /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb; 01:25:02.078 INFO ProgressMeter - Starting traversal; 01:25:02.078 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/per,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7598:3238,update,update,3238,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7598,1,['update'],['update']
Deployability,"ommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18:49:12.567 INFO PrintReadsSpark - Shutting down engine; [April 27, 2016 6:49:12 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=3858759680; java.io.FileNotFoundException: File file:/Users/louisb/Workspace/gatk-protected/build/libIntelDeflater.so does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:609); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:822); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:599); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:337); at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289); at org.apache.spark.deploy.yarn.Client.copyFileToRemote(Client.scala:317); at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:407); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:471); at org.ap",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:6082,pipeline,pipelines,6082,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,1,['pipeline'],['pipelines']
Deployability,ompositeStoppable.stop(CompositeStoppable.java:98); at org.gradle.internal.service.DefaultServiceRegistry$CompositeProvider.stop(DefaultServiceRegistry.java:920); at org.gradle.internal.concurrent.CompositeStoppable.stop(CompositeStoppable.java:98); at org.gradle.internal.service.DefaultServiceRegistry.close(DefaultServiceRegistry.java:326); at org.gradle.internal.concurrent.CompositeStoppable$2.stop(CompositeStoppable.java:83); at org.gradle.internal.concurrent.CompositeStoppable.stop(CompositeStoppable.java:98); at org.gradle.initialization.DefaultGradleLauncher.stop(DefaultGradleLauncher.java:199); at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:46); at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:28); at org.gradle.launcher.exec.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:77); at org.gradle.launcher.exec.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:47); at org.gradle.launcher.exec.DaemonUsageSuggestingBuildActionExecuter.execute(DaemonUsageSuggestingBuildActionExecuter.java:51); at org.gradle.launcher.exec.DaemonUsageSuggestingBuildActionExecuter.execute(DaemonUsageSuggestingBuildActionExecuter.java:28); at org.gradle.launcher.cli.RunBuildAction.run(RunBuildAction.java:43); at org.gradle.internal.Actions$RunnableActionAdapter.execute(Actions.java:170); at org.gradle.launcher.cli.CommandLineActionFactory$ParseAndBuildAction.execute(CommandLineActionFactory.java:237); at org.gradle.launcher.cli.CommandLineActionFactory$ParseAndBuildAction.execute(CommandLineActionFactory.java:210); at org.gradle.launcher.cli.JavaRuntimeValidationAction.execute(JavaRuntimeValidationAction.java:35); at org.gradle.launcher.cli.JavaRuntimeValidationAction.execute(JavaRuntimeValidationAction.java:24); at org.gradle.launcher.cli.CommandLineActionFactory$WithLogging.execute(CommandLineActionFactory.java:206); at org.gradle.launcher,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:4937,Continuous,ContinuousBuildActionExecuter,4937,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,3,['Continuous'],['ContinuousBuildActionExecuter']
Deployability,"on localhost (executor driver) (4/4); 17/05/05 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool ; 17/05/05 17:03:58 INFO DAGScheduler: ResultStage 2 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:202) finished in 10.370 s; 17/05/05 17:03:58 INFO DAGScheduler: Job 1 finished: saveAsNewAPIHadoopFile at ReadsSparkSink.java:202, took 16.702399 s; 17/05/05 17:03:58 INFO SparkUI: Stopped Spark web UI at http://172.30.0.122:46483; 17/05/05 17:03:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/05/05 17:03:59 INFO MemoryStore: MemoryStore cleared; 17/05/05 17:03:59 INFO BlockManager: BlockManager stopped; 17/05/05 17:03:59 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/05/05 17:03:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/05/05 17:03:59 INFO SparkContext: Successfully stopped SparkContext; [May 5, 2017 5:03:59 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=799080448; 17/05/05 17:03:59 INFO ApplicationMaster: Final app status: FAILED, exitCode: 16, (reason: Shutdown hook called before final status was reported.); 17/05/05 17:03:59 INFO ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: Shutdown hook called before final status was reported.); 17/05/05 17:03:59 INFO ApplicationMaster: Deleting staging directory hdfs://ip-172-30-0-86.ec2.internal:8020/user/hadoop/.sparkStaging/application_1493961816416_0010; 17/05/05 17:03:59 INFO ShutdownHookManager: Shutdown hook called; 17/05/05 17:03:59 INFO ShutdownHookManager: Deleting directory /mnt1/yarn/usercache/hadoop/appcache/application_1493961816416_0010/spark-223a9e8b-0fe9-41f0-8bed-f843978f1882; 17/05/05 17:03:59 INFO ShutdownHookManager: Deleting directory /mnt/yarn/usercache/hadoop/appcache/application_1493961816416_0010/spark-573a9c53-e268-4f3b-8907-1f35e5839788; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299525046:18234,pipeline,pipelines,18234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299525046,2,['pipeline'],['pipelines']
Deployability,"on;; import java.nio.file.Files;; import java.nio.file.Path;; import java.nio.file.Paths;; import java.nio.file.spi.FileSystemProvider;; import java.util.ArrayList;; import java.util.List;; import java.util.ServiceLoader;. @CommandLineProgramProperties(summary = ""test"", oneLineSummary = ""testthing"", programGroup = SparkProgramGroup.class); public class TestGCS extends GATKSparkTool {; private static final long serialVersionUID = 1L;. @Override; protected void runTool(JavaSparkContext ctx) {; try {; modifyProviders();; } catch (IllegalAccessException | NoSuchFieldException e) {; throw new RuntimeException(""Couldn't reset FilesystemProviders"");; }; try {; final Path index = Paths.get(new URI(""gs://hellbender/test/build_reports/1626.1/tests/index.html""));; System.out.println(""Count:"" + Files.lines(index).count());; } catch (URISyntaxException | IOException e) {; throw new RuntimeException(""Couldn't read file"");; }; }; }. private void modifyProviders() throws IllegalAccessException, NoSuchFieldException {; final Field installedProviders = FileSystemProvider.class.getDeclaredField(""installedProviders"");; installedProviders.setAccessible(true);; installedProviders.set(null, loadInstalledProviders());; installedProviders.setAccessible(false);; }. //copied from FileSystemProvider, modified to use TestGCS.classLoader() instead of systemClassloader; private static List<FileSystemProvider> loadInstalledProviders() {; List<FileSystemProvider> list = new ArrayList<FileSystemProvider>();. ServiceLoader<FileSystemProvider> sl = ServiceLoader; .load(FileSystemProvider.class, TestGCS.class.getClassLoader());. // ServiceConfigurationError may be throw here; for (FileSystemProvider provider: sl) {; String scheme = provider.getScheme();. // add to list if the provider is not ""file"" and isn't a duplicate; if (!scheme.equalsIgnoreCase(""file"")) {; boolean found = false;; for (FileSystemProvider p: list) {; if (p.getScheme().equalsIgnoreCase(scheme)) {; found = true;; break;; }; }; if (!fou",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2312:1813,install,installedProviders,1813,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2312,1,['install'],['installedProviders']
Deployability,"onActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be8",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:5347,configurat,configuration,5347,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['configurat'],['configuration']
Deployability,"onCommandExecution.java:120); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:293); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.api.GradleException: Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.984 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$_resolveLargeResourceStubFiles_closure36.doCall(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:102); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.resolveLargeResourceStubFiles(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:116); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$resolveLargeResourceStubFiles$0.callCurrent(Unknown Source); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.ensureBuildPrerequisites(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:140); 22:05:55.985 [E",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:12791,install,installed,12791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['install'],['installed']
Deployability,"onScriptExecutorException for some of the **random** sub-projects: . .............................................................(BUG 001).......................................................... Traceback (most recent call last):; File ""/tmp/cohort_determine_ploidy_and_depth.3351404099122294482.py"", line 8, in <module>; import gcnvkernel; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/__init__.py"", line 5, in <module>; from .distributions import *; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/distributions/__init__.py"", line 1, in <module>; from . import timeseries; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/distributions/timeseries.py"", line 5, in <module>; from .continuous import get_tau_sd, Normal, Flat; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/distributions/continuous.py"", line 16, in <module>; from pymc3.theanof import floatX; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/theanof.py"", line 89, in <module>; empty_gradient = tt.zeros(0, dtype='float32'); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/tensor/basic.py"", line 2558, in zeros; return alloc(np.array(0, dtype=dtype), *shape); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/tensor/basic.py"", line 3091, in __call__; ret = super(Alloc, self).__call__(val, *shapes, **kwargs); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/op.py"", line 670, in __call__; no_recycling=[]); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/op.py"", line 955, in make_thunk; no_recycling); File ""/usr/local/Anaconda/envs_app/gatk/4.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235:2147,continuous,continuous,2147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235,1,['continuous'],['continuous']
Deployability,onSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9RdWFsaXR5U2NvcmVEaXN0cmlidXRpb25TcGFyay5qYXZh) | `95.238% <100%> (ø)` | `16 <0> (ø)` | :arrow_down: |; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `94.872% <100%> (+0.427%)` | `38 <9> (+4)` | :arrow_up: |; | [...pipelines/metrics/CollectMultipleMetricsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0TXVsdGlwbGVNZXRyaWNzU3BhcmsuamF2YQ==) | `92.593% <100%> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...k/pipelines/metrics/MetricsCollectorSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZXRyaWNzQ29sbGVjdG9yU3BhcmtUb29sLmphdmE=) | `75% <100%> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...ark/pipelines/metrics/MeanQualityByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZWFuUXVhbGl0eUJ5Q3ljbGVTcGFyay5qYXZh) | `90.816% <100%> (ø)` | `11 <0> (ø)` | :arrow_down: |; | [...s/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0QmFzZURpc3RyaWJ1dGlvbkJ5Q3ljbGVTcGFyay5qYXZh) | `87.037% <100%> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/eng,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5430#issuecomment-442613021:1952,pipeline,pipelines,1952,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5430#issuecomment-442613021,1,['pipeline'],['pipelines']
Deployability,"onTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db21wYXJlSW50ZXJ2YWxMaXN0c0ludGVncmF0aW9uVGVzdC5qYXZh) | `100% <100%> (ø)` | `4 <4> (?)` | |; | [...stitute/hellbender/tools/CompareIntervalLists.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db21wYXJlSW50ZXJ2YWxMaXN0cy5qYXZh) | `93.33% <93.33%> (ø)` | `4 <4> (?)` | |; | [...broadinstitute/hellbender/utils/IntervalUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbFV0aWxzLmphdmE=) | `91.88% <0%> (+0.35%)` | `188% <0%> (+1%)` | :arrow_up: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (+0.47%)` | `33% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (+1.21%)` | `42% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3702?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3702?src=pr&el=footer). Last update [a74e571...8f85021](https://codecov.io/gh/broadinstitute/gatk/pull/3702?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3702#issuecomment-337303370:2995,update,update,2995,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3702#issuecomment-337303370,2,['update'],['update']
Deployability,once a new htsjdk release comes out we should switch off relying on since #1153,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1154:18,release,release,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1154,1,['release'],['release']
Deployability,"oncotator that was fixed in Funcotator involving cdna; strings for - strand indels. In Oncotator the positions reported are off by 1 (they; should be one less) and the base reported is also wrong.; This is now fixed. - Removed some old code that had been taken out of the main codepath. - Fixed a bug in how the gencode reference contexts are created.; - Fixed a bug in how the end points for the gencode annotations are; created. - Ref context field is now consistent for indels.; The reference context will give WINDOW bases before and after the; logical reference allele for a variant. This is NOT the allele in the; input VCF, but rather the allele that actually has changed. For; insertions, the logical allele is the SPACE BETWEEN TWO BASES (and; therefore the resulting string will always be 2xWINDOW bases long).; For deletions, the logical allele is the given ref allele without the; required preceding base. For MNPs the logical allele is the given ref; allele.; Updated some tests and test data to reflect this change. - Added a small HG38 regression test set. - Fixed a boundary bug with codon strings.; Now codon change strings have an alternate (correct) form for insertions; that involve the start codon on the - strand, and the stop codon on the; + strand. This form eliminates any overrun/out of bounds exceptions. - Fixed an issue involving variants that overrun the end of the coding sequence. - Added in additional required files for regression test gencode data source. - Added a helpful script and modified test data set to be correct. - Updated part of Gencode to prepare for fixing the exon boundary issue. - Updated FuncotatorIntegrationTests to use environment-variable paths; more safely. - Updated `FuncotatorUtils::getCodingSequenceChangeString` to use; base data types rather than those in `SequenceComparison`. - Refactored; `GencodeFuncotationFactory::createCodingRegionFuncotationForNonProteinCodingFeature`; to remove the use of `SequenceComparison` objects. - Updat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5302:3939,Update,Updated,3939,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5302,1,['Update'],['Updated']
Deployability,ons-2.11.0.jar;E:\repository\com\fasterxml\jackson\core\jackson-core\2.11.0\jackson-core-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.11.0\jackson-datatype-jdk8-2.11.0.jar;E:\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.11.0\jackson-datatype-jsr310-2.11.0.jar;E:\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.11.0\jackson-module-parameter-names-2.11.0.jar;E:\repository\org\springframework\boot\spring-boot-starter-tomcat\2.3.0.RELEASE\spring-boot-starter-tomcat-2.3.0.RELEASE.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.35\tomcat-embed-core-9.0.35.jar;E:\repository\org\glassfish\jakarta.el\3.0.3\jakarta.el-3.0.3.jar;E:\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.35\tomcat-embed-websocket-9.0.35.jar;E:\repository\org\springframework\spring-web\5.2.6.RELEASE\spring-web-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-webmvc\5.2.6.RELEASE\spring-webmvc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\repository\org\springframework\spring-core\5.2.6.RELEASE\spring-core-5.2.6.RELEASE.jar;E:\repository\org\springframewo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:4667,RELEASE,RELEASE,4667,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,ontextFactory.getSparkContext(SparkContextFactory.java:110); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@3e0a9b1d: java.net.BindException: Address already in use; java.net.BindException: Address already in use; at sun.nio.ch.Net.bind0(Native Method); at sun.nio.ch.Net.bind(Net.java:433); at sun.nio.ch.Net.bind(Net.java:425); at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223); at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74); at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:321); at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80); at ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:7251,deploy,deploy,7251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725,1,['deploy'],['deploy']
Deployability,"ontrast to genotyping in matched-normal mode, in which the normal determines the set of hets used in all samples). We will thus have to take the intersection of these hets before performing multisample segmentation. Unfortunately, we will not be able to re-perform this intersection in each scatter, since we will no longer have access to the hets from the other samples. However, we *will* ultimately intersect the hets from each sample with the joint segmentation before modeling, which may be a rough proxy for the intersection of hets from all samples. As always, tumor-only mode may yield suboptimal results in certain scenarios, e.g., high purity CNLOH. I think I'm OK with just documenting these wrinkles, rather than working too hard to iron them out. I think this structure sets us up nicely to accommodate germline tagging/filtering in the near future. We can still pass the Picard interval list containing the joint segmentation to the scatter for the normal, but can instead subsequently pass the *.modelBegin.seg result from the normal to the tumors. This modeled-segment file will have breakpoints identical to those from the joint segmentation (as opposed to the *.modelFinal.seg result, since that undergoes segment smoothing/merging), but will also contain the segment-level posteriors necessary for performing germline filtering. We will just need to add code to toggle on the type of `--segments` input (Picard interval list or modeled segments), add filtering arguments and code, perhaps output an additional seg file showing filter status for the *.modelBegin.seg segments, and modify the segment merging/smoothing code to properly account for filter status (so we don't incorrectly impute across filtered segments, which is currently done by the unsupported code, for whatever reason). I think this should clock in at well under ~5k lines of code, which is the count for the current unsupported code (see https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607313549:4228,toggle,toggle,4228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607313549,1,['toggle'],['toggle']
Deployability,"oogle.com/apt cloud-sdk-bionic InRelease [6786 B] ; Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1426 kB] ; Err:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease ; The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; Get:7 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2295 kB] ; Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] ; Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] ; Get:10 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] ; Get:11 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]; Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] ; Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB] ; Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2200 kB]; Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.4 kB]; Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [575 kB]; Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2731 kB]; Get:18 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [11.4 kB]; Get:19 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [11.3 kB]; Reading package lists... Done ; W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; E: The repository 'http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease' is not signed.; N: Updating from such a repository can't be done securely, and is therefore disabled by default.; N: See apt-secure(8) manpage for repository creation and user configuration detai",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7447:2060,update,updates,2060,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7447,1,['update'],['updates']
Deployability,"ool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `AllelicCountCollector` per partition, instead of per locus. Assigning to @tomwhite by request of @droazen ...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3823:1165,integrat,integration,1165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823,2,['integrat'],['integration']
Deployability,"oooh, re: ijson, should I just add checking for and installing it into the ./build_docker.sh file?. I've had it forever since I need it to run the python script. It's in requirements.txt, where else should I put it?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7756#issuecomment-1113482902:52,install,installing,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7756#issuecomment-1113482902,1,['install'],['installing']
Deployability,openjdk-8 can still be found on many major distributions albeit it is not the default one to be installed. Just check the package manager for openjdk-8 tags. ; If not check adoptopenjdk repos to install one from there. Or use the docker image.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7333#issuecomment-876369940:96,install,installed,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7333#issuecomment-876369940,2,['install'],"['install', 'installed']"
Deployability,"or driver) (4/4); 17/05/05 06:03:53 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool ; 17/05/05 06:03:53 INFO DAGScheduler: ResultStage 2 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:202) finished in 10.796 s; 17/05/05 06:03:53 INFO DAGScheduler: Job 1 finished: saveAsNewAPIHadoopFile at ReadsSparkSink.java:202, took 17.010114 s; 17/05/05 06:03:53 INFO SparkUI: Stopped Spark web UI at http://172.30.0.122:35794; 17/05/05 06:03:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/05/05 06:03:53 INFO MemoryStore: MemoryStore cleared; 17/05/05 06:03:53 INFO BlockManager: BlockManager stopped; 17/05/05 06:03:53 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/05/05 06:03:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/05/05 06:03:53 INFO SparkContext: Successfully stopped SparkContext; [May 5, 2017 6:03:53 AM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=799080448; 17/05/05 06:03:53 INFO ApplicationMaster: Final app status: FAILED, exitCode: 16, (reason: Shutdown hook called before final status was reported.); 17/05/05 06:03:53 INFO ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: Shutdown hook called before final status was reported.); 17/05/05 06:03:53 INFO ApplicationMaster: Deleting staging directory hdfs://ip-172-30-0-86.ec2.internal:8020/user/hadoop/.sparkStaging/application_1493961816416_0002; 17/05/05 06:03:53 INFO ShutdownHookManager: Shutdown hook called; 17/05/05 06:03:53 INFO ShutdownHookManager: Deleting directory /mnt1/yarn/usercache/hadoop/appcache/application_1493961816416_0002/spark-23bc1c26-8133-475d-8418-1def58e976fd; 17/05/05 06:03:53 INFO ShutdownHookManager: Deleting directory /mnt/yarn/usercache/hadoop/appcache/application_1493961816416_0002/spark-edb79d30-a7d3-4ed2-ad61-2dc8ea95c5b1; ```. Thanks in helping ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2666:4216,pipeline,pipelines,4216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2666,1,['pipeline'],['pipelines']
Deployability,"or.onTraversalSuccess(VariantRecalibrator.java:680); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1062); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms100g -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar VariantRecalibrator -V /rprojectnb2/kageproj/gatk/pVCF/chr1/chr1.raw.excessHet.sites.vcf.gz -O snps.recal --tranches-file snps.tranches --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.8 -tranche 99.6 -tranche 99.5 -tranche 99.4 -tranche 99.3 -tranche 99.0 -tranche 98.0 -tranche 97.0 -tranche 90.0 -an AS_QD -an AS_ReadPosRankSum -an AS_MQRankSum -an AS_FS -an AS_MQ -an AS_SOR -an AS_MQ --use-allele-specific-annotations -mode SNP --output-model snps.model --max-gaussians 6 -resource:hapmap,known=false,training=true,truth=true,prior=15 /rprojectnb2/kageproj/gatk/bundle/hapmap_3.3.hg38.vcf.gz -resource:omni,known=false,training=true,truth=true,prior=12 /rprojectnb2/kageproj/gatk/bundle/1000G_omni2.5.hg38.vcf.gz -resource:1000G,known=false,training=true,truth=false,prior=10 /rprojectnb2/kageproj/gatk/bundle/1000G_phase1.snps.high_confidence.hg38.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=7 /rprojectnb2/kag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7380:10326,install,install,10326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7380,1,['install'],['install']
Deployability,"or: 0.0007 +/- 0.0011: 9%|9 | 9/100 [00:02<00:24, 3.73it/s]; 15:10:07.919 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0008 +/- 0.0009: 10%|# | 10/100 [00:02<00:24, 3.72it/s]; 15:10:08.193 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0006: 11%|#1 | 11/100 [00:02<00:24, 3.70it/s]; 15:10:08.463 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0005 +/- 0.0007: 12%|#2 | 12/100 [00:03<00:23, 3.70it/s]; 15:10:08.732 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0007: 13%|#3 | 13/100 [00:03<00:23, 3.70it/s]; 15:10:09.001 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0004 +/- 0.0005: 13%|#3 | 13/100 [00:03<00:25, 3.45it/s]; 15:10:09.002 INFO gcnvkernel.tasks.inference_task_base - (ploidy calling epoch 1): 0%| | 0/1 [00:00<?, ?it/s]; 15:10:09.003 INFO gcnvkernel.tasks.inference_task_base - (ploidy calling epoch 1) ploidy update size: 0.200122: 100%|##########| 1/1 [00:00<00:00, 1605.78it/s]; 15:10:09.004 INFO gcnvkernel.tasks.inference_task_base - (denoising) starting...: 0%| | 0/1000 [00:00<?, ?it/s]; 15:10:09.105 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 2) ELBO: -419.253 +/- 160.674, SNR: 8.0, T: 1.79: 4%|3 | 37/1000 [00:00<00:02, 365.67it/s]; 15:10:09.207 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 2) ELBO: -412.997 +/- 158.620, SNR: 7.8, T: 1.79: 7%|7 | 74/1000 [00:00<00:02, 363.49it/s]; 15:10:09.312 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 2) ELBO: -407.614 +/- 156.431, SNR: 7.6, T: 1.78: 11%|#1 | 111/1000 [00:00<00:02, 359.40it/s]; 15:10:09.415 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 2) ELBO: -402.921 +/- 154.484, SNR: 7.4, T: 1.77: 15%|#4 | 147/1000 [00:00<00:02, 354.82it/s]; 15:10:09.521 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 2) ELBO: -398.490 +/- 152.601, SNR: 7.2, T: 1.76: 18",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:13177,update,update,13177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['update'],['update']
Deployability,"orcement of consistent GC-bias correction).; - [ ] That said, I'll carry over this TODO from above: Revisit standardization procedure by checking with simulated data. We should make sure that the centering of the data does not rescale the true copy ratio.; - The only major difference is we no longer make a QC PoN or check for large events. This was performed awkwardly in the old pipeline, so I'd rather not port it over. Eventually we will do all denoising with the gCNV coverage model anyway.; - Pre/tangent-normalization copy ratio are now referred to as standardized/denoised copy ratio.; - [x] Old code is still used for GC-bias correction in `CreateReadCountPanelOfNormals`, and we still use the `AnnotateTargets` tool. We should port this over (possibly as part of `PreprocessIntervals`) at some point (actually, I think we will be forced to, since `PreprocessIntervals` will output a Picard interval list, and `AnnotateTargets` outputs a target file).; - [x] Integration tests are still needed for `CreateReadCountPanelOfNormals`. These might not test for correctness, but we could possibly compare to old PoNs. Segmentation/modeling:; - Instead of separate tools for copy-ratio segmentation (`PerformSegmentation`) and allele-fraction segmentation/union/modeling (`AllelicCNV`), there is now just a single segmentation/modeling tool (`ModelSegments`).; - Input is denoised copy ratio and/or allelic counts. If only one input is provided, then we only model only the corresponding quantity.; - There is no separate allele-fraction workflow. Unlike the old approach, we do not perform any genotyping or modeling before doing kernel segmentation.; - [x] Old code and classes are used for segment union. We should port or possibly replace this with a simple method that uses kernel segmentation. EDIT: Actually, just tried running a WGS sample and this is still a major bottleneck. EDIT 2: Hmm...actually doesn't seem to be an issue on my desktop (compared to my laptop, on which the run hangs ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:2887,Integrat,Integration,2887,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['Integrat'],['Integration']
Deployability,"org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:40); 	at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:42); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:500); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:468); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:459); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:207); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:635); 18/09/15 17:21:28 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: 15, (reason: User class threw exception: java.lang.OutOfMemoryError: Java heap space); 18/09/15 17:21:28 INFO util.ShutdownHookManager: Shutdown hook called; 18/09/15 17:21:28 INFO util.ShutdownHookManager: Deleting directory /tmp/hadoop-test/nm-local-dir/usercache/test/appcache/application_1537046459822_0001/spark-d0ea2344-815c-4bbf-a11b-35031a9c4940; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-421544535:2367,deploy,deploy,2367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-421544535,1,['deploy'],['deploy']
Deployability,org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellb,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:21165,pipeline,pipeline,21165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['pipeline'],['pipeline']
Deployability,org\springframework\spring-web\5.2.6.RELEASE\spring-web-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-webmvc\5.2.6.RELEASE\spring-webmvc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\repository\org\springframework\spring-core\5.2.6.RELEASE\spring-core-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-jcl\5.2.6.RELEASE\spring-jcl-5.2.6.RELEASE.jar;E:\repository\com\google\firebase\firebase-admin\6.8.1\firebase-admin-6.8.1.jar;E:\repository\com\google\api-client\google-api-client\1.25.0\google-api-client-1.25.0.jar;E:\repository\com\google\oauth-client\google-oauth-client\1.25.0\google-oauth-client-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-jackson2\1.25.0\google-http-client-jackson2-1.25.0.jar;E:\repository\com\google\api-client\google-api-client-gson\1.25.0\google-api-client-gson-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-gson\1.25.0\google-http-client-gson-1.25.0.jar;E:\repository\com\google\code\gson\gson\2.8.6\gson-2.8.6.jar;E:\repository\com\google\http-client\google-http-client\1.25.0\google-http-client-1.25.0.jar;E:\repository\com\google\code\findbugs\jsr305\3.0,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:5488,RELEASE,RELEASE,5488,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,2,"['RELEASE', 'configurat']","['RELEASE', 'configuration-processor-']"
Deployability,orrentBroadcast.scala:268); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1303); 	at org.apache.spark.broadcast.TorrentBroadcast$.blockifyObject(TorrentBroadcast.scala:269); 	at org.apache.spark.broadcast.TorrentBroadcast.writeBlocks(TorrentBroadcast.scala:126); 	at org.apache.spark.broadcast.TorrentBroadcast.<init>(TorrentBroadcast.scala:88); 	at org.apache.spark.broadcast.TorrentBroadcastFactory.newBroadcast(TorrentBroadcastFactory.scala:34); 	at org.apache.spark.broadcast.BroadcastManager.newBroadcast(BroadcastManager.scala:56); 	at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1411); 	at org.apache.spark.api.java.JavaSparkContext.broadcast(JavaSparkContext.scala:650); 	at org.broadinstitute.hellbender.engine.spark.BroadcastJoinReadsWithVariants.join(BroadcastJoinReadsWithVariants.java:27); 	at org.broadinstitute.hellbender.engine.spark.AddContextDataToReadSpark.add(AddContextDataToReadSpark.java:68); 	at org.broadinstitute.hellbender.tools.spark.pipelines.BQSRPipelineSpark.runTool(BQSRPipelineSpark.java:108); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Delegati,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3303:3276,pipeline,pipelines,3276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3303,1,['pipeline'],['pipelines']
Deployability,"ory, uses location instead of position; - add query mode; - fix contig name; - forgot this file; - fix location bug; - Ingest wip to be added to other var db code (#6582); - ingest arrays refactored; - add filter, change sample to sample_id; - fix bugs; - wip; - major refactor splitting ingest for arrays from exomes/genomes; - create output files for actual raw array tables; - change site_name to rsid; - change GT encoding, change output file names and remove dir structure, get probe metadata; - fix prefix; - update GT encoding; - remove filter, rename columns, allow sample id as input; - array cohort extract (#6666); - new bit-compression (#6691); - refactored to common ProbeInfo, support compressed data on ingest, support local CSV probe info; - update exome ingest; - minor mods; - change structure, add compressed option to ingest; - add imputed tsv creator and refactor; - add fields for uncompressed imputed data; - Adding a test and small features to var store branch (#6761); - upgraded to new google bigquery libraries and storage api v1; used storage api for probe info; synced encoded gt definitions; - added support for probe_id ranges (#6806); - ah - use new GT encoding (#6822); - Tool for arrays QC metrics calculations (#6812); - ah update array extract tool (#6827); - fix enum (#6834); - updating ArrayCalculateMetrics for new genotype counts table (#6843); - Ability to filter variants based on QC in ArrayExtractCohort (#6844); - switch from ExcessHet back to HWE (#6848); - resolved rebase conflicts; - initial cohort extract; - minor changes; - wip; - get genotypes working; - clarify sample -> sample_id; - add mode; - mode is mandatory, uses location instead of position; - add query mode; - fix contig name; - fix location bug; - Ingest wip to be added to other var db code (#6582); - ingest arrays refactored; - add filter, change sample to sample_id; - fix bugs; - wip; - major refactor splitting ingest for arrays from exomes/genomes; - create output files for ac",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:1137,upgrade,upgraded,1137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,['upgrade'],['upgraded']
Deployability,"ossibility is not ported yet. Regarding alt allele reduction in AF calculator, has [this](https://github.com/broadinstitute/gatk/pull/1918) been ported back to GATK3?. ---. @SHuang-Broad commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1376#issuecomment-260688221). By ""possible place"" I mean they don't always remove alt alleles, just when certain conditions are met, and are independent. ---. @vdauwera commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1376#issuecomment-260781482). I don't think https://github.com/broadinstitute/gatk/pull/1918 has been backported, no. . ---. @SHuang-Broad commented on [Mon Dec 19 2016](https://github.com/broadinstitute/gsa-unstable/issues/1376#issuecomment-268016064). Looking more closely, isn't this done already in #1377 ? @vruano ?. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1376#issuecomment-287822737). @SHuang-Broad @vruano Status update on this?. ---. @vruano commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1376#issuecomment-287916452). @SHuang-Broad this is not fixed by #1377 as this makes reference to the selection executed by the AFCalculator... it might be that @davidbenjamin now AF calculator addressed the issue, but is also possible that he avoid it it entirely and just focused in the new QUAL calculation. . ---. @vruano commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1376#issuecomment-287921195). Looking at the code I made reference in GATK3, it seem that it is still faulty... I guess we need to take a look on whether in GATK4 has been fixed and then back-ported if people are interested. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1376#issuecomment-287952396). Alright, thanks for the update. At this point we don't care too much about fixing it in GATK3; we're all about m",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2958:3882,update,update,3882,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2958,1,['update'],['update']
Deployability,"ot sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage if there is no data for known indels. I will propose very soon two PRs with fully functional tools (without the n-way out feature for indel-realignment), and trying to add simple integration tests with the data already available on the repository and running with GATK3.8-1. If that is OK for you, I will proceed with this approach.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:2181,integrat,integration,2181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115,2,['integrat'],['integration']
Deployability,"otationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default ; ; 22:06:39.383 INFO  NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/gvandeweyer/miniconda3/envs/ELPREP/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Mar 12, 2022 10:06:39 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 22:06:39.543 INFO  HaplotypeCaller - ------------------------------------------------------------ ; ; 22:06:39.543 INFO  HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.2.5.0 ; ; 22:06:39.543 INFO  HaplotypeCaller - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 22:06:39.543 INFO  HaplotypeCaller - Executing as [gvandeweyer@ngsvm-pipelines.uza.be](mailto:gvandeweyer@ngsvm-pipelines.uza.be) on Linux v4.4.0-210-generic amd64 ; ; 22:06:39.543 INFO  HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_312-b07 ; ; 22:06:39.544 INFO  HaplotypeCaller - Start Date/Time: March 12, 2022 10:06:39 PM CET ; ; 22:06:39.544 INFO  HaplotypeCaller - ------------------------------------------------------------ ; ; 22:06:39.544 INFO  HaplotypeCaller - ------------------------------------------------------------ ; ; 22:06:39.544 INFO  HaplotypeCaller - HTSJDK Version: 2.24.1 ; ; 22:06:39.544 INFO  HaplotypeCaller - Picard Version: 2.25.4 ; ; 22:06:39.544 INFO  HaplotypeCaller - Built for Spark Version: 2.4.5 ; ; 22:06:39.544 INFO  HaplotypeCaller - HTSJDK Defaults.COMPRESSION\_LEVEL : 2 ; ; 22:06:39.545 INFO  HaplotypeCaller - HTSJDK Defaults.USE\_ASYNC\_IO\_READ\_FOR\_SAMTOOLS : false ; ; 22:06:39.545 INFO  HaplotypeCaller - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true ; ; 22:06:39.545 INFO  HaplotypeCaller - HTSJDK Defaults.USE\_ASYNC\",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7741:5265,pipeline,pipelines,5265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7741,1,['pipeline'],['pipelines']
Deployability,other than manually testing this---is there a test I can write to include this? Maybe add it to the QS integration test?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7844#issuecomment-1125299078:103,integrat,integration,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7844#issuecomment-1125299078,1,['integrat'],['integration']
Deployability,"ound.; library inux-gnu/7.3.0/crtbeginS.o(.text+0x1a): is not found.; library inux-gnu/7.3.0/crtbeginS.o(.text+0x6b): is not found.; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 81, in <module>; actual_version, force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 105, in <module>; actual_version, force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/bin/theano-nose"", line 11, in <module>; load_entry_point('Theano==1.0.4', 'console_scripts', 'theano-nose')(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 207, in main; result = main_function(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 45, in main_function; from theano import config; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/__init__.py"", line 110, in <module>; from theano.compile import (; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/__init__.py"", line 12, in <module>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinke",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:1728,INSTALL,INSTALLDIRGATK,1728,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['INSTALL'],['INSTALLDIRGATK']
Deployability,"output renderers. This is used when output type is `SEG`, so that it can write both output files simultaneously.; - Introduces the `GeneListOutputRenderer`. This does not write anything to disk until the entire input file is processed. The actual writing happens during the `close()` command. This is necessary since it cannot actually render its output until all segments have been seen. This output renderer also relies heavily on specific funcotation fields being in the input `FuncotationMap`. Internally, the gene list output renderer uses the `SimpleTsvOutputRenderer` (see below) to do the actual writing.; - Introduces the `SimpleTsvOutputRenderer`. This output renderer is very flexible and renders a tab-separated text file based on several output rules. Formats are driven through config files. And developers can limit the output columns to ignore extraneous funcotation fields. Note that excluded fields are honored, regardless. If a configuration + parameter combination would result in this class producing an empty file, an exception is thrown. More notes are in the javadocs of the class.; - Currently, only the `GencodeFuncotationFactory` can actually funcotate segments. ; - Code base currently enforces only small mutations when running `Funcotator` (segs are funcotated as CANNOT_DETERMINE) and only segments when running `FuncotateSegments` (small mutations produce exception). This is enforced with flags in the code. The backend does not disallow a mixture for future use. This may prove important when funcotating CNVs from VCFs produced by tools other than `ModelSegments`.; - Added copy creation method for FuncotationMap based on Kryo. Also, added the necessary Kryo registrations. This induced a new unit test to enforce any concrete implementations of `Funcotation` to be Kryo serializable. The unit test does a recursive search of the funcotator package. For all concrete implementations, it tracks whether this unit test tests the serialization. If not, it fails. Instr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5941:2354,configurat,configuration,2354,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5941,1,['configurat'],['configuration']
Deployability,ov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...spark/pipelines/metrics/MetricsCollectorSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZXRyaWNzQ29sbGVjdG9yU3BhcmsuamF2YQ==) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `83.582% <ø> (-0.122%)` | `36 <0> (-1)` | |; | [...roadinstitute/hellbender/metrics/MetricsUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9tZXRyaWNzL01ldHJpY3NVdGlscy5qYXZh) | `57.143% <ø> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...ark/pipelines/metrics/MeanQualityByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZWFuUXVhbGl0eUJ5Q3ljbGVTcGFyay5qYXZh) | `90.625% <100%> (ø)` | `10 <2> (ø)` | :arrow_down: |; | [...k/pipelines/metrics/MetricsCollectorSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZXRyaWNzQ29sbGVjdG9yU3BhcmtUb29sLmphdmE=) | `75% <100%> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...pipelines/metrics/CollectMultipleMetricsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2785?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0TXVsdGlwbGVNZXRyaWNzU3BhcmsuamF2YQ==) | `92.593% <100%> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...nes/metrics/QualityYieldMetricsCollectorSpark,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2785#issuecomment-305262449:1791,pipeline,pipelines,1791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2785#issuecomment-305262449,1,['pipeline'],['pipelines']
Deployability,"own=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz. 14:58:10.389 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 12, 2020 2:58:10 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:58:10.555 INFO VariantRecalibrator - ------------------------------------------------------------; 14:58:10.555 INFO VariantRecalibrator - The Genome Analysis Toolkit (GATK) v4.1.9.0; 14:58:10.555 INFO VariantRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:58:10.555 INFO VariantRecalibrator - Executing as y@c001 on Linux v3.10.0-957.el7.x86_64 amd64; 14:58:10.555 INFO VariantRecalibrator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 14:58:10.556 INFO VariantRecalibrator - Start Date/Time: November 12, 2020 2:58:10 PM CST; 14:58:10.556 INFO VariantRecalibrator - ------------------------------------------------------------; 14:58:10.556 INFO VariantRecalibrator - ------------------------------------------------------------; 14:58:10.556 INFO VariantRecalibrator - HTSJDK Version: 2.23.0; 14:58:10.556 INFO VariantRecalibrator - Picard Version: 2.23.3; 14:58:10.556 INFO VariantRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:58:10.556 INFO VariantRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:58:10.556 INFO VariantRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:58:10.556 INFO VariantRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:58:10.556 INFO VariantRecalibrator - Deflater: IntelDeflater; 14:58:10.556 INFO VariantRecalibrator - Inflater: IntelInflater; 14:58:10.556 INFO VariantRecalibrator - GCS max retries/reopens: 20; 14:5",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6963:3790,release,release-,3790,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963,1,['release'],['release-']
Deployability,"own=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz. 14:58:10.389 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 12, 2020 2:58:10 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:58:10.555 INFO VariantRecalibrator - ------------------------------------------------------------; 14:58:10.555 INFO VariantRecalibrator - The Genome Analysis Toolkit (GATK) v4.1.9.0; 14:58:10.555 INFO VariantRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:58:10.555 INFO VariantRecalibrator - Executing as y@c001 on Linux v3.10.0-957.el7.x86_64 amd64; 14:58:10.555 INFO VariantRecalibrator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 14:58:10.556 INFO VariantRecalibrator - Start Date/Time: November 12, 2020 2:58:10 PM CST; 14:58:10.556 INFO VariantRecalibrator - ------------------------------------------------------------; 14:58:10.556 INFO VariantRecalibrator - ------------------------------------------------------------; 14:58:10.556 INFO VariantRecalibrator - HTSJDK Version: 2.23.0; 14:58:10.556 INFO VariantRecalibrator - Picard Version: 2.23.3; 14:58:10.556 INFO VariantRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:58:10.556 INFO VariantRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:58:10.556 INFO VariantRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:58:10.556 INFO VariantRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:58:10.556 INFO VariantRecalibrator - Deflater: IntelDeflater; 14:58:10.556 INFO VariantRecalibrator - Inflater: IntelInflater; 14:58:10.556 INFO VariantRecalibrator - GCS max retries/reopens: 20; 14:5",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6701#issuecomment-726406532:2442,release,release-,2442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701#issuecomment-726406532,1,['release'],['release-']
Deployability,p: |; | [...er/tools/picard/analysis/CollectGcBiasMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9waWNhcmQvYW5hbHlzaXMvQ29sbGVjdEdjQmlhc01ldHJpY3MuamF2YQ==) | `0.794% <0%> (+0.794%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...utils/test/ReadsPreprocessingPipelineTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRzUHJlcHJvY2Vzc2luZ1BpcGVsaW5lVGVzdERhdGEuamF2YQ==) | `0.847% <0%> (+0.847%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...spark/sv/evidence/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `67.347% <0%> (+1.02%)` | `34% <0%> (+1%)` | :arrow_up: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `73.118% <0%> (+1.075%)` | `25% <0%> (ø)` | :arrow_down: |; | [...e/conversion/allelicbalancecaller/CNLOHCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9jb252ZXJzaW9uL2FsbGVsaWNiYWxhbmNlY2FsbGVyL0NOTE9IQ2FsbGVyLmphdmE=) | `96.283% <0%> (+1.115%)` | `95% <0%> (+3%)` | :arrow_up: |; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `92.737% <0%> (+1.117%)` | `61% <0%> (+2%)` | :arrow_up: |; | [...itute/hellbender/tools/picard/vcf/LiftOverVcf.java](h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320273200:2874,Integrat,IntegrationTestSpec,2874,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320273200,1,['Integrat'],['IntegrationTestSpec']
Deployability,"pache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; 11:00:54.078 INFO AbstractConnector - Stopped Spark@2f829853{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}; 11:00:54.091 INFO SparkUI - Stopped Spark web UI at http://172.20.19.130:4040; 11:00:54.122 INFO MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!; 11:00:54.175 INFO MemoryStore - MemoryStore cleared; 11:00:54.175 INFO BlockManager - BlockManager stopped; 11:00:54.193 INFO BlockManagerMaster - BlockManagerMaster stopped; 11:00:54.211 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!; 11:00:54.302 INFO SparkContext - Successfully stopped SparkContext; 11:00:54.303 INFO SortSamSpark - Shutting down engine; [August 11, 2024 at 11:00:54 AM CST] org.broadinstitute.hellbender.tools.spark.pipelines.SortSamSpark done. Elapsed time: 27.81 minutes.; Runtime.totalMemory()=1926292832256; org.apache.spark.SparkException: Job aborted.; at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:106); at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsNewAPIHadoopDataset$1(PairRDDFunctions.scala:1078); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:406); at org.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopDataset(PairRDDFunctions.scala:1076); at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsNewAPIHadoopFile$2(PairRDDFunctions.scala:995); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:24697,pipeline,pipelines,24697,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['pipeline'],['pipelines']
Deployability,pareLocalResources(Client.scala:422); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:635); at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:124); at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:56); at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144); at org.apache.spark.SparkContext.<init>(SparkContext.scala:523); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66); at org.broadinstitute.hellbender.Main.main(Main.java:81); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1389:2563,deploy,deploy,2563,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1389,6,['deploy'],['deploy']
Deployability,pe ConfigurationContainerInternal.; > Cannot create service of type ConfigurationContainerInternal using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createConfigurationContainer() as there is a problem with parameter #13 of type DefaultConfigurationFactory.; > Cannot create service of type DefaultConfigurationFactory using DefaultConfigurationFactory constructor as there is a problem with parameter #2 of type ConfigurationResolver.; > Cannot create service of type ConfigurationResolver using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyResolver() as there is a problem with parameter #1 of type ArtifactDependencyResolver.; > Cannot create service of type ArtifactDependencyResolver using method DependencyManagementBuildScopeServices.createArtifactDependencyResolver() as there is a problem with parameter #4 of type List<ResolverProviderFactory>.; > Could not create service of type VersionControlRepositoryConnectionFactory using VersionControlBuildSessionServices.createVersionControlSystemFactory().; > Failed to create parent directory '/home/jdjdj0202/gatk/.gradle' when creating directory '/home/jdjdj0202/gatk/.gradle/vcs-1'. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. BUILD FAILED in 754ms. FAILURE: Build failed with an exception. * What went wrong:; Could not update /home/jdjdj0202/gatk/.gradle/7.5.1/fileChanges/last-build.bin; > /home/jdjdj0202/gatk/.gradle/7.5.1/fileChanges/last-build.bin (No such file or directory). * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org; * ; BUILD FAILED in 761ms; ====================================. How can I build GATK4? . Thanks a lot.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8346:2523,update,update,2523,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8346,1,['update'],['update']
Deployability,pe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz  -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test.table ; ; Using GATK jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar ; ; Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx8G -Djava.io.tmpdir=/data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/shell/temp -jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test.table ; ; 00:09:41.541 INFO  NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 00:09:41.554 WARN  NativeLibraryLoader - Unable to load libgkl\_compression.so from native/libgkl\_compression.so (No such file or directory) ; ; 00:09:41.557 INFO  NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 00:09:41.558 WARN  NativeLibraryLoader - Unable to load libgkl\_compression.so from na,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:1948,pipeline,pipeline,1948,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability,"peCaller version Z, gatk-public version P, etc. This is probably the most ""correct"" solution from a software engineering perspective, but might be a nightmare to work with.; 2. Have the ability to release jars with a subset of the tools exposed to the user (eg., CNV-only jars). Geraldine hates this one, and it does seem like a bad idea to have these incomplete jars floating out in the wild.; 3. Everyone develops on separate branches, and merges to master only when everything in a branch is ""release-ready"". In this scenario master itself is always (theoretically, at least) ready for release. This solves the original problem of release of some tools being blocked by others, but creates some other problems: last-minute merge conflicts across dev teams, large amounts of code being held back for months while it undergoes testing, harder to share code across groups, more complex git workflows for everyone.; 4. Everyone is free to merge development versions of tools to master (as is currently the case), and most of the time we try to release everything in the GATK together. On rare occasions when, eg., CNV needs a release now and HC is not ready, we create a branch off of the last tagged release, cherry-pick the CNV tools (or whatever) into it, and release that. Then when the HC stabilizes and master is once again releasable, we do the next release from master. I've renamed this issue to make the problem we're trying to solve clearer. @akiezun @lbergelson @LeeTL1220 @vdauwera would you vote for any of the above options? Do you have alternate proposals that solve the same problem and you think are better? Should we seek professional (release engineering) help?. ---. @akiezun commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215761749). only 4 seems remotely sane to me. ---. @vdauwera commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215779225). 3 and 4 both produce an",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:4292,release,release,4292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,1,['release'],['release']
Deployability,phdmE=) | `73.913% <0%> (ø)` | `8 <0> (ø)` | :arrow_down: |; | [...ools/walkers/annotator/VariantAnnotatorEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2534?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9WYXJpYW50QW5ub3RhdG9yRW5naW5lLmphdmE=) | `97.248% <66.667%> (+0.025%)` | `23 <1> (+1)` | :arrow_up: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2534?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/2534?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> (ø)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2534?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2534?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/2534?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2534?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2534#issuecomment-289406391:2777,pipeline,pipelines,2777,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2534#issuecomment-289406391,1,['pipeline'],['pipelines']
Deployability,pick and update changes from tws_ideas,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2677:9,update,update,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2677,1,['update'],['update']
Deployability,"piens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.table --tmp-dir /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam ; ; 00:11:11.683 INFO  NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 00:11:11.697 WARN  NativeLibraryLoader - Unable to load libgkl\_compression.so from native/libgkl\_compression.so (No such file or directory) ; ; 00:11:11.700 INFO  NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 00:11:11.700 WARN  NativeLibraryLoader - Unable to load libgkl\_compression.so from native/libgkl\_compression.so (No such file or directory) ; ; 00:11:11.812 INFO  BaseRecalibrator - ------------------------------------------------------------ ; ; 00:11:11.813 INFO  BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.2.6.1 ; ; 00:11:11.813 INFO  BaseRecalibrator - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 00:11:11.813 INFO  BaseRecalibrator - Executing as xieduo@pbs-master on Linux v3.10.0-1160.41.1.el7.x86\_64 amd64 ; ; 00:11:11.813 INFO  BaseRecalibrator - Java runtime: Java HotSpot(TM) 64-Bit Server VM v18+36-2087 ; ; 00:11:11.813 INFO  BaseRecalibrator - Start Date/Time: August 21, 2022 at 12:11:11 AM CST ; ; 00:11:11.813 INFO  BaseRecalibrator - --------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:9531,pipeline,pipeline,9531,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability,"piledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3632551' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '62379' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3633423' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3633419' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3633423' (I am process '61988'); INF",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7411#issuecomment-905060709:1494,release,release,1494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7411#issuecomment-905060709,1,['release'],['release']
Deployability,"piledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '62379' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3633423' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3633419' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3633423' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3633419' (I am process '61988'); INF",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7411#issuecomment-905060709:1856,release,release,1856,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7411#issuecomment-905060709,1,['release'],['release']
Deployability,pin hail version in the integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8424:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8424,1,['integrat'],['integration']
Deployability,"pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # conda-installed 2.2.4 appears to be the most recent version with a consistent API and without conflicts/clobbers; # if you wish to update, note that versions of conda-forge::keras after 2.2.5; # undesirably set the environment variable KERAS_BACKEND = theano by default; - defaults::intel-openmp=2019.4; - conda-forge::scikit-learn=0.22.2; - conda-forge::matplotlib=3.2.1; - conda-forge::pandas=1.0.3. # core R dependencies; these should only be used for plotting and do not take precedence over core python dependencies!; - r-base=3.6.2; - r-data.table=1.12.8; - r-dplyr=0.8.5; - r-getopt=1.20.3; - r-ggplot2=3.3.0; - r-gplots=3.0.3; - r-gsalib=2.1; - r-optparse=1.6.4. # other python dependencies; these shoul",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:2486,update,update,2486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['update'],['update']
Deployability,"piped beta variables through to high-level beta workflow.; Also updated the gatk jar so it succeeds, as it didn't before. [Successful run of beta workflow on quickstart data](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Tiny%20Quickstart%20hatcher/job_history/e9a1af96-8c1a-463a-8063-ae455d0ba6b3)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8200:64,update,updated,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8200,1,['update'],['updated']
Deployability,"plotypes in the sample contains the site-specific alternate allele at the site (ie. excluding `*` which represents variation that beings upstream of the current variant. NB that this results in cases where `PGT` is not the same as the phased `GT` field. For example, in the case of a spanned SNP site with REF allele `A` and alt alleles `C` and `*`, `GT` may be set to `1|2` to represent the spanned SNP, while PGT would be set to `1|0` to represent the fact that it is the first haplotype in the pair of phased haplotypes that contains the site-specific alt allele (in this case `C`). If reviewers agree with this interpretation, I think we should create a new ticket to clarify documentation around the PGT and PID tags to reflect it. . After discussions with @ldgauthier I believe that there may be downstream issues in preserving phasing after passing gVCFs through CombineGVCFs, GenomicsDBImport, and/or GenotypeGVCFs, especially if the gVCFs are emitted without GT fields. In that case, `GenotypeGVCFs` should probably have logic to reconstruct the phased genotype for each sample based on the PGT and PID tags when possible. I will create a new ticket describing the issue. There still may be cases where HaplotypeCaller does not emit phasing information for spanning deletions due to the presence of extra haplotypes that contradict diploid phasing, as in https://github.com/broadinstitute/gatk/issues/6845. A fix to that issue would likely reduce the number of those cases. The integration test result file `src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/withOxoGReadCounts.vcf` does not have any changes that have to do with this PR -- it was automatically updated by GenotypeGVCFsIntegrationTest, which included some new jitter in QUAL scores as described in https://github.com/broadinstitute/gatk/pull/6859, but never got checked in with that PR. I figure that it's best to update it now so that the results reflect the current expected behavior of the tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6937:1856,integrat,integration,1856,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6937,3,"['integrat', 'update']","['integration', 'update', 'updated']"
Deployability,"poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred deletion calls, which currently output as `DEL` with `INSSEQ` annotation, to one of these; - [x] `INS`/`DEL`, when deleted/inserted bases are < 50 bp and annotate accordingly; when type is determined as`INS`, the `POS` will be 1 base before the micro-deleted range and `END` will be end of the micro-deleted range, where the `REF` allele will be the corresponding reference bases.; - [x] two records `INS` and `DEL` when both are >= 50, share the same `POS`, and link by `EVENT`; - [ ] we are making a choice that treats duplication expansion as insertion. If decide to treat `DUP` as a separate 1st class type, we need to ; - [ ] shift the left breakpoint to the right by 1 base compared to the current implementation, and ; - [ ] `downstreamBreakpointRefPos = complication.getDupSeqRepeatUnitRefSpan().getEnd();`. ----------; ## CPX varian",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:2207,update,update,2207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021,2,['update'],['update']
Deployability,"ppreciate that beverage while you tinker with dependencies!); #; # When changing dependencies or versions in this file, check to see if the ""supportedPythonPackages"" DataProvider; # used by the testGATKPythonEnvironmentPackagePresent test in PythonEnvironmentIntegrationTest needs to be updated; # to reflect the changes.; #; name: gatk; channels:; # if channels other than conda-forge are added and the channel order is changed (note that conda channel_priority is currently set to flexible),; # verify that key dependencies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # co",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:1777,update,update,1777,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['update'],['update']
Deployability,pr&el=desc) will **increase** coverage by `0.002%`.; > The diff coverage is `90.909%`. ```diff; @@ Coverage Diff @@; ## master #5551 +/- ##; ===============================================; + Coverage 87.001% 87.003% +0.002% ; + Complexity 32105 32104 -1 ; ===============================================; Files 1974 1974 ; Lines 147223 147235 +12 ; Branches 16216 16219 +3 ; ===============================================; + Hits 128086 128099 +13 ; Misses 13231 13231 ; + Partials 5906 5905 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5551?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...umber/utils/MergeAnnotatedRegionsByAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL01lcmdlQW5ub3RhdGVkUmVnaW9uc0J5QW5ub3RhdGlvbi5qYXZh) | `94.737% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [.../tools/copynumber/utils/MergeAnnotatedRegions.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL01lcmdlQW5ub3RhdGVkUmVnaW9ucy5qYXZh) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `80.172% <ø> (ø)` | `19 <0> (ø)` | :arrow_down: |; | [...tute/hellbender/tools/AnnotatePairOrientation.j,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5551#issuecomment-450184780:1274,pipeline,pipelines,1274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5551#issuecomment-450184780,1,['pipeline'],['pipelines']
Deployability,"pr&el=h1) Report; > Merging [#2548](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/c8ede6ef810a3d9a05c7deb8052e27ca724ce8ba?src=pr&el=desc) will **increase** coverage by `0.003%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2548 +/- ##; ===============================================; + Coverage 76.279% 76.282% +0.003% ; - Complexity 10891 10893 +2 ; ===============================================; Files 752 752 ; Lines 39590 39590 ; Branches 6925 6925 ; ===============================================; + Hits 30199 30200 +1 ; Misses 6768 6768 ; + Partials 2623 2622 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9BbGxlbGVTdWJzZXR0aW5nVXRpbHMuamF2YQ==) | `85.185% <ø> (ø)` | `39 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=footer). Last update [c8ede6e...b79b75d](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2548#issuecomment-290305475:1889,update,update,1889,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2548#issuecomment-290305475,2,['update'],['update']
Deployability,pression8271576113600851848.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform); 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1824); 	at java.lang.Runtime.load0(Runtime.java:809); 	at java.lang.System.load(System.java:1086); 	at com.intel.gkl.IntelGKLUtils.load(IntelGKLUtils.java:133); 	at com.intel.gkl.compression.IntelDeflater.load(IntelDeflater.java:58); 	at com.intel.gkl.compression.IntelDeflater.load(IntelDeflater.java:53); 	at com.intel.gkl.compression.IntelDeflaterFactory.<init>(IntelDeflaterFactory.java:16); 	at com.intel.gkl.compression.IntelDeflaterFactory.<init>(IntelDeflaterFactory.java:20); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2302#issuecomment-265854885:3070,deploy,deploy,3070,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2302#issuecomment-265854885,6,['deploy'],['deploy']
Deployability,"previously CommandLineParser would accept non-ambiguous abbreviations for longopts; this caused issues where -v would have different meanings in different tools. I patched joptSimple to add an option to disallow abbreviations, and updated to 5.0-beta-1 which incorporates the necessary changes.; fixes #1347",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1549:164,patch,patched,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1549,2,"['patch', 'update']","['patched', 'updated']"
Deployability,"previously avx code was sometimes included if installDist had been run prior to running sparkJar, now sparkJar will always contain the native code; fixes #1576. also changing download of inteldeflator.so to only happen if it doesn't exist already",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1681:46,install,installDist,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1681,1,['install'],['installDist']
Deployability,"provements that were discovered while reviewing the variants ; (https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest/tree/master/Evaluation/Analysis/masterVSfeature/notes.xlsx); The implemented fixes are:; * for removing the hard-coded/explicit mentioning of ""chr"" in non-canonical versions, it is now fixed in 5eff782e4d582d516004fba2cee7535d984b1540; * for contigs whose alignments paint ambiguous picture, i.e. multiple alignment configurations offer equally good explanation:; 	1. if only one configuration has all alignment with MQ above a specified threshold, it is favored; this is implemented in ecc31f5fbec4e524b401fc9474a3a1b7ab08c561; 	2. if one configuration has alignment to non-canonical chromosome that explains the contig better than would-be-event-inducing mappings to canonical chromosomes, the canonical mappings are saved but the better non-canonical mappings are saved as SA tag as in SAM spec, and the VCF record produced is annotated accordingly; this is implemented in 65cdb523a2f9fa2026334713fed45381d76ffc82; * fixed a bug where sometimes an assembly contig as several alignments, only one of which has non-mediocre MQ but at the sametime this alignment contains a large gap, such contigs were previously incorrectly filtered away, they are now salvaged by commit b6b2f197b112981e00efd9d415f010c024d31b36. So, for the FN variants (FN in the sense that they are captured in the stable version of our interpretation tool but now goes missing in the experimental interpretation tool); that were curated in the above-mentioned review, only the following ones are not salvaged, with plans or comments attached. ```; asm012854:tig00000	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face by group represented by asm002398:tig00001); asm014580:tig00018	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522:863,configurat,configuration,863,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522,2,['configurat'],['configuration']
Deployability,ps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:107); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:980); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /gatk/build/libs/gatk-package-4.0.5.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx5g -Xms5g -jar /gatk/build/libs/gatk-package-4.0.5.0-local.jar GenotypeGVCFs -R /cromwell-executions/JointGenotyping/3a733624-60a0-4e57-b7f5-7b7e99795738/call-GenotypeGVCFs/shard-25/inputs/data1/bill/pipeline/cromwell/hg38/Homo_sapiens_assembly38.fasta -O output.vcf.gz -D /cromwell-executions/JointGenotyping/3a733624-60a0-4e57-b7f5-7b7e99795738/call-GenotypeGVCFs/shard-25/inputs/data1/bill/pipeline/cromwell/hg38/Homo_sapiens_assembly38.dbsnp138.vcf -G StandardAnnotation --only-output-calls-starting-in-intervals --use-new-qual-calculator -V gendb://genomicsdb -L chrY:10821870-11717714; ```; This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/12283/running-260-wes-samples-through-joint-discovery-and-vqsr/p1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4975:4477,pipeline,pipeline,4477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4975,2,['pipeline'],['pipeline']
Deployability,ps://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F416C69676E6D656E74526567696F6E2E6A617661) |; | •••••• 60% | [...ute/hellbender/tools/spark/sv/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F4368696D65726963416C69676E6D656E742E6A617661) |; | ••••••• 72% | *new* [...llbender/tools/spark/sv/AssemblyAlignmentParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F417373656D626C79416C69676E6D656E745061727365722E6A617661) |; | •••••••••• 100% | [.../hellbender/tools/spark/sv/SVVariantCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F535656617269616E7443616C6C65725574696C732E6A617661) |; | •••••••••• 100% | [...tute/hellbender/tools/spark/sv/BreakpointAllele.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F427265616B706F696E74416C6C656C652E6A617661) |; | •••••••••• 100% | [...institute/hellbender/tools/spark/sv/SVConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F5356436F6E7374616E74732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [cb48a6e...073dabb](https://codecov.io/gh/broadinstitute/gatk/compare/cb48a6e4d524355c8ed312a622cbfae69f8ce26b...073dabbdf1e44a0c76e6c64adcc7570c9f310cc0?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2285#issuecomment-263705162:3661,update,update,3661,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2285#issuecomment-263705162,1,['update'],['update']
Deployability,"ps://github.com/broadinstitute/gatk/blob/4e1741896bcd04d70493f94b082dd0d27023f14c/src/main/python/org/broadinstitute/hellbender/gcnvkernel/structs/metadata.py#L177); [gcnvkernel metadata.py SampleMetadataCollection class](https://github.com/broadinstitute/gatk/blob/4e1741896bcd04d70493f94b082dd0d27023f14c/src/main/python/org/broadinstitute/hellbender/gcnvkernel/structs/metadata.py#L215); [gcnvkernel model_denoising_calling.py](https://github.com/broadinstitute/gatk/blob/4e1741896bcd04d70493f94b082dd0d27023f14c/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py); [gcnvkernel io_metadata.py write_sample_coverage_metadata function](https://github.com/broadinstitute/gatk/blob/4e1741896bcd04d70493f94b082dd0d27023f14c/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_metadata.py#L16); [theano scan_op.py](https://github.com/Theano/Theano/blob/master/theano/scan_module/scan_op.py). ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I'm getting a strange error (see below) when running a nf-core module test. I am using test files, which are obviously smaller as for short testing times i.e. the provided bam file only provides mapped reads for a small section of the genome. #### Steps to reproduce; Run the following to create and interactive container and mount the required zip folder ([gatk_test.tar.gz](https://github.com/broadinstitute/gatk/files/10022295/gatk_test.tar.gz)):; ```docker run -it -v /path/to/gatk_test_dir:/mnt/gatk_test broadinstitute/gatk bash```; If you bash the `gatk_germlinecnvcaller.sh` within the provided zip folder in a gatk4 Docker container. #### Expected behavior; gatk GermlineCNVCaller should run as expected. #### Actual behavior; ```TypeError: ('The following error happened while compiling the node', forall_inplace,cpu,scan_fn}(Elemwise{Maximum}[(0, 0)].0, Subtensor{int64:int64:int8}.0, Subtensor{int64:int64:in",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8097:1093,release,release,1093,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8097,1,['release'],['release']
Deployability,"ption=None,; services=List(),; started=false); 2019-05-19 19:09:41 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-05-19 19:09:41 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-05-19 19:09:41 INFO MemoryStore:54 - MemoryStore cleared; 2019-05-19 19:09:41 INFO BlockManager:54 - BlockManager stopped; 2019-05-19 19:09:41 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-05-19 19:09:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-05-19 19:09:41 INFO SparkContext:54 - Successfully stopped SparkContext; 19:09:41.578 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [May 19, 2019 7:09:41 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 44.89 minutes.; Runtime.totalMemory()=21646802944; htsjdk.samtools.util.RuntimeIOException: Error opening file: file:///restricted/projectnb/casa/wgs.hg38/pipelines/sv/gatk.sv/temp/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.contig-sam-file.sam; at htsjdk.samtools.SAMFileWriterFactory.makeSAMWriter(SAMFileWriterFactory.java:356); at htsjdk.samtools.SAMFileWriterFactory.makeSAMOrBAMWriter(SAMFileWriterFactory.java:437); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVFileUtils.writeSAMFile(SVFileUtils.java:29); at org.broadinstitute.hellbender.tools.spark.sv.evidence.AlignedAssemblyOrExcuse.writeAssemblySAMFile(AlignedAssemblyOrExcuse.java:336); at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.gatherEvidenceAndWriteContigSamFile(FindBreakpointEvidenceSpark.java:199); at org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark.runTool(StructuralVariationDiscoveryPipelineSpark.java:164); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkComma",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-494014590:4846,pipeline,pipelines,4846,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-494014590,2,['pipeline'],['pipelines']
Deployability,publishing a master-snapshot update on every push to master,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2403:29,update,update,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2403,1,['update'],['update']
Deployability,"py=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # conda-installed 2.2.4 appears to be the most recent version with a consistent API and without conflicts/clobbers; # if you wish to update, note that versions of conda-forge::keras after 2.2.5; # undesirably set the environment variable KERAS_BACKEND = theano by default; - defaults::intel-openmp=2019.4; - conda-forge::scikit-learn=0.22.2; - conda-forge::matplotlib=3.2.1; - conda-forge::pandas=1.0.3. # core R dependencies; these should only be used for plotting and do not take precedence over core python dependencies!; - r-base=3.6.2; - r-data.table=1.12.8; - r-dplyr=0.8.5; - r-getopt=1.20.3; - r-ggplot2=3.3.0; - r-gplots=3.0.3; - r-gsalib=2.1; - r-optparse=1.6.4. # other python dependencies; these should be removed after functionality is moved into Java code; - biopython=1.76; - pyvcf=0.6.8; - bioconda::pysam=0.15.3 # using older conda-installed versions may result in libcrypto / openssl bugs. # pip installs should be avoided, as pip may not respect the depen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:2764,install,installed,2764,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,4,['install'],['installed']
Deployability,quick pr to update the beta workflow to use the latest ploidy changes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8349:12,update,update,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8349,1,['update'],['update']
Deployability,"quified samples. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-260475512). @ldgauthier Will this tool be ported to GATK4? . ---. @ldgauthier commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-260637796). ¯_(ツ)_/¯. I wasn't going to port it myself. It's not under active development, but GTEx used it a little in the past. ---. @vdauwera commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-260713724). Hmm. Who would be the right person to ask whether GTex would need this ported? . ---. @ldgauthier commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-260739166). Last I checked, Xiao Li was using the tool for the work he was doing with Ayellet Segre. ---. @vdauwera commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-260778577). Thanks, I emailed them to ask about their use of the tool. . ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-287823398). Response from Xiao Li:. > The “CombineSampleData” tool is initially developed by Laura to perform integrated variant calling when we have both WES and WGS data for same individuals. Use GTEx release v6 data, we have found that it helps generating better genotype calls and improves calls from older technologies (e.g.: HiSeq2000 vs. HiSeqX, Agilent vs. ICE). In GTEx, all samples will be genotyped with both WGS and WES, and because of this, in our final release next year, we want to use this tool to generate a call set that integrates WGS and WES. Prior to this, we plan to publish this method that we could cite it in the final release paper. I will expect this method very useful for other big consortiums where both WGS and WES are available for same samples. . > Hope you could keep it in GATK.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2485:4110,integrat,integrated,4110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2485,5,"['integrat', 'release']","['integrated', 'integrates', 'release']"
Deployability,"r (MappingQualityAvailableReadFilter) is not enabled by this tool. 07:33:15.003 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/nobackupp16/swbuild/hsp/COVID19/anaconda3/envs/COVIRT_GATK/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so. Sep 20, 2020 7:33:15 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 07:33:15.360 INFO FilterMutectCalls - ------------------------------------------------------------. 07:33:15.361 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.1.7.0. 07:33:15.361 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/. 07:33:15.361 INFO FilterMutectCalls - Executing as lnsingh@pfe26 on Linux v4.12.14-122.23.1.20200609-nasa amd64. 07:33:15.361 INFO FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12. 07:33:15.361 INFO FilterMutectCalls - Start Date/Time: September 20, 2020 7:33:14 AM PDT. 07:33:15.361 INFO FilterMutectCalls - ------------------------------------------------------------. 07:33:15.361 INFO FilterMutectCalls - ------------------------------------------------------------. 07:33:15.362 INFO FilterMutectCalls - HTSJDK Version: 2.21.2. 07:33:15.362 INFO FilterMutectCalls - Picard Version: 2.21.9. 07:33:15.362 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2. 07:33:15.362 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false. 07:33:15.362 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true. 07:33:15.362 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false. 07:33:15.362 INFO FilterMutectCalls - Deflater: IntelDeflater. 07:33:15.362 INFO FilterMutectCalls - Inflater: IntelInflater. 07:33:15.363 INFO FilterMutectCalls - GCS max retries/reopens: 20. 07:33:15.363 INFO Filt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6850:2519,release,release-,2519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850,1,['release'],['release-']
Deployability,"r gradle; build.gradle. 3. Significant changes to existing code to support/invoke new filter; - add arguments for XGBoostEvidenceFilter, changes for scaling density filter by coverage; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/StructuralVariationDiscoveryArgumentCollection.java; - replace calls to BreakpointDensityFilter with calls to BreakpointFilterFactory; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/FindBreakpointEvidenceSpark.java; - input coverage-scaled thresholds, convert to absolute internally. Allow thresholds to be double instead of int; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointDensityFilter.java; - getter functions added to calculate properties for XGBoostEvidenceFilter. Also fromStringRep() and helper constructors added for testing; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointEvidence.java; - updates to tests reflecting changes to these interfaces; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointDensityFilterTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/FindBreakpointEvidenceSparkUnitTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/integration/FindBreakpointEvidenceSparkIntegrationTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/integration/SVIntegrationTestDataProvider.java. 4. Added code; - factory to call appropriate BreakpointEvidence filter; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointFilterFactory.java; - simple helper class to hold feature vectors for classifier; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/EvidenceFeatures.java; - implement classifier-based BreakpointEvidence filter; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/XGBoostEvidenceFilter.java; - unit test for classifier filter; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389218477:1696,update,updates,1696,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389218477,2,['update'],['updates']
Deployability,"r i post this kind of question elsewhere, please let me know. My lab creates a large dataset of macaque variant data. We regularly add new samples to a dataset that currently has ~2300 WGS/WXS datasets. We largely follow the GATK short variant calling pipeline. Our gVCF data are aggregated into a GenomicsDb workspace, followed by GenotypeGVCFs. As is, whenever we get new samples, we append them to this growing GenomicsDb workspace, and then re-call all of the genotypes. These steps are getting slower and slower (even when scatter/gathered on a cluster), and I'm concerned it's going to become untenable. Plus it's just really inefficient to constantly re-call 1000s of datasets at 40m genome-wide sites. My question is: do you have any experience with analogous datasets, where you have a large base of ""static"" datasets with regular additions of new data? It would be quite nice to avoid constantly re-genotyping the existing datasets. We could in theory just run GenotypeGVCFs on the incoming data and do a simple merge with the existing data. Are you aware of anyone running a process that looks more like this?. There are some caveats to this: 1) for the incoming batches of data, we could run GenotypeGVCF where we force it to call genotypes from every site that exists in the current dataset. This would promote consistent calling across a common set of sites, 2) after we genotype the incoming batch, we could compare the sites present in that against the sites in the current data. It's likely there would be a handful of novel sites. We could re-run GenotypeGVCFs on the existing data specifically on those new sites (presumably the existing animals are largely WT at those positions), and merge those new sites with the existing data, 3) we then merge the incoming data with the updated core data, which should each have genotypes called at the identical set of sites. Are there any discussions happening about managing/updating large variant datasets like this? Thanks for any ideas.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7526:1809,update,updated,1809,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7526,1,['update'],['updated']
Deployability,r the second pass.; 44	GetPileupSummaries	beta; helper tool for CalculateContamination	6/5/2017	https://github.com/broadinstitute/gatk-protected/blob/2bf35790393332da5414b42ec6dca813fcc63202/src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/GetPileupSummaries.java	scripts/mutect2_wdl/mutect2.wdl	https://github.com/broadinstitute/gatk/pull/3006	yes	; 33	AnnotateVcfWithBamDepth	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/AnnotateVcfWithBamDepth.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes	; 34	AnnotateVcfWithExpectedAlleleFraction	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/AnnotateVcfWithExpectedAlleleFraction.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes	; 37	CalculateMixingFractions	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/CalculateMixingFractions.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes	; 47	RemoveNearbyIndels	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/RemoveNearbyIndels.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes		; ```. This is also at <https://docs.google.com/a/broadinstitute.org/spreadsheets/d/15xviLwYUjU82MtYwxxPINiJAkovmaHpRGhqkghiEATQ/edit?usp=sharing>.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3055:14025,a/b,a/broadinstitute,14025,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3055,1,['a/b'],['a/broadinstitute']
Deployability,"r to the new contamination tool, about 3 weeks. ---. @vdauwera commented on [Tue Mar 14 2017](https://github.com/broadinstitute/gatk-protected/issues/800#issuecomment-286453446). I would like us to consider this part of the somatic short variants discovery pipeline (which is probably what you mean by Mutect wdl). I'm not sure how urgently we need it, probably ""not very urgent in the scheme of things, but should be done eventually"". I assume @LeeTL1220 has a better idea of what we need when on the somatic side of things. . And you're right that this creates a loss of sensitivity, not false positives. I'm being distracted by a tiny human. . ---. @LeeTL1220 commented on [Tue Mar 14 2017](https://github.com/broadinstitute/gatk-protected/issues/800#issuecomment-286457270). We should do it. Generally, I agree with Geraldine's statement about; urgency, though. We can meet to discuss prioritization relative to other; auxiliary tools. On Tue, Mar 14, 2017 at 11:15 AM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > I would like us to consider this part of the somatic short variants; > discovery pipeline (which is probably what you mean by Mutect wdl). I'm not; > sure how urgently we need it, probably ""not very urgent in the scheme of; > things, but should be done eventually"". I assume @LeeTL1220; > <https://github.com/LeeTL1220> has a better idea of what we need when on; > the somatic side of things.; >; > And you're right that this creates a loss of sensitivity, not false; > positives. I'm being distracted by a tiny human.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk-protected/issues/800#issuecomment-286453446>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk6kK5A_Mhh9S3s4xX_EEZQlwtKvGks5rlq8hgaJpZM4K3d-Q>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 7003EB; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2919:2441,pipeline,pipeline,2441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2919,1,['pipeline'],['pipeline']
Deployability,"r&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21hZk91dHB1dC9NYWZPdXRwdXRSZW5kZXJlckNvbnN0YW50cy5qYXZh) | `99.01% <100%> (+0.04%)` | `1 <0> (ø)` | :arrow_down: |; | [...der/tools/funcotator/metadata/TumorNormalPair.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21ldGFkYXRhL1R1bW9yTm9ybWFsUGFpci5qYXZh) | `63.63% <63.63%> (ø)` | `5 <5> (?)` | |; | [...cotator/mafOutput/CustomMafFuncotationCreator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21hZk91dHB1dC9DdXN0b21NYWZGdW5jb3RhdGlvbkNyZWF0b3IuamF2YQ==) | `90% <90%> (ø)` | `17 <17> (?)` | |; | [...tools/funcotator/metadata/SamplePairExtractor.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21ldGFkYXRhL1NhbXBsZVBhaXJFeHRyYWN0b3IuamF2YQ==) | `95% <95%> (ø)` | `9 <9> (?)` | |; | [...titute/hellbender/tools/funcotator/Funcotator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3IuamF2YQ==) | `86.18% <0%> (+0.65%)` | `43% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4917?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4917?src=pr&el=footer). Last update [9d8fdac...0e8a045](https://codecov.io/gh/broadinstitute/gatk/pull/4917?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4917#issuecomment-399122987:3724,update,update,3724,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4917#issuecomment-399122987,2,['update'],['update']
Deployability,"r&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvTG9jdXNXYWxrZXJTcGFyay5qYXZh) | `82.5% <83.33%> (+4.72%)` | `12 <2> (ø)` | :arrow_down: |; | [...itute/hellbender/engine/spark/ReadWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvUmVhZFdhbGtlclNwYXJrLmphdmE=) | `72.22% <85.71%> (-5.2%)` | `8 <3> (-2)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `72.51% <0%> (+0.94%)` | `38% <0%> (+1%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `80% <0%> (+30%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5221?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5221?src=pr&el=footer). Last update [2ee7df3...e40ce5e](https://codecov.io/gh/broadinstitute/gatk/pull/5221?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5221#issuecomment-426308250:4594,update,update,4594,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5221#issuecomment-426308250,2,['update'],['update']
Deployability,"r(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-0bd07e00-4f6d-43bd-b9d2-b1999376c72b; ```. Just to verify, the non-spark version still runs fine with the compressed fasta.... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; 13:38:54.168 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:38:55.869 INFO CountReads - ------------------------------------------------------------; 13:38:55.870 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:38:55.870 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:38:55.871 INFO CountReads - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:38:55.871 INFO CountReads - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:38:55.871 INFO CountReads - Start Date/Time: January 9, 2019 1:38:54 PM EST; 13:38:55.871 INFO CountReads - -----------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:43782,install,install,43782,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['install'],['install']
Deployability,"rImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at java.io.ObjectStreamClass.invokeReadResolve(ObjectStreamClass.java:1104); ... 31 more; Caused by: java.lang.IllegalAccessError: no such method: org.broadinstitute.hellbender.tools.FlagStat$FlagStatus.add(GATKRead)FlagStatus/invokeVirtual; at java.lang.invoke.MethodHandleNatives.linkMethodHandleConstant(MethodHandleNatives.java:448); at org.broadinstitute.hellbender.tools.spark.pipelines.FlagStatSpark.$deserializeLambda$(FlagStatSpark.java:20); ... 40 more; Caused by: java.lang.LinkageError: loader constraint violation: when resolving method ""org.broadinstitute.hellbender.tools.FlagStat$FlagStatus.add(Lorg/broadinstitute/hellbender/utils/read/GATKRead;)Lorg/broadinstitute/hellbender/tools/FlagStat$FlagStatus;"" the class loader (instance of org/apache/spark/util/ChildFirstURLClassLoader) of the current class, org/broadinstitute/hellbender/tools/spark/pipelines/FlagStatSpark, and the class loader (instance of org/apache/spark/util/ChildFirstURLClassLoader) for the method's defining class, org/broadinstitute/hellbender/tools/FlagStat$FlagStatus, have different Class objects for the type org/broadinstitute/hellbender/utils/read/GATKRead used in the signature; at java.lang.invoke.MethodHandleNatives.resolve(Native Method); at java.lang.invoke.MemberName$Factory.resolve(MemberName.java:965); at java.lang.invoke.MemberName$Factory.resolveOrFail(MemberName.java:990); at java.lang.invoke.MethodHandles$Lookup.resolveOrFail(MethodHandles.java:1387); at java.lang.invoke.MethodHandles$Lookup.linkMethodHandleConstant(MethodHandles.java:1739); at java.lang.invoke.MethodHandleNatives.linkMethodHandleConstant(MethodHandleNatives.java:442); ... 41 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1273); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(D",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1315:4225,pipeline,pipelines,4225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1315,1,['pipeline'],['pipelines']
Deployability,"ra commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-260494000). @vruano Are you currently working on this? Or can this be moved into the GATK4 repo for future work? . ---. @vruano commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-260503444). Working on it on GATK3 but I could merge it into GATK4 whenever is ready if you prefer. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-260509332). Ok great, totally fine to do in 3 but please do port to 4 when it's ready. Do you have an order of magnitude sense of when it might be ready? Meaning days/weeks/months (for release scheduling purposes). ---. @vruano commented on [Fri Mar 10 2017](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-285721454). In the last methods meeting I presented the results of our first effort to improve accuracy calling in STR. As far as unfiltered single and trio calls are concerned the recommendation is to apply the new model with PCR+ data. However, for PCR- dataset one either can choose not apply any correction or to apply the new model train on PCR- data... the latter seems to have slightly F1 values however for the sake of simplicity it might just make sense no to apply any correct; either way is good. The presentation I gave can be found [here](https://drive.google.com/open?id=0Bzt9p0vCNxlHWlZVUHZfdXR5MTg). ---. @vruano commented on [Fri Mar 10 2017](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-285722791). It seems that at some point Planatir will take a look and see whether it improves calls once filtered with VQSR. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-287822174). Is there a PR associated with this issue? Will there be a new feature to release? Need to know for release scheduling purposes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2519:2596,release,release,2596,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2519,2,['release'],['release']
Deployability,"ract Dockerfile; remove exception catching in extract python script (#7113); - remove problematic storage_location imports (#7119); - Reduce memory and CPU for CreateImportTsvs task, check for files before attempting load (#7121); - add -m flag to gsutil mv step (#7129); - ah_var_store : Add sample file argument to cohort extract (#7117); - wip; - initial cohort extract; - minor changes; - wip; - get genotypes working; - clarify sample -> sample_id; - add mode; - mode is mandatory, uses location instead of position; - add query mode; - fix contig name; - forgot this file; - fix location bug; - Ingest wip to be added to other var db code (#6582); - ingest arrays refactored; - add filter, change sample to sample_id; - fix bugs; - wip; - major refactor splitting ingest for arrays from exomes/genomes; - create output files for actual raw array tables; - change site_name to rsid; - change GT encoding, change output file names and remove dir structure, get probe metadata; - fix prefix; - update GT encoding; - remove filter, rename columns, allow sample id as input; - array cohort extract (#6666); - new bit-compression (#6691); - refactored to common ProbeInfo, support compressed data on ingest, support local CSV probe info; - update exome ingest; - minor mods; - change structure, add compressed option to ingest; - add imputed tsv creator and refactor; - add fields for uncompressed imputed data; - Adding a test and small features to var store branch (#6761); - upgraded to new google bigquery libraries and storage api v1; used storage api for probe info; synced encoded gt definitions; - added support for probe_id ranges (#6806); - ah - use new GT encoding (#6822); - Tool for arrays QC metrics calculations (#6812); - ah update array extract tool (#6827); - fix enum (#6834); - updating ArrayCalculateMetrics for new genotype counts table (#6843); - Ability to filter variants based on QC in ArrayExtractCohort (#6844); - switch from ExcessHet back to HWE (#6848); - resolved rebas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:6628,update,update,6628,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['update'],['update']
Deployability,radle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:31); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:67); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.435 [ERROR] [org.gradle.internal.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:8337,Continuous,ContinuousBuildActionExecuter,8337,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['Continuous'],['ContinuousBuildActionExecuter']
Deployability,radle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:47); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:7485,Continuous,ContinuousBuildActionExecuter,7485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['Continuous'],['ContinuousBuildActionExecuter']
Deployability,"rage Diff @@; ## master #5539 +/- ##; ============================================; - Coverage 87.06% 87.06% -0.01% ; + Complexity 31324 31322 -2 ; ============================================; Files 1921 1921 ; Lines 144579 144579 ; Branches 15949 15949 ; ============================================; - Hits 125884 125880 -4 ; - Misses 12902 12906 +4 ; Partials 5793 5793; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (-0.61%)` | `42% <0%> (ø)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=footer). Last update [10aa8c7...3aec594](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5539#issuecomment-449065825:2412,update,update,2412,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5539#issuecomment-449065825,2,['update'],['update']
Deployability,"rage by `0.008%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2468 +/- ##; ===============================================; + Coverage 76.268% 76.275% +0.008% ; - Complexity 10876 10879 +3 ; ===============================================; Files 752 752 ; Lines 39583 39583 ; Branches 6922 6922 ; ===============================================; + Hits 30189 30192 +3 ; + Misses 6774 6772 -2 ; + Partials 2620 2619 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2468?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...4bebcdf005e9191206558f09e14f59d87324f1c8?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...4bebcdf005e9191206558f09e14f59d87324f1c8?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2468?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2468?src=pr&el=footer). Last update [c62914a...4bebcdf](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...4bebcdf005e9191206558f09e14f59d87324f1c8?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2468#issuecomment-288779580:2043,update,update,2043,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2468#issuecomment-288779580,2,['update'],['update']
Deployability,"rage is `100%`. ```diff; @@ Coverage Diff @@; ## master #2427 +/- ##; ===============================================; + Coverage 76.218% 76.221% +0.003% ; - Complexity 10819 10821 +2 ; ===============================================; Files 750 750 ; Lines 39420 39421 +1 ; Branches 6883 6883 ; ===============================================; + Hits 30045 30047 +2 ; Misses 6757 6757 ; + Partials 2618 2617 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2427?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tute/hellbender/tools/spark/sv/ReadClassifier.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...fc95362d5a29cc5738032c43aa922b491b6accf5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkQ2xhc3NpZmllci5qYXZh) | `83.607% <100%> (+0.273%)` | `31 <4> (+1)` | :white_check_mark: |; | [.../hellbender/tools/spark/sv/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...fc95362d5a29cc5738032c43aa922b491b6accf5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `83.756% <0%> (+0.508%)` | `24% <0%> (+1%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2427?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2427?src=pr&el=footer). Last update [fcd103c...fc95362](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...fc95362d5a29cc5738032c43aa922b491b6accf5?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2427#issuecomment-282851101:2077,update,update,2077,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2427#issuecomment-282851101,2,['update'],['update']
Deployability,rage Δ | Complexity Δ | |; |---|---|---|---|; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...spark/ReadsPreprocessingPipelineSparkTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvUmVhZHNQcmVwcm9jZXNzaW5nUGlwZWxpbmVTcGFya1Rlc3REYXRhLmphdmE=) | `0% <0%> (-94.03%)` | `0% <0%> (-11%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-89.583%)` | `0% <0%> (-12%)` | |; | [...adinstitute/hellbender/engine/ReadContextData.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZENvbnRleHREYXRhLmphdmE=) | `0% <0%> (-70.37%)` | `0% <0%> (-6%)` | |; | [...n/java/org/broadinstitute/hellbender/utils/KV.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9LVi5qYXZh) | `0% <0%> (-57.143%)` | `0% <0%> (-5%)` | |; | [...walkers/genotyper/afcalc/AFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlb,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5251#issuecomment-426437671:1889,pipeline,pipelines,1889,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5251#issuecomment-426437671,1,['pipeline'],['pipelines']
