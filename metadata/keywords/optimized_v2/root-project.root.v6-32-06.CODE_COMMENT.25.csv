quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,filename,wiki,url,total_similar,target_keywords,target_matched_words
Performance,// TODO: get and print the raw bytes of the load command.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-objdump/MachODump.cpp:44,load,load,44,interpreter/llvm-project/llvm/tools/llvm-objdump/MachODump.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-objdump/MachODump.cpp,1,['load'],['load']
Performance,// TODO: handle scalable vectors.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp:16,scalab,scalable,16,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,1,['scalab'],['scalable']
Performance,"// TODO: if this becomes a bottleneck, we can save on GetLastDef calls by; // keeping this map before the loop. We can reuse already populated entries; // if an edge is added from the same predecessor to two different blocks,; // and this does happen in rotate. Note that the map needs to be updated; // when deleting non-necessary phis below, if the phi is in the map by; // replacing the value with DefP1.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSAUpdater.cpp:27,bottleneck,bottleneck,27,interpreter/llvm-project/llvm/lib/Analysis/MemorySSAUpdater.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSAUpdater.cpp,1,['bottleneck'],['bottleneck']
Performance,"// TODO: improve performance",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/genvector/src/AxisAngleXother.cxx:17,perform,performance,17,math/genvector/src/AxisAngleXother.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/src/AxisAngleXother.cxx,12,['perform'],['performance']
Performance,// TODO: maybe this could be cached when generating the; // associated namespaces / entities.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp:29,cache,cached,29,interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,1,['cache'],['cached']
Performance,// TODO: optimized implementation using constant values,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/VE/VEISelLowering.cpp:9,optimiz,optimized,9,interpreter/llvm-project/llvm/lib/Target/VE/VEISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/VE/VEISelLowering.cpp,2,['optimiz'],['optimized']
Performance,// TODO: perform context-sensitive analysis?,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionAttrs.cpp:9,perform,perform,9,interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionAttrs.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionAttrs.cpp,1,['perform'],['perform']
Performance,// TODO: print all the other kinds of load commands.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-objdump/MachODump.cpp:38,load,load,38,interpreter/llvm-project/llvm/tools/llvm-objdump/MachODump.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-objdump/MachODump.cpp,1,['load'],['load']
Performance,"// TODO: provide atomic and non-atomic reduction generators for reduction; // operators defined by the OpenMP specification.; /// Generator for '#omp reduction'.; ///; /// Emits the IR instructing the runtime to perform the specific kind of; /// reductions. Expects reduction variables to have been privatized and; /// initialized to reduction-neutral values separately. Emits the calls to; /// runtime functions as well as the reduction function and the basic blocks; /// performing the reduction atomically and non-atomically.; ///; /// The code emitted for the following:; ///; /// \code; /// type var_1;; /// type var_2;; /// #pragma omp <directive> reduction(reduction-op:var_1,var_2); /// /* body */;; /// \endcode; ///; /// corresponds to the following sketch.; ///; /// \code; /// void _outlined_par() {; /// // N is the number of different reductions.; /// void *red_array[] = {privatized_var_1, privatized_var_2, ...};; /// switch(__kmpc_reduce(..., N, /*size of data in red array*/, red_array,; /// _omp_reduction_func,; /// _gomp_critical_user.reduction.var)) {; /// case 1: {; /// var_1 = var_1 <reduction-op> privatized_var_1;; /// var_2 = var_2 <reduction-op> privatized_var_2;; /// // ...; /// __kmpc_end_reduce(...);; /// break;; /// }; /// case 2: {; /// _Atomic<ReductionOp>(var_1, privatized_var_1);; /// _Atomic<ReductionOp>(var_2, privatized_var_2);; /// // ...; /// break;; /// }; /// default: break;; /// }; /// }; ///; /// void _omp_reduction_func(void **lhs, void **rhs) {; /// *(type *)lhs[0] = *(type *)lhs[0] <reduction-op> *(type *)rhs[0];; /// *(type *)lhs[1] = *(type *)lhs[1] <reduction-op> *(type *)rhs[1];; /// // ...; /// }; /// \endcode; ///; /// \param Loc The location where the reduction was; /// encountered. Must be within the associate; /// directive and after the last local access to the; /// reduction variables.; /// \param AllocaIP An insertion point suitable for allocas usable; /// in reductions.; /// \param ReductionInfos A list of info on each redu",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Frontend/OpenMP/OMPIRBuilder.h:212,perform,perform,212,interpreter/llvm-project/llvm/include/llvm/Frontend/OpenMP/OMPIRBuilder.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Frontend/OpenMP/OMPIRBuilder.h,2,['perform'],"['perform', 'performing']"
Performance,"// TODO: return a good value for BB-VECTORIZER that includes the; // immediate loads, which we do not want to count for the loop; // vectorizer, since they are hopefully hoisted out of the loop. This; // would require a new parameter 'InLoop', but not sure if constant; // args are common enough to motivate this.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp:79,load,loads,79,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp,1,['load'],['loads']
Performance,// TODO: setStaticVL(ElementCount) for scalable types.; // Emit a VP intrinsic call that mimics a regular instruction.; // This operation behaves according to the VectorBuilderBehavior.; // \p Opcode The functional instruction opcode of the emitted intrinsic.; // \p ReturnTy The return type of the operation.; // \p VecOpArray The operand list.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/IR/VectorBuilder.h:39,scalab,scalable,39,interpreter/llvm-project/llvm/include/llvm/IR/VectorBuilder.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/IR/VectorBuilder.h,1,['scalab'],['scalable']
Performance,// TODO: skip functions that have no instrumented allocas for optimization,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64MachineFunctionInfo.cpp:62,optimiz,optimization,62,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64MachineFunctionInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64MachineFunctionInfo.cpp,1,['optimiz'],['optimization']
Performance,"// TODO: this is naive. The optimization is still valid if DupPg; // 'encompasses' OpPredicate, not only if they're the same predicate.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp:28,optimiz,optimization,28,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,1,['optimiz'],['optimization']
Performance,"// TODO: this should call checkModel so we can use the cache, however,; // this method tries to get the interpretation (the actual value) from; // the solver, which is currently not cached.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/StaticAnalyzer/Core/PathSensitive/SMTConstraintManager.h:55,cache,cache,55,interpreter/llvm-project/clang/include/clang/StaticAnalyzer/Core/PathSensitive/SMTConstraintManager.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/StaticAnalyzer/Core/PathSensitive/SMTConstraintManager.h,2,['cache'],"['cache', 'cached']"
Performance,// TODO: tune vector-to-scalar cast.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp:9,tune,tune,9,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp,1,['tune'],['tune']
Performance,"// TODO: we need to factor out the routine for the branch alone...; // Maybe a cache for the names?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RRootDS.cxx:79,cache,cache,79,tree/dataframe/src/RRootDS.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RRootDS.cxx,1,['cache'],['cache']
Performance,"// TODO: white-list trivial vbase initializers. This case wouldn't; // be subject to the restrictions below.; // TODO: white-list cases where:; // - there are no non-reference parameters to the constructor; // - the initializers don't access any non-reference parameters; // - the initializers don't take the address of non-reference; // parameters; // - etc.; // If we ever add any of the above cases, remember that:; // - function-try-blocks will always exclude this optimization; // - we need to perform the constructor prologue and cleanup in; // EmitConstructorBody.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGClass.cpp:469,optimiz,optimization,469,interpreter/llvm-project/clang/lib/CodeGen/CGClass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGClass.cpp,2,"['optimiz', 'perform']","['optimization', 'perform']"
Performance,"// TODO: would a masked load be faster?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/builtins/zlib/adler32_cf.c:24,load,load,24,builtins/zlib/adler32_cf.c,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/builtins/zlib/adler32_cf.c,1,['load'],['load']
Performance,"// TODO:; // - add an TGFrame::HandleDNDStatus event handler?; // - implement INCR protocol; // - cache several requests?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/gui/src/TGDNDManager.cxx:98,cache,cache,98,gui/gui/src/TGDNDManager.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/gui/src/TGDNDManager.cxx,1,['cache'],['cache']
Performance,"// TODO:; // - implement ""custom"" colors.; // - optimize the code, specially the one handling the fColormap image; // and dithering in pseudo-color modes; remove duplicated code.; // - improve the color allocation routine.; // - use a buffering pixmap for the fColormap image.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/gui/src/TGColorDialog.cxx:48,optimiz,optimize,48,gui/gui/src/TGColorDialog.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/gui/src/TGColorDialog.cxx,1,['optimiz'],['optimize']
Performance,"// TODO:; // Additional cases that we need to add to this file:; //; // cbrt:; // * cbrt(expN(X)) -> expN(x/3); // * cbrt(sqrt(x)) -> pow(x,1/6); // * cbrt(cbrt(x)) -> pow(x,1/9); //; // exp, expf, expl:; // * exp(log(x)) -> x; //; // log, logf, logl:; // * log(exp(x)) -> x; // * log(exp(y)) -> y*log(e); // * log(exp10(y)) -> y*log(10); // * log(sqrt(x)) -> 0.5*log(x); //; // pow, powf, powl:; // * pow(sqrt(x),y) -> pow(x,y*0.5); // * pow(pow(x,y),z)-> pow(x,y*z); //; // signbit:; // * signbit(cnst) -> cnst'; // * signbit(nncst) -> 0 (if pstv is a non-negative constant); //; // sqrt, sqrtf, sqrtl:; // * sqrt(expN(x)) -> expN(x*0.5); // * sqrt(Nroot(x)) -> pow(x,1/(2*N)); // * sqrt(pow(x,y)) -> pow(|x|,y*0.5); //; //===----------------------------------------------------------------------===//; // Fortified Library Call Optimizations; //===----------------------------------------------------------------------===//",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp:831,Optimiz,Optimizations,831,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp,1,['Optimiz'],['Optimizations']
Performance,"// TSystem::Load",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/gpadv7/src/RVirtualCanvasPainter.cxx:12,Load,Load,12,graf2d/gpadv7/src/RVirtualCanvasPainter.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/gpadv7/src/RVirtualCanvasPainter.cxx,1,['Load'],['Load']
Performance,"// TSystem::Load returns 1 when the library was already loaded, return success in this case.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TROOT.cxx:12,Load,Load,12,core/base/src/TROOT.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TROOT.cxx,2,"['Load', 'load']","['Load', 'loaded']"
Performance,// TTI based checks if we want to proceed with wider load,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp:53,load,load,53,interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp,1,['load'],['load']
Performance,"// TTI call to check if target would like to expand memcmp. Also, get the; // available load sizes.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp:88,load,load,88,interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,1,['load'],['load']
Performance,"// TTree I/O performance measurement",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/inc/TTreePerfStats.h:13,perform,performance,13,tree/treeplayer/inc/TTreePerfStats.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/inc/TTreePerfStats.h,1,['perform'],['performance']
Performance,"// TTree cache handling",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/inc/TMPWorkerTree.h:9,cache,cache,9,tree/treeplayer/inc/TMPWorkerTree.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/inc/TMPWorkerTree.h,1,['cache'],['cache']
Performance,// Table-Driven optimization,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULibCalls.cpp:16,optimiz,optimization,16,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULibCalls.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULibCalls.cpp,1,['optimiz'],['optimization']
Performance,"// Table2Addr - Holds instructions which their memory form performs; // load+store.; //; // Table#i - Holds instructions which the their memory form; // performs a load OR a store, and their #i'th operand is folded.; //; // BroadcastTable#i - Holds instructions which the their memory form performs; // a broadcast load and their #i'th operand is folded.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/X86FoldTablesEmitter.cpp:59,perform,performs,59,interpreter/llvm-project/llvm/utils/TableGen/X86FoldTablesEmitter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/X86FoldTablesEmitter.cpp,6,"['load', 'perform']","['load', 'performs']"
Performance,// Tag changes whenever cached information needs to be recomputed. An RCInfo; // entry is valid when its tag matches.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/RegisterClassInfo.h:24,cache,cached,24,interpreter/llvm-project/llvm/include/llvm/CodeGen/RegisterClassInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/RegisterClassInfo.h,1,['cache'],['cached']
Performance,// Tag the result of a load from 'self' so that we can easily know that the; // value is the object that 'self' points to.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/ObjCSelfInitChecker.cpp:23,load,load,23,interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/ObjCSelfInitChecker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/ObjCSelfInitChecker.cpp,1,['load'],['load']
Performance,// Tail duplication.; // Note that duplicating tail just increases code size and degrades; // performance for targets that require Structured Control Flow.; // In addition it can also make CFG irreducible. Thus we disable it.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/CodeGenPassBuilder.h:94,perform,performance,94,interpreter/llvm-project/llvm/include/llvm/CodeGen/CodeGenPassBuilder.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/CodeGenPassBuilder.h,2,['perform'],['performance']
Performance,"// Tail page optimization and buffered writing on, IMT not disabled.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/test/ntuple_model.cxx:13,optimiz,optimization,13,tree/ntuple/v7/test/ntuple_model.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/test/ntuple_model.cxx,1,['optimiz'],['optimization']
Performance,"// Take a MVEEXT(load x) and split that into (extload x, extload x+8)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:17,load,load,17,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['load'],['load']
Performance,// Take advantage of the optimized sequence for vec_all_eq when vcmpequd is; // not available.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/altivec.h:25,optimiz,optimized,25,interpreter/llvm-project/clang/lib/Headers/altivec.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/altivec.h,1,['optimiz'],['optimized']
Performance,"// Take advantage of vector comparisons (etc.) producing 0 or -1 in each lane; // to optimize away operation when it's from a constant.; //; // The general transformation is:; // UNARYOP(AND(VECTOR_CMP(x,y), constant)) -->; // AND(VECTOR_CMP(x,y), constant2); // constant2 = UNARYOP(constant); // Early exit if this isn't a vector operation, the operand of the; // unary operation isn't a bitwise AND, or if the sizes of the operations; // aren't the same.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:85,optimiz,optimize,85,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['optimiz'],['optimize']
Performance,"// Take advantage of vector comparisons producing 0 or -1 in each lane to; // optimize away operation when it's from a constant.; //; // The general transformation is:; // UNARYOP(AND(VECTOR_CMP(x,y), constant)) -->; // AND(VECTOR_CMP(x,y), constant2); // constant2 = UNARYOP(constant); // Early exit if this isn't a vector operation, the operand of the; // unary operation isn't a bitwise AND, or if the sizes of the operations; // aren't the same.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:78,optimiz,optimize,78,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['optimiz'],['optimize']
Performance,"// Take it from the cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProofServ.cxx:20,cache,cache,20,proof/proof/src/TProofServ.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProofServ.cxx,1,['cache'],['cache']
Performance,"// Take ownership.; // Make sure we can resolve symbols in the program as well. The zero arg; // to the function tells DynamicLibrary to load the program, not a library.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/ExecutionEngine.cpp:137,load,load,137,interpreter/llvm-project/llvm/lib/ExecutionEngine/ExecutionEngine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/ExecutionEngine.cpp,1,['load'],['load']
Performance,// Takes a function and runs it on a set of inputs; // First determines whether f is the optimized or unoptimized function,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-fuzzer/handle-llvm/handle_llvm.cpp:89,optimiz,optimized,89,interpreter/llvm-project/clang/tools/clang-fuzzer/handle-llvm/handle_llvm.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-fuzzer/handle-llvm/handle_llvm.cpp,1,['optimiz'],['optimized']
Performance,// Target does not support indexed loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelDAGToDAG.cpp:35,load,loads,35,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelDAGToDAG.cpp,2,['load'],['loads']
Performance,// Target does not support load/store pair.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:27,load,load,27,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['load'],['load']
Performance,"// Target hook to do target-specific const optimization, which is called by; // ShrinkDemandedConstant. This function should return true if the target; // doesn't want ShrinkDemandedConstant to further optimize the constant.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/TargetLowering.h:43,optimiz,optimization,43,interpreter/llvm-project/llvm/include/llvm/CodeGen/TargetLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/TargetLowering.h,2,['optimiz'],"['optimization', 'optimize']"
Performance,// Target-specific peephole cleanups performed after instruction; // selection.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetMachine.cpp:37,perform,performed,37,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetMachine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetMachine.cpp,1,['perform'],['performed']
Performance,// Targets have to explicitly opt-in for extending vector loads and; // truncating vector stores.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:58,load,loads,58,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['load'],['loads']
Performance,// Targets have to explicitly opt-in for extending vector loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:58,load,loads,58,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['load'],['loads']
Performance,"// Targets must implement a default value for the scalable case, since; // we don't know how many lanes the vector has.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h:50,scalab,scalable,50,interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,3,['scalab'],['scalable']
Performance,"// Technically we need the write lock only for the call to ClassInfo_FullName; // and GenerateTClass but FindObject will take the read lock (and LoadClass will; // take the write lock). Since taking/releasing the lock is expensive, let just; // take the write guard and keep it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:145,Load,LoadClass,145,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,1,['Load'],['LoadClass']
Performance,"// Technically, this code could allow multiple uses of the load, and; // check if all the uses are the same extension operation, but this; // should be sufficient for most cases.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonTargetTransformInfo.cpp:59,load,load,59,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonTargetTransformInfo.cpp,1,['load'],['load']
Performance,// Tell the linker to load the plugin. This has to come before; // AddLinkerInputs as gold requires -plugin and AIX ld requires -bplugin to; // come before any -plugin-opt/-bplugin_opt that -Wl might forward.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/CommonArgs.cpp:22,load,load,22,interpreter/llvm-project/clang/lib/Driver/ToolChains/CommonArgs.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/CommonArgs.cpp,1,['load'],['load']
Performance,// Tell the user to assign it into a variable to force a volatile load if this; // isn't an array.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaStmt.cpp:66,load,load,66,interpreter/llvm-project/clang/lib/Sema/SemaStmt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaStmt.cpp,1,['load'],['load']
Performance,// Temporary RAII solution to perform a push/pop stack event on the OpenMP IR; // Builder if one is present.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp:30,perform,perform,30,interpreter/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp,1,['perform'],['perform']
Performance,// Temporary basic block live-in cache.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSchedStrategy.h:33,cache,cache,33,interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSchedStrategy.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSchedStrategy.h,1,['cache'],['cache']
Performance,// Temporary buffer to store each combination before performing Callback.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/CombinationGenerator.h:53,perform,performing,53,interpreter/llvm-project/llvm/include/llvm/ADT/CombinationGenerator.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/CombinationGenerator.h,1,['perform'],['performing']
Performance,// Temporary copies of cached variables we will be modifying and replacing if; // sinking succeeds.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSchedStrategy.cpp:23,cache,cached,23,interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSchedStrategy.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSchedStrategy.cpp,1,['cache'],['cached']
Performance,"// Temporary loads should be used in the same packet, but don't commit; // results, so it should be disregarded if another insn changes the same; // register.; // TODO: relies on the impossibility of a current and a temporary loads; // in the same packet.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/MCTargetDesc/HexagonMCChecker.cpp:13,load,loads,13,interpreter/llvm-project/llvm/lib/Target/Hexagon/MCTargetDesc/HexagonMCChecker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/MCTargetDesc/HexagonMCChecker.cpp,2,['load'],['loads']
Performance,// Temporary option added for the purpose of testing functionality added; // to DAGCombiner.cpp in D92230. It is expected that this can be removed; // in future when both implementations will be based off MGATHER rather; // than the GLD1 nodes added for the SVE gather load intrinsics.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:269,load,load,269,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['load'],['load']
Performance,"// Test RooCacheManager::selectFromSet1 and RooCacheManager::selectFromSet2.; // the cached class doesn't matter for this test, it just has to be an object that the cache is going to own",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/test/testRooCacheManager.cxx:85,cache,cached,85,roofit/roofitcore/test/testRooCacheManager.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/test/testRooCacheManager.cxx,2,['cache'],"['cache', 'cached']"
Performance,"// Test against https://github.com/root-project/root/issues/13691; // At destruction time TDirectoryFile called the destructor of; // TDirectory, thus:; // - inadvertently triggered initialization of gROOT; // - called TDirectory::RecursiveRemove which didn't check for the validity; // of the `fList` data member, which had already been deleted in the; // TDirectoryFile destructor; //; // NOTE: In order for the segfault to actually be triggered, this test needs; // to link against some library that is not in the list of globally ignored; // PCMs (gIgnoredPCMNames in TCling.cxx). The loading of a PCM is what; // actually triggers the call to TDirectory::RecursiveRemove in the end.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/test/tdirectoryfile_destructor_segfault.cxx:589,load,loading,589,hist/hist/test/tdirectoryfile_destructor_segfault.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/test/tdirectoryfile_destructor_segfault.cxx,1,['load'],['loading']
Performance,"// Test class: creates a reference solution (computing the gradient with scalar; // values in a serial scenario), and; // compares its values and its performance against the evaluation of the; // gradient specified by the GradientTestTraits; // type.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/test/testGradient.cxx:150,perform,performance,150,math/mathcore/test/testGradient.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/test/testGradient.cxx,3,['perform'],['performance']
Performance,"// Test consistancy of the hist after concurrentfill",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/histv7/test/concurrentfill.cxx:38,concurren,concurrentfill,38,hist/histv7/test/concurrentfill.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/histv7/test/concurrentfill.cxx,1,['concurren'],['concurrentfill']
Performance,"// Test if all participating instruction will be dead after the; // transformation. If intermediate results are used, no performance gain can; // be expected. Also sum the cost of the Instructions beeing left dead.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp:121,perform,performance,121,interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp,1,['perform'],['performance']
Performance,// Test if the previous node was as the same expression. This can happen; // when the expression fails to evaluate to anything meaningful and; // (as an optimization) we don't generate a node.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/ExprEngine.cpp:153,optimiz,optimization,153,interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/ExprEngine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/ExprEngine.cpp,1,['optimiz'],['optimization']
Performance,// Test if this instruction is one of our post load instructions (and; // remove it from the set if so).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:47,load,load,47,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,1,['load'],['load']
Performance,"// Test that the loop-vectorizer can legalize all operations for this MaxVF.; // FIXME: While for scalable vectors this is currently sufficient, this should; // be replaced by a more detailed mechanism that filters out specific VFs,; // instead of invalidating vectorization for a whole set of VFs based on the; // MaxVF.; // Disable scalable vectorization if the loop contains unsupported reductions.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:98,scalab,scalable,98,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,2,['scalab'],['scalable']
Performance,"// Test whether the variable has completed initialization.; //; // Itanium C++ ABI 3.3.2:; // The following is pseudo-code showing how these functions can be used:; // if (obj_guard.first_byte == 0) {; // if ( __cxa_guard_acquire (&obj_guard) ) {; // try {; // ... initialize the object ...;; // } catch (...) {; // __cxa_guard_abort (&obj_guard);; // throw;; // }; // ... queue object destructor with __cxa_atexit() ...;; // __cxa_guard_release (&obj_guard);; // }; // }; //; // If threadsafe statics are enabled, but we don't have inline atomics, just; // call __cxa_guard_acquire unconditionally. The ""inline"" check isn't; // actually inline, and the user might not expect calls to __atomic libcalls.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/ItaniumCXXABI.cpp:373,queue,queue,373,interpreter/llvm-project/clang/lib/CodeGen/ItaniumCXXABI.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/ItaniumCXXABI.cpp,1,['queue'],['queue']
Performance,// That load must be at least naturally aligned.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULateCodeGenPrepare.cpp:8,load,load,8,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULateCodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULateCodeGenPrepare.cpp,1,['load'],['load']
Performance,"// The ""LoadN"" is just a machine load instruction. The intrinsic also; // involves storing it. Generate an appropriate store to the location; // given in the intrinsic's operand(3).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp:8,Load,LoadN,8,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,2,"['Load', 'load']","['LoadN', 'load']"
Performance,"// The ""isGenreflex"" parameter allows the distinction between; // genreflex and rootcling only for the treatment of collections which; // are data members. To preserve the behaviour of the original; // genreflex and rootcling tools, if the selection is performed with; // genreflex, data members with collection type do not trigger the; // selection of the collection type",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/dictgen/src/rootcling_impl.cxx:253,perform,performed,253,core/dictgen/src/rootcling_impl.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/dictgen/src/rootcling_impl.cxx,1,['perform'],['performed']
Performance,// The 'Darwin' toolchain is initialized only when its arguments are; // computed. Get the default arguments for OFK_None to ensure that; // initialization is performed before processing the offload action.; // FIXME: Remove when darwin's toolchain is initialized during construction.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/Driver.cpp:159,perform,performed,159,interpreter/llvm-project/clang/lib/Driver/Driver.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/Driver.cpp,1,['perform'],['performed']
Performance,"// The 'nvlink' application performs RDC-mode linking when given a '.o'; // file and device linking when given a '.cubin' file. We always want to; // perform device linking, so just rename any '.o' files.; // FIXME: This should hopefully be removed if NVIDIA updates their tooling.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Cuda.cpp:28,perform,performs,28,interpreter/llvm-project/clang/lib/Driver/ToolChains/Cuda.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Cuda.cpp,2,['perform'],"['perform', 'performs']"
Performance,"// The -O1 optimization flag has nasty side effects on Windows (32 and 64 bit); // See the GitHub issues #9809 and #9944; // TODO: to be reviewed after the upgrade of LLVM & Clang",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:11,optimiz,optimization,11,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,1,['optimiz'],['optimization']
Performance,"// The -dfsan-preserve-alignment flag controls whether this pass assumes that; // alignment requirements provided by the input IR are correct. For example,; // if the input IR contains a load with alignment 8, this flag will cause; // the shadow load to have alignment 16. This flag is disabled by default as; // we have unfortunately encountered too much code (including Clang itself;; // see PR14291) which performs misaligned access.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp:187,load,load,187,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp,3,"['load', 'perform']","['load', 'performs']"
Performance,// The -fmodule-file=<name>=<file> form specifies the mapping of module; // names to precompiled module files (the module is loaded only if used).; // The -fmodule-file=<file> form can be used to unconditionally load; // precompiled module files (whether used or not).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp:125,load,loaded,125,interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp,2,['load'],"['load', 'loaded']"
Performance,// The 2 offset instructions use offset0 and offset1 instead. We can treat; // these as a load with a single offset if the 2 offsets are consecutive.; // We will use this for some partially aligned loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp:90,load,load,90,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp,2,['load'],"['load', 'loads']"
Performance,// The 2nd operand is always the post increment operand in load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVLIWPacketizer.cpp:59,load,load,59,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVLIWPacketizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVLIWPacketizer.cpp,1,['load'],['load']
Performance,"// The 4-byte load must be aligned, while a char or short may be; // anywhere in the word. Hence all this nasty bookkeeping code.; // add ptr1, ptrA, ptrB [copy if ptrA==0]; // rlwinm shift1, ptr1, 3, 27, 28 [3, 27, 27]; // xori shift, shift1, 24 [16]; // rlwinm ptr, ptr1, 0, 0, 29; // slw incr2, incr, shift; // li mask2, 255 [li mask3, 0; ori mask2, mask3, 65535]; // slw mask, mask2, shift; // loopMBB:; // lwarx tmpDest, ptr; // add tmp, tmpDest, incr2; // andc tmp2, tmpDest, mask; // and tmp3, tmp, mask; // or tmp4, tmp3, tmp2; // stwcx. tmp4, ptr; // bne- loopMBB; // fallthrough --> exitMBB; // srw SrwDest, tmpDest, shift; // rlwinm SrwDest, SrwDest, 0, 24 [16], 31",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:14,load,load,14,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['load']
Performance,"// The 4-byte load must be aligned, while a char or short may be; // anywhere in the word. Hence all this nasty bookkeeping code.; // add ptr1, ptrA, ptrB [copy if ptrA==0]; // rlwinm shift1, ptr1, 3, 27, 28 [3, 27, 27]; // xori shift, shift1, 24 [16]; // rlwinm ptr, ptr1, 0, 0, 29; // slw newval2, newval, shift; // slw oldval2, oldval,shift; // li mask2, 255 [li mask3, 0; ori mask2, mask3, 65535]; // slw mask, mask2, shift; // and newval3, newval2, mask; // and oldval3, oldval2, mask; // loop1MBB:; // lwarx tmpDest, ptr; // and tmp, tmpDest, mask; // cmpw tmp, oldval3; // bne- exitBB; // loop2MBB:; // andc tmp2, tmpDest, mask; // or tmp4, tmp2, newval3; // stwcx. tmp4, ptr; // bne- loop1MBB; // b exitBB; // exitBB:; // srw dest, tmpDest, shift",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:14,load,load,14,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['load']
Performance,"// The 440 has no SIMD support, but floating-point instructions; // have a 5-cycle latency, so unroll by 5x for latency hiding.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp:83,latency,latency,83,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,2,['latency'],['latency']
Performance,// The 8-bit and 16-bit scalar buffer load instructions have 32-bit; // destination register.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp:38,load,load,38,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,1,['load'],['load']
Performance,"// The A2 has no SIMD support, but floating-point instructions; // have a 6-cycle latency, so unroll by 6x for latency hiding.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp:82,latency,latency,82,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,2,['latency'],['latency']
Performance,"// The A2 is in-order with a deep pipeline, and concatenation unrolling; // helps expose latency-hiding opportunities to the instruction scheduler.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp:89,latency,latency-hiding,89,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,1,['latency'],['latency-hiding']
Performance,"// The ABIs that maintain a TOC pointer accross calls need to have a nop; // immediately following the call instruction if the caller and callee may; // have different TOC bases. At link time if the linker determines the calls; // may not share a TOC base, the call is redirected to a trampoline inserted; // by the linker. The trampoline will (among other things) save the callers; // TOC pointer at an ABI designated offset in the linkage area and the; // linker will rewrite the nop to be a load of the TOC pointer from the; // linkage area into gpr2.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:494,load,load,494,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['load']
Performance,"// The AddrMode enums are declared in ARMBaseInfo.h; // IndexMode - Unindex, pre-indexed, or post-indexed are valid for load; // and store ops only. Generic ""updating"" flag is used for ld/st multiple.; // The index mode enums are declared in ARMBaseInfo.h",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/MCTargetDesc/ARMBaseInfo.h:120,load,load,120,interpreter/llvm-project/llvm/lib/Target/ARM/MCTargetDesc/ARMBaseInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/MCTargetDesc/ARMBaseInfo.h,1,['load'],['load']
Performance,// The Bucket class holds the struct fields we're trying to fill to a; // cache-line.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/Randstruct.cpp:74,cache,cache-line,74,interpreter/llvm-project/clang/lib/AST/Randstruct.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/Randstruct.cpp,1,['cache'],['cache-line']
Performance,"// The C++11 standard defines the notion of a discarded-value expression;; // normally, we don't need to do anything to handle it, but if it is a; // volatile lvalue with a special form, we perform an lvalue-to-rvalue; // conversion.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp:190,perform,perform,190,interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp,1,['perform'],['perform']
Performance,"// The CMP instruction is just an alias for SUBS, and representing it as; // SUBS means that it's possible to get CSE with subtract operations.; // A later phase can perform the optimization of setting the destination; // register to WZR/XZR if it ends up being unused.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:166,perform,perform,166,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,2,"['optimiz', 'perform']","['optimization', 'perform']"
Performance,"// The CPPInstance::kNoMemReg by-passes the memory regulator; the assumption here is; // that objects in vectors are simple and thus do not need to maintain object identity; // (or at least not during the loop anyway). This gains 2x in performance.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CustomPyTypes.cxx:236,perform,performance,236,bindings/pyroot/cppyy/CPyCppyy/src/CustomPyTypes.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CustomPyTypes.cxx,1,['perform'],['performance']
Performance,// The Callback function that performs analyses:,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/AnalysisBasedWarnings.cpp:30,perform,performs,30,interpreter/llvm-project/clang/lib/Sema/AnalysisBasedWarnings.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/AnalysisBasedWarnings.cpp,1,['perform'],['performs']
Performance,"// The DAG can change (due to CSE) during selection, so cache all the; // unselected nodes first to avoid traversing a mutating DAG.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAGHVX.cpp:56,cache,cache,56,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAGHVX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAGHVX.cpp,1,['cache'],['cache']
Performance,// The DominatorTree needs to be rebuilt by any consumers after this; // transformation. We simply reset here rather than setting the ModifiedDT; // flag to avoid restarting the function walk in runOnFunction for each; // select optimized.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:229,optimiz,optimized,229,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,1,['optimiz'],['optimized']
Performance,"// The ELFFile whose ELF headers and program headers are copied into the; // output file. Normally the same as ElfFile, but if we're extracting a; // loadable partition it will point to the partition's headers.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/ELF/ELFObject.cpp:150,load,loadable,150,interpreter/llvm-project/llvm/lib/ObjCopy/ELF/ELFObject.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/ELF/ELFObject.cpp,1,['load'],['loadable']
Performance,// The Element types determine the type of cast to perform.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExprScalar.cpp:51,perform,perform,51,interpreter/llvm-project/clang/lib/CodeGen/CGExprScalar.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExprScalar.cpp,1,['perform'],['perform']
Performance,// The FixedValue should always be zero since the region handle is only; // known at load time.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/XCOFFObjectWriter.cpp:85,load,load,85,interpreter/llvm-project/llvm/lib/MC/XCOFFObjectWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/XCOFFObjectWriter.cpp,1,['load'],['load']
Performance,// The FrontendAction::BeginSourceFile () method loads the AST so that much; // of the information is already available and modules should have been; // loaded.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/FrontendActions.cpp:49,load,loads,49,interpreter/llvm-project/clang/lib/Frontend/FrontendActions.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/FrontendActions.cpp,2,['load'],"['loaded', 'loads']"
Performance,"// The GOTTPOFF relocation was not used in one of the sequences; // described in the spec, so we can't optimize it to a TPOFF; // relocation.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp:103,optimiz,optimize,103,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp,1,['optimiz'],['optimize']
Performance,"// The GP register contains the ""user"" value, so we cannot perform; // any gp relative loads until we restore the ""kernel"" or ""system"" gp; // value. Until support is written we shall only accept the static; // relocation model.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEFrameLowering.cpp:59,perform,perform,59,interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEFrameLowering.cpp,2,"['load', 'perform']","['loads', 'perform']"
Performance,// The G_PTR_ADD that's used by the store. We keep this to cache the; // MachineInstr def.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64PostLegalizerCombiner.cpp:59,cache,cache,59,interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64PostLegalizerCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64PostLegalizerCombiner.cpp,1,['cache'],['cache']
Performance,// The GenericScheduler that we use defaults to scheduling bottom up only.; // We want to schedule from both the top and the bottom and so we set; // OnlyBottomUp to false.; // We want to do bi-directional scheduling since it provides a more balanced; // schedule leading to better performance.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCSubtarget.cpp:282,perform,performance,282,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCSubtarget.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCSubtarget.cpp,1,['perform'],['performance']
Performance,// The L0 cache keeps all memory operations in order for; // work-items in the same wavefront.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMemoryLegalizer.cpp:10,cache,cache,10,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMemoryLegalizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMemoryLegalizer.cpp,2,['cache'],['cache']
Performance,// The L1 cache keeps all memory operations in order for; // wavefronts in the same work-group.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMemoryLegalizer.cpp:10,cache,cache,10,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMemoryLegalizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMemoryLegalizer.cpp,1,['cache'],['cache']
Performance,// The L1 data cache,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfo.h:15,cache,cache,15,interpreter/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfo.h,1,['cache'],['cache']
Performance,"// The L2 data cache; // We currently do not model L3 caches, as their sizes differ widely between; // microarchitectures. Also, we currently do not have a use for L3 cache; // size modeling yet.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfo.h:15,cache,cache,15,interpreter/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfo.h,3,['cache'],"['cache', 'caches']"
Performance,"// The LLVM intrinsics minnum/maxnum correspond to fmin/fmax. Canonicalize to; // the intrinsics for improved optimization (for example, vectorization).; // No-signed-zeros is implied by the definitions of fmax/fmin themselves.; // From the C standard draft WG14/N1256:; // ""Ideally, fmax would be sensitive to the sign of zero, for example; // fmax(-0.0, +0.0) would return +0; however, implementation in software; // might be impractical.""",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp:110,optimiz,optimization,110,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp,1,['optimiz'],['optimization']
Performance,"// The LR can correspond to the whole reg and its def slot is not obliged; // to be the same as the MO' def slot. E.g. when we check here ""normal""; // subreg MO but there is other EC subreg MO in the same instruction so the; // whole reg has EC def slot and differs from the currently checked MO' def; // slot. For example:; // %0 [16e,32r:0) 0@16e L..3 [16e,32r:0) 0@16e L..C [16r,32r:0) 0@16r; // Check that there is an early-clobber def of the same superregister; // somewhere is performed in visitMachineFunctionAfter()",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineVerifier.cpp:483,perform,performed,483,interpreter/llvm-project/llvm/lib/CodeGen/MachineVerifier.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineVerifier.cpp,1,['perform'],['performed']
Performance,// The LdStLimit limits how far we search for load/store pairs.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp:46,load,load,46,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp,1,['load'],['load']
Performance,"// The Linux kernel's dynamic loader doesn't support GOT relative; // relocations, but it doesn't support late binding either, so just call; // the function directly.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64AsmPrinter.cpp:30,load,loader,30,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64AsmPrinter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64AsmPrinter.cpp,1,['load'],['loader']
Performance,// The Load's Base Ptr must also match.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:7,Load,Load,7,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['Load'],['Load']
Performance,"// The Load() function reads multiple values from the pointed-to; // memory into xx. This is why we have to copy the input values from; // the x array into a zero-padded buffer to read from. Otherwise,; // Load() would access the x array out of bounds.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Fit/FitUtil.h:7,Load,Load,7,math/mathcore/inc/Fit/FitUtil.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Fit/FitUtil.h,2,['Load'],['Load']
Performance,// The LoaderUninitialized attribute acts as a definition (of undef).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp:7,Load,LoaderUninitialized,7,interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp,1,['Load'],['LoaderUninitialized']
Performance,"// The M and N constraints are a superset of K and L respectively, for use; // with the MOV (immediate) alias. As well as the logical immediates they; // also match 32 or 64-bit immediates that can be loaded either using a; // *single* MOVZ or MOVN , such as 32-bit 0x12340000, 0x00001234, 0xffffedca; // (M) or 64-bit 0x1234000000000000 (N) etc.; // As a note some of this code is liberally stolen from the asm parser.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:201,load,loaded,201,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['load'],['loaded']
Performance,// The MSVC compiler 19.37 for ARM64 has an optimization bug that; // causes an incorrect behavior with the orignal version. Work around; // by using a slightly different variation.; // https://developercommunity.visualstudio.com/t/C-ARM64-compiler-optimization-bug/10481261,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/MCTargetDesc/AArch64AddressingModes.h:44,optimiz,optimization,44,interpreter/llvm-project/llvm/lib/Target/AArch64/MCTargetDesc/AArch64AddressingModes.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/MCTargetDesc/AArch64AddressingModes.h,2,['optimiz'],"['optimization', 'optimization-bug']"
Performance,// The MachineScheduler does not currently require JoinSplitEdges. This will; // either be enabled unconditionally or replaced by a more general live range; // splitting optimization.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RegisterCoalescer.cpp:170,optimiz,optimization,170,interpreter/llvm-project/llvm/lib/CodeGen/RegisterCoalescer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RegisterCoalescer.cpp,1,['optimiz'],['optimization']
Performance,"// The ManagedStatic enables the ThreadPoolExecutor to be stopped via; // llvm_shutdown() which allows a ""clean"" fast exit, e.g. via _exit(). This; // stops the thread pool and waits for any worker thread creation to complete; // but does not wait for the threads to finish. The wait for worker thread; // creation to complete is important as it prevents intermittent crashes on; // Windows due to a race condition between thread creation and process exit.; //; // The ThreadPoolExecutor will only be destroyed when the static unique_ptr to; // it is destroyed, i.e. in a normal full exit. The ThreadPoolExecutor; // destructor ensures it has been stopped and waits for worker threads to; // finish. The wait is important as it prevents intermittent crashes on; // Windows when the process is doing a full exit.; //; // The Windows crashes appear to only occur with the MSVC static runtimes and; // are more frequent with the debug static runtime.; //; // This also prevents intermittent deadlocks on exit with the MinGW runtime.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/Parallel.cpp:400,race condition,race condition,400,interpreter/llvm-project/llvm/lib/Support/Parallel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/Parallel.cpp,1,['race condition'],['race condition']
Performance,// The MemoryManager to load objects into.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldImpl.h:24,load,load,24,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldImpl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldImpl.h,1,['load'],['load']
Performance,// The MergeICmpsPass tries to create memcmp calls by grouping sequences of; // loads and compares. ExpandMemCmpPass then tries to expand those calls; // into optimally-sized loads and compares. The transforms are enabled by a; // target lowering hook.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/CodeGenPassBuilder.h:80,load,loads,80,interpreter/llvm-project/llvm/include/llvm/CodeGen/CodeGenPassBuilder.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/CodeGenPassBuilder.h,4,['load'],['loads']
Performance,"// The Microsoft ABI requires that we perform the destructor body; // checks (i.e. operator delete() lookup) when the vtable is marked used, as; // the deleting destructor is emitted with the vtable, not with the; // destructor definition as in the Itanium ABI.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp:38,perform,perform,38,interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp,1,['perform'],['perform']
Performance,"// The ModuleManager's use of FileEntry nodes as the keys for its map of; // loaded modules is less than ideal. Uniqueness for FileEntry nodes is; // maintained by FileManager, which in turn uses inode numbers on hosts; // that support that. When coupled with the module cache's proclivity for; // turning over and deleting stale PCMs, this means entries for different; // module files can wind up reusing the same underlying inode. When this; // happens, subsequent accesses to the Modules map will disagree on the; // ModuleFile associated with a given file. In general, it is not sufficient; // to resolve this conundrum with a type like FileEntryRef that stores the; // name of the FileEntry node on first access because of path canonicalization; // issues. However, the paths constructed for implicit module builds are; // fully under Clang's control. We *can*, therefore, rely on their structure; // being consistent across operating systems and across subsequent accesses; // to the Modules map.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ModuleManager.cpp:77,load,loaded,77,interpreter/llvm-project/clang/lib/Serialization/ModuleManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ModuleManager.cpp,2,"['cache', 'load']","['cache', 'loaded']"
Performance,"// The ModuleMap maybe a nullptr, when we load a cached C++ module without; // *.modulemap file. In this case, just return an empty string.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp:42,load,load,42,interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp,2,"['cache', 'load']","['cached', 'load']"
Performance,"// The Null output is intended for use for performance analysis and testing,; // not real users.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LLVMTargetMachine.cpp:43,perform,performance,43,interpreter/llvm-project/llvm/lib/CodeGen/LLVMTargetMachine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LLVMTargetMachine.cpp,1,['perform'],['performance']
Performance,// The OptimizationList is automatically populated with registered Passes by the; // PassNameParser.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/opt/opt.cpp:7,Optimiz,OptimizationList,7,interpreter/llvm-project/llvm/tools/opt/opt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/opt/opt.cpp,1,['Optimiz'],['OptimizationList']
Performance,// The PPC MMA builtins take a pointer to a __vector_quad as an argument.; // Some of the MMA instructions accumulate their result into an existing; // accumulator whereas the others generate a new accumulator. So we need to; // use custom code generation to expand a builtin call with a pointer to a; // load (if the corresponding instruction accumulates its result) followed by; // the call to the intrinsic and a store of the result.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:305,load,load,305,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,1,['load'],['load']
Performance,// The PREFETCHW instruction was added with 3DNow but later CPUs gave it; // its own CPUID bit as part of deprecating 3DNow. Intel eventually added; // it and KNL has another that prefetches to L2 cache. We assume the; // L1 version exists if the L2 version does.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h:197,cache,cache,197,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h,1,['cache'],['cache']
Performance,"// The PiecewiseInterpolation class is used in the context of HistFactory; // models, where is is always used the same way: all RooAbsReals in _lowSet,; // _histSet, and also nominal are 1D RooHistFuncs with with same structure.; //; // Therefore, we can make a big optimization: we get the bin index only once; // here in the generated code for PiecewiseInterpolation. Then, we also; // rearrange the histogram data in such a way that we can always pass the; // same arrays to the free function that implements the interpolation, just; // with a dynamic offset calculated from the bin index.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/histfactory/src/PiecewiseInterpolation.cxx:266,optimiz,optimization,266,roofit/histfactory/src/PiecewiseInterpolation.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/histfactory/src/PiecewiseInterpolation.cxx,1,['optimiz'],['optimization']
Performance,"// The ProducerOpIsMemIndex logic checks for the index of the producer; // register operand. Z-reg load instructions have an implicit operand; // that's not encoded, so the producer won't appear as the 1-th def, it; // will be at the 0-th.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/MCTargetDesc/HexagonMCChecker.cpp:99,load,load,99,interpreter/llvm-project/llvm/lib/Target/Hexagon/MCTargetDesc/HexagonMCChecker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/MCTargetDesc/HexagonMCChecker.cpp,1,['load'],['load']
Performance,// The RPC client symbol is defined in `libc` and indicates that something; // required an RPC server. If its users were all optimized out then we can; // safely remove it.; // TODO: This should be somewhere more common in the future.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp:125,optimiz,optimized,125,interpreter/llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp,1,['optimiz'],['optimized']
Performance,"// The Reader is the module that creates the logical view using the debug; // information contained in the binary file specified in the command line.; // This is the main entry point for the Reader and performs the following; // steps:; // - Process any patterns collected from the '--select' options.; // - For each compile unit in the debug information:; // * Create the logical elements (scopes, symbols, types, lines).; // * Collect debug ranges and debug locations.; // * Move the collected logical lines to their associated scopes.; // - Once all the compile units have been processed, traverse the scopes; // tree in order to:; // * Calculate symbol coverage.; // * Detect invalid ranges and locations.; // * ""resolve"" the logical elements. During this pass, the names and; // file information are updated, to reflect any dependency with other; // logical elements.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DebugInfo/LogicalView/Core/LVReader.cpp:202,perform,performs,202,interpreter/llvm-project/llvm/lib/DebugInfo/LogicalView/Core/LVReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DebugInfo/LogicalView/Core/LVReader.cpp,1,['perform'],['performs']
Performance,"// The Reg operand should be a virtual register, which is defined; // outside the current basic block. DAG combiner has done a pretty; // good job in removing truncating inside a single basic block except; // when the Reg operand comes from bpf_load_[byte | half | word] for; // which the generic optimizer doesn't understand their results are; // zero extended.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFISelDAGToDAG.cpp:297,optimiz,optimizer,297,interpreter/llvm-project/llvm/lib/Target/BPF/BPFISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFISelDAGToDAG.cpp,1,['optimiz'],['optimizer']
Performance,"// The SCC may get split while we are optimizing functions due to deleting; // edges. If this happens, the current SCC can shift, so keep track of; // a pointer we can overwrite.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CGSCCPassManager.cpp:38,optimiz,optimizing,38,interpreter/llvm-project/llvm/lib/Analysis/CGSCCPassManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CGSCCPassManager.cpp,1,['optimiz'],['optimizing']
Performance,"// The SCCP optimization tends to produce code like this:; // switch(x) { case 42: phi(42, ...) }; // Materializing the constant for the phi-argument needs instructions; So we; // change the code to:; // switch(x) { case 42: phi(x, ...) }",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:12,optimiz,optimization,12,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,1,['optimiz'],['optimization']
Performance,// The SHR/AND sequence should get optimized to an RISBG.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp:35,optimiz,optimized,35,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp,1,['optimiz'],['optimized']
Performance,"// The SIGSTOP test failed spuriously on CI at some point. We suspected this was due to some; // improbable race condition caused in some place where SIGSTOP/SIGCONT crashes a process.; // To find this crash, we bombard the processes with signals in this test.; // We were not able to trigger the crash, so we disabled the test, but leave it in for when; // the spurious test resurfaces.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/test/test_Messenger.cxx:108,race condition,race condition,108,roofit/multiprocess/test/test_Messenger.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/test/test_Messenger.cxx,1,['race condition'],['race condition']
Performance,"// The Sections list may contain sections that weren't loaded for; // whatever reason: they may be debug sections, and ProcessAllSections; // is false, or they may be sections that contain 0 bytes. If the; // section isn't loaded, the load address will be 0, and it should not; // be included in the ImageBase calculation.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldCOFFAArch64.h:55,load,loaded,55,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldCOFFAArch64.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldCOFFAArch64.h,6,['load'],"['load', 'loaded']"
Performance,// The ShAmt variable is used to indicate that we've consumed a right; // shift. I.e. we want to narrow the width of the load by skipping to load the; // ShAmt least significant bits.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:121,load,load,121,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,['load'],['load']
Performance,"// The Stride Value, if we're looking at a strided load/store.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Instrumentation/AddressSanitizerCommon.h:51,load,load,51,interpreter/llvm-project/llvm/include/llvm/Transforms/Instrumentation/AddressSanitizerCommon.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Instrumentation/AddressSanitizerCommon.h,1,['load'],['load']
Performance,"// The Z() component is the viewport depth value - for a default; // depth range this is 0.0 (at near clip plane) to 1.0 (at far clip; // plane). Without Z() the viewport position corresponds to a line; // in 3D world space - see:; // TGLLine3 TGLCamera::ViewportToWorld(Double_t viewportX, Double_t viewportY) const; //; // See also OpenGL gluUnProject & glDepth documentation.; //; // Camera must have valid frustum cache - call Apply() after last; // modification, before using.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/src/TGLCamera.cxx:418,cache,cache,418,graf3d/gl/src/TGLCamera.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/src/TGLCamera.cxx,1,['cache'],['cache']
Performance,"// The `Typeid<T>::Id` static data member below is a globally unique; // identifier for the type `T`. It is explicitly marked with default; // visibility so that when `-fvisibility=hidden` is used, the loader still; // merges duplicate definitions across DSO boundaries.; // We also cannot mark it as `const`, otherwise msvc merges all definitions; // when lto is enabled, making any comparison return true.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/Any.h:202,load,loader,202,interpreter/llvm-project/llvm/include/llvm/ADT/Any.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/Any.h,1,['load'],['loader']
Performance,"// The above message send needs these objects, but in ARC they are; // passed in a buffer that is essentially __unsafe_unretained.; // Therefore we must prevent the optimizer from releasing them until; // after the call.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp:165,optimiz,optimizer,165,interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp,1,['optimiz'],['optimizer']
Performance,"// The actions to be performed on the Remote Reduce list is dependent; // on the algorithm version.; //; // if (AlgoVer==0) || (AlgoVer==1 && (LaneId < Offset)) || (AlgoVer==2 &&; // LaneId % 2 == 0 && Offset > 0):; // do the reduction value aggregation; //; // The thread local variable Reduce list is mutated in place to host the; // reduced data, which is the aggregated value produced from local and; // remote lanes.; //; // Note that AlgoVer is expected to be a constant integer known at compile; // time.; // When AlgoVer==0, the first conjunction evaluates to true, making; // the entire predicate true during compile time.; // When AlgoVer==1, the second conjunction has only the second part to be; // evaluated during runtime. Other conjunctions evaluates to false; // during compile time.; // When AlgoVer==2, the third conjunction has only the second part to be; // evaluated during runtime. Other conjunctions evaluates to false; // during compile time.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGOpenMPRuntimeGPU.cpp:21,perform,performed,21,interpreter/llvm-project/clang/lib/CodeGen/CGOpenMPRuntimeGPU.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGOpenMPRuntimeGPU.cpp,1,['perform'],['performed']
Performance,"// The active lane intrinsic has this form:; //; // @llvm.get.active.lane.mask(IV, TC); //; // Here we perform checks that this intrinsic behaves as expected,; // which means:; //; // 1) Check that the TripCount (TC) belongs to this loop (originally).; // 2) The element count (TC) needs to be sufficiently large that the decrement; // of element counter doesn't overflow, which means that we need to prove:; // ceil(ElementCount / VectorWidth) >= TripCount; // by rounding up ElementCount up:; // ((ElementCount + (VectorWidth - 1)) / VectorWidth; // and evaluate if expression isKnownNonNegative:; // (((ElementCount + (VectorWidth - 1)) / VectorWidth) - TripCount; // 3) The IV must be an induction phi with an increment equal to the; // vector width.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/MVETailPredication.cpp:103,perform,perform,103,interpreter/llvm-project/llvm/lib/Target/ARM/MVETailPredication.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/MVETailPredication.cpp,1,['perform'],['perform']
Performance,"// The actual base register (BP) is typically shared between many; // instructions where frame indices are being replaced. In scalar; // instructions the offset range is large, and the need for an extra; // add instruction is infrequent. Vector loads/stores, however, have; // a much smaller offset range: [-8, 7), or #s4. In those cases it; // makes sense to ""standardize"" the immediate in the ""addi"" instruction; // so that multiple loads/stores could be based on it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonRegisterInfo.cpp:245,load,loads,245,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonRegisterInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonRegisterInfo.cpp,2,['load'],['loads']
Performance,// The actual cache entries.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterferenceCache.h:14,cache,cache,14,interpreter/llvm-project/llvm/lib/CodeGen/InterferenceCache.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterferenceCache.h,1,['cache'],['cache']
Performance,"// The actual information about the decl may have been loaded via an; // external source that created a new AST node/decl for the definition; // rather than reusing the one we had (DC) like the ASTReader does.; // To avoid the caller to continue using the still incomplete decl, let's; // set it to the definition.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaCXXScopeSpec.cpp:55,load,loaded,55,interpreter/llvm-project/clang/lib/Sema/SemaCXXScopeSpec.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaCXXScopeSpec.cpp,1,['load'],['loaded']
Performance,"// The actual servers for a given normalization set depend on whether the; // cache is rearranged or not. See RooProdPdf::calculateBatch to see; // which args in the cache are used directly.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooProdPdf.cxx:78,cache,cache,78,roofit/roofitcore/src/RooProdPdf.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooProdPdf.cxx,2,['cache'],['cache']
Performance,// The actual update starts here. We look at all allocations and depending on; // their status perform the appropriate check(s).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/AttributorAttributes.cpp:95,perform,perform,95,interpreter/llvm-project/llvm/lib/Transforms/IPO/AttributorAttributes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/AttributorAttributes.cpp,1,['perform'],['perform']
Performance,// The actual work is performed by LoadEliminationForLoop.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp:22,perform,performed,22,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp,2,"['Load', 'perform']","['LoadEliminationForLoop', 'performed']"
Performance,// The address being loaded in this non-local block may not be the same as; // the pointer operand of the load if PHI translation occurs. Make sure; // to consider the right address.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp:21,load,loaded,21,interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,2,['load'],"['load', 'loaded']"
Performance,"// The address field is 0000 (not used) and the byte count is always 04.; // The four data bytes represent a 32-bit address value. In the case of; // 80386 and higher CPUs, this address is loaded into the EIP register.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/ELF/ELFObject.h:189,load,loaded,189,interpreter/llvm-project/llvm/lib/ObjCopy/ELF/ELFObject.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/ELF/ELFObject.h,1,['load'],['loaded']
Performance,"// The address passed to operator() will be the address of the start of the; // object. Overload this routine, if your derived class can optimize; // the handling of the onfileClass (rather than storing and restoring from the; // fOnFileClass member.; // Note we can not name this routine 'operator' has it would be slightly; // backward incompatible and lead to the following warning/error from the; // compiler in the derived class overloading the other operator():; // include/TClassStreamer.h:51: error: ‘virtual void TClassStreamer::operator()(TBuffer&, void*, const TClass*)’ was hidden; // include/TCollectionProxyFactory.h:180: error: by ‘virtual void TCollectionClassStreamer::operator()(TBuffer&, void*)’; // cc1plus: warnings being treated as errors",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TClassStreamer.h:137,optimiz,optimize,137,core/meta/inc/TClassStreamer.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TClassStreamer.h,1,['optimiz'],['optimize']
Performance,// The address that the snippet should be loaded in at if the execution mode; // being used supports it.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/BenchmarkResult.h:42,load,loaded,42,interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/BenchmarkResult.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/BenchmarkResult.h,1,['load'],['loaded']
Performance,// The addressing modes for loads and stores.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.h:28,load,loads,28,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.h,1,['load'],['loads']
Performance,"// The aggregate ops. Aggregates can either be in the heap or on the; // stack, but in either case, this is simply a field load. As a result,; // this is a defining definition of the base just like a load is.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp:123,load,load,123,interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,2,['load'],['load']
Performance,"// The algorithm to split up a load of a scalable vector into individual; // elements currently requires knowing the length of the loaded type,; // so will need adjusting to work on scalable vectors.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:31,load,load,31,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,4,"['load', 'scalab']","['load', 'loaded', 'scalable']"
Performance,"// The aligned loads/stores will use blocks that are either scalars,; // or HVX vectors. Let ""sector"" be the unified term for such a block.; // blend(scalar, vector) -> sector...",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp:15,load,loads,15,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp,1,['load'],['loads']
Performance,"// The alignment could be greater than the minimum at run-time, so we cannot; // infer much about the resulting pointer value. One case is possible:; // For `_Alignas(32) char buf[N]; __builtin_align_down(&buf[idx], 32)` we; // can infer the correct index if the requested alignment is smaller than; // the base alignment so we can perform the computation on the offset.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ExprConstant.cpp:332,perform,perform,332,interpreter/llvm-project/clang/lib/AST/ExprConstant.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ExprConstant.cpp,1,['perform'],['perform']
Performance,// The alignment of a pointer is interesting for loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/Attributor.cpp:49,load,loads,49,interpreter/llvm-project/llvm/lib/Transforms/IPO/Attributor.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/Attributor.cpp,1,['load'],['loads']
Performance,"// The amdgcn_make_buffer_rsrc function does not alter the address of the; // input pointer (and thus preserve null-ness for the purposes of escape; // analysis, which is where the MustPreserveNullness flag comes in to play).; // However, it will not necessarily map ptr addrspace(N) null to ptr; // addrspace(8) null, aka the ""null descriptor"", which has ""all loads return; // 0, all stores are dropped"" semantics. Given the context of this intrinsic; // list, no one should be relying on such a strict interpretation of; // MustPreserveNullness (and, at time of writing, they are not), but we; // document this fact out of an abundance of caution.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ValueTracking.cpp:361,load,loads,361,interpreter/llvm-project/llvm/lib/Analysis/ValueTracking.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ValueTracking.cpp,1,['load'],['loads']
Performance,// The analysis currently has scalability issues for very large CFGs.; // Bail out if it looks too large.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/LiveVariables.cpp:30,scalab,scalability,30,interpreter/llvm-project/clang/lib/Analysis/LiveVariables.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/LiveVariables.cpp,1,['scalab'],['scalability']
Performance,"// The analysis will generate location definitions for all variables, but we; // only need to perform a dataflow on the set of variables which have a stack; // slot. Find those now.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AssignmentTrackingAnalysis.cpp:94,perform,perform,94,interpreter/llvm-project/llvm/lib/CodeGen/AssignmentTrackingAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AssignmentTrackingAnalysis.cpp,1,['perform'],['perform']
Performance,"// The analyzer may stop exploring if it sees a state it has previously; // visited (""cache out""). The early return here is a defensive check to; // prevent accidental caching out by checker API clients. Unless there is a; // tag or the client checker has requested that the generated node be; // marked as a sink, we assume that a client requesting a transition to a; // state that is the same as the predecessor state has made a mistake. We; // return the predecessor rather than cache out.; //; // TODO: We could potentially change the return to an assertion to alert; // clients to their mistake, but several checkers (including; // DereferenceChecker, CallAndMessageChecker, and DynamicTypePropagation); // rely upon the defensive behavior and would need to be updated.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/StaticAnalyzer/Core/PathSensitive/CheckerContext.h:86,cache,cache,86,interpreter/llvm-project/clang/include/clang/StaticAnalyzer/Core/PathSensitive/CheckerContext.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/StaticAnalyzer/Core/PathSensitive/CheckerContext.h,2,['cache'],['cache']
Performance,"// The architecture doesn't allow three dependent instructions in the same; // packet. So, if the destination has a zero latency successor, then it's; // not a candidate for a zero latency predecessor.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonSubtarget.cpp:121,latency,latency,121,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonSubtarget.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonSubtarget.cpp,2,['latency'],['latency']
Performance,"// The argument is a reference, so load from it to get the boolean value.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/GTestChecker.cpp:35,load,load,35,interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/GTestChecker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/GTestChecker.cpp,1,['load'],['load']
Performance,"// The arguments used to set Optimize, OptimizeSize and NoInlineDefine are; // generated from CodeGenOptions.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInvocation.cpp:29,Optimiz,Optimize,29,interpreter/llvm-project/clang/lib/Frontend/CompilerInvocation.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInvocation.cpp,2,['Optimiz'],"['Optimize', 'OptimizeSize']"
Performance,"// The arrangement methods are split into three families:; // - those meant to drive the signature and prologue/epilogue; // of a function declaration or definition,; // - those meant for the computation of the LLVM type for an abstract; // appearance of a function, and; // - those meant for performing the IR-generation of a call.; // They differ mainly in how they deal with optional (i.e. variadic); // arguments, as well as unprototyped functions.; //; // Key points:; // - The CGFunctionInfo for emitting a specific call site must include; // entries for the optional arguments.; // - The function type used at the call site must reflect the formal; // signature of the declaration being called, or else the call will; // go awry.; // - For the most part, unprototyped functions are called by casting to; // a formal signature inferred from the specific argument types used; // at the call-site. However, some targets (e.g. x86-64) screw with; // this for compatibility reasons.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenTypes.h:293,perform,performing,293,interpreter/llvm-project/clang/lib/CodeGen/CodeGenTypes.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenTypes.h,1,['perform'],['performing']
Performance,"// The artifact was not found in the local cache, query the debuginfod; // servers.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Debuginfod/Debuginfod.cpp:43,cache,cache,43,interpreter/llvm-project/llvm/lib/Debuginfod/Debuginfod.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Debuginfod/Debuginfod.cpp,1,['cache'],['cache']
Performance,"// The atomic instruction is marked volatile for consistency with MSVC. This; // blocks the few atomics optimizations that LLVM has. If we want to optimize; // _Interlocked* operations in the future, we will have to remove the volatile; // marker.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:104,optimiz,optimizations,104,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,4,['optimiz'],"['optimizations', 'optimize']"
Performance,// The backend has peephole optimizations for powers of two.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandLargeDivRem.cpp:28,optimiz,optimizations,28,interpreter/llvm-project/llvm/lib/CodeGen/ExpandLargeDivRem.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandLargeDivRem.cpp,1,['optimiz'],['optimizations']
Performance,// The base address of the load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:27,load,load,27,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,2,['load'],['load']
Performance,"// The base case handles scalable vectors fine for now, since it treats the; // cost as 1 * legalization cost.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp:25,scalab,scalable,25,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,1,['scalab'],['scalable']
Performance,"// The base pointer is passed by address, so it needs to be loaded.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:60,load,loaded,60,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,1,['load'],['loaded']
Performance,"// The basic MD5 functions.; // F and G are optimized compared to their RFC 1321 definitions for; // architectures that lack an AND-NOT instruction, just like in Colin Plumb's; // implementation.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/MD5.cpp:44,optimiz,optimized,44,interpreter/llvm-project/llvm/lib/Support/MD5.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/MD5.cpp,1,['optimiz'],['optimized']
Performance,"// The basic MVE VLDR on a v2i1/v4i1/v8i1 actually loads the entire 16bit; // predicate, with the ""v4i1"" bits spread out over the 16 bits loaded. We; // need to make sure that 8/4/2 bits are actually loaded into the correct; // place, which means loading the value and then shuffling the values into; // the bottom bits of the predicate.; // Equally, VLDR for an v16i1 will actually load 32bits (so will be incorrect; // for BE).; // Speaking of BE, apparently the rest of llvm will assume a reverse order to; // a natural VMSR(load), so needs to be reversed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:51,load,loads,51,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,6,['load'],"['load', 'loaded', 'loading', 'loads']"
Performance,"// The basic algorithm can be found in the compiler-rt project's; // implementation of __udivsi3.c. Here, we do a lower-level IR based approach; // that's been hand-tuned to lessen the amount of control flow involved.; // Some helper values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/IntegerDivision.cpp:165,tune,tuned,165,interpreter/llvm-project/llvm/lib/Transforms/Utils/IntegerDivision.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/IntegerDivision.cpp,1,['tune'],['tuned']
Performance,"// The basic idea here is that we're expanding a cmpxchg of a; // smaller memory size up to a word-sized cmpxchg. To do this, we; // need to add a retry-loop for strong cmpxchg, so that; // modifications to other parts of the word don't cause a spurious; // failure.; // This generates code like the following:; // [[Setup mask values PMV.*]]; // %NewVal_Shifted = shl i32 %NewVal, %PMV.ShiftAmt; // %Cmp_Shifted = shl i32 %Cmp, %PMV.ShiftAmt; // %InitLoaded = load i32* %addr; // %InitLoaded_MaskOut = and i32 %InitLoaded, %PMV.Inv_Mask; // br partword.cmpxchg.loop; // partword.cmpxchg.loop:; // %Loaded_MaskOut = phi i32 [ %InitLoaded_MaskOut, %entry ],; // [ %OldVal_MaskOut, %partword.cmpxchg.failure ]; // %FullWord_NewVal = or i32 %Loaded_MaskOut, %NewVal_Shifted; // %FullWord_Cmp = or i32 %Loaded_MaskOut, %Cmp_Shifted; // %NewCI = cmpxchg i32* %PMV.AlignedAddr, i32 %FullWord_Cmp,; // i32 %FullWord_NewVal success_ordering failure_ordering; // %OldVal = extractvalue { i32, i1 } %NewCI, 0; // %Success = extractvalue { i32, i1 } %NewCI, 1; // br i1 %Success, label %partword.cmpxchg.end,; // label %partword.cmpxchg.failure; // partword.cmpxchg.failure:; // %OldVal_MaskOut = and i32 %OldVal, %PMV.Inv_Mask; // %ShouldContinue = icmp ne i32 %Loaded_MaskOut, %OldVal_MaskOut; // br i1 %ShouldContinue, label %partword.cmpxchg.loop,; // label %partword.cmpxchg.end; // partword.cmpxchg.end:; // %tmp1 = lshr i32 %OldVal, %PMV.ShiftAmt; // %FinalOldVal = trunc i32 %tmp1 to i8; // %tmp2 = insertvalue { i8, i1 } undef, i8 %FinalOldVal, 0; // %Res = insertvalue { i8, i1 } %25, i1 %Success, 1",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp:461,load,load,461,interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp,1,['load'],['load']
Performance,// The below are shared state needed when performing accumulator recursion.; // There values should be populated by insertAccumulator the first time we; // find an elimination that requires an accumulator.; // PHI node to store our current accumulated value.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/TailRecursionElimination.cpp:42,perform,performing,42,interpreter/llvm-project/llvm/lib/Transforms/Scalar/TailRecursionElimination.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/TailRecursionElimination.cpp,1,['perform'],['performing']
Performance,"// The below are utility functions. Other than creation of accesses to pass; // to insertDef, and removeAccess to remove accesses, you should generally; // not attempt to update memoryssa yourself. It is very non-trivial to get; // the edge cases right, and the above calls already operate in near-optimal; // time bounds.; /// Create a MemoryAccess in MemorySSA at a specified point in a block.; ///; /// When used by itself, this method will only insert the new MemoryAccess; /// into the access list, but not make any other changes, such as inserting; /// MemoryPHI nodes, or updating users to point to the new MemoryAccess. You; /// must specify a correct Definition in this case.; ///; /// Usually, this API is instead combined with insertUse() or insertDef(),; /// which will perform all the necessary MSSA updates. If these APIs are used,; /// then nullptr can be used as Definition, as the correct defining access; /// will be automatically determined.; ///; /// Note: If a MemoryAccess already exists for I, this function will make it; /// inaccessible and it *must* have removeMemoryAccess called on it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/MemorySSAUpdater.h:782,perform,perform,782,interpreter/llvm-project/llvm/include/llvm/Analysis/MemorySSAUpdater.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/MemorySSAUpdater.h,1,['perform'],['perform']
Performance,"// The below check is quadratic. Check we're not going to do too many tests.; // FIXME: Even though this will always have worst-case quadratic time, we; // could put effort into minimizing the average time by putting stores that; // have been shown to dominate at least one load at the beginning of the; // Stores array, making subsequent dominance checks more likely to succeed; // early.; //; // The threshold here is fairly large because global->local demotion is a; // very powerful optimization should it fire.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp:274,load,load,274,interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,2,"['load', 'optimiz']","['load', 'optimization']"
Performance,// The below optimizations narrow the load so they are only valid for little; // endian.; // TODO: Support big endian by adding an offset into the frame object?,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVInstrInfo.cpp:13,optimiz,optimizations,13,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVInstrInfo.cpp,2,"['load', 'optimiz']","['load', 'optimizations']"
Performance,// The below optimizations require a constant RHS.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:13,optimiz,optimizations,13,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,2,['optimiz'],['optimizations']
Performance,"// The bitmap is a series of skip/scan instructions, aligned to word; // boundaries. The skip is performed first.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp:97,perform,performed,97,interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp,1,['perform'],['performed']
Performance,"// The block must end in a return statement or unreachable.; //; // FIXME: Decline tailcall if it's not guaranteed and if the block ends in; // an unreachable, for now. The way tailcall optimization is currently; // implemented means it will add an epilogue followed by a jump. That is; // not profitable. Also, if the callee is a special function (e.g.; // longjmp on x86), it can end up causing miscompilation that has not; // been fully understood.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/Analysis.cpp:186,optimiz,optimization,186,interpreter/llvm-project/llvm/lib/CodeGen/Analysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/Analysis.cpp,1,['optimiz'],['optimization']
Performance,// The block reciprocal throughput is computed as the MAX of:; // - (NumMicroOps / DispatchWidth); // - (NumUnits / ReleaseAtCycles) for every consumed processor resource.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MCA/Support.cpp:24,throughput,throughput,24,interpreter/llvm-project/llvm/lib/MCA/Support.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MCA/Support.cpp,1,['throughput'],['throughput']
Performance,"// The block throughput is also limited by the amount of hardware parallelism.; // The number of available resource units affects the resource pressure; // distribution, as well as how many blocks can be executed every cycle.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MCA/Support.cpp:13,throughput,throughput,13,interpreter/llvm-project/llvm/lib/MCA/Support.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MCA/Support.cpp,1,['throughput'],['throughput']
Performance,// The block throughput is bounded from above by the hardware dispatch; // throughput. That is because the DispatchWidth is an upper bound on the; // number of opcodes that can be part of a single dispatch group.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MCA/Support.cpp:13,throughput,throughput,13,interpreter/llvm-project/llvm/lib/MCA/Support.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MCA/Support.cpp,2,['throughput'],['throughput']
Performance,"// The bool indicates whether there might be reads outside the set, in which; // case only loads may be promoted.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp:91,load,loads,91,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp,1,['load'],['loads']
Performance,"// The bounds of a scalable store are not known until runtime, so this; // store cannot be elided.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:19,scalab,scalable,19,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['scalab'],['scalable']
Performance,"// The buffer is, at minimum, in the file cache. We must know its index in the requests list; // In order to get its info",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCacheUnzip.cxx:42,cache,cache,42,tree/tree/src/TTreeCacheUnzip.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCacheUnzip.cxx,1,['cache'],['cache']
Performance,"// The building compiler does not have __(de)register_frame but; // it may be found at runtime in a dynamically-loaded library.; // For example, this happens when building LLVM with Visual C++; // but using the MingW runtime.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/TargetProcess/RegisterEHFrames.cpp:112,load,loaded,112,interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/TargetProcess/RegisterEHFrames.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/TargetProcess/RegisterEHFrames.cpp,2,['load'],['loaded']
Performance,// The cache is cleared (in the above line) so we will have lost; // information about blocks we have already visited. We therefore must; // assume that the cache information is incomplete.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp:7,cache,cache,7,interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,4,['cache'],['cache']
Performance,// The cache is not valid for any specific block anymore.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp:7,cache,cache,7,interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,1,['cache'],['cache']
Performance,"// The cache object",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooProdPdf.h:7,cache,cache,7,roofit/roofitcore/inc/RooProdPdf.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooProdPdf.h,1,['cache'],['cache']
Performance,"// The caching layer sits on top of all the other lexers, so it's incorrect; // to cache tokens while inside a nested lex action. The cached tokens would; // be retained after returning to the enclosing lex action and, at best,; // would appear at the wrong position in the token stream.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/PPCaching.cpp:83,cache,cache,83,interpreter/llvm-project/clang/lib/Lex/PPCaching.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/PPCaching.cpp,2,['cache'],"['cache', 'cached']"
Performance,"// The call to FindSpecialObject might induces any kind of use; // of the interpreter ... (library loading, function calling, etc.); // ... and we _know_ we are in the middle of parsing, so let's make; // sure to save the state and then restore it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:99,load,loading,99,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,1,['load'],['loading']
Performance,"// The call to TChain::BuildIndex does much more than just copying; // the indices that may have been already present in the trees of the; // chain. Notably, it calls `LoadTree` for every tree in the chain; // making sure that all branches, indices and relationships are; // properly set. In order to avoid unexpected behaviours, we always; // let the task-local friend chain rebuild its index.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/InternalTreeUtils.cxx:168,Load,LoadTree,168,tree/tree/src/InternalTreeUtils.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/InternalTreeUtils.cxx,1,['Load'],['LoadTree']
Performance,"// The call to visitNonBranch could propagate the changes until a branch; // is actually visited. This could result in adding CFG edges to the flow; // queue. Since the queue won't be processed, clear it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/BitTracker.cpp:152,queue,queue,152,interpreter/llvm-project/llvm/lib/Target/Hexagon/BitTracker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/BitTracker.cpp,2,['queue'],['queue']
Performance,"// The callback is used to clear the autoparsing caches.; //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TClingCallbacks.cxx:49,cache,caches,49,core/metacling/src/TClingCallbacks.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TClingCallbacks.cxx,2,['cache'],['caches']
Performance,// The callee saved info is valid so it can be traversed.; // Checking for registers that need saving that do not have load or store; // forms where the address offset is an immediate.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCRegisterInfo.cpp:119,load,load,119,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCRegisterInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCRegisterInfo.cpp,1,['load'],['load']
Performance,// The caller is responsible for loading the full value if the argument is; // passed with CCValAssign::Indirect.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/LoongArch/LoongArchISelLowering.cpp:33,load,loading,33,interpreter/llvm-project/llvm/lib/Target/LoongArch/LoongArchISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/LoongArch/LoongArchISelLowering.cpp,3,['load'],['loading']
Performance,"// The check on hasMetadataOtherThanDebugLoc is to prevent us from burning; // time in isGuaranteedToExecute if we don't actually have anything to; // drop. It is a compile time optimization, not required for correctness.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp:178,optimiz,optimization,178,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp,1,['optimiz'],['optimization']
Performance,// The checks are likely to be turned on by default and it is possible to do; // them without tracking any nullability related information. As an optimization; // no nullability information will be tracked when only these two checks are; // enables.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/NullabilityChecker.cpp:146,optimiz,optimization,146,interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/NullabilityChecker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/NullabilityChecker.cpp,1,['optimiz'],['optimization']
Performance,"// The choice to exclude all things constant here is slightly subtle.; // There are two independent reasons:; // - We assume that things which are constant (from LLVM's definition); // do not move at runtime. For example, the address of a global; // variable is fixed, even though it's contents may not be.; // - Second, we can't disallow arbitrary inttoptr constants even; // if the language frontend does. Optimization passes are free to; // locally exploit facts without respect to global reachability. This; // can create sections of code which are dynamically unreachable and; // contain just about anything. (see constants.ll in tests)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp:408,Optimiz,Optimization,408,interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,1,['Optimiz'],['Optimization']
Performance,"// The class has a TClass proper bootstrap coming from a run; // through rootcling/genreflex/TMetaUtils and the library; // containing this dictionary has been loaded in memory.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TClass.h:160,load,loaded,160,core/meta/inc/TClass.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TClass.h,1,['load'],['loaded']
Performance,"// The class is not loaded, hence it is 'emulated' and the main source of; // information is the StreamerInfo.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:20,load,loaded,20,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,1,['load'],['loaded']
Performance,"// The client may be running the old pass manager, in which case, we need to; // map the requested Analysis to its equivalent wrapper in the old pass; // manager. The scheme implemented here does not require every Analysis to be; // updated. Only those new analyses that the client cares about in the old; // pass manager need to expose a LegacyWrapper type, and that wrapper should; // support a getResult() method that matches the new Analysis.; //; // We need SFINAE to check for the LegacyWrapper, but function templates don't; // allow partial specialization, which is needed in this case. So instead, we; // use a constexpr bool to perform the SFINAE, and then use this information; // inside the function template.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/IPO/Attributor.h:638,perform,perform,638,interpreter/llvm-project/llvm/include/llvm/Transforms/IPO/Attributor.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/IPO/Attributor.h,1,['perform'],['perform']
Performance,"// The cmpxchg return value is the only place we need more than one; // contained type ID, however the second one will always be the same (i1),; // so we don't need to include it in the cache key. This asserts that the; // contained types are indeed as expected and there are no collisions.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Reader/BitcodeReader.cpp:186,cache,cache,186,interpreter/llvm-project/llvm/lib/Bitcode/Reader/BitcodeReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Reader/BitcodeReader.cpp,1,['cache'],['cache']
Performance,"// The code below assumes shifting a value by <number of bits>,; // whereas scalable vectors would have to be shifted by; // <2log(vscale) + number of bits> in order to store the; // low/high parts. Bailing out for now.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:76,scalab,scalable,76,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,1,['scalab'],['scalable']
Performance,"// The code below generates two loads, both aligned as NeedAlign, and; // with the distance of NeedAlign between them. For that to cover the; // bits that need to be loaded (and without overlapping), the size of; // the loads should be equal to NeedAlign. This is true for all loadable; // types, but add an assertion in case something changes in the future.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelLowering.cpp:32,load,loads,32,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelLowering.cpp,4,['load'],"['loadable', 'loaded', 'loads']"
Performance,"// The code below optimizes (or (and X, Y), Z).; // The AND operand needs to have a single user to make these optimizations; // profitable.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:18,optimiz,optimizes,18,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,2,['optimiz'],"['optimizations', 'optimizes']"
Performance,"// The code in this block deals with the following 2 equivalences:; // select(C0|C1, x, y) <=> select(C0, x, select(C1, x, y)); // select(C0&C1, x, y) <=> select(C0, select(C1, x, y), y); // The target can specify its preferred form with the; // shouldNormalizeToSelectSequence() callback. However we always transform; // to the right anyway if we find the inner select exists in the DAG anyway; // and we always transform to the left side if we know that we can further; // optimize the combination of the conditions.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:475,optimiz,optimize,475,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['optimiz'],['optimize']
Performance,"// The code transformation here is a modified version of the sinking; // transformation in CodeGenPrepare::optimizeSelectInst with a more; // aggressive strategy of which instructions to sink.; //; // TODO: eliminate the redundancy of logic transforming selects to branches; // by removing CodeGenPrepare::optimizeSelectInst and optimizing here; // selects for all cases (with and without profile information).; // Transform a sequence like this:; // start:; // %cmp = cmp uge i32 %a, %b; // %sel = select i1 %cmp, i32 %c, i32 %d; //; // Into:; // start:; // %cmp = cmp uge i32 %a, %b; // %cmp.frozen = freeze %cmp; // br i1 %cmp.frozen, label %select.true, label %select.false; // select.true:; // br label %select.end; // select.false:; // br label %select.end; // select.end:; // %sel = phi i32 [ %c, %select.true ], [ %d, %select.false ]; //; // %cmp should be frozen, otherwise it may introduce undefined behavior.; // In addition, we may sink instructions that produce %c or %d into the; // destination(s) of the new branch.; // If the true or false blocks do not contain a sunken instruction, that; // block and its branch may be optimized away. In that case, one side of the; // first branch will point directly to select.end, and the corresponding PHI; // predecessor block will be the start block.; // Find all the instructions that can be soundly sunk to the true/false; // blocks. These are instructions that are computed solely for producing the; // operands of the select instructions in the group and can be sunk without; // breaking the semantics of the LLVM IR (e.g., cannot sink instructions; // with side effects).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectOptimize.cpp:107,optimiz,optimizeSelectInst,107,interpreter/llvm-project/llvm/lib/CodeGen/SelectOptimize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectOptimize.cpp,4,['optimiz'],"['optimizeSelectInst', 'optimized', 'optimizing']"
Performance,"// The code-generator is currently not able to handle scalable vectors; // of <vscale x 1 x eltty> yet, so return an invalid cost to avoid selecting; // it. This change will be removed when code-generation for these types is; // sufficiently reliable.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp:54,scalab,scalable,54,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,4,['scalab'],['scalable']
Performance,// The common alignment is the most restrictive (smallest) of all the loads,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:70,load,loads,70,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['load'],['loads']
Performance,// The common case is to map the virtual path to the same path inside the; // cache.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/ModuleDependencyCollector.cpp:78,cache,cache,78,interpreter/llvm-project/clang/lib/Frontend/ModuleDependencyCollector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/ModuleDependencyCollector.cpp,1,['cache'],['cache']
Performance,"// The comparison here must be unsigned, and performed with the same; // width as the pointer.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ExprConstant.cpp:45,perform,performed,45,interpreter/llvm-project/clang/lib/AST/ExprConstant.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ExprConstant.cpp,1,['perform'],['performed']
Performance,// The computation is correct in the face of overflow provided that the; // multiplication is performed _after_ the evaluation of the binomial; // coefficient.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp:94,perform,performed,94,interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,1,['perform'],['performed']
Performance,"// The concept of the reassociation pass is that these operations can benefit; // from this kind of transformation:; //; // A = ? op ?; // B = A op X (Prev); // C = B op Y (Root); // -->; // A = ? op ?; // B = X op Y; // C = A op B; //; // breaking the dependency between A and B, allowing them to be executed in; // parallel (or back-to-back in a pipeline) instead of depending on each other.; // FIXME: This has the potential to be expensive (compile time) while not; // improving the code at all. Some ways to limit the overhead:; // 1. Track successful transforms; bail out if hit rate gets too low.; // 2. Only enable at -O3 or some other non-default optimization level.; // 3. Pre-screen pattern candidates here: if an operand of the previous; // instruction is known to not increase the critical path, then don't match; // that pattern.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/TargetInstrInfo.cpp:656,optimiz,optimization,656,interpreter/llvm-project/llvm/lib/CodeGen/TargetInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/TargetInstrInfo.cpp,1,['optimiz'],['optimization']
Performance,// The condition is satisfied (Succ is affected). Add Succ to the; // bucket queue.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Support/GenericDomTreeConstruction.h:77,queue,queue,77,interpreter/llvm-project/llvm/include/llvm/Support/GenericDomTreeConstruction.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Support/GenericDomTreeConstruction.h,1,['queue'],['queue']
Performance,// The condition must be the *opposite* of the one we've decided to branch; // on as the branch will go *around* the load and the load should happen; // when the CMOV condition is false.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86CmovConversion.cpp:117,load,load,117,interpreter/llvm-project/llvm/lib/Target/X86/X86CmovConversion.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86CmovConversion.cpp,2,['load'],['load']
Performance,"// The constant pool load will be 64 bits, so need to convert to FPR128 reg.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp:21,load,load,21,interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp,1,['load'],['load']
Performance,"// The constants we just created may not be legal (eg, floating point). We; // must lower the vector right here because we can not guarantee that we'll; // legalize it before loading it. This is also why we could not just create; // a new build vector here. If the build vector contains illegal constants,; // it could get split back up into a series of insert elements.; // TODO: Improve this by using shorter loads with broadcast/VZEXT_LOAD.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:175,load,loading,175,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,2,['load'],"['loading', 'loads']"
Performance,"// The constructor attach the new cache.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCloner.cxx:34,cache,cache,34,tree/tree/src/TTreeCloner.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCloner.cxx,1,['cache'],['cache']
Performance,"// The content of the loadable member file needs to be aligned at MAX(maximum; // alignment of .text, maximum alignment of .data) if there are both fields.; // If the desired alignment is > PAGESIZE, 32-bit members are aligned on a; // word boundary, while 64-bit members are aligned on a PAGESIZE(2^12=4096); // boundary.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Object/ArchiveWriter.cpp:22,load,loadable,22,interpreter/llvm-project/llvm/lib/Object/ArchiveWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Object/ArchiveWriter.cpp,1,['load'],['loadable']
Performance,"// The copy constructor is non-trivial, create a mapping from this class; // type to this constructor.; // N.B. The selection of copy constructor is not sensitive to this; // particular throw-site. Lookup will be performed at the catch-site to; // ensure that the copy constructor is, in fact, accessible (via; // friendship or any other means).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp:213,perform,performed,213,interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp,1,['perform'],['performed']
Performance,"// The correct behavior here is to add the offset into the TBAA; // struct node offset. The base type, however may not have defined; // a type at this additional offset, resulting in errors. Since; // this method is only used within a given load/store access; // the offset provided is only used to subdivide the previous load; // maintaining the validity of the previous TBAA.; //; // This, however, should be revisited in the future.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/TypeBasedAliasAnalysis.cpp:241,load,load,241,interpreter/llvm-project/llvm/lib/Analysis/TypeBasedAliasAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/TypeBasedAliasAnalysis.cpp,2,['load'],['load']
Performance,"// The corresponding bullet in C++03 [dcl.init.ref]p5 gives the; // compiler the freedom to perform a copy here or bind to the; // object, while C++0x requires that we bind directly to the; // object. Hence, we always bind to the object without making an; // extra copy. However, in C++03 requires that we check for the; // presence of a suitable copy constructor:; //; // The constructor that would be used to make the copy shall; // be callable whether or not the copy is actually done.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp:92,perform,perform,92,interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,1,['perform'],['perform']
Performance,// The cost for vectorized loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp:27,load,loads,27,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,1,['load'],['loads']
Performance,"// The cost is actually exactly the same for mov+fmov vs. adrp+ldr;; // however the mov+fmov sequence is always better because of the reduced; // cache pressure. The timings are still the same if you consider; // movw+movk+fmov vs. adrp+ldr (it's one instruction longer, but the; // movw+movk is fused). So we limit up to 2 instrdduction at most.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:146,cache,cache,146,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['cache'],['cache']
Performance,// The cost is modeled on the expansion performed by ExpandPowI in; // SelectionDAGBuilder.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h:40,perform,performed,40,interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,1,['perform'],['performed']
Performance,// The cost of forming the vector from loaded scalars/; // scalarizing the vector to perform scalar stores.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:39,load,loaded,39,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,2,"['load', 'perform']","['loaded', 'perform']"
Performance,// The cost of the scalar loads/stores.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:26,load,loads,26,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,1,['load'],['loads']
Performance,// The current bucket of fields that we are trying to fill to a cache-line.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/Randstruct.cpp:64,cache,cache-line,64,interpreter/llvm-project/clang/lib/AST/Randstruct.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/Randstruct.cpp,1,['cache'],['cache-line']
Performance,"// The current cycle is already greater than the critical path, so we are; // already latency limited and don't need to compute the remaining latency.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp:86,latency,latency,86,interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp,2,['latency'],['latency']
Performance,"// The current selector can't handle <6 x s16>, <8 x s16>, s96, s128 etc, so; // workaround this. Eventually it should ignore the type for loads and only care; // about the size. Return true in cases where we will workaround this for now by; // bitcasting.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp:139,load,loads,139,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,1,['load'],['loads']
Performance,"// The current thinking is that wasm engines will perform this optimization,; // so we can save on code size.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp:50,perform,perform,50,interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp,2,"['optimiz', 'perform']","['optimization', 'perform']"
Performance,// The current token should go after the cached tokens.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseExprCXX.cpp:41,cache,cached,41,interpreter/llvm-project/clang/lib/Parse/ParseExprCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseExprCXX.cpp,1,['cache'],['cached']
Performance,// The current value is a zero.; // Explicitly express that as it would be easier for; // optimizations to kick in.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp:90,optimiz,optimizations,90,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,1,['optimiz'],['optimizations']
Performance,"// The custom pointers (fat pointers, buffer resources) don't work with load; // and store at this level. Fat pointers should have been lowered to; // intrinsics before the translation to MIR.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp:72,load,load,72,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,1,['load'],['load']
Performance,"// The data is stored in host byte order, make sure to cast back to the right; // type to load with the right endianness.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/Constants.cpp:90,load,load,90,interpreter/llvm-project/llvm/lib/IR/Constants.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/Constants.cpp,2,['load'],['load']
Performance,"// The default assumption for an RVV instruction is TAMA, as an undisturbed; // policy generally will affect the performance of an out-of-order core.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Support/RISCVVIntrinsicUtils.h:113,perform,performance,113,interpreter/llvm-project/clang/include/clang/Support/RISCVVIntrinsicUtils.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Support/RISCVVIntrinsicUtils.h,1,['perform'],['performance']
Performance,"// The default implementation reduces to just comparison, since comparison; // is required by the API, even if no widening is performed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Analysis/FlowSensitive/DataflowEnvironment.h:126,perform,performed,126,interpreter/llvm-project/clang/include/clang/Analysis/FlowSensitive/DataflowEnvironment.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Analysis/FlowSensitive/DataflowEnvironment.h,1,['perform'],['performed']
Performance,"// The desired load overlaps a non-bit-field member, bail out.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGRecordLayoutBuilder.cpp:15,load,load,15,interpreter/llvm-project/clang/lib/CodeGen/CGRecordLayoutBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGRecordLayoutBuilder.cpp,1,['load'],['load']
Performance,// The distance is too large - still may be profitable to use masked; // loads/gathers.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp:73,load,loads,73,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,1,['load'],['loads']
Performance,"// The dynamic heuristic for setting the packet size (default); // Calculates the packet size based on performance of this slave; // and estimated time left until the end of the query.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/src/TPacketizerAdaptive.cxx:103,perform,performance,103,proof/proofplayer/src/TPacketizerAdaptive.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/src/TPacketizerAdaptive.cxx,1,['perform'],['performance']
Performance,"// The early exit in the original loop means that when performing vector; // loads we are potentially reading ahead of the early exit. So we could; // fault if crossing a page boundary. Therefore, we create runtime memory; // checks based on the minimum page size as follows:; // 1. Calculate the addresses of the first memory accesses in the loop,; // i.e. LhsStart and RhsStart.; // 2. Get the last accessed addresses in the loop, i.e. LhsEnd and RhsEnd.; // 3. Determine which pages correspond to all the memory accesses, i.e; // LhsStartPage, LhsEndPage, RhsStartPage, RhsEndPage.; // 4. If LhsStartPage == LhsEndPage and RhsStartPage == RhsEndPage, then; // we know we won't cross any page boundaries in the loop so we can; // enter the vector loop! Otherwise we fall back on the scalar loop.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoopIdiomTransform.cpp:55,perform,performing,55,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoopIdiomTransform.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoopIdiomTransform.cpp,2,"['load', 'perform']","['loads', 'performing']"
Performance,"// The easiest way to get this right-justified in a register; // is to copy the structure into the rightmost portion of a; // local variable slot, then load the whole slot into the; // register.; // FIXME: The memcpy seems to produce pretty awful code for; // small aggregates, particularly for packed ones.; // FIXME: It would be preferable to use the slot in the; // parameter save area instead of a new local variable.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:152,load,load,152,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['load']
Performance,// The edge from Pred to LoadBB is a critical edge will be splitted.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp:25,Load,LoadBB,25,interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,1,['Load'],['LoadBB']
Performance,"// The edge from Pred to LoadBB is a critical edge, another successor of Pred; // contains a load can be moved to Pred. This data structure maps the Pred to; // the movable load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp:25,Load,LoadBB,25,interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,3,"['Load', 'load']","['LoadBB', 'load']"
Performance,"// The element was not yet optimized we first need to copy it into; // the set of original copies.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfoActions.cxx:27,optimiz,optimized,27,io/io/src/TStreamerInfoActions.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfoActions.cxx,1,['optimiz'],['optimized']
Performance,"// The elements must be reversed when the element order is different; // to the endianness of the elements (because the BITCAST is itself a; // vector shuffle in this situation). However, we do not need any code to; // perform this reversal because getConstant() is producing a vector; // splat.; // This situation occurs in MIPS MSA.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp:219,perform,perform,219,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,1,['perform'],['perform']
Performance,// The encoding with rd1 == rd2 == rs1 is reserved for XTHead load pair.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp:62,load,load,62,interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp,1,['load'],['load']
Performance,"// The epilog restore of a wwm-scratch register can cause undesired; // optimization during machine-cp post PrologEpilogInserter if the same; // register was assigned for return value ABI lowering with a COPY; // instruction. As given below, with the epilog reload, the earlier COPY; // appeared to be dead during machine-cp.; // ...; // v0 in WWM operation, needs the WWM spill at prolog/epilog.; // $vgpr0 = V_WRITELANE_B32 $sgpr20, 0, $vgpr0; // ...; // Epilog block:; // $vgpr0 = COPY $vgpr1 // outgoing value moved to v0; // ...; // WWM spill restore to preserve the inactive lanes of v0.; // $sgpr4_sgpr5 = S_XOR_SAVEEXEC_B64 -1; // $vgpr0 = BUFFER_LOAD $sgpr0_sgpr1_sgpr2_sgpr3, $sgpr32, 0, 0, 0; // $exec = S_MOV_B64 killed $sgpr4_sgpr5; // ...; // SI_RETURN implicit $vgpr0; // ...; // To fix it, mark the same reg as a tied op for such restore instructions; // so that it marks a usage for the preceding COPY.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIRegisterInfo.cpp:72,optimiz,optimization,72,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIRegisterInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIRegisterInfo.cpp,1,['optimiz'],['optimization']
Performance,// The establisher parameter passed to a CLR funclet is actually a pointer; // to the (mostly empty) frame of its nearest enclosing funclet; we have; // to find the root function establisher frame by loading the PSPSym from; // the intermediate frame.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FrameLowering.cpp:200,load,loading,200,interpreter/llvm-project/llvm/lib/Target/X86/X86FrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FrameLowering.cpp,1,['load'],['loading']
Performance,"// The evaluation of this constraint resulted in us trying to re-evaluate it; // recursively. This isn't really possible, except we try to form a; // RecoveryExpr as a part of the evaluation. If this is the case, just; // return the 'cached' version (which will have the same result), and save; // ourselves the extra-insert. If it ever becomes possible to legitimately; // recursively check a constraint, we should skip checking the 'inner' one; // above, and replace the cached version with this one, as it would be more; // specific.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaConcept.cpp:234,cache,cached,234,interpreter/llvm-project/clang/lib/Sema/SemaConcept.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaConcept.cpp,2,['cache'],['cached']
Performance,// The event is for loading a separate executable segment.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/PerfReader.cpp:20,load,loading,20,interpreter/llvm-project/llvm/tools/llvm-profgen/PerfReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/PerfReader.cpp,1,['load'],['loading']
Performance,// The expander optimized away the kernel. We can't do any useful checking.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ModuloSchedule.cpp:16,optimiz,optimized,16,interpreter/llvm-project/llvm/lib/CodeGen/ModuloSchedule.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ModuloSchedule.cpp,1,['optimiz'],['optimized']
Performance,// The expected latency of the critical path in this scheduled zone.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineScheduler.h:16,latency,latency,16,interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineScheduler.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineScheduler.h,1,['latency'],['latency']
Performance,"// The explicit NULL case, no operation is performed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/MallocChecker.cpp:43,perform,performed,43,interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/MallocChecker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/MallocChecker.cpp,1,['perform'],['performed']
Performance,// The extend of other kinds of load is free,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp:32,load,load,32,interpreter/llvm-project/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp,1,['load'],['load']
Performance,"// The extra bits are guaranteed to be zero, since we stored them that; // way. A zext load from NVT thus automatically gives zext from SrcVT.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp:87,load,load,87,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,1,['load'],['load']
Performance,"// The extra bits are guaranteed to be zero, since we stored them that; // way. A zext load from Wide thus automatically gives zext from MemVT.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalizerHelper.cpp:87,load,load,87,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalizerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalizerHelper.cpp,1,['load'],['load']
Performance,"// The factory creates all MVA methods, and performs their training and testing",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/Factory.h:44,perform,performs,44,tmva/tmva/inc/TMVA/Factory.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/Factory.h,1,['perform'],['performs']
Performance,"// The fieldID could be the root field or the class of fieldId might not be loaded.; // In these cases, only the inner fields are exposed as RDF columns.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RNTupleDS.cxx:76,load,loaded,76,tree/dataframe/src/RNTupleDS.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RNTupleDS.cxx,1,['load'],['loaded']
Performance,"// The file cache was restored to its previous value at the end of Exec,; // we can safely delete our cache.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCloner.cxx:12,cache,cache,12,tree/tree/src/TTreeCloner.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCloner.cxx,2,['cache'],['cache']
Performance,// The file may have come from PCH and then changed after loading the; // PCH; Fail gracefully.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/LiteralSupport.cpp:58,load,loading,58,interpreter/llvm-project/clang/lib/Lex/LiteralSupport.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/LiteralSupport.cpp,2,['load'],['loading']
Performance,"// The filename for the cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/net/src/TApplicationRemote.cxx:24,cache,cache,24,net/net/src/TApplicationRemote.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/net/src/TApplicationRemote.cxx,1,['cache'],['cache']
Performance,"// The files are now on the workers: now we send the loading request",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProof.cxx:53,load,loading,53,proof/proof/src/TProof.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProof.cxx,1,['load'],['loading']
Performance,"// The final result from the CAS is {load of 'expected' alloca, bool result; // from call}",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp:37,load,load,37,interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp,1,['load'],['load']
Performance,"// The first case is the same as selectAddrModeXRO, except we need an extend.; // In this case, we try to find a shift and extend, and fold them into the; // addressing mode.; //; // E.g.; //; // off_reg = G_Z/S/ANYEXT ext_reg; // val = G_CONSTANT LegalShiftVal; // shift = G_SHL off_reg val; // ptr = G_PTR_ADD base_reg shift; // x = G_LOAD ptr; //; // In this case we can get a load like this:; //; // ldr x0, [base_reg, ext_reg, sxtw #LegalShiftVal]",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp:380,load,load,380,interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp,1,['load'],['load']
Performance,"// The first elements of each vector should be loads with sexts. If we; // find that its two pairs of consecutive loads, then these can be; // transformed into two wider loads and the users can be replaced with; // DSP intrinsics.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMParallelDSP.cpp:47,load,loads,47,interpreter/llvm-project/llvm/lib/Target/ARM/ARMParallelDSP.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMParallelDSP.cpp,3,['load'],['loads']
Performance,"// The first instruction loads a PC-relative address into %r11 which is a; // GOT entry for this stub. This initially contains the address to the; // IFunc resolver. We can use %r11 here as it's caller saved but not used; // to pass any arguments. In fact, x86_64 ABI even suggests using %r11 for; // code in the PLT. The IFunc resolver will use %r11 to update the GOT; // entry.; //; // The next instruction just jumps to the address contained in the GOT; // entry. As mentioned above, we do this two-step jump by first setting; // %r11 so that the IFunc resolver has access to it.; //; // The IFunc resolver of course also needs to know the actual address of; // the actual IFunc resolver function. This will be stored in a GOT entry; // right next to the first one for this stub. So, the IFunc resolver will; // be able to call it with %r11+8.; //; // In total, two adjacent GOT entries (+relocation) and one additional; // relocation are required:; // GOT1: Address of the IFunc resolver.; // GOT2: Address of the IFunc resolver function.; // IFuncStubOffset+3: 32-bit PC-relative address of GOT1.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp:25,load,loads,25,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp,1,['load'],['loads']
Performance,"// The first pass over the block: collect all the loads which can have their; // loaded value hardened and all the loads that instead need their address; // hardened. During this walk we propagate load dependence for address; // hardened loads and also look for LFENCE to stop hardening wherever; // possible. When deciding whether or not to harden the loaded value or not,; // we check to see if any registers used in the address will have been; // hardened at this point and if so, harden any remaining address registers; // as that often successfully re-uses hardened addresses and minimizes; // instructions.; //; // FIXME: We should consider an aggressive mode where we continue to keep as; // many loads value hardened even when some address register hardening would; // be free (due to reuse).; //; // Note that we only need this pass if we are actually hardening loads.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:50,load,loads,50,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,8,['load'],"['load', 'loaded', 'loads']"
Performance,"// The first pass we add one basket per branches around the requested entry; // then in the second pass we add the other baskets of the cluster.; // This is to support the case where the cache is too small to hold a full cluster.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx:187,cache,cache,187,tree/tree/src/TTreeCache.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx,1,['cache'],['cache']
Performance,// The fixed integer arguments of a variadic function are stored to the; // VarArgsFrameIndex on the stack so that they may be loaded by; // dereferencing the result of va_next.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:127,load,loaded,127,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,2,['load'],['loaded']
Performance,// The flags leaving this block have high latency.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/Thumb2SizeReduction.cpp:42,latency,latency,42,interpreter/llvm-project/llvm/lib/Target/ARM/Thumb2SizeReduction.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/Thumb2SizeReduction.cpp,1,['latency'],['latency']
Performance,"// The folding we want to perform is:; // (add x, [zext] (setcc cc ...) ); // -->; // (csel x, (add x, 1), !cc ...); //; // The latter will get matched to a CSINC instruction.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:26,perform,perform,26,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['perform'],['perform']
Performance,"// The folding we want to perform is:; // (xor x, (select_cc a, b, cc, 0, -1) ); // -->; // (csel x, (xor x, -1), cc ...); //; // The latter will get matched to a CSINV instruction.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:26,perform,perform,26,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['perform'],['perform']
Performance,// The following are only meaningful on targets that support; // S_WAIT_LOADCNT_DSCNT and S_WAIT_STORECNT_DSCNT.; /// \returns Decoded Waitcnt structure from given \p LoadcntDscnt for given; /// isa \p Version.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/Utils/AMDGPUBaseInfo.h:167,Load,LoadcntDscnt,167,interpreter/llvm-project/llvm/lib/Target/AMDGPU/Utils/AMDGPUBaseInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/Utils/AMDGPUBaseInfo.h,1,['Load'],['LoadcntDscnt']
Performance,"// The following class implements a function executor that executes the; // benchmark code within a subprocess rather than within the main llvm-exegesis; // process. This allows for much more control over the execution context of the; // snippet, particularly with regard to memory. This class performs all the; // necessary functions to create the subprocess, execute the snippet in the; // subprocess, and report results/handle errors.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/BenchmarkRunner.cpp:294,perform,performs,294,interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/BenchmarkRunner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/BenchmarkRunner.cpp,1,['perform'],['performs']
Performance,"// The following code pattern is handled:; // %3 = call i8* @llvm.stacksave(); // store i8* %3, i8** %saved_stack, align 8; // ...; // %4 = load i8*, i8** %saved_stack, align 8; // call void @llvm.stackrestore(i8* %4); // ...; // The goal is to remove the above four instructions,; // so we won't have instructions with r11 (stack pointer); // if eventually there is no variable length stack allocation.; // InstrCombine also tries to remove the above instructions,; // if it is proven safe (constant alloca etc.), but depending; // on code pattern, it may still miss some.; //; // With unconditionally removing these instructions, if alloca is; // constant, we are okay then. Otherwise, SelectionDag will complain; // since BPF does not support dynamic allocation yet.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFIRPeephole.cpp:140,load,load,140,interpreter/llvm-project/llvm/lib/Target/BPF/BPFIRPeephole.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFIRPeephole.cpp,1,['load'],['load']
Performance,// The following currently have unknown cache line sizes (but they are probably all 64):; // Core,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/X86.cpp:40,cache,cache,40,interpreter/llvm-project/clang/lib/Basic/Targets/X86.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/X86.cpp,1,['cache'],['cache']
Performance,"// The following extend from a legal type to an illegal type, so need to; // split the load. This introduced an extra load operation, but the; // extend is still ""free"".",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp:87,load,load,87,interpreter/llvm-project/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp,2,['load'],['load']
Performance,"// The following function sets up the auxiliary memory by opening shared; // memory objects backing memory definitions and putting file descriptors; // into appropriate places. Arguments: MemoryDefinitions - A map from memory; // values names to Memoryvalues, ParentPID - The ID of the process that; // setup the memory definitions, CounterFileDescriptor - The file descriptor; // for the performance counter that will be placed in the auxiliary memory; // section.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/SubprocessMemory.h:389,perform,performance,389,interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/SubprocessMemory.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/SubprocessMemory.h,1,['perform'],['performance']
Performance,// The following has the side effect of loading the missing module.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp:40,load,loading,40,interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,1,['load'],['loading']
Performance,"// The following loop iterates over all instructions in the basic block,; // and performs 2 operations:; // 1. Insert a CSDB at this location if needed.; // 2. Expand the SpeculationSafeValuePseudo if the current instruction is; // one.; //; // The insertion of the CSDB is done as late as possible (i.e. just before; // the use of a masked register), in the hope that that will reduce the; // total number of CSDBs in a block when there are multiple masked registers; // in the block.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64SpeculationHardening.cpp:81,perform,performs,81,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64SpeculationHardening.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64SpeculationHardening.cpp,1,['perform'],['performs']
Performance,"// The following methods are only meaningful on targets that support; // S_WAIT_*CNT, introduced with gfx12.; /// \returns Loadcnt bit mask for given isa \p Version.; /// Returns 0 for versions that do not support LOADcnt",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/Utils/AMDGPUBaseInfo.h:123,Load,Loadcnt,123,interpreter/llvm-project/llvm/lib/Target/AMDGPU/Utils/AMDGPUBaseInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/Utils/AMDGPUBaseInfo.h,2,"['LOAD', 'Load']","['LOADcnt', 'Loadcnt']"
Performance,// The following optimization is valid only if every value in SrcVT (when; // treated as signed) is representable in DestVT. Check that the mantissa; // size of DestVT is >= than the number of bits in SrcVT -1.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp:17,optimiz,optimization,17,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,1,['optimiz'],['optimization']
Performance,"// The following pattern is likely to emerge with vector reduction ops. Moving; // the binary operation ahead of insertion may allow using a narrower vector; // instruction that has better performance than the wide version of the op:; // VBinOp (ins undef, X, Z), (ins undef, Y, Z) --> ins VecC, (VBinOp X, Y), Z",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:189,perform,performance,189,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['perform'],['performance']
Performance,"// The following pattern is likely to emerge with vector reduction ops. Moving; // the binary operation ahead of the concat may allow using a narrower vector; // instruction that has better performance than the wide version of the op:; // VBinOp (concat X, undef/constant), (concat Y, undef/constant) -->; // concat (VBinOp X, Y), VecC",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:190,perform,performance,190,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['perform'],['performance']
Performance,// The following semantically builds up a fixed length concat_vector; // of the component build_vectors. We eagerly lower to scalable and; // insert_subvector here to avoid DAG combining it back to a large; // build_vector.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:125,scalab,scalable,125,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['scalab'],['scalable']
Performance,// The following semantically builds up a fixed length concat_vector; // of the component shuffle_vectors. We eagerly lower to scalable here; // to avoid DAG combining it back to a large shuffle_vector again.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:127,scalab,scalable,127,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['scalab'],['scalable']
Performance,"// The following types are asummed to be canonical names; thus, do not perform `typedef` resolution on those",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RField.cxx:71,perform,perform,71,tree/ntuple/v7/src/RField.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RField.cxx,1,['perform'],['perform']
Performance,"// The four core functions - F1 is optimized somewhat; //#define F1(x, y, z) (x & y | ~x & z)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TMD5.cxx:35,optimiz,optimized,35,core/base/src/TMD5.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TMD5.cxx,1,['optimiz'],['optimized']
Performance,"// The function epilogue should not depend on the current stack pointer!; // It should use the frame pointer only. This is mandatory because; // of alloca; we also take advantage of it to omit stack adjustments; // before returning.; //; // Note that when we go to restore the preserved register values we must; // not try to address their slots by using offsets from the stack pointer.; // That's because the stack pointer may have been moved during the function; // execution due to a call to alloca(). Rather, we must restore all; // preserved registers via offsets from the frame pointer value.; //; // Note also that when the current frame is being ""popped"" (by adjusting; // the value of the stack pointer) on function exit, we must (for the; // sake of alloca) set the new value of the stack pointer based upon; // the current value of the frame pointer. We can't just add what we; // believe to be the (static) frame size to the stack pointer because; // if we did that, and alloca() had been called during this function,; // we would end up returning *without* having fully deallocated all of; // the space grabbed by alloca. If that happened, and a function; // containing one or more alloca() calls was called over and over again,; // then the stack would grow without limit!; //; // RET is lowered to; // ld -4[%fp],%pc # modify %pc (two delay slots); // as the return address is in the stack frame and mov to pc is allowed.; // emitEpilogue emits; // mov %fp,%sp # restore the stack pointer; // ld -8[%fp],%fp # restore the caller's frame pointer; // before RET and the delay slot filler will move RET such that these; // instructions execute in the delay slots of the load to PC.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Lanai/LanaiFrameLowering.cpp:1682,load,load,1682,interpreter/llvm-project/llvm/lib/Target/Lanai/LanaiFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Lanai/LanaiFrameLowering.cpp,1,['load'],['load']
Performance,// The function is going to insert a wait on everything in its prolog.; // This still needs to be careful if the call target is a load (e.g. a GOT; // load). We also need to check WAW dependency with saved PC.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInsertWaitcnts.cpp:130,load,load,130,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInsertWaitcnts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInsertWaitcnts.cpp,2,['load'],['load']
Performance,"// The general transformation to keep in mind is; //; // call @func(..., src, ...); // memcpy(dest, src, ...); //; // ->; //; // memcpy(dest, src, ...); // call @func(..., dest, ...); //; // Since moving the memcpy is technically awkward, we additionally check that; // src only holds uninitialized values at the moment of the call, meaning that; // the memcpy can be discarded rather than moved.; // We can't optimize scalable types.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp:410,optimiz,optimize,410,interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,2,"['optimiz', 'scalab']","['optimize', 'scalable']"
Performance,"// The getStrengthenedNoWrapFlagsFromBinOp() check inferred additional nowrap; // flags on addrecs while performing zero/sign extensions. We could call; // forgetValue() here to make sure those flags also propagate to any other; // SCEV expressions based on the addrec. However, this can have pathological; // compile-time impact, see https://bugs.llvm.org/show_bug.cgi?id=50384.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyIndVar.cpp:105,perform,performing,105,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyIndVar.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyIndVar.cpp,1,['perform'],['performing']
Performance,"// The global gROOT is defined to be a function (ROOT::GetROOT()); // which itself is dereferencing a function pointer.; // Initially this function pointer's value is & GetROOT1 whose role is to; // create and initialize the TROOT object itself.; // At the very end of the TROOT constructor the value of the function pointer; // is switch to & GetROOT2 whose role is to initialize the interpreter.; // This mechanism was primarily intended to fix the issues with order in which; // global TROOT and LLVM globals are initialized. TROOT was initializing; // Cling, but Cling could not be used yet due to LLVM globals not being; // Initialized yet. The solution is to delay initializing the interpreter in; // TROOT till after main() when all LLVM globals are initialized.; // Technically, the mechanism used actually delay the interpreter; // initialization until the first use of gROOT *after* the end of the; // TROOT constructor.; // So to delay until after the start of main, we also made sure that none; // of the ROOT code (mostly the dictionary code) used during library loading; // is using gROOT (directly or indirectly).; // In practice, the initialization of the interpreter is now delayed until; // the first use gROOT (or gInterpreter) after the start of main (but user; // could easily break this by using gROOT in their library initialization; // code).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TROOT.cxx:1076,load,loading,1076,core/base/src/TROOT.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TROOT.cxx,1,['load'],['loading']
Performance,"// The goal of this pass is to enable more efficient code generation for; // operations on narrow types (i.e. types with < 32-bits) and this is a; // motivating IR code example:; //; // define hidden i32 @cmp(i8 zeroext) {; // %2 = add i8 %0, -49; // %3 = icmp ult i8 %2, 3; // ..; // }; //; // The issue here is that i8 is type-legalized to i32 because i8 is not a; // legal type. Thus, arithmetic is done in integer-precision, but then the; // byte value is masked out as follows:; //; // t19: i32 = add t4, Constant:i32<-49>; // t24: i32 = and t19, Constant:i32<255>; //; // Consequently, we generate code like this:; //; // subs r0, #49; // uxtb r1, r0; // cmp r1, #3; //; // This shows that masking out the byte value results in generation of; // the UXTB instruction. This is not optimal as r0 already contains the byte; // value we need, and so instead we can just generate:; //; // sub.w r1, r0, #49; // cmp r1, #3; //; // We achieve this by type promoting the IR to i32 like so for this example:; //; // define i32 @cmp(i8 zeroext %c) {; // %0 = zext i8 %c to i32; // %c.off = add i32 %0, -49; // %1 = icmp ult i32 %c.off, 3; // ..; // }; //; // For this to be valid and legal, we need to prove that the i32 add is; // producing the same value as the i8 addition, and that e.g. no overflow; // happens.; //; // A brief sketch of the algorithm and some terminology.; // We pattern match interesting IR patterns:; // - which have ""sources"": instructions producing narrow values (i8, i16), and; // - they have ""sinks"": instructions consuming these narrow values.; //; // We collect all instruction connecting sources and sinks in a worklist, so; // that we can mutate these instruction and perform type promotion when it is; // legal to do so.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/TypePromotion.cpp:1696,perform,perform,1696,interpreter/llvm-project/llvm/lib/CodeGen/TypePromotion.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/TypePromotion.cpp,1,['perform'],['perform']
Performance,"// The handle is a parameter value being loaded, replace with the; // parameter symbol",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXReplaceImageHandles.cpp:41,load,loaded,41,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXReplaceImageHandles.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXReplaceImageHandles.cpp,1,['load'],['loaded']
Performance,"// The hard-coded scores listed here are not very important, though it shall; // be higher for better matches to improve the resulting cost. When; // computing the scores of matching one sub-tree with another, we are; // basically counting the number of values that are matching. So even if all; // scores are set to 1, we would still get a decent matching result.; // However, sometimes we have to break ties. For example we may have to; // choose between matching loads vs matching opcodes. This is what these; // scores are helping us with: they provide the order of preference. Also,; // this is important if the scalar is externally used or used in another; // tree entry node in the different lane.; /// Loads from consecutive memory addresses, e.g. load(A[i]), load(A[i+1]).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp:466,load,loads,466,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,4,"['Load', 'load']","['Loads', 'load', 'loads']"
Performance,// The hi masked load has zero storage size. We therefore simply set it to; // the low masked load and rely on subsequent removal from the chain.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp:17,load,load,17,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp,2,['load'],['load']
Performance,"// The high 19 bits of a 21-bit pc-relative immediate. Same encoding as; // fixup_aarch64_pcrel_adrhi, except this is used by pc-relative loads and; // generates relocations directly when necessary.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/MCTargetDesc/AArch64FixupKinds.h:138,load,loads,138,interpreter/llvm-project/llvm/lib/Target/AArch64/MCTargetDesc/AArch64FixupKinds.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/MCTargetDesc/AArch64FixupKinds.h,1,['load'],['loads']
Performance,"// The i8 and i16 cases don't need compares. We zext the loaded values and; // subtract them to get the suitable negative, zero, or positive i32 result.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp:57,load,loaded,57,interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,1,['load'],['loaded']
Performance,// The identified swap entry requires special handling to allow its; // containing computation to be optimized. Perform that handling; // here.; // FIXME: Additional opportunities will be phased in with subsequent; // patches.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp:101,optimiz,optimized,101,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp,2,"['Perform', 'optimiz']","['Perform', 'optimized']"
Performance,"// The imm operand of ADDS is an unsigned immediate, in the range 0 to 4095.; // For the i8 operand, the largest immediate is 255, so this can be easily; // encoded in the compare instruction. For the i16 operand, however, the; // largest immediate cannot be encoded in the compare.; // Therefore, use a sign extending load and cmn to avoid materializing the; // -1 constant. For example,; // movz w1, #65535; // ldrh w0, [x0, #0]; // cmp w0, w1; // >; // ldrsh w0, [x0, #0]; // cmn w0, #1; // Fundamental, we're relying on the property that (zext LHS) == (zext RHS); // if and only if (sext LHS) == (sext RHS). The checks are in place to; // ensure both the LHS and RHS are truly zero extended and to make sure the; // transformation is profitable.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:319,load,load,319,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['load'],['load']
Performance,"// The immediate in the load/store is scaled by the size of the memory; // operation. The immediate in the add we're looking for,; // however, is not, so adjust here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp:24,load,load,24,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp,1,['load'],['load']
Performance,// The imported AST had been generated for a different target.; // Some parts of the triple in the loaded ASTContext can be unknown while the; // very same parts in the target ASTContext are known. Thus we check for the; // known parts only.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CrossTU/CrossTranslationUnit.cpp:99,load,loaded,99,interpreter/llvm-project/clang/lib/CrossTU/CrossTranslationUnit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CrossTU/CrossTranslationUnit.cpp,1,['load'],['loaded']
Performance,// The index is incremented before the GEP/Load pair so we need to; // add 1 to the start value.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoopIdiomTransform.cpp:43,Load,Load,43,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoopIdiomTransform.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoopIdiomTransform.cpp,1,['Load'],['Load']
Performance,// The initial queue should not have reaching defs for shadows. The; // whole point of a shadow is that it will have a reaching def that; // is not aliased to the reaching defs of the related shadows.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RDFLiveness.cpp:15,queue,queue,15,interpreter/llvm-project/llvm/lib/CodeGen/RDFLiveness.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RDFLiveness.cpp,1,['queue'],['queue']
Performance,// The initializer was deferred; parse it and cache the tokens.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseDeclCXX.cpp:46,cache,cache,46,interpreter/llvm-project/clang/lib/Parse/ParseDeclCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseDeclCXX.cpp,1,['cache'],['cache']
Performance,"// The input instruction is : ""I=0.0 +/- V"". If the ""V"" were able to be; // splitted into two addends, say ""V = X - Y"", the instruction would have; // been optimized into ""I = Y - X"" in the previous steps.; //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp:156,optimiz,optimized,156,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp,1,['optimiz'],['optimized']
Performance,// The input is a load that doesn't sign-extend (it will be zero-extended).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp:18,load,load,18,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,1,['load'],['load']
Performance,// The input is a sign-extending load. All ppc sign-extending loads; // sign-extend to the full 64-bits.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp:33,load,load,33,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,2,['load'],"['load', 'loads']"
Performance,// The insertion point is the LoadInst which loads the first values. The; // following tests are used to proof that the combined load can be inserted; // just before InsertionPoint.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp:30,Load,LoadInst,30,interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp,3,"['Load', 'load']","['LoadInst', 'load', 'loads']"
Performance,// The instruction result is the result of loading from the; // hidden sret parameter.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp:43,load,loading,43,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,1,['load'],['loading']
Performance,// The integer extend has already been emitted - delete all the instructions; // that have been emitted by the integer extend lowering code and use the; // result from the load instruction directly.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FastISel.cpp:172,load,load,172,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FastISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FastISel.cpp,1,['load'],['load']
Performance,"// The intention here is to find diamonds or triangles (see below) where each; // conditional block contains a store to the same address. Both of these; // stores are conditional, so they can't be unconditionally sunk. But it may; // be profitable to speculatively sink the stores into one merged store at the; // end, and predicate the merged store on the union of the two conditions of; // PBI and QBI.; //; // This can reduce the number of stores executed if both of the conditions are; // true, and can allow the blocks to become small enough to be if-converted.; // This optimization will also chain, so that ladders of test-and-set; // sequences can be if-converted away.; //; // We only deal with simple diamonds or triangles:; //; // PBI or PBI or a combination of the two; // / \ | \; // PTB PFB | PFB; // \ / | /; // QBI QBI; // / \ | \; // QTB QFB | QFB; // \ / | /; // PostBB PostBB; //; // We model triangles as a type of diamond with a nullptr ""true"" block.; // Triangles are canonicalized so that the fallthrough edge is represented by; // a true condition, as in the diagram above.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp:576,optimiz,optimization,576,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp,1,['optimiz'],['optimization']
Performance,// The interface for this implementation must exist and be loaded.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/ModuleMap.cpp:59,load,loaded,59,interpreter/llvm-project/clang/lib/Lex/ModuleMap.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/ModuleMap.cpp,1,['load'],['loaded']
Performance,"// The interleave cost is similar to extract sub vectors' elements; // from the wide vector, and insert them into sub vectors.; //; // E.g. An interleaved load of factor 2 (with one member of index 0):; // %vec = load <8 x i32>, <8 x i32>* %ptr; // %v0 = shuffle %vec, undef, <0, 2, 4, 6> ; Index 0; // The cost is estimated as extract elements at 0, 2, 4, 6 from the; // <8 x i32> vector and insert them into a <4 x i32> vector.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h:155,load,load,155,interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,2,['load'],['load']
Performance,// The interleaved memory access pass will lower interleaved memory ops (i.e; // a load and store followed by a specific shuffle) to vlseg/vsseg; // intrinsics. In those cases then we can treat it as if it's just one (legal); // memory op,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVTargetTransformInfo.cpp:83,load,load,83,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVTargetTransformInfo.cpp,1,['load'],['load']
Performance,"// The internal return value temp always will have pointer-to-return-type; // type, just do a load.; // If there is a dominating store to ReturnValue, we can elide; // the load, zap the store, and usually zap the alloca.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGCall.cpp:94,load,load,94,interpreter/llvm-project/clang/lib/CodeGen/CGCall.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGCall.cpp,2,['load'],['load']
Performance,"// The intrinsic function call is of the form { ElTy, i8* }; // @llvm.hexagon.L2.loadXX.pbr(i8*, i32). The pointer and memory access type; // should be derived from ElTy.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelLowering.cpp:81,load,loadXX,81,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelLowering.cpp,1,['load'],['loadXX']
Performance,"// The intrinsic generates one result, which is the new value for the base; // pointer. It needs to be returned. The result of the load instruction is; // passed to intrinsic by address, so the value needs to be stored.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:131,load,load,131,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,1,['load'],['load']
Performance,"// The intrinsics for load circ/brev perform two operations:; // 1. Load a value V from the specified location, using the addressing; // mode corresponding to the intrinsic.; // 2. Store V into a specified location. This location is typically a; // local, temporary object.; // In many cases, the program using these intrinsics will immediately; // load V again from the local object. In those cases, when certain; // conditions are met, the last load can be removed.; // This function identifies and optimizes this pattern. If the pattern; // cannot be optimized, it returns nullptr, which will cause the load; // to be selected separately from the intrinsic (which will be handled; // in SelectIntrinsicWChain).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp:22,load,load,22,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,8,"['Load', 'load', 'optimiz', 'perform']","['Load', 'load', 'optimized', 'optimizes', 'perform']"
Performance,"// The inttoptr case works because isNonEscapingLocalObject considers all; // means of converting or equating a pointer to an int (ptrtoint, ptr store; // which could be followed by an integer load, ptr<->int compare) as; // escaping, and objects located at well-known addresses via platform-specific; // means cannot be considered non-escaping local objects.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/AliasAnalysis.cpp:193,load,load,193,interpreter/llvm-project/llvm/lib/Analysis/AliasAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/AliasAnalysis.cpp,1,['load'],['load']
Performance,"// The isOrdered check is used to ensure that volatiles end up as defs; // (atomics end up as ModRef right now anyway). Until we separate the; // ordering chain from the memory chain, this enables people to see at least; // some relative ordering to volatiles. Note that getClobberingMemoryAccess; // will still give an answer that bypasses other volatile loads. TODO:; // Separate memory aliasing and ordering into two different chains so that; // we can precisely represent both ""what memory will this read/write/is; // clobbered by"" and ""what instructions can I move this past"".",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp:356,load,loads,356,interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp,1,['load'],['loads']
Performance,"// The item is corresponding to the '%m' format specifier, no value is; // populated in the buffer and the runtime is loading the errno value.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/AST/OSLog.h:118,load,loading,118,interpreter/llvm-project/clang/include/clang/AST/OSLog.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/AST/OSLog.h,1,['load'],['loading']
Performance,// The jump-table might have been optimized away.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64CompressJumpTables.cpp:34,optimiz,optimized,34,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64CompressJumpTables.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64CompressJumpTables.cpp,1,['optimiz'],['optimized']
Performance,"// The key rationale for this optimization is that for some kinds of shift; // recurrences, the value of the recurrence ""stabilizes"" to either 0 or -1; // within a finite number of iterations. If the condition guarding the; // backedge (in the sense that the backedge is taken if the condition is true); // is false for the value the shift recurrence stabilizes to, then we know; // that the backedge is taken only a finite number of times.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp:30,optimiz,optimization,30,interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,1,['optimiz'],['optimization']
Performance,"// The largest constant describeable in the StackMap format is 64 bits.; // Potential Optimization: Constants values are sign extended by consumer,; // and thus there are many constants of static type > 64 bits whose value; // happens to be sext(Con64) and could thus be lowered directly.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/StatepointLowering.cpp:86,Optimiz,Optimization,86,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/StatepointLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/StatepointLowering.cpp,1,['Optimiz'],['Optimization']
Performance,// The last copy may be partial. Do an extending load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp:49,load,load,49,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp,1,['load'],['load']
Performance,// The last operand holds the original LoadSDNode::getExtensionType() value,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp:39,Load,LoadSDNode,39,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp,1,['Load'],['LoadSDNode']
Performance,"// The last statement in the block should be the ObjCForCollectionStmt, which; // performs the actual binding to 'element' and determines if there are any; // more items in the collection.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/CFG.cpp:82,perform,performs,82,interpreter/llvm-project/clang/lib/Analysis/CFG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/CFG.cpp,1,['perform'],['performs']
Performance,// The last store may be partial. Do a truncating store. On big-endian; // machines this requires an extending load from the stack slot to ensure; // that the bits are in the right place.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp:111,load,load,111,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp,1,['load'],['load']
Performance,// The latency of dependence chains leading into this zone.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineScheduler.h:7,latency,latency,7,interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineScheduler.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineScheduler.h,1,['latency'],['latency']
Performance,"// The latency of dependence chains leading into this zone.; // For each node scheduled bottom-up: DLat = max DLat, N.Depth.; // For each cycle scheduled: DLat -= 1.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineScheduler.h:7,latency,latency,7,interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineScheduler.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineScheduler.h,1,['latency'],['latency']
Performance,// The latency of mtctr is only justified if there are more than 4; // comparisons that will be removed as a result.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp:7,latency,latency,7,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,1,['latency'],['latency']
Performance,"// The layout splits profile with context information from profile without; // context information. When Thinlto is enabled, ThinLTO postlink phase only; // has to load profile with context information and can skip the other part.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ProfileData/SampleProfWriter.h:164,load,load,164,interpreter/llvm-project/llvm/include/llvm/ProfileData/SampleProfWriter.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ProfileData/SampleProfWriter.h,1,['load'],['load']
Performance,// The leftover modules from the crash are stored in; // <name>.cache/vfs/modules; // Leave it untouched for pcm inspection and provide a clean/empty dir; // path to contain the future generated module cache:; // <name>.cache/vfs/repro-modules,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/Job.cpp:64,cache,cache,64,interpreter/llvm-project/clang/lib/Driver/Job.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/Job.cpp,3,['cache'],['cache']
Performance,"// The legalizer (the caller) is expecting two values from the legalized; // load, so we build a MergeValues node for it. See ExpandUnalignedLoad(); // in LegalizeDAG.cpp which also uses MergeValues.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:77,load,load,77,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,1,['load'],['load']
Performance,"// The library already exist, let's just load it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx:41,load,load,41,core/base/src/TSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx,1,['load'],['load']
Performance,"// The library containing the dictionary for this class was; // loaded and has been unloaded from memory.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TClass.h:64,load,loaded,64,core/meta/inc/TClass.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TClass.h,1,['load'],['loaded']
Performance,"// The library has already been built and loaded.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx:42,load,loaded,42,core/base/src/TSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx,1,['load'],['loaded']
Performance,"// The library is already loaded as the class's dictionary is known.; // Return success.; // Note: the name (cls) is expected to be normalized as it comes either; // from a callbacks (that can/should calculate the normalized name from the; // decl) or from TClass::GetClass (which does also calculate the normalized; // name).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:26,load,loaded,26,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,1,['load'],['loaded']
Performance,// The link register (return address) is saved in the caller's frame; // not the callee's stack frame. So we must get the caller's frame; // address and load the return address at the LR offset from there.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:153,load,load,153,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['load']
Performance,// The list does not exist in our cache. Create it.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/ImmutableList.h:34,cache,cache,34,interpreter/llvm-project/llvm/include/llvm/ADT/ImmutableList.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/ImmutableList.h,1,['cache'],['cache']
Performance,"// The list of available load sizes (in bytes), sorted in decreasing order.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfo.h:25,load,load,25,interpreter/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfo.h,1,['load'],['load']
Performance,"// The list of virtual calls made by this function using; // llvm.type.checked.load intrinsics that do not have all constant integer; // arguments.; // [n x (typeid, offset)]",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Bitcode/LLVMBitCodes.h:79,load,load,79,interpreter/llvm-project/llvm/include/llvm/Bitcode/LLVMBitCodes.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Bitcode/LLVMBitCodes.h,1,['load'],['load']
Performance,"// The load TLS GD address pseudo-instruction ""la.tls.gd"" is used in; // global-dynamic TLS model addressing of global symbols:; // la.tls.gd rdest, symbol; // expands to; // TmpLabel: AUIPC rdest, %tls_gd_pcrel_hi(symbol); // ADDI rdest, rdest, %pcrel_lo(TmpLabel)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp,1,['load'],['load']
Performance,"// The load TLS IE address pseudo-instruction ""la.tls.ie"" is used in; // initial-exec TLS model addressing of global symbols:; // la.tls.ie rdest, symbol; // expands to; // TmpLabel: AUIPC rdest, %tls_ie_pcrel_hi(symbol); // Lx rdest, %pcrel_lo(TmpLabel)(rdest)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp,1,['load'],['load']
Performance,// The load address of a TLS section is not equal to the address of its; // initialization image,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyld.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyld.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyld.cpp,1,['load'],['load']
Performance,"// The load address pseudo-instruction ""la"" is used in PC-relative and; // GOT-indirect addressing of global symbols:; // la rdest, symbol; // is an alias for either (for non-PIC); // lla rdest, symbol; // or (for PIC); // lga rdest, symbol",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp,1,['load'],['load']
Performance,// The load already has the right type.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['load'],['load']
Performance,// The load case works because isNonEscapingLocalObject considers all; // stores to be escapes (it passes true for the StoreCaptures argument; // to PointerMayBeCaptured).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/AliasAnalysis.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Analysis/AliasAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/AliasAnalysis.cpp,1,['load'],['load']
Performance,"// The load didn't work out, but we may still find a store.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp,1,['load'],['load']
Performance,// The load does not alias with GV.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/GlobalsModRef.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Analysis/GlobalsModRef.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/GlobalsModRef.cpp,1,['load'],['load']
Performance,"// The load global address pseudo-instruction ""lga"" is used in GOT-indirect; // addressing of global symbols:; // lga rdest, symbol; // expands to; // TmpLabel: AUIPC rdest, %got_pcrel_hi(symbol); // Lx rdest, %pcrel_lo(TmpLabel)(rdest)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp,1,['load'],['load']
Performance,"// The load intrinsics generate two results (Value, NewBase), stores; // generate one (NewBase). The new base address needs to be stored.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:7,load,load,7,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,1,['load'],['load']
Performance,// The load is only dominated by the store if DomTree says so; // and the number of bits loaded in L is less than or equal to; // the number of bits stored in S.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,2,['load'],"['load', 'loaded']"
Performance,"// The load local address pseudo-instruction ""lla"" is used in PC-relative; // addressing of local symbols:; // lla rdest, symbol; // expands to; // TmpLabel: AUIPC rdest, %pcrel_hi(symbol); // ADDI rdest, rdest, %pcrel_lo(TmpLabel)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp,1,['load'],['load']
Performance,// The load may have dependencies to unanalyzable stores.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ScheduleDAGInstrs.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/CodeGen/ScheduleDAGInstrs.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ScheduleDAGInstrs.cpp,1,['load'],['load']
Performance,// The load must be an extending one and the constant must be within the; // range of the unextended value.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,1,['load'],['load']
Performance,// The load must be used exclusively to store into other pointers for; // us to be able to arbitrarily pre-split it. The stores must also be; // simple to avoid changing semantics.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,1,['load'],['load']
Performance,// The load of the GOT address has an addend of -4,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp,1,['load'],['load']
Performance,// The load uses the register as part of its address making it not; // invariant.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,1,['load'],['load']
Performance,"// The load was previously folded, so this is the only use.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/TwoAddressInstructionPass.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/CodeGen/TwoAddressInstructionPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/TwoAddressInstructionPass.cpp,1,['load'],['load']
Performance,// The load which uses the lowest index.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,1,['load'],['load']
Performance,// The load/store instruction that uses the address from the PLD will; // either use a register (for a store) or define a register (for the; // load). That register will be added as an implicit def to the PLD; // and as an implicit use on the second memory op. This is a precaution; // to prevent future passes from using that register between the two; // instructions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCPreEmitPeephole.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCPreEmitPeephole.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCPreEmitPeephole.cpp,2,['load'],['load']
Performance,"// The load/store pseudo-instruction does a pc-relative load with; // a symbol.; //; // The expansion looks like this; //; // TmpLabel: AUIPC tmp, %pcrel_hi(symbol); // [S|L]X rd, %pcrel_lo(TmpLabel)(tmp)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/AsmParser/RISCVAsmParser.cpp,2,['load'],['load']
Performance,"// The loaded class version is not the same as the version of the code; // which was used to allocate this array. The best we can do is use; // the TVirtualStreamerInfo to try to free up some of the allocated memory.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:7,load,loaded,7,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,1,['load'],['loaded']
Performance,"// The loaded class version is not the same as the version of the code; // which was used to allocate this object. The best we can do is use; // the TVirtualStreamerInfo to try to free up some of the allocated memory.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:7,load,loaded,7,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,1,['load'],['loaded']
Performance,"// The loaded value is unrelated to the pointer argument, no need to; // follow the users of the load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/AttributorAttributes.cpp:7,load,loaded,7,interpreter/llvm-project/llvm/lib/Transforms/IPO/AttributorAttributes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/AttributorAttributes.cpp,2,['load'],"['load', 'loaded']"
Performance,// The loads / stores of the same base are in order. Scan them from first to; // last and check for the following:; // 1. Any def of base.; // 2. Any gaps.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp:7,load,loads,7,interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp,1,['load'],['loads']
Performance,// The loads must not depend on one another.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:7,load,loads,7,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['loads']
Performance,// The locality degree is the opposite of the cache speed.; // Put the number the other way around.; // The encoding starts at 0 for level 1,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:46,cache,cache,46,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,2,['cache'],['cache']
Performance,"// The loop below is emitting the value starting at least significant byte,; // so we need to perform a byte-swap to get the byte order correct in case; // of a big-endian target.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfExpression.cpp:94,perform,perform,94,interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfExpression.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfExpression.cpp,1,['perform'],['perform']
Performance,"// The loop branch contains the parallel loop metadata. In order to ensure; // that any parallel-loop-unaware optimization pass hasn't added loop-carried; // dependencies (thus converted the loop back to a sequential loop), check; // that all the memory instructions in the loop belong to an access group that; // is parallel to this loop.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LoopInfo.cpp:110,optimiz,optimization,110,interpreter/llvm-project/llvm/lib/Analysis/LoopInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LoopInfo.cpp,1,['optimiz'],['optimization']
Performance,"// The lowest index used in any load. (The lowest ""i"" for each x[i].)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:32,load,load,32,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,1,['load'],['load']
Performance,"// The lvalue-to-rvalue conversion would have no effect for an array.; // It's implausible that the programmer expected this to result in a; // volatile array load, so don't warn.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/Expr.cpp:159,load,load,159,interpreter/llvm-project/clang/lib/AST/Expr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/Expr.cpp,1,['load'],['load']
Performance,"// The machine model may explicitly specify an invalid latency, which; // effectively means infinite latency. Since users of the TargetSchedule API; // don't know how to handle this, we convert it to a very large latency that is; // easy to distinguish when debugging the DAG but won't induce overflow.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/TargetSchedule.cpp:55,latency,latency,55,interpreter/llvm-project/llvm/lib/CodeGen/TargetSchedule.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/TargetSchedule.cpp,3,['latency'],['latency']
Performance,"// The manipulations performed when we're looking through an insertvalue or; // an extractvalue would happen at the front of the RetPath list, so since; // we have to copy it anyway it's more efficient to create a reversed copy.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/Analysis.cpp:21,perform,performed,21,interpreter/llvm-project/llvm/lib/CodeGen/Analysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/Analysis.cpp,1,['perform'],['performed']
Performance,// The map that caches the threshold values. The keys are the percentile; // cutoff values and the values are the corresponding threshold values.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/ProfileSummaryInfo.h:16,cache,caches,16,interpreter/llvm-project/llvm/include/llvm/Analysis/ProfileSummaryInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/ProfileSummaryInfo.h,1,['cache'],['caches']
Performance,// The mapping is:; // 0 .. SQ_MAX_PGM_VGPRS-1 real VGPRs; // SQ_MAX_PGM_VGPRS .. NUM_ALL_VGPRS-1 extra VGPR-like slots; // NUM_ALL_VGPRS .. NUM_ALL_VGPRS+SQ_MAX_PGM_SGPRS-1 real SGPRs; // We reserve a fixed number of VGPR slots in the scoring tables for; // special tokens like SCMEM_LDS (needed for buffer load to LDS).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInsertWaitcnts.cpp:308,load,load,308,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInsertWaitcnts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInsertWaitcnts.cpp,1,['load'],['load']
Performance,"// The mask Value, if we're looking at a masked load/store.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Instrumentation/AddressSanitizerCommon.h:48,load,load,48,interpreter/llvm-project/llvm/include/llvm/Transforms/Instrumentation/AddressSanitizerCommon.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Instrumentation/AddressSanitizerCommon.h,1,['load'],['load']
Performance,// The mask is constant or extended from a bool vector. Convert this x86; // intrinsic to the LLVM intrinsic to allow target-independent optimizations.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstCombineIntrinsic.cpp:137,optimiz,optimizations,137,interpreter/llvm-project/llvm/lib/Target/X86/X86InstCombineIntrinsic.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstCombineIntrinsic.cpp,2,['optimiz'],['optimizations']
Performance,"// The maximum number of memoization entries to store.; // 10k has been experimentally found to give a good trade-off; // of performance vs. memory consumption by running matcher; // that match on every statement over a very large codebase.; //; // FIXME: Do some performance optimization in general and; // revisit this number; also, put up micro-benchmarks that we can; // optimize this on.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/ASTMatchers/ASTMatchFinder.cpp:125,perform,performance,125,interpreter/llvm-project/clang/lib/ASTMatchers/ASTMatchFinder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/ASTMatchers/ASTMatchFinder.cpp,4,"['optimiz', 'perform']","['optimization', 'optimize', 'performance']"
Performance,"// The merged loads are required to have the same incoming chain, so; // using the first's chain is acceptable.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:14,load,loads,14,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['loads']
Performance,"// The metadata sections are parallel arrays. Optimizers (e.g.; // GlobalOpt/ConstantMerge) may not discard associated sections as a unit, so; // we conservatively retain all unconditionally in the compiler.; //; // On ELF and Mach-O, the linker can guarantee the associated sections will be; // retained or discarded as a unit, so llvm.compiler.used is sufficient.; // Similarly on COFF, if prof data is not referenced by code we use one comdat; // and ensure this GC property as well. Otherwise, we have to conservatively; // make all of the sections retained by the linker.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/InstrProfiling.cpp:46,Optimiz,Optimizers,46,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/InstrProfiling.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/InstrProfiling.cpp,1,['Optimiz'],['Optimizers']
Performance,// The method here to extract the awaiter decl is not precise.; // This is intentional. Since it is hard to perform the analysis in the; // frontend due to the complexity of C++'s type systems.; // And we prefer to perform such analysis in the middle end since it is; // easier to implement and more powerful.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaCoroutine.cpp:108,perform,perform,108,interpreter/llvm-project/clang/lib/Sema/SemaCoroutine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaCoroutine.cpp,2,['perform'],['perform']
Performance,// The microMIPS size reduction pass performs instruction reselection for; // instructions which can be remapped to a 16 bit instruction.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsTargetMachine.cpp:37,perform,performs,37,interpreter/llvm-project/llvm/lib/Target/Mips/MipsTargetMachine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsTargetMachine.cpp,1,['perform'],['performs']
Performance,// The minimal length of the vector is limited by the real length of vector; // operations performed on the current platform. That's why several final; // reduction operations are performed on the vectors with the same; // architecture-dependent length.; // By default reductions need one shuffle per reduction level.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h:91,perform,performed,91,interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,2,['perform'],['performed']
Performance,// The minimal length of the vector is limited by the real length of vector; // operations performed on the current platform. That's why several final; // reduction opertions are perfomed on the vectors with the same; // architecture-dependent length.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h:91,perform,performed,91,interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,1,['perform'],['performed']
Performance,// The minimum call count to optimize memory intrinsic calls.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/PGOMemOPSizeOpt.cpp:29,optimiz,optimize,29,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/PGOMemOPSizeOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/PGOMemOPSizeOpt.cpp,1,['optimiz'],['optimize']
Performance,// The minimum width used by the recurrence is found by checking for; // casts on its operands. The minimum width is used by the vectorizer; // when finding the widest type for in-loop reductions without any; // loads/stores.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/IVDescriptors.cpp:212,load,loads,212,interpreter/llvm-project/llvm/lib/Analysis/IVDescriptors.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/IVDescriptors.cpp,1,['load'],['loads']
Performance,// The module loader will assume we're trying to import the module that; // we're building if `LangOpts.CurrentModule` equals to 'ModuleName'.; // Change the value for `LangOpts.CurrentModule` temporarily to make the; // module loader work properly.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaModule.cpp:14,load,loader,14,interpreter/llvm-project/clang/lib/Sema/SemaModule.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaModule.cpp,2,['load'],['loader']
Performance,"// The module may be cached, this helps handling it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/LTO/LTO.cpp:21,cache,cached,21,interpreter/llvm-project/llvm/lib/LTO/LTO.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/LTO/LTO.cpp,2,['cache'],['cached']
Performance,"// The more common cases of a phi with no constant operands or just one; // variable operand are handled by FoldPHIArgOpIntoPHI() and foldOpIntoPhi(); // respectively. foldOpIntoPhi() wants to do the opposite transform that is; // performed here. It tries to replicate a cast in the phi operand's basic; // block to expose other folding opportunities. Thus, InstCombine will; // infinite loop without this check.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombinePHI.cpp:231,perform,performed,231,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombinePHI.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombinePHI.cpp,1,['perform'],['performed']
Performance,"// The motivating example is:; //; // MUL Other MUL_op1 MUL_op2 Other; // \ / \ | /; // ADD/SUB => MADD/MSUB; // (=Root) (=NewRoot); // The DAGCombine code always replaced MUL + ADD/SUB by MADD. While this is; // usually beneficial for code size it unfortunately can hurt performance; // when the ADD is on the critical path, but the MUL is not. With the; // substitution the MUL becomes part of the critical path (in form of the; // MADD) and can lengthen it on architectures where the MADD latency is; // longer than the ADD latency.; //; // For each instruction we check if it can be the root of a combiner; // pattern. Then for each pattern the new code sequence in form of MI is; // generated and evaluated. When the efficiency criteria (don't lengthen; // critical path, don't use more resources) is met the new sequence gets; // hooked up into the basic block before the old sequence is removed.; //; // The algorithm does not try to evaluate all patterns and pick the best.; // This is only an artificial restriction though. In practice there is; // mostly one pattern, and getMachineCombinerPatterns() can order patterns; // based on an internal cost heuristic. If; // machine-combiner-verify-pattern-order is enabled, all patterns are; // checked to ensure later patterns do not provide better latency savings.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineCombiner.cpp:272,perform,performance,272,interpreter/llvm-project/llvm/lib/CodeGen/MachineCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineCombiner.cpp,4,"['latency', 'perform']","['latency', 'performance']"
Performance,"// The name of the performance tree",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proofbench/inc/TProofPerfAnalysis.h:19,perform,performance,19,proof/proofbench/inc/TProofPerfAnalysis.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proofbench/inc/TProofPerfAnalysis.h,1,['perform'],['performance']
Performance,"// The name of the type being destroyed is a dependent name, and we; // couldn't find anything useful in scope. Just store the identifier and; // it's location, and we'll perform (qualified) name lookup again at; // template instantiation time.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp:171,perform,perform,171,interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp,1,['perform'],['perform']
Performance,"// The named return value optimization: allocate this variable in the; // return slot, so that we can elide the copy when returning this; // variable (C++0x [class.copy]p34).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDecl.cpp:26,optimiz,optimization,26,interpreter/llvm-project/clang/lib/CodeGen/CGDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDecl.cpp,1,['optimiz'],['optimization']
Performance,// The narrow load will be offset from the base address of the old load if; // we are extracting from something besides index 0 (little-endian).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:14,load,load,14,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,['load'],['load']
Performance,"// The narrowing should be profitable, the load/store operation should be; // legal (or custom) and the store size should be equal to the NewVT width.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:43,load,load,43,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,"// The native instructions return -1 on 0 input. Optimize out a select that; // produces -1 on 0.; //; // TODO: If zero is not undef, we could also do this if the output is compared; // against the bitwidth.; //; // TODO: Should probably combine against FFBH_U32 instead of ctlz directly.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelLowering.cpp:49,Optimiz,Optimize,49,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelLowering.cpp,1,['Optimiz'],['Optimize']
Performance,// The new BUILD_VECTOR node has the potential to be further optimized.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:61,optimiz,optimized,61,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['optimiz'],['optimized']
Performance,// The new masked load has an undef pass-through operand. The select uses the; // original pass-through operand.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,load,load,18,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,// The new memory operation must have the same position as the old load in; // terms of memory dependency. Create a TokenFactor for the old load and new; // memory operation and update uses of the old load's output chain to use that; // TokenFactor.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp:67,load,load,67,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,3,['load'],['load']
Performance,"// The next call locks the interpreter mutex. The result is cached in the; // fSignature data member.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TFunction.cxx:60,cache,cached,60,core/meta/src/TFunction.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TFunction.cxx,1,['cache'],['cached']
Performance,"// The next call locks the interpreter mutex.; // The result is cached in the fSignature data member.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TFunction.cxx:64,cache,cached,64,core/meta/src/TFunction.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TFunction.cxx,1,['cache'],['cached']
Performance,"// The next optimizations are desirable only if SELECT_CC can be lowered.; // fold (sint_to_fp (setcc x, y, cc)) -> (select (setcc x, y, cc), -1.0, 0.0)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:12,optimiz,optimizations,12,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['optimiz'],['optimizations']
Performance,"// The next two checks allow COPY between physical and virtual registers,; // when the virtual register has a scalable size and the physical register; // has a fixed size. These checks allow COPY between *potentialy* mismatched; // sizes. However, once RegisterBankSelection occurs, MachineVerifier should; // be able to resolve a fixed size for the scalable vector, and at that; // point this function will know for sure whether the sizes are mismatched; // and correctly report a size mismatch.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineVerifier.cpp:110,scalab,scalable,110,interpreter/llvm-project/llvm/lib/CodeGen/MachineVerifier.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineVerifier.cpp,2,['scalab'],['scalable']
Performance,// The next two loops are part of the same conceptual operation. We need to; // insert a store to the alloca after the original def and at each; // redefinition. We need to insert a load before each use. These are split; // into distinct loops for performance reasons.; // Update gc pointer after each statepoint: either store a relocated value or; // null (if no relocated value was found for this gc pointer and it is not a; // gc_result). This must happen before we update the statepoint with load of; // alloca otherwise we lose the link between statepoint and old def.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp:182,load,load,182,interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,3,"['load', 'perform']","['load', 'performance']"
Performance,"// The node we are looking at matches with the pattern, check if we can; // replace it with a single (possibly zero-extended) load and bswap + shift if; // needed.; // If the load needs byte swap check if the target supports it",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:126,load,load,126,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,['load'],['load']
Performance,// The noinline and the asm prevent calls to this function from being; // optimized out.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/TargetProcess/JITLoaderGDB.cpp:74,optimiz,optimized,74,interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/TargetProcess/JITLoaderGDB.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/TargetProcess/JITLoaderGDB.cpp,1,['optimiz'],['optimized']
Performance,// The number of loads of a legal type it will take to represent a load; // of the unlegalized vector type.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h:17,load,loads,17,interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,2,['load'],"['load', 'loads']"
Performance,"// The number of uOps for load / store multiple are determined by the number; // registers.; //; // On Cortex-A8, each pair of register loads / stores can be scheduled on the; // same cycle. The scheduling for the first load / store must be done; // separately by assuming the address is not 64-bit aligned.; //; // On Cortex-A9, the formula is simply (#reg / 2) + (#reg % 2). If the address; // is not 64-bit aligned, then AGU would take an extra cycle. For VFP / NEON; // load / store multiple, the formula is (#reg / 2) + (#reg % 2) + 1.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp:26,load,load,26,interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp,4,['load'],"['load', 'loads']"
Performance,"// The object was allocated using code for the same class version; // as is loaded now. We may proceed without worry.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:76,load,loaded,76,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,2,['load'],['loaded']
Performance,"// The obvious transform is to shift the switch condition right and emit a; // check that the condition actually cleanly divided by GCD, i.e.; // C & (1 << Shift - 1) == 0; // inserting a new CFG edge to handle the case where it didn't divide cleanly.; //; // A cheaper way of doing this is a simple ROTR(C, Shift). This performs the; // shift and puts the shifted-off bits in the uppermost bits. If any of these; // are nonzero then the switch condition will be very large and will hit the; // default case.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp:321,perform,performs,321,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp,1,['perform'],['performs']
Performance,"// The offset cache contains the location of the \n for the specified line,; // we want the start of the line. As such, we look for the previous entry.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/SourceMgr.cpp:14,cache,cache,14,interpreter/llvm-project/llvm/lib/Support/SourceMgr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/SourceMgr.cpp,1,['cache'],['cache']
Performance,"// The offset of this load from the base pointer, in bytes.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp:22,load,load,22,interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,1,['load'],['load']
Performance,// The only condition under which we can omit the actual extend instruction:; // - The value is a positive constant; // - The value comes from a load that isn't a sign-extending load; // An ISD::TRUNCATE needs to be zero-extended unless it is fed by a zext.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp:145,load,load,145,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,2,['load'],['load']
Performance,// The only other translation we can do is to integral loads with !range; // metadata.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/Local.cpp:55,load,loads,55,interpreter/llvm-project/llvm/lib/Transforms/Utils/Local.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/Local.cpp,1,['load'],['loads']
Performance,// The only supported nontemporal loads are for aligned vectors of 16 or 32; // bytes. Note that 32-byte nontemporal vector loads are supported by AVX2; // (the equivalent stores only require AVX).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:34,load,loads,34,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,2,['load'],['loads']
Performance,"// The only way FirstUnused would not be set is if every single entry in the; // table were Present. But this would violate the load factor constraints; // that we impose, so it should never happen.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/DebugInfo/PDB/Native/HashTable.h:128,load,load,128,interpreter/llvm-project/llvm/include/llvm/DebugInfo/PDB/Native/HashTable.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/DebugInfo/PDB/Native/HashTable.h,1,['load'],['load']
Performance,// The opcode used for performing the comparison.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMInstructionSelector.cpp:23,perform,performing,23,interpreter/llvm-project/llvm/lib/Target/ARM/ARMInstructionSelector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMInstructionSelector.cpp,1,['perform'],['performing']
Performance,"// The open performance file",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proofbench/inc/TProofPerfAnalysis.h:12,perform,performance,12,proof/proofbench/inc/TProofPerfAnalysis.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proofbench/inc/TProofPerfAnalysis.h,1,['perform'],['performance']
Performance,"// The operator requires a prvalue, so perform lvalue conversions.; // Only do this if we might plausibly end with a pointer, as otherwise; // this was likely to be intended to be a '.'.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp:39,perform,perform,39,interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp,1,['perform'],['perform']
Performance,"// The optimisations below currently assume we are dealing with fixed length; // vectors. It is possible to add support for scalable vectors, but at the; // moment we've done no analysis to prove whether they are profitable or not.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:124,scalab,scalable,124,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['scalab'],['scalable']
Performance,"// The optimization cannot be applied for all the predicates because; // of the way FMINNUM/FMAXNUM and FMINNUM_IEEE/FMAXNUM_IEEE handle; // NaNs. For FMINNUM_IEEE/FMAXNUM_IEEE, the optimization cannot be; // applied at all if one of the operands is a signaling NaN.; // It is safe to use FMINNUM_IEEE/FMAXNUM_IEEE if all the operands; // are non NaN values.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:7,optimiz,optimization,7,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,['optimiz'],['optimization']
Performance,// The optimization is profitable only if LHS can be removed in the end.; // In other words LHS should be used (directly or indirectly) by I only.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NaryReassociate.cpp:7,optimiz,optimization,7,interpreter/llvm-project/llvm/lib/Transforms/Scalar/NaryReassociate.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NaryReassociate.cpp,1,['optimiz'],['optimization']
Performance,// The optimization level matches; // CompilerInvocation.cpp:getOptimizationLevel().,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/CommonArgs.cpp:7,optimiz,optimization,7,interpreter/llvm-project/clang/lib/Driver/ToolChains/CommonArgs.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/CommonArgs.cpp,1,['optimiz'],['optimization']
Performance,"// The optimization removes store aspect of the atomicrmw. Therefore, cache; // must be flushed if the atomic ordering had a release semantics. This is; // not necessary a fence, a release fence just coincides to do that flush.; // Avoid replacing of an atomicrmw with a release semantics.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:7,optimiz,optimization,7,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,2,"['cache', 'optimiz']","['cache', 'optimization']"
Performance,// The optimization to convert the D-Form load/store into its X-Form; // counterpart should only occur if the source value offset of the load/; // store is 0. This also means that The offset should always be undefined.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp:7,optimiz,optimization,7,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,3,"['load', 'optimiz']","['load', 'optimization']"
Performance,// The optimized Reg is not alive through Flow blocks anymore.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIOptimizeVGPRLiveRange.cpp:7,optimiz,optimized,7,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIOptimizeVGPRLiveRange.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIOptimizeVGPRLiveRange.cpp,1,['optimiz'],['optimized']
Performance,"// The optimizer likes to eliminate bitcasts leading into variadic; // calls, but that messes with our invariants. Re-insert the; // bitcast and ignore this type mismatch.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Coroutines/Coroutines.cpp:7,optimiz,optimizer,7,interpreter/llvm-project/llvm/lib/Transforms/Coroutines/Coroutines.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Coroutines/Coroutines.cpp,1,['optimiz'],['optimizer']
Performance,// The optimizer may remove local variables. If there is an interest; // to preserve variable info in such situation then stash it in a; // named mdnode.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/DIBuilder.cpp:7,optimiz,optimizer,7,interpreter/llvm-project/llvm/lib/IR/DIBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/DIBuilder.cpp,1,['optimiz'],['optimizer']
Performance,"// The optimizer might have replaced fcmp oeq %x, %x with fcmp ord %x, 0.0.; // We don't have to materialize a zero constant for this case and can just use; // %x again on the RHS.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FastISel.cpp:7,optimiz,optimizer,7,interpreter/llvm-project/llvm/lib/Target/X86/X86FastISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FastISel.cpp,2,['optimiz'],['optimizer']
Performance,"// The optimizer might have replaced fcmp oeq %x, %x with fcmp ord %x,; // 0.0.; // We don't have to materialize a zero constant for this case and can just; // use %x again on the RHS.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FastISel.cpp:7,optimiz,optimizer,7,interpreter/llvm-project/llvm/lib/Target/X86/X86FastISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FastISel.cpp,1,['optimiz'],['optimizer']
Performance,"// The order in which branches appear in ImmBranches is approximately their; // order within the function body. By visiting later branches first, we reduce; // the distance between earlier forward branches and their targets, making it; // more likely that the cbn?z optimization, which can only apply to forward; // branches, will succeed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMConstantIslandPass.cpp:266,optimiz,optimization,266,interpreter/llvm-project/llvm/lib/Target/ARM/ARMConstantIslandPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMConstantIslandPass.cpp,1,['optimiz'],['optimization']
Performance,// The original code has one big load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:33,load,load,33,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,"// The original definition (or at least its debug info - if the variable is; // internalized and optimized away) will remain in the source module, so; // there's no need to import them.; // If LLVM ever does more advanced optimizations on global variables; // (removing/localizing write operations, for instance) that can track; // through debug info, this decision may need to be revisited - but do so; // with care when it comes to debug info size. Emitting small CUs containing; // only a few imported entities into every destination module may be very; // size inefficient.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Linker/IRMover.cpp:97,optimiz,optimized,97,interpreter/llvm-project/llvm/lib/Linker/IRMover.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Linker/IRMover.cpp,2,['optimiz'],"['optimizations', 'optimized']"
Performance,// The original load instruction.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:16,load,load,16,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,"// The original load itself didn't wrap, so an offset within it doesn't.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:16,load,load,16,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,"// The pass ""x86 speculative load hardening"" always attaches symbols to; // call instructions. We need copy it form old instruction.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/TargetInstrInfo.cpp:29,load,load,29,interpreter/llvm-project/llvm/lib/CodeGen/TargetInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/TargetInstrInfo.cpp,1,['load'],['load']
Performance,"// The pass needs to identify integer add/sub reductions of 16-bit vector; // multiplications.; // To use SMLAD:; // 1) we first need to find integer add then look for this pattern:; //; // acc0 = ...; // ld0 = load i16; // sext0 = sext i16 %ld0 to i32; // ld1 = load i16; // sext1 = sext i16 %ld1 to i32; // mul0 = mul %sext0, %sext1; // ld2 = load i16; // sext2 = sext i16 %ld2 to i32; // ld3 = load i16; // sext3 = sext i16 %ld3 to i32; // mul1 = mul i32 %sext2, %sext3; // add0 = add i32 %mul0, %acc0; // acc1 = add i32 %add0, %mul1; //; // Which can be selected to:; //; // ldr r0; // ldr r1; // smlad r2, r0, r1, r2; //; // If constants are used instead of loads, these will need to be hoisted; // out and into a register.; //; // If loop invariants are used instead of loads, these need to be packed; // before the loop begins.; //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMParallelDSP.cpp:211,load,load,211,interpreter/llvm-project/llvm/lib/Target/ARM/ARMParallelDSP.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMParallelDSP.cpp,6,['load'],"['load', 'loads']"
Performance,// The pass-through vector for an x86 masked load is a zero vector.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstCombineIntrinsic.cpp:45,load,load,45,interpreter/llvm-project/llvm/lib/Target/X86/X86InstCombineIntrinsic.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstCombineIntrinsic.cpp,1,['load'],['load']
Performance,// The per-location information collected for producing an optimization report.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-opt-report/OptReport.cpp:59,optimiz,optimization,59,interpreter/llvm-project/llvm/tools/llvm-opt-report/OptReport.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-opt-report/OptReport.cpp,1,['optimiz'],['optimization']
Performance,// The percent threshold to optimize memory intrinsic calls.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/PGOMemOPSizeOpt.cpp:28,optimiz,optimize,28,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/PGOMemOPSizeOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/PGOMemOPSizeOpt.cpp,1,['optimiz'],['optimize']
Performance,"// The performance tree",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proofbench/inc/TProofPerfAnalysis.h:7,perform,performance,7,proof/proofbench/inc/TProofPerfAnalysis.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proofbench/inc/TProofPerfAnalysis.h,1,['perform'],['performance']
Performance,"// The pipe signal handler must be installed before any other handlers are; // registered. This is because the Unix \ref RegisterHandlers function does; // not perform a sigaction() for SIGPIPE unless a one-shot handler is; // present, to allow long-lived processes (like lldb) to fully opt-out of; // llvm's SIGPIPE handling and ignore the signal safely.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/InitLLVM.cpp:160,perform,perform,160,interpreter/llvm-project/llvm/lib/Support/InitLLVM.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/InitLLVM.cpp,1,['perform'],['perform']
Performance,// The pointer loaded from the global can only be used in simple ways:; // we allow addressing of it and loading storing to it. We do *not* allow; // storing the loaded pointer somewhere else or passing to a function.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/GlobalsModRef.cpp:15,load,loaded,15,interpreter/llvm-project/llvm/lib/Analysis/GlobalsModRef.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/GlobalsModRef.cpp,3,['load'],"['loaded', 'loading']"
Performance,// The pointer to the thread's TLS data area is at the TLS Index scaled by 4; // offset into the TLSArray.; // Load the TLS index from the C runtime,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:111,Load,Load,111,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['Load'],['Load']
Performance,"// The postorder_ref_sccs range we are walking is lazily constructed, so; // we only push the first one onto the worklist. The worklist allows us; // to capture *new* RefSCCs created during transformations.; //; // We really want to form RefSCCs lazily because that makes them cheaper; // to update as the program is simplified and allows us to have greater; // cache locality as forming a RefSCC touches all the parts of all the; // functions within that RefSCC.; //; // We also eagerly increment the iterator to the next position because; // the CGSCC passes below may delete the current RefSCC.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CGSCCPassManager.cpp:362,cache,cache,362,interpreter/llvm-project/llvm/lib/Analysis/CGSCCPassManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CGSCCPassManager.cpp,1,['cache'],['cache']
Performance,// The preferred load address of each executable segment.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.h:17,load,load,17,interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.h,1,['load'],['load']
Performance,// The preferred load address of the executable segment.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ProfileData/RawMemProfReader.h:17,load,load,17,interpreter/llvm-project/llvm/include/llvm/ProfileData/RawMemProfReader.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ProfileData/RawMemProfReader.h,1,['load'],['load']
Performance,"// The preprocessor cache of macro expanded tokens owns these tokens,not us.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/TokenLexer.cpp:20,cache,cache,20,interpreter/llvm-project/clang/lib/Lex/TokenLexer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/TokenLexer.cpp,1,['cache'],['cache']
Performance,"// The presence of the following lane-sensitive operations in a; // web will kill the optimization, at least for now. For these; // we do nothing, causing the optimization to fail.; // FIXME: Some of these could be permitted with special handling,; // and will be phased in as time permits.; // FIXME: There is no simple and maintainable way to express a set; // of opcodes having a common attribute in TableGen. Should this; // change, this is a prime candidate to use such a mechanism.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp:86,optimiz,optimization,86,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp,2,['optimiz'],['optimization']
Performance,// The processing of the data loaded by the aligned loads; // needs to be inserted after the data is available.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp:30,load,loaded,30,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp,2,['load'],"['loaded', 'loads']"
Performance,// The processor's time-stamp counter (a 64-bit MSR) is stored into the; // EDX:EAX registers. EDX is loaded with the high-order 32 bits of the MSR; // and the EAX register is loaded with the low-order 32 bits.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:102,load,loaded,102,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,2,['load'],['loaded']
Performance,// The promotion is neutral but it may help folding the sign extension in; // loads for instance.; // Check that we did not create an illegal instruction.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:78,load,loads,78,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,1,['load'],['loads']
Performance,"// The proposed shuffle may be trivial, in which case we shouldn't; // perform the combine.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineVectorOps.cpp:71,perform,perform,71,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineVectorOps.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineVectorOps.cpp,1,['perform'],['perform']
Performance,// The query's Size is greater than the cached one. Throw out the; // cached data and proceed with the query at the greater size.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp:40,cache,cached,40,interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,2,['cache'],['cached']
Performance,// The queue of and/or/xor i1 instructions to be potentially folded.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTDC.cpp:7,queue,queue,7,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTDC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTDC.cpp,1,['queue'],['queue']
Performance,// The raw content of the payload of the load command (located right after the; // corresponding struct). In some cases it is either empty or can be; // copied-over without digging into its structure.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObject.h:41,load,load,41,interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObject.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObject.h,1,['load'],['load']
Performance,"// The raw dword aligned data component of the load. The only legal cases; // where this matters should be when using the packed D16 format, for; // s16 -> <2 x s16>, and <3 x s16> -> <4 x s16>,",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp:47,load,load,47,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,1,['load'],['load']
Performance,// The reaching def of LRExtRR at load/store node should be same as the; // one reaching at the SN.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonOptAddrMode.cpp:34,load,load,34,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonOptAddrMode.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonOptAddrMode.cpp,1,['load'],['load']
Performance,"// The reader needs to switch to a type server, to process the types from; // the server. We need to keep the original input source, as reading other; // sections will require the input associated with the loaded object file.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DebugInfo/LogicalView/Readers/LVCodeViewReader.cpp:206,load,loaded,206,interpreter/llvm-project/llvm/lib/DebugInfo/LogicalView/Readers/LVCodeViewReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DebugInfo/LogicalView/Readers/LVCodeViewReader.cpp,1,['load'],['loaded']
Performance,// The reassociate transformation for FP operations is performed only; // if unsafe algebra is permitted by FastMathFlags. Propagate those flags; // to the newly generated operations.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/Reassociate.cpp:55,perform,performed,55,interpreter/llvm-project/llvm/lib/Transforms/Scalar/Reassociate.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/Reassociate.cpp,1,['perform'],['performed']
Performance,"// The record forms set the condition register based on a signed comparison; // with zero (see comments in optimizeCompareInstr). Since we can't do the; // equality checks in post-RA, we are more restricted on a unsigned; // comparison.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp:107,optimiz,optimizeCompareInstr,107,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,1,['optimiz'],['optimizeCompareInstr']
Performance,"// The record-form instructions set CR bit based on signed comparison; // against 0. We try to convert a compare against 1 or -1 into a compare; // against 0 to exploit record-form instructions. For example, we change; // the condition ""greater than -1"" into ""greater than or equal to 0""; // and ""less than 1"" into ""less than or equal to 0"".; // Since we optimize comparison based on a specific branch condition,; // we don't optimize if condition code is used by more than once.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp:355,optimiz,optimize,355,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,2,['optimiz'],['optimize']
Performance,// The register is live through the path If->Flow or Flow->Endif.; // we should not optimize for such cases.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIOptimizeVGPRLiveRange.cpp:84,optimiz,optimize,84,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIOptimizeVGPRLiveRange.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIOptimizeVGPRLiveRange.cpp,1,['optimiz'],['optimize']
Performance,"// The register which is not null checked should be part of the Displacement; // calculation, otherwise we do not know whether the Displacement is made up; // by some symbolic values.; // This matters because we do not want to incorrectly assume that load from; // falls in the zeroth faulting page in the ""sane offset check"" below.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ImplicitNullChecks.cpp:251,load,load,251,interpreter/llvm-project/llvm/lib/CodeGen/ImplicitNullChecks.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ImplicitNullChecks.cpp,1,['load'],['load']
Performance,"// The relative offset to the alignment assumption did not yield a constant,; // but we should try harder: if we assume that a is 32-byte aligned, then in; // for (i = 0; i < 1024; i += 4) r += a[i]; not all of the loads from a are; // 32-byte aligned, but instead alternate between 32 and 16-byte alignment.; // As a result, the new alignment will not be a constant, but can still; // be improved over the default (of 4) to 16.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/AlignmentFromAssumptions.cpp:215,load,loads,215,interpreter/llvm-project/llvm/lib/Transforms/Scalar/AlignmentFromAssumptions.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/AlignmentFromAssumptions.cpp,1,['load'],['loads']
Performance,"// The relative order of LChild and RChild is a tiebreaker when; // - locs expand to the same location (occurs in macro arg expansion); // - one loc is a parent of the other (we consider the parent as ""first""); // For the parent entry to be first, its invalid child file ID must; // compare smaller to the valid child file ID of the other entry.; // However loaded FileIDs are <0, so we perform *unsigned* comparison!; // This changes the relative order of local vs loaded FileIDs, but it; // doesn't matter as these are never mixed in macro expansion.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/SourceManager.cpp:358,load,loaded,358,interpreter/llvm-project/clang/lib/Basic/SourceManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/SourceManager.cpp,3,"['load', 'perform']","['loaded', 'perform']"
Performance,// The remaining case is packed with a sequence of dsll and ori with zeros; // being omitted and any neighbouring dsll's being coalesced.; // The highest 32-bit's are equivalent to a 32-bit immediate load.; // Load bits 32-63 of ImmValue into bits 0-31 of the temporary register.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/AsmParser/MipsAsmParser.cpp:200,load,load,200,interpreter/llvm-project/llvm/lib/Target/Mips/AsmParser/MipsAsmParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/AsmParser/MipsAsmParser.cpp,2,"['Load', 'load']","['Load', 'load']"
Performance,"// The remaining optimizations require the format string to be ""%s"" or ""%c""; // and have an extra operand.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp:17,optimiz,optimizations,17,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp,3,['optimiz'],['optimizations']
Performance,// The requesting module for the lookup we cached.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Lex/HeaderSearch.h:43,cache,cached,43,interpreter/llvm-project/clang/include/clang/Lex/HeaderSearch.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Lex/HeaderSearch.h,1,['cache'],['cached']
Performance,// The restriction on `FoundRHS` be lifted easily -- it exists only to; // reduce the compile time impact of this optimization.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp:114,optimiz,optimization,114,interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,1,['optimiz'],['optimization']
Performance,"// The result may still be based on assumptions higher up in the chain.; // Remember it, so it can be purged from the cache later.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/BasicAliasAnalysis.cpp:118,cache,cache,118,interpreter/llvm-project/llvm/lib/Analysis/BasicAliasAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/BasicAliasAnalysis.cpp,1,['cache'],['cache']
Performance,// The result of a comparison between implicit conversion; // sequences. Use Sema::CompareImplicitConversionSequences to; // actually perform the comparison.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Sema/Overload.h:134,perform,perform,134,interpreter/llvm-project/clang/include/clang/Sema/Overload.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Sema/Overload.h,1,['perform'],['perform']
Performance,"// The result of a load is not alloca-derived (unless an alloca has; // otherwise escaped, but this is a local analysis).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/TailRecursionElimination.cpp:19,load,load,19,interpreter/llvm-project/llvm/lib/Transforms/Scalar/TailRecursionElimination.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/TailRecursionElimination.cpp,1,['load'],['load']
Performance,// The result of load,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:17,load,load,17,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['load'],['load']
Performance,// The result of the load is only i32. It's the subreg_to_reg that makes; // it into an i64.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelDAGToDAG.cpp:21,load,load,21,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelDAGToDAG.cpp,3,['load'],['load']
Performance,"// The result type is legal, but the input type is illegal. If splitting; // ends up with the result type of each half still being legal, just; // do that. If, however, that would result in an illegal result type,; // we can try to get more clever with power-two vectors. Specifically,; // split the input type, but also widen the result element size, then; // concatenate the halves and truncate again. For example, consider a target; // where v8i8 is legal and v8i32 is not (ARM, which doesn't have 256-bit; // vectors). To perform a ""%res = v8i8 trunc v8i32 %in"" we do:; // %inlo = v4i32 extract_subvector %in, 0; // %inhi = v4i32 extract_subvector %in, 4; // %lo16 = v4i16 trunc v4i32 %inlo; // %hi16 = v4i16 trunc v4i32 %inhi; // %in16 = v8i16 concat_vectors v4i16 %lo16, v4i16 %hi16; // %res = v8i8 trunc v8i16 %in16; //; // Without this transform, the original truncate would end up being; // scalarized, which is pretty much always a last resort.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp:526,perform,perform,526,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp,1,['perform'],['perform']
Performance,// The right shift amount in bits from the original load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:52,load,load,52,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,"// The rule was a cached element for a read, rule, the real offset is in the; // next element (the one for the rule itself).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfoWriteBuffer.cxx:18,cache,cached,18,io/io/src/TStreamerInfoWriteBuffer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfoWriteBuffer.cxx,1,['cache'],['cached']
Performance,"// The rules are:; // - If there are any pointer types in the chain, use an integer type.; // - Prefer an integer type if it appears in the chain.; // - Otherwise, use the first type in the chain.; //; // The rule about pointer types is a simplification when we merge e.g. a load; // of a ptr and a double. There's no direct conversion from a ptr to a; // double; it requires a ptrtoint followed by a bitcast.; //; // It's unclear to me if the other rules have any practical effect, but we do; // it to match this pass's previous behavior.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoadStoreVectorizer.cpp:275,load,load,275,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoadStoreVectorizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoadStoreVectorizer.cpp,1,['load'],['load']
Performance,// The runtime base address that the first executable segment is loaded at.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.h:65,load,loaded,65,interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.h,1,['load'],['loaded']
Performance,// The runtime base address that the first loadabe segment is loaded at.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.h:43,load,loadabe,43,interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.h,2,['load'],"['loadabe', 'loaded']"
Performance,// The scalar source must be a normal load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,load,load,38,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,// The scalarization code below does not work for scalable vectors.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/ScalarizeMaskedMemIntrin.cpp:50,scalab,scalable,50,interpreter/llvm-project/llvm/lib/Transforms/Scalar/ScalarizeMaskedMemIntrin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/ScalarizeMaskedMemIntrin.cpp,1,['scalab'],['scalable']
Performance,"// The scratch registers here with the EarlyClobber | Define | Implicit; // flags is used to persuade the register allocator and the machine; // verifier to accept the usage of this register. This has to be a real; // register which has an UNDEF value but is dead after the instruction which; // is unique among the registers chosen for the instruction.; // The EarlyClobber flag has the semantic properties that the operand it is; // attached to is clobbered before the rest of the inputs are read. Hence it; // must be unique among the operands to the instruction.; // The Define flag is needed to coerce the machine verifier that an Undef; // value isn't a problem.; // The Dead flag is needed as the value in scratch isn't used by any other; // instruction. Kill isn't used as Dead is more precise.; // The implicit flag is here due to the interaction between the other flags; // and the machine verifier.; // For correctness purpose, a new pseudo is introduced here. We need this; // new pseudo, so that FastRegisterAllocator does not see an ll/sc sequence; // that is spread over >1 basic blocks. A register allocator which; // introduces (or any codegen infact) a store, can violate the expectations; // of the hardware.; //; // An atomic read-modify-write sequence starts with a linked load; // instruction and ends with a store conditional instruction. The atomic; // read-modify-write sequence fails if any of the following conditions; // occur between the execution of ll and sc:; // * A coherent store is completed by another process or coherent I/O; // module into the block of synchronizable physical memory containing; // the word. The size and alignment of the block is; // implementation-dependent.; // * A coherent store is executed between an LL and SC sequence on the; // same processor to the block of synchornizable physical memory; // containing the word.; //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.cpp:1294,load,load,1294,interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.cpp,1,['load'],['load']
Performance,// The second argument is a temporary array with space for NumItems; // pointers. We'll actually be loading elements from the array; // pointer written into the control state; this buffer is so that; // collections that *aren't* backed by arrays can still queue up; // batches of elements.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp:100,load,loading,100,interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp,2,"['load', 'queue']","['loading', 'queue']"
Performance,"// The second block should contain 7 instructions, e.g.; //; // while.body:; // %idx = zext i32 %inc to i64; // %idx.a = getelementptr inbounds i8, ptr %a, i64 %idx; // %load.a = load i8, ptr %idx.a; // %idx.b = getelementptr inbounds i8, ptr %b, i64 %idx; // %load.b = load i8, ptr %idx.b; // %cmp.not.ld = icmp eq i8 %load.a, %load.b; // br i1 %cmp.not.ld, label %while.cond, label %while.end; //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoopIdiomTransform.cpp:170,load,load,170,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoopIdiomTransform.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoopIdiomTransform.cpp,6,['load'],['load']
Performance,// The second load can only be eliminated if its extension type matches; // that of the load instruction corresponding to the intrinsic. The user; // can provide an address of an unsigned variable to store the result of; // a sign-extending intrinsic into (or the other way around).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp:14,load,load,14,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,2,['load'],['load']
Performance,"// The section data starts after the header, the segment load command (and; // section headers) and the symbol table.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp:57,load,load,57,interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp,1,['load'],['load']
Performance,"// The select routine does not have access to the LoadSDNode instance, so; // pass along the extension information",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:50,Load,LoadSDNode,50,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,1,['Load'],['LoadSDNode']
Performance,"// The semantics of RISCVISD::VMV_V_X_VL is that when the operand; // type is wider than the resulting vector element type: an implicit; // truncation first takes place. Therefore, perform a manual; // truncation/sign-extension in order to ignore any truncated bits and catch; // any zero-extended immediate.; // For example, we wish to match (i8 -1) -> (XLenVT 255) as a simm5 by first; // sign-extending to (XLenVT -1).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelDAGToDAG.cpp:181,perform,perform,181,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelDAGToDAG.cpp,1,['perform'],['perform']
Performance,"// The set of known/encountered (unique, canonicalized) NamespaceDecls.; //; // The boolean value will be true to indicate that the namespace was loaded; // from an AST/PCH file, or false otherwise.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Sema/Sema.h:146,load,loaded,146,interpreter/llvm-project/clang/include/clang/Sema/Sema.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Sema/Sema.h,1,['load'],['loaded']
Performance,"// The set of types which have conversions in this class or its; // subclasses. As an optimization, we don't copy the derived set; // unless it might change.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/DeclCXX.cpp:86,optimiz,optimization,86,interpreter/llvm-project/clang/lib/AST/DeclCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/DeclCXX.cpp,1,['optimiz'],['optimization']
Performance,// The sext(setcc()) => setcc() optimization relies on the appropriate; // constant being emitted.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp:32,optimiz,optimization,32,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp,1,['optimiz'],['optimization']
Performance,"// The shared variables are packed together as members of structure.; // So the address of each shared variable can be computed by adding; // offset of it (within record) to the base address of record. For each; // shared variable, debug intrinsic llvm.dbg.declare is generated with; // appropriate expressions (DIExpression).; // Ex:; // %12 = load %struct.anon*, %struct.anon** %__context.addr.i; // call void @llvm.dbg.declare(metadata %struct.anon* %12,; // metadata !svar1,; // metadata !DIExpression(DW_OP_deref)); // call void @llvm.dbg.declare(metadata %struct.anon* %12,; // metadata !svar2,; // metadata !DIExpression(DW_OP_plus_uconst, 8, DW_OP_deref))",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGStmtOpenMP.cpp:345,load,load,345,interpreter/llvm-project/clang/lib/CodeGen/CGStmtOpenMP.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGStmtOpenMP.cpp,1,['load'],['load']
Performance,// The shift can be combined if it matches the size of the value being; // loaded (and so reducing the width would make it not match).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:75,load,loaded,75,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['load'],['loaded']
Performance,"// The size is not directly available for physical registers.; // Instead, we need to access a register class that contains Reg and; // get the size of that register class.; // Because this is expensive, we'll cache the register class by calling",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RegisterBankInfo.cpp:210,cache,cache,210,interpreter/llvm-project/llvm/lib/CodeGen/RegisterBankInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RegisterBankInfo.cpp,1,['cache'],['cache']
Performance,"// The size of the load for this block, in bytes.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp:19,load,load,19,interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,1,['load'],['load']
Performance,"// The smallest scalable element supported by scaled SVE addressing; // modes are predicates, which are 2 scalable bytes in size. So the scalable; // byte offset must always be a multiple of 2.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64InstrInfo.cpp:16,scalab,scalable,16,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64InstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64InstrInfo.cpp,9,['scalab'],['scalable']
Performance,"// The specific comparison ""(x<<c) > 0x80000000U"" can be optimized to a; // single ""lsls x, c+1"". The shift sets the ""C"" and ""Z"" flags the same; // way a cmp would.; // FIXME: Add support for ARM/Thumb2; this would need isel patterns, and; // some tweaks to the heuristics for the previous and->shift transform.; // FIXME: Optimize cases where the LHS isn't a shift.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:57,optimiz,optimized,57,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,2,"['Optimiz', 'optimiz']","['Optimize', 'optimized']"
Performance,// The splat index for permuted loads will be in the left half of the vector; // which is strictly wider than the loaded value by 8 bytes. So we need to; // adjust the splat index to point to the correct address in memory.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:32,load,loads,32,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,2,['load'],"['loaded', 'loads']"
Performance,"// The split call above ""helpfully"" added a branch at the end of BB (to the; // wrong place), but we want a load. It's easiest to just remove; // the branch entirely.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp:108,load,load,108,interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp,1,['load'],['load']
Performance,"// The stack id gives an indication of whether the object is scalable or; // not, so it's safe to pass in the minimum size here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp:61,scalab,scalable,61,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,1,['scalab'],['scalable']
Performance,"// The stackmap intrinsic only records the live variables (the arguments; // passed to it) and emits NOPS (if requested). Unlike the patchpoint; // intrinsic, this won't be lowered to a function call. This means we don't; // have to worry about calling conventions and target specific lowering code.; // Instead we perform the call lowering right here.; //; // chain, flag = CALLSEQ_START(chain, 0, 0); // chain, flag = STACKMAP(id, nbytes, ..., chain, flag); // chain, flag = CALLSEQ_END(chain, 0, 0, flag); //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp:315,perform,perform,315,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,1,['perform'],['perform']
Performance,"// The stackmap intrinsic only records the live variables (the arguments; // passed to it) and emits NOPS (if requested). Unlike the patchpoint; // intrinsic, this won't be lowered to a function call. This means we don't; // have to worry about calling conventions and target-specific lowering code.; // Instead we perform the call lowering right here.; //; // CALLSEQ_START(0, 0...); // STACKMAP(id, nbytes, ...); // CALLSEQ_END(0, 0); //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/FastISel.cpp:315,perform,perform,315,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/FastISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/FastISel.cpp,1,['perform'],['perform']
Performance,// The standard behaviour in the backend for these cases is to split the; // extend up into two parts:; // 1. Perform an extending load or masked load up to the legal type.; // 2. Extend the loaded data to the final type.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp:110,Perform,Perform,110,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,4,"['Perform', 'load']","['Perform', 'load', 'loaded']"
Performance,"// The step returned by `createStepForVF` is a runtime-evaluated value; // when VF is scalable. Otherwise, it should be folded into a Constant.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlanRecipes.cpp:86,scalab,scalable,86,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlanRecipes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlanRecipes.cpp,1,['scalab'],['scalable']
Performance,// The store and load must share the same stride.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonLoopIdiomRecognition.cpp:17,load,load,17,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonLoopIdiomRecognition.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonLoopIdiomRecognition.cpp,2,['load'],['load']
Performance,// The store can potentially clobber loads and prevent repeated loads from; // being eliminated.; // FIXME:; // 1. We can probably keep an initial set of eliminatable loads substracted; // from the cost even when we finally see a store. We just need to disable; // *further* accumulation of elimination savings.; // 2. We should probably at some point thread MemorySSA for the callee into; // this and then use that to actually compute *really* precise savings.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InlineCost.cpp:37,load,loads,37,interpreter/llvm-project/llvm/lib/Analysis/InlineCost.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InlineCost.cpp,3,['load'],['loads']
Performance,// The store has to be at least as big as the load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/VNCoercion.cpp:46,load,load,46,interpreter/llvm-project/llvm/lib/Transforms/Utils/VNCoercion.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/VNCoercion.cpp,1,['load'],['load']
Performance,"// The store isn't a valid to consider for the prior sequence,; // so try to optimize what we have so far and start a new sequence.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64PostLegalizerCombiner.cpp:77,optimiz,optimize,77,interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64PostLegalizerCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64PostLegalizerCombiner.cpp,1,['optimiz'],['optimize']
Performance,// The store may have dependencies to unanalyzable loads and; // stores.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ScheduleDAGInstrs.cpp:51,load,loads,51,interpreter/llvm-project/llvm/lib/CodeGen/ScheduleDAGInstrs.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ScheduleDAGInstrs.cpp,1,['load'],['loads']
Performance,// The store must be feeding a non-volatile load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonLoopIdiomRecognition.cpp:44,load,load,44,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonLoopIdiomRecognition.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonLoopIdiomRecognition.cpp,3,['load'],['load']
Performance,"// The store to the fixedstack object is needed becuase accessing a; // field of the ByVal will use a gep and load. Ideally we will optimize; // to extracting the value from the register directly, and elide the; // stores when the arguments address is not taken, but that will need to; // be future work.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:110,load,load,110,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,2,"['load', 'optimiz']","['load', 'optimize']"
Performance,// The strategy assumes that we can efficiently load power-of-two widths.; // The routine chops the vector into the largest vector loads with the same; // element type or scalar loads and then recombines it to the widen vector; // type.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp:48,load,load,48,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp,3,['load'],"['load', 'loads']"
Performance,// The switch operand is a load from the cleanup-dest alloca.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGCleanup.cpp:27,load,load,27,interpreter/llvm-project/clang/lib/CodeGen/CGCleanup.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGCleanup.cpp,1,['load'],['load']
Performance,// The switches specify inline thresholds used in SampleProfileLoader inlining.; // TODO: the actual threshold to be tuned here because the size here is based; // on machine code not LLVM IR.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/CSPreInliner.cpp:117,tune,tuned,117,interpreter/llvm-project/llvm/tools/llvm-profgen/CSPreInliner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/CSPreInliner.cpp,1,['tune'],['tuned']
Performance,// The table is stored as an array of values. Values are retrieved by load; // instructions from the table.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp:70,load,load,70,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp,1,['load'],['load']
Performance,// The tables (AVX512InterleavedLoadTbl and AVX512InterleavedStoreTbl); // contain the cost of the optimized shuffle sequence that the; // X86InterleavedAccess pass will generate.; // The cost of loads and stores are computed separately from the table.; // X86InterleavedAccess support only the following interleaved-access group.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:99,optimiz,optimized,99,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,2,"['load', 'optimiz']","['loads', 'optimized']"
Performance,"// The target location for the relocation is described by RE.SectionID and; // RE.Offset. RE.SectionID can be used to find the SectionEntry. Each; // SectionEntry has three members describing its location.; // SectionEntry::Address is the address at which the section has been loaded; // into memory in the current (host) process. SectionEntry::LoadAddress is the; // address that the section will have in the target process.; // SectionEntry::ObjAddress is the address of the bits for this section in the; // original emitted object image (also in the current address space).; //; // Relocations will be applied as if the section were loaded at; // SectionEntry::LoadAddress, but they will be applied at an address based; // on SectionEntry::Address. SectionEntry::ObjAddress will be used to refer to; // Target memory contents if they are required for value calculations.; //; // The Value parameter here is the load address of the symbol for the; // relocation to be applied. For relocations which refer to symbols in the; // current object Value will be the LoadAddress of the section in which; // the symbol resides (RE.Addend provides additional information about the; // symbol location). For external symbols, Value will be the address of the; // symbol in the target address space.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp:277,load,loaded,277,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp,6,"['Load', 'load']","['LoadAddress', 'load', 'loaded']"
Performance,"// The target location for the relocation is described by RE.SectionID and; // RE.Offset. RE.SectionID can be used to find the SectionEntry. Each; // SectionEntry has three members describing its location.; // SectionEntry::Address is the address at which the section has been loaded; // into memory in the current (host) process. SectionEntry::LoadAddress is; // the address that the section will have in the target process.; // SectionEntry::ObjAddress is the address of the bits for this section in the; // original emitted object image (also in the current address space).; //; // Relocations will be applied as if the section were loaded at; // SectionEntry::LoadAddress, but they will be applied at an address based; // on SectionEntry::Address. SectionEntry::ObjAddress will be used to refer; // to Target memory contents if they are required for value calculations.; //; // The Value parameter here is the load address of the symbol for the; // relocation to be applied. For relocations which refer to symbols in the; // current object Value will be the LoadAddress of the section in which; // the symbol resides (RE.Addend provides additional information about the; // symbol location). For external symbols, Value will be the address of the; // symbol in the target address space.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldCOFFX86_64.h:277,load,loaded,277,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldCOFFX86_64.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldCOFFX86_64.h,6,"['Load', 'load']","['LoadAddress', 'load', 'loaded']"
Performance,"// The temporary Phi is being fixed, unmark it for not to optimize.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSAUpdater.cpp:58,optimiz,optimize,58,interpreter/llvm-project/llvm/lib/Analysis/MemorySSAUpdater.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSAUpdater.cpp,1,['optimiz'],['optimize']
Performance,// The tokens will be added to Preprocessor's cache and will be removed; // when this TokenLexer finishes lexing them.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/TokenLexer.cpp:46,cache,cache,46,interpreter/llvm-project/clang/lib/Lex/TokenLexer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/TokenLexer.cpp,1,['cache'],['cache']
Performance,"// The transform has determined that we should perform a simple; // transformation on the pack expansion, producing another pack; // expansion.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/TreeTransform.h:47,perform,perform,47,interpreter/llvm-project/clang/lib/Sema/TreeTransform.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/TreeTransform.h,4,['perform'],['perform']
Performance,// The transform has determined that we should perform an elementwise; // expansion of the pattern. Do so.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/TreeTransform.h:47,perform,perform,47,interpreter/llvm-project/clang/lib/Sema/TreeTransform.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/TreeTransform.h,4,['perform'],['perform']
Performance,// The transform has determined that we should perform an expansion;; // transform and capture each of the arguments.; // expansion of the pattern. Do so.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/TreeTransform.h:47,perform,perform,47,interpreter/llvm-project/clang/lib/Sema/TreeTransform.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/TreeTransform.h,1,['perform'],['perform']
Performance,// The transform needs to know the exact runtime length of scalable vectors,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/SVEIntrinsicOpts.cpp:59,scalab,scalable,59,interpreter/llvm-project/llvm/lib/Target/AArch64/SVEIntrinsicOpts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/SVEIntrinsicOpts.cpp,2,['scalab'],['scalable']
Performance,"// The transformation from a zero-extending load to a sign-extending; // load is only legal when the displacement is a multiple of 4.; // If the displacement is not at least 4 byte aligned, don't perform; // the transformation.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp:44,load,load,44,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp,3,"['load', 'perform']","['load', 'perform']"
Performance,// The transformation is OK. Rebuild Branch as a load-and-trap.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZElimCompare.cpp:49,load,load-and-trap,49,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZElimCompare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZElimCompare.cpp,1,['load'],['load-and-trap']
Performance,"// The transformation is somewhat dangerous if the call's chain was glued to; // the call. After MoveBelowOrigChain the load is moved between the call and; // the chain, this can create a cycle if the load is not folded. So it is; // *really* important that we are sure the load will be folded.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp:120,load,load,120,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,3,['load'],['load']
Performance,"// The transformation performed here aims to widen a widenable condition; // above the loop such that all analyzeable exit leading to deopt are dead.; // It assumes that the latch is the dominant exit for profitability and that; // exits branching to deoptimizing blocks are rarely taken. It relies on the; // semantics of widenable expressions for legality. (i.e. being able to fall; // down the widenable path spuriously allows us to ignore exit order,; // unanalyzeable exits, side effects, exceptional exits, and other challenges; // which restrict the applicability of the non-WC based version of this; // transform in IndVarSimplify.); //; // NOTE ON POISON/UNDEF - We're hoisting an expression above guards which may; // imply flags on the expression being hoisted and inserting new uses (flags; // are only correct for current uses). The result is that we may be; // inserting a branch on the value which can be either poison or undef. In; // this case, the branch can legally go either way; we just need to avoid; // introducing UB. This is achieved through the use of the freeze; // instruction.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopPredication.cpp:22,perform,performed,22,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopPredication.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopPredication.cpp,1,['perform'],['performed']
Performance,"// The transforms below here are expected to be handled more generally with; // simplifyAndOrOfICmpsWithLimitConst() or in InstCombine's; // foldAndOrOfICmpsWithConstEq(). If we are looking to trim optimizer overlap,; // these are candidates for removal.; // X < Y && Y != 0 --> X < Y; // X < Y || Y != 0 --> Y != 0",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InstructionSimplify.cpp:198,optimiz,optimizer,198,interpreter/llvm-project/llvm/lib/Analysis/InstructionSimplify.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InstructionSimplify.cpp,1,['optimiz'],['optimizer']
Performance,"// The treatment of both loads and stores is the same: the arguments for; // the builtin are the same as the arguments for the intrinsic.; // Load:; // builtin(Base, Inc, Mod, Start) -> intr(Base, Inc, Mod, Start); // builtin(Base, Mod, Start) -> intr(Base, Mod, Start); // Store:; // builtin(Base, Inc, Mod, Val, Start) -> intr(Base, Inc, Mod, Val, Start); // builtin(Base, Mod, Val, Start) -> intr(Base, Mod, Val, Start)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:25,load,loads,25,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,2,"['Load', 'load']","['Load', 'loads']"
Performance,"// The trickiest case to handle is when we have large blocks. Because of this,; // this code is optimized assuming that large blocks happen. This does not; // significantly pessimize the small block case. This uses LargeBlockInfo to; // make it efficient to get the index of various operations in the block.; // Walk the use-def list of the alloca, getting the locations of all stores.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp:96,optimiz,optimized,96,interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp,1,['optimiz'],['optimized']
Performance,// The trip counts should be cached by now.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:29,cache,cached,29,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,1,['cache'],['cached']
Performance,// The two maps below are used to cache decisions instead of recomputing:; // This is used to cache instruction replacement decisions within function; // units and across function units.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64SIMDInstrOpt.cpp:34,cache,cache,34,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64SIMDInstrOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64SIMDInstrOpt.cpp,2,['cache'],['cache']
Performance,// The type MachO::macho_load_command is defined in llvm/BinaryFormat/MachO.h; // and it is a union of all the structs corresponding to various load; // commands.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObject.h:144,load,load,144,interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObject.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObject.h,1,['load'],['load']
Performance,"// The type legalizer turns a vector load of i8 values into a zextload to i16; // registers, optionally ANY_EXTENDs it (if target type is integer),; // and ANDs off the high 8 bits. Since we turn this load into a; // target-specific DAG node, the DAG combiner fails to eliminate these AND; // nodes. Do that here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:37,load,load,37,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,2,['load'],['load']
Performance,"// The type might not be legal for the target. This should only happen; // if the type is smaller than a legal type, as on PPC, so the right; // thing to do is generate a LoadExt/StoreTrunc pair. These simplify; // to Load/Store if NVT==VT.; // FIXME does the case above also need this?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp:171,Load,LoadExt,171,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,2,['Load'],"['Load', 'LoadExt']"
Performance,"// The type of the internal cache used inside the findBasePointers family; // of functions. From the callers perspective, this is an opaque type and; // should not be inspected.; //; // In the actual implementation this caches two relations:; // - The base relation itself (i.e. this pointer is based on that one); // - The base defining value relation (i.e. before base_phi insertion); // Generally, after the execution of a full findBasePointer call, only the; // base relation will remain. Internally, we add a mixture of the two; // types, then update all the second type to the first type",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp:28,cache,cache,28,interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,2,['cache'],"['cache', 'caches']"
Performance,// The type the comparison is being performed in.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaChecking.cpp:36,perform,performed,36,interpreter/llvm-project/clang/lib/Sema/SemaChecking.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaChecking.cpp,1,['perform'],['performed']
Performance,// The types of the parameters from which we will perform template argument; // deduction.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplateDeduction.cpp:50,perform,perform,50,interpreter/llvm-project/clang/lib/Sema/SemaTemplateDeduction.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplateDeduction.cpp,1,['perform'],['perform']
Performance,"// The unzip cache does not consume memory by itself, it just allocates in advance; // mem blocks which are then picked as they are by the baskets.; // Hence there is no good reason to limit it too much",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCacheUnzip.cxx:13,cache,cache,13,tree/tree/src/TTreeCacheUnzip.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCacheUnzip.cxx,1,['cache'],['cache']
Performance,// The update instruction source and destination register must be the; // same as the load/store base register.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp:86,load,load,86,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp,1,['load'],['load']
Performance,// The use is (one of) the uses of the preferred use we chose earlier.; // We're going to update the load to def this value later so just erase; // the old extend.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:101,load,load,101,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,1,['load'],['load']
Performance,// The use isn't an extend. Truncate back to the type we originally loaded.; // This is free on many targets.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:68,load,loaded,68,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,1,['load'],['loaded']
Performance,"// The value V returned from this function is used differently depending; // on whether MemInst is a load or a store. If it's a load, we will replace; // MemInst with V, if it's a store, we will check if V is the same as the; // available value.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp:101,load,load,101,interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,2,['load'],['load']
Performance,"// The value for the symbol depends on the context we're evaluating in:; // Inside a load this is the address in the linker's memory, outside a; // load it's the address in the target processes memory.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldChecker.cpp:85,load,load,85,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldChecker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldChecker.cpp,2,['load'],['load']
Performance,// The value from output queue A (denoted by register OQAP) can; // only be fetched during the first cycle.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/R600InstrInfo.cpp:25,queue,queue,25,interpreter/llvm-project/llvm/lib/Target/AMDGPU/R600InstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/R600InstrInfo.cpp,1,['queue'],['queue']
Performance,"// The value is loaded into a value with FIELD_BYTE_SIZE size,; // and then zero or sign extended to U64.; // FIELD_LSHIFT_U64 and FIELD_RSHIFT_U64 are operations; // to extract the original value.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFAbstractMemberAccess.cpp:16,load,loaded,16,interpreter/llvm-project/llvm/lib/Target/BPF/BPFAbstractMemberAccess.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFAbstractMemberAccess.cpp,1,['load'],['loaded']
Performance,// The value is returned directly for optimized libcalls but the expr; // provided an out-param.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGAtomic.cpp:38,optimiz,optimized,38,interpreter/llvm-project/clang/lib/CodeGen/CGAtomic.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGAtomic.cpp,1,['optimiz'],['optimized']
Performance,// The value loaded is an gc base itself,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp:13,load,loaded,13,interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,1,['load'],['loaded']
Performance,"// The value printers of TTreeReaderValue and TTreeReaderArray rely on the; // one of TTreeReaderValueBase, from which they both inherit.; // This is why we use RTTI inside the function, avoiding to duplicate code.; // The performance penalty is irrelevant because we are already printing; // the objects in an interactive environment.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/src/TTreeReaderValue.cxx:223,perform,performance,223,tree/treeplayer/src/TTreeReaderValue.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/src/TTreeReaderValue.cxx,1,['perform'],['performance']
Performance,// The value returned by the load op.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp:29,load,load,29,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,1,['load'],['load']
Performance,"// The value we want is 0 if we came directly from the initial block; // (having failed the range or alignment checks), or the loaded bit if; // we came from the block in which we loaded it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/LowerTypeTests.cpp:127,load,loaded,127,interpreter/llvm-project/llvm/lib/Transforms/IPO/LowerTypeTests.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/LowerTypeTests.cpp,2,['load'],['loaded']
Performance,// The vast majority of the instructions would need their operand 2 replaced; // with an immediate when switching to the reg+imm form. A marked exception; // are the update form loads/stores for which a constant operand 2 would need; // to turn into a displacement and move operand 1 to the operand 2 position.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp:178,load,loads,178,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,1,['load'],['loads']
Performance,// The vector type that is returned may be different from the; // eventual type loaded from memory.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:80,load,loaded,80,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,1,['load'],['loaded']
Performance,// The vectorizer may have significantly shortened a loop body; unroll; // again. Unroll small loops to hide loop backedge latency and saturate any; // parallel execution resources of an out-of-order processor. We also then; // need to clean up redundancies and loop invariant code.; // FIXME: It would be really good to use a loop-integrated instruction; // combiner for cleanup here so that the unrolling and LICM can be pipelined; // across the loop nests.; // We do UnrollAndJam in a separate LPM to ensure it happens before unroll,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp:123,latency,latency,123,interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,1,['latency'],['latency']
Performance,"// The victim is a nested class, but we will not need to perform; // any processing after the definition of this class since it has; // no members whose handling was delayed. Therefore, we can just; // remove this nested class.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseDeclCXX.cpp:57,perform,perform,57,interpreter/llvm-project/clang/lib/Parse/ParseDeclCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseDeclCXX.cpp,1,['perform'],['perform']
Performance,"// The virtual friends page source does not pre-load any clusters itself. However, the underlying page sources; // that are combined may well do it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RPageSourceFriends.cxx:48,load,load,48,tree/ntuple/v7/src/RPageSourceFriends.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RPageSourceFriends.cxx,1,['load'],['load']
Performance,"// The volatile store here is intended to escape the local variable, to; // prevent the compiler from optimizing CharOnStack into anything other; // than a char on the stack.; //; // Tested on: MSVC 2015 - 2019, GCC 4.9 - 9, Clang 3.2 - 9, ICC 13 - 19.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Stack.cpp:102,optimiz,optimizing,102,interpreter/llvm-project/clang/lib/Basic/Stack.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Stack.cpp,1,['optimiz'],['optimizing']
Performance,"// The wide helper function returns (writes out) an array of chaining values; // and returns the length of that array. The number of chaining values returned; // is the dyanmically detected SIMD degree, at most MAX_SIMD_DEGREE. Or fewer,; // if the input is shorter than that many chunks. The reason for maintaining a; // wide array of chaining values going back up the tree, is to allow the; // implementation to hash as many parents in parallel as possible.; //; // As a special case when the SIMD degree is 1, this function will still return; // at least 2 outputs. This guarantees that this function doesn't perform the; // root compression. (If it did, it would use the wrong flags, and also we; // wouldn't be able to implement exendable ouput.) Note that this function is; // not used when the whole input is only 1 chunk long; that's a different; // codepath.; //; // Why not just have the caller split the input on the first update(), instead; // of implementing this special rule? Because we don't want to limit SIMD or; // multi-threading parallelism for that update().",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/blake3.c:612,perform,perform,612,interpreter/llvm-project/llvm/lib/Support/BLAKE3/blake3.c,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/blake3.c,2,"['multi-thread', 'perform']","['multi-threading', 'perform']"
Performance,"// The widenIVUse avoids generating trunc by evaluating the use as AddRec, this; // will not work when:; // 1) SCEV traces back to an instruction inside the loop that SCEV can not; // expand, eg. add %indvar, (load %addr); // 2) SCEV finds a loop variant, eg. add %indvar, %loopvariant; // While SCEV fails to avoid trunc, we can still try to use instruction; // combining approach to prove trunc is not required. This can be further; // extended with other instruction combining checks, but for now we handle the; // following case (sub can be ""add"" and ""mul"", ""nsw + sext"" can be ""nus + zext""); //; // Src:; // %c = sub nsw %b, %indvar; // %d = sext %c to i64; // Dst:; // %indvar.ext1 = sext %indvar to i64; // %m = sext %b to i64; // %d = sub nsw i64 %m, %indvar.ext1; // Therefore, as long as the result of add/sub/mul is extended to wide type, no; // trunc is required regardless of how %b is generated. This pattern is common; // when calculating address in 64 bit architecture",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyIndVar.cpp:210,load,load,210,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyIndVar.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyIndVar.cpp,1,['load'],['load']
Performance,"// The width of the type must be a power of 2 and greater than 8-bits.; // Otherwise the load cannot be represented in LLVM IR.; // Moreover, if we shifted with a non-8-bits multiple, the slice; // will be across several bytes. We do not support that.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:89,load,load,89,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,"// The worklist of live basic blocks in the callee *after* inlining. We avoid; // adding basic blocks of the callee which can be proven to be dead for this; // particular call site in order to get more accurate cost estimates. This; // requires a somewhat heavyweight iteration pattern: we need to walk the; // basic blocks in a breadth-first order as we insert live successors. To; // accomplish this, prioritizing for small iterations because we exit after; // crossing our threshold, we use a small-size optimized SetVector.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InlineCost.cpp:507,optimiz,optimized,507,interpreter/llvm-project/llvm/lib/Analysis/InlineCost.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InlineCost.cpp,1,['optimiz'],['optimized']
Performance,"// The x86 definition of ""undef"" is not the same as the LLVM definition; // (PR32176). We leave optimizing away an unnecessary zero constant to the; // IR optimizer and backend.; // TODO: If we had a ""freeze"" IR instruction to generate a fixed undef; // value, we should use that here instead of a zero.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:96,optimiz,optimizing,96,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,2,['optimiz'],"['optimizer', 'optimizing']"
Performance,// Then copy the newly loaded TOC anchor to the TOC pointer.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:23,load,loaded,23,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['loaded']
Performance,// Then handle deferred loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUPromoteAlloca.cpp:24,load,loads,24,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUPromoteAlloca.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUPromoteAlloca.cpp,1,['load'],['loads']
Performance,// Then load configuration files specified explicitly.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/Driver.cpp:8,load,load,8,interpreter/llvm-project/clang/lib/Driver/Driver.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/Driver.cpp,1,['load'],['load']
Performance,// Then load the GPRs from the stack,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:8,load,load,8,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['load']
Performance,// Then perform the interleave; // v[0] v[n] v[1] v[n+1] v[2] v[n+2] v[3] v[n+3] ...,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:8,perform,perform,8,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['perform'],['perform']
Performance,// Then we need enough elements to exceed the number of vector; // registers we have. Note that this is an oversimplification since; // fusing also takes some extra loads which may exceed the number of; // reloads necessary.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LowerMatrixIntrinsics.cpp:165,load,loads,165,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LowerMatrixIntrinsics.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LowerMatrixIntrinsics.cpp,1,['load'],['loads']
Performance,"// Then, look for a value in Cache.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/BypassSlowDivision.cpp:29,Cache,Cache,29,interpreter/llvm-project/llvm/lib/Transforms/Utils/BypassSlowDivision.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/BypassSlowDivision.cpp,1,['Cache'],['Cache']
Performance,"// Then, perform overload resolution over the candidate set.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp:9,perform,perform,9,interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,1,['perform'],['perform']
Performance,"// There are 4 additional tail-allocated arrays at the end of the class:; // 1. Contains list of pseudo variables with the default initialization for; // each non-firstprivate variables. Used in codegen for initialization of; // lastprivate copies.; // 2. List of helper expressions for proper generation of assignment operation; // required for lastprivate clause. This list represents private variables; // (for arrays, single array element).; // 3. List of helper expressions for proper generation of assignment operation; // required for lastprivate clause. This list represents original variables; // (for arrays, single array element).; // 4. List of helper expressions that represents assignment operation:; // \code; // DstExprs = SrcExprs;; // \endcode; // Required for proper codegen of final assignment performed by the; // lastprivate clause.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/AST/OpenMPClause.h:814,perform,performed,814,interpreter/llvm-project/clang/include/clang/AST/OpenMPClause.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/AST/OpenMPClause.h,1,['perform'],['performed']
Performance,"// There are a few different cases we have to handle, because the load or the; // sign-/zero-extend might not be selected by FastISel if we fall-back to; // SelectionDAG. There is also an ordering issue when both instructions are in; // different basic blocks.; // 1.) The load instruction is selected by FastISel, but the integer extend; // not. This usually happens when the integer extend is in a different; // basic block and SelectionDAG took over for that basic block.; // 2.) The load instruction is selected before the integer extend. This only; // happens when the integer extend is in a different basic block.; // 3.) The load instruction is selected by SelectionDAG and the integer extend; // by FastISel. This happens if there are instructions between the load; // and the integer extend that couldn't be selected by FastISel.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FastISel.cpp:66,load,load,66,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FastISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FastISel.cpp,5,['load'],['load']
Performance,"// There are cases where we cannot determine whether two values are; // equivalent, because it depends on not yet processed basic blocks -- see the; // documentation on assumptions.; //; // AC is the context in which we are currently performing a diff.; // When we encounter a pair of values for which we can neither prove; // equivalence nor the opposite, we do the following:; // * If AC is nullptr, we treat the pair as non-equivalent.; // * If AC is set, we add an assumption for the basic blocks given by AC,; // and treat the pair as equivalent. The assumption is checked later.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-diff/lib/DifferenceEngine.cpp:234,perform,performing,234,interpreter/llvm-project/llvm/tools/llvm-diff/lib/DifferenceEngine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-diff/lib/DifferenceEngine.cpp,1,['perform'],['performing']
Performance,"// There are five possible optimizations we can do for memcpy:; // a) memcpy-memcpy xform which exposes redundance for DSE.; // b) call-memcpy xform for return slot optimization.; // c) memcpy from freshly alloca'd space or space that has just started; // its lifetime copies undefined data, and we can therefore eliminate; // the memcpy in favor of the data that was already at the destination.; // d) memcpy from a just-memset'd source can be turned into memset.; // e) elimination of memcpy via stack-move optimization.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp:27,optimiz,optimizations,27,interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,3,['optimiz'],"['optimization', 'optimizations']"
Performance,"// There are many forms of this optimization we can handle, for now, just do; // the simple index into a single-dimensional array.; //; // Require: GEP GV, 0, i {{, constant indices}}",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCompares.cpp:32,optimiz,optimization,32,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCompares.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCompares.cpp,1,['optimiz'],['optimization']
Performance,"// There are no SMRD extloads, so if we have to do a small type access we; // will use a MUBUF load.; // FIXME?: We also need to do this if unaligned, but we don't know the; // alignment here.; // TODO: Update this for GFX12 which does have scalar sub-dword loads.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:95,load,load,95,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,2,['load'],"['load', 'loads']"
Performance,// There are no extending loads or truncating stores.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:26,load,loads,26,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['load'],['loads']
Performance,// There are no update forms for Altivec vector load/stores.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCLoopInstrFormPrep.cpp:48,load,load,48,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCLoopInstrFormPrep.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCLoopInstrFormPrep.cpp,1,['load'],['load']
Performance,"// There are particular cases where we can conclude no-alias between; // a non-addr-taken global and some other underlying object. Specifically,; // a non-addr-taken global is known to not be escaped from any function. It is; // also incorrect for a transformation to introduce an escape of a global in; // a way that is observable when it was not there previously. One function; // being transformed to introduce an escape which could possibly be observed; // (via loading from a global or the return value for example) within another; // function is never safe. If the observation is made through non-atomic; // operations on different threads, it is a data-race and UB. If the; // observation is well defined, by being observed the transformation would have; // changed program behavior by introducing the observed escape, making it an; // invalid transform.; //; // This property does require that transformations which *temporarily* escape; // a global that was not previously escaped, prior to restoring it, cannot rely; // on the results of GMR::alias. This seems a reasonable restriction, although; // currently there is no way to enforce it. There is also no realistic; // optimization pass that would make this mistake. The closest example is; // a transformation pass which does reg2mem of SSA values but stores them into; // global variables temporarily before restoring the global variable's value.; // This could be useful to expose ""benign"" races for example. However, it seems; // reasonable to require that a pass which introduces escapes of global; // variables in this way to either not trust AA results while the escape is; // active, or to be forced to operate as a module pass that cannot co-exist; // with an alias analysis such as GMR.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/GlobalsModRef.cpp:466,load,loading,466,interpreter/llvm-project/llvm/lib/Analysis/GlobalsModRef.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/GlobalsModRef.cpp,2,"['load', 'optimiz']","['loading', 'optimization']"
Performance,"// There are some benefits to schedule the ADDI as early as possible post ra; // to avoid stalled by vector instructions which take up all the hw units.; // And ADDI is usually used to post inc the loop indvar, which matters the; // performance.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMachineScheduler.cpp:233,perform,performance,233,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMachineScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMachineScheduler.cpp,1,['perform'],['performance']
Performance,"// There are some benefits to schedule the ADDI before the load to hide the; // latency, as RA may create a true dependency between the load and addi.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMachineScheduler.cpp:59,load,load,59,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMachineScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMachineScheduler.cpp,3,"['latency', 'load']","['latency', 'load']"
Performance,// There are some more conversions we can perform under exactly one pointer.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp:42,perform,perform,42,interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp,1,['perform'],['perform']
Performance,// There are some special cases that we need to look at for 32 bit and 96; // bit SGPR loads otherwise we have nothing to do.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPURegisterBankInfo.cpp:87,load,loads,87,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPURegisterBankInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPURegisterBankInfo.cpp,1,['load'],['loads']
Performance,"// There are three cases for the receiver:; // (1) it is definitely nil,; // (2) it is definitely non-nil, and; // (3) we don't know.; //; // If the receiver is definitely nil, we skip the pre/post callbacks and; // instead call the ObjCMessageNil callbacks and return.; //; // If the receiver is definitely non-nil, we call the pre- callbacks,; // evaluate the call, and call the post- callbacks.; //; // If we don't know, we drop the potential nil flow and instead; // continue from the assumed non-nil state as in (2). This approach; // intentionally drops coverage in order to prevent false alarms; // in the following scenario:; //; // id result = [o someMethod]; // if (result) {; // if (!o) {; // // <-- This program point should be unreachable because if o is nil; // // it must the case that result is nil as well.; // }; // }; //; // However, it also loses coverage of the nil path prematurely,; // leading to missed reports.; //; // It's possible to handle this by performing a state split on every call:; // explore the state where the receiver is non-nil, and independently; // explore the state where it's nil. But this is not only slow, but; // completely unwarranted. The mere presence of the message syntax in the code; // isn't sufficient evidence that nil is a realistic possibility.; //; // An ideal solution would be to add the following constraint that captures; // both possibilities without splitting the state:; //; // ($x == 0) => ($y == 0) (1); //; // where in our case '$x' is the receiver symbol, '$y' is the returned symbol,; // and '=>' is logical implication. But RangeConstraintManager can't handle; // such constraints yet, so for now we go with a simpler, more restrictive; // constraint: $x != 0, from which (1) follows as a vacuous truth.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/ExprEngineObjC.cpp:976,perform,performing,976,interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/ExprEngineObjC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/ExprEngineObjC.cpp,1,['perform'],['performing']
Performance,"// There are three cases here:; //; // - if the only defined element is a loaded one, the best sequence; // is a replicating load.; //; // - otherwise, if the only defined element is an i64 value, we will; // end up with the same VLVGP sequence regardless of whether we short-cut; // for replication or fall through to the later code.; //; // - otherwise, if the only defined element is an i32 or smaller value,; // we would need 2 instructions to replicate it: VLVGP followed by VREPx.; // This is only a win if the single defined element is used more than once.; // In other cases we're better off using a single VLVGx.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:74,load,loaded,74,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,2,['load'],"['load', 'loaded']"
Performance,"// There are three possible options here:; // 1. Available operator<< to convert through an ostringstream; // 2. Cling's pretty printing; // 3. Generic printing as done in op_repr; //; // Additionally, there may be a mapped __str__ from the C++ type defining `operator char*`; // or `operator const char*`. Results are memoized for performance reasons.; // 0. Protect against trying to print a typed nullptr object through an insertion operator",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPInstance.cxx:332,perform,performance,332,bindings/pyroot/cppyy/CPyCppyy/src/CPPInstance.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPInstance.cxx,1,['perform'],['performance']
Performance,"// There are two cases to consider here:; // 1. The store is fixed width and the load is scalable. In this case we; // don't know at compile time if the store completely envelops the load; // so we abandon the optimisation.; // 2. The store is scalable and the load is fixed width. We could; // potentially support a limited number of cases here, but there has been; // no cost-benefit analysis to prove it's worth it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:81,load,load,81,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,5,"['load', 'scalab']","['load', 'scalable']"
Performance,// There are two different ways of expanding RMW instructions:; // - into a load if it is idempotent; // - into a Cmpxchg/LL-SC loop otherwise; // we try them in that order.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp:76,load,load,76,interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp,1,['load'],['load']
Performance,"// There are two different ways this can be done:; // 1. xxlor : This has lower latency (on the P7), 2 cycles, but can only; // issue in VSU pipeline 0.; // 2. xmovdp/xmovsp: This has higher latency (on the P7), 6 cycles, but; // can go to either pipeline.; // We'll always use xxlor here, because in practically all cases where; // copies are generated, they are close enough to some use that the; // lower-latency form is preferable.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp:80,latency,latency,80,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,3,['latency'],['latency']
Performance,"// There are two general methods for expanding a BUILD_VECTOR node:; // 1. Use SCALAR_TO_VECTOR on the defined scalar values and then shuffle; // them together.; // 2. Build the vector on the stack and then load it.; // If this function returns true, then method (1) will be used, subject to; // the constraint that all of the necessary shuffles are legal (as determined; // by isShuffleMaskLegal). If this function returns false, then method (2) is; // always used. The vector type, and the number of defined values, are; // provided.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/TargetLowering.h:207,load,load,207,interpreter/llvm-project/llvm/include/llvm/CodeGen/TargetLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/TargetLowering.h,1,['load'],['load']
Performance,"// There aren't really 64-bit registers, but pairs of 32-bit ones and only a; // limited number of native 64-bit operations. Shrinking an operation to fit; // in a single 32-bit register should always be helpful. As currently used,; // this is much less general than the name suggests, and is only used in; // places trying to reduce the sizes of loads. Shrinking loads to < 32-bits is; // not profitable, and may actually be harmful.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelLowering.cpp:347,load,loads,347,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelLowering.cpp,2,['load'],['loads']
Performance,"// There can't be any side effects between the load and store, such as; // a call or store.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:47,load,load,47,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,// There is a form of VFSGNJ which injects the negated sign of its second; // operand. Try and bubble any FNEG up after the extend/round to produce; // this optimized pattern. Avoid modifying cases where FP_ROUND and; // TRUNC=1.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:157,optimiz,optimized,157,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['optimiz'],['optimized']
Performance,"// There is a gap between this basket and the max of the 'lowest' already loaded basket; // If we are tight in memory, reading this basket may prevent reading the basket (for the other branches); // that covers this gap, forcing those baskets to be read uncached (because the cache wont be reloaded; // until we use this basket).; // eg. We could end up with the cache contain; // b1: [428, 514[ // 'this' basket and we can assume [321 to 428[ is already in memory; // b2: [400, 424[; // and when reading entry 425 we will read b2's basket uncached.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx:74,load,loaded,74,tree/tree/src/TTreeCache.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx,3,"['cache', 'load']","['cache', 'loaded']"
Performance,"// There is a possibility that the linker may try to rewrite:; // adrp x0, @sym@PAGE; // add x1, x0, @sym@PAGEOFF; // [x0 = some other def]; // ldr x2, [x1]; // ...into...; // adrp x0, @sym; // nop; // [x0 = some other def]; // ldr x2, [x0]; // ...if the offset to the symbol won't fit within a literal load.; // This causes the load to use the result of the adrp, which in this; // case has already been clobbered.; // FIXME: Implement proper liveness tracking for all registers. For now,; // don't emit the LOH if there are any instructions between the add and; // the ldr.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64CollectLOH.cpp:303,load,load,303,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64CollectLOH.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64CollectLOH.cpp,2,['load'],['load']
Performance,"// There is a scalar version available, but unlike the vector version which; // has a separate operand for the offset and width, the scalar version packs; // the width and offset into a single operand. Try to move to the scalar; // version if the offsets are constant, so that we can try to keep extended; // loads of kernel arguments in SGPRs.; // TODO: Technically we could try to pattern match scalar bitshifts of; // dynamic values, but it's probably not useful.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelDAGToDAG.cpp:309,load,loads,309,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelDAGToDAG.cpp,1,['load'],['loads']
Performance,"// There is currently no clean way of extracting a templated method out of ROOT/meta; // for a variety of reasons, none of them fundamental. The game played below is to; // first get any pre-existing functions already managed by ROOT/meta, but if that fails,; // to do an explicit lookup that ignores the prototype (i.e. the full name should be; // enough), and finally to ignore the template arguments part of the name as this fails; // in cling if there are default parameters.; // It would be possible to get the prototype from the created functions and use that to; // do a new lookup, after which ROOT/meta will manage the function. However, neither; // TFunction::GetPrototype() nor TFunction::GetSignature() is of the proper form, so; // we'll/ manage the new TFunctions instead and will assume that they are cached on the; // calling side to prevent multiple creations.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:816,cache,cached,816,bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx,1,['cache'],['cached']
Performance,// There is little performance gain if we pend the recalculation under; // Lazy UpdateStrategy so we recalculate available trees immediately.; // Prevent forceFlushDeletedBB() from erasing DomTree or PostDomTree nodes.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/DomTreeUpdater.cpp:19,perform,performance,19,interpreter/llvm-project/llvm/lib/Analysis/DomTreeUpdater.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/DomTreeUpdater.cpp,1,['perform'],['performance']
Performance,// There is no byte sized k-register load or store without AVX512DQ.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:37,load,load,37,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,"// There is no dominating use, check if we can find a closest non-dominating; // use that lies between any other potentially available use and Load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp:143,Load,Load,143,interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,1,['Load'],['Load']
Performance,// There is no extending load for vXi1.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,load,load,25,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,"// There is no header registered for this class, if this a; // template, it will be instantiated if/when it is requested; // and if we do no load/parse its components we might end up; // not using an eventual specialization.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:141,load,load,141,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,1,['load'],['load']
Performance,// There is no libcall for atomic load; fake it with ATOMIC_CMP_SWAP.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp:34,load,load,34,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,1,['load'],['load']
Performance,// There is no meaningful transformation that one could perform on the; // global scope.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/TreeTransform.h:56,perform,perform,56,interpreter/llvm-project/clang/lib/Sema/TreeTransform.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/TreeTransform.h,1,['perform'],['perform']
Performance,"// There is no mechanism yet to create a scalable scalarization loop,; // so this is currently Invalid.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:41,scalab,scalable,41,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,1,['scalab'],['scalable']
Performance,"// There is no need to recompute _stateNames and _insertionOrder, as only defining new; // mappings has an effect on these. When the input category changes it shape, it is sufficient; // to clear the cached state mappings.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooMappedCategory.cxx:200,cache,cached,200,roofit/roofitcore/src/RooMappedCategory.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooMappedCategory.cxx,1,['cache'],['cached']
Performance,// There is no noticable performance difference here between Lazy and Eager; // UpdateStrategy based on some test results. It is feasible to switch the; // UpdateStrategy to Lazy if we find it profitable later.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/TailRecursionElimination.cpp:25,perform,performance,25,interpreter/llvm-project/llvm/lib/Transforms/Scalar/TailRecursionElimination.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/TailRecursionElimination.cpp,2,['perform'],['performance']
Performance,"// There is no store before this load, bail out (load may be affected; // by the following stores - see main comment).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp:33,load,load,33,interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp,2,['load'],['load']
Performance,"// There is no t2LSRLr instruction so negate and perform an lsll if the; // shift amount is in a register, emulating a right shift.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:49,perform,perform,49,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['perform'],['perform']
Performance,"// There is nothing more to be loaded from the stack, so now we can; // restore SP: SP = RBReg + SPAdd.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCFrameLowering.cpp:31,load,loaded,31,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCFrameLowering.cpp,1,['load'],['loaded']
Performance,"// There is one load per block in this case, BlockIndex == LoadIndex.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp:16,load,load,16,interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,2,"['Load', 'load']","['LoadIndex', 'load']"
Performance,"// There is only one HIP fat binary per linked module, however there are; // multiple constructor functions. Make sure the fat binary is registered; // only once. The constructor functions are executed by the dynamic loader; // before the program gains control. The dynamic loader cannot execute the; // constructor functions concurrently since doing that would not guarantee; // thread safety of the loaded program. Therefore we can assume sequential; // execution of constructor functions here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGCUDANV.cpp:217,load,loader,217,interpreter/llvm-project/clang/lib/CodeGen/CGCUDANV.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGCUDANV.cpp,4,"['concurren', 'load']","['concurrently', 'loaded', 'loader']"
Performance,// There is possibility of hoisting this instruction above some arbitrary; // condition. Any metadata defined on it can be control dependent on this; // condition. Conservatively strip it here so that we don't give any wrong; // information to the optimizer.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LoopInfo.cpp:248,optimiz,optimizer,248,interpreter/llvm-project/llvm/lib/Analysis/LoopInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LoopInfo.cpp,1,['optimiz'],['optimizer']
Performance,"// There may be duplication in the gc.relocate list; such as two copies of; // each relocation on normal and exceptional path for an invoke. We only; // need to spill once and record one copy in the stackmap, but we need to; // reload once per gc.relocate. (Dedupping gc.relocates is trickier and best; // handled as a CSE problem elsewhere.); // TODO: There a couple of major stackmap size optimizations we could do; // here if we wished.; // 1) If we've encountered a derived pair {B, D}, we don't need to actually; // record {B,B} if it's seen later.; // 2) Due to rematerialization, actual derived pointers are somewhat rare;; // given that, we could change the format to record base pointer relocations; // separately with half the space. This would require a format rev and a; // fairly major rework of the STATEPOINT node though.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/StatepointLowering.cpp:391,optimiz,optimizations,391,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/StatepointLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/StatepointLowering.cpp,1,['optimiz'],['optimizations']
Performance,"// There might be 'cycles' in the forced dependencies, since profile; // data isn't 100% accurate. Typically this is observed in loops, when the; // loop edges are the hottest successors for the basic blocks of the loop.; // Break the cycles by choosing the node with the smallest index as the; // head. This helps to keep the original order of the loops, which likely; // have already been rotated in the optimized manner.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/CodeLayout.cpp:406,optimiz,optimized,406,interpreter/llvm-project/llvm/lib/Transforms/Utils/CodeLayout.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/CodeLayout.cpp,1,['optimiz'],['optimized']
Performance,"// There remain 0 to (MaxLoadSize - 1) bytes to load, this will be done with; // an overlapping load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp:48,load,load,48,interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,2,['load'],['load']
Performance,"// There shouldn't be any stale affected values in the assumption cache; // that were previously in the old function, but that have now been moved; // to the new function.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/CodeExtractor.cpp:66,cache,cache,66,interpreter/llvm-project/llvm/lib/Transforms/Utils/CodeExtractor.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/CodeExtractor.cpp,1,['cache'],['cache']
Performance,// There will be no VS if all copies are available_externally having no; // type metadata. In that case we can't safely perform WPD.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/WholeProgramDevirt.cpp:120,perform,perform,120,interpreter/llvm-project/llvm/lib/Transforms/IPO/WholeProgramDevirt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/WholeProgramDevirt.cpp,1,['perform'],['perform']
Performance,"// There's a potential optimization opportunity in combining; // memsets; that would be easy for arrays, but relatively; // difficult for structures with the current code.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExprAgg.cpp:23,optimiz,optimization,23,interpreter/llvm-project/clang/lib/CodeGen/CGExprAgg.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExprAgg.cpp,1,['optimiz'],['optimization']
Performance,// There's currently no cached token...,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/PPCaching.cpp:24,cache,cached,24,interpreter/llvm-project/clang/lib/Lex/PPCaching.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/PPCaching.cpp,1,['cache'],['cached']
Performance,// There's no chance of overlap if the load is invariant.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp:39,load,load,39,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp,1,['load'],['load']
Performance,// There's no point in performing runtime unrolling if this unroll count; // results in a full unroll.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopUnroll.cpp:23,perform,performing,23,interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopUnroll.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopUnroll.cpp,1,['perform'],['performing']
Performance,// There's no segment named TargetSegName. Create a new load command and; // Insert a new section into it.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObjcopy.cpp:56,load,load,56,interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObjcopy.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObjcopy.cpp,1,['load'],['load']
Performance,"// There's no way to specify FP16 and BF16 immediates in .(b)f16 ops, so we; // have to load them into an .(b)f16 register first.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp:88,load,load,88,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp,1,['load'],['load']
Performance,"// There's nothing to suggest in here as we parsed a full expression.; // Instead fail and propagate the error since caller might have something; // the suggest, e.g. signature help in function call. Note that this is; // performed before pushing the \p Expr, so that signature help can report; // current argument correctly.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseDecl.cpp:222,perform,performed,222,interpreter/llvm-project/clang/lib/Parse/ParseDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseDecl.cpp,2,['perform'],['performed']
Performance,"// These are all functions related to the ""miss cache"": this attempts to; // optimize ROOT's behavior when the TTreeCache has a cache miss. In this; // case, we try to read several branches for the event with the miss.; //; // The miss cache is more CPU-intensive than the rest of the TTreeCache code;; // for local work (i.e., laptop with SSD), this CPU cost may outweight the; // benefit.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/inc/TTreeCache.h:48,cache,cache,48,tree/tree/inc/TTreeCache.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/inc/TTreeCache.h,4,"['cache', 'optimiz']","['cache', 'optimize']"
Performance,// These are all likely to be optimized into something smaller.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfoImpl.h:30,optimiz,optimized,30,interpreter/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfoImpl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfoImpl.h,1,['optimiz'],['optimized']
Performance,"// These are arbitrary chosen limits on the maximum number of values and the; // maximum size of a debug expression we can salvage up to, used for; // performance reasons.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenCommonISel.cpp:151,perform,performance,151,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenCommonISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenCommonISel.cpp,2,['perform'],['performance']
Performance,// These are for truncated stores/narrowing loads. They are fine so long as; // the alignment is at least the size of the item being loaded,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:44,load,loads,44,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,2,['load'],"['loaded', 'loads']"
Performance,"// These are identical to the builtins above, except they don't consume; // input carry, only generate carry-out. Since they still produce two; // outputs, generate the store of the predicate, but no load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:200,load,load,200,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,1,['load'],['load']
Performance,// These are instructions like; // - `ST(0) = fsqrt(ST(0))` (OneArgFPRW); // - `ST(0) = ST(0) + ST(i)` (TwoArgFP); // They are intrinsically serial and do not modify the state of the stack.; // We generate the same code for latency and uops.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/X86/Target.cpp:224,latency,latency,224,interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/X86/Target.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/X86/Target.cpp,1,['latency'],['latency']
Performance,"// These are invoked internally before parsing command line options.; // This enables lazy-initialization of all the globals in libSupport, instead; // of eagerly loading everything on program startup.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/DebugOptions.h:163,load,loading,163,interpreter/llvm-project/llvm/lib/Support/DebugOptions.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/DebugOptions.h,1,['load'],['loading']
Performance,"// These are symbols used to throw/catch C++ exceptions and C longjmps. These; // symbols have to be emitted somewhere once in the module. Check if each of; // the symbols has already been created, i.e., we have at least one 'throw' or; // 'catch' instruction with the symbol in the module, and emit the symbol only; // if so.; //; // But in dynamic linking, it is in general not possible to come up with a; // module instantiating order in which tag-defining modules are loaded before; // the importing modules. So we make them undefined symbols here, define tags; // in the JS side, and feed them to each importing module.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/WasmException.cpp:472,load,loaded,472,interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/WasmException.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/WasmException.cpp,1,['load'],['loaded']
Performance,"// These are the attributes that are still valid on loads and stores after; // RS4GC.; // The metadata implying dereferenceability and noalias are (conservatively); // dropped. This is because semantically, after RewriteStatepointsForGC runs,; // all calls to gc.statepoint ""free"" the entire heap. Also, gc.statepoint can; // touch the entire heap including noalias objects. Note: The reasoning is; // same as stripping the dereferenceability and noalias attributes that are; // analogous to the metadata counterparts.; // We also drop the invariant.load metadata on the load because that metadata; // implies the address operand to the load points to memory that is never; // changed once it became dereferenceable. This is no longer true after RS4GC.; // Similar reasoning applies to invariant.group metadata, which applies to; // loads within a group.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp:52,load,loads,52,interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,5,['load'],"['load', 'loads']"
Performance,// These are the common checks that need to performed; // to determine if; // 1. compare instruction can be moved before jump.; // 2. feeder to the compare instruction can be moved before jump.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonNewValueJump.cpp:44,perform,performed,44,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonNewValueJump.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonNewValueJump.cpp,1,['perform'],['performed']
Performance,// These arguments are generated from OptimizationRemark fields of; // CodeGenOptions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInvocation.cpp:38,Optimiz,OptimizationRemark,38,interpreter/llvm-project/clang/lib/Frontend/CompilerInvocation.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInvocation.cpp,1,['Optimiz'],['OptimizationRemark']
Performance,// These builtins exist to emit regular volatile loads and stores not; // affected by the -fms-volatile setting.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:49,load,loads,49,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,1,['load'],['loads']
Performance,"// These calls return their argument verbatim, as a low-level; // optimization. However, this makes high-level optimizations; // harder. Undo any uses of this optimization that the front-end; // emitted here. We'll redo them in the contract pass.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/ObjCARC/ObjCARCExpand.cpp:66,optimiz,optimization,66,interpreter/llvm-project/llvm/lib/Transforms/ObjCARC/ObjCARCExpand.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/ObjCARC/ObjCARCExpand.cpp,3,['optimiz'],"['optimization', 'optimizations']"
Performance,"// These files need to be available everywhere, cache and sandbox",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProof.cxx:48,cache,cache,48,proof/proof/src/TProof.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProof.cxx,1,['cache'],['cache']
Performance,// These folds should be beneficial regardless of when this pass is run; // in the optimization pipeline.; // The type checking is for run-time efficiency. We can avoid wasting time; // dispatching to folding functions if there's no chance of matching.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VectorCombine.cpp:83,optimiz,optimization,83,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VectorCombine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VectorCombine.cpp,1,['optimiz'],['optimization']
Performance,"// These instructions only load 16 bits, we can't fold them if the; // destination register is wider than 16 bits (2 bytes), and its user; // instruction isn't scalar (SH).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp:27,load,load,27,interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp,1,['load'],['load']
Performance,"// These instructions only load 32 bits, we can't fold them if the; // destination register is wider than 32 bits (4 bytes), and its user; // instruction isn't scalar (SS).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp:27,load,load,27,interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp,1,['load'],['load']
Performance,"// These instructions only load 64 bits, we can't fold them if the; // destination register is wider than 64 bits (8 bytes), and its user; // instruction isn't scalar (SD).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp:27,load,load,27,interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp,1,['load'],['load']
Performance,"// These instructions take an address operand, but have load-like or; // other innocuous behavior that should not trigger a stack protector.; // atomicrmw conceptually has both load and store semantics, but the; // value being stored must be integer; so if a pointer is being stored,; // we'll catch it in the PtrToInt case above.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/StackProtector.cpp:56,load,load-like,56,interpreter/llvm-project/llvm/lib/CodeGen/StackProtector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/StackProtector.cpp,2,['load'],"['load', 'load-like']"
Performance,"// These intrinsics return a tuple {Vector, VectorPred} in LLVM IR,; // and the corresponding C/C++ builtins use loads/stores to update; // the predicate.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:113,load,loads,113,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,1,['load'],['loads']
Performance,"// These is used by the updater to perform various internal MemorySSA; // machinsations. They do not always leave the IR in a correct state, and; // relies on the updater to fixup what it breaks, so it is not public.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/MemorySSA.h:35,perform,perform,35,interpreter/llvm-project/llvm/include/llvm/Analysis/MemorySSA.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/MemorySSA.h,1,['perform'],['perform']
Performance,// These may load memory.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.cpp:13,load,load,13,interpreter/llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.cpp,1,['load'],['load']
Performance,"// These must not be moved across calls or instructions that may change; // floating-point exception masks or read floating-point exception flags.; // In addition, they cannot be optimized out even if unused.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp:179,optimiz,optimized,179,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,1,['optimiz'],['optimized']
Performance,"// These need be generated for performance. Currently they are not,; // using API calls instead.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/Rewrite/RewriteModernObjC.cpp:31,perform,performance,31,interpreter/llvm-project/clang/lib/Frontend/Rewrite/RewriteModernObjC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/Rewrite/RewriteModernObjC.cpp,1,['perform'],['performance']
Performance,"// These nodes match the semantics of the corresponding RVV vector reduction; // instructions. They produce a vector result which is the reduction; // performed over the second vector operand plus the first element of the; // third vector operand. The first operand is the pass-thru operand. The; // second operand is an unconstrained vector type, and the result, first, and; // third operand's types are expected to be the corresponding full-width; // LMUL=1 type for the second operand:; // nxv8i8 = vecreduce_add nxv8i8, nxv32i8, nxv8i8; // nxv2i32 = vecreduce_add nxv2i32, nxv8i32, nxv2i32; // The different in types does introduce extra vsetvli instructions but; // similarly it reduces the number of registers consumed per reduction.; // Also has a mask and VL operand.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.h:151,perform,performed,151,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.h,1,['perform'],['performed']
Performance,// These operations perform a matrix multiplication and accumulation of; // the form:; // D = A * B + C; // We need to specify one type for matrices AB and one for matrices CD.; // Sparse matrix operations can have different types for A and B as well as; // an additional type for sparsity index.; // Destination type should be put before types used for source operands.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:20,perform,perform,20,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,1,['perform'],['perform']
Performance,"// These pointers may be based on the memory owned by an indirect global. If; // so, we may be able to handle this. First check to see if the base pointer; // is a direct load from an indirect global.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/GlobalsModRef.cpp:171,load,load,171,interpreter/llvm-project/llvm/lib/Analysis/GlobalsModRef.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/GlobalsModRef.cpp,1,['load'],['load']
Performance,"// These queries ask for a single size_t result for a given dimension index, e.g; // size_t get_global_id(uint dimindex). In SPIR-V, the builtins corresonding to; // these values are all vec3 types, so we need to extract the correct index or; // return defaultVal (0 or 1 depending on the query). We also handle extending; // or tuncating in case size_t does not match the expected result type's; // bitwidth.; //; // For a constant index >= 3 we generate:; // %res = OpConstant %SizeT 0; //; // For other indices we generate:; // %g = OpVariable %ptr_V3_SizeT Input; // OpDecorate %g BuiltIn XXX; // OpDecorate %g LinkageAttributes ""__spirv_BuiltInXXX""; // OpDecorate %g Constant; // %loadedVec = OpLoad %V3_SizeT %g; //; // Then, if the index is constant < 3, we generate:; // %res = OpCompositeExtract %SizeT %loadedVec idx; // If the index is dynamic, we generate:; // %tmp = OpVectorExtractDynamic %SizeT %loadedVec %idx; // %cmp = OpULessThan %bool %idx %const_3; // %res = OpSelect %SizeT %cmp %tmp %const_0; //; // If the bitwidth of %res does not match the expected return type, we add an; // extend or truncate.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SPIRV/SPIRVBuiltins.cpp:686,load,loadedVec,686,interpreter/llvm-project/llvm/lib/Target/SPIRV/SPIRVBuiltins.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SPIRV/SPIRVBuiltins.cpp,3,['load'],['loadedVec']
Performance,// These should happen AFTER plugins have been loaded!,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/FrontendTool/ExecuteCompilerInvocation.cpp:47,load,loaded,47,interpreter/llvm-project/clang/lib/FrontendTool/ExecuteCompilerInvocation.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/FrontendTool/ExecuteCompilerInvocation.cpp,1,['load'],['loaded']
Performance,"// These stub helpers are only ever called once, so here we're optimizing for; // minimum size by using the pre-indexed store variants, which saves a few; // bytes of instructions to bump & restore sp.; // _ifunc.stub_helper:; // stp	fp, lr, [sp, #-16]!; // mov	fp, sp; // stp	x1, x0, [sp, #-16]!; // stp	x3, x2, [sp, #-16]!; // stp	x5, x4, [sp, #-16]!; // stp	x7, x6, [sp, #-16]!; // stp	d1, d0, [sp, #-16]!; // stp	d3, d2, [sp, #-16]!; // stp	d5, d4, [sp, #-16]!; // stp	d7, d6, [sp, #-16]!; // bl	_resolver; // adrp	x16, lazy_pointer@GOTPAGE; // ldr	x16, [x16, lazy_pointer@GOTPAGEOFF]; // str	x0, [x16]; // mov	x16, x0; // ldp	d7, d6, [sp], #16; // ldp	d5, d4, [sp], #16; // ldp	d3, d2, [sp], #16; // ldp	d1, d0, [sp], #16; // ldp	x7, x6, [sp], #16; // ldp	x5, x4, [sp], #16; // ldp	x3, x2, [sp], #16; // ldp	x1, x0, [sp], #16; // ldp	fp, lr, [sp], #16; // br	x16",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64AsmPrinter.cpp:63,optimiz,optimizing,63,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64AsmPrinter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64AsmPrinter.cpp,1,['optimiz'],['optimizing']
Performance,"// These two lines would make the test fail because of two reasons:; // - An assertion failure ""Assertion failed: (detail::isPresent(Val) && ""dyn_cast on a non-existent value""), function dyn_cast, file Casting.h, line 662.""; // - An error ""Error in <TInterpreter::RefreshClassInfo>: Should not need to update the classInfo a non type decl: Detail""; // This is why there is no check performed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/test/TClingTests.cxx:382,perform,performed,382,core/metacling/test/TClingTests.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/test/TClingTests.cxx,1,['perform'],['performed']
Performance,"// These types can be variably-modified. All these modifications; // preserve structure except as noted by comments.; // TODO: if we ever care about optimizing VLAs, there are no-op; // optimizations available here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ASTContext.cpp:149,optimiz,optimizing,149,interpreter/llvm-project/clang/lib/AST/ASTContext.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ASTContext.cpp,2,['optimiz'],"['optimizations', 'optimizing']"
Performance,"// These uses are both partially available at Load were it not for; // the clobber, but neither lies strictly after the other.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp:46,Load,Load,46,interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,1,['Load'],['Load']
Performance,"// They are in the same block, the later one will forward to the load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp:65,load,load,65,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp,1,['load'],['load']
Performance,"// Think all other usages may be an escaping candidate conservatively.; //; // Note that the major user of switch ABI coroutine (the C++) will store; // resume.fn, destroy.fn and the index to the coroutine frame immediately.; // So the parent of the coro.begin in C++ will be always escaping.; // Then we can't get any performance benefits for C++ by improving the; // precision of the method.; //; // The reason why we still judge it is we want to make LLVM Coroutine in; // switch ABIs to be self contained as much as possible instead of a; // by-product of C++20 Coroutines.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Coroutines/CoroElide.cpp:319,perform,performance,319,interpreter/llvm-project/llvm/lib/Transforms/Coroutines/CoroElide.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Coroutines/CoroElide.cpp,1,['perform'],['performance']
Performance,"// Third argument (bool), defines whether the clobber search should skip the; // original queried access. If true, there will be a follow-up query searching; // for a clobber access past ""self"". Note that the Optimized access is not; // updated if a new clobber is found by this SkipSelf search. If this; // additional query becomes heavily used we may decide to cache the result.; // Walker instantiations will decide how to set the SkipSelf bool.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp:209,Optimiz,Optimized,209,interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp,2,"['Optimiz', 'cache']","['Optimized', 'cache']"
Performance,"// This (complex pattern) function is meant to detect a sign-extension; // i32->i64 on a per-operand basis. This would allow writing single; // patterns that would cover a number of combinations of different ways; // a sign-extensions could be written. For example:; // (mul (DetectUseSxtw x) (DetectUseSxtw y)) -> (M2_dpmpyss_s0 x y); // could match either one of these:; // (mul (sext x) (sext_inreg y)); // (mul (sext-load *p) (sext_inreg y)); // (mul (sext_inreg x) (sext y)); // etc.; //; // The returned value will have type i64 and its low word will; // contain the value being extended. The high bits are not specified.; // The returned type is i64 because the original type of N was i64,; // but the users of this function should only use the low-word of the; // result, e.g.; // (mul sxtw:x, sxtw:y) -> (M2_dpmpyss_s0 (LoReg sxtw:x), (LoReg sxtw:y))",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp:421,load,load,421,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,1,['load'],['load']
Performance,// This CacheStream will move the temporary file into the cache when done.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/Caching.cpp:8,Cache,CacheStream,8,interpreter/llvm-project/llvm/lib/Support/Caching.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/Caching.cpp,2,"['Cache', 'cache']","['CacheStream', 'cache']"
Performance,// This HeaderFileInfo was externally loaded.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp:38,load,loaded,38,interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,1,['load'],['loaded']
Performance,"// This ProbeContext has a probe, so it has code before inlining and; // optimization. Make sure we mark its size as known.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.cpp:73,optimiz,optimization,73,interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.cpp,1,['optimiz'],['optimization']
Performance,// This access turns into a read/modify/write of the vector. Load the input; // value now.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExpr.cpp:61,Load,Load,61,interpreter/llvm-project/clang/lib/CodeGen/CGExpr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExpr.cpp,1,['Load'],['Load']
Performance,// This accounts for any modification of the EXEC mask within the block and; // can be optimized out pre-RA when not required.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SILowerControlFlow.cpp:87,optimiz,optimized,87,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SILowerControlFlow.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SILowerControlFlow.cpp,1,['optimiz'],['optimized']
Performance,"// This action is explicitly left unimplemented.; // While it is theoretically possible to; // legalize operations on scalable types with a; // loop that handles the vscale * #lanes of the; // vector, this is non-trivial at SelectionDAG; // level and these types are better to be; // widened or promoted.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/TargetLowering.h:118,scalab,scalable,118,interpreter/llvm-project/llvm/include/llvm/CodeGen/TargetLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/TargetLowering.h,1,['scalab'],['scalable']
Performance,"// This algorithm implements the same visitor loop as; // hasUnsafePHIOrSelectUse, and fixes the alignment of each load; // or store found.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:115,load,load,115,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,1,['load'],['load']
Performance,// This allows the latency-based scheduler to notice high latency instructions; // without a target itinerary. The choice of number here has more to do with; // balancing scheduler heuristics than with the actual machine latency.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/ScheduleDAGSDNodes.cpp:19,latency,latency-based,19,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/ScheduleDAGSDNodes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/ScheduleDAGSDNodes.cpp,3,['latency'],"['latency', 'latency-based']"
Performance,"// This almost never happens, but if it does, ensure that our cache; // doesn't contain a stale result.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp:62,cache,cache,62,interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp,1,['cache'],['cache']
Performance,// This also handles volatile loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/TailRecursionElimination.cpp:30,load,loads,30,interpreter/llvm-project/llvm/lib/Transforms/Scalar/TailRecursionElimination.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/TailRecursionElimination.cpp,1,['load'],['loads']
Performance,// This and only this kind of non-signed ICmpInst is to be replaced with; // the comparing of the value of the created global init bool later in; // optimizeGlobalAddressOfAllocation for the global variable.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp:149,optimiz,optimizeGlobalAddressOfAllocation,149,interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,1,['optimiz'],['optimizeGlobalAddressOfAllocation']
Performance,"// This array is used as a medium to transfer, one reduce element at a time,; // the data from the first lane of every warp to lanes in the first warp; // in order to perform the final step of a reduction in a parallel region; // (reduction across warps). The array is placed in NVPTX __shared__ memory; // for reduced latency, as well as to have a distinct copy for concurrently; // executing target regions. The array is declared with common linkage so; // as to be shared across compilation units.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGOpenMPRuntimeGPU.cpp:167,perform,perform,167,interpreter/llvm-project/clang/lib/CodeGen/CGOpenMPRuntimeGPU.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGOpenMPRuntimeGPU.cpp,3,"['concurren', 'latency', 'perform']","['concurrently', 'latency', 'perform']"
Performance,"// This avoids any chances of creating a REPLICATE recipe during planning; // since that would result in generation of scalarized code during execution,; // which is not supported for scalable vectors.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:184,scalab,scalable,184,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,1,['scalab'],['scalable']
Performance,"// This basket was in the previous cache/cluster and was not used,; // let's not read it again. I.e. we bet that it will continue to not; // be used. At worst it will be used and thus read by itself.; // Usually in this situation the basket is large so the penalty for; // (re)reading it uselessly is high and the penalty to read it by; // itself is 'small' (i.e. size bigger than latency).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx:35,cache,cache,35,tree/tree/src/TTreeCache.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx,2,"['cache', 'latency']","['cache', 'latency']"
Performance,// This block could now be visited again from a different predecessor. Note; // that this will result in exponential runtime. Subpaths could possibly be; // cached but it takes a lot of memory to store them.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/DFAJumpThreading.cpp:157,cache,cached,157,interpreter/llvm-project/llvm/lib/Transforms/Scalar/DFAJumpThreading.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/DFAJumpThreading.cpp,1,['cache'],['cached']
Performance,"// This branch is taken when the callback was from DynamicLibraryManager::loadLibrary",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:74,load,loadLibrary,74,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,1,['load'],['loadLibrary']
Performance,"// This can be a 32bit load/store scaled by 4, a 16bit load/store scaled by 2,; // or a 8bit, 16bit or 32bit load/store scaled by 1",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/MVEGatherScatterLowering.cpp:23,load,load,23,interpreter/llvm-project/llvm/lib/Target/ARM/MVEGatherScatterLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/MVEGatherScatterLowering.cpp,3,['load'],['load']
Performance,"// This can be needed if the library defining this typedef was loaded after; // another library and that this other library is unloaded (in which case; // things can get renumbered inside CINT).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TDataType.cxx:63,load,loaded,63,core/meta/src/TDataType.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TDataType.cxx,1,['load'],['loaded']
Performance,"// This can happen if someone switched trees behind us.; // Likely cause: a TChain::LoadTree() e.g. from TTree::Process().; // This means that ""local"" should be set!; // There are two entities switching trees which is bad.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/src/TTreeReader.cxx:84,Load,LoadTree,84,tree/treeplayer/src/TTreeReader.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/src/TTreeReader.cxx,1,['Load'],['LoadTree']
Performance,"// This can happen in awkward cases with tied operands, e.g. a; // writeback load/store with a complex addressing mode in; // which there's an output operand corresponding to the; // updated written-back base register: the Tablegen-generated; // AsmMatcher will have written a placeholder operand to that; // slot in the form of an immediate 0, because it can't; // generate the register part of the complex addressing-mode; // operand ahead of time.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/AsmParser/ARMAsmParser.cpp:77,load,load,77,interpreter/llvm-project/llvm/lib/Target/ARM/AsmParser/ARMAsmParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/AsmParser/ARMAsmParser.cpp,1,['load'],['load']
Performance,"// This can happen when the unwind dest was removed during the; // optimization, e.g. because it was unreachable.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyCFGStackify.cpp:67,optimiz,optimization,67,interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyCFGStackify.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyCFGStackify.cpp,1,['optimiz'],['optimization']
Performance,"// This can run concurrently with another thread trying to get; // the read lock and ending up in the next section (""Wait for writers, if any""); // which need to also get the local readers count and thus can; // modify the map.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/thread/src/TReentrantRWLock.cxx:16,concurren,concurrently,16,core/thread/src/TReentrantRWLock.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/thread/src/TReentrantRWLock.cxx,1,['concurren'],['concurrently']
Performance,"// This case can be generated by ABI lowering, performe anyext",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp:47,perform,performe,47,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86InstructionSelector.cpp,1,['perform'],['performe']
Performance,"// This case can't be merged with the above because; // `delete Load` / `delete Store` wants a concrete type,; // destructor of Instruction is protected.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFPreserveStaticOffset.cpp:64,Load,Load,64,interpreter/llvm-project/llvm/lib/Target/BPF/BPFPreserveStaticOffset.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFPreserveStaticOffset.cpp,1,['Load'],['Load']
Performance,// This cast represents the load we're looking for.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/BugReporterVisitors.cpp:28,load,load,28,interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/BugReporterVisitors.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/BugReporterVisitors.cpp,1,['load'],['load']
Performance,// This causes operator= above to be invoked for every -load option.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Support/PluginLoader.h:56,load,load,56,interpreter/llvm-project/llvm/include/llvm/Support/PluginLoader.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Support/PluginLoader.h,1,['load'],['load']
Performance,// This causes the object file to be loaded.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/MCJIT/MCJIT.cpp:37,load,loaded,37,interpreter/llvm-project/llvm/lib/ExecutionEngine/MCJIT/MCJIT.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/MCJIT/MCJIT.cpp,1,['load'],['loaded']
Performance,"// This check doesn't cover all cases, but it will suffice for now.; // TODO: take branch probability into consideration, if the blocking; // store is in an unreached block, breaking the memcopy could lose; // performance.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86AvoidStoreForwardingBlocks.cpp:210,perform,performance,210,interpreter/llvm-project/llvm/lib/Target/X86/X86AvoidStoreForwardingBlocks.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86AvoidStoreForwardingBlocks.cpp,1,['perform'],['performance']
Performance,"// This check is overly conservative. Unless we are certain that the machine; // operand is not a symbol reference, we return that it is a symbol reference.; // This is important as the load pair may not be split up Windows.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMExpandPseudoInsts.cpp:186,load,load,186,interpreter/llvm-project/llvm/lib/Target/ARM/ARMExpandPseudoInsts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMExpandPseudoInsts.cpp,1,['load'],['load']
Performance,"// This check seems unnatural, however it is necessary to ensure the proper; // conversion of functions/arrays. If the conversion were done for all; // DeclExpr's (created by ActOnIdExpression), it would mess up the unary; // expressions that suppress this implicit conversion (&, sizeof). This needs; // to happen before we check for null pointer conversions because C does not; // undergo the same implicit conversions as C++ does above (by the calls to; // TryImplicitConversion() and PerformImplicitConversion()) which insert the; // lvalue to rvalue cast before checking for null pointer constraints. This; // addresses code like: nullptr_t val; int *ptr; ptr = val;; //; // Suppress this for references: C++ 8.5.3p5.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp:488,Perform,PerformImplicitConversion,488,interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp,1,['Perform'],['PerformImplicitConversion']
Performance,// This checks against logic errors in the MCJIT implementation.; // This function should never be called with either a Module that MCJIT; // does not own or a Module that has already been loaded and/or finalized.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/MCJIT/MCJIT.h:189,load,loaded,189,interpreter/llvm-project/llvm/lib/ExecutionEngine/MCJIT/MCJIT.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/MCJIT/MCJIT.h,1,['load'],['loaded']
Performance,"// This checks against logic errors in the MCJIT implementation.; // This function should never be called with either a Module that MCJIT; // does not own, a Module that has not been loaded or a Module that has; // already been finalized.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/MCJIT/MCJIT.h:183,load,loaded,183,interpreter/llvm-project/llvm/lib/ExecutionEngine/MCJIT/MCJIT.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/MCJIT/MCJIT.h,1,['load'],['loaded']
Performance,// This choice of file name allows the cache to be pruned (see pruneCache(); // in include/llvm/Support/CachePruning.h).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/LTO/ThinLTOCodeGenerator.cpp:39,cache,cache,39,interpreter/llvm-project/llvm/lib/LTO/ThinLTOCodeGenerator.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/LTO/ThinLTOCodeGenerator.cpp,4,"['Cache', 'cache']","['CachePruning', 'cache']"
Performance,"// This class doesn't know about the latency of a load instruction. So, it; // conservatively/pessimistically assumes that the latency of a load opcode; // matches the instruction latency.; //; // FIXME: In the absence of cache misses (i.e. L1I/L1D/iTLB/dTLB hits/misses),; // and load/store conflicts, the latency of a load is determined by the depth; // of the load pipeline. So, we could use field `LoadLatency` in the; // MCSchedModel to model that latency.; // Field `LoadLatency` often matches the so-called 'load-to-use' latency from; // L1D, and it usually already accounts for any extra latency due to data; // forwarding.; // When doing throughput analysis, `LoadLatency` is likely to; // be a better predictor of load latency than instruction latency. This is; // particularly true when simulating code with temporal/spatial locality of; // memory accesses.; // Using `LoadLatency` (instead of the instruction latency) is also expected; // to improve the load queue allocation for long latency instructions with; // folded memory operands (See PR39829).; //; // FIXME: On some processors, load/store operations are split into multiple; // uOps. For example, X86 AMD Jaguar natively supports 128-bit data types, but; // not 256-bit data types. So, a 256-bit load is effectively split into two; // 128-bit loads, and each split load consumes one 'LoadQueue' entry. For; // simplicity, this class optimistically assumes that a load instruction only; // consumes one entry in the LoadQueue. Similarly, store instructions only; // consume a single entry in the StoreQueue.; // In future, we should reassess the quality of this design, and consider; // alternative approaches that let instructions specify the number of; // load/store queue entries which they consume at dispatch stage (See; // PR39830).; //; // An instruction that both 'mayStore' and 'HasUnmodeledSideEffects' is; // conservatively treated as a store barrier. It forces older store to be; // executed before newer stores are is",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/HardwareUnits/LSUnit.h:37,latency,latency,37,interpreter/llvm-project/llvm/include/llvm/MCA/HardwareUnits/LSUnit.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/HardwareUnits/LSUnit.h,26,"['Load', 'cache', 'latency', 'load', 'queue', 'throughput']","['LoadLatency', 'cache', 'latency', 'load', 'load-to-use', 'queue', 'throughput']"
Performance,"// This class is used to get an estimate of the optimization effects that we; // could get from complete loop unrolling. It comes from the fact that some; // loads might be replaced with concrete constant values and that could trigger; // a chain of instruction simplifications.; //; // E.g. we might have:; // int a[] = {0, 1, 0};; // v = 0;; // for (i = 0; i < 3; i ++); // v += b[i]*a[i];; // If we completely unroll the loop, we would get:; // v = b[0]*a[0] + b[1]*a[1] + b[2]*a[2]; // Which then will be simplified to:; // v = b[0]* 0 + b[1]* 1 + b[2]* 0; // And finally:; // v = b[1]",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/LoopUnrollAnalyzer.h:48,optimiz,optimization,48,interpreter/llvm-project/llvm/include/llvm/Analysis/LoopUnrollAnalyzer.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/LoopUnrollAnalyzer.h,2,"['load', 'optimiz']","['loads', 'optimization']"
Performance,"// This class is used to manage RVVType, RVVType should only created by this; // class, also provided thread-safe cache capability.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Support/RISCVVIntrinsicUtils.h:114,cache,cache,114,interpreter/llvm-project/clang/include/clang/Support/RISCVVIntrinsicUtils.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Support/RISCVVIntrinsicUtils.h,1,['cache'],['cache']
Performance,// This class may have local implicit instantiations that need to be; // performed within this scope.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplateInstantiateDecl.cpp:73,perform,performed,73,interpreter/llvm-project/clang/lib/Sema/SemaTemplateInstantiateDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplateInstantiateDecl.cpp,1,['perform'],['performed']
Performance,"// This class performs the following tasks:; // - Creates a logical reader for every binary file in the command line,; // that parses the debug information and creates a high level logical; // view representation containing scopes, symbols, types and lines.; // - Prints and compares the logical views.; //; // The supported binary formats are: ELF, Mach-O and CodeView.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/DebugInfo/LogicalView/LVReaderHandler.h:14,perform,performs,14,interpreter/llvm-project/llvm/include/llvm/DebugInfo/LogicalView/LVReaderHandler.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/DebugInfo/LogicalView/LVReaderHandler.h,1,['perform'],['performs']
Performance,"// This code essentially performs a ""mark-and-sweep"" of the VariableBindings.; // The roots are any Block-level exprs and Decls that our liveness algorithm; // tells us are live. We then see what Decls they may reference, and keep; // those around. This code more than likely can be made faster, and the; // frequency of which this method is called should be experimented with; // for optimum performance.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/ProgramState.cpp:25,perform,performs,25,interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/ProgramState.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/ProgramState.cpp,2,['perform'],"['performance', 'performs']"
Performance,"// This code lowers all pseudo-CMOV instructions. Generally it lowers these; // as described above, by inserting a MBB, and then making a PHI at the join; // point to select the true and false operands of the CMOV in the PHI.; //; // The code also handles two different cases of multiple CMOV opcodes; // in a row.; //; // Case 1:; // In this case, there are multiple CMOVs in a row, all which are based on; // the same condition setting (or the exact opposite condition setting).; // In this case we can lower all the CMOVs using a single inserted MBB, and; // then make a number of PHIs at the join point to model the CMOVs. The only; // trickiness here, is that in a case like:; //; // t2 = CMOV cond1 t1, f1; // t3 = CMOV cond1 t2, f2; //; // when rewriting this into PHIs, we have to perform some renaming on the; // temps since you cannot have a PHI operand refer to a PHI result earlier; // in the same block. The ""simple"" but wrong lowering would be:; //; // t2 = PHI t1(BB1), f1(BB2); // t3 = PHI t2(BB1), f2(BB2); //; // but clearly t2 is not defined in BB1, so that is incorrect. The proper; // renaming is to note that on the path through BB1, t2 is really just a; // copy of t1, and do that renaming, properly generating:; //; // t2 = PHI t1(BB1), f1(BB2); // t3 = PHI t1(BB1), f2(BB2); //; // Case 2, we lower cascaded CMOVs such as; //; // (CMOV (CMOV F, T, cc1), T, cc2); //; // to two successives branches.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/M68k/M68kISelLowering.cpp:789,perform,perform,789,interpreter/llvm-project/llvm/lib/Target/M68k/M68kISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/M68k/M68kISelLowering.cpp,1,['perform'],['perform']
Performance,"// This code mitigates LVI by replacing each indirect call/jump with a; // direct call/jump to a thunk that looks like:; // ```; // lfence; // jmpq *%r11; // ```; // This ensures that if the value in register %r11 was loaded from memory,; // then the value in %r11 is (architecturally) correct prior to the jump.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86IndirectThunks.cpp:218,load,loaded,218,interpreter/llvm-project/llvm/lib/Target/X86/X86IndirectThunks.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86IndirectThunks.cpp,1,['load'],['loaded']
Performance,"// This code performs rounding towards negative infinity in case the result; // cannot be represented exactly for the given scale. Targets that do care; // about rounding should use a target hook for specifying how rounding; // should be done, and provide their own folding to be consistent with; // rounding. This is the same approach as used by; // DAGTypeLegalizer::ExpandIntRes_MULFIX.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ConstantFolding.cpp:13,perform,performs,13,interpreter/llvm-project/llvm/lib/Analysis/ConstantFolding.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ConstantFolding.cpp,1,['perform'],['performs']
Performance,"// This code performs the conversion for case 2, which moves; // the block to the fall-thru case (BB3 in the code above).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonCFGOptimizer.cpp:13,perform,performs,13,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonCFGOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonCFGOptimizer.cpp,1,['perform'],['performs']
Performance,"// This code tries to replace unaligned vector loads/stores with aligned; // ones.; // Consider unaligned load:; // %v = original_load %some_addr, align <bad>; // %user = %v; // It will generate; // = load ..., align <good>; // = load ..., align <good>; // = valign; // etc.; // %synthesize = combine/shuffle the loaded data so that it looks; // exactly like what ""original_load"" has loaded.; // %user = %synthesize; // Similarly for stores.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp:47,load,loads,47,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp,6,['load'],"['load', 'loaded', 'loads']"
Performance,"// This combine needs to run after all reassociations/folds on pointer; // addressing have been done, specifically those that combine two G_PTR_ADDs; // with constant offsets into a single G_PTR_ADD with a combined offset.; // The goal of this optimization is to undo that combine in the case where; // doing so has prevented the formation of pair stores due to illegal; // addressing modes of STP. The reason that we do it here is because; // it's much easier to undo the transformation of a series consecutive; // mem ops, than it is to detect when doing it would be a bad idea looking; // at a single G_PTR_ADD in the reassociation/ptradd_immed_chain combine.; //; // An example:; // G_STORE %11:_(<2 x s64>), %base:_(p0) :: (store (<2 x s64>), align 1); // %off1:_(s64) = G_CONSTANT i64 4128; // %p1:_(p0) = G_PTR_ADD %0:_, %off1:_(s64); // G_STORE %11:_(<2 x s64>), %p1:_(p0) :: (store (<2 x s64>), align 1); // %off2:_(s64) = G_CONSTANT i64 4144; // %p2:_(p0) = G_PTR_ADD %0:_, %off2:_(s64); // G_STORE %11:_(<2 x s64>), %p2:_(p0) :: (store (<2 x s64>), align 1); // %off3:_(s64) = G_CONSTANT i64 4160; // %p3:_(p0) = G_PTR_ADD %0:_, %off3:_(s64); // G_STORE %11:_(<2 x s64>), %17:_(p0) :: (store (<2 x s64>), align 1)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64PostLegalizerCombiner.cpp:244,optimiz,optimization,244,interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64PostLegalizerCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64PostLegalizerCombiner.cpp,1,['optimiz'],['optimization']
Performance,"// This combine tries to find build_vector's which have every source element; // extracted using G_EXTRACT_VECTOR_ELT. This can happen when transforms like; // the masked load scalarization is run late in the pipeline. There's already; // a combine for a similar pattern starting from the extract, but that; // doesn't attempt to do it if there are multiple uses of the build_vector,; // which in this case is true. Starting the combine from the build_vector; // feels more natural than trying to find sibling nodes of extracts.; // E.g.; // %vec(<4 x s32>) = G_BUILD_VECTOR %s1(s32), %s2, %s3, %s4; // %ext1 = G_EXTRACT_VECTOR_ELT %vec, 0; // %ext2 = G_EXTRACT_VECTOR_ELT %vec, 1; // %ext3 = G_EXTRACT_VECTOR_ELT %vec, 2; // %ext4 = G_EXTRACT_VECTOR_ELT %vec, 3; // ==>; // replace ext{1,2,3,4} with %s{1,2,3,4}",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:171,load,load,171,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,1,['load'],['load']
Performance,// This controls whether or not we perform JustMyCode instrumentation.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp:35,perform,perform,35,interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp,2,['perform'],['perform']
Performance,"// This copy is a liveout value. It is likely coalesced, so reduce the; // latency so not to penalize the def.; // FIXME: need target specific adjustment here?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/ScheduleDAGSDNodes.cpp:75,latency,latency,75,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/ScheduleDAGSDNodes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/ScheduleDAGSDNodes.cpp,1,['latency'],['latency']
Performance,// This could cache & dedup here rather than relying on metadata deduping.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp:14,cache,cache,14,interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp,1,['cache'],['cache']
Performance,"// This coverage record is a zero region for a function that's unused in; // some TU, but used in a different TU. Ignore it. The coverage maps from the; // the other TU will either be loaded (providing full region counts) or they; // won't (in which case we don't unintuitively report functions as uncovered; // when they have non-zero counts in the profile).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ProfileData/Coverage/CoverageMapping.cpp:184,load,loaded,184,interpreter/llvm-project/llvm/lib/ProfileData/Coverage/CoverageMapping.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ProfileData/Coverage/CoverageMapping.cpp,1,['load'],['loaded']
Performance,"// This currently forces unfolding various combinations of fsub into fma with; // free fneg'd operands. As long as we have fast FMA (controlled by; // isFMAFasterThanFMulAndFAdd), we should perform these.; // When fma is quarter rate, for f64 where add / sub are at best half rate,; // most of these combines appear to be cycle neutral but save on instruction; // count / code size.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:190,perform,perform,190,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,1,['perform'],['perform']
Performance,// This deduction has no relation to any outer instantiation we might be; // performing.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplateDeduction.cpp:77,perform,performing,77,interpreter/llvm-project/clang/lib/Sema/SemaTemplateDeduction.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplateDeduction.cpp,2,['perform'],['performing']
Performance,"// This defaults to loading a pointer from the input and storing it to the; // output, returning the chain.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp:20,load,loading,20,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,1,['load'],['loading']
Performance,// This division is eligible for optimization only if global unsafe math; // is enabled or if this division allows reciprocal formation.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:33,optimiz,optimization,33,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['optimiz'],['optimization']
Performance,"// This does not work ... seems it is not standard pass?; // this.outline_pass.renderToScreen = true;; // Tried hacking with this, but would apparently need to load it somehow, sigh.; // let copyPass = new ShaderPass( CopyShader );; // this.composer.addPass( new THREE.ShaderPass(CopyShader) );",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/ui5/eve7/lib/GlViewerThree.js:160,load,load,160,ui5/eve7/lib/GlViewerThree.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/ui5/eve7/lib/GlViewerThree.js,1,['load'],['load']
Performance,// This does something sensible for scalable vectors - see the; // definition of EXTRACT_SUBVECTOR for further details.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp:36,scalab,scalable,36,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,1,['scalab'],['scalable']
Performance,"// This drastically improves execution time in ""collect"" over using; // SetVector as a work queue, and popping the first element from it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/RDFDeadCode.cpp:92,queue,queue,92,interpreter/llvm-project/llvm/lib/Target/Hexagon/RDFDeadCode.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/RDFDeadCode.cpp,1,['queue'],['queue']
Performance,"// This field is the threshold to use for a callee by default. This is; // derived from one or more of:; // * optimization or size-optimization levels,; // * a value passed to createFunctionInliningPass function, or; // * the -inline-threshold flag.; // If the -inline-threshold flag is explicitly specified, that is used; // irrespective of anything else.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InlineCost.cpp:110,optimiz,optimization,110,interpreter/llvm-project/llvm/lib/Analysis/InlineCost.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InlineCost.cpp,2,['optimiz'],['optimization']
Performance,// This file isn't in our cache,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/examples/Kaleidoscope/MCJIT/cached/toy.cpp:26,cache,cache,26,interpreter/llvm-project/llvm/examples/Kaleidoscope/MCJIT/cached/toy.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/examples/Kaleidoscope/MCJIT/cached/toy.cpp,2,['cache'],['cache']
Performance,// This file stream is responsible for commiting the resulting file to the; // cache and calling AddBuffer to add it to the link.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/Caching.cpp:79,cache,cache,79,interpreter/llvm-project/llvm/lib/Support/Caching.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/Caching.cpp,1,['cache'],['cache']
Performance,"// This flag controls whether we check the shadow of the address; // operand of load or store. Such bugs are very rare, since load from; // a garbage address typically results in SEGV, but still happen; // (e.g. only lower bits of address are garbage, or the access happens; // early at program startup where malloc-ed memory is more likely to; // be zeroed. As of 2012-08-28 this flag adds 20% slowdown.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp:80,load,load,80,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp,2,['load'],['load']
Performance,"// This flag indicates whether the current bindings are within the analysis; // that has started from main(). It affects how we perform loads from; // global variables that have initializers: if we have observed the; // program execution from the start and we know that these variables; // have not been overwritten yet, we can be sure that their initializers; // are still relevant. This flag never gets changed when the bindings are; // updated, so it could potentially be moved into RegionStoreManager; // (as if it's the same bindings but a different loading procedure); // however that would have made the manager needlessly stateful.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/RegionStore.cpp:128,perform,perform,128,interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/RegionStore.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/RegionStore.cpp,3,"['load', 'perform']","['loading', 'loads', 'perform']"
Performance,// This flag is set by the dyld shared cache.; // A flag indicating that the module has no instances of a @synthesize of a; // superclass variable. This flag used to be consumed by the runtime to work; // around miscompile by gcc.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp:39,cache,cache,39,interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp,1,['cache'],['cache']
Performance,// This flag shows if a nontemporal load/stores should be used when accessing; // this lvalue.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGValue.h:36,load,load,36,interpreter/llvm-project/clang/lib/CodeGen/CGValue.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGValue.h,1,['load'],['load']
Performance,"// This flag specifies a textual description of the optimization pass pipeline; // to run over the module. This flag switches opt to use the new pass manager; // infrastructure, completely disabling all of the flags specific to the old; // pass management.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llc/llc.cpp:52,optimiz,optimization,52,interpreter/llvm-project/llvm/tools/llc/llc.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llc/llc.cpp,2,['optimiz'],['optimization']
Performance,"// This flag tells the linker that no global symbols contain code that fall; // through to other global symbols (e.g. an implementation of multiple entry; // points). If this doesn't occur, the linker can safely perform dead code; // stripping. Since LLVM never generates code that does this, it is always; // safe to set.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86AsmPrinter.cpp:212,perform,perform,212,interpreter/llvm-project/llvm/lib/Target/X86/X86AsmPrinter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86AsmPrinter.cpp,1,['perform'],['perform']
Performance,"// This flags allows or disallows DSE to optimize MemorySSA during its; // traversal. Note that DSE optimizing MemorySSA may impact other passes; // downstream of the DSE invocation and can lead to issues not being; // reproducible in isolation (i.e. when MemorySSA is built from scratch). In; // those cases, the flag can be used to check if DSE's MemorySSA optimizations; // impact follow-up passes.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/DeadStoreElimination.cpp:41,optimiz,optimize,41,interpreter/llvm-project/llvm/lib/Transforms/Scalar/DeadStoreElimination.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/DeadStoreElimination.cpp,3,['optimiz'],"['optimizations', 'optimize', 'optimizing']"
Performance,"// This friend element was added by the chain that owns this; // tree, the chain will deal with loading the correct entry.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx:96,load,loading,96,tree/tree/src/TTree.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx,1,['load'],['loading']
Performance,"// This function calculates the register usage by measuring the highest number; // of values that are alive at a single location. Obviously, this is a very; // rough estimation. We scan the loop in a topological order in order and; // assign a number to each instruction. We use RPO to ensure that defs are; // met before their users. We assume that each instruction that has in-loop; // users starts an interval. We record every time that an in-loop value is; // used, so we have a list of the first and last occurrences of each; // instruction. Next, we transpose this data structure into a multi map that; // holds the list of intervals that *end* at a specific location. This multi; // map allows us to perform a linear search. We scan the instructions linearly; // and record each time that a new interval starts, by placing it in a set.; // If we find this value in the multi-map then we remove it from the set.; // The max register usage is the maximum size of the set.; // We also search for instructions that are defined outside the loop, but are; // used inside the loop. We need this number separately from the max-interval; // usage number because when we unroll, loop-invariant values do not take; // more register.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:707,perform,perform,707,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,1,['perform'],['perform']
Performance,"// This function can be performance-critical, so we rely on the power-of-2; // knowledge that we have about the mask sizes to replace div/rem ops with; // bit-masks and shifts.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:24,perform,performance-critical,24,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['perform'],['performance-critical']
Performance,// This function checks if the parameter Inst is part of the setup for a link; // time GOT PC Relative optimization. For example in this situation:; // <MCInst PLDpc <MCOperand Reg:282> <MCOperand Expr:(glob_double@got@pcrel)>; // <MCOperand Imm:0> <MCOperand Expr:(.Lpcrel@<<invalid>>)>>; // <MCInst SOME_LOAD <MCOperand Reg:22> <MCOperand Imm:0> <MCOperand Reg:282>; // <MCOperand Expr:(.Lpcrel@<<invalid>>)>>; // The above is a pair of such instructions and this function will not return; // std::nullopt for either one of them. In both cases we are looking for the; // last operand <MCOperand Expr:(.Lpcrel@<<invalid>>)> which needs to be an; // MCExpr and has the flag MCSymbolRefExpr::VK_PPC_PCREL_OPT. After that we just; // look at the opcode and in the case of PLDpc we will return true. For the load; // (or store) this function will return false indicating it has found the second; // instruciton in the pair.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/MCTargetDesc/PPCELFStreamer.cpp:103,optimiz,optimization,103,interpreter/llvm-project/llvm/lib/Target/PowerPC/MCTargetDesc/PPCELFStreamer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/MCTargetDesc/PPCELFStreamer.cpp,2,"['load', 'optimiz']","['load', 'optimization']"
Performance,"// This function checks to see if an expansion of memcmp can be generated.; // It checks for constant compare size that is less than the max inline size.; // If an expansion cannot occur, returns false to leave as a library call.; // Otherwise, the library call is replaced with a new IR instruction sequence.; /// We want to transform:; /// %call = call signext i32 @memcmp(i8* %0, i8* %1, i64 15); /// To:; /// loadbb:; /// %0 = bitcast i32* %buffer2 to i8*; /// %1 = bitcast i32* %buffer1 to i8*; /// %2 = bitcast i8* %1 to i64*; /// %3 = bitcast i8* %0 to i64*; /// %4 = load i64, i64* %2; /// %5 = load i64, i64* %3; /// %6 = call i64 @llvm.bswap.i64(i64 %4); /// %7 = call i64 @llvm.bswap.i64(i64 %5); /// %8 = sub i64 %6, %7; /// %9 = icmp ne i64 %8, 0; /// br i1 %9, label %res_block, label %loadbb1; /// res_block: ; preds = %loadbb2,; /// %loadbb1, %loadbb; /// %phi.src1 = phi i64 [ %6, %loadbb ], [ %22, %loadbb1 ], [ %36, %loadbb2 ]; /// %phi.src2 = phi i64 [ %7, %loadbb ], [ %23, %loadbb1 ], [ %37, %loadbb2 ]; /// %10 = icmp ult i64 %phi.src1, %phi.src2; /// %11 = select i1 %10, i32 -1, i32 1; /// br label %endblock; /// loadbb1: ; preds = %loadbb; /// %12 = bitcast i32* %buffer2 to i8*; /// %13 = bitcast i32* %buffer1 to i8*; /// %14 = bitcast i8* %13 to i32*; /// %15 = bitcast i8* %12 to i32*; /// %16 = getelementptr i32, i32* %14, i32 2; /// %17 = getelementptr i32, i32* %15, i32 2; /// %18 = load i32, i32* %16; /// %19 = load i32, i32* %17; /// %20 = call i32 @llvm.bswap.i32(i32 %18); /// %21 = call i32 @llvm.bswap.i32(i32 %19); /// %22 = zext i32 %20 to i64; /// %23 = zext i32 %21 to i64; /// %24 = sub i64 %22, %23; /// %25 = icmp ne i64 %24, 0; /// br i1 %25, label %res_block, label %loadbb2; /// loadbb2: ; preds = %loadbb1; /// %26 = bitcast i32* %buffer2 to i8*; /// %27 = bitcast i32* %buffer1 to i8*; /// %28 = bitcast i8* %27 to i16*; /// %29 = bitcast i8* %26 to i16*; /// %30 = getelementptr i16, i16* %28, i16 6; /// %31 = getelementptr i16, i16* %29, i16 6",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp:413,load,loadbb,413,interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,5,['load'],"['load', 'loadbb']"
Performance,"// This function converts the set of members for a congruence class from values,; // to the set of defs for loads and stores, with associated DFS info.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp:108,load,loads,108,interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,1,['load'],['loads']
Performance,// This function creates the IR instructions for loading and comparing 1 byte.; // It loads 1 byte from each source of the memcmp parameters with the given; // GEPIndex. It then subtracts the two loaded values and adds this result to the; // final phi node for selecting the memcmp result.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp:49,load,loading,49,interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,3,['load'],"['loaded', 'loading', 'loads']"
Performance,"// This function creates the IR intructions for loading and comparing using the; // given LoadSize. It loads the number of bytes specified by LoadSize from each; // source of the memcmp parameters. It then does a subtract to see if there was; // a difference in the loaded values. If a difference is found, it branches; // with an early exit to the ResultBlock for calculating which source was; // larger. Otherwise, it falls through to the either the next LoadCmpBlock or; // the EndBlock if this is the last LoadCmpBlock. Loading 1 byte is handled with; // a special case through emitLoadCompareByteBlock. The special handling can; // simply subtract the loaded values and add it to the result phi node.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp:48,load,loading,48,interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,9,"['Load', 'load']","['LoadCmpBlock', 'LoadSize', 'Loading', 'loaded', 'loading', 'loads']"
Performance,"// This function does custom insertion during lowering BPFISD::MEMCPY which; // only has two register operands from memcpy semantics, the copy source; // address and the copy destination address.; //; // Because we will expand BPFISD::MEMCPY into load/store pairs, we will need; // a third scratch register to serve as the destination register of load and; // source register of store.; //; // The scratch register here is with the Define | Dead | EarlyClobber flags.; // The EarlyClobber flag has the semantic property that the operand it is; // attached to is clobbered before the rest of the inputs are read. Hence it; // must be unique among the operands to the instruction. The Define flag is; // needed to coerce the machine verifier that an Undef value isn't a problem; // as we anyway is loading memory into it. The Dead flag is needed as the; // value in scratch isn't supposed to be used by any other instruction.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFISelLowering.cpp:247,load,load,247,interpreter/llvm-project/llvm/lib/Target/BPF/BPFISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFISelLowering.cpp,3,['load'],"['load', 'loading']"
Performance,"// This function does not (and should not) attempt to check in the; // list of loaded classes or in the typedef.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:79,load,loaded,79,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,3,['load'],['loaded']
Performance,"// This function doesn't use getAndAdvanceChar because C++0x [lex.pptoken]p3:; // Between the initial and final double quote characters of the raw string,; // any transformations performed in phases 1 and 2 (trigraphs,; // universal-character-names, and line splicing) are reverted.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/Lexer.cpp:179,perform,performed,179,interpreter/llvm-project/clang/lib/Lex/Lexer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/Lexer.cpp,1,['perform'],['performed']
Performance,// This function expands PseudoRV32ZdinxLoad for loading a double-precision; // floating-point value from memory into an equivalent instruction sequence for; // RV32.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVExpandPseudoInsts.cpp:49,load,loading,49,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVExpandPseudoInsts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVExpandPseudoInsts.cpp,1,['load'],['loading']
Performance,"// This function indicates whether the emergency spillslot should be placed; // close to the beginning of the stackframe (closer to FP) or the end; // (closer to SP).; //; // The beginning works most reliably if we have a frame pointer.; // In the presence of any non-constant space between FP and locals,; // (e.g. in case of stack realignment or a scalable SVE area), it is; // better to use SP or BP.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64RegisterInfo.cpp:350,scalab,scalable,350,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64RegisterInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64RegisterInfo.cpp,1,['scalab'],['scalable']
Performance,"// This function inserts instructions in order to optimize interactions between; // SPR registers and DPR/QPR registers. It does so by performing VDUPs on all; // lanes, and the using VEXT instructions to recompose the result.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/A15SDOptimizer.cpp:50,optimiz,optimize,50,interpreter/llvm-project/llvm/lib/Target/ARM/A15SDOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/A15SDOptimizer.cpp,2,"['optimiz', 'perform']","['optimize', 'performing']"
Performance,// This function is almost a copy of SelectionDAG::expandVAArg().; // The only diff is that this one produces loads from local address space.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:110,load,loads,110,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,1,['load'],['loads']
Performance,"// This function is called by a client after using the low-level API to add; // live-out and live-in blocks. The unique value optimization is not; // available, SplitEditor::transferValues handles that case directly anyway.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveRangeCalc.cpp:126,optimiz,optimization,126,interpreter/llvm-project/llvm/lib/CodeGen/LiveRangeCalc.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveRangeCalc.cpp,1,['optimiz'],['optimization']
Performance,"// This function is called for all ""deserialized"" decls, where the; // ""deserialized"" decl either really comes from an AST file or from; // a header that's loaded to import the AST for a library with a dictionary; // (the non-PCM case).; //; // Functions that are inlined must be sent to CodeGen - they will not have a; // symbol in the library.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/DeclCollector.cpp:156,load,loaded,156,interpreter/cling/lib/Interpreter/DeclCollector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/DeclCollector.cpp,1,['load'],['loaded']
Performance,"// This function is copied and adapted from NamedDecl::printQualifiedName(); // By matching each part individually we optimize in a couple of ways:; // - We can exit early on the first failure.; // - We can skip inline/anonymous namespaces without another pass.; // - We print one name at a time, reducing the chance of overflowing the; // inlined space of the SmallString.; // First, match the name.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/ASTMatchers/ASTMatchersInternal.cpp:118,optimiz,optimize,118,interpreter/llvm-project/clang/lib/ASTMatchers/ASTMatchersInternal.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/ASTMatchers/ASTMatchersInternal.cpp,1,['optimiz'],['optimize']
Performance,// This function is for memory optimization by shortening the lifetimes; // of CoverageMappingReader instances.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ProfileData/Coverage/CoverageMapping.cpp:31,optimiz,optimization,31,interpreter/llvm-project/llvm/lib/ProfileData/Coverage/CoverageMapping.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ProfileData/Coverage/CoverageMapping.cpp,1,['optimiz'],['optimization']
Performance,"// This function is normally used with SP which is Address Register, but AND,; // or any other logical instructions in M68k do not support ARs so we need; // to use a temp Data Register to perform the op.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/M68k/M68kFrameLowering.cpp:189,perform,perform,189,interpreter/llvm-project/llvm/lib/Target/M68k/M68kFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/M68k/M68kFrameLowering.cpp,1,['perform'],['perform']
Performance,"// This function is superhot. No branches here, breaks inlining and makes; // overall performance around 4x slower.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/DynamicLibraryManagerSymbol.cpp:86,perform,performance,86,interpreter/cling/lib/Interpreter/DynamicLibraryManagerSymbol.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/DynamicLibraryManagerSymbol.cpp,1,['perform'],['performance']
Performance,"// This function is to check whether the ""Offset"" is in the correct range of; // the given ""Opcode"". If ""Offset"" is not in the correct range, ""A2_addi"" is; // inserted to calculate the final address. Due to this reason, the function; // assumes that the ""Offset"" has correct alignment.; // We used to assert if the offset was not properly aligned, however,; // there are cases where a misaligned pointer recast can cause this; // problem, and we need to allow for it. The front end warns of such; // misaligns with respect to load size.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonInstrInfo.cpp:526,load,load,526,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonInstrInfo.cpp,1,['load'],['load']
Performance,"// This function is used when removing elements: when a vector is compared; // to a non-vector or a scalable vector to any non-scalable MVT, it should; // return false (to avoid removal).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.cpp:100,scalab,scalable,100,interpreter/llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.cpp,2,['scalab'],['scalable']
Performance,"// This function loads the default behavior for the; // loading of classes.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TGenericClassInfo.cxx:17,load,loads,17,core/meta/src/TGenericClassInfo.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TGenericClassInfo.cxx,2,['load'],"['loading', 'loads']"
Performance,// This function must be implemented if Optimizable is ever set.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/TargetInstrInfo.h:40,Optimiz,Optimizable,40,interpreter/llvm-project/llvm/include/llvm/CodeGen/TargetInstrInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/TargetInstrInfo.h,1,['Optimiz'],['Optimizable']
Performance,"// This function performed double-checked locking using `DepDirectives`.; // Assigning it must be the last thing this function does, otherwise other; // threads may skip the; // critical section (`DepDirectives != nullptr`), leading to a data race.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Tooling/DependencyScanning/DependencyScanningFilesystem.cpp:17,perform,performed,17,interpreter/llvm-project/clang/lib/Tooling/DependencyScanning/DependencyScanningFilesystem.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Tooling/DependencyScanning/DependencyScanningFilesystem.cpp,1,['perform'],['performed']
Performance,// This function performs an optimization on a specific pattern involving; // an AND operation and SETCC (Set Condition Code) node.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:17,perform,performs,17,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,2,"['optimiz', 'perform']","['optimization', 'performs']"
Performance,// This function populates the ResultBlock with a sequence to calculate the; // memcmp result. It compares the two loaded source values and returns -1 if; // src1 < src2 and 1 if src1 > src2.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp:115,load,loaded,115,interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,1,['load'],['loaded']
Performance,"// This function prints the LVI analysis for the instruction I at the beginning; // of various basic blocks. It relies on calculated values that are stored in; // the LazyValueInfoCache, and in the absence of cached values, recalculate the; // LazyValueInfo for `I`, and print that info.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LazyValueInfo.cpp:209,cache,cached,209,interpreter/llvm-project/llvm/lib/Analysis/LazyValueInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LazyValueInfo.cpp,1,['cache'],['cached']
Performance,"// This function rebuilds a coawait-expr given its operator.; // For an explicit coawait-expr, the rebuild involves the full set; // of transformations performed by BuildUnresolvedCoawaitExpr(),; // including calling await_transform().; // For an implicit coawait-expr, we need to rebuild the ""operator; // coawait"" but not await_transform(), so use BuildResolvedCoawaitExpr().; // This mirrors how the implicit CoawaitExpr is originally created; // in Sema::ActOnCoroutineBodyStart().",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/TreeTransform.h:152,perform,performed,152,interpreter/llvm-project/clang/lib/Sema/TreeTransform.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/TreeTransform.h,1,['perform'],['performed']
Performance,"// This function recognizes cases where X86 bzhi instruction can replace and; // 'and-load' sequence.; // In case of loading integer value from an array of constants which is defined; // as follows:; //; // int array[SIZE] = {0x0, 0x1, 0x3, 0x7, 0xF ..., 2^(SIZE-1) - 1}; //; // then applying a bitwise and on the result with another input.; // It's equivalent to performing bzhi (zero high bits) on the input, with the; // same index of the load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:86,load,load,86,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,4,"['load', 'perform']","['load', 'loading', 'performing']"
Performance,"// This function removes any redundant load immediates. It has two level; // loops - The outer loop finds the load immediates BBI that could be used; // to replace following redundancy. The inner loop scans instructions that; // after BBI to find redundancy and update kill/dead flags accordingly. If; // AfterBBI is the same as BBI, it is redundant, otherwise any instructions; // that modify the def register of BBI would break the scanning.; // DeadOrKillToUnset is a pointer to the previous operand that had the; // kill/dead flag set. It keeps track of the def register of BBI, the use; // registers of AfterBBIs and the def registers of AfterBBIs.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCPreEmitPeephole.cpp:39,load,load,39,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCPreEmitPeephole.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCPreEmitPeephole.cpp,2,['load'],['load']
Performance,"// This function returns a list of all PHI nodes in the tree starting from; // the RootPHI node. We perform a BFS traversal to get an ordered list of nodes.; // The list initially only contains the root PHI. When we visit a PHI node, we; // add it to the list. We continue to look for other PHI node operands while; // there are nodes to visit in the list. The function returns false if the; // optimization cannot be applied on this tree.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp:100,perform,perform,100,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp,2,"['optimiz', 'perform']","['optimization', 'perform']"
Performance,// This function returns the const value in constant pool if the \p I is a load; // from constant pool.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp:75,load,load,75,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,1,['load'],['load']
Performance,"// This function tells the analyzer's engine that symbols produced by our; // checker, most notably iterator positions, are relatively small.; // A distance between items in the container should not be very large.; // By assuming that it is within around 1/8 of the address space,; // we can help the analyzer perform operations on these symbols; // without being afraid of integer overflows.; // FIXME: Should we provide it as an API, so that all checkers could use it?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/Iterator.cpp:310,perform,perform,310,interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/Iterator.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/Iterator.cpp,1,['perform'],['perform']
Performance,// This function tries to add a comment as to what is being referenced by a load; // instruction with the base register that is the Pc. These can often be values; // in a literal pool near the Address of the instruction. The Address of the; // instruction and its immediate Value are used as a possible literal pool entry.; // The SymbolLookUp call back will return the name of a symbol referenced by the; // literal pool's entry if the referenced address is that of a symbol. Or it; // will return a pointer to a literal 'C' string if the referenced address of; // the literal pool's entry is an address into a section with C string literals.; // Or if the reference is to an Objective-C data structure it will return a; // specific reference type for it and a string.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MCDisassembler/MCExternalSymbolizer.cpp:76,load,load,76,interpreter/llvm-project/llvm/lib/MC/MCDisassembler/MCExternalSymbolizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MCDisassembler/MCExternalSymbolizer.cpp,1,['load'],['load']
Performance,// This function updates and optimizes the branching instructions of every basic; // block in a given function to account for changes in the layout.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/BasicBlockSections.cpp:29,optimiz,optimizes,29,interpreter/llvm-project/llvm/lib/CodeGen/BasicBlockSections.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/BasicBlockSections.cpp,1,['optimiz'],['optimizes']
Performance,"// This function will select a scalable VF if the target supports scalable; // vectors and a fixed one otherwise.; // TODO: we could return a pair of values that specify the max VF and; // min VF, to be used in `buildVPlans(MinVF, MaxVF)` instead of; // `buildVPlans(VF, VF)`. We cannot do it because VPLAN at the moment; // doesn't have a cost model that can choose which plan to execute if; // more than one is generated.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:31,scalab,scalable,31,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,2,['scalab'],['scalable']
Performance,"// This has to perform the lookup every time, since posing and related; // techniques can modify the name -> class mapping.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjCGNU.cpp:15,perform,perform,15,interpreter/llvm-project/clang/lib/CodeGen/CGObjCGNU.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjCGNU.cpp,1,['perform'],['perform']
Performance,// This heuristic was chosen using a empirical testing on a; // reasonably high core machine (iMacPro 18 cores / 36 threads). The cache; // sharding gives a performance edge by reducing the lock contention.; // FIXME: A better heuristic might also consider the OS to account for; // the different cost of lock contention on different OSes.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Tooling/DependencyScanning/DependencyScanningFilesystem.cpp:130,cache,cache,130,interpreter/llvm-project/clang/lib/Tooling/DependencyScanning/DependencyScanningFilesystem.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Tooling/DependencyScanning/DependencyScanningFilesystem.cpp,2,"['cache', 'perform']","['cache', 'performance']"
Performance,// This hopefully will just get inlined and removed by the optimizer.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderInternals.h:59,optimiz,optimizer,59,interpreter/llvm-project/clang/lib/Serialization/ASTReaderInternals.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderInternals.h,2,['optimiz'],['optimizer']
Performance,// This implementation handles frame registration for local targets.; // Memory managers for remote targets should re-implement this function; // and use the LoadAddr parameter.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RTDyldMemoryManager.cpp:158,Load,LoadAddr,158,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RTDyldMemoryManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RTDyldMemoryManager.cpp,1,['Load'],['LoadAddr']
Performance,"// This implements the loading of unaligned vectors as described in; // the venerable Apple Velocity Engine overview. Specifically:; // https://developer.apple.com/hardwaredrivers/ve/alignment.html; // https://developer.apple.com/hardwaredrivers/ve/code_optimization.html; //; // The general idea is to expand a sequence of one or more unaligned; // loads into an alignment-based permutation-control instruction (lvsl; // or lvsr), a series of regular vector loads (which always truncate; // their input address to an aligned address), and a series of; // permutations. The results of these permutations are the requested; // loaded values. The trick is that the last ""extra"" load is not taken; // from the address you might suspect (sizeof(vector) bytes after the; // last requested load), but rather sizeof(vector) - 1 bytes after the; // last requested vector. The point of this is to avoid a page fault if; // the base address happened to be aligned. This works because if the; // base address is aligned, then adding less than a full vector length; // will cause the last vector in the sequence to be (re)loaded.; // Otherwise, the next vector will be fetched as you might suspect was; // necessary.; // We might be able to reuse the permutation generation from; // a different base address offset from this one by an aligned amount.; // The INTRINSIC_WO_CHAIN DAG combine will attempt to perform this; // optimization later.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:23,load,loading,23,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,9,"['load', 'optimiz', 'perform']","['load', 'loaded', 'loading', 'loads', 'optimization', 'perform']"
Performance,// This increases the cost associated with multiplication and division; // to 64 times what the baseline arithmetic cost is. The arithmetic; // instruction cost was arbitrarily chosen to reduce the desirability; // of emitting arithmetic instructions that are emulated in software.; // TODO: Investigate the performance impact given specialized lowerings.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Lanai/LanaiTargetTransformInfo.h:308,perform,performance,308,interpreter/llvm-project/llvm/lib/Target/Lanai/LanaiTargetTransformInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Lanai/LanaiTargetTransformInfo.h,1,['perform'],['performance']
Performance,"// This information is used for the binned likelihood optimization.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooFit/Detail/NormalizationHelpers.h:54,optimiz,optimization,54,roofit/roofitcore/inc/RooFit/Detail/NormalizationHelpers.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooFit/Detail/NormalizationHelpers.h,1,['optimiz'],['optimization']
Performance,"// This instruction only demands the single element from the input vector.; // Skip for scalable type, the number of elements is unknown at; // compile-time.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineVectorOps.cpp:88,scalab,scalable,88,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineVectorOps.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineVectorOps.cpp,1,['scalab'],['scalable']
Performance,// This internal switch can be used to turn off the cmov/branch optimization.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86CmovConversion.cpp:64,optimiz,optimization,64,interpreter/llvm-project/llvm/lib/Target/X86/X86CmovConversion.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86CmovConversion.cpp,1,['optimiz'],['optimization']
Performance,// This is a *major* performance win.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/LiveVariables.cpp:21,perform,performance,21,interpreter/llvm-project/clang/lib/Analysis/LiveVariables.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/LiveVariables.cpp,1,['perform'],['performance']
Performance,"// This is a bitvector because, on larger functions, we may have; // thousands of touched instructions at once (entire blocks,; // instructions with hundreds of uses, etc). Even with optimization; // for when we mark whole blocks as touched, when this was a; // SmallPtrSet or DenseSet, for some functions, we spent >20% of all; // the time in GVN just managing this list. The bitvector, on the; // other hand, efficiently supports test/set/clear of both; // individual and ranges, as well as ""find next element"" This; // enables us to use it as a worklist with essentially 0 cost.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp:183,optimiz,optimization,183,interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,1,['optimiz'],['optimization']
Performance,"// This is a comparison function for a priority queue: give higher priority; // to earlier instructions.; // This operator is used as ""less"", so returning ""true"" gives InstB higher; // priority (because then InstA < InstB).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/BitTracker.cpp:48,queue,queue,48,interpreter/llvm-project/llvm/lib/Target/Hexagon/BitTracker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/BitTracker.cpp,1,['queue'],['queue']
Performance,// This is a constant address at most 32 bits. The base will be; // zero or load-immediate-shifted and the displacement will be; // the low 16 bits of the address.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:76,load,load-immediate-shifted,76,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['load-immediate-shifted']
Performance,"// This is a core module which was already loaded.; // Load system modules now and delay the other modules after we have; // loaded all system ones.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:43,load,loaded,43,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,3,"['Load', 'load']","['Load', 'loaded']"
Performance,"// This is a cunning lie. DiagnosticBuilder actually performs move; // construction in its copy constructor (but due to varied uses, it's not; // possible to conveniently express this as actual move construction). So; // the default copy ctor here is fine, because the base class disables the; // source anyway, so the user-defined ~ImmediateDiagBuilder is a safe no-op; // in that case anwyay.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Sema/Sema.h:53,perform,performs,53,interpreter/llvm-project/clang/include/clang/Sema/Sema.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Sema/Sema.h,1,['perform'],['performs']
Performance,"// This is a debug-labelled instruction, but the operand being folded isn't; // at operand zero. Most likely this means it's a load being folded in.; // Substitute any register defs from operand zero up to the one being; // folded -- past that point, we don't know what the new operand indexes; // will be.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InlineSpiller.cpp:127,load,load,127,interpreter/llvm-project/llvm/lib/CodeGen/InlineSpiller.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InlineSpiller.cpp,1,['load'],['load']
Performance,"// This is a debuggin method used to print the parameter values; // stored in the fitpanel. This is useful when performing a fit, to; // know against which values the test should be compare to.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/test/UnitTesting.cxx:112,perform,performing,112,gui/fitpanel/test/UnitTesting.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/test/UnitTesting.cxx,1,['perform'],['performing']
Performance,"// This is a doubleword splat if it is of the form; // XXPERMDI t, s, s, 0 or XXPERMDI t, s, s, 3. As above we; // must look through chains of copy-likes to find the source; // register. We turn off the marking for mention of a physical; // register, because splatting it is safe; the optimization; // will not swap the value in the physical register. Whether; // or not the two input registers are identical, we can handle; // these by adjusting the form of the XXPERMDI.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp:285,optimiz,optimization,285,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp,1,['optimiz'],['optimization']
Performance,"// This is a flash memory load, move the pointer into R31R30 and emit; // the lpm instruction.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AVR/AVRISelDAGToDAG.cpp:26,load,load,26,interpreter/llvm-project/llvm/lib/Target/AVR/AVRISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AVR/AVRISelDAGToDAG.cpp,1,['load'],['load']
Performance,"// This is a function which gets callback from cling when DynamicLibraryManager->loadLibrary failed for some reason.; // Try to solve the problem by AutoLoading. Return true when AutoLoading success, return; // false if not.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:81,load,loadLibrary,81,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,1,['load'],['loadLibrary']
Performance,"// This is a group of loads, with gaps, and without a last-member",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/VectorUtils.h:22,load,loads,22,interpreter/llvm-project/llvm/include/llvm/Analysis/VectorUtils.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/VectorUtils.h,1,['load'],['loads']
Performance,// This is a load instruction.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AVR/Disassembler/AVRDisassembler.cpp:13,load,load,13,interpreter/llvm-project/llvm/lib/Target/AVR/Disassembler/AVRDisassembler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AVR/Disassembler/AVRDisassembler.cpp,1,['load'],['load']
Performance,// This is a magic number for limiting the cache size. It was experimentally; // derived from a small Objective-C project (where the cache filled; // out to ~250 items). We can make it larger if necessary.; // FIXME: this is almost certainly full these days. Use an LRU cache?,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/SourceManager.cpp:43,cache,cache,43,interpreter/llvm-project/clang/lib/Basic/SourceManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/SourceManager.cpp,3,['cache'],['cache']
Performance,// This is a no-op load. This can be eliminated,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:19,load,load,19,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,1,['load'],['load']
Performance,"// This is a non-ARC instruction. If we're delaying an AutoreleaseRV,; // check if it's safe to skip over it; if not, optimize the AutoreleaseRV; // now.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/ObjCARC/ObjCARCOpts.cpp:118,optimiz,optimize,118,interpreter/llvm-project/llvm/lib/Transforms/ObjCARC/ObjCARCOpts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/ObjCARC/ObjCARCOpts.cpp,1,['optimiz'],['optimize']
Performance,"// This is a non-standard eliminator. The normal way to eliminate is; // to walk the dominator tree in order, keeping track of available; // values, and eliminating them. However, this is mildly; // pointless. It requires doing lookups on every instruction,; // regardless of whether we will ever eliminate it. For; // instructions part of most singleton congruence classes, we know we; // will never eliminate them.; // Instead, this eliminator looks at the congruence classes directly, sorts; // them into a DFS ordering of the dominator tree, and then we just; // perform elimination straight on the sets by walking the congruence; // class member uses in order, and eliminate the ones dominated by the; // last member. This is worst case O(E log E) where E = number of; // instructions in a single congruence class. In theory, this is all; // instructions. In practice, it is much faster, as most instructions are; // either in singleton congruence classes or can't possibly be eliminated; // anyway (if there are no overlapping DFS ranges in class).; // When we find something not dominated, it becomes the new leader; // for elimination purposes.; // TODO: If we wanted to be faster, We could remove any members with no; // overlapping ranges while sorting, as we will never eliminate anything; // with those members, as they don't dominate anything else in our set.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp:567,perform,perform,567,interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,1,['perform'],['perform']
Performance,"// This is a point in time - we determined including these pairs of; // consecutive instructions (in the IR layout available at inline time) as; // features improves the model performance. We want to move away from manual; // feature selection.; // The array is given in opcode pairs rather than labels because 1) labels; // weren't readily available, and 2) the successions were hand - extracted.; //; // This array must be sorted.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InlineSizeEstimatorAnalysis.cpp:176,perform,performance,176,interpreter/llvm-project/llvm/lib/Analysis/InlineSizeEstimatorAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InlineSizeEstimatorAnalysis.cpp,1,['perform'],['performance']
Performance,"// This is a raw type and an already loaded typedef.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:37,load,loaded,37,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,1,['load'],['loaded']
Performance,// This is a reference to a member without an explicitly-specified; // template argument list. Optimize for this common case.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/TreeTransform.h:95,Optimiz,Optimize,95,interpreter/llvm-project/clang/lib/Sema/TreeTransform.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/TreeTransform.h,1,['Optimiz'],['Optimize']
Performance,"// This is a simple greedy algorithm for merging allocas. First, sort the; // slots, placing the largest slots first. Next, perform an n^2 scan and look; // for disjoint slots. When you find disjoint slots, merge the smaller one; // into the bigger one and update the live interval. Remove the small alloca; // and continue.; // Sort the slots according to their size. Place unused slots at the end.; // Use stable sort to guarantee deterministic code generation.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/StackColoring.cpp:124,perform,perform,124,interpreter/llvm-project/llvm/lib/CodeGen/StackColoring.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/StackColoring.cpp,1,['perform'],['perform']
Performance,// This is a size optimization.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVMakeCompressible.cpp:18,optimiz,optimization,18,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVMakeCompressible.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVMakeCompressible.cpp,1,['optimiz'],['optimization']
Performance,"// This is a standard ""union of predecessor outs"" dataflow problem.; // To solve it, we perform join() and process() using the two worklist method; // until the ranges converge.; // Ranges have converged when both worklists are empty.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/VarLocBasedImpl.cpp:88,perform,perform,88,interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/VarLocBasedImpl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/VarLocBasedImpl.cpp,1,['perform'],['perform']
Performance,"// This is a target-specific version of a DAGCombine performed in; // DAGCombiner::visitBITCAST. It performs the equivalent of:; // fold (bitconvert (fneg x)) -> (xor (bitconvert x), signbit); // fold (bitconvert (fabs x)) -> (and (bitconvert x), (not signbit))",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:53,perform,performed,53,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,4,['perform'],"['performed', 'performs']"
Performance,// This is a temporary option until we change the interface to this pass based; // on optimization level.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/ADCE.cpp:86,optimiz,optimization,86,interpreter/llvm-project/llvm/lib/Transforms/Scalar/ADCE.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/ADCE.cpp,1,['optimiz'],['optimization']
Performance,// This is a type-legal unaligned Altivec load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:42,load,load,42,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['load']
Performance,"// This is a vector load that legalizes to a larger type than the vector; // itself. Unless the corresponding extending load or truncating store is; // legal, then this will scalarize.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h:20,load,load,20,interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,2,['load'],['load']
Performance,// This is a vector load/store for some illegal type that is scalarized.; // We must account for the cost of building or decomposing the vector.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h:20,load,load,20,interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,1,['load'],['load']
Performance,"// This is actually ""load effective address"" of the stack slot; // instruction. We have only two-address instructions, thus we need to; // expand it into mov + add",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/MSP430/MSP430RegisterInfo.cpp:21,load,load,21,interpreter/llvm-project/llvm/lib/Target/MSP430/MSP430RegisterInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/MSP430/MSP430RegisterInfo.cpp,1,['load'],['load']
Performance,"// This is actually ""load effective address"" of the stack slot; // instruction. We have only two-address instructions, thus we need to; // expand it into move + add.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AVR/AVRRegisterInfo.cpp:21,load,load,21,interpreter/llvm-project/llvm/lib/Target/AVR/AVRRegisterInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AVR/AVRRegisterInfo.cpp,1,['load'],['load']
Performance,"// This is already a power of 2, but we still need to split this in half.; //; // Assume we're being asked to decompose an unaligned load.; // TODO: If this requires multiple splits, handle them all at once.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalizerHelper.cpp:133,load,load,133,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalizerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalizerHelper.cpp,1,['load'],['load']
Performance,"// This is always good. However, in case of a pointer; // to an object that is guaranteed to be there and not; // being referenced by other objects we could use; // xx->Streamer(b);; // Optimize this with control statement in title.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/dictgen/src/rootcling_impl.cxx:186,Optimiz,Optimize,186,core/dictgen/src/rootcling_impl.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/dictgen/src/rootcling_impl.cxx,1,['Optimiz'],['Optimize']
Performance,"// This is an argument in memory. We might be able to perform copy elision.; // If the argument is passed directly in memory without any extension, then we; // can perform copy elision. Large vector types, for example, may be passed; // indirectly by pointer.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:54,perform,perform,54,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,2,['perform'],['perform']
Performance,// This is an extending load from a sub-dword size. Widen the memory; // access size to 4 bytes and clear the extra high bits appropriately,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPURegisterBankInfo.cpp:24,load,load,24,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPURegisterBankInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPURegisterBankInfo.cpp,1,['load'],['load']
Performance,// This is an imperfect hack to prevent constant hoisting of; // compares that might be trying to check if a 64-bit value fits in; // 32-bits. The backend can optimize these cases using a right shift by 32.; // Ideally we would check the compare predicate here. There also other; // similar immediates the backend can use shifts for.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:159,optimiz,optimize,159,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,1,['optimiz'],['optimize']
Performance,// This is an optimization for a specific case when this Range covers; // the whole range of the target type.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/RangeConstraintManager.cpp:14,optimiz,optimization,14,interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/RangeConstraintManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/RangeConstraintManager.cpp,1,['optimiz'],['optimization']
Performance,"// This is an optimization that should work in most cases.; // As a side effect, it may cause selection of an alias; // instead of a primary operand name in case of sparse tables.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/Utils/AMDGPUBaseInfo.cpp:14,optimiz,optimization,14,interpreter/llvm-project/llvm/lib/Target/AMDGPU/Utils/AMDGPUBaseInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/Utils/AMDGPUBaseInfo.cpp,1,['optimiz'],['optimization']
Performance,"// This is an optimized override for the equidistant-equidistant case,; // fall back to the default implementation if we're not in that case.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/histv7/src/RAxis.cxx:14,optimiz,optimized,14,hist/histv7/src/RAxis.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/histv7/src/RAxis.cxx,1,['optimiz'],['optimized']
Performance,"// This is an optimized override for the irregular-irregular case,; // fall back to the default implementation if we're not in that case.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/histv7/src/RAxis.cxx:14,optimiz,optimized,14,hist/histv7/src/RAxis.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/histv7/src/RAxis.cxx,1,['optimiz'],['optimized']
Performance,"// This is anyextending load, use 4 byte lwr/lwl.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsLegalizerInfo.cpp:24,load,load,24,interpreter/llvm-project/llvm/lib/Target/Mips/MipsLegalizerInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsLegalizerInfo.cpp,1,['load'],['load']
Performance,// This is basically copied from process() and inverted (process is; // performing something like a union whereas this is more of an; // intersect).; // There's no work to do if interval `a` overlaps no fragments in map `B`.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AssignmentTrackingAnalysis.cpp:72,perform,performing,72,interpreter/llvm-project/llvm/lib/CodeGen/AssignmentTrackingAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AssignmentTrackingAnalysis.cpp,1,['perform'],['performing']
Performance,// This is complicated by the tail call optimization. For non-PIC code; // there is only a 32bit sized unconditional branch which can be assumed; // to be able to reach the target. b16 only has a range of +/- 1 KB.; // It's entirely possible that the target function is reachable with b16; // but we don't have enough information to make that decision.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsDelaySlotFiller.cpp:40,optimiz,optimization,40,interpreter/llvm-project/llvm/lib/Target/Mips/MipsDelaySlotFiller.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsDelaySlotFiller.cpp,1,['optimiz'],['optimization']
Performance,"// This is deferred from part 2 - but must happen after part 3 - otherwise invalid bins cannot be properly marked in cacheValidEntries",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsOptTestStatistic.cxx:117,cache,cacheValidEntries,117,roofit/roofitcore/src/RooAbsOptTestStatistic.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsOptTestStatistic.cxx,1,['cache'],['cacheValidEntries']
Performance,// This is disabled by default because having separate loads and stores; // makes it more likely that the -combiner-alias-analysis limits will be; // reached.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/Scalarizer.cpp:55,load,loads,55,interpreter/llvm-project/llvm/lib/Transforms/Scalar/Scalarizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/Scalarizer.cpp,1,['load'],['loads']
Performance,// This is done in SVEIntrinsicOpts rather than InstCombine so that we introduce; // scalable loads as late as possible,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/SVEIntrinsicOpts.cpp:85,scalab,scalable,85,interpreter/llvm-project/llvm/lib/Target/AArch64/SVEIntrinsicOpts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/SVEIntrinsicOpts.cpp,2,"['load', 'scalab']","['loads', 'scalable']"
Performance,// This is done in SVEIntrinsicOpts rather than InstCombine so that we introduce; // scalable stores as late as possible,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/SVEIntrinsicOpts.cpp:85,scalab,scalable,85,interpreter/llvm-project/llvm/lib/Target/AArch64/SVEIntrinsicOpts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/SVEIntrinsicOpts.cpp,1,['scalab'],['scalable']
Performance,"// This is endian dependent, but it will only work on x86 anyway.; // FIXME: Will not trap if loading a signaling NaN.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/ExecutionEngine.cpp:94,load,loading,94,interpreter/llvm-project/llvm/lib/ExecutionEngine/ExecutionEngine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/ExecutionEngine.cpp,1,['load'],['loading']
Performance,"// This is for dynamic loads ...",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/auth/src/TAuthenticate.cxx:23,load,loads,23,net/auth/src/TAuthenticate.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/auth/src/TAuthenticate.cxx,1,['load'],['loads']
Performance,"// This is hot code, so optimize the two most common cases of 1 and 2; // results.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGISel.cpp:24,optimiz,optimize,24,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGISel.cpp,1,['optimiz'],['optimize']
Performance,"// This is macOS-specific work-around and makes no sense for any; // other host OS. See https://openradar.appspot.com/FB8914231; //; // The macOS kernel maintains a signature-verification cache to; // quickly validate applications at time of execve(2). The trouble; // is that for the kernel creates the cache entry at the time of the; // mmap(2) call, before we have a chance to write either the code to; // sign or the signature header+hashes. The fix is to invalidate; // all cached data associated with the output file, thus discarding; // the bogus prematurely-cached signature.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOWriter.cpp:188,cache,cache,188,interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOWriter.cpp,4,['cache'],"['cache', 'cached']"
Performance,"// This is marked always_inline and nodebug so it doesn't show up in stack; // traces at -O0 (or other optimization levels). Large TypeSwitch's are; // common, are equivalent to a switch, and don't add any value to stack; // traces.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/TypeSwitch.h:103,optimiz,optimization,103,interpreter/llvm-project/llvm/include/llvm/ADT/TypeSwitch.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/TypeSwitch.h,1,['optimiz'],['optimization']
Performance,// This is needed to perform LCSSA verification inside LPPassManager,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LCSSA.cpp:21,perform,perform,21,interpreter/llvm-project/llvm/lib/Transforms/Utils/LCSSA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LCSSA.cpp,1,['perform'],['perform']
Performance,"// This is not a micro-optimization, it avoids UB, should Borrowed be an null; // buffer.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Demangle/MicrosoftDemangle.cpp:23,optimiz,optimization,23,interpreter/llvm-project/llvm/lib/Demangle/MicrosoftDemangle.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Demangle/MicrosoftDemangle.cpp,1,['optimiz'],['optimization']
Performance,"// This is not always beneficial to transform. Exts can be incorporated into; // loads, Truncs can be folded into stores.; // Truncs are usually the same number of instructions,; // VSTRH.32(A);VSTRH.32(B) vs VSTRH.16(VMOVNT A, B) with interleaving; // Exts are unfortunately more instructions in the general case:; // A=VLDRH.32; B=VLDRH.32;; // vs with interleaving:; // T=VLDRH.16; A=VMOVNB T; B=VMOVNT T; // But those VMOVL may be folded into a VMULL.; // But expensive extends/truncs are always good to remove. FPExts always; // involve extra VCVT's so are always considered to be beneficial to convert.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/MVELaneInterleavingPass.cpp:81,load,loads,81,interpreter/llvm-project/llvm/lib/Target/ARM/MVELaneInterleavingPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/MVELaneInterleavingPass.cpp,1,['load'],['loads']
Performance,"// This is not an essential optimization and it has a noticeable impact on; // compilation time, so we only enable it from O2.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUTargetMachine.cpp:28,optimiz,optimization,28,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUTargetMachine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUTargetMachine.cpp,1,['optimiz'],['optimization']
Performance,// This is not an outlined function region - need to call __kmpc_int32; // kmpc_global_thread_num(ident_t *loc).; // Generate thread id value and cache this value for use across the; // function.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp:146,cache,cache,146,interpreter/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp,1,['cache'],['cache']
Performance,"// This is not the first piece of an argument in memory. See if there is; // already a fixed stack object including this offset. If so, assume it; // was created by the PartOffset == 0 branch above and create a load from; // the appropriate offset into it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp:211,load,load,211,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLoweringCall.cpp,1,['load'],['load']
Performance,"// This is pretty easy. We're taking the value that we received from; // our load from the relocation, sticking it in either RDI (x86-64); // or EAX and doing an indirect call. The return value will then; // be in the normal return register.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:77,load,load,77,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,// This is really weird but for some magic scheduling regions twice; // gives performance improvement,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNIterativeScheduler.cpp:78,perform,performance,78,interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNIterativeScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNIterativeScheduler.cpp,1,['perform'],['performance']
Performance,"// This is recognising a LD1 single-element structure to one lane of one; // register instruction. I.e., if this is an `insertelement` instruction,; // and its second operand is a load, then we will generate a LD1, which; // are expensive instructions.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp:180,load,load,180,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,1,['load'],['load']
Performance,"// This is something like an NRVO variable, where the pointer has been; // spilt to the stack. It should end up being a memory location, with; // the pointer to the variable loaded off the stack with a deref:",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.cpp:174,load,loaded,174,interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.cpp,1,['load'],['loaded']
Performance,"// This is still a valid proxy.; // All updates to preserve valid results are done below, so we don't need to; // invalidate this proxy.; //; // Note that in order to preserve this proxy, a module pass must ensure that; // the FAM has been completely updated to handle the deletion of functions.; // Specifically, any FAM-cached results for those functions need to have been; // forcibly cleared. When preserved, this proxy will only invalidate results; // cached on functions *still in the module* at the end of the module pass.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CGSCCPassManager.cpp:322,cache,cached,322,interpreter/llvm-project/llvm/lib/Analysis/CGSCCPassManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CGSCCPassManager.cpp,2,['cache'],['cached']
Performance,"// This is still a valid proxy.; // If this proxy isn't marked as preserved, then even if the result remains; // valid, the key itself may no longer be valid, so we clear everything.; //; // Note that in order to preserve this proxy, a module pass must ensure that; // the FAM has been completely updated to handle the deletion of functions.; // Specifically, any FAM-cached results for those functions need to have been; // forcibly cleared. When preserved, this proxy will only invalidate results; // cached on functions *still in the module* at the end of the module pass.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/PassManager.cpp:368,cache,cached,368,interpreter/llvm-project/llvm/lib/IR/PassManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/PassManager.cpp,2,['cache'],['cached']
Performance,// This is still used for explicit load from addrspace(8),MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/R600ISelLowering.cpp:35,load,load,35,interpreter/llvm-project/llvm/lib/Target/AMDGPU/R600ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/R600ISelLowering.cpp,1,['load'],['load']
Performance,// This is temporary solution to test performance. Float should be; // replaced with round independent type (based on integers) to avoid; // different results for different target builds.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopStrengthReduce.cpp:38,perform,performance,38,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopStrengthReduce.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopStrengthReduce.cpp,1,['perform'],['performance']
Performance,"// This is the __NO_INLINE__ define, which just depends on things like the; // optimization level and -fno-inline, not actually whether the backend has; // inlining enabled.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInvocation.cpp:79,optimiz,optimization,79,interpreter/llvm-project/clang/lib/Frontend/CompilerInvocation.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInvocation.cpp,1,['optimiz'],['optimization']
Performance,"// This is the first ""real"" definition of the namespace ""std"", so update; // our cache of the ""std"" namespace to point at this definition.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp:81,cache,cache,81,interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp,1,['cache'],['cache']
Performance,"// This is the high-performance happy path, though getting here depends; // on the caller giving us a long enough input.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/blake3.c:20,perform,performance,20,interpreter/llvm-project/llvm/lib/Support/BLAKE3/blake3.c,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/blake3.c,1,['perform'],['performance']
Performance,"// This is the last chance we have of checking copy elision eligibility; // for functions in dependent contexts. The sema actions for building; // the return statement during template instantiation will have no effect; // regarding copy elision, since NRVO propagation runs on the scope exit; // actions, and these are not run on instantiation.; // This might run through some VarDecls which were returned from non-taken; // 'if constexpr' branches, and these will end up being constructed on the; // return slot even if they will never be returned, as a sort of accidental; // 'optimization'. Notably, functions with 'auto' return types won't have it; // deduced by this point. Coupled with the limitation described; // previously, this makes it very hard to support copy elision for these.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplateInstantiateDecl.cpp:579,optimiz,optimization,579,interpreter/llvm-project/clang/lib/Sema/SemaTemplateInstantiateDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplateInstantiateDecl.cpp,1,['optimiz'],['optimization']
Performance,// This is the native endianness case that is most common and optimized for; // efficient lookups. Here we just grab pointers to the native data and; // use ArrayRef objects to allow efficient read only access.; // Read the address offsets.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DebugInfo/GSYM/GsymReader.cpp:62,optimiz,optimized,62,interpreter/llvm-project/llvm/lib/DebugInfo/GSYM/GsymReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DebugInfo/GSYM/GsymReader.cpp,1,['optimiz'],['optimized']
Performance,"// This is the new cost model returned from loop cache analysis.; // A smaller index means the loop should be placed an outer loop, and vice; // versa.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopInterchange.cpp:49,cache,cache,49,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopInterchange.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopInterchange.cpp,1,['cache'],['cache']
Performance,// This is the new location for the loads / stores.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp:36,load,loads,36,interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp,1,['load'],['loads']
Performance,// This is the non native endianness case that is not common and not; // optimized for lookups. Here we decode the important tables into local; // storage and then set the ArrayRef objects to point to these swapped; // copies of the read only data so lookups can be as efficient as possible.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DebugInfo/GSYM/GsymReader.cpp:73,optimiz,optimized,73,interpreter/llvm-project/llvm/lib/DebugInfo/GSYM/GsymReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DebugInfo/GSYM/GsymReader.cpp,1,['optimiz'],['optimized']
Performance,"// This is the offset to the index, when we see this we skip all the; // records and load only an index to these.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Reader/MetadataLoader.cpp:85,load,load,85,interpreter/llvm-project/llvm/lib/Bitcode/Reader/MetadataLoader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Reader/MetadataLoader.cpp,1,['load'],['load']
Performance,"// This is the same as getStoreValueForLoad, except it performs no insertion.; // It returns nullptr if it cannot produce a constant.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Utils/VNCoercion.h:55,perform,performs,55,interpreter/llvm-project/llvm/include/llvm/Transforms/Utils/VNCoercion.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Utils/VNCoercion.h,1,['perform'],['performs']
Performance,"// This is the same as getValueForLoad, except it performs no insertion.; // It only allows constant inputs.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Utils/VNCoercion.h:50,perform,performs,50,interpreter/llvm-project/llvm/include/llvm/Transforms/Utils/VNCoercion.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Utils/VNCoercion.h,1,['perform'],['performs']
Performance,"// This is the set of blocks that need to be recomputed. In the cached case,; // this can happen due to instructions being deleted etc. In the uncached; // case, this starts out as the set of predecessors we care about.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp:64,cache,cached,64,interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,1,['cache'],['cached']
Performance,"// This is the very rare case (i.e. called before any dictionary load); // so we don't need to execute this outside of the critical section.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/cont/src/TClassTable.cxx:65,load,load,65,core/cont/src/TClassTable.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/cont/src/TClassTable.cxx,1,['load'],['load']
Performance,// This is used by the use optimizer and updater.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/MemorySSA.h:27,optimiz,optimizer,27,interpreter/llvm-project/llvm/include/llvm/Analysis/MemorySSA.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/MemorySSA.h,2,['optimiz'],['optimizer']
Performance,// This is used in the LPPassManager to perform LCSSA verification on passes; // which preserve lcssa form,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopUtils.cpp:40,perform,perform,40,interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopUtils.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopUtils.cpp,1,['perform'],['perform']
Performance,// This is used to cache the decision of whether to leave the interleaved; // store instructions replacement pass early or not for a particular target.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64SIMDInstrOpt.cpp:19,cache,cache,19,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64SIMDInstrOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64SIMDInstrOpt.cpp,1,['cache'],['cache']
Performance,"// This is used to handle spills for 128/256-bit registers when we have AVX512,; // but not VLX. If it uses an extended register we need to use an instruction; // that loads the lower 128/256-bit, but is available with only AVX512F.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp:168,load,loads,168,interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp,1,['load'],['loads']
Performance,// This is useful information to dump after bumpNode.; // Note that the Queue contents are more useful before pickNodeFromQueue.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp:72,Queue,Queue,72,interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp,1,['Queue'],['Queue']
Performance,"// This isn't actually true, but the instructions ignore any of the; // upper bits, so any immediate loaded with an LI is acceptable.; // This does not apply to shift right algebraic because a value; // out of range will produce a -1/0.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp:101,load,loaded,101,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,2,['load'],['loaded']
Performance,// This isn't exactly right. We're using slow unaligned 32-byte accesses; // as a proxy for a double-pumped AVX memory interface such as on; // Sandybridge.; // Sub-32-bit loads/stores will be slower either with PINSR*/PEXTR* or; // will be scalarized.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:172,load,loads,172,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,1,['load'],['loads']
Performance,"// This latency applies to Pentium M, Merom, Wolfdale, Nehalem, and Sandy; // Bridge. Probably Ivy Bridge as well.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp:8,latency,latency,8,interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp,1,['latency'],['latency']
Performance,"// This linker time GOT PC Relative optimization relocation will look like this:; // pld <reg> symbol@got@pcrel; // <Label###>:; // .reloc Label###-8,R_PPC64_PCREL_OPT,.-(Label###-8); // load <loadedreg>, 0(<reg>); // The reason we place the label after the PLDpc instruction is that there; // may be an alignment nop before it since prefixed instructions must not; // cross a 64-byte boundary (please see; // PPCELFStreamer::emitPrefixedInstruction()). When referring to the; // label, we subtract the width of a prefixed instruction (8 bytes) to ensure; // we refer to the PLDpc.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/MCTargetDesc/PPCELFStreamer.cpp:36,optimiz,optimization,36,interpreter/llvm-project/llvm/lib/Target/PowerPC/MCTargetDesc/PPCELFStreamer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/MCTargetDesc/PPCELFStreamer.cpp,3,"['load', 'optimiz']","['load', 'loadedreg', 'optimization']"
Performance,"// This list is very small, so this need not be optimized.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/ARCMigrate/ObjCMT.cpp:48,optimiz,optimized,48,interpreter/llvm-project/clang/lib/ARCMigrate/ObjCMT.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/ARCMigrate/ObjCMT.cpp,1,['optimiz'],['optimized']
Performance,// This load (store) aliases with a preceding store (load). Delay; // it until the depenency is cleared.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MCA/Stages/InOrderIssueStage.cpp:8,load,load,8,interpreter/llvm-project/llvm/lib/MCA/Stages/InOrderIssueStage.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MCA/Stages/InOrderIssueStage.cpp,2,['load'],['load']
Performance,"// This load is not sufficiently aligned, so bail out and let this vector; // load be scalarized. Note that we may still be able to emit smaller; // vector loads. For example, if we are loading a <4 x float> with an; // alignment of 8, this check will fail but the legalizer will try again; // with 2 x <2 x float>, which will succeed with an alignment of 8.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:8,load,load,8,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,4,['load'],"['load', 'loading', 'loads']"
Performance,// This load needs splitting into power of 2 sized loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalizerHelper.cpp:8,load,load,8,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalizerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalizerHelper.cpp,2,['load'],"['load', 'loads']"
Performance,"// This load needs splitting into power of 2 sized loads.; //; // Our strategy here is to generate anyextending loads for the smaller; // types up to next power-2 result type, and then combine the two larger; // result values together, before truncating back down to the non-pow-2; // type.; // E.g. v1 = i24 load =>; // v2 = i32 zextload (2 byte); // v3 = i32 load (1 byte); // v4 = i32 shl v3, 16; // v5 = i32 or v4, v2; // v1 = i24 trunc v5; // By doing this we generate the correct truncate which should get; // combined away as an artifact with a matching extend.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalizerHelper.cpp:8,load,load,8,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalizerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalizerHelper.cpp,5,['load'],"['load', 'loads']"
Performance,// This load will be eliminated by the IPSCCP because it is constant; // weak_odr without externally_initialized. Either changing it to weak or; // adding externally_initialized will keep the load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:8,load,load,8,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,2,['load'],['load']
Performance,"// This lock is held during iteration over several data structures: the collection of in-flight clusters,; // the current pool of cached clusters, and the set of cluster ids to be preloaded.; // All three collections are expected to be small (certainly < 100, more likely < 10). All operations; // are non-blocking and moving around small items (pointers, ids, etc). Thus the overall locking time should; // still be reasonably small and the lock is rarely taken (usually once per cluster).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RClusterPool.cxx:130,cache,cached,130,tree/ntuple/v7/src/RClusterPool.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RClusterPool.cxx,1,['cache'],['cached']
Performance,// This looks like a vector load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp:28,load,load,28,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp,1,['load'],['load']
Performance,// This loop populates each of the LoadCmpBlocks with the IR sequence to; // handle multiple loads per block.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp:35,Load,LoadCmpBlocks,35,interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,2,"['Load', 'load']","['LoadCmpBlocks', 'loads']"
Performance,// This loop scans instructions after BBI to see if there is any; // redundant load immediate.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCPreEmitPeephole.cpp:79,load,load,79,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCPreEmitPeephole.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCPreEmitPeephole.cpp,1,['load'],['load']
Performance,"// This lowers an INSERT_SUBVECTOR by extracting the individual elements from; // the small vector and inserting them into the big vector. That is better than; // the default expansion of doing it via a stack slot. Even though the use of; // the stack slot would be optimized away afterwards, the stack slot itself; // remains.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:266,optimiz,optimized,266,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,1,['optimiz'],['optimized']
Performance,"// This macro loads the shared library libEvent.so provided in $ROOTSYS/test.; // Before executing this macro, we assume that:; // - you have changed your current directory to $ROOTSYS/test.; // - you have executed Event.; // If not, go to directory test and issue the commands:; // make Event to generate the executable module and shared library; // Event to produce the file Event.root; //; // Load shared library created in $ROOTSYS/test/libEvent.so",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/test/eventload.cxx:14,load,loads,14,test/eventload.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/test/eventload.cxx,2,"['Load', 'load']","['Load', 'loads']"
Performance,// This map is used to track the relationship between the virtual; // register that is the result of a load that is moved and the DBG_VALUE; // MachineInstr pointer that uses that virtual register.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp:103,load,load,103,interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp,1,['load'],['load']
Performance,"// This map keeps track of the number of ""unsafe"" uses of a loaded function; // pointer. The key is the associated llvm.type.test intrinsic call generated; // by this pass. An unsafe use is one that calls the loaded function pointer; // directly. Every time we eliminate an unsafe use (for example, by; // devirtualizing it or by applying virtual constant propagation), we; // decrement the value stored in this map. If a value reaches zero, we can; // eliminate the type check by RAUWing the associated llvm.type.test call with; // true.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/WholeProgramDevirt.cpp:60,load,loaded,60,interpreter/llvm-project/llvm/lib/Transforms/IPO/WholeProgramDevirt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/WholeProgramDevirt.cpp,2,['load'],['loaded']
Performance,"// This may be a def / use of a variable_ops instruction, the operand; // latency might be determinable dynamically. Let the target try to; // figure it out.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp:74,latency,latency,74,interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp,1,['latency'],['latency']
Performance,// This may be a size or type changing load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/MachineIRBuilder.cpp:39,load,load,39,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/MachineIRBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/MachineIRBuilder.cpp,1,['load'],['load']
Performance,// This may be the module cache directory.; // Only cache stat failures on files that are not expected to change during; // the build.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Tooling/DependencyScanning/DependencyScanningFilesystem.cpp:26,cache,cache,26,interpreter/llvm-project/clang/lib/Tooling/DependencyScanning/DependencyScanningFilesystem.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Tooling/DependencyScanning/DependencyScanningFilesystem.cpp,2,['cache'],['cache']
Performance,"// This may not be followed by a direct initializer, but it can't be a; // function declaration either, and we'd prefer to perform a tentative; // parse in order to produce the right diagnostic.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Sema/DeclSpec.h:123,perform,perform,123,interpreter/llvm-project/clang/include/clang/Sema/DeclSpec.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Sema/DeclSpec.h,1,['perform'],['perform']
Performance,"// This may support multi-threading for zstd in the future. Note that; // different threads may produce different output, so be careful if certain; // output determinism is desired.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Support/Compression.h:20,multi-thread,multi-threading,20,interpreter/llvm-project/llvm/include/llvm/Support/Compression.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Support/Compression.h,1,['multi-thread'],['multi-threading']
Performance,// This method adds Use to the set of data dependent reads. IID is the; // instruction identifier associated with this write. ReadAdvance is the; // number of cycles to subtract from the latency of this data dependency.; // Use is in a RAW dependency with this write.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/Instruction.h:187,latency,latency,187,interpreter/llvm-project/llvm/include/llvm/MCA/Instruction.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/Instruction.h,1,['latency'],['latency']
Performance,"// This method attempts to fold trees of add(ext(load p), shl(ext(load p+4)); // into a single load of twice the size, that we extract the bottom part and top; // part so that the shl can use a shll2 instruction. The two loads in that; // example can also be larger trees of instructions, which are identical except; // for the leaves which are all loads offset from the LHS, including; // buildvectors of multiple loads. For example the RHS tree could be; // sub(zext(buildvec(load p+4, load q+4)), zext(buildvec(load r+4, load s+4))); // Whilst it can be common for the larger loads to replace LDP instructions; // (which doesn't gain anything on it's own), the larger loads can help create; // more efficient code, and in buildvectors prevent the need for ld1 lane; // inserts which can be slower than normal loads.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:49,load,load,49,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,13,['load'],"['load', 'loads']"
Performance,// This method can't handle scalable vector types.; // FIXME: This support could be added in the future.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp:28,scalab,scalable,28,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp,1,['scalab'],['scalable']
Performance,"// This method creates the following nodes, which are necessary for; // computing a global symbol's address in large-GOT mode:; //; // (load (wrapper (add %hi(sym), $gp), %lo(sym)))",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.h:136,load,load,136,interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.h,1,['load'],['load']
Performance,"// This method creates the following nodes, which are necessary for; // computing a global symbol's address:; //; // (load (wrapper $gp, %got(sym)))",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.h:118,load,load,118,interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.h,1,['load'],['load']
Performance,"// This method creates the following nodes, which are necessary for; // computing a local symbol's address:; //; // (add (load (wrapper $gp, %got(sym)), %lo(sym))",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.h:122,load,load,122,interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.h,1,['load'],['load']
Performance,// This method is intended to forget all info about loops. It should; // invalidate caches as if the following happened:; // - The trip counts of all loops have changed arbitrarily; // - Every llvm::Value has been updated in place to produce a different; // result.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp:84,cache,caches,84,interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,1,['cache'],['caches']
Performance,"// This method is relatively performance sensitive, so as a performance; // shortcut, use one AddInteger call instead of four for the next four; // fields.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/Type.cpp:29,perform,performance,29,interpreter/llvm-project/clang/lib/AST/Type.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/Type.cpp,2,['perform'],['performance']
Performance,"// This method stops the calling thread until the task queue is empty",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/thread/inc/TThreadPool.h:55,queue,queue,55,core/thread/inc/TThreadPool.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/thread/inc/TThreadPool.h,1,['queue'],['queue']
Performance,"// This method takes the specified list of LLVM input files, attempts to load; // them, either as assembly or bitcode, then link them together. It returns; // true on failure (if, for example, an input bitcode file could not be; // parsed), and false on success.; //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/bugpoint/BugDriver.cpp:73,load,load,73,interpreter/llvm-project/llvm/tools/bugpoint/BugDriver.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/bugpoint/BugDriver.cpp,1,['load'],['load']
Performance,"// This might be an implementation of a function without a prototype, in; // which case, try to do special replacement of calls which match the new; // prototype. The really key thing here is that we also potentially drop; // arguments from the call site so as to make a direct call, which makes the; // inliner happier and suppresses a number of optimizer warnings (!) about; // dropping arguments.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenModule.cpp:347,optimiz,optimizer,347,interpreter/llvm-project/clang/lib/CodeGen/CodeGenModule.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenModule.cpp,1,['optimiz'],['optimizer']
Performance,"// This might be slow if a whole population of intrinsics already existed, but; // we cache the values for later usage.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/Module.cpp:86,cache,cache,86,interpreter/llvm-project/llvm/lib/IR/Module.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/Module.cpp,1,['cache'],['cache']
Performance,"// This must be a module which has already been added but not loaded to this; // MCJIT instance, since these conditions are tested by our caller,; // generateCodeForModule.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/MCJIT/MCJIT.cpp:62,load,loaded,62,interpreter/llvm-project/llvm/lib/ExecutionEngine/MCJIT/MCJIT.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/MCJIT/MCJIT.cpp,1,['load'],['loaded']
Performance,"// This mutex prevents simultaneously loading objects from two different; // threads. This keeps us from having to protect individual data structures; // and guarantees that section allocation requests to the memory manager; // won't be interleaved between modules. It is also used in mapSectionAddress; // and resolveRelocations to protect write access to internal data structures.; //; // loadObject may be called on the same thread during the handling of; // processRelocations, and that's OK. The handling of the relocation lists; // is written in such a way as to work correctly if new elements are added to; // the end of the list while the list is being processed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldImpl.h:38,load,loading,38,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldImpl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldImpl.h,2,['load'],"['loadObject', 'loading']"
Performance,// This operation may not be performed on boolean vectors.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp:29,perform,performed,29,interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp,1,['perform'],['performed']
Performance,"// This optimisation potentially adds lots of load and store; // micro-operations, it's only really a great benefit to code-size.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp:46,load,load,46,interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp,1,['load'],['load']
Performance,"// This optimization is invalid for strict comparisons, since FNEG; // does not raise any exceptions.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:8,optimiz,optimization,8,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,1,['optimiz'],['optimization']
Performance,// This optimization only applies to GFX11 and beyond.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUImageIntrinsicOptimizer.cpp:8,optimiz,optimization,8,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUImageIntrinsicOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUImageIntrinsicOptimizer.cpp,1,['optimiz'],['optimization']
Performance,"// This optimization only makes sense if compressed instructions are emitted.; // FIXME: Support Zca, Zcf, Zcd granularity.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVMakeCompressible.cpp:8,optimiz,optimization,8,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVMakeCompressible.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVMakeCompressible.cpp,1,['optimiz'],['optimization']
Performance,// This optimization only works on little endian.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:8,optimiz,optimization,8,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['optimiz'],['optimization']
Performance,// This optimization will emit code that assumes 64-bit registers; // so we don't want to run it in 32-bit mode. Also don't run it; // on functions that are not to be optimized.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp:8,optimiz,optimization,8,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,2,['optimiz'],"['optimization', 'optimized']"
Performance,// This option is used in simplifying testing SampleFDO optimizations for; // profile loading.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp:56,optimiz,optimizations,56,interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,2,"['load', 'optimiz']","['loading', 'optimizations']"
Performance,"// This part of code attempts to optimize the LoadSequence by merging allowed; // subsequences into single loads of allowed sizes from; // `MemCmpExpansionOptions::AllowedTailExpansions`. If it is for zero; // comparison or if no allowed tail expansions are specified, we exit early.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp:33,optimiz,optimize,33,interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,3,"['Load', 'load', 'optimiz']","['LoadSequence', 'loads', 'optimize']"
Performance,// This pass expands memcmp() to load/stores.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/Passes.h:33,load,load,33,interpreter/llvm-project/llvm/include/llvm/CodeGen/Passes.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/Passes.h,1,['load'],['load']
Performance,// This pass is used to annotate instructions during the inline process for; // debugging and analysis. The main purpose of the pass is to see and test; // inliner's decisions when creating new optimizations to InlineCost.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/InlineCost.h:194,optimiz,optimizations,194,interpreter/llvm-project/llvm/include/llvm/Analysis/InlineCost.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/InlineCost.h,1,['optimiz'],['optimizations']
Performance,"// This pass performs several distinct transformations. As a compile-time aid; // when compiling code that isn't ObjC, skip these if the relevant ObjC; // library functions aren't declared.; // Preliminary optimizations. This also computes UsedInThisFunction.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/ObjCARC/ObjCARCOpts.cpp:13,perform,performs,13,interpreter/llvm-project/llvm/lib/Transforms/ObjCARC/ObjCARCOpts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/ObjCARC/ObjCARCOpts.cpp,2,"['optimiz', 'perform']","['optimizations', 'performs']"
Performance,"// This pass performs the following transformation on LLVM IR level required; // for the following translation to SPIR-V:; // - replaces direct usages of aggregate constants with target-specific; // intrinsics;; // - replaces aggregates-related instructions (extract/insert, ld/st, etc); // with a target-specific intrinsics;; // - emits intrinsics for the global variable initializers since IRTranslator; // doesn't handle them and it's not very convenient to translate them; // ourselves;; // - emits intrinsics to keep track of the string names assigned to the values;; // - emits intrinsics to keep track of constants (this is necessary to have an; // LLVM IR constant after the IRTranslation is completed) for their further; // deduplication;; // - emits intrinsics to keep track of original LLVM types of the values; // to be able to emit proper SPIR-V types eventually.; //; // TODO: consider removing spv.track.constant in favor of spv.assign.type.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SPIRV/SPIRVEmitIntrinsics.cpp:13,perform,performs,13,interpreter/llvm-project/llvm/lib/Target/SPIRV/SPIRVEmitIntrinsics.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SPIRV/SPIRVEmitIntrinsics.cpp,1,['perform'],['performs']
Performance,"// This performs any lvalue-to-rvalue conversions if necessary, which; // can affect what gets captured in the containing decl-context.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseExprCXX.cpp:8,perform,performs,8,interpreter/llvm-project/clang/lib/Parse/ParseExprCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseExprCXX.cpp,1,['perform'],['performs']
Performance,// This performs initialization so lowering for SplitCSR will be correct.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGISel.cpp:8,perform,performs,8,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGISel.cpp,1,['perform'],['performs']
Performance,"// This performs splitting without a need for externalization, which might not; // always be possible.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SplitModule.cpp:8,perform,performs,8,interpreter/llvm-project/llvm/lib/Transforms/Utils/SplitModule.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SplitModule.cpp,1,['perform'],['performs']
Performance,"// This performs the necessary local basic block ordering checks to tell; // whether A comes before B, where both are in the same basic block.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/PredicateInfo.cpp:8,perform,performs,8,interpreter/llvm-project/llvm/lib/Transforms/Utils/PredicateInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/PredicateInfo.cpp,1,['perform'],['performs']
Performance,// This pseudo performs an FADD with rounding mode temporarily forced; // to round-to-zero. We emit this via custom inserter since the FPSCR; // is not modeled at the SelectionDAG level.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:15,perform,performs,15,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['perform'],['performs']
Performance,// This query's Size is less than the cached one. Conservatively restart; // the query using the greater size.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp:38,cache,cached,38,interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,1,['cache'],['cached']
Performance,"// This recipe contributes to the address computation of a widen; // load/store. If the underlying instruction has poison-generating flags,; // drop them directly.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:69,load,load,69,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,1,['load'],['load']
Performance,"// This returns a Range object where fMin is the maximum of all the minimun entry; // number loaded for each branch and fMax is the minimum of all the maximum entry; // number loaded for each branch.; // As such it is valid to have fMin > fMax, this is the case where there; // are no overlap between the branch's range. For example for 2 branches; // where we have for one the entry [50,99] and for the other [0,49] then; // we will have fMin = max(50,0) = 50 and fMax = min(99,49) = 49",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx:93,load,loaded,93,tree/tree/src/TTreeCache.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx,2,['load'],['loaded']
Performance,"// This routine is used to load fields one-by-one to perform a copy, so; // don't load reference fields.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExpr.cpp:27,load,load,27,interpreter/llvm-project/clang/lib/CodeGen/CGExpr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExpr.cpp,3,"['load', 'perform']","['load', 'perform']"
Performance,// This routine performs a basic correctness check. This routine should only; // be called when we know that 'IR' is not in the scheduler's instruction; // queues.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/HardwareUnits/Scheduler.h:16,perform,performs,16,interpreter/llvm-project/llvm/include/llvm/MCA/HardwareUnits/Scheduler.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/HardwareUnits/Scheduler.h,2,"['perform', 'queue']","['performs', 'queues']"
Performance,"// This scheduler implements a different scheduling algorithm than; // GenericScheduler.; //; // There are several specific architecture behaviours that can't be modelled; // for GenericScheduler:; // . When accessing the result of an SGPR load instruction, you have to wait; // for all the SGPR load instructions before your current instruction to; // have finished.; // . When accessing the result of an VGPR load instruction, you have to wait; // for all the VGPR load instructions previous to the VGPR load instruction; // you are interested in to finish.; // . The less the register pressure, the best load latencies are hidden; //; // Moreover some specifities (like the fact a lot of instructions in the shader; // have few dependencies) makes the generic scheduler have some unpredictable; // behaviours. For example when register pressure becomes high, it can either; // manage to prevent register pressure from going too high, or it can; // increase register pressure even more than if it hadn't taken register; // pressure into account.; //; // Also some other bad behaviours are generated, like loading at the beginning; // of the shader a constant in VGPR you won't need until the end of the shader.; //; // The scheduling problem for SI can distinguish three main parts:; // . Hiding high latencies (texture sampling, etc); // . Hiding low latencies (SGPR constant loading, etc); // . Keeping register usage low for better latency hiding and general; // performance; //; // Some other things can also affect performance, but are hard to predict; // (cache usage, the fact the HW can issue several instructions from different; // wavefronts if different types, etc); //; // This scheduler tries to solve the scheduling problem by dividing it into; // simpler sub-problems. It divides the instructions into blocks, schedules; // locally inside the blocks where it takes care of low latencies, and then; // chooses the order of the blocks by taking care of high latencies.; // Dividing the ",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMachineScheduler.cpp:240,load,load,240,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMachineScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMachineScheduler.cpp,6,['load'],['load']
Performance,// This second loop tries to optimize the remaining instructions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/MVETPAndVPTOptimisationsPass.cpp:29,optimiz,optimize,29,interpreter/llvm-project/llvm/lib/Target/ARM/MVETPAndVPTOptimisationsPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/MVETPAndVPTOptimisationsPass.cpp,1,['optimiz'],['optimize']
Performance,// This section is new so place it in the queue. This will cause it; // to be reported after deleted sections.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/StandardInstrumentations.cpp:42,queue,queue,42,interpreter/llvm-project/llvm/lib/Passes/StandardInstrumentations.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/StandardInstrumentations.cpp,1,['queue'],['queue']
Performance,"// This should not need a cast (ie. BindCppObjectNoCast), but performing the cast; // here means callbacks receive down-casted object when passed by-ptr, which is; // needed for object identity. The latter case is assumed to be more common than; // conversion of (global) objects.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Converters.cxx:62,perform,performing,62,bindings/pyroot/cppyy/CPyCppyy/src/Converters.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Converters.cxx,1,['perform'],['performing']
Performance,"// This should only occur in unusual situations like bitcasting to an; // x86_fp80, so just turn it into a store+load",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeIntegerTypes.cpp:113,load,load,113,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeIntegerTypes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeIntegerTypes.cpp,1,['load'],['load']
Performance,"// This should really never happen (the content of map should always; // be a pair and thus have a TClass ... so let's just give up ...; // It actually happens in the case where one of the member is an; // enum that is part of dictionary payload that is not yet; // auto-loaded.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfo.cxx:271,load,loaded,271,io/io/src/TStreamerInfo.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfo.cxx,1,['load'],['loaded']
Performance,"// This should return a register mask that is the same as that returned by; // getCallPreservedMask but that additionally preserves the register used for; // the first i32 argument (which must also be the register used to return a; // single i32 return value); //; // In case that the calling convention does not use the same register for; // both or otherwise does not want to enable this optimization, the function; // should return NULL",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseRegisterInfo.cpp:390,optimiz,optimization,390,interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseRegisterInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseRegisterInfo.cpp,1,['optimiz'],['optimization']
Performance,"// This should run after inlining to have any chance of doing; // anything, and before other cleanup optimizations.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUTargetMachine.cpp:101,optimiz,optimizations,101,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUTargetMachine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUTargetMachine.cpp,1,['optimiz'],['optimizations']
Performance,"// This still will detect consecutive loads, but we might have ""holes""; // in some cases. It is ok for non-power-2 vectorization and may produce; // better results. It should not affect current vectorization.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp:38,load,loads,38,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,1,['load'],['loads']
Performance,// This stream is used to collect all of the declaration attribute merging; // logic for performing mutual exclusion checks. This gets emitted at the; // end of the file in a helper function of its own.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/utils/TableGen/ClangAttrEmitter.cpp:89,perform,performing,89,interpreter/llvm-project/clang/utils/TableGen/ClangAttrEmitter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/utils/TableGen/ClangAttrEmitter.cpp,1,['perform'],['performing']
Performance,// This table describes sign- and zero-extend instructions which can be; // folded into a preceding load. All of these extends have an immediate; // (sometimes a mask and sometimes a shift) that's applied after; // extension.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMFastISel.cpp:100,load,load,100,interpreter/llvm-project/llvm/lib/Target/ARM/ARMFastISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMFastISel.cpp,1,['load'],['load']
Performance,// This tells LTO to perform JustMyCode instrumentation.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/PS4CPU.cpp:21,perform,perform,21,interpreter/llvm-project/clang/lib/Driver/ToolChains/PS4CPU.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/PS4CPU.cpp,1,['perform'],['perform']
Performance,// This tells PEI to spill the FP as if it is any other callee-save register; // to take advantage the eliminateFrameIndex machinery. This also ensures it; // is spilled in the order specified by getCalleeSavedRegs() to make it easier; // to combine multiple loads / stores.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMFrameLowering.cpp:259,load,loads,259,interpreter/llvm-project/llvm/lib/Target/ARM/ARMFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMFrameLowering.cpp,1,['load'],['loads']
Performance,"// This test verifies that the correct method is called and there is no ambiguity between the JIT call to Cache using; // a column list as a parameter and the JIT call to Cache using the Regexp.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_cache.cxx:106,Cache,Cache,106,tree/dataframe/test/dataframe_cache.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_cache.cxx,2,['Cache'],['Cache']
Performance,"// This test will crash if the cached normalization sets are not reset; // correctly after servers are redirected. This is a reduced version of a code; // provided in the ROOT forum that originally unveiled this problem:; // https://root-forum.cern.ch/t/problems-with-2d-simultaneous-fit/48249/4",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/test/testRooAbsPdf.cxx:31,cache,cached,31,roofit/roofitcore/test/testRooAbsPdf.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/test/testRooAbsPdf.cxx,1,['cache'],['cached']
Performance,"// This transform is agnostic to the signedness of the input or case values. We; // can treat the case values as signed or unsigned. We can optimize more common; // cases such as a sequence crossing zero {-4,0,4,8} if we interpret case values; // as signed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp:140,optimiz,optimize,140,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp,1,['optimiz'],['optimize']
Performance,// This transform works with scalable and fixed vectors; // TODO: Identify and allow other scalable transforms,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VectorCombine.cpp:29,scalab,scalable,29,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VectorCombine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VectorCombine.cpp,2,['scalab'],['scalable']
Performance,"// This transformation is legal for weak ODR globals in the sense it; // doesn't change semantics, but we really don't want to perform it; // anyway; it's likely to pessimize code generation, and some tools; // (like the Darwin linker in cases involving CFString) don't expect it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/ConstantMerge.cpp:127,perform,perform,127,interpreter/llvm-project/llvm/lib/Transforms/IPO/ConstantMerge.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/ConstantMerge.cpp,1,['perform'],['perform']
Performance,"// This transformation is only valid if the we are loading either a byte,; // halfword, word, or doubleword.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:51,load,loading,51,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['loading']
Performance,// This transformation isn't valid for vector loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:46,load,loads,46,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['loads']
Performance,"// This transformation should not be performed if `nsw` is missing and is not; // `equalityOnly` comparison. Since if there is overflow, sub_lt, sub_gt in; // CRReg do not reflect correct order. If `equalityOnly` is true, sub_eq in; // CRReg can reflect if compared values are equal, this optz is still valid.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp:37,perform,performed,37,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,1,['perform'],['performed']
Performance,"// This transformation will leave the intrinsic dead. If it remains in; // the DAG, the selection code will see it again, but without the load,; // and it will generate a store that is normally required for it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp:138,load,load,138,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,1,['load'],['load']
Performance,// This turns into unaligned loads. We only do this if the target natively; // supports the MVT we'll be loading or if it is small enough (<= 4) that; // we'll only produce a small number of byte loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp:29,load,loads,29,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,3,['load'],"['loading', 'loads']"
Performance,"// This unrolling functionality is target independent, but to provide some; // motivation for its intended use, for x86:; // According to the Intel 64 and IA-32 Architectures Optimization Reference; // Manual, Intel Core models and later have a loop stream detector (and; // associated uop queue) that can benefit from partial unrolling.; // The relevant requirements are:; // - The loop must have no more than 4 (8 for Nehalem and later) branches; // taken, and none of them may be calls.; // - The loop can have no more than 18 (28 for Nehalem and later) uops.; // According to the Software Optimization Guide for AMD Family 15h; // Processors, models 30h-4fh (Steamroller and later) have a loop predictor; // and loop buffer which can benefit from partial unrolling.; // The relevant requirements are:; // - The loop must have fewer than 16 branches; // - The loop must have less than 40 uops in all executed loop branches; // The number of taken branches in a loop is hard to estimate here, and; // benchmarking has revealed that it is better not to be conservative when; // estimating the branch count. As a result, we'll ignore the branch limits; // until someone finds a case where it matters in practice.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h:175,Optimiz,Optimization,175,interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,3,"['Optimiz', 'queue']","['Optimization', 'queue']"
Performance,// This value defaults to the instruction latency. This instruction is; // considered executed when field CyclesLeft goes to zero.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/Instruction.h:42,latency,latency,42,interpreter/llvm-project/llvm/include/llvm/MCA/Instruction.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/Instruction.h,1,['latency'],['latency']
Performance,"// This walker pretends uses don't exist. If we're handed one, silently grab; // its def. (This has the nice side-effect of ensuring we never cache uses)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp:142,cache,cache,142,interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp,1,['cache'],['cache']
Performance,// This was already cached,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp:20,cache,cached,20,interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,1,['cache'],['cached']
Performance,"// This was already the correct extending load result type, so just adjust; // the memory type.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp:42,load,load,42,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,1,['load'],['load']
Performance,"// This was handled above, but as we form SCEVs, we can sometimes refine; // existing ones; this allows exit counts to be folded to zero which; // weren't when optimizeLoopExits saw them. Arguably, we should iterate; // until stable to handle cases like this better.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/IndVarSimplify.cpp:160,optimiz,optimizeLoopExits,160,interpreter/llvm-project/llvm/lib/Transforms/Scalar/IndVarSimplify.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/IndVarSimplify.cpp,1,['optimiz'],['optimizeLoopExits']
Performance,"// This was optimized.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfo.cxx:12,optimiz,optimized,12,io/io/src/TStreamerInfo.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfo.cxx,1,['optimiz'],['optimized']
Performance,// This will default to printing load variants when neither MayStore nor; // MayLoad flag is present which is the case with instructions like; // image_get_resinfo.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/MCTargetDesc/AMDGPUInstPrinter.cpp:33,load,load,33,interpreter/llvm-project/llvm/lib/Target/AMDGPU/MCTargetDesc/AMDGPUInstPrinter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/MCTargetDesc/AMDGPUInstPrinter.cpp,1,['load'],['load']
Performance,// This will generate a load from the constant pool.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:24,load,load,24,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['load'],['load']
Performance,// This will give us somewhere between EltCount / 2 and; // EltCount buckets. This puts us in the load factor; // range of 1.0 - 2.0.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/FoldingSet.cpp:98,load,load,98,interpreter/llvm-project/llvm/lib/Support/FoldingSet.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/FoldingSet.cpp,1,['load'],['load']
Performance,// This works by adding extra bitcasts between load/stores and removing; // existing bicasts. If we have a phi(bitcast(load)) or a store(bitcast(phi)); // we can get in the situation where we remove a bitcast in one iteration; // just to add it again in the next. We need to ensure that at least one; // bitcast we remove are anchored to something that will not change back.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:47,load,load,47,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,2,['load'],['load']
Performance,"// This would be a completely new member (so it would need to be cached); // TOBEDONE",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfo.cxx:65,cache,cached,65,io/io/src/TStreamerInfo.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfo.cxx,1,['cache'],['cached']
Performance,"// Thread safety: this solution is not elegant, but given the action performed; // by the method, this construct can be considered non-problematic.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/src/TFileDrawMap.cxx:69,perform,performed,69,tree/treeplayer/src/TFileDrawMap.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/src/TFileDrawMap.cxx,1,['perform'],['performed']
Performance,// Throttle for huge numbers of predecessors (compile speed problems),MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/BranchFolding.cpp:3,Throttle,Throttle,3,interpreter/llvm-project/llvm/lib/CodeGen/BranchFolding.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/BranchFolding.cpp,1,['Throttle'],['Throttle']
Performance,"// Throughs calls to `GetCacheAutoSize` or `EnableCache` (for example; // by TTreePlayer::Process, the cache size will be automatically; // determined unless the user explicitly call `SetCacheSize`",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx:103,cache,cache,103,tree/tree/src/TTree.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx,1,['cache'],['cache']
Performance,"// Thumb-1 can do a limited post-inc load or store as an updating LDM. It; // must be non-extending/truncating, i32, with an offset of 4.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:37,load,load,37,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['load'],['load']
Performance,"// Thumb-1 has limited post-inc load/store support - LDM r0!, {r1}.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:32,load,load,32,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['load'],['load']
Performance,"// Thumb1 has very limited immediate modes, so turning an ""and"" into a; // shift can save multiple instructions.; //; // If we have (x & C1), and C1 is an appropriate mask, we can transform it; // into ""((x << n) >> n)"". But that isn't necessarily profitable on its; // own. If it's the operand to an unsigned comparison with an immediate,; // we can eliminate one of the shifts: we transform; // ""((x << n) >> n) == C2"" to ""(x << n) == (C2 << n)"".; //; // We avoid transforming cases which aren't profitable due to encoding; // details:; //; // 1. C2 fits into the immediate field of a cmp, and the transformed version; // would not; in that case, we're essentially trading one immediate load for; // another.; // 2. C1 is 255 or 65535, so we can use uxtb or uxth.; // 3. C2 is zero; we have other code for this special case.; //; // FIXME: Figure out profitability for Thumb2; we usually can't save an; // instruction, since the AND is always one instruction anyway, but we could; // use narrow instructions in some cases.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:689,load,load,689,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['load'],['load']
Performance,// Thumb1 is already using updating loads/stores.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp:36,load,loads,36,interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp,1,['load'],['loads']
Performance,// Thumb1 post-indexed loads are really just single-register LDMs.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:23,load,loads,23,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['load'],['loads']
Performance,// Time how long it takes to load the module.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp:29,load,load,29,interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,1,['load'],['load']
Performance,"// TmpR0 = A2_tfrsi 0x01010101; // TmpR1 = load FI, 0; // DstR = V6_vandvrt TmpR1, TmpR0",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonFrameLowering.cpp:43,load,load,43,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonFrameLowering.cpp,1,['load'],['load']
Performance,"// To ""insert"" Select_* instructions, we actually have to insert the triangle; // control-flow pattern. The incoming instructions know the destination vreg; // to set, the condition code register to branch on, the true/false values to; // select between, and the condcode to use to select the appropriate branch.; //; // We produce the following control flow:; // HeadMBB; // | \; // | IfFalseMBB; // | /; // TailMBB; //; // When we find a sequence of selects we attempt to optimize their emission; // by sharing the control flow. Currently we only handle cases where we have; // multiple selects with the exact same condition (same LHS, RHS and CC).; // The selects may be interleaved with other instructions if the other; // instructions meet some requirements we deem safe:; // - They are not pseudo instructions.; // - They are debug instructions. Otherwise,; // - They do not have side-effects, do not access memory and their inputs do; // not depend on the results of the select pseudo-instructions.; // The TrueV/FalseV operands of the selects cannot depend on the result of; // previous selects in the sequence.; // These conditions could be further relaxed. See the X86 target for a; // related approach and more information.; //; // Select_FPRX_ (rs1, rs2, imm, rs4, (Select_FPRX_ rs1, rs2, imm, rs4, rs5)); // is checked here and handled by a separate function -; // EmitLoweredCascadedSelect.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:474,optimiz,optimize,474,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['optimiz'],['optimize']
Performance,"// To ""insert"" a SELECT_CC instruction, we actually have to insert the; // diamond control-flow pattern. The incoming instruction knows the; // destination vreg to set, the condition code register to branch on, the; // true/false values to select between and a branch opcode to use.; // ThisMBB:; // ...; // TrueVal = ...; // cmpTY ccX, r1, r2; // bCC copy1MBB; // fallthrough --> FalseMBB; // This code lowers all pseudo-CMOV instructions. Generally it lowers these; // as described above, by inserting a BB, and then making a PHI at the join; // point to select the true and false operands of the CMOV in the PHI.; //; // The code also handles two different cases of multiple CMOV opcodes; // in a row.; //; // Case 1:; // In this case, there are multiple CMOVs in a row, all which are based on; // the same condition setting (or the exact opposite condition setting).; // In this case we can lower all the CMOVs using a single inserted BB, and; // then make a number of PHIs at the join point to model the CMOVs. The only; // trickiness here, is that in a case like:; //; // t2 = CMOV cond1 t1, f1; // t3 = CMOV cond1 t2, f2; //; // when rewriting this into PHIs, we have to perform some renaming on the; // temps since you cannot have a PHI operand refer to a PHI result earlier; // in the same block. The ""simple"" but wrong lowering would be:; //; // t2 = PHI t1(BB1), f1(BB2); // t3 = PHI t2(BB1), f2(BB2); //; // but clearly t2 is not defined in BB1, so that is incorrect. The proper; // renaming is to note that on the path through BB1, t2 is really just a; // copy of t1, and do that renaming, properly generating:; //; // t2 = PHI t1(BB1), f1(BB2); // t3 = PHI t1(BB1), f2(BB2); //; // Case 2:; // CMOV ((CMOV F, T, cc1), T, cc2) is checked here and handled by a separate; // function - EmitLoweredCascadedSelect.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:1178,perform,perform,1178,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['perform'],['perform']
Performance,"// To address a limitation of the current GVN, we need to rerun the; // hoisting after we hoisted loads or stores in order to be able to; // hoist all scalars dependent on the hoisted ld/st.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVNHoist.cpp:98,load,loads,98,interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVNHoist.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVNHoist.cpp,1,['load'],['loads']
Performance,// To allow easy access to all instructions in a function with a given; // opcode we store them in the InfoCache. As not all opcodes are interesting; // to concrete attributes we only cache the ones that are as identified in; // the following switch.; // Note: There are no concrete attributes now so this is initially empty.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/Attributor.cpp:184,cache,cache,184,interpreter/llvm-project/llvm/lib/Transforms/IPO/Attributor.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/Attributor.cpp,1,['cache'],['cache']
Performance,"// To avoid breaking dependences, vectorized instructions of an interleave; // group should be inserted at either the first load or the last store in; // program order.; //; // E.g. %even = load i32 // Insert Position; // %add = add i32 %even // Use of %even; // %odd = load i32; //; // store i32 %even; // %odd = add i32 // Def of %odd; // store i32 %odd // Insert Position",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/VectorUtils.h:124,load,load,124,interpreter/llvm-project/llvm/include/llvm/Analysis/VectorUtils.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/VectorUtils.h,3,['load'],['load']
Performance,// To avoid combining conditionals in the same basic block by; // instrcombine optimization.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFAdjustOpt.cpp:79,optimiz,optimization,79,interpreter/llvm-project/llvm/lib/Target/BPF/BPFAdjustOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFAdjustOpt.cpp,2,['optimiz'],['optimization']
Performance,// To avoid cycle construction make sure that neither the load nor the add; // are predecessors to each other or the Vector.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:58,load,load,58,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['load'],['load']
Performance,"// To avoid false positives (Ex: finding user defined functions with; // similar names), only perform fuzzy name matching when it's a builtin.; // Using a string compare is slow, we might want to switch on BuiltinID here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/CheckerContext.cpp:94,perform,perform,94,interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/CheckerContext.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/CheckerContext.cpp,1,['perform'],['perform']
Performance,"// To avoid having these optimizations undone by constant folding,; // we convert to a pseudo that will be expanded later into one of; // the above forms.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:25,optimiz,optimizations,25,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['optimiz'],['optimizations']
Performance,"// To avoid needlessly dropping large volumes of variable locations, propagate; // variables through aritifical blocks, i.e. those that don't have any; // instructions in scope at all. To accurately replicate VarLoc; // LiveDebugValues, this means exploring all artificial successors too.; // Perform a depth-first-search to enumerate those blocks.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.cpp:293,Perform,Perform,293,interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.cpp,1,['Perform'],['Perform']
Performance,"// To be safe that the loads can be combined, iterate over all loads and test; // that the corresponding defining access dominates first LI. This guarantees; // that there are no aliasing stores in between the loads.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp:23,load,loads,23,interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp,3,['load'],['loads']
Performance,"// To conserve compile-time, we avoid walking to the next clobbering def.; // Instead, we just try to get the optimized access, if it exists. DSE; // will try to optimize defs during the earlier traversal.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/DeadStoreElimination.cpp:110,optimiz,optimized,110,interpreter/llvm-project/llvm/lib/Transforms/Scalar/DeadStoreElimination.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/DeadStoreElimination.cpp,2,['optimiz'],"['optimize', 'optimized']"
Performance,"// To consider a PHI profitable to break, we need to see some interesting; // incoming values. At least 2/3rd (rounded up) of all PHIs in the worklist; // must have one to consider all PHIs breakable.; //; // This threshold has been determined through performance testing.; //; // Note that the computation below is equivalent to; //; // (unsigned)ceil((K / 3.0) * 2); //; // It's simply written this way to avoid mixing integral/FP arithmetic.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUCodeGenPrepare.cpp:252,perform,performance,252,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUCodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUCodeGenPrepare.cpp,1,['perform'],['performance']
Performance,"// To further other optimizations, loop over all users of NewGV and try to; // constant prop them. This will promote GEP instructions with constant; // indices into GEP constant-exprs, which will allow global-opt to hack on it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp:20,optimiz,optimizations,20,interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,1,['optimiz'],['optimizations']
Performance,"// To handle a max with more than two operands, this optimization would; // require additional checking and setup.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopStrengthReduce.cpp:53,optimiz,optimization,53,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopStrengthReduce.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopStrengthReduce.cpp,1,['optimiz'],['optimization']
Performance,"// To keep things simple for now, remove those where the load is potentially; // fed by multiple stores.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp:57,load,load,57,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp,1,['load'],['load']
Performance,"// To perform the test, it's easier to sort",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_simple.cxx:6,perform,perform,6,tree/dataframe/test/dataframe_simple.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_simple.cxx,1,['perform'],['perform']
Performance,"// To perform this operation, we just need to swap the L and G bits of the; // operation.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp:6,perform,perform,6,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,1,['perform'],['perform']
Performance,"// To protect arguments on the stack from being clobbered in a tail call,; // force all the loads to happen before doing any other lowering.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:92,load,loads,92,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['loads']
Performance,"// To read the 64-bit cycle CSR on a 32-bit target, we read the two halves.; // Should the count have wrapped while it was being read, we need to try; // again.; // ...; // read:; // rdcycleh x3 # load high word of cycle; // rdcycle x2 # load low word of cycle; // rdcycleh x4 # load high word of cycle; // bne x3, x4, read # check if high word reads match, otherwise try again; // ...",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:197,load,load,197,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,3,['load'],['load']
Performance,"// To read the 64-bit time-base register on a 32-bit target, we read the; // two halves. Should the counter have wrapped while it was being read, we; // need to try again.; // ...; // readLoop:; // mfspr Rx,TBU # load from TBU; // mfspr Ry,TB # load from TB; // mfspr Rz,TBU # load from TBU; // cmpw crX,Rx,Rz # check if 'old'='new'; // bne readLoop # branch if they're not equal; // ...",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:213,load,load,213,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,3,['load'],['load']
Performance,"// To reduce compilation time, we check MRI->hasOneNonDBGUser when inserting; // loads. It should be checked when processing uses of the load, since; // uses can be removed during peephole.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/PeepholeOptimizer.cpp:81,load,loads,81,interpreter/llvm-project/llvm/lib/CodeGen/PeepholeOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/PeepholeOptimizer.cpp,2,['load'],"['load', 'loads']"
Performance,"// To support object unload notification, we need to keep a list of; // registered function addresses for each loaded object. We will; // use the MethodIDs map to get the registered ID for each function.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/IntelJITEvents/IntelJITEventListener.cpp:111,load,loaded,111,interpreter/llvm-project/llvm/lib/ExecutionEngine/IntelJITEvents/IntelJITEventListener.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/IntelJITEvents/IntelJITEventListener.cpp,1,['load'],['loaded']
Performance,"// To update r = r - c * m, it suffices to know c * (-2 ** 240 + 1); // because the 2 ** 576 will cancel out. Also note that c may be zero, but; // the operation is still performed to avoid branching.; // c * (-2 ** 240 + 1) in 576 bits looks as follows, depending on c:; // - if c = 0, the number is zero.; // - if c = 1: bits 576 to 240 are set,; // bits 239 to 1 are zero, and; // the last one is set; // - if c = -1, which corresponds to all bits set (signed int64_t):; // bits 576 to 240 are zero and the rest is set.; // Note that all bits except the last are exactly complimentary (unless c = 0); // and the last byte is conveniently represented by c already.; // Now construct the three bit patterns from c, their names correspond to the; // assembly implementation by Alexei Sibidanov.; // c = 0 -> t0 = 0; c = 1 -> t0 = 0; c = -1 -> all bits set (sign extension); // (The assembly implementation shifts by 63, which gives the same result.)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/ranluxpp/mulmod.h:171,perform,performed,171,math/mathcore/src/ranluxpp/mulmod.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/ranluxpp/mulmod.h,1,['perform'],['performed']
Performance,"// To use guards for proving predicates, we need to scan every instruction in; // relevant basic blocks, and not just terminators. Doing this is a waste of; // time if the IR does not actually contain any calls to; // @llvm.experimental.guard, so do a quick check and remember this beforehand.; //; // This pessimizes the case where a pass that preserves ScalarEvolution wants; // to _add_ guards to the module when there weren't any before, and wants; // ScalarEvolution to optimize based on those guards. For now we prefer to be; // efficient in lieu of being smart in that rather obscure case.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp:475,optimiz,optimize,475,interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,1,['optimiz'],['optimize']
Performance,"// To use this object, it should be created before the new attribute is created,; // and destructed after it is created. The construction already performs the; // import of the data.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ASTImporter.cpp:146,perform,performs,146,interpreter/llvm-project/clang/lib/AST/ASTImporter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ASTImporter.cpp,1,['perform'],['performs']
Performance,"// To use this object, it should be created before the new attribute is created,; // and destructed after it is created. The construction already performs the; // import of the data. The array data is accessible in a pointer form, this form; // is used by the attribute classes. This object should be created once for the; // array data to be imported (the array size is not imported, just copied).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ASTImporter.cpp:146,perform,performs,146,interpreter/llvm-project/clang/lib/AST/ASTImporter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ASTImporter.cpp,1,['perform'],['performs']
Performance,"// To work around a stupid optimization bug in MSVC++ 6.0",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/Bytes.h:27,optimiz,optimization,27,core/base/inc/Bytes.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/Bytes.h,5,['optimiz'],['optimization']
Performance,"// TokenFactor operands are considered zero latency, and some schedulers; // (e.g. Top-Down list) may rely on the fact that operand latency is nonzero; // whenever node latency is nonzero.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/ScheduleDAGSDNodes.cpp:44,latency,latency,44,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/ScheduleDAGSDNodes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/ScheduleDAGSDNodes.cpp,3,['latency'],['latency']
Performance,"// Tokens can't be used in PHI nodes and live-out tokens prevent loop; // optimizations, so for the purposes of considered LCSSA form, we; // can ignore them.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LoopInfo.cpp:74,optimiz,optimizations,74,interpreter/llvm-project/llvm/lib/Analysis/LoopInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LoopInfo.cpp,1,['optimiz'],['optimizations']
Performance,"// Tool access.; /// TranslateArgs - Create a new derived argument list for any argument; /// translations this ToolChain may wish to perform, or 0 if no tool chain; /// specific translations are needed. If \p DeviceOffloadKind is specified; /// the translation specific for that offload kind is performed.; ///; /// \param BoundArch - The bound architecture name, or 0.; /// \param DeviceOffloadKind - The device offload kind used for the; /// translation.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Driver/ToolChain.h:134,perform,perform,134,interpreter/llvm-project/clang/include/clang/Driver/ToolChain.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Driver/ToolChain.h,2,['perform'],"['perform', 'performed']"
Performance,// Top-Level entry points for the schedule() driver...; /// Apply each ScheduleDAGMutation step in order. This allows different; /// instances of ScheduleDAGMI to perform custom DAG postprocessing.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineScheduler.h:163,perform,perform,163,interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineScheduler.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineScheduler.h,1,['perform'],['perform']
Performance,"// Top-level API for clients that know the operand indices. This doesn't need to; // return std::optional<unsigned>, as it always returns a valid latency.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/TargetSchedule.cpp:146,latency,latency,146,interpreter/llvm-project/llvm/lib/CodeGen/TargetSchedule.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/TargetSchedule.cpp,1,['latency'],['latency']
Performance,// Top-level driver to manage the queue of unassigned VirtRegs and call the; // selectOrSplit implementation.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RegAllocBase.cpp:34,queue,queue,34,interpreter/llvm-project/llvm/lib/CodeGen/RegAllocBase.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RegAllocBase.cpp,1,['queue'],['queue']
Performance,"// Topological sort the CFG, with additional constraints:; // - Between a region header and the last block in the region, there can be; // no blocks not dominated by its header.; // - It's desirable to preserve the original block order when possible.; // We use two ready lists; Preferred and Ready. Preferred has recently; // processed successors, to help preserve block sequences from the original; // order. Ready has the remaining ready blocks. EH blocks are picked first; // from both queues.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyCFGSort.cpp:490,queue,queues,490,interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyCFGSort.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyCFGSort.cpp,1,['queue'],['queues']
Performance,"// Tot latency",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proofbench/src/TProofPerfAnalysis.cxx:7,latency,latency,7,proof/proofbench/src/TProofPerfAnalysis.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proofbench/src/TProofPerfAnalysis.cxx,1,['latency'],['latency']
Performance,"// Track all instructions that may raise floating-point exceptions.; // These do not depend on one other (or normal loads or stores), but; // must not be rescheduled across global barriers. Note that we don't; // really need a ""map"" here since we don't track those MIs by value;; // using the same Value2SUsMap data type here is simply a matter of; // convenience.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ScheduleDAGInstrs.cpp:116,load,loads,116,interpreter/llvm-project/llvm/lib/CodeGen/ScheduleDAGInstrs.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ScheduleDAGInstrs.cpp,1,['load'],['loads']
Performance,// Track any allocas we end up splitting loads and stores for so we iterate; // on them.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:41,load,loads,41,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,1,['load'],['loads']
Performance,"// Track function byte size under different context (outlined version as well as; // various inlined versions). It also provides query support to get function; // size with the best matching context, which is used to help pre-inliner use; // accurate post-optimization size to make decisions.; // TODO: If an inlinee is completely optimized away, ideally we should have zero; // for its context size, currently we would misss such context since it doesn't; // have instructions. To fix this, we need to mark all inlinee with entry probe; // but without instructions as having zero size.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.h:256,optimiz,optimization,256,interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.h,2,['optimiz'],"['optimization', 'optimized']"
Performance,"// Track loads out of this alloca which cannot, for any reason, be pre-split.; // This is important as we also cannot pre-split stores of those loads!; // FIXME: This is all pretty gross. It means that we can be more aggressive; // in pre-splitting when the load feeding the store happens to come from; // a separate alloca. Put another way, the effectiveness of SROA would be; // decreased by a frontend which just concatenated all of its local allocas; // into one big flat alloca. But defeating such patterns is exactly the job; // SROA is tasked with! Sadly, to not have this discrepancy we would have; // change store pre-splitting to actually force pre-splitting of the load; // that feeds it *and all stores*. That makes pre-splitting much harder, but; // maybe it would make it more principled?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:9,load,loads,9,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,4,['load'],"['load', 'loads']"
Performance,// Track optimized-away inlinee for probed binary. A function inlined and then; // optimized away should still have their probes left over in places.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.cpp:9,optimiz,optimized-away,9,interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/ProfiledBinary.cpp,2,['optimiz'],"['optimized', 'optimized-away']"
Performance,"// Track the loads and stores which are candidates for pre-splitting here, in; // the order they first appear during the partition scan. These give stable; // iteration order and a basis for tracking which loads and stores we; // actually split.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:13,load,loads,13,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,2,['load'],['loads']
Performance,// Track the maximum number of stall cycles that could arise either from the; // latency of a DAG edge or the number of cycles that a processor resource is; // reserved (SchedBoundary::ReservedCycles).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp:81,latency,latency,81,interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp,1,['latency'],['latency']
Performance,"// Track the number of scalar loads we know we'd be inserting, estimated as; // any non-zero floating-point constant. Other kinds of element are either; // already in registers or are materialized on demand. The threshold at which; // a vector load is more desirable than several scalar materializion and; // vector-insertion instructions is not known.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:30,load,loads,30,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,2,['load'],"['load', 'loads']"
Performance,// Track the operand that kill Reg. We would unset the kill flag of; // the operand if there is a following redundant load immediate.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCPreEmitPeephole.cpp:118,load,load,118,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCPreEmitPeephole.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCPreEmitPeephole.cpp,1,['load'],['load']
Performance,"// Track the set of load-dependent registers through the basic block. Because; // the values of these registers have an existing data dependency on a loaded; // value which we would have checked, we can omit any checks on them.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:20,load,load-dependent,20,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,2,['load'],"['load-dependent', 'loaded']"
Performance,// Track the subprogram attachment that needs to be cloned to fine-tune the; // mapping within the same module.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/CloneFunction.cpp:67,tune,tune,67,interpreter/llvm-project/llvm/lib/Transforms/Utils/CloneFunction.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/CloneFunction.cpp,1,['tune'],['tune']
Performance,"// Track whether any functions in this SCC have an unknown call edge.; // Note: if this is ever a performance hit, we can common it with; // subsequent routines which also do scans over the instructions of the; // function.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionAttrs.cpp:98,perform,performance,98,interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionAttrs.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionAttrs.cpp,1,['perform'],['performance']
Performance,"// Track whether we hit an error; in particular, in the multi-threaded case,; // we can't exit() early because the rest of the threads wouldn't have had a; // change to be join-ed, and that would result in a ""terminate called without; // an active exception"". Altogether, this results in nondeterministic; // behavior. Instead, we don't exit in the multi-threaded case, but we make; // sure to report the error and then at the end (after joining cleanly); // exit(1).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-lto2/llvm-lto2.cpp:56,multi-thread,multi-threaded,56,interpreter/llvm-project/llvm/tools/llvm-lto2/llvm-lto2.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-lto2/llvm-lto2.cpp,2,['multi-thread'],['multi-threaded']
Performance,"// Track whether we need to add the optnone LLVM attribute,; // starting with the default for this optimization level.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenModule.cpp:99,optimiz,optimization,99,interpreter/llvm-project/clang/lib/CodeGen/CodeGenModule.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenModule.cpp,1,['optimiz'],['optimization']
Performance,// Track whether we performed a qualification conversion anywhere other; // than the top level. This matters for ranking reference bindings in; // overload resolution.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp:20,perform,performed,20,interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,1,['perform'],['performed']
Performance,// Tracks the usage of a scheduler's queue.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-mca/Views/SchedulerStatistics.h:37,queue,queue,37,interpreter/llvm-project/llvm/tools/llvm-mca/Views/SchedulerStatistics.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-mca/Views/SchedulerStatistics.h,1,['queue'],['queue']
Performance,"// Transfer \a Segment from \a Obj to the output file. This calls into \a Writer; // to write these load commands directly in the output file at the current; // position.; //; // The function also tries to find a hole in the address map to fit the __DWARF; // segment of \a DwarfSegmentSize size. \a EndAddress is updated to point at the; // highest segment address.; //; // When the __LINKEDIT segment is transferred, its offset and size are set resp.; // to \a LinkeditOffset and \a LinkeditSize.; //; // When the eh_frame section is transferred, its offset and size are set resp.; // to \a EHFrameOffset and \a EHFrameSize.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/dsymutil/MachOUtils.cpp:100,load,load,100,interpreter/llvm-project/llvm/tools/dsymutil/MachOUtils.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/dsymutil/MachOUtils.cpp,1,['load'],['load']
Performance,// Transfer chain users from old loads to the new load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:33,load,loads,33,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,4,['load'],"['load', 'loads']"
Performance,// Transfer the old load's AA tags to the new load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp:20,load,load,20,interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,2,['load'],['load']
Performance,"// Transform ""(X >> (8-C1)) & (0xff << C1)"" to ""((X >> 8) & 0xff) << C1"" if; // safe. This allows us to convert the shift and and into an h-register; // extract and a scaled index. Returns false if the simplification is; // performed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp:224,perform,performed,224,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,1,['perform'],['performed']
Performance,"// Transform ""(X >> SHIFT) & (MASK << C1)"" to; // ""((X >> (SHIFT + C1)) & (MASK)) << C1"". Everything before the SHL will be; // matched to a BEXTR later. Returns false if the simplification is performed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp:193,perform,performed,193,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,1,['perform'],['performed']
Performance,// Transform (fneg/fabs (bitconvert x)) to avoid loading constant pool values.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:49,load,loading,49,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['loading']
Performance,"// Transform PTEST_ANY(X=OP(PG,...), X) -> PTEST_ANY(PG, X)).; // Later optimizations may rewrite sequence to use the flag-setting variant; // of instruction X to remove PTEST.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp:72,optimiz,optimizations,72,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,1,['optimiz'],['optimizations']
Performance,"// Transform a scalar load that is REPLICATEd as well as having other; // use(s) to the form where the other use(s) use the first element of the; // REPLICATE instead of the load. Otherwise instruction selection will not; // produce a VLREP. Avoid extracting to a GPR, so only do this for floating; // point loads.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:22,load,load,22,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,3,['load'],"['load', 'loads']"
Performance,"// Transform a sequence like this:; // start:; // %cmp = cmp uge i32 %a, %b; // %sel = select i1 %cmp, i32 %c, i32 %d; //; // Into:; // start:; // %cmp = cmp uge i32 %a, %b; // %cmp.frozen = freeze %cmp; // br i1 %cmp.frozen, label %select.true, label %select.false; // select.true:; // br label %select.end; // select.false:; // br label %select.end; // select.end:; // %sel = phi i32 [ %c, %select.true ], [ %d, %select.false ]; //; // %cmp should be frozen, otherwise it may introduce undefined behavior.; // In addition, we may sink instructions that produce %c or %d from; // the entry block into the destination(s) of the new branch.; // If the true or false blocks do not contain a sunken instruction, that; // block and its branch may be optimized away. In that case, one side of the; // first branch will point directly to select.end, and the corresponding PHI; // predecessor block will be the start block.; // Collect values that go on the true side and the values that go on the false; // side.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:746,optimiz,optimized,746,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,1,['optimiz'],['optimized']
Performance,// Transform all loads nodes into one single node because; // all load nodes are independent of each other.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARC/ARCISelLowering.cpp:17,load,loads,17,interpreter/llvm-project/llvm/lib/Target/ARC/ARCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARC/ARCISelLowering.cpp,4,['load'],"['load', 'loads']"
Performance,// Transform load (constant global) into the value loaded.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SCCPSolver.cpp:13,load,load,13,interpreter/llvm-project/llvm/lib/Transforms/Utils/SCCPSolver.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SCCPSolver.cpp,2,['load'],"['load', 'loaded']"
Performance,// Transform load from a constant into a constant if possible.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SCCPSolver.cpp:13,load,load,13,interpreter/llvm-project/llvm/lib/Transforms/Utils/SCCPSolver.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SCCPSolver.cpp,1,['load'],['load']
Performance,"// Transform loads and stores to pointers in address space 1 to loads and; // stores to WebAssembly global variables, outside linear memory.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp:13,load,loads,13,interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp,2,['load'],['loads']
Performance,// Transform managed variables to pointers to managed variables in device code.; // Each use of the original managed variable is replaced by a load from the; // transformed managed variable. The transformed managed variable contains; // the address of managed memory which will be allocated by the runtime.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGCUDANV.cpp:143,load,load,143,interpreter/llvm-project/clang/lib/CodeGen/CGCUDANV.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGCUDANV.cpp,1,['load'],['load']
Performance,"// Transform sequences of insertelements ops with constant data/indexes into; // a single shuffle op.; // Can not handle scalable type, the number of elements needed to create; // shuffle mask is not a compile-time constant.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineVectorOps.cpp:121,scalab,scalable,121,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineVectorOps.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineVectorOps.cpp,1,['scalab'],['scalable']
Performance,"// Transform the instruction, now that it no longer has a load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/TwoAddressInstructionPass.cpp:58,load,load,58,interpreter/llvm-project/llvm/lib/CodeGen/TwoAddressInstructionPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/TwoAddressInstructionPass.cpp,1,['load'],['load']
Performance,"// Transform the std::bit_ceil(X) pattern like:; //; // %dec = add i32 %x, -1; // %ctlz = tail call i32 @llvm.ctlz.i32(i32 %dec, i1 false); // %sub = sub i32 32, %ctlz; // %shl = shl i32 1, %sub; // %ugt = icmp ugt i32 %x, 1; // %sel = select i1 %ugt, i32 %shl, i32 1; //; // into:; //; // %dec = add i32 %x, -1; // %ctlz = tail call i32 @llvm.ctlz.i32(i32 %dec, i1 false); // %neg = sub i32 0, %ctlz; // %masked = and i32 %ctlz, 31; // %shl = shl i32 1, %sub; //; // Note that the select is optimized away while the shift count is masked with; // 31. We handle some variations of the input operand like std::bit_ceil(X +; // 1).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineSelect.cpp:492,optimiz,optimized,492,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineSelect.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineSelect.cpp,1,['optimiz'],['optimized']
Performance,"// Transform: (EXTRACT_VECTOR_ELT( VECTOR_SHUFFLE )) -> EXTRACT_VECTOR_ELT.; // We only perform this optimization before the op legalization phase because; // we may introduce new vector instructions which are not backed by TD; // patterns. For example on AVX, extracting elements from a wide vector; // without using extract_subvector. However, if we can find an underlying; // scalar value, then we can always use that.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:88,perform,perform,88,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,"['optimiz', 'perform']","['optimization', 'perform']"
Performance,"// Transform: (load ch (add x (and (srl y c) Mask))); // to: (load ch (add x (shl (srl y d) d-c))); // where; // Mask = 00..0 111..1 0.0; // | | +-- d-c 0s, and d-c is 0, 1 or 2.; // | +-------- 1s; // +-------------- at most c 0s; // Motivating example:; // DAG combiner optimizes (add x (shl (srl y 5) 2)); // to (add x (and (srl y 3) 1FFFFFFC)); // which results in a constant-extended and(##...,lsr). This transformation; // undoes this simplification for cases where the shl can be folded into; // an addressing mode.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp:15,load,load,15,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,6,"['load', 'optimiz']","['load', 'optimizes']"
Performance,"// Transform: (store ch val (add x (add (shl y c) e))); // to: (store ch val (add x (shl (add y d) c))),; // where e = (shl d c) for some integer d.; // The purpose of this is to enable generation of loads/stores with; // shifted addressing mode, i.e. mem(x+y<<#c). For that, the shift; // value c must be 0, 1 or 2.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp:200,load,loads,200,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,2,['load'],['loads']
Performance,"// Transforms ""int $3"" into ""int3"" as a size optimization.; // We can't write this as an InstAlias.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp:45,optimiz,optimization,45,interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/AsmParser/X86AsmParser.cpp,1,['optimiz'],['optimization']
Performance,"// Transforms vselect(not(cond), lhs, rhs) into vselect(cond, rhs, lhs).; //; // We need to re-implement this optimization here as the implementation in the; // Target-Independent DAGCombiner does not handle the kind of constant we make; // (it calls isConstOrConstSplat with AllowTruncation set to false - and for; // good reason, allowing truncation there would break other targets).; //; // Currently, this is only done for MVE, as it's the only target that benefits; // from this transformation (e.g. VPNOT+VPSEL becomes a single VPSEL).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:110,optimiz,optimization,110,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['optimiz'],['optimization']
Performance,// Transforms; // <Instr that uses %A ('User' Operand)>; // Into; // %K = VPNOT %Target; // <Instr that uses %K ('User' Operand)>; // And returns the newly inserted VPNOT.; // This optimization is done in the hopes of preventing spills/reloads of VPR by; // reducing the number of VCCR values with overlapping lifetimes.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/MVETPAndVPTOptimisationsPass.cpp:181,optimiz,optimization,181,interpreter/llvm-project/llvm/lib/Target/ARM/MVETPAndVPTOptimisationsPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/MVETPAndVPTOptimisationsPass.cpp,1,['optimiz'],['optimization']
Performance,"// Transition to the ""executed"" stage if this is a zero-latency instruction.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MCA/Instruction.cpp:56,latency,latency,56,interpreter/llvm-project/llvm/lib/MCA/Instruction.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MCA/Instruction.cpp,1,['latency'],['latency']
Performance,"// Transition to the dispatch stage, and assign a RCUToken to this; // instruction. The RCUToken is used to track the completion of every; // register write performed by this instruction.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/Instruction.h:157,perform,performed,157,interpreter/llvm-project/llvm/include/llvm/MCA/Instruction.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/Instruction.h,1,['perform'],['performed']
Performance,// Transitively search for more arguments by looking at the users of the; // ones we know already. During the search the GTIdArgs vector is extended; // so we cannot cache the size nor can we use a range based for.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp:166,cache,cache,166,interpreter/llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp,1,['cache'],['cache']
Performance,// Translate a clang statement or expression to a TIL expression.; // Also performs substitution of variables; Ctx provides the context.; // Dispatches on the type of S.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Analysis/Analyses/ThreadSafetyCommon.h:75,perform,performs,75,interpreter/llvm-project/clang/include/clang/Analysis/Analyses/ThreadSafetyCommon.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Analysis/Analyses/ThreadSafetyCommon.h,2,['perform'],['performs']
Performance,"// Translate a masked gather intrinsic like; // <16 x i32 > @llvm.masked.gather.v16i32( <16 x i32*> %Ptrs, i32 4,; // <16 x i1> %Mask, <16 x i32> %Src); // to a chain of basic blocks, with loading element one-by-one if; // the appropriate mask bit is set; //; // %Ptrs = getelementptr i32, i32* %base, <16 x i64> %ind; // %Mask0 = extractelement <16 x i1> %Mask, i32 0; // br i1 %Mask0, label %cond.load, label %else; //; // cond.load:; // %Ptr0 = extractelement <16 x i32*> %Ptrs, i32 0; // %Load0 = load i32, i32* %Ptr0, align 4; // %Res0 = insertelement <16 x i32> poison, i32 %Load0, i32 0; // br label %else; //; // else:; // %res.phi.else = phi <16 x i32>[%Res0, %cond.load], [poison, %0]; // %Mask1 = extractelement <16 x i1> %Mask, i32 1; // br i1 %Mask1, label %cond.load1, label %else2; //; // cond.load1:; // %Ptr1 = extractelement <16 x i32*> %Ptrs, i32 1; // %Load1 = load i32, i32* %Ptr1, align 4; // %Res1 = insertelement <16 x i32> %res.phi.else, i32 %Load1, i32 1; // br label %else2; // . . .; // %Result = select <16 x i1> %Mask, <16 x i32> %res.phi.select, <16 x i32> %Src; // ret <16 x i32> %Result",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/ScalarizeMaskedMemIntrin.cpp:189,load,loading,189,interpreter/llvm-project/llvm/lib/Transforms/Scalar/ScalarizeMaskedMemIntrin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/ScalarizeMaskedMemIntrin.cpp,6,['load'],"['load', 'loading']"
Performance,"// Translate a masked load intrinsic like; // <16 x i32 > @llvm.masked.load( <16 x i32>* %addr, i32 align,; // <16 x i1> %mask, <16 x i32> %passthru); // to a chain of basic blocks, with loading element one-by-one if; // the appropriate mask bit is set; //; // %1 = bitcast i8* %addr to i32*; // %2 = extractelement <16 x i1> %mask, i32 0; // br i1 %2, label %cond.load, label %else; //; // cond.load: ; preds = %0; // %3 = getelementptr i32* %1, i32 0; // %4 = load i32* %3; // %5 = insertelement <16 x i32> %passthru, i32 %4, i32 0; // br label %else; //; // else: ; preds = %0, %cond.load; // %res.phi.else = phi <16 x i32> [ %5, %cond.load ], [ poison, %0 ]; // %6 = extractelement <16 x i1> %mask, i32 1; // br i1 %6, label %cond.load1, label %else2; //; // cond.load1: ; preds = %else; // %7 = getelementptr i32* %1, i32 1; // %8 = load i32* %7; // %9 = insertelement <16 x i32> %res.phi.else, i32 %8, i32 1; // br label %else2; //; // else2: ; preds = %else, %cond.load1; // %res.phi.else3 = phi <16 x i32> [ %9, %cond.load1 ], [ %res.phi.else, %else ]; // %10 = extractelement <16 x i1> %mask, i32 2; // br i1 %10, label %cond.load4, label %else5; //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/ScalarizeMaskedMemIntrin.cpp:22,load,load,22,interpreter/llvm-project/llvm/lib/Transforms/Scalar/ScalarizeMaskedMemIntrin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/ScalarizeMaskedMemIntrin.cpp,9,['load'],"['load', 'loading']"
Performance,// Translate global code completions into cached completions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/ASTUnit.cpp:42,cache,cached,42,interpreter/llvm-project/clang/lib/Frontend/ASTUnit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/ASTUnit.cpp,1,['cache'],['cached']
Performance,// Transpose shuffle kinds can be performed with 'trn1/trn2' and; // 'zip1/zip2' instructions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp:34,perform,performed,34,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,1,['perform'],['performed']
Performance,"// Traverse all instructions, collect loads/stores/returns, check for calls.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/ThreadSanitizer.cpp:38,load,loads,38,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/ThreadSanitizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/ThreadSanitizer.cpp,1,['load'],['loads']
Performance,// Traverse all the indirect-call callsite and get the value profile; // annotation to perform indirect-call promotion.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/IndirectCallPromotion.cpp:87,perform,perform,87,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/IndirectCallPromotion.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/IndirectCallPromotion.cpp,1,['perform'],['perform']
Performance,"// Traverse all uses of the load operand value, to see if invariant.start is; // one of the uses, and whether it dominates the load instruction.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp:28,load,load,28,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp,2,['load'],['load']
Performance,"// Traverse the CFG until we find a branch.; // TODO: While this should still be very fast,; // maybe we should cache the answer.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/CFG.cpp:112,cache,cache,112,interpreter/llvm-project/clang/lib/Analysis/CFG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/CFG.cpp,1,['cache'],['cache']
Performance,"// Traverse the expression tree in bottom-up order looking for loads. If we; // encounter an instruction we don't yet handle, we give up.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp:63,load,loads,63,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,1,['load'],['loads']
Performance,"// Traverse the given statement. If the most-derived traverse function takes a; // data recursion queue, pass it on; otherwise, discard it. Note that the; // first branch of this conditional must compile whether or not the derived; // class can take a queue, so if we're taking the second arm, make the first; // arm call our function rather than the derived class version.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/AST/RecursiveASTVisitor.h:98,queue,queue,98,interpreter/llvm-project/clang/include/clang/AST/RecursiveASTVisitor.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/AST/RecursiveASTVisitor.h,2,['queue'],['queue']
Performance,"// Traverse the operand, looking for constant vectors. Replace them by a; // load of a global variable of constant vector type.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64PromoteConstant.cpp:77,load,load,77,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64PromoteConstant.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64PromoteConstant.cpp,1,['load'],['load']
Performance,"// Traverse the type, build GEPs and loads.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/AttributorAttributes.cpp:37,load,loads,37,interpreter/llvm-project/llvm/lib/Transforms/IPO/AttributorAttributes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/AttributorAttributes.cpp,1,['load'],['loads']
Performance,// Treat any function we're trying not to optimize as if it were an; // indirect call and omit it from the node set used below.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionAttrs.cpp:42,optimiz,optimize,42,interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionAttrs.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionAttrs.cpp,1,['optimiz'],['optimize']
Performance,"// Treat constant and global as identical. SMRD loads are sometimes usable for; // global loads (ideally constant address space should be eliminated); // depending on the context. Legality cannot be context dependent, but; // RegBankSelect can split the load as necessary depending on the pointer; // register bank/uniformity and if the memory is invariant or not written in a; // kernel.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp:48,load,loads,48,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,3,['load'],"['load', 'loads']"
Performance,// Treat i1 loads the same as i8 loads. Masking will be done when storing.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FastISel.cpp:12,load,loads,12,interpreter/llvm-project/llvm/lib/Target/X86/X86FastISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FastISel.cpp,2,['load'],['loads']
Performance,// Treat the new block as incoming for load insertion.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/WinEHPrepare.cpp:39,load,load,39,interpreter/llvm-project/llvm/lib/CodeGen/WinEHPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/WinEHPrepare.cpp,1,['load'],['load']
Performance,"// Tries to find a possibility to optimize a v_cmp ..., s_and_saveexec; // sequence by looking at an instance of an s_and_saveexec instruction.; // Returns a pointer to the v_cmp instruction if it is safe to replace the; // sequence (see the conditions in the function body). This is after register; // allocation, so some checks on operand dependencies need to be considered.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIOptimizeExecMasking.cpp:34,optimiz,optimize,34,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIOptimizeExecMasking.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIOptimizeExecMasking.cpp,1,['optimiz'],['optimize']
Performance,"// Tries to perform; // (lshr (add (zext X), (zext Y)), K); // -> (icmp ult (add X, Y), X); // where; // - The add's operands are zexts from a K-bits integer to a bigger type.; // - The add is only used by the shr, or by iK (or narrower) truncates.; // - The lshr type has more than 2 bits (other types are boolean math).; // - K > 1; // note that; // - The resulting add cannot have nuw/nsw, else on overflow we get a; // poison value and the transform isn't legal anymore.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineShifts.cpp:12,perform,perform,12,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineShifts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineShifts.cpp,1,['perform'],['perform']
Performance,"// Trigger create of all object caches now in nodes that have deferred object creation; // so that cache contents can be processed immediately",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsOptTestStatistic.cxx:32,cache,caches,32,roofit/roofitcore/src/RooAbsOptTestStatistic.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsOptTestStatistic.cxx,6,['cache'],"['cache', 'caches']"
Performance,// Trigger filtee loading at runtime.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/BinaryFormat/ELF.h:18,load,loading,18,interpreter/llvm-project/llvm/include/llvm/BinaryFormat/ELF.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/BinaryFormat/ELF.h,1,['load'],['loading']
Performance,"// Trim cache here",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAcceptReject.cxx:8,cache,cache,8,roofit/roofitcore/src/RooAcceptReject.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAcceptReject.cxx,1,['cache'],['cache']
Performance,// Trivial if we are optimizing for code size or if there is only; // one use of the value.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelDAGToDAG.cpp:21,optimiz,optimizing,21,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelDAGToDAG.cpp,2,['optimiz'],['optimizing']
Performance,"// Tru64 stack walk. Uses the exception handling library and the; // run-time linker's core functions (loader(5)). FIXME: Tru64; // should have _RLD_DLADDR like IRIX below. Verify and update.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/unix/src/TUnixSystem.cxx:103,load,loader,103,core/unix/src/TUnixSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/unix/src/TUnixSystem.cxx,1,['load'],['loader']
Performance,"// True for volatile instruction.; // For Load/Store return true if atomic ordering is stronger than AO,; // for other instruction just true if it can read or write to memory.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp:42,Load,Load,42,interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,1,['Load'],['Load']
Performance,// True if Offset is a constant that needs to be; // rematerialized before the new load/store.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/GlobalISel/CombinerHelper.h:83,load,load,83,interpreter/llvm-project/llvm/include/llvm/CodeGen/GlobalISel/CombinerHelper.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/GlobalISel/CombinerHelper.h,1,['load'],['load']
Performance,"// True if file permissions must be open; // Local cache handling",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/inc/TDataSetManagerFile.h:51,cache,cache,51,proof/proof/inc/TDataSetManagerFile.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/inc/TDataSetManagerFile.h,1,['cache'],['cache']
Performance,// True if it's the first LICM in the loop.; // Holds information about whether it is allowed to move load instructions; // out of the loop,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineLICM.cpp:102,load,load,102,interpreter/llvm-project/llvm/lib/CodeGen/MachineLICM.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineLICM.cpp,1,['load'],['load']
Performance,"// True if the cache is used for browsing remote repositories",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/inc/TDataSetManagerFile.h:15,cache,cache,15,proof/proof/inc/TDataSetManagerFile.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/inc/TDataSetManagerFile.h,1,['cache'],['cache']
Performance,// True if the identifier has changed from the definition; // loaded from an AST file.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Basic/IdentifierTable.h:62,load,loaded,62,interpreter/llvm-project/clang/include/clang/Basic/IdentifierTable.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Basic/IdentifierTable.h,1,['load'],['loaded']
Performance,// True if the identifier was loaded (at least partially) from an AST file.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Basic/IdentifierTable.h:30,load,loaded,30,interpreter/llvm-project/clang/include/clang/Basic/IdentifierTable.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Basic/IdentifierTable.h,1,['load'],['loaded']
Performance,// True if the identifier's frontend information has changed from the; // definition loaded from an AST file.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Basic/IdentifierTable.h:85,load,loaded,85,interpreter/llvm-project/clang/include/clang/Basic/IdentifierTable.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Basic/IdentifierTable.h,1,['load'],['loaded']
Performance,// True if the previous pipeline Stage was unable to dispatch a full group of; // opcodes because scheduler buffers (or LS queues) were unavailable.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/HardwareUnits/Scheduler.h:123,queue,queues,123,interpreter/llvm-project/llvm/include/llvm/MCA/HardwareUnits/Scheduler.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/HardwareUnits/Scheduler.h,1,['queue'],['queues']
Performance,// True if this instruction has been optimized at register renaming stage.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/Instruction.h:37,optimiz,optimized,37,interpreter/llvm-project/llvm/include/llvm/MCA/Instruction.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/Instruction.h,1,['optimiz'],['optimized']
Performance,// True if throughput was affected by dispatch stalls.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-mca/Views/BottleneckAnalysis.h:11,throughput,throughput,11,interpreter/llvm-project/llvm/tools/llvm-mca/Views/BottleneckAnalysis.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-mca/Views/BottleneckAnalysis.h,1,['throughput'],['throughput']
Performance,// True if we can perform outlining given the last mapped (non-invisible); // instruction. This lets us know if we have a legal range.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineOutliner.cpp:18,perform,perform,18,interpreter/llvm-project/llvm/lib/CodeGen/MachineOutliner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineOutliner.cpp,1,['perform'],['perform']
Performance,// True when either the Target Machine specifies no optimizations or the; // function has the optnone attribute.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/GlobalISel/IRTranslator.h:52,optimiz,optimizations,52,interpreter/llvm-project/llvm/include/llvm/CodeGen/GlobalISel/IRTranslator.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/GlobalISel/IRTranslator.h,1,['optimiz'],['optimizations']
Performance,// Truncating/extending stores/loads are also not supported.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Sparc/SparcISelLowering.cpp:31,load,loads,31,interpreter/llvm-project/llvm/lib/Target/Sparc/SparcISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Sparc/SparcISelLowering.cpp,1,['load'],['loads']
Performance,// Try and modify users of the load that are extractelement instructions to; // use the shufflevector instructions instead of the load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedAccessPass.cpp:31,load,load,31,interpreter/llvm-project/llvm/lib/CodeGen/InterleavedAccessPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedAccessPass.cpp,2,['load'],['load']
Performance,"// Try and vectorize the indices. We are currently only interested in; // gather-like cases of the form:; //; // ... = g[a[0] - b[0]] + g[a[1] - b[1]] + ...; //; // where the loads of ""a"", the loads of ""b"", and the subtractions can be; // performed in parallel. It's likely that detecting this pattern in a; // bottom-up phase will be simpler and less costly than building a; // full-blown top-down phase beginning at the consecutive loads.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp:175,load,loads,175,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,4,"['load', 'perform']","['loads', 'performed']"
Performance,"// Try best to find dbg.declare. If the spill is a temp, there may not; // be a direct dbg.declare. Walk up the load chain to find one from an; // alias.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Coroutines/CoroFrame.cpp:112,load,load,112,interpreter/llvm-project/llvm/lib/Transforms/Coroutines/CoroFrame.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Coroutines/CoroFrame.cpp,1,['load'],['load']
Performance,// Try common optimizations,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/R600ISelLowering.cpp:14,optimiz,optimizations,14,interpreter/llvm-project/llvm/lib/Target/AMDGPU/R600ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/R600ISelLowering.cpp,1,['optimiz'],['optimizations']
Performance,"// Try different normalization sets to check if there is a false cache hit; // after changing the normalization range of the servers.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/test/testRooProdPdf.cxx:65,cache,cache,65,roofit/roofitcore/test/testRooProdPdf.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/test/testRooProdPdf.cxx,1,['cache'],['cache']
Performance,// Try hard to fold loads from bitcasted strange and non-type-safe things.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ConstantFolding.cpp:20,load,loads,20,interpreter/llvm-project/llvm/lib/Analysis/ConstantFolding.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ConstantFolding.cpp,1,['load'],['loads']
Performance,"// Try harder: look for min/max pattern based on instructions producing; // same values such as: select ((cmp Inst1, Inst2), Inst1, Inst2).; // During the intermediate stages of SLP, it's very common to have; // pattern like this (since optimizeGatherSequence is run only once; // at the end):; // %1 = extractelement <2 x i32> %a, i32 0; // %2 = extractelement <2 x i32> %a, i32 1; // %cond = icmp sgt i32 %1, %2; // %3 = extractelement <2 x i32> %a, i32 0; // %4 = extractelement <2 x i32> %a, i32 1; // %select = select i1 %cond, i32 %3, i32 %4",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp:237,optimiz,optimizeGatherSequence,237,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,1,['optimiz'],['optimizeGatherSequence']
Performance,"// Try loading <mode>.cfg, and return if loading failed. If a matching file; // was not found, still proceed on to try <triple>.cfg.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/Driver.cpp:7,load,loading,7,interpreter/llvm-project/clang/lib/Driver/Driver.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/Driver.cpp,2,['load'],['loading']
Performance,// Try loading <triple>.cfg and return if we find a match.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/Driver.cpp:7,load,loading,7,interpreter/llvm-project/clang/lib/Driver/Driver.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/Driver.cpp,1,['load'],['loading']
Performance,// Try loading the buffer for this cache entry.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/LTO/ThinLTOCodeGenerator.cpp:7,load,loading,7,interpreter/llvm-project/llvm/lib/LTO/ThinLTOCodeGenerator.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/LTO/ThinLTOCodeGenerator.cpp,2,"['cache', 'load']","['cache', 'loading']"
Performance,"// Try opening the file from the cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx:33,cache,cache,33,io/io/src/TFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx,1,['cache'],['cache']
Performance,// Try scalarizing vector stores of loads where we only change one element,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:36,load,loads,36,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['loads']
Performance,// Try simplification again because we use this function to optimize; // BLENDV nodes that are not handled by the generic combiner.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:60,optimiz,optimize,60,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['optimiz'],['optimize']
Performance,// Try some other optimizations before falling back to generic lowering.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:18,optimiz,optimizations,18,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['optimiz'],['optimizations']
Performance,// Try splitting an indexed load/store to an un-indexed one plus an add/sub; // operation.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp:28,load,load,28,interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp,1,['load'],['load']
Performance,// Try the cache first.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CrossTU/CrossTranslationUnit.cpp:11,cache,cache,11,interpreter/llvm-project/clang/lib/CrossTU/CrossTranslationUnit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CrossTU/CrossTranslationUnit.cpp,3,['cache'],['cache']
Performance,"// Try the queued iterator, which may itself be empty.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp:11,queue,queued,11,interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,1,['queue'],['queued']
Performance,// Try to adjust CC masks for the LOAD AND TEST opcode that could replace MI.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZElimCompare.cpp:34,LOAD,LOAD,34,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZElimCompare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZElimCompare.cpp,1,['LOAD'],['LOAD']
Performance,// Try to annotate calls that were created during optimization.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp:50,optimiz,optimization,50,interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,1,['optimiz'],['optimization']
Performance,"// Try to apply the named return value optimization. We have to check again; // if we can do this, though, because blocks keep return statements around; // to deduce an implicit return type.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp:39,optimiz,optimization,39,interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp,1,['optimiz'],['optimization']
Performance,// Try to apply the named return value optimization. We have to check; // if we can do this here because lambdas keep return statements around; // to deduce an implicit return type.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp:39,optimiz,optimization,39,interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp,1,['optimiz'],['optimization']
Performance,"// Try to avoid using an extload by loading earlier than the argument address,; // and extracting the relevant bits. The load should hopefully be merged with; // the previous argument.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:36,load,loading,36,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,2,['load'],"['load', 'loading']"
Performance,// Try to canonicalize the loaded type.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp:27,load,loaded,27,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp,1,['load'],['loaded']
Performance,"// Try to combine the following nodes; // t29: i64 = X86ISD::Wrapper TargetConstantPool:i64; // <i32 -2147483648[float -0.000000e+00]> 0; // t27: v16i32[v16f32],ch = X86ISD::VBROADCAST_LOAD; // <(load 4 from constant-pool)> t0, t29; // [t30: v16i32 = bitcast t27]; // t6: v16i32 = xor t7, t27[t30]; // t11: v16f32 = bitcast t6; // t21: v16f32 = X86ISD::VFMULC[X86ISD::VCFMULC] t11, t8; // into X86ISD::VFCMULC[X86ISD::VFMULC] if possible:; // t22: v16f32 = bitcast t7; // t23: v16f32 = X86ISD::VFCMULC[X86ISD::VFMULC] t8, t22; // t24: v32f16 = bitcast t23",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:196,load,load,196,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,// Try to combine two adjacent loads/stores to a single pair instruction from; // the XTHeadMemPair vendor extension.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:31,load,loads,31,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['load'],['loads']
Performance,// Try to compute the result without performing a partial substitution.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/TreeTransform.h:37,perform,performing,37,interpreter/llvm-project/clang/lib/Sema/TreeTransform.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/TreeTransform.h,1,['perform'],['performing']
Performance,// Try to create 16-bit GP relative load instruction.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/AsmParser/MipsAsmParser.cpp:36,load,load,36,interpreter/llvm-project/llvm/lib/Target/Mips/AsmParser/MipsAsmParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/AsmParser/MipsAsmParser.cpp,1,['load'],['load']
Performance,// Try to create target specific intrinsics to replace the load and shuffles.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedAccessPass.cpp:59,load,load,59,interpreter/llvm-project/llvm/lib/CodeGen/InterleavedAccessPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedAccessPass.cpp,1,['load'],['load']
Performance,"// Try to decode to a load/store instruction. ST/LD need a specified; // DecoderMethod, as they already have a specified PostEncoderMethod.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AVR/Disassembler/AVRDisassembler.cpp:22,load,load,22,interpreter/llvm-project/llvm/lib/Target/AVR/Disassembler/AVRDisassembler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AVR/Disassembler/AVRDisassembler.cpp,1,['load'],['load']
Performance,"// Try to determine a join block through the help of the dominance tree. If no; // tree was provided, we perform simple pattern matching for one block; // conditionals only.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MustExecute.cpp:105,perform,perform,105,interpreter/llvm-project/llvm/lib/Analysis/MustExecute.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MustExecute.cpp,1,['perform'],['perform']
Performance,"// Try to determine a join block through the help of the post-dominance; // tree. If no tree was provided, we perform simple pattern matching for one; // block conditionals and one block loops only.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MustExecute.cpp:110,perform,perform,110,interpreter/llvm-project/llvm/lib/Analysis/MustExecute.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MustExecute.cpp,1,['perform'],['perform']
Performance,"// Try to eliminate a power-of-2 mask constant by converting to a signbit; // test in a narrow type that we can truncate to with no cost. Examples:; // (i32 X & 32768) == 0 --> (trunc X to i16) >= 0; // (i32 X & 32768) != 0 --> (trunc X to i16) < 0; // TODO: This conservatively checks for type legality on the source and; // destination types. That may inhibit optimizations, but it also; // allows setcc->shift transforms that may be more beneficial.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp:362,optimiz,optimizations,362,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp,1,['optimiz'],['optimizations']
Performance,// Try to emit code for scalar constant instead of emitting LValue and; // loading it because we are not guaranteed to have an l-value. One of such; // cases is DeclRefExpr referencing non-odr-used constant-evaluated variable.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp:75,load,loading,75,interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp,1,['load'],['loading']
Performance,"// Try to evict a less worthy live range, but only for ranges from the primary; // queue. The RS_Split ranges already failed to do this, and they should not; // get a second chance until they have been split.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RegAllocGreedy.cpp:83,queue,queue,83,interpreter/llvm-project/llvm/lib/CodeGen/RegAllocGreedy.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RegAllocGreedy.cpp,1,['queue'],['queue']
Performance,// Try to find a larger VBROADCAST_LOAD/SUBV_BROADCAST_LOAD that we can extract; // from. Limit this to cases where the loads have the same input chain and the; // output chains are unused. This avoids any memory ordering issues.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:120,load,loads,120,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['loads']
Performance,"// Try to find a tree of shuffles and concats from how IR shuffles of loads; // are lowered. Note that this only comes up because we do not always visit; // operands before uses. After that is fixed this can be removed and in the; // meantime this is fairly specific to the lowering we expect from IR.; // t46: v16i8 = vector_shuffle<0,1,2,3,4,5,6,7,8,9,10,11,16,17,18,19> t44, t45; // t44: v16i8 = vector_shuffle<0,1,2,3,4,5,6,7,16,17,18,19,u,u,u,u> t42, t43; // t42: v16i8 = concat_vectors t40, t36, undef:v4i8, undef:v4i8; // t40: v4i8,ch = load<(load (s32) from %ir.17)> t0, t22, undef:i64; // t36: v4i8,ch = load<(load (s32) from %ir.13)> t0, t18, undef:i64; // t43: v16i8 = concat_vectors t32, undef:v4i8, undef:v4i8, undef:v4i8; // t32: v4i8,ch = load<(load (s32) from %ir.9)> t0, t14, undef:i64; // t45: v16i8 = concat_vectors t28, undef:v4i8, undef:v4i8, undef:v4i8; // t28: v4i8,ch = load<(load (s32) from %ir.0)> t0, t2, undef:i64",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:70,load,loads,70,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,9,['load'],"['load', 'loads']"
Performance,// Try to find an interleaved load using the front of Worklist as first line,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp:30,load,load,30,interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp,1,['load'],['load']
Performance,// Try to find load and store instructions which recalculate addresses already; // calculated by some LEA and replace their memory operands with its def; // register.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp:15,load,load,15,interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86OptimizeLEAs.cpp,1,['load'],['load']
Performance,// Try to fold a load. No need to check alignment.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp:17,load,load,17,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,2,['load'],['load']
Performance,"// Try to fold intrinsic into select operands. This is legal if:; // * The intrinsic is speculatable.; // * The select condition is not a vector, or the intrinsic does not; // perform cross-lane operations.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp:176,perform,perform,176,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp,1,['perform'],['perform']
Performance,"// Try to fold load/store + G_PTR_ADD + G_CONSTANT; // %SignedOffset:(s32) = G_CONSTANT i32 16_bit_signed_immediate; // %Addr:(p0) = G_PTR_ADD %BaseAddr, %SignedOffset; // %LoadResult/%StoreSrc = load/store %Addr(p0); // into:; // %LoadResult/%StoreSrc = NewOpc %BaseAddr(p0), 16_bit_signed_immediate",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsInstructionSelector.cpp:15,load,load,15,interpreter/llvm-project/llvm/lib/Target/Mips/MipsInstructionSelector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsInstructionSelector.cpp,4,"['Load', 'load']","['LoadResult', 'load']"
Performance,// Try to fold the base pointer arithmetic into subsequent loads and; // stores.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:59,load,loads,59,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['loads']
Performance,// Try to fold the load/store with an update that matches memory; // access size. This should work well for sequential loads.; //; // Filter out invalid updates as well.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:19,load,load,19,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,2,['load'],"['load', 'loads']"
Performance,"// Try to forward the store to any loads. If we have more than one store, we; // may have a store of the initializer between StoredOnceStore and a load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp:35,load,loads,35,interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,2,['load'],"['load', 'loads']"
Performance,// Try to get the region from which the ivar value was loaded.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/CheckObjCDealloc.cpp:55,load,loaded,55,interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/CheckObjCDealloc.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/CheckObjCDealloc.cpp,1,['load'],['loaded']
Performance,"// Try to get the region from which the released value was loaded.; // Note that, unlike diagnosing for missing releases, here we don't track; // values that must not be released in the state. This is because even if; // these values escape, it is still an error under the rules of MRR to; // release them in -dealloc.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/CheckObjCDealloc.cpp:59,load,loaded,59,interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/CheckObjCDealloc.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/CheckObjCDealloc.cpp,1,['load'],['loaded']
Performance,// Try to guess the type of the load from the MMO.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64RegisterBankInfo.cpp:32,load,load,32,interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64RegisterBankInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64RegisterBankInfo.cpp,1,['load'],['load']
Performance,// Try to identify two factorizable MUL/SHL children greedily. Leave; // them out of the priority queue for now so we can deal with them; // after.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp:98,queue,queue,98,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,1,['queue'],['queue']
Performance,// Try to infer better alignment information than the load already has.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:54,load,load,54,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,// Try to inline memcpy type calls if optimizations are enabled.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64O0PreLegalizerCombiner.cpp:38,optimiz,optimizations,38,interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64O0PreLegalizerCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64O0PreLegalizerCombiner.cpp,2,['optimiz'],['optimizations']
Performance,"// Try to insert; if insertion failed because the entry existed, DeepAutoLoadImpl(); // has previously (within the same call to `AutoLoad()`) tried to load this class; // and we are done, whether success or not, as it won't work better now than before,; // because there is no additional information now compared to before.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:151,load,load,151,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,1,['load'],['load']
Performance,// Try to interpret value loaded by instruction.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfDebug.cpp:26,load,loaded,26,interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfDebug.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfDebug.cpp,1,['load'],['loaded']
Performance,// Try to interpret values loaded by instruction.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfDebug.cpp:27,load,loaded,27,interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfDebug.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfDebug.cpp,1,['load'],['loaded']
Performance,"// Try to keep the same value in SOffset for adjacent loads, so that; // the corresponding register contents can be re-used.; //; // Load values with all low-bits (except for alignment bits) set into; // SOffset, so that a larger range of values can be covered using; // s_movk_i32.; //; // Atomic operations fail to work correctly when individual address; // components are unaligned, even if their sum is aligned.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp:54,load,loads,54,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp,2,"['Load', 'load']","['Load', 'loads']"
Performance,"// Try to load TrueType font renderer. Only try to load if not in batch; // mode and Root.UseTTFonts is true and Root.TTFontPath exists. Abort silently; // if libttf or libGX11TTF are not found in $ROOTSYS/lib or $ROOTSYS/ttf/lib.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TApplication.cxx:10,load,load,10,core/base/src/TApplication.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TApplication.cxx,2,['load'],['load']
Performance,// Try to load a corresponding private module map.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp:10,load,load,10,interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp,1,['load'],['load']
Performance,// Try to load a module map file for the search directory.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp:10,load,load,10,interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp,2,['load'],['load']
Performance,// Try to load a module map file.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp:10,load,load,10,interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp,1,['load'],['load']
Performance,// Try to load archive and force it to be memory mapped.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/dsymutil/BinaryHolder.cpp:10,load,load,10,interpreter/llvm-project/llvm/tools/dsymutil/BinaryHolder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/dsymutil/BinaryHolder.cpp,1,['load'],['load']
Performance,// Try to load module map files for immediate subdirectories of this; // search directory.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp:10,load,load,10,interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp,1,['load'],['load']
Performance,// Try to load regular binary and force it to be memory mapped.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/dsymutil/BinaryHolder.cpp:10,load,load,10,interpreter/llvm-project/llvm/tools/dsymutil/BinaryHolder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/dsymutil/BinaryHolder.cpp,1,['load'],['load']
Performance,// Try to load the API notes.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/APINotes/APINotesManager.cpp:10,load,load,10,interpreter/llvm-project/clang/lib/APINotes/APINotesManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/APINotes/APINotesManager.cpp,1,['load'],['load']
Performance,// Try to load the file buffer.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/ARCMigrate/TransformActions.cpp:10,load,load,10,interpreter/llvm-project/clang/lib/ARCMigrate/TransformActions.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/ARCMigrate/TransformActions.cpp,7,['load'],['load']
Performance,// Try to load the global index.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp:10,load,load,10,interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,1,['load'],['load']
Performance,"// Try to load the library which should provide the symbol definition.; // TODO: Should this interface with the DynamicLibraryManager directly?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TClingCallbacks.cxx:10,load,load,10,core/metacling/src/TClingCallbacks.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TClingCallbacks.cxx,1,['load'],['load']
Performance,// Try to load the module file.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp:10,load,load,10,interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,1,['load'],['load']
Performance,"// Try to load the module file. If we are not trying to load from the; // module cache, we don't know how to rebuild modules.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp:10,load,load,10,interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,3,"['cache', 'load']","['cache', 'load']"
Performance,// Try to load the module from the module cache.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp:10,load,load,10,interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,2,"['cache', 'load']","['cache', 'load']"
Performance,// Try to load the module from the prebuilt module path.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp:10,load,load,10,interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,1,['load'],['load']
Performance,// Try to load the module map file in this directory.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp:10,load,load,10,interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp,1,['load'],['load']
Performance,// Try to load the pre-compiled object from cache if possible,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/MCJIT/MCJIT.cpp:10,load,load,10,interpreter/llvm-project/llvm/lib/ExecutionEngine/MCJIT/MCJIT.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/MCJIT/MCJIT.cpp,2,"['cache', 'load']","['cache', 'load']"
Performance,"// Try to lower with the simpler initial blend/unpack/rotate strategies unless; // one of the input shuffles would be a no-op. We prefer to shuffle inputs as; // the shuffle may be able to fold with a load or other benefit. However, when; // we'll have to do 2x as many shuffles in order to achieve this, a 2-input; // pre-shuffle first is a better strategy.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:201,load,load,201,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,// Try to match a sign-extended load/store with a zero-extended load/store.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp:32,load,load,32,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp,2,['load'],['load']
Performance,// Try to match an unscaled load/store with a scaled load/store.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp:28,load,load,28,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp,2,['load'],['load']
Performance,// Try to match splat of a scalar load to a strided load with stride of x0.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelDAGToDAG.cpp:34,load,load,34,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelDAGToDAG.cpp,2,['load'],['load']
Performance,// Try to merge vector loads and extend_inreg to an extload.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,load,loads,23,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['loads']
Performance,"// Try to omit the note if we know in advance which branch is; // taken (this means, only one branch exists).; // This check is performed inside the lambda, after other; // (or this) checkers had a chance to add other successors.; // Dereferencing the saved node object is valid because it's part; // of a bug report call sequence.; // FIXME: This check is not exact. We may be here after a state; // split that was performed by another checker (and can not find; // the successors). This is why this check is only used in the; // EvalCallAsPure case.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/StdLibraryFunctionsChecker.cpp:128,perform,performed,128,interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/StdLibraryFunctionsChecker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/StdLibraryFunctionsChecker.cpp,2,['perform'],['performed']
Performance,"// Try to optimize 'icmp GEP, P' or 'icmp P, GEP'.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCompares.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCompares.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCompares.cpp,1,['optimiz'],['optimize']
Performance,// Try to optimize already sign-/zero-extended values from function arguments.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FastISel.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FastISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FastISel.cpp,1,['optimiz'],['optimize']
Performance,// Try to optimize already sign-/zero-extended values from load instructions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FastISel.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FastISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FastISel.cpp,2,"['load', 'optimiz']","['load', 'optimize']"
Performance,"// Try to optimize cases that only set the denormal mode or rounding mode.; //; // If the s_setreg_b32 fully sets all of the bits in the rounding mode or; // denormal mode to a constant, we can use s_round_mode or s_denorm_mode; // instead.; //; // FIXME: This could be predicates on the immediate, but tablegen doesn't; // allow you to have a no side effect instruction in the output of a; // sideeffecting pattern.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,1,['optimiz'],['optimize']
Performance,// Try to optimize cases where comparison instruction Compare is testing; // a value against zero. Return true on success and if Compare should be; // deleted as dead. CCUsers is the list of instructions that use the CC; // value produced by Compare.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZElimCompare.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZElimCompare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZElimCompare.cpp,1,['optimiz'],['optimize']
Performance,"// Try to optimize conversions using tbl. This requires materializing constant; // index vectors, which can increase code size and add loads. Skip the; // transform unless the conversion is in a loop block guaranteed to execute; // and we are not optimizing for size.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,3,"['load', 'optimiz']","['loads', 'optimize', 'optimizing']"
Performance,// Try to optimize equality comparisons against alloca-based pointers.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCompares.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCompares.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCompares.cpp,1,['optimiz'],['optimize']
Performance,// Try to optimize globals based on the knowledge that only one value (besides; // its initializer) is ever stored to the global.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,1,['optimiz'],['optimize']
Performance,// Try to optimize globals based on the knowledge that only one value; // (besides its initializer) is ever stored to the global.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,1,['optimiz'],['optimize']
Performance,// Try to optimize or fold the cmp.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FastISel.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FastISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FastISel.cpp,5,['optimiz'],['optimize']
Performance,// Try to optimize sign extends in formal parameters. It's relying on; // callee already sign extending the values. I'm not sure if our ABI; // requires callee to sign extend though.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonOptimizeSZextends.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonOptimizeSZextends.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonOptimizeSZextends.cpp,1,['optimiz'],['optimize']
Performance,"// Try to optimize the call if possible, we require DataLayout for most of; // this. None of these calls are seen as possibly dead so go ahead and; // delete the instruction now.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp,1,['optimiz'],['optimize']
Performance,// Try to optimize the comparison against 0.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,1,['optimiz'],['optimize']
Performance,"// Try to optimize things like ""A[i] > 4"" to index computations.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCompares.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCompares.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCompares.cpp,1,['optimiz'],['optimize']
Performance,"// Try to optimize to; // bstrpick $Rd, $Rs, msb, lsb; // slli $Rd, $Rd, lsb",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/LoongArch/LoongArchISelLowering.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Target/LoongArch/LoongArchISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/LoongArch/LoongArchISelLowering.cpp,1,['optimiz'],['optimize']
Performance,"// Try to optimize v16i16->v16i8 truncating stores when BWI is not; // supported, but avx512f is by extending to v16i32 and truncating.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['optimiz'],['optimize']
Performance,// Try to optimize vXi1 selects if both operands are either all constants or; // bitcasts from scalar integer type. In that case we can convert the operands; // to integer and use an integer select which will be converted to a CMOV.; // We need to take a little bit of care to avoid creating an i64 type after; // type legalization.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['optimiz'],['optimize']
Performance,"// Try to peel the top probability case if it exceeds the threshold.; // Return current MachineBasicBlock for the switch statement if the peeling; // does not occur.; // If the peeling is performed, return the newly created MachineBasicBlock; // for the peeled switch statement. Also update Clusters to remove the peeled; // case. PeeledCaseProb is the BranchProbability for the peeled case.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp:188,perform,performed,188,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,1,['perform'],['performed']
Performance,// Try to perform OpenMP specific optimizations on the module. This is a; // (quick!) no-op if there are no OpenMP runtime calls present in the module.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp:10,perform,perform,10,interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,2,"['optimiz', 'perform']","['optimizations', 'perform']"
Performance,// Try to perform OpenMP specific optimizations. This is a (quick!) no-op if; // there are no OpenMP runtime calls present in the module.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp:10,perform,perform,10,interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,2,"['optimiz', 'perform']","['optimizations', 'perform']"
Performance,"// Try to perform atomicrmw xchg, otherwise simple exchange.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGStmtOpenMP.cpp:10,perform,perform,10,interpreter/llvm-project/clang/lib/CodeGen/CGStmtOpenMP.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGStmtOpenMP.cpp,1,['perform'],['perform']
Performance,// Try to perform better estimation of the permutation.; // 1. Split the source/destination vectors into real registers.; // 2. Do the mask analysis to identify which real registers are; // permuted.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/VectorUtils.cpp:10,perform,perform,10,interpreter/llvm-project/llvm/lib/Analysis/VectorUtils.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/VectorUtils.cpp,1,['perform'],['perform']
Performance,"// Try to perform better estimation of the permutation.; // 1. Split the source/destination vectors into real registers.; // 2. Do the mask analysis to identify which real registers are; // permuted. If more than 1 source registers are used for the; // destination register building, the cost for this destination register; // is (Number_of_source_register - 1) * Cost_PermuteTwoSrc. If only one; // source register is used, build mask and calculate the cost as a cost; // of PermuteSingleSrc.; // Also, for the single register permute we try to identify if the; // destination register is just a copy of the source register or the; // copy of the previous destination register (the cost is; // TTI::TCC_Basic). If the source register is just reused, the cost for; // this operation is 0.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:10,perform,perform,10,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,1,['perform'],['perform']
Performance,// Try to perform integral promotions if the object has a theoretically; // promotable type.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp:10,perform,perform,10,interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp,1,['perform'],['perform']
Performance,// Try to perform the memcmp when the result is tested for [in]equality with 0,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:10,perform,perform,10,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['perform'],['perform']
Performance,// Try to promote a chain of computation if it allows to form an extended; // load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:78,load,load,78,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,1,['load'],['load']
Performance,"// Try to read from cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/netxng/src/TNetXNGFile.cxx:20,cache,cache,20,net/netxng/src/TNetXNGFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/netxng/src/TNetXNGFile.cxx,1,['cache'],['cache']
Performance,"// Try to recognize special cases the DAG will emit special, better expansions; // than the general expansion we do here.; // TODO: It would be better to just directly handle those optimizations here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUCodeGenPrepare.cpp:181,optimiz,optimizations,181,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUCodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUCodeGenPrepare.cpp,1,['optimiz'],['optimizations']
Performance,"// Try to recognize table-based ctz implementation.; // E.g., an example in C (for more cases please see the llvm/tests):; // int f(unsigned x) {; // static const char table[32] =; // {0, 1, 28, 2, 29, 14, 24, 3, 30,; // 22, 20, 15, 25, 17, 4, 8, 31, 27,; // 13, 23, 21, 19, 16, 7, 26, 12, 18, 6, 11, 5, 10, 9};; // return table[((unsigned)((x & -x) * 0x077CB531U)) >> 27];; // }; // this can be lowered to `cttz` instruction.; // There is also a special case when the element is 0.; //; // Here are some examples or LLVM IR for a 64-bit target:; //; // CASE 1:; // %sub = sub i32 0, %x; // %and = and i32 %sub, %x; // %mul = mul i32 %and, 125613361; // %shr = lshr i32 %mul, 27; // %idxprom = zext i32 %shr to i64; // %arrayidx = getelementptr inbounds [32 x i8], [32 x i8]* @ctz1.table, i64 0,; // i64 %idxprom; // %0 = load i8, i8* %arrayidx, align 1, !tbaa !8; //; // CASE 2:; // %sub = sub i32 0, %x; // %and = and i32 %sub, %x; // %mul = mul i32 %and, 72416175; // %shr = lshr i32 %mul, 26; // %idxprom = zext i32 %shr to i64; // %arrayidx = getelementptr inbounds [64 x i16], [64 x i16]* @ctz2.table,; // i64 0, i64 %idxprom; // %0 = load i16, i16* %arrayidx, align 2, !tbaa !8; //; // CASE 3:; // %sub = sub i32 0, %x; // %and = and i32 %sub, %x; // %mul = mul i32 %and, 81224991; // %shr = lshr i32 %mul, 27; // %idxprom = zext i32 %shr to i64; // %arrayidx = getelementptr inbounds [32 x i32], [32 x i32]* @ctz3.table,; // i64 0, i64 %idxprom; // %0 = load i32, i32* %arrayidx, align 4, !tbaa !8; //; // CASE 4:; // %sub = sub i64 0, %x; // %and = and i64 %sub, %x; // %mul = mul i64 %and, 283881067100198605; // %shr = lshr i64 %mul, 58; // %arrayidx = getelementptr inbounds [64 x i8], [64 x i8]* @table, i64 0,; // i64 %shr; // %0 = load i8, i8* %arrayidx, align 1, !tbaa !8; //; // All this can be lowered to @llvm.cttz.i32/64 intrinsic.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp:822,load,load,822,interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp,4,['load'],['load']
Performance,"// Try to regroup reduced values so that it gets more profitable to try to; // reduce them. Values are grouped by their value ids, instructions - by; // instruction op id and/or alternate op id, plus do extra analysis for; // loads (grouping them by the distabce between pointers) and cmp; // instructions (grouping them by the predicate).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp:226,load,loads,226,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,1,['load'],['loads']
Performance,"// Try to remove as much code from the loop header as possible,; // to reduce amount of IR that will have to be duplicated. However,; // do not perform speculative hoisting the first time as LICM; // will destroy metadata that may not need to be destroyed if run; // after loop rotation.; // TODO: Investigate promotion cap for O1.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp:144,perform,perform,144,interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,2,['perform'],['perform']
Performance,// Try to remove both MI and Compare by converting a branch to BRCT(G).; // or a load-and-trap instruction. We don't care in this case whether; // CC is modified between MI and Compare.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZElimCompare.cpp:81,load,load-and-trap,81,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZElimCompare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZElimCompare.cpp,1,['load'],['load-and-trap']
Performance,"// Try to run OpenMP optimizations, quick no-op if no OpenMP metadata present.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp:21,optimiz,optimizations,21,interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,1,['optimiz'],['optimizations']
Performance,// Try to select as an indexed load. Fall through to normal processing; // if we can't.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelDAGToDAG.cpp:31,load,load,31,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelDAGToDAG.cpp,1,['load'],['load']
Performance,// Try to shrink a vector of FP constants. This returns nullptr on scalable; // vectors,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCasts.cpp:67,scalab,scalable,67,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCasts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCasts.cpp,1,['scalab'],['scalable']
Performance,// Try to simplify (sext (load x)).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:26,load,load,26,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,// Try to simplify (zext (load x)).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:26,load,load,26,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,['load'],['load']
Performance,"// Try to simplify:; // t1 = nxv8i16 add(X, 1 << (ShiftValue - 1)); // t2 = nxv8i16 srl(t1, ShiftValue); // to; // t1 = nxv8i16 rshrnb(X, shiftvalue).; // rshrnb will zero the top half bits of each element. Therefore, this combine; // should only be performed when a following instruction with the rshrnb; // as an operand does not care about the top half of each element. For example,; // a uzp1 or a truncating store.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:250,perform,performed,250,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['perform'],['performed']
Performance,// Try to sink a splat shuffle after a binop with a uniform constant.; // This is limited to cases where neither the shuffle nor the constant have; // undefined elements because that could be poison-unsafe or inhibit; // demanded elements analysis. It is further limited to not change a splat; // of an inserted scalar because that may be optimized better by; // load-folding or other target-specific behaviors.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:339,optimiz,optimized,339,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,"['load', 'optimiz']","['load-folding', 'optimized']"
Performance,// Try to slice up N to more direct loads if the slices are mapped to; // different register banks or pairing can take place.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:36,load,loads,36,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['loads']
Performance,"// Try to store any remaining integer argument regs; // to their spots on the stack so that they may be loaded by dereferencing; // the result of va_next.; // If there is no regs to be stored, just point address after last; // argument passed via stack.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:104,load,loaded,104,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['load'],['loaded']
Performance,// Try to the load the file buffer.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/Lexer.cpp:14,load,load,14,interpreter/llvm-project/clang/lib/Lex/Lexer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/Lexer.cpp,2,['load'],['load']
Performance,"// Try to traverse the given statement, or enqueue it if we're performing data; // recursion in the middle of traversing another statement. Can only be called; // from within a DEF_TRAVERSE_STMT body or similar context.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/AST/RecursiveASTVisitor.h:63,perform,performing,63,interpreter/llvm-project/clang/include/clang/AST/RecursiveASTVisitor.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/AST/RecursiveASTVisitor.h,1,['perform'],['performing']
Performance,// Try to turn 8 and 16-bit scalar loads into SMEM eligible 32-bit loads.; // TODO: Skip this on GFX12 which does have scalar sub-dword loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:35,load,loads,35,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,3,['load'],['loads']
Performance,// Try to turn sub-dword accesses of vectors into accesses of the same 32-bit; // elements. This exposes more load reduction opportunities by replacing; // multiple small extract_vector_elements with a single 32-bit extract.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:110,load,load,110,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,1,['load'],['load']
Performance,"// Try to use the base optimizeSelect, which uses canFoldIntoMOVCC to fold the; // MOVCC into another instruction. If that fails on 8.1-M fall back to using a; // CSEL.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/Thumb2InstrInfo.cpp:23,optimiz,optimizeSelect,23,interpreter/llvm-project/llvm/lib/Target/ARM/Thumb2InstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/Thumb2InstrInfo.cpp,1,['optimiz'],['optimizeSelect']
Performance,"// Try to vectorize the interleave group that \p Instr belongs to.; //; // E.g. Translate following interleaved load group (factor = 3):; // for (i = 0; i < N; i+=3) {; // R = Pic[i]; // Member of index 0; // G = Pic[i+1]; // Member of index 1; // B = Pic[i+2]; // Member of index 2; // ... // do something to R, G, B; // }; // To:; // %wide.vec = load <12 x i32> ; Read 4 tuples of R,G,B; // %R.vec = shuffle %wide.vec, poison, <0, 3, 6, 9> ; R elements; // %G.vec = shuffle %wide.vec, poison, <1, 4, 7, 10> ; G elements; // %B.vec = shuffle %wide.vec, poison, <2, 5, 8, 11> ; B elements; //; // Or translate following interleaved store group (factor = 3):; // for (i = 0; i < N; i+=3) {; // ... do something to R, G, B; // Pic[i] = R; // Member of index 0; // Pic[i+1] = G; // Member of index 1; // Pic[i+2] = B; // Member of index 2; // }; // To:; // %R_G.vec = shuffle %R.vec, %G.vec, <0, 1, 2, ..., 7>; // %B_U.vec = shuffle %B.vec, poison, <0, 1, 2, 3, u, u, u, u>; // %interleaved.vec = shuffle %R_G.vec, %B_U.vec,; // <0, 4, 8, 1, 5, 9, 2, 6, 10, 3, 7, 11> ; Interleave R,G,B elements; // store <12 x i32> %interleaved.vec ; Write 4 tuples of R,G,B",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:112,load,load,112,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,2,['load'],['load']
Performance,// Try transforming N to an indexed load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:36,load,load,36,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,['load'],['load']
Performance,// Try transforming a pair floating point load / store ops to integer; // load / store ops.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:42,load,load,42,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,['load'],['load']
Performance,"// Try turning it into a post-indexed load / store except when; // 1) All uses are load / store ops that use it as base ptr (and; // it may be folded as addressing mmode).; // 2) Op must be independent of N, i.e. Op is neither a predecessor; // nor a successor of N. Otherwise, if Op is folded that would; // create a cycle.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:38,load,load,38,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,['load'],['load']
Performance,// Try turning it into a pre-indexed load / store except when:; // 1) The new base ptr is a frame index.; // 2) If N is a store and the new base ptr is either the same as or is a; // predecessor of the value being stored.; // 3) Another use of old base ptr is a predecessor of N. If ptr is folded; // that would create a cycle.; // 4) All uses are load / store ops that use it as old base ptr.; // Check #1. Preinc'ing a frame index would require copying the stack pointer; // (plus the implicit offset) to a register to preinc anyway.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:37,load,load,37,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,['load'],['load']
Performance,// Trying to cluster all the neighboring loads/stores.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp:41,load,loads,41,interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp,1,['load'],['loads']
Performance,// Trying to hoist the IVInc to loop header if all IVInc users are in; // the loop header. It will help backend to generate post index load/store; // when the latch block is different from loop header block.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopStrengthReduce.cpp:135,load,load,135,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopStrengthReduce.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopStrengthReduce.cpp,1,['load'],['load']
Performance,"// Trying to remove a store of the loaded value.; // Check that the pointers are the same, and; // - store's mask is a subset of the load's mask.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp:35,load,loaded,35,interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,2,['load'],"['load', 'loaded']"
Performance,"// Trying to replace a load of a stored value with the store's value.; // Check that the pointers are the same, and; // - load's mask is a subset of store's mask, and; // - load's pass-through is ""undef"".",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp:23,load,load,23,interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,3,['load'],['load']
Performance,"// Trying to replace later masked load with the earlier one.; // Check that the pointers are the same, and; // - masks and pass-throughs are the same, or; // - replacee's pass-through is ""undef"" and replacer's mask is a; // super-set of the replacee's mask.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp:34,load,load,34,interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,1,['load'],['load']
Performance,"// Tuple types are expressed as aggregregate types of the same scalable; // vector type (e.g. vint32m1x2_t is two vint32m1_t, which is {<vscale x; // 2 x i32>, <vscale x 2 x i32>}).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenTypes.cpp:63,scalab,scalable,63,interpreter/llvm-project/clang/lib/CodeGen/CodeGenTypes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenTypes.cpp,1,['scalab'],['scalable']
Performance,// Ture if this register file only knows how to optimize register moves from; // known zero registers.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MC/MCSchedule.h:48,optimiz,optimize,48,interpreter/llvm-project/llvm/include/llvm/MC/MCSchedule.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MC/MCSchedule.h,1,['optimiz'],['optimize']
Performance,// Turn -fplugin=name.so into -load name.so,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp:31,load,load,31,interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp,1,['load'],['load']
Performance,"// Turn BSWAP (LOAD) -> lhbrx/lwbrx.; // For subtargets without LDBRX, we can still do better than the default; // expansion even for 64-bit BSWAP (LOAD).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:15,LOAD,LOAD,15,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,2,['LOAD'],['LOAD']
Performance,// Turn FP extload into load/fpextend,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:24,load,load,24,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,2,['load'],['load']
Performance,// Turn FP extload into load/fpextend.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelLowering.cpp:24,load,load,24,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelLowering.cpp,1,['load'],['load']
Performance,// Turn MOVDQ2Q+simple_load into an mmx load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:40,load,load,40,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,// Turn PPC VSX loads into normal loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp:16,load,loads,16,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,2,['load'],['loads']
Performance,// Turn PPC lvx -> load if the pointer is known aligned.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp:19,load,load,19,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,1,['load'],['load']
Performance,// Turn a 128-bit MOVDDUP of a full vector load into movddup+vzload.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:43,load,load,43,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,"// Turn load->store of MMX types into GPR load/stores. This avoids clobbering; // the FP state in cases where an emms may be missing.; // A preferable solution to the general problem is to figure out the right; // places to insert EMMS. This qualifies as a quick hack.; // Similarly, turn load->store of i64 into double load/stores in 32-bit mode.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,load,load,8,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,4,['load'],['load']
Performance,"// Turn off commute-with-shift transform after legalization, so it doesn't; // conflict with PerformSHLSimplify. (We could try to detect when; // PerformSHLSimplify would trigger more precisely, but it isn't; // really necessary.)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:93,Perform,PerformSHLSimplify,93,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,2,['Perform'],['PerformSHLSimplify']
Performance,// Turn splatted vector load into a strided load with an X0 stride.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:24,load,load,24,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,2,['load'],['load']
Performance,// Turn the unsupported load into an EXTLOAD followed by an; // explicit zero/sign extend inreg.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp:24,load,load,24,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,1,['load'],['load']
Performance,"// Turn this intrinsic straight into the appropriate ARMISD::VADDV node,; // which allow PerformADDVecReduce to turn it into VADDLV when possible.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:89,Perform,PerformADDVecReduce,89,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['Perform'],['PerformADDVecReduce']
Performance,"// Turn vperm(V1,V2,mask) -> shuffle(V1,V2,mask) if mask is a constant.; // Note that ppc_altivec_vperm has a big-endian bias, so when creating; // a vectorshuffle for little endian, we must undo the transformation; // performed on vec_perm in altivec.h. That is, we must complement; // the permutation mask with respect to 31 and reverse the order of; // V1 and V2.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp:219,perform,performed,219,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,1,['perform'],['performed']
Performance,"// Turns this:; //; // %base = ...; // %ptr = gep %base + 15; // %tok = statepoint (%fun, i32 0, i32 0, i32 0, %base, %ptr); // %base' = relocate(%tok, i32 4, i32 4); // %ptr' = relocate(%tok, i32 4, i32 5); // %val = load %ptr'; //; // into this:; //; // %base = ...; // %ptr = gep %base + 15; // %tok = statepoint (%fun, i32 0, i32 0, i32 0, %base, %ptr); // %base' = gc.relocate(%tok, i32 4, i32 4); // %ptr' = gep %base' + 15; // %val = load %ptr'",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:218,load,load,218,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,2,['load'],['load']
Performance,"// Two things:; // A. We can't reliably cache all of NewPaused back. Consider a case; // where we have two paths in NewPaused; one of which can't optimize; // above this phi, whereas the other can. If we cache the second path; // back, we'll end up with suboptimal cache entries. We can handle; // cases like this a bit better when we either try to find all; // clobbers that block phi optimization, or when our cache starts; // supporting unfinished searches.; // B. We can't reliably cache TerminatedPaths back here without doing; // extra checks; consider a case like:; // T; // / \; // D C; // \ /; // S; // Where T is our target, C is a node with a clobber on it, D is a; // diamond (with a clobber *only* on the left or right node, N), and; // S is our start. Say we walk to D, through the node opposite N; // (read: ignoring the clobber), and see a cache entry in the top; // node of D. That cache entry gets put into TerminatedPaths. We then; // walk up to C (N is later in our worklist), find the clobber, and; // quit. If we append TerminatedPaths to OtherClobbers, we'll cache; // the bottom part of D to the cached clobber, ignoring the clobber; // in N. Again, this problem goes away if we start tracking all; // blockers for a given phi optimization.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp:40,cache,cache,40,interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp,12,"['cache', 'optimiz']","['cache', 'cached', 'optimization', 'optimize']"
Performance,"// Type legalization of vectors and DAG canonicalization of SHUFFLE_VECTOR; // nodes often generate nop CONCAT_VECTOR nodes. Scan the CONCAT_VECTOR; // operands and look for a CONCAT operations that place the incoming vectors; // at the exact same location.; //; // For scalable vectors, EXTRACT_SUBVECTOR indexes are implicitly scaled.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:270,scalab,scalable,270,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['scalab'],['scalable']
Performance,// Type v256i1 is used for pairs and v512i1 is used for accumulators.; // Here we create 2 or 4 v16i8 loads to load the pair or accumulator value in; // 2 or 4 vsx registers.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:102,load,loads,102,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,2,['load'],"['load', 'loads']"
Performance,"// Typically, the correct way to call GetListOfFriends would be `tree.GetTree()->GetListOfFriends()`; // (see e.g. the discussion at https://github.com/root-project/root/issues/6741).; // However, in this case, in case we are dealing with a TChain we really only care about the TChain's; // list of friends (which will need to be rebuilt in each processing task) while friends of the TChain's; // internal TTree, if any, will be automatically loaded in each task just like they would be automatically; // loaded here if we used tree.GetTree()->GetListOfFriends().",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/InternalTreeUtils.cxx:443,load,loaded,443,tree/tree/src/InternalTreeUtils.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/InternalTreeUtils.cxx,2,['load'],['loaded']
Performance,"// Typically, unsigned comparison is used for equality check, but; // we replace it with a signed comparison if the comparison; // to be merged is a signed comparison.; // In other cases of opcode mismatch, we cannot optimize this.; // We cannot change opcode when comparing against an immediate; // if the most significant bit of the immediate is one; // due to the difference in sign extension.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp:217,optimiz,optimize,217,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp,1,['optimiz'],['optimize']
Performance,"// UI5 rendering is performed; // only from here we can start to analyze messages and create TGeo painter, clones objects and so on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/ui5/geom/controller/GeomViewer.controller.js:20,perform,performed,20,ui5/geom/controller/GeomViewer.controller.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/ui5/geom/controller/GeomViewer.controller.js,1,['perform'],['performed']
Performance,"// UMAAL is similar to UMLAL except that it adds two unsigned values.; // While trying to combine for the other MLAL nodes, first search for the; // chance to use UMAAL. Check if Addc uses a node which has already; // been combined into a UMLAL. The other pattern is UMLAL using Addc/Adde; // as the addend, and it's handled in PerformUMLALCombine.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:328,Perform,PerformUMLALCombine,328,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['Perform'],['PerformUMLALCombine']
Performance,"// UberRegSet is a helper class for computeRegUnitWeights. Each UberRegSet is; // the transitive closure of the union of overlapping register; // classes. Together, the UberRegSets form a partition of the registers. If we; // consider overlapping register classes to be connected, then each UberRegSet; // is a set of connected components.; //; // An UberRegSet will likely be a horizontal slice of register names of; // the same width. Nontrivial subregisters should then be in a separate; // UberRegSet. But this property isn't required for valid computation of; // register unit weights.; //; // A Weight field caches the max per-register unit weight in each UberRegSet.; //; // A set of SingularDeterminants flags single units of some register in this set; // for which the unit weight equals the set weight. These units should not have; // their weight increased.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/CodeGenRegisters.cpp:614,cache,caches,614,interpreter/llvm-project/llvm/utils/TableGen/CodeGenRegisters.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/CodeGenRegisters.cpp,1,['cache'],['caches']
Performance,// Unable to find operand latency. The caller may resort to getInstrLatency.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp:26,latency,latency,26,interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp,1,['latency'],['latency']
Performance,// Unaligned loads need special handling. Floats require word-alignment.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMFastISel.cpp:13,load,loads,13,interpreter/llvm-project/llvm/lib/Target/ARM/ARMFastISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMFastISel.cpp,1,['load'],['loads']
Performance,// Unaligned loads will be handled by the default lowering.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelLoweringHVX.cpp:13,load,loads,13,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelLoweringHVX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelLoweringHVX.cpp,1,['load'],['loads']
Performance,// Unaligned loads/stores are extremely inefficient.; // We need 4 uops for vst.1/vld.1 vs 1uop for vldr/vstr.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp:13,load,loads,13,interpreter/llvm-project/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp,1,['load'],['loads']
Performance,"// Unassigned virtreg is probably in the priority queue.; // RegAllocBase will erase it after dequeueing.; // Nonetheless, clear the live-range so that the debug; // dump will show the right state for that VirtReg.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RegAllocBasic.cpp:50,queue,queue,50,interpreter/llvm-project/llvm/lib/CodeGen/RegAllocBasic.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RegAllocBasic.cpp,2,['queue'],['queue']
Performance,// Unconditionally try to reduce latency.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSchedStrategy.cpp:33,latency,latency,33,interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSchedStrategy.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSchedStrategy.cpp,1,['latency'],['latency']
Performance,"// UndefValue means this is a load of a kernel input. These are uniform.; // Sometimes LDS instructions have constant pointers.; // If Ptr is null, then that means this mem operand contains a; // PseudoSourceValue like GOT.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUInstrInfo.cpp:30,load,load,30,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUInstrInfo.cpp,2,['load'],['load']
Performance,"// Under -fmodules-codegen, codegen is performed for all non-internal,; // non-always_inline functions, unless they are available elsewhere.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTWriterDecl.cpp:39,perform,performed,39,interpreter/llvm-project/clang/lib/Serialization/ASTWriterDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTWriterDecl.cpp,1,['perform'],['performed']
Performance,"// Under the large code model, we cannot assume that __morestack lives; // within 2^31 bytes of the call site, so we cannot use pc-relative; // addressing. We cannot perform the call via a temporary register,; // as the rax register may be used to store the static chain, and all; // other suitable registers may be either callee-save or used for; // parameter passing. We cannot use the stack at this point either; // because __morestack manipulates the stack directly.; //; // To avoid these issues, perform an indirect call via a read-only memory; // location containing the address.; //; // This solution is not perfect, as it assumes that the .rodata section; // is laid out within 2^31 bytes of each function body, but this seems; // to be sufficient for JIT.; // FIXME: Add retpoline support and remove the error here..",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FrameLowering.cpp:166,perform,perform,166,interpreter/llvm-project/llvm/lib/Target/X86/X86FrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FrameLowering.cpp,2,['perform'],['perform']
Performance,"// Under the standard C++ Modules, the dot is just part of the module name,; // and not a real hierarchy separator. Flatten such module names now.; //; // FIXME: Is this the right level to be performing this transformation?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/Preprocessor.cpp:192,perform,performing,192,interpreter/llvm-project/clang/lib/Lex/Preprocessor.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/Preprocessor.cpp,1,['perform'],['performing']
Performance,"// Undo the LSB-preserving shift performed by QuantizeReals",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RColumnElement.hxx:33,perform,performed,33,tree/ntuple/v7/src/RColumnElement.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RColumnElement.hxx,1,['perform'],['performed']
Performance,// Unfold the load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/TwoAddressInstructionPass.cpp:14,load,load,14,interpreter/llvm-project/llvm/lib/CodeGen/TwoAddressInstructionPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/TwoAddressInstructionPass.cpp,1,['load'],['load']
Performance,// Unfold; // x & (-1 'logical shift' y); // To; // (x 'opposite logical shift' y) 'logical shift' y; // if it is better for performance.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:125,perform,performance,125,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['perform'],['performance']
Performance,"// Unfolding code generates a load/store instruction according to the size of; // the register in the register form instruction.; // If the register's size is greater than the memory's operand size, do not; // allow unfolding.; // the unfolded load size will be based on the register size. If that’s bigger; // than the memory operand size, the unfolded load will load more memory and; // potentially cause a memory fault.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/X86FoldTablesEmitter.cpp:30,load,load,30,interpreter/llvm-project/llvm/utils/TableGen/X86FoldTablesEmitter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/X86FoldTablesEmitter.cpp,4,['load'],['load']
Performance,"// Uniform return value optimization. If all functions return the same; // constant, replace all calls with that constant.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/WholeProgramDevirt.cpp:24,optimiz,optimization,24,interpreter/llvm-project/llvm/lib/Transforms/IPO/WholeProgramDevirt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/WholeProgramDevirt.cpp,1,['optimiz'],['optimization']
Performance,// Unindexed loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:13,load,loads,13,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['loads']
Performance,"// UniqueTimestamps is a special case to improve debugging on Darwin:; //; // The Darwin linker does not link debug info into the final; // binary. Instead, it emits entries of type N_OSO in the output; // binary's symbol table, containing references to the linked-in; // object files. Using that reference, the debugger can read the; // debug data directly from the object files. Alternatively, an; // invocation of 'dsymutil' will link the debug data from the object; // files into a dSYM bundle, which can be loaded by the debugger,; // instead of the object files.; //; // For an object file, the N_OSO entries contain the absolute path; // path to the file, and the file's timestamp. For an object; // included in an archive, the path is formatted like; // ""/absolute/path/to/archive.a(member.o)"", and the timestamp is the; // archive member's timestamp, rather than the archive's timestamp.; //; // However, this doesn't always uniquely identify an object within; // an archive -- an archive file can have multiple entries with the; // same filename. (This will happen commonly if the original object; // files started in different directories.) The only way they get; // distinguished, then, is via the timestamp. But this process is; // unable to find the correct object file in the archive when there; // are two files of the same name and timestamp.; //; // Additionally, timestamp==0 is treated specially, and causes the; // timestamp to be ignored as a match criteria.; //; // That will ""usually"" work out okay when creating an archive not in; // deterministic timestamp mode, because the objects will probably; // have been created at different timestamps.; //; // To ameliorate this problem, in deterministic archive mode (which; // is the default), on Darwin we will emit a unique non-zero; // timestamp for each entry with a duplicated name. This is still; // deterministic: the only thing affecting that timestamp is the; // order of the files in the resultant archive.; //; // See al",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Object/ArchiveWriter.cpp:512,load,loaded,512,interpreter/llvm-project/llvm/lib/Object/ArchiveWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Object/ArchiveWriter.cpp,1,['load'],['loaded']
Performance,"// Unless a specific value is passed to invalidation, completely clear both; // caches.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp:80,cache,caches,80,interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,1,['cache'],['caches']
Performance,"// Unless noted otherwise, an instruction is considered; // safe for the optimization. There are a large number of; // such true-SIMD instructions (all vector math, logical,; // select, compare, etc.). However, if the instruction; // mentions a partial vector register and does not have; // special handling defined, it is not swappable.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp:73,optimiz,optimization,73,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp,1,['optimiz'],['optimization']
Performance,"// Unless the ABI requires an extra load, return a direct reference to; // the global.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FastISel.cpp:36,load,load,36,interpreter/llvm-project/llvm/lib/Target/X86/X86FastISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FastISel.cpp,1,['load'],['load']
Performance,// Unless the load is volatile or atomic.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,load,load,14,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,"// Unless this is a named pipe (in which case we can handle a mismatch),; // check that the file's size is the same as in the file entry (which may; // have come from a stat cache).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/SourceManager.cpp:174,cache,cache,174,interpreter/llvm-project/clang/lib/Basic/SourceManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/SourceManager.cpp,1,['cache'],['cache']
Performance,"// Unless we are optimizing for code size, consider the; // expensive operation first.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:17,optimiz,optimizing,17,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['optimiz'],['optimizing']
Performance,// Unless we're able to load in one instruction we must work out how to load; // the remainder.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp:24,load,load,24,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp,2,['load'],['load']
Performance,"// Unlike appending rpaths, the indexes of subsequent load commands must; // be recalculated after prepending one.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObjcopy.cpp:54,load,load,54,interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObjcopy.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObjcopy.cpp,1,['load'],['load']
Performance,"// Unlike loads, we never try to eliminate stores, so we do not check if they; // are simple and avoid value numbering them.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp:10,load,loads,10,interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,1,['load'],['loads']
Performance,"// Unlike most conventional targets (where FP points to the saved FP),; // FP points to the bottom of the fixed-size locals, so we can use positive; // offsets in load/store instructions.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyFrameLowering.cpp:163,load,load,163,interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyFrameLowering.cpp,1,['load'],['load']
Performance,"// Unnecessary backedge, should never be taken. The conditional; // jump should be optimized away later.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopUnrollRuntime.cpp:83,optimiz,optimized,83,interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopUnrollRuntime.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopUnrollRuntime.cpp,1,['optimiz'],['optimized']
Performance,// Unrelated loads are definitely safe.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:13,load,loads,13,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,1,['load'],['loads']
Performance,// Unroll small loops to hide loop backedge latency and saturate any; // parallel execution resources of an out-of-order processor. We also then; // need to clean up redundancies and loop invariant code.; // FIXME: It would be really good to use a loop-integrated instruction; // combiner for cleanup here so that the unrolling and LICM can be pipelined; // across the loop nests.; // We do UnrollAndJam in a separate LPM to ensure it happens before unroll,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp:44,latency,latency,44,interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,1,['latency'],['latency']
Performance,"// Unrolling can do several things to introduce new loops into a loop nest:; // - Full unrolling clones child loops within the current loop but then; // removes the current loop making all of the children appear to be new; // sibling loops.; //; // When a new loop appears as a sibling loop after fully unrolling,; // its nesting structure has fundamentally changed and we want to revisit; // it to reflect that.; //; // When unrolling has removed the current loop, we need to tell the; // infrastructure that it is gone.; //; // Finally, we support a debugging/testing mode where we revisit child loops; // as well. These are not expected to require further optimizations as either; // they or the loop they were cloned from have been directly visited already.; // But the debugging mode allows us to check this assumption.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopUnrollPass.cpp:659,optimiz,optimizations,659,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopUnrollPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopUnrollPass.cpp,1,['optimiz'],['optimizations']
Performance,// Unsafe Math optimization; // Remember that ci_opr1 is set if opr1 is integral,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULibCalls.cpp:15,optimiz,optimization,15,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULibCalls.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULibCalls.cpp,1,['optimiz'],['optimization']
Performance,// Unsigned gather loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.h:19,load,loads,19,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.h,2,['load'],['loads']
Performance,// Unspecified extending load is selected into zeroExtending load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsInstructionSelector.cpp:25,load,load,25,interpreter/llvm-project/llvm/lib/Target/Mips/MipsInstructionSelector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsInstructionSelector.cpp,2,['load'],['load']
Performance,"// Until we port more of the optimized selections, for now just use a vector; // insert sequence.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp:29,optimiz,optimized,29,interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp,1,['optimiz'],['optimized']
Performance,"// Unused because we overwrite LoadPage()",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RPageSourceFriends.hxx:31,Load,LoadPage,31,tree/ntuple/v7/inc/ROOT/RPageSourceFriends.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RPageSourceFriends.hxx,1,['Load'],['LoadPage']
Performance,"// Unwire cache in case it was wired",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooCacheManager.h:10,cache,cache,10,roofit/roofitcore/inc/RooCacheManager.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooCacheManager.h,1,['cache'],['cache']
Performance,"// Up to 2 vector registers can be truncated efficiently with pack or; // permute. The latter requires an immediate mask to be loaded, which; // typically gets hoisted out of a loop. TODO: return a good value for; // BB-VECTORIZER that includes the immediate loads, which we do not want; // to count for the loop vectorizer.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp:127,load,loaded,127,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp,2,['load'],"['loaded', 'loads']"
Performance,"// Update (and propagate) cached information",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TVirtualRefProxy.h:26,cache,cached,26,core/meta/inc/TVirtualRefProxy.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TVirtualRefProxy.h,1,['cache'],['cached']
Performance,// Update AVL to vl-output of the fault first load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVInsertVSETVLI.cpp:46,load,load,46,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVInsertVSETVLI.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVInsertVSETVLI.cpp,1,['load'],['load']
Performance,"// Update CodeGen to current optimization level, which might be different; // from what it had when constructed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/IncrementalParser.cpp:29,optimiz,optimization,29,interpreter/cling/lib/Interpreter/IncrementalParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/IncrementalParser.cpp,1,['optimiz'],['optimization']
Performance,// Update DILocation only in O0 since it is easy to get out of sync in; // optimizations. See https://github.com/llvm/llvm-project/pull/75104 for; // an example.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Coroutines/CoroFrame.cpp:75,optimiz,optimizations,75,interpreter/llvm-project/llvm/lib/Transforms/Coroutines/CoroFrame.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Coroutines/CoroFrame.cpp,2,['optimiz'],['optimizations']
Performance,// Update DT to redelete edges; this matches the real CFG so we can; // perform the standard update without a postview of the CFG.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSAUpdater.cpp:72,perform,perform,72,interpreter/llvm-project/llvm/lib/Analysis/MemorySSAUpdater.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSAUpdater.cpp,1,['perform'],['perform']
Performance,// Update FreshBBs to optimize the merged BB.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:22,optimiz,optimize,22,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,2,['optimiz'],['optimize']
Performance,// Update Load Chain uses as well.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp:10,Load,Load,10,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,1,['Load'],['Load']
Performance,"// Update PHI nodes in both successors. The original BB needs to be; // replaced in one successor's PHI nodes, because the branch comes now from; // the newly generated BB (NewBB). In the other successor we need to add one; // incoming edge to the PHI nodes, because both branch instructions target; // now the same successor. Depending on the original branch condition; // (and/or) we have to swap the successors (TrueDest, FalseDest), so that; // we perform the correct update for the PHI nodes.; // This doesn't change the successor order of the just created branch; // instruction (or any other instruction).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:452,perform,perform,452,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,1,['perform'],['perform']
Performance,// Update RegUses. The data structure is not optimized for this purpose;; // we must iterate through it and update each of the bit vectors.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopStrengthReduce.cpp:45,optimiz,optimized,45,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopStrengthReduce.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopStrengthReduce.cpp,1,['optimiz'],['optimized']
Performance,// Update all users to load a pointer from the global table.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/ModuleUtils.cpp:23,load,load,23,interpreter/llvm-project/llvm/lib/Transforms/Utils/ModuleUtils.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/ModuleUtils.cpp,1,['load'],['load']
Performance,// Update basic block branches by inserting explicit fallthrough branches; // when required and re-optimize branches when possible.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineBlockPlacement.cpp:99,optimiz,optimize,99,interpreter/llvm-project/llvm/lib/CodeGen/MachineBlockPlacement.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineBlockPlacement.cpp,1,['optimiz'],['optimize']
Performance,// Update cached ext-tsp score for the new chain.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/CodeLayout.cpp:10,cache,cached,10,interpreter/llvm-project/llvm/lib/Transforms/Utils/CodeLayout.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/CodeLayout.cpp,1,['cache'],['cached']
Performance,// Update cached sum.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SpillPlacement.cpp:10,cache,cached,10,interpreter/llvm-project/llvm/lib/CodeGen/SpillPlacement.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SpillPlacement.cpp,1,['cache'],['cached']
Performance,"// Update contents value caches for _intList and _sumList",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooRealIntegral.cxx:25,cache,caches,25,roofit/roofitcore/src/RooRealIntegral.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooRealIntegral.cxx,1,['cache'],['caches']
Performance,"// Update current weight cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooTreeDataStore.cxx:25,cache,cache,25,roofit/roofitcore/src/RooTreeDataStore.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooTreeDataStore.cxx,2,['cache'],['cache']
Performance,"// Update existing Phi.; // FIXME: some updates may be redundant, try to optimize and skip some.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSAUpdater.cpp:73,optimiz,optimize,73,interpreter/llvm-project/llvm/lib/Analysis/MemorySSAUpdater.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSAUpdater.cpp,1,['optimiz'],['optimize']
Performance,// Update indices of special load commands,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObject.cpp:29,load,load,29,interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObject.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObject.cpp,1,['load'],['load']
Performance,// Update internal cache.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorizationLegality.cpp:19,cache,cache,19,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorizationLegality.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorizationLegality.cpp,1,['cache'],['cache']
Performance,"// Update live-ins, register pressure, and regions caches.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSchedStrategy.cpp:51,cache,caches,51,interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSchedStrategy.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSchedStrategy.cpp,1,['cache'],['caches']
Performance,// Update load commands.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObjcopy.cpp:10,load,load,10,interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObjcopy.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/MachO/MachOObjcopy.cpp,1,['load'],['load']
Performance,// Update path cache for the new right sibling position.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/IntervalMap.h:15,cache,cache,15,interpreter/llvm-project/llvm/include/llvm/ADT/IntervalMap.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/IntervalMap.h,1,['cache'],['cache']
Performance,"// Update reference counts. Nothing happens when RefCount reaches 0, so; // we don't have to check for E == CacheEntry etc.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterferenceCache.h:108,Cache,CacheEntry,108,interpreter/llvm-project/llvm/lib/CodeGen/InterferenceCache.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterferenceCache.h,1,['Cache'],['CacheEntry']
Performance,// Update signatures and invalidate gain cache,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BalancedPartitioning.cpp:41,cache,cache,41,interpreter/llvm-project/llvm/lib/Support/BalancedPartitioning.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BalancedPartitioning.cpp,1,['cache'],['cache']
Performance,// Update the cache entry with the DwoId of the module loaded from disk.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DWARFLinker/Classic/DWARFLinker.cpp:14,cache,cache,14,interpreter/llvm-project/llvm/lib/DWARFLinker/Classic/DWARFLinker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DWARFLinker/Classic/DWARFLinker.cpp,4,"['cache', 'load']","['cache', 'loaded']"
Performance,// Update the cache of affected values for this assumption (we might be; // here because we just simplified the condition).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp:14,cache,cache,14,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp,1,['cache'],['cache']
Performance,// Update the cache.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CrossTU/CrossTranslationUnit.cpp:14,cache,cache,14,interpreter/llvm-project/clang/lib/CrossTU/CrossTranslationUnit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CrossTU/CrossTranslationUnit.cpp,3,['cache'],['cache']
Performance,// Update the destination register of the load with the destination register; // of the sign extension.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUPostLegalizerCombiner.cpp:42,load,load,42,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUPostLegalizerCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUPostLegalizerCombiner.cpp,1,['load'],['load']
Performance,// Update the immediate in the load/store instructions to add the offset.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVMergeBaseOffset.cpp:31,load,load,31,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVMergeBaseOffset.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVMergeBaseOffset.cpp,1,['load'],['load']
Performance,// Update the indent level cache size so that we can rely on it; // having the right size in adjustToUnmodifiedline.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Format/UnwrappedLineFormatter.cpp:27,cache,cache,27,interpreter/llvm-project/clang/lib/Format/UnwrappedLineFormatter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Format/UnwrappedLineFormatter.cpp,1,['cache'],['cache']
Performance,// Update the latency of chain edges between v60 vector load or store; // instructions to be 1. These instruction cannot be scheduled in the; // same packet.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonSubtarget.cpp:14,latency,latency,14,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonSubtarget.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonSubtarget.cpp,2,"['latency', 'load']","['latency', 'load']"
Performance,// Update the latency of opposite edge too.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonSubtarget.cpp:14,latency,latency,14,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonSubtarget.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonSubtarget.cpp,2,['latency'],['latency']
Performance,// Update the next highest slot available to loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/MCTargetDesc/HexagonShuffler.cpp:45,load,loads,45,interpreter/llvm-project/llvm/lib/Target/Hexagon/MCTargetDesc/HexagonShuffler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/MCTargetDesc/HexagonShuffler.cpp,1,['load'],['loads']
Performance,// Update the ready queues.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/HardwareUnits/Scheduler.h:20,queue,queues,20,interpreter/llvm-project/llvm/include/llvm/MCA/HardwareUnits/Scheduler.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/HardwareUnits/Scheduler.h,1,['queue'],['queues']
Performance,// Update the slot index to be the next item in the circular queue.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MCA/HardwareUnits/RetireControlUnit.cpp:61,queue,queue,61,interpreter/llvm-project/llvm/lib/MCA/HardwareUnits/RetireControlUnit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MCA/HardwareUnits/RetireControlUnit.cpp,1,['queue'],['queue']
Performance,"// Update the stack pointer.; // In many cases this can be done far more efficiently by pushing the; // relevant values directly to the stack. However, doing that correctly; // (in the right order, possibly skipping some empty space for undef; // values, etc) is tricky and thus left to be optimized in the future.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AVR/AVRFrameLowering.cpp:290,optimiz,optimized,290,interpreter/llvm-project/llvm/lib/Target/AVR/AVRFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AVR/AVRFrameLowering.cpp,1,['optimiz'],['optimized']
Performance,// Update the terminator added by SplitBlock to branch to the first; // LoadCmpBlock.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp:72,Load,LoadCmpBlock,72,interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,1,['Load'],['LoadCmpBlock']
Performance,// Update the token cache to match what we just did if necessary.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseTemplate.cpp:20,cache,cache,20,interpreter/llvm-project/clang/lib/Parse/ParseTemplate.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseTemplate.cpp,1,['cache'],['cache']
Performance,"// Update the work queue and the in-flight cluster list with new requests. We already hold the work queue; // mutex; // TODO(jblomer): we should ensure that clusterId is given first to the I/O thread. That is usually the; // case but it's not ensured by the code",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RClusterPool.cxx:19,queue,queue,19,tree/ntuple/v7/src/RClusterPool.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RClusterPool.cxx,2,['queue'],['queue']
Performance,"// Update to the new value. Optimize for the case when we have a single; // operand that we're changing, but handle bulk updates efficiently.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/ConstantsContext.h:28,Optimiz,Optimize,28,interpreter/llvm-project/llvm/lib/IR/ConstantsContext.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/ConstantsContext.h,1,['Optimiz'],['Optimize']
Performance,// Update use with load allocas and add store for gc_relocated.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp:19,load,load,19,interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,1,['load'],['load']
Performance,// Update uses of the loaded Value while preserving old chains.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:22,load,loaded,22,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,1,['load'],['loaded']
Performance,"// Updated caller/callee profiles only when requested. For sample loader; // inlining, the context-sensitive inlinee profile doesn't need to be; // subtracted from callee profile, and the inlined clone also doesn't need; // to be scaled based on call site count.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/InlineFunction.cpp:66,load,loader,66,interpreter/llvm-project/llvm/lib/Transforms/Utils/InlineFunction.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/InlineFunction.cpp,1,['load'],['loader']
Performance,"// Updates for visible decls can occur for other contexts than just the; // TU, and when we read those update records, the actual context may not; // be available yet, so have this pending map using the ID as a key. It; // will be realized when the context is actually loaded.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Serialization/ASTReader.h:269,load,loaded,269,interpreter/llvm-project/clang/include/clang/Serialization/ASTReader.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Serialization/ASTReader.h,1,['load'],['loaded']
Performance,"// Upgrade 32-bit loads/stores to 64-bit. These mostly differ by having; // an offset64 arg instead of offset32, but to the assembler matcher; // they're both immediates so don't get selected for.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/AsmParser/WebAssemblyAsmParser.cpp:18,load,loads,18,interpreter/llvm-project/llvm/lib/Target/WebAssembly/AsmParser/WebAssemblyAsmParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/AsmParser/WebAssemblyAsmParser.cpp,1,['load'],['loads']
Performance,// Upgrade debug info after we're done materializing all the globals and we; // have loaded all the required metadata!,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionImport.cpp:85,load,loaded,85,interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionImport.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionImport.cpp,1,['load'],['loaded']
Performance,"// Upon failure, verify that the masked-out part of the loaded value; // has been modified. If it didn't, abort the cmpxchg, since the; // masked-in part must've.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp:56,load,loaded,56,interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp,1,['load'],['loaded']
Performance,"// Upscale to compensate for the loss of precision from division, and; // perform the full division.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/APFixedPoint.cpp:74,perform,perform,74,interpreter/llvm-project/llvm/lib/Support/APFixedPoint.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/APFixedPoint.cpp,1,['perform'],['perform']
Performance,"// Usable locations are valid with non-zero line numbers. A line number of zero; // corresponds to optimized code that doesn't have a distinct source location.; // In this case, we try to use the previous or next source location depending on; // the context.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/CodeViewDebug.cpp:99,optimiz,optimized,99,interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/CodeViewDebug.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/CodeViewDebug.cpp,1,['optimiz'],['optimized']
Performance,"// Use 'unsigned add with overflow' to optimize an unsigned saturating add.; // This is conservatively limited to pre-legal-operations to give targets; // a chance to reverse the transform if they want to do that. Also, it is; // unlikely that the pattern would be formed late, so it's probably not; // worth going through the other checks.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:39,optimiz,optimize,39,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['optimiz'],['optimize']
Performance,// Use 16-bit registers for small load-stores as it's the; // smallest general purpose register size supported by NVPTX.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:34,load,load-stores,34,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,1,['load'],['load-stores']
Performance,// Use BT if the immediate can't be encoded in a TEST instruction or we; // are optimizing for size and the immedaite won't fit in a byte.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:80,optimiz,optimizing,80,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['optimiz'],['optimizing']
Performance,// Use CachedFunctionScope to avoid allocating memory when possible.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/Sema.cpp:7,Cache,CachedFunctionScope,7,interpreter/llvm-project/clang/lib/Sema/Sema.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/Sema.cpp,1,['Cache'],['CachedFunctionScope']
Performance,// Use DW_AT_call_all_calls to express that call site entries are present; // for both tail and non-tail calls. Don't use DW_AT_call_all_source_calls; // because one of its requirements is not met: call site entries for; // optimized-out calls are elided.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfDebug.cpp:224,optimiz,optimized-out,224,interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfDebug.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfDebug.cpp,1,['optimiz'],['optimized-out']
Performance,// Use FPR64 for s64 loads on rv32.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/GISel/RISCVRegisterBankInfo.cpp:21,load,loads,21,interpreter/llvm-project/llvm/lib/Target/RISCV/GISel/RISCVRegisterBankInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/GISel/RISCVRegisterBankInfo.cpp,1,['load'],['loads']
Performance,"// Use Intrinsic::spv_extractelt so dynamic vs static extraction is; // handled later: extr = spv_extractelt LoadedVector, IndexRegister.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SPIRV/SPIRVBuiltins.cpp:109,Load,LoadedVector,109,interpreter/llvm-project/llvm/lib/Target/SPIRV/SPIRVBuiltins.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SPIRV/SPIRVBuiltins.cpp,1,['Load'],['LoadedVector']
Performance,// Use LARL to load the address of the constant pool entry.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:15,load,load,15,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,1,['load'],['load']
Performance,// Use LARL to load the address of the table.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:15,load,load,15,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,1,['load'],['load']
Performance,// Use LE to convert equal sized loads to zext.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:33,load,loads,33,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['loads']
Performance,// Use OS facilities to search the current binary and all loaded libs.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/DynamicLibrary.cpp:58,load,loaded,58,interpreter/llvm-project/llvm/lib/Support/DynamicLibrary.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/DynamicLibrary.cpp,1,['load'],['loaded']
Performance,"// Use PC-relative addressing to access the GOT for this TLS symbol, then; // load the address from the GOT and add the thread pointer. This generates; // the pattern (PseudoLA_TLS_IE sym), which expands to; // (ld (auipc %tls_ie_pcrel_hi(sym)) %pcrel_lo(auipc)).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:78,load,load,78,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['load'],['load']
Performance,"// Use PC-relative addressing to access the GOT for this symbol, then load; // the address from the GOT. This generates the pattern (PseudoLGA sym),; // which expands to (ld (addi (auipc %got_pcrel_hi(sym)) %pcrel_lo(auipc))).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:70,load,load,70,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['load'],['load']
Performance,"// Use PC-relative addressing to access the GOT for this symbol, then; // load the address from the GOT. This generates the pattern (PseudoLGA; // sym), which expands to (ld (addi (auipc %got_pcrel_hi(sym)); // %pcrel_lo(auipc))).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/GISel/RISCVInstructionSelector.cpp:74,load,load,74,interpreter/llvm-project/llvm/lib/Target/RISCV/GISel/RISCVInstructionSelector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/GISel/RISCVInstructionSelector.cpp,1,['load'],['load']
Performance,"// Use STOCOpcode if possible. We could use different store patterns in; // order to avoid matching the index register, but the performance trade-offs; // might be more complicated in that case.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:128,perform,performance,128,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,1,['perform'],['performance']
Performance,"// Use SelectionDAG SSP handling, since there isn't an IR guard.; //; // This is more or less weird, since we optionally output whether we; // should perform a SelectionDAG SP here. The reason is that it's strictly; // defined as !TLI->getIRStackGuard(B), where getIRStackGuard is also; // mutating. There is no way to get this bit without mutating the IR, so; // getting this bit has to happen in this right time.; //; // We could have define a new function TLI::supportsSelectionDAGSP(), but that; // will put more burden on the backends' overriding work, especially when it; // actually conveys the same information getIRStackGuard() already gives.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/StackProtector.cpp:150,perform,perform,150,interpreter/llvm-project/llvm/lib/CodeGen/StackProtector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/StackProtector.cpp,1,['perform'],['perform']
Performance,// Use a constant pool to load the index vector for TBL.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp:26,load,load,26,interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp,1,['load'],['load']
Performance,// Use a load effective address to get the current instruction pointer and put; // it into the result register.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/X86/Target.cpp:9,load,load,9,interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/X86/Target.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/X86/Target.cpp,1,['load'],['load']
Performance,// Use a priority queue keyed on dominator tree level so that inserted nodes; // are handled from the bottom of the dominator tree upwards. We also augment; // the level with a DFS number to ensure that the blocks are ordered in a; // deterministic way.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Support/GenericIteratedDominanceFrontier.h:18,queue,queue,18,interpreter/llvm-project/llvm/include/llvm/Support/GenericIteratedDominanceFrontier.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Support/GenericIteratedDominanceFrontier.h,1,['queue'],['queue']
Performance,// Use a scope to keep the lifetime of the CachedKernel short.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp:43,Cache,CachedKernel,43,interpreter/llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp,1,['Cache'],['CachedKernel']
Performance,"// Use a smaller load with the desired size, possibly with updated offset.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp:17,load,load,17,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp,1,['load'],['load']
Performance,// Use a special diagnostic for loads from property references.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp:32,load,loads,32,interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp,1,['load'],['loads']
Performance,// Use a splat (which might be selected as a load splat),MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp:45,load,load,45,interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp,1,['load'],['load']
Performance,// Use a target machine opcode to prevent further DAGCombine; // optimizations that may separate the arithmetic operations; // from the setcc node.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/M68k/M68kISelLowering.cpp:65,optimiz,optimizations,65,interpreter/llvm-project/llvm/lib/Target/M68k/M68kISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/M68k/M68kISelLowering.cpp,1,['optimiz'],['optimizations']
Performance,// Use a temporary cursor so that we don't mess up the main Stream cursor or; // the lazy loading IndexCursor (which holds the necessary abbrev ids).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Reader/MetadataLoader.cpp:90,load,loading,90,interpreter/llvm-project/llvm/lib/Bitcode/Reader/MetadataLoader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Reader/MetadataLoader.cpp,1,['load'],['loading']
Performance,"// Use a worklist to perform a depth-first search of OldSucc's successors.; // NOTE: We do not need a visited list since any blocks we have already; // visited will have had their overdefined markers cleared already, and we; // thus won't loop to their successors.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LazyValueInfo.cpp:21,perform,perform,21,interpreter/llvm-project/llvm/lib/Analysis/LazyValueInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LazyValueInfo.cpp,1,['perform'],['perform']
Performance,"// Use an anonymous struct to pool the strings.; // TODO: This pass uses a single anonymous struct for all of the pooled; // entries. This may cause a performance issue in the situation where; // computing the offset requires two instructions (addis, addi). For the; // future we may want to split this into multiple structs.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMergeStringPool.cpp:151,perform,performance,151,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMergeStringPool.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMergeStringPool.cpp,1,['perform'],['performance']
Performance,// Use an f64/i64 load and a scalar_to_vector for v2f32/v2i32 loads. This; // avoids scalarizing in 32-bit mode. In 64-bit mode this avoids a int->fp; // cast since type legalization will try to use an i64 load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:18,load,load,18,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,3,['load'],"['load', 'loads']"
Performance,// Use an integer load+store unless we can find something better.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp:18,load,load,18,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp,1,['load'],['load']
Performance,"// Use any cached events first",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAcceptReject.cxx:11,cache,cached,11,roofit/roofitcore/src/RooAcceptReject.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAcceptReject.cxx,1,['cache'],['cached']
Performance,"// Use assert, so that this line (slow because of the TClassEdit) is completely; // removed in optimized code.; //assert(TestBit(kLoading) || !TClassEdit::IsSTLCont(fName) || fCollectionProxy || 0 == ""The TClass for the STL collection has no collection proxy!"");",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:95,optimiz,optimized,95,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,1,['optimiz'],['optimized']
Performance,// Use cached result for invariant load only if there is no dependency for non; // invariant load. In this case invariant load can not have any dependency as; // well.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp:7,cache,cached,7,interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,4,"['cache', 'load']","['cached', 'load']"
Performance,// Use callback to load if this is not an optimizable case for origin; // tracking.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp:19,load,load,19,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp,2,"['load', 'optimiz']","['load', 'optimizable']"
Performance,// Use is on an EH pad phi. Leave it alone; we'll insert loads and; // stores for it separately.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/WinEHPrepare.cpp:57,load,loads,57,interpreter/llvm-project/llvm/lib/CodeGen/WinEHPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/WinEHPrepare.cpp,1,['load'],['loads']
Performance,"// Use lazy loading, since we only care about selected global values.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-extract/llvm-extract.cpp:12,load,loading,12,interpreter/llvm-project/llvm/tools/llvm-extract/llvm-extract.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-extract/llvm-extract.cpp,1,['load'],['loading']
Performance,// Use load(literal) for tiny code model.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp,1,['load'],['load']
Performance,// Use load/store pair instructions when possible.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetMachine.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetMachine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetMachine.cpp,1,['load'],['load']
Performance,// Use memcpy for PODs (std::uninitialized_copy optimizes to memmove).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Analysis/Support/BumpVector.h:48,optimiz,optimizes,48,interpreter/llvm-project/clang/include/clang/Analysis/Support/BumpVector.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Analysis/Support/BumpVector.h,2,['optimiz'],['optimizes']
Performance,"// Use memcpy for PODs iterated by pointers (which includes SmallVector; // iterators): std::uninitialized_copy optimizes to memmove, but we can; // use memcpy here. Note that I and E are iterators and thus might be; // invalid for memcpy if they are equal.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/SmallVector.h:112,optimiz,optimizes,112,interpreter/llvm-project/llvm/include/llvm/ADT/SmallVector.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/SmallVector.h,1,['optimiz'],['optimizes']
Performance,"// Use memcpy for PODs iterated by pointers (which includes SmallVector; // iterators): std::uninitialized_copy optimizes to memmove, but we can; // use memcpy here. Note that I and E are iterators and thus might be; // invalid for memcpy if they are equal.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/vecops/inc/ROOT/RVec.hxx:112,optimiz,optimizes,112,math/vecops/inc/ROOT/RVec.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/inc/ROOT/RVec.hxx,1,['optimiz'],['optimizes']
Performance,// Use normal unroll factors even if the rest of the code is optimized for; // size.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Frontend/OpenMP/OMPIRBuilder.cpp:61,optimiz,optimized,61,interpreter/llvm-project/llvm/lib/Frontend/OpenMP/OMPIRBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Frontend/OpenMP/OMPIRBuilder.cpp,1,['optimiz'],['optimized']
Performance,"// Use own name as base name for caches",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooAbsSelfCachedReal.h:33,cache,caches,33,roofit/roofitcore/inc/RooAbsSelfCachedReal.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooAbsSelfCachedReal.h,1,['cache'],['caches']
Performance,"// Use performance counter (system dependent support) if possible",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/src/TGLStopwatch.cxx:7,perform,performance,7,graf3d/gl/src/TGLStopwatch.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/src/TGLStopwatch.cxx,1,['perform'],['performance']
Performance,// Use push / pop for slot sized adjustments as a size optimization. We; // need to find a dead register when using pop.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FrameLowering.cpp:55,optimiz,optimization,55,interpreter/llvm-project/llvm/lib/Target/X86/X86FrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FrameLowering.cpp,1,['optimiz'],['optimization']
Performance,"// Use push for slot sized adjustments as a size optimization,; // like emitSPUpdate does when not probing.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FrameLowering.cpp:49,optimiz,optimization,49,interpreter/llvm-project/llvm/lib/Target/X86/X86FrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FrameLowering.cpp,1,['optimiz'],['optimization']
Performance,"// Use push_back with a copy in case Args has an internal reference,; // side-stepping reference invalidation problems without losing the realloc; // optimization.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/SmallVector.h:150,optimiz,optimization,150,interpreter/llvm-project/llvm/include/llvm/ADT/SmallVector.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/SmallVector.h,1,['optimiz'],['optimization']
Performance,"// Use quadratic probing, it has fewer clumping artifacts than linear; // probing and has good cache behavior in the common case.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/StringMap.cpp:95,cache,cache,95,interpreter/llvm-project/llvm/lib/Support/StringMap.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/StringMap.cpp,2,['cache'],['cache']
Performance,// Use register %o7 to load the lower 32 bits.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Sparc/SparcAsmPrinter.cpp:23,load,load,23,interpreter/llvm-project/llvm/lib/Target/Sparc/SparcAsmPrinter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Sparc/SparcAsmPrinter.cpp,1,['load'],['load']
Performance,"// Use return type. If it's segment load, return type is a struct.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:36,load,load,36,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['load'],['load']
Performance,// Use set for scalable 'contains' check.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/VectorUtils.cpp:15,scalab,scalable,15,interpreter/llvm-project/llvm/lib/Analysis/VectorUtils.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/VectorUtils.cpp,1,['scalab'],['scalable']
Performance,"// Use the ID of masked load as the ""matching id"". This will; // prevent matching non-masked loads/stores with masked ones; // (which could be done), but at the moment, the code here; // does not support matching intrinsics with non-intrinsics,; // so keep the MatchingIds specific to masked instructions; // for now (TODO).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp:24,load,load,24,interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,2,['load'],"['load', 'loads']"
Performance,"// Use the Module pointer as the key into the cache. This is a; // nullptr if the ""Module"" is a PCH, which is safe because we don't; // support chained PCH debug info, so there can only be a single PCH.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp:46,cache,cache,46,interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp,1,['cache'],['cache']
Performance,// Use the YAML path from -ivfsoverlay to compute the dir to be prefixed; // to each 'external-contents' path.; //; // Example:; // -ivfsoverlay dummy.cache/vfs/vfs.yaml; // yields:; // FS->OverlayFileDir => /<absolute_path_to>/dummy.cache/vfs; //,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/VirtualFileSystem.cpp:151,cache,cache,151,interpreter/llvm-project/llvm/lib/Support/VirtualFileSystem.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/VirtualFileSystem.cpp,2,['cache'],['cache']
Performance,"// Use the approach from ""x86-64 Linker Optimizations"" from the TLS spec; // to replace the GOTTPOFF relocation with a TPOFF relocation. The spec; // only mentions one optimization even though there are two different; // code sequences for the Initial Exec TLS Model. We match the code to; // find out which one was used.; // A possible TLS code sequence and its replacement",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp:40,Optimiz,Optimizations,40,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp,2,"['Optimiz', 'optimiz']","['Optimizations', 'optimization']"
Performance,"// Use the base destructor variant in place of the complete destructor variant; // if the class has no virtual bases. This effectively implements some of the; // -mconstructor-aliases optimization, but as part of the MS C++ ABI.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/MicrosoftCXXABI.cpp:184,optimiz,optimization,184,interpreter/llvm-project/clang/lib/CodeGen/MicrosoftCXXABI.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/MicrosoftCXXABI.cpp,1,['optimiz'],['optimization']
Performance,// Use the cached hash value for insertion instead of recalculating it.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ProfileData/SampleProfReader.cpp:11,cache,cached,11,interpreter/llvm-project/llvm/lib/ProfileData/SampleProfReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ProfileData/SampleProfReader.cpp,1,['cache'],['cached']
Performance,"// Use the cached result, which may be nullptr.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp:11,cache,cached,11,interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,1,['cache'],['cached']
Performance,"// Use the code completion consumer we were given, but adding any cached; // code-completion results.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/ASTUnit.cpp:66,cache,cached,66,interpreter/llvm-project/clang/lib/Frontend/ASTUnit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/ASTUnit.cpp,1,['cache'],['cached']
Performance,"// Use the default pass pipeline. We also have to map our optimization; // levels into one of the distinct levels used to configure the pipeline.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/BackendPasses.cpp:58,optimiz,optimization,58,interpreter/cling/lib/Interpreter/BackendPasses.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/BackendPasses.cpp,1,['optimiz'],['optimization']
Performance,// Use the dependency scanning optimized file system if requested to do so.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Tooling/DependencyScanning/DependencyScanningWorker.cpp:31,optimiz,optimized,31,interpreter/llvm-project/clang/lib/Tooling/DependencyScanning/DependencyScanningWorker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Tooling/DependencyScanning/DependencyScanningWorker.cpp,1,['optimiz'],['optimized']
Performance,// Use the generic version if we don't know that the operand will be; // suitably aligned for the optimized version.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGAtomic.cpp:98,optimiz,optimized,98,interpreter/llvm-project/clang/lib/CodeGen/CGAtomic.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGAtomic.cpp,1,['optimiz'],['optimized']
Performance,// Use the hack that clang uses to avoid SelectionDAG ruining v3 loads,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerKernelArguments.cpp:65,load,loads,65,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerKernelArguments.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerKernelArguments.cpp,1,['load'],['loads']
Performance,// Use the maximum column as stride. It must be the same with load; // stride.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:62,load,load,62,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,1,['load'],['load']
Performance,// Use the minimum alignment of the gathered loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp:45,load,loads,45,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,1,['load'],['loads']
Performance,"// Use the model's optimized generator, if one is available.; // The generator writes directly into our local 'event' since we attached it above.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooGenContext.cxx:19,optimiz,optimized,19,roofit/roofitcore/src/RooGenContext.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooGenContext.cxx,1,['optimiz'],['optimized']
Performance,"// UseInst has a MemoryDef associated in MemorySSA. It's possible for a; // MemoryDef to not write to memory, e.g. a volatile load is modeled as a; // MemoryDef.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/DeadStoreElimination.cpp:126,load,load,126,interpreter/llvm-project/llvm/lib/Transforms/Scalar/DeadStoreElimination.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/DeadStoreElimination.cpp,1,['load'],['load']
Performance,// Used by the bottleneck analysis to compute the interference; // probability for processor resources.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-mca/Views/BottleneckAnalysis.h:15,bottleneck,bottleneck,15,interpreter/llvm-project/llvm/tools/llvm-mca/Views/BottleneckAnalysis.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-mca/Views/BottleneckAnalysis.h,1,['bottleneck'],['bottleneck']
Performance,"// Used for --adjust-vma to check if address should be adjusted by the; // specified value for a given section.; // For ELF we do not adjust non-allocatable sections like debug ones,; // because they are not loadable.; // TODO: implement for other file formats.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-objdump/llvm-objdump.cpp:208,load,loadable,208,interpreter/llvm-project/llvm/tools/llvm-objdump/llvm-objdump.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-objdump/llvm-objdump.cpp,1,['load'],['loadable']
Performance,"// Used for D16: Casts the result of an instruction into the right vector,; // packs values if loads return unpacked values.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:95,load,loads,95,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,1,['load'],['loads']
Performance,"// Used to check if the reduced values used same number of times. In this; // case the compiler may produce better code. E.g. if reduced values are; // aabbccdd (8 x values), then the first node of the tree will have a node; // for 4 x abcd + shuffle <4 x abcd>, <0, 0, 1, 1, 2, 2, 3, 3>.; // Plus, the final reduction will be performed on <8 x aabbccdd>.; // Instead compiler may build <4 x abcd> tree immediately, + reduction (4; // x abcd) * 2.; // Currently it only handles add/fadd/xor. and/or/min/max do not require; // this analysis, other operations may require an extra estimation of; // the profitability.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp:327,perform,performed,327,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,1,['perform'],['performed']
Performance,"// Used to map a vector Value and associated type to its scattered form.; // The associated type is only non-null for pointer values that are ""scattered""; // when used as pointer operands to load or store.; //; // We use std::map because we want iterators to persist across insertion and; // because the values are relatively large.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/Scalarizer.cpp:191,load,load,191,interpreter/llvm-project/llvm/lib/Transforms/Scalar/Scalarizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/Scalarizer.cpp,1,['load'],['load']
Performance,// Used to tune the minimum number of execution counts needed in the predecessor; // block to the cold edge. ie. confidence interval.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/PartialInlining.cpp:11,tune,tune,11,interpreter/llvm-project/llvm/lib/Transforms/IPO/PartialInlining.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/PartialInlining.cpp,1,['tune'],['tune']
Performance,"// User of the GOT-indirect address.; // For example, the load that will get the relocation as follows:; // .reloc .Lpcrel1-8,R_PPC64_PCREL_OPT,.-(.Lpcrel1-8); // lwa 3, 4(3)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/MCTargetDesc/PPCELFStreamer.cpp:58,load,load,58,interpreter/llvm-project/llvm/lib/Target/PowerPC/MCTargetDesc/PPCELFStreamer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/MCTargetDesc/PPCELFStreamer.cpp,1,['load'],['load']
Performance,"// UserI can't fold two loads, so in that case return 0 cost only; // half of the time.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp:24,load,loads,24,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp,1,['load'],['loads']
Performance,// Users of the old loads now use the new load's chain. We know the; // old-load value is dead now.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:20,load,loads,20,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,3,['load'],"['load', 'loads']"
Performance,// Users of the select now use the result of the load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:49,load,load,49,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,// Uses IncludedLocMap to retrieve/cache the decomposed loc.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/SourceManager.cpp:35,cache,cache,35,interpreter/llvm-project/clang/lib/Basic/SourceManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/SourceManager.cpp,1,['cache'],['cache']
Performance,// Using CAS for an atomic load has a better chance of succeeding under high; // contention situations. So use it if available.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:27,load,load,27,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['load'],['load']
Performance,"// Using Seen as a visited set, perform a BFS for all reaching defs.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveRangeCalc.cpp:32,perform,perform,32,interpreter/llvm-project/llvm/lib/CodeGen/LiveRangeCalc.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveRangeCalc.cpp,1,['perform'],['perform']
Performance,// Using element-wise loads and stores for widening operations is not; // supported for scalable vectors,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp:22,load,loads,22,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorTypes.cpp,2,"['load', 'scalab']","['loads', 'scalable']"
Performance,"// Using the full decoder string as the key value here is a bit; // heavyweight, but is effective. If the string comparisons become a; // performance concern, we can implement a mangling of the predicate; // data easily enough with a map back to the actual string. That's; // overkill for now, though.; // Make sure the predicate is in the table.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/DecoderEmitter.cpp:138,perform,performance,138,interpreter/llvm-project/llvm/utils/TableGen/DecoderEmitter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/DecoderEmitter.cpp,1,['perform'],['performance']
Performance,"// Using the full predicate string as the key value here is a bit; // heavyweight, but is effective. If the string comparisons become a; // performance concern, we can implement a mangling of the predicate; // data easily enough with a map back to the actual string. That's; // overkill for now, though.; // Make sure the predicate is in the table.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/DecoderEmitter.cpp:140,perform,performance,140,interpreter/llvm-project/llvm/utils/TableGen/DecoderEmitter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/DecoderEmitter.cpp,1,['perform'],['performance']
Performance,"// Using the identity !(x ^ y) == (!x ^ y) == (x ^ !y), we can; // invert either source and then perform the XOR. If either source is a; // scalar register, then we can leave the inversion on the scalar unit to; // achieve a better distribution of scalar and vector instructions.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp:97,perform,perform,97,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp,1,['perform'],['perform']
Performance,"// Using the machine combiner in this way is potentially expensive, so; // restrict to when aggressive optimizations are desired.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp:103,optimiz,optimizations,103,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,1,['optimiz'],['optimizations']
Performance,"// Using the versions of createTemporaryFile() and; // createUniqueFile() with a file descriptor guarantees; // that we would never get a race condition in a multi-threaded setting; // (i.e., multiple threads getting the same temporary path).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/PrecompiledPreamble.cpp:138,race condition,race condition,138,interpreter/llvm-project/clang/lib/Frontend/PrecompiledPreamble.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/PrecompiledPreamble.cpp,2,"['multi-thread', 'race condition']","['multi-threaded', 'race condition']"
Performance,"// Usual destructor.; // Idea: the configuration ownership might be moved to a single list so that; // we can shared them between the optimized and non-optimized list of actions.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/inc/TStreamerInfoActions.h:134,optimiz,optimized,134,io/io/inc/TStreamerInfoActions.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/inc/TStreamerInfoActions.h,2,['optimiz'],['optimized']
Performance,"// UsualArithmeticConversions - performs the UsualUnaryConversions on it's; // operands and then handles various conversions that are common to binary; // operators (C99 6.3.1.8). If both operands aren't arithmetic, this; // routine returns the first non-arithmetic type found. The client is; // responsible for emitting appropriate error diagnostics.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Sema/Sema.h:32,perform,performs,32,interpreter/llvm-project/clang/include/clang/Sema/Sema.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Sema/Sema.h,1,['perform'],['performs']
Performance,"// Usually chunks are not created implicitly, but rather loaded from YAML.; // This flag is used to signal whether this is the case or not.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ObjectYAML/ELFYAML.h:57,load,loaded,57,interpreter/llvm-project/llvm/include/llvm/ObjectYAML/ELFYAML.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ObjectYAML/ELFYAML.h,1,['load'],['loaded']
Performance,"// VE doesn't have fp128 load/store, so expand them in custom lower.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/VE/VEISelLowering.cpp:25,load,load,25,interpreter/llvm-project/llvm/lib/Target/VE/VEISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/VE/VEISelLowering.cpp,1,['load'],['load']
Performance,// VE loads HiReg from 8(addr) and LoReg from 0(addr),MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/VE/VERegisterInfo.cpp:6,load,loads,6,interpreter/llvm-project/llvm/lib/Target/VE/VERegisterInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/VE/VERegisterInfo.cpp,1,['load'],['loads']
Performance,// VE target does not yet support tail call optimization.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/VE/VEISelLowering.cpp:44,optimiz,optimization,44,interpreter/llvm-project/llvm/lib/Target/VE/VEISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/VE/VEISelLowering.cpp,1,['optimiz'],['optimization']
Performance,// VECTOR LOAD (RIGHTMOST) WITH LENGTH with a length operand of 15; // or larger is simply a vector load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:10,LOAD,LOAD,10,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,2,"['LOAD', 'load']","['LOAD', 'load']"
Performance,"// VECTOR [numelts, eltty] or; // [numelts, eltty, scalable]",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Writer/BitcodeWriter.cpp:51,scalab,scalable,51,interpreter/llvm-project/llvm/lib/Bitcode/Writer/BitcodeWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Writer/BitcodeWriter.cpp,1,['scalab'],['scalable']
Performance,"// VECTOR: [numelts, eltty] or; // [numelts, eltty, scalable]",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Reader/BitcodeReader.cpp:52,scalab,scalable,52,interpreter/llvm-project/llvm/lib/Bitcode/Reader/BitcodeReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Reader/BitcodeReader.cpp,1,['scalab'],['scalable']
Performance,// VECTOR_SHUFFLE doesn't support a scalable mask so use a dedicated node.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp:36,scalab,scalable,36,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,1,['scalab'],['scalable']
Performance,"// VLDM[SD]_UPD, VSTM[SD]_UPD; // (There are no base-updating versions of VLDR/VSTR instructions, but the; // updating load/store-multiple instructions can be used with only one; // register.)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp:119,load,load,119,interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp,1,['load'],['load']
Performance,// VMem load vgpr def,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInsertWaitcnts.cpp:8,load,load,8,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInsertWaitcnts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInsertWaitcnts.cpp,1,['load'],['load']
Performance,// VP Memory operations can be replaced by either the chain (stores) or the; // chain + undef (loads).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:95,load,loads,95,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['loads']
Performance,// VP doesn't support extending loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:32,load,loads,32,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['load'],['loads']
Performance,// VPERMQ/VPERMPD can perform the cross-lane shuffle directly.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:22,perform,perform,22,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['perform'],['perform']
Performance,"// VPHeaderPHIRecipes must be kept in the phi section of HeaderVPBB. In; // the following cases, VPHeaderPHIRecipes may be created after non-phi; // recipes and need to be moved to the phi section of HeaderVPBB:; // * tail-folding (non-phi recipes computing the header mask are; // introduced earlier than regular header phi recipes, and should appear; // after them); // * Optimizing truncates to VPWidenIntOrFpInductionRecipe.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:374,Optimiz,Optimizing,374,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,1,['Optimiz'],['Optimizing']
Performance,"// VPPERM reverses the bits of a byte with the permute Op (2 << 5), and we; // perform the BSWAP in the shuffle.; // Its best to shuffle using the second operand as this will implicitly allow; // memory folding for multiple vectors.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:79,perform,perform,79,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['perform'],['perform']
Performance,// VSX has 32b/64b load instructions. Legalization can handle loading of; // 32b/64b to VSR correctly and cheaply. But BaseT::getMemoryOpCost and; // PPCTargetLowering can't compute the cost appropriately. So here we; // explicitly check this case. There are also corresponding store; // instructions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp:19,load,load,19,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,2,['load'],"['load', 'loading']"
Performance,// VSX only provides an indexed load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCFastISel.cpp:32,load,load,32,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCFastISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCFastISel.cpp,2,['load'],['load']
Performance,// VZEXT_LOAD - consecutive 32/64-bit load/undefs followed by zeros/undefs.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,load,load,38,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,// Validate the image format.; //; // Load the image starts.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Object/MachOObjectFile.cpp:38,Load,Load,38,interpreter/llvm-project/llvm/lib/Object/MachOObjectFile.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Object/MachOObjectFile.cpp,1,['Load'],['Load']
Performance,// Value for llvm.loop.vectorize.scalable.enable,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGLoopInfo.h:33,scalab,scalable,33,interpreter/llvm-project/clang/lib/CodeGen/CGLoopInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGLoopInfo.h,1,['scalab'],['scalable']
Performance,"// Value is a value that has been passed to us in the location described by VA; // (and so has type VA.getLocVT()). Convert Value to VA.getValVT(), chaining; // any loads onto Chain.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:165,load,loads,165,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,1,['load'],['loads']
Performance,// Value loaded - nothing to do here.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/Interp/ByteCodeExprGen.cpp:9,load,loaded,9,interpreter/llvm-project/clang/lib/AST/Interp/ByteCodeExprGen.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/Interp/ByteCodeExprGen.cpp,1,['load'],['loaded']
Performance,"// Value number a single instruction, symbolically evaluating, performing; // congruence finding, and updating mappings.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp:63,perform,performing,63,interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,1,['perform'],['performing']
Performance,// Values depend on loads if the pointers are must aliased. This means; // that a load depends on another must aliased load from the same value.; // One exception is atomic loads: a value can depend on an atomic load that; // it does not alias with when this atomic load indicates that another; // thread may be accessing the location.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp:20,load,loads,20,interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,6,['load'],"['load', 'loads']"
Performance,// Various optimizations for (in)equality comparisons.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InstructionSimplify.cpp:11,optimiz,optimizations,11,interpreter/llvm-project/llvm/lib/Analysis/InstructionSimplify.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InstructionSimplify.cpp,1,['optimiz'],['optimizations']
Performance,"// Various optimizations may have happened to the value during codegen,; // recorded in the value substitution table. Apply any substitutions to; // the instruction / operand number in this DBG_INSTR_REF, and collect; // any subregister extractions performed during optimization.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.cpp:11,optimiz,optimizations,11,interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.cpp,3,"['optimiz', 'perform']","['optimization', 'optimizations', 'performed']"
Performance,// Various statistics we track for performance analysis.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Lex/Preprocessor.h:35,perform,performance,35,interpreter/llvm-project/clang/include/clang/Lex/Preprocessor.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Lex/Preprocessor.h,1,['perform'],['performance']
Performance,// Vec load or compute.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorPrint.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorPrint.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorPrint.cpp,1,['load'],['load']
Performance,"// VecTy for interleave memop is <VF*Factor x Elt>.; // So, for VF=4, Interleave Factor = 3, Element type = i32 we have; // VecTy = <12 x i32>.; // Calculate the number of memory operations (NumOfMemOps), required; // for load/store the VecTy.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:222,load,load,222,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,1,['load'],['load']
Performance,// VecVT should be scalable and memory VT should match the element type.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:19,scalab,scalable,19,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['scalab'],['scalable']
Performance,"// Vector arguments to VaArg functions are passed both on the stack, and; // in any available GPRs. Load the value from the stack and add the GPRs; // as live ins.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:100,Load,Load,100,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['Load'],['Load']
Performance,"// Vector builtins. Note that most vector builtins are mapped automatically; // to target-specific LLVM intrinsics. The ones handled specially here can; // be represented via standard LLVM IR, which is preferable to enable common; // LLVM optimizations.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:239,optimiz,optimizations,239,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,1,['optimiz'],['optimizations']
Performance,"// Vector element insert/extract with Altivec is very expensive,; // because they require store and reload with the attendant; // processor stall for load-hit-store. Until VSX is available,; // these need to be estimated as very costly.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp:150,load,load-hit-store,150,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,1,['load'],['load-hit-store']
Performance,"// Vector shifts: check for immediate versions and lower them.; // Note: This is done during DAG combining instead of DAG legalizing because; // the build_vectors for 64-bit vector element shift counts are generally; // not legal, and it is hard to see their values after they get legalized to; // loads from a constant pool.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:298,load,loads,298,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['load'],['loads']
Performance,// Vector splat address w/known mask -> scalar load; // Fold the gather to load the source vector first lane; // because it is reloading the same value each time,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp:47,load,load,47,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp,2,['load'],['load']
Performance,// Vectorization for masked interleaved accesses is only enabled for scalable; // VF.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp:69,scalab,scalable,69,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,1,['scalab'],['scalable']
Performance,// Vectorize the index computations of getelementptr instructions. This; // is primarily intended to catch gather-like idioms ending at; // non-consecutive loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp:156,load,loads,156,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,1,['load'],['loads']
Performance,// Vectorize the interleaved load group.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:29,load,load,29,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,1,['load'],['load']
Performance,// Vectorizing non-consecutive loads with `llvm.masked.gather`.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp:31,load,loads,31,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,2,['load'],['loads']
Performance,// Verify FoldCache/FoldCacheUser caches.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp:34,cache,caches,34,interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,1,['cache'],['caches']
Performance,// Verify all the cached regunit intervals.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineVerifier.cpp:18,cache,cached,18,interpreter/llvm-project/llvm/lib/CodeGen/MachineVerifier.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineVerifier.cpp,1,['cache'],['cached']
Performance,// Verify if both loads have same base pointers and load sizes are same.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp:18,load,loads,18,interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp,2,['load'],"['load', 'loads']"
Performance,// Verify if shift amount and load index aligns and verifies that loads; // are consecutive.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp:30,load,load,30,interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/AggressiveInstCombine/AggressiveInstCombine.cpp,2,['load'],"['load', 'loads']"
Performance,// Verify integrity of the block disposition cache.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp:45,cache,cache,45,interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,1,['cache'],['cache']
Performance,// Verify intergity of loop disposition cache.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp:40,cache,cache,40,interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,1,['cache'],['cache']
Performance,// Verify segments are loaded consecutively.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/PerfReader.cpp:23,load,loaded,23,interpreter/llvm-project/llvm/tools/llvm-profgen/PerfReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-profgen/PerfReader.cpp,1,['load'],['loaded']
Performance,// Verify that ConstantMultipleCache computations are correct. We check that; // cached multiples and recomputed multiples are multiples of each other to; // verify correctness. It is possible that a recomputed multiple is different; // from the cached multiple due to strengthened no wrap flags or changes in; // KnownBits computations.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp:81,cache,cached,81,interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,2,['cache'],['cached']
Performance,"// Verify that each user of the global is an inrange getelementptr constant.; // From this it follows that any loads from or stores to that global must use; // a pointer derived from an inrange getelementptr constant, which is; // sufficient to allow us to apply the splitting transform.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalSplit.cpp:111,load,loads,111,interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalSplit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalSplit.cpp,1,['load'],['loads']
Performance,"// Verify that for each store expression in the expression to class mapping,; // only the latest appears, and multiple ones do not appear.; // Because loads do not use the stored value when doing equality with stores,; // if we don't erase the old store expressions from the table, a load can find; // a no-longer valid StoreExpression.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp:151,load,loads,151,interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,2,['load'],"['load', 'loads']"
Performance,// Verify that pushes and pops are performed in LIFO order.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyRegStackify.cpp:35,perform,performed,35,interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyRegStackify.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyRegStackify.cpp,1,['perform'],['performed']
Performance,"// Verify that the binned likelihood optimization works also when fitting a; // single-channel RooRealSumPdf or RooProdPdf.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/test/testTestStatistics.cxx:37,optimiz,optimization,37,roofit/roofitcore/test/testTestStatistics.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/test/testTestStatistics.cxx,1,['optimiz'],['optimization']
Performance,// Verify that the cached type info is for both A and its users is still; // accurate by comparing it to freshly computed types.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlanTransforms.cpp:19,cache,cached,19,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlanTransforms.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlanTransforms.cpp,1,['cache'],['cached']
Performance,"// Verify that the copied-from memory doesn't change in between the two; // transfers. For example, in:; // memcpy(a <- b); // *b = 42;; // memcpy(c <- a); // It would be invalid to transform the second memcpy into memcpy(c <- b).; //; // TODO: If the code between M and MDep is transparent to the destination ""c"",; // then we could still perform the xform by moving M up to the first memcpy.; // TODO: It would be sufficient to check the MDep source up to the memcpy; // size of M, rather than MDep.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp:339,perform,perform,339,interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,1,['perform'],['perform']
Performance,// Verify that the initializer is simple enough for us to handle. We are; // only allowed to optimize the initializer if it is unique.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/CtorUtils.cpp:93,optimiz,optimize,93,interpreter/llvm-project/llvm/lib/Transforms/Utils/CtorUtils.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/CtorUtils.cpp,1,['optimiz'],['optimize']
Performance,// Verify that the relocation points to one of the expected load / store; // instructions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldMachOAArch64.h:60,load,load,60,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldMachOAArch64.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldMachOAArch64.h,2,['load'],['load']
Performance,// Verify that the relocation points to one of the expected load / store; // or add / sub instructions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldMachOAArch64.h:60,load,load,60,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldMachOAArch64.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldMachOAArch64.h,2,['load'],['load']
Performance,// Verify that we are actually reducing a load width here.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:42,load,load,42,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,// Verify that we set the queues up correctly.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/OptimizedStructLayout.cpp:26,queue,queues,26,interpreter/llvm-project/llvm/lib/Support/OptimizedStructLayout.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/OptimizedStructLayout.cpp,1,['queue'],['queues']
Performance,"// Version 0 is special, it means the currently loaded version.; // We need to set it at the beginning to be able to guess it correctly.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:48,load,loaded,48,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,1,['load'],['loaded']
Performance,"// Very detailed queue dump, to be used with higher verbosity levels.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/VLIWMachineScheduler.cpp:17,queue,queue,17,interpreter/llvm-project/llvm/lib/CodeGen/VLIWMachineScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/VLIWMachineScheduler.cpp,1,['queue'],['queue']
Performance,// Visit \p SI instruction and perform tasks according to visit mode.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/PGOInstrumentation.cpp:31,perform,perform,31,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/PGOInstrumentation.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/PGOInstrumentation.cpp,1,['perform'],['perform']
Performance,"// Visit all instructions in the given basic block and try to simplify; // it. We don't change the actual IR, just count optimization; // opportunities.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopUnrollPass.cpp:121,optimiz,optimization,121,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopUnrollPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopUnrollPass.cpp,1,['optimiz'],['optimization']
Performance,"// Visit all reached defs, and add them to the queue. These defs may; // override some of the uses collected here, but that will be handled; // later.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RDFLiveness.cpp:47,queue,queue,47,interpreter/llvm-project/llvm/lib/CodeGen/RDFLiveness.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RDFLiveness.cpp,1,['queue'],['queue']
Performance,"// Visit all the live registers. If they are already assigned to a physical; // register, unify them with the corresponding LiveIntervalUnion, otherwise push; // them on the priority queue for later assignment.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RegAllocBase.cpp:183,queue,queue,183,interpreter/llvm-project/llvm/lib/CodeGen/RegAllocBase.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RegAllocBase.cpp,1,['queue'],['queue']
Performance,"// Visit an individual instruction. This could be a newly added instruction,; // or one that has been modified by an optimization.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/BitTracker.cpp:117,optimiz,optimization,117,interpreter/llvm-project/llvm/lib/Target/Hexagon/BitTracker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/BitTracker.cpp,1,['optimiz'],['optimization']
Performance,// Visit queue - used to maintain BFS ordering.; // std::optional<> because we need markers for levels.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/BreadthFirstIterator.h:9,queue,queue,9,interpreter/llvm-project/llvm/include/llvm/ADT/BreadthFirstIterator.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/BreadthFirstIterator.h,1,['queue'],['queue']
Performance,// VisitedBBs - Cache of previously visited BBs.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PadShortFunction.cpp:16,Cache,Cache,16,interpreter/llvm-project/llvm/lib/Target/X86/X86PadShortFunction.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86PadShortFunction.cpp,1,['Cache'],['Cache']
Performance,"// Visualization of Load-Op-Store fusion:; // -------------------------; // Legend:; // *-lines = Chain operand dependencies.; // |-lines = Normal operand dependencies.; // Dependencies flow down and right. n-suffix references multiple nodes.; //; // C Xn C; // * * *; // * * *; // Xn A-LD Yn TF Yn; // * * \ | * |; // * * \ | * |; // * * \ | => A--LD_OP_ST; // * * \| \; // TF OP \; // * | \ Zn; // * | \; // A-ST Zn; //; // This merge induced dependences from: #1: Xn -> LD, OP, Zn; // #2: Yn -> LD; // #3: ST -> Zn; // Ensure the transform is safe by checking for the dual; // dependencies to make sure we do not induce a loop.; // As LD is a predecessor to both OP and ST we can do this by checking:; // a). if LD is a predecessor to a member of Xn or Yn.; // b). if a Zn is a predecessor to ST.; // However, (b) can only occur through being a chain predecessor to; // ST, which is the same as Zn being a member or predecessor of Xn,; // which is a subset of LD being a predecessor of Xn. So it's; // subsumed by check (a).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp:20,Load,Load-Op-Store,20,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,1,['Load'],['Load-Op-Store']
Performance,"// Volatile RMWs perform a load and a store, we cannot replace this by just a; // load or just a store. We chose not to canonicalize out of general paranoia; // about user expectations around volatile.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAtomicRMW.cpp:17,perform,perform,17,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAtomicRMW.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAtomicRMW.cpp,3,"['load', 'perform']","['load', 'perform']"
Performance,// Volatile loads make the address observable.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CaptureTracking.cpp:12,load,loads,12,interpreter/llvm-project/llvm/lib/Analysis/CaptureTracking.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CaptureTracking.cpp,1,['load'],['loads']
Performance,"// Volatile loads/stores are only supported for shared and global address; // spaces, or for generic AS that maps to them.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXTargetTransformInfo.h:12,load,loads,12,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXTargetTransformInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXTargetTransformInfo.h,1,['load'],['loads']
Performance,// Volatile operations effectively capture the memory location that they; // load and store to.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CaptureTracking.cpp:77,load,load,77,interpreter/llvm-project/llvm/lib/Analysis/CaptureTracking.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CaptureTracking.cpp,1,['load'],['load']
Performance,"// WARNING to developers: people use RooFormula a lot via RooGenericPdf and; // RooFormulaVar! Performance matters here. Avoid non-static std::regex,; // because constructing these can become a bottleneck because of the regex; // compilation.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooFormula.cxx:95,Perform,Performance,95,roofit/roofitcore/src/RooFormula.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooFormula.cxx,2,"['Perform', 'bottleneck']","['Performance', 'bottleneck']"
Performance,"// WARNING: At this time, the state attached to 'Call' may be older than the; // state in 'Pred'. This is a minor optimization since CheckerManager will; // use an updated CallEvent instance when calling checkers, but if 'Call' is; // ever used directly in this function all callers should be updated to pass; // the most recent state. (It is probably not worth doing the work here since; // for some callers this will not be necessary.); // Run any pre-call checks using the generic call interface.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/ExprEngineCallAndReturn.cpp:114,optimiz,optimization,114,interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/ExprEngineCallAndReturn.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/ExprEngineCallAndReturn.cpp,1,['optimiz'],['optimization']
Performance,"// WARNING: no matter how worthwhile it may seem, we can not perform PHI CSE; // here, because the PHI we may succeed simplifying to was not; // def-reachable from the original PHI!; // If all of the PHI's incoming values are the same then replace the PHI node; // with the common value.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InstructionSimplify.cpp:61,perform,perform,61,interpreter/llvm-project/llvm/lib/Analysis/InstructionSimplify.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InstructionSimplify.cpp,1,['perform'],['perform']
Performance,"// WVE - Patch to allow customization of optimization level per component pdf",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsOptTestStatistic.cxx:41,optimiz,optimization,41,roofit/roofitcore/src/RooAbsOptTestStatistic.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsOptTestStatistic.cxx,1,['optimiz'],['optimization']
Performance,"// WVE copy values of cached variables here!!!",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooTreeDataStore.cxx:22,cache,cached,22,roofit/roofitcore/src/RooTreeDataStore.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooTreeDataStore.cxx,1,['cache'],['cached']
Performance,"// WVE need to prune tracking entries _below_ constant nodes as the're not needed; // cout << ""Number of Cache-and-Tracked args are "" << trackArgs.size() << endl ;; // cout << ""Compound ordered cache parameters = "" << endl ;; // orderedArgs.Print(""v"") ;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooVectorDataStore.cxx:105,Cache,Cache-and-Tracked,105,roofit/roofitcore/src/RooVectorDataStore.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooVectorDataStore.cxx,2,"['Cache', 'cache']","['Cache-and-Tracked', 'cache']"
Performance,"// WVE need to reset TTRee buffers to original datamembers here; //resetBuffers() ;; // Refill regular and cached variables of current tree from clone",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooTreeDataStore.cxx:107,cache,cached,107,roofit/roofitcore/src/RooTreeDataStore.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooTreeDataStore.cxx,1,['cache'],['cached']
Performance,"// WVE use cache manager here!",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooGenProdProj.cxx:11,cache,cache,11,roofit/roofitcore/src/RooGenProdProj.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooGenProdProj.cxx,1,['cache'],['cache']
Performance,// Wait for messages to be pushed into the queue.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Debuginfod/Debuginfod.cpp:43,queue,queue,43,interpreter/llvm-project/llvm/lib/Debuginfod/Debuginfod.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Debuginfod/Debuginfod.cpp,1,['queue'],['queue']
Performance,"// Wait until less than a full chunk of batches are in the queue before loading splitting the next chunk into; // batches",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RBatchLoader.hxx:59,queue,queue,59,tmva/tmva/inc/TMVA/RBatchLoader.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RBatchLoader.hxx,2,"['load', 'queue']","['loading', 'queue']"
Performance,"// Walk (both up and down) the chain looking for another load at the real; // (aligned) offset (the alignment of the other load does not matter in; // this case). If found, then do not use the offset reduction trick, as; // that will prevent the loads from being later combined (as they would; // otherwise be duplicates).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:57,load,load,57,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,3,['load'],"['load', 'loads']"
Performance,"// Walk all of the loads from this alloca, replacing them with the nearest; // store above them, if any.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp:19,load,loads,19,interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp,1,['load'],['loads']
Performance,"// Walk back through the IR for a pointer, looking for a select like the; // following:; //; // %offset = select i1 %cmp, i64 %a, i64 %b; // %addr = getelementptr double, double* %base, i64 %offset; // %ld = load double, double* %addr, align 8; //; // We won't be able to form a single SCEVAddRecExpr from this since the; // address for each loop iteration depends on %cmp. We could potentially; // produce multiple valid SCEVAddRecExprs, though, and check all of them for; // memory safety/aliasing if needed.; //; // If we encounter some IR we don't yet handle, or something obviously fine; // like a constant, then we just add the SCEV for that term to the list passed; // in by the caller. If we have a node that may potentially yield a valid; // SCEVAddRecExpr then we decompose it into parts and build the SCEV terms; // ourselves before adding to the list.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LoopAccessAnalysis.cpp:208,load,load,208,interpreter/llvm-project/llvm/lib/Analysis/LoopAccessAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LoopAccessAnalysis.cpp,1,['load'],['load']
Performance,"// Walk over all of the call graph nodes in topological order, so that we; // analyze parents before the children. Skip the functions inlined into; // the previously processed functions. Use external Visited set to identify; // inlined functions. The topological order allows the ""do not reanalyze; // previously inlined function"" performance heuristic to be triggered more; // often.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Frontend/AnalysisConsumer.cpp:331,perform,performance,331,interpreter/llvm-project/clang/lib/StaticAnalyzer/Frontend/AnalysisConsumer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Frontend/AnalysisConsumer.cpp,1,['perform'],['performance']
Performance,"// Walk the entire directory cache, looking for unused files.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/CachePruning.cpp:29,cache,cache,29,interpreter/llvm-project/llvm/lib/Support/CachePruning.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/CachePruning.cpp,1,['cache'],['cache']
Performance,"// Walk the entire module cache, looking for unused module files and module; // indices.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp:26,cache,cache,26,interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,1,['cache'],['cache']
Performance,"// Walk the register/memloc assignments, inserting copies/loads.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:58,load,loads,58,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,10,['load'],['loads']
Performance,"// Walk the register/memloc assignments, inserting copies/loads. In the case; // of tail call optimization arguments are handle later.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/M68k/M68kISelLowering.cpp:58,load,loads,58,interpreter/llvm-project/llvm/lib/Target/M68k/M68kISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/M68k/M68kISelLowering.cpp,4,"['load', 'optimiz']","['loads', 'optimization']"
Performance,"// Walk the register/memloc assignments, inserting copies/loads. In the case; // of tail call optimization, arguments are handled later.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:58,load,loads,58,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,2,"['load', 'optimiz']","['loads', 'optimization']"
Performance,"// Walk the register/memloc assignments, inserting copies/loads.; // i - Tracks the index into the list of registers allocated for the call; // RealArgIdx - Tracks the index into the list of actual function arguments; // j - Tracks the index into the list of byval arguments",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:58,load,loads,58,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['loads']
Performance,"// Walk the super chain. If we find a hit with a parent, we'll end; // up returning that summary. We actually allow that key (null,S), as; // we cache summaries for the null ObjCInterfaceDecl* to allow us to; // generate initial summaries without having to worry about NSObject; // being declared.; // FIXME: We may change this at some point.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Analysis/RetainSummaryManager.h:145,cache,cache,145,interpreter/llvm-project/clang/include/clang/Analysis/RetainSummaryManager.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Analysis/RetainSummaryManager.h,1,['cache'],['cache']
Performance,"// Walk the swap vector entries looking for conditions that prevent their; // containing computations from being optimized. When such conditions are; // found, mark the representative of the computation's equivalence class; // as rejected.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp:113,optimiz,optimized,113,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp,1,['optimiz'],['optimized']
Performance,"// Walk the swap vector entries looking for swaps fed by permuting loads; // and swaps that feed permuting stores. If the containing computation; // has not been marked rejected, mark each such swap for removal.; // (Removal is delayed in case optimization has disturbed the pattern,; // such that multiple loads feed the same swap, etc.)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp:67,load,loads,67,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp,3,"['load', 'optimiz']","['loads', 'optimization']"
Performance,"// Walk the use list of the global seeing if all the uses are load or store.; // If there is anything else, bail out.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp:62,load,load,62,interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,1,['load'],['load']
Performance,"// Walk the user list of the global. If we find anything other than a direct; // load or store, bail out.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/GlobalsModRef.cpp:81,load,load,81,interpreter/llvm-project/llvm/lib/Analysis/GlobalsModRef.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/GlobalsModRef.cpp,1,['load'],['load']
Performance,"// Walk through SortedEdges to initialize the queue, instead of using NodeInfoMap; // to ensure an ordered deterministic push.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/SCCIterator.h:46,queue,queue,46,interpreter/llvm-project/llvm/include/llvm/ADT/SCCIterator.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/SCCIterator.h,1,['queue'],['queue']
Performance,// Walk through lvalue casts to get the original expression; // that syntactically caused the load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/DereferenceChecker.cpp:94,load,load,94,interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/DereferenceChecker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/DereferenceChecker.cpp,1,['load'],['load']
Performance,"// Walk through the Non-local dependencies, removing this one as the value; // for any cached queries.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp:87,cache,cached,87,interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,1,['cache'],['cached']
Performance,"// Walk through the computed steps for the initialization sequence,; // performing the specified conversions along the way.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp:72,perform,performing,72,interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,1,['perform'],['performing']
Performance,"// Walk up the stack to determine whether we can capture the variable,; // performing the ""simple"" checks that don't depend on type. We stop when; // we've either hit the declared scope of the variable or find an existing; // capture of that variable. We start from the innermost capturing-entity; // (the DC) and ensure that all intervening capturing-entities; // (blocks/lambdas etc.) between the innermost capturer and the variable`s; // declcontext can either capture the variable or have already captured; // the variable.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp:75,perform,performing,75,interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp,1,['perform'],['performing']
Performance,// Walks all basic blocks in the function performing the SSA rename algorithm; // and inserting the phi nodes we marked as necessary,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp:42,perform,performing,42,interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp,1,['perform'],['performing']
Performance,// Warn for reference variables whose initializtion performs lifetime; // extension.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp:52,perform,performs,52,interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp,1,['perform'],['performs']
Performance,"// Warn that we did this, if we're not performing template instantiation.; // In that case, we'll have warned already when the template was defined.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp:39,perform,performing,39,interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp,1,['perform'],['performing']
Performance,// Warning: This loop can end up being somewhat performance sensitive.; // We're running this loop for once for each value queried resulting in a; // runtime of ~O(#assumes * #values).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ValueTracking.cpp:48,perform,performance,48,interpreter/llvm-project/llvm/lib/Analysis/ValueTracking.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ValueTracking.cpp,2,['perform'],['performance']
Performance,// Warning: We maintain cost tables in AArch64TargetTransformInfo.cpp.; // Any additional optimization in this function should be recorded; // in the cost tables.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:90,optimiz,optimization,90,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,2,['optimiz'],['optimization']
Performance,"// Was CPSR last defined by a high latency instruction?; // When CPSRDef is null, this refers to CPSR defs in predecessors.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/Thumb2SizeReduction.cpp:35,latency,latency,35,interpreter/llvm-project/llvm/lib/Target/ARM/Thumb2SizeReduction.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/Thumb2SizeReduction.cpp,1,['latency'],['latency']
Performance,"// Watch out for:; // r4 := ldr [r0, #8]; // r4 := ldr [r0, #4]; // or; // r0 := ldr [r0]; // If a load overrides the base register or a register loaded by; // another load in our chain, we cannot take this instruction.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp:99,load,load,99,interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp,3,['load'],"['load', 'loaded']"
Performance,"// We 'support' these types up to bitcast/load/store level, regardless of; // MVE integer-only / float support. Only doing FP data processing on the FP; // vector types is inhibited at integer-only level.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:42,load,load,42,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['load'],['load']
Performance,"// We *could* handle shifted masks here, but doing so would require an; // 'and' operation to fix up the low-order bits so we would trade; // shr+and for bfe+and, which has the same throughput",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp:182,throughput,throughput,182,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp,1,['throughput'],['throughput']
Performance,// We actually have to do a cast now. Perform the cast according to the; // opcode specified.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/ConstantFold.cpp:38,Perform,Perform,38,interpreter/llvm-project/llvm/lib/IR/ConstantFold.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/ConstantFold.cpp,1,['Perform'],['Perform']
Performance,"// We add all to the not assigned list so that they will be distributed; // according to the load",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/src/TPacketizerFile.cxx:93,load,load,93,proof/proofplayer/src/TPacketizerFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/src/TPacketizerFile.cxx,1,['load'],['load']
Performance,// We allow LE non-masked loads to change the type (for example use a vldrb.8; // as opposed to a vldrw.32). This can allow extra addressing modes or; // alignments for what is otherwise an equivalent instruction.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelDAGToDAG.cpp:26,load,loads,26,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelDAGToDAG.cpp,2,['load'],['loads']
Performance,"// We allow a load factor of up to 2.0,; // so that means our capacity is NumBuckets * 2",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/FoldingSet.h:14,load,load,14,interpreter/llvm-project/llvm/include/llvm/ADT/FoldingSet.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/FoldingSet.h,1,['load'],['load']
Performance,"// We allow direct calls to any llvm.foo function here, because the; // target may not be linked into the optimizer.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/AsmWriter.cpp:106,optimiz,optimizer,106,interpreter/llvm-project/llvm/lib/IR/AsmWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/AsmWriter.cpp,1,['optimiz'],['optimizer']
Performance,"// We allow splitting of non-volatile loads and stores where the type is an; // integer type. These may be used to implement 'memcpy' or other ""transfer; // of bits"" patterns.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:38,load,loads,38,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,1,['load'],['loads']
Performance,"// We already cached and used this basket during this cluster range,; // let's not redo it",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx:14,cache,cached,14,tree/tree/src/TTreeCache.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx,1,['cache'],['cached']
Performance,"// We already did load elimination, so nothing to do here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp:18,load,load,18,interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,1,['load'],['load']
Performance,// We already implement getCastInstrCost and getMemoryOpCost where we perform; // the vector adjustment there.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp:70,perform,perform,70,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,1,['perform'],['perform']
Performance,// We already visited the elements of this initializer list while; // performing the initialization. Don't visit them again unless we've; // changed the lifetime of the initialized entity.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp:70,perform,performing,70,interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,1,['perform'],['performing']
Performance,"// We also disable the optimization for variadic functions because; // it's impossible to ""re-pass"" varargs.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGClass.cpp:23,optimiz,optimization,23,interpreter/llvm-project/clang/lib/CodeGen/CGClass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGClass.cpp,1,['optimiz'],['optimization']
Performance,// We also need to make sure it is safe to move the load.; // Assume there are stores between DefMI and UseMI.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveRangeEdit.cpp:52,load,load,52,interpreter/llvm-project/llvm/lib/CodeGen/LiveRangeEdit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveRangeEdit.cpp,1,['load'],['load']
Performance,"// We also skip empty results. If any of the results could be external and; // the currently available results are empty, then all of the results are; // external and we skip it above. So the only way we get here with an empty; // results is when no results could have been external *and* we have; // external results.; //; // FIXME: While we might want to start emitting on-disk entries for negative; // lookups into a decl context as an optimization, today we *have* to skip; // them because there are names with empty lookup results in decl contexts; // which we can't emit in any stable ordering: we lookup constructors and; // conversion functions in the enclosing namespace scope creating empty; // results for them. This in almost certainly a bug in Clang's name lookup,; // but that is likely to be hard or impossible to fix and so we tolerate it; // here by omitting lookups with empty results.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp:439,optimiz,optimization,439,interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp,1,['optimiz'],['optimization']
Performance,"// We also want to do this peephole for cases like this: if (a*b == 0),; // and optimise away the CMP instruction from the generated code sequence:; // MULS, MOVS, MOVS, CMP. Here the MOVS instructions load the boolean values; // resulting from the select instruction, but these MOVS instructions for; // Thumb1 (V6M) are flag setting and are thus preventing this optimisation.; // However, if we only have MOVS instructions in between the CMP and the; // other instruction (the MULS in this example), then the CPSR is dead so we; // can safely reorder the sequence into: MOVS, MOVS, MULS, CMP. We do this; // reordering and then continue the analysis hoping we can eliminate the; // CMP. This peephole works on the vregs, so is still in SSA form. As a; // consequence, the movs won't redefine/kill the MUL operands which would; // make this reordering illegal.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp:202,load,load,202,interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp,1,['load'],['load']
Performance,"// We always copy the contents of TTreeReaderArray<bool> into an RVec<bool> (never take a view into the memory; // buffer) because the underlying memory buffer might be the one of a std::vector<bool>, which is not a contiguous; // slab of bool values.; // Note that this also penalizes the case in which the column type is actually bool[], but the possible performance; // gains in this edge case is probably not worth the extra complication required to differentiate the two cases.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RTreeColumnReader.hxx:357,perform,performance,357,tree/dataframe/inc/ROOT/RDF/RTreeColumnReader.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RTreeColumnReader.hxx,1,['perform'],['performance']
Performance,"// We always run the verifier once on the merged module. If it has already; // been called in optimize(), this call will return early.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/LTO/LTOCodeGenerator.cpp:94,optimiz,optimize,94,interpreter/llvm-project/llvm/lib/LTO/LTOCodeGenerator.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/LTO/LTOCodeGenerator.cpp,1,['optimiz'],['optimize']
Performance,// We approximate the number of loads and stores needed by dividing the; // size of the byval type by the target's pointer size.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InlineCost.cpp:32,load,loads,32,interpreter/llvm-project/llvm/lib/Analysis/InlineCost.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InlineCost.cpp,1,['load'],['loads']
Performance,"// We are about to read a token. For the multiple-include optimization FA to; // work, we have to remember if we had read any tokens *before* this; // pp-directive.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/PPDirectives.cpp:58,optimiz,optimization,58,interpreter/llvm-project/clang/lib/Lex/PPDirectives.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/PPDirectives.cpp,1,['optimiz'],['optimization']
Performance,// We are adding a 64 bit SGPR and a constant. If constant bus limit; // is 1 we would need to perform 1 or 2 extra moves for each half of; // the constant and it is better to do a scalar add and then issue a; // single VALU instruction to materialize zero. Otherwise it is less; // instructions to perform VALU adds with immediates or inline literals.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUInstructionSelector.cpp:95,perform,perform,95,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUInstructionSelector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUInstructionSelector.cpp,4,['perform'],['perform']
Performance,"// We are adding a new user for this load, for which the original; // metadata may not hold. Additionally, the new load may have a different; // size and type, so their metadata cannot be combined in any; // straightforward way.; // Drop all metadata that is not known to cause immediate UB on violation,; // unless the load has !noundef, in which case all metadata violations; // will be promoted to UB.; // TODO: We can combine noalias/alias.scope metadata here, because it is; // independent of the load type.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp:37,load,load,37,interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,4,['load'],['load']
Performance,"// We are already using the cache, no need to recurse one more time.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfoReadBuffer.cxx:28,cache,cache,28,io/io/src/TStreamerInfoReadBuffer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfoReadBuffer.cxx,2,['cache'],['cache']
Performance,"// We are always replacing N0/N1's use in N and only need additional; // replacements if there are additional uses.; // Note: We are checking uses of the *nodes* (SDNode) rather than values; // (SDValue) here because the node may reference multiple values; // (for example, the chain value of a load node).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:295,load,load,295,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,"// We are at the top of this chain.; // If the copy has a glue operand, we conservatively assume it; // isn't safe to perform a tail call.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:118,perform,perform,118,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['perform'],['perform']
Performance,"// We are broadcasting, even if there is just one waiter...; // Record that we are broadcasting, which helps optimize; // <pthread_cond_wait> for the non-broadcast case.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/thread/src/TWin32Condition.cxx:109,optimiz,optimize,109,core/thread/src/TWin32Condition.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/thread/src/TWin32Condition.cxx,1,['optimiz'],['optimize']
Performance,// We are constructing the OptimizationRemarkEmitter on the fly rather than; // using the analysis pass to avoid building DominatorTree and LoopInfo which; // are not available this late in the IR pipeline.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/StackProtector.cpp:27,Optimiz,OptimizationRemarkEmitter,27,interpreter/llvm-project/llvm/lib/CodeGen/StackProtector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/StackProtector.cpp,1,['Optimiz'],['OptimizationRemarkEmitter']
Performance,"// We are currently instantiating one (or more) templates. At that point,; // all Decls are present in the AST (with possibly deserialization pending),; // and we should not load more modules which could find an implicit template; // instantiation that is lazily loaded.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TClingCallbacks.cxx:174,load,load,174,core/metacling/src/TClingCallbacks.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TClingCallbacks.cxx,2,['load'],"['load', 'loaded']"
Performance,"// We are disabling shrinkwrapping for now when PAC is enabled, as; // shrinkwrapping can cause clobbering of r12 when the PAC code is; // generated. A follow-up patch will fix this in a more performant manner.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMFrameLowering.cpp:192,perform,performant,192,interpreter/llvm-project/llvm/lib/Target/ARM/ARMFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMFrameLowering.cpp,1,['perform'],['performant']
Performance,"// We are extracting from 2 different indexes, so one operand must be shuffled; // before performing a vector operation and/or extract. The more expensive; // extract will be replaced by a shuffle.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VectorCombine.cpp:90,perform,performing,90,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VectorCombine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VectorCombine.cpp,1,['perform'],['performing']
Performance,"// We are going to insert code that relies on the fact that the callee; // will become a non-readonly function after it is instrumented by us. To; // prevent this code from being optimized out, mark that function; // non-readonly in advance.; // TODO: We can likely do better than dropping memory() completely here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp:179,optimiz,optimized,179,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp,1,['optimiz'],['optimized']
Performance,"// We are going to make changes to this loop. SCEV may be keeping cached info; // about it, in particular about backedge taken count. The changes we make; // are guaranteed to invalidate this information for our loop. It is tempting; // to only invalidate the loop being unrolled, but it is incorrect as long as; // all exiting branches from all inner loops have impact on the outer loops,; // and if something changes inside them then any of outer loops may also; // change. When we forget outermost loop, we also forget all contained loops; // and this is what we need here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopUnroll.cpp:66,cache,cached,66,interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopUnroll.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopUnroll.cpp,1,['cache'],['cached']
Performance,"// We are going to try to rewrite this load to a larger zero-extending; // load. This is safe if all portions of the 32 bit super-register; // of the original destination register, except for the original destination; // register are dead. getSuperRegDestIfDead checks that.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FixupBWInsts.cpp:39,load,load,39,interpreter/llvm-project/llvm/lib/Target/X86/X86FixupBWInsts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FixupBWInsts.cpp,2,['load'],['load']
Performance,"// We are here about to generate a truncate instruction that may hurt; // performance because the scalar evolution expression computed earlier; // in WideAddRec.first does not indicate a polynomial induction expression.; // In that case, look at the operands of the use instruction to determine; // if we can still widen the use instead of truncating its operand.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyIndVar.cpp:74,perform,performance,74,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyIndVar.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyIndVar.cpp,1,['perform'],['performance']
Performance,"// We are in a lambda function where ""this"" is captured so the; // CXXThisValue need to be loaded from the lambda capture",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGException.cpp:91,load,loaded,91,interpreter/llvm-project/clang/lib/CodeGen/CGException.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGException.cpp,1,['load'],['loaded']
Performance,"// We are in the case where the branch holds a custom collection; // proxy but the dictionary is not loaded, calling; // GetCollectionProxy had the side effect of creating the TClass; // corresponding to this emulated collection.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TBranchElement.cxx:101,load,loaded,101,tree/tree/src/TBranchElement.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TBranchElement.cxx,1,['load'],['loaded']
Performance,"// We are likely in the situation where the base class comes after the derived; // class in the TFile's list of StreamerInfo, so it has not yet been loaded,; // let's see if it is there.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfo.cxx:149,load,loaded,149,io/io/src/TStreamerInfo.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfo.cxx,1,['load'],['loaded']
Performance,"// We are looking for a collection on interconnected phi nodes that together; // only use loads/bitcasts and are used by stores/bitcasts, and the bitcasts; // are of the same type. Convert the whole set of nodes to the type of the; // bitcast.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:90,load,loads,90,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,1,['load'],['loads']
Performance,// We are looking for:; // One zero offset load/store that can become postinc,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp:43,load,load,43,interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp,1,['load'],['load']
Performance,"// We are not allowed to modify the input array, so we can't apply the; // transformation in-place and then call _input->binNumbers() without; // allocating additional memory. That's why we fall back to binNumber() for; // now. The RooLinTransBinning is only ever used in the RooLinearVar, so if; // this ever becomes a bottleneck this could be optimized.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooLinTransBinning.cxx:320,bottleneck,bottleneck,320,roofit/roofitcore/src/RooLinTransBinning.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooLinTransBinning.cxx,2,"['bottleneck', 'optimiz']","['bottleneck', 'optimized']"
Performance,"// We are not in read mode, or the file status information is not yet; // in the cache. Update or read the status information with dc_stat().",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/dcache/src/TDCacheFile.cxx:81,cache,cache,81,io/dcache/src/TDCacheFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/dcache/src/TDCacheFile.cxx,1,['cache'],['cache']
Performance,"// We are not in recursive loading, so it's safe to pass the ""interesting""; // decls to the consumer.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp:27,load,loading,27,interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,1,['load'],['loading']
Performance,"// We are now ready (enough is loaded) to init the list of opaque typedefs.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/dictgen/src/rootcling_impl.cxx:31,load,loaded,31,core/dictgen/src/rootcling_impl.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/dictgen/src/rootcling_impl.cxx,2,['load'],['loaded']
Performance,"// We are now tracking the loaded value instead of the address. In the; // future if multi-location support is added to the IR, it might be; // preferable to keep tracking both the loaded value and the original; // address in case the alloca can not be elided.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/Local.cpp:27,load,loaded,27,interpreter/llvm-project/llvm/lib/Transforms/Utils/Local.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/Local.cpp,4,['load'],['loaded']
Performance,// We are replacing a vector load with a scalar load. The new load must have; // identical memory op ordering to the original.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:29,load,load,29,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,3,['load'],['load']
Performance,"// We are selecting i64 ADD here instead of custom lower it during; // DAG legalization, so we can fold some i64 ADDs used for address; // calculation into the LOAD and STORE instructions.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelDAGToDAG.cpp:160,LOAD,LOAD,160,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelDAGToDAG.cpp,1,['LOAD'],['LOAD']
Performance,"// We are storing the pointer into a memory location, potentially escaping.; // As an optimization, we try to detect simple cases where it doesn't; // actually escape, for example:; // %ptr = alloca ..; // %addr = alloca ..; // store %ptr, %addr; // %x = load %addr; // ..; // If %addr is only used by loading from it, we could simply treat %x as; // another alias of %ptr, and not considering %ptr being escaped.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Coroutines/CoroFrame.cpp:86,optimiz,optimization,86,interpreter/llvm-project/llvm/lib/Transforms/Coroutines/CoroFrame.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Coroutines/CoroFrame.cpp,3,"['load', 'optimiz']","['load', 'loading', 'optimization']"
Performance,"// We are supposed to perform no initialization but begin the lifetime of; // the object. We interpret that as meaning to do what default; // initialization of the object would do if all constructors involved were; // trivial:; // * All base, non-variant member, and array element subobjects' lifetimes; // begin; // * No variant members' lifetimes begin; // * All scalar subobjects whose lifetimes begin have indeterminate values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ExprConstant.cpp:22,perform,perform,22,interpreter/llvm-project/clang/lib/AST/ExprConstant.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ExprConstant.cpp,1,['perform'],['perform']
Performance,// We assume that all of BB is (probably) live now and if there are calls to; // internal functions we will assume that those are now live as well. This; // is a performance optimization for blocks with calls to a lot of internal; // functions. It can however cause dead functions to be treated as live.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/AttributorAttributes.cpp:162,perform,performance,162,interpreter/llvm-project/llvm/lib/Transforms/IPO/AttributorAttributes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/AttributorAttributes.cpp,2,"['optimiz', 'perform']","['optimization', 'performance']"
Performance,"// We assume that all pointers passed to deopt are base pointers; as an; // optimization, we can use this to avoid seperately materializing the base; // pointer graph. This is only relevant since we're very conservative about; // generating new conflict nodes during base pointer insertion. If we were; // smarter there, this would be irrelevant.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp:76,optimiz,optimization,76,interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,1,['optimiz'],['optimization']
Performance,"// We assume that objects with a constant base (e.g. a global) can't move; // and don't need to be reported to the collector because they are always; // live. Besides global references, all kinds of constants (e.g. undef,; // constant expressions, null pointers) can be introduced by the inliner or; // the optimizer, especially on dynamically dead paths.; // Here we treat all of them as having single null base. By doing this we; // trying to avoid problems reporting various conflicts in a form of; // ""phi (const1, const2)"" or ""phi (const, regular gc ptr)"".; // See constant.ll file for relevant test cases.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp:307,optimiz,optimizer,307,interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,1,['optimiz'],['optimizer']
Performance,"// We assume that we are called in already serialized code.; // Note: should we also cache the negative answers?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/foundation/src/TClassEdit.cxx:85,cache,cache,85,core/foundation/src/TClassEdit.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/foundation/src/TClassEdit.cxx,1,['cache'],['cache']
Performance,"// We assume this is supposed to correspond to a C++0x-style; // sequentially-consistent fence (i.e. this is only usable for; // synchronization, not device I/O or anything like that). This intrinsic; // is really badly designed in the sense that in theory, there isn't; // any way to safely use it... but in practice, it mostly works; // to use it with non-atomic loads and stores to get acquire/release; // semantics.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:365,load,loads,365,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,1,['load'],['loads']
Performance,"// We build scalar steps for both integer and floating-point induction; // variables. Here, we determine the kind of arithmetic we will perform.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlanRecipes.cpp:136,perform,perform,136,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlanRecipes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlanRecipes.cpp,1,['perform'],['perform']
Performance,"// We build scheduling units by walking a block's instruction list; // from bottom to top.; // Each MIs' memory operand(s) is analyzed to a list of underlying; // objects. The SU is then inserted in the SUList(s) mapped from the; // Value(s). Each Value thus gets mapped to lists of SUs depending; // on it, stores and loads kept separately. Two SUs are trivially; // non-aliasing if they both depend on only identified Values and do; // not share any common Value.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ScheduleDAGInstrs.cpp:319,load,loads,319,interpreter/llvm-project/llvm/lib/CodeGen/ScheduleDAGInstrs.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ScheduleDAGInstrs.cpp,1,['load'],['loads']
Performance,// We cache a non-const iterator so we're forced to resort to const_cast to; // get the begin/end in the case where 'this' is const. To avoid duplication; // of code with the only difference being whether the const cast is present; // 'this' is always const in this particular function and we sort out the; // difference in FindLowerBound and FindLowerBoundConst.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/SparseBitVector.h:6,cache,cache,6,interpreter/llvm-project/llvm/include/llvm/ADT/SparseBitVector.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/SparseBitVector.h,1,['cache'],['cache']
Performance,// We cache the record vectors for single classes. Many backends request; // the same vectors multiple times.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TableGen/Record.cpp:6,cache,cache,6,interpreter/llvm-project/llvm/lib/TableGen/Record.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/TableGen/Record.cpp,1,['cache'],['cache']
Performance,"// We cached PHINodes in PHIs. To avoid accessing deleted PHINodes later,; // do not delete PHINodes here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp:6,cache,cached,6,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp,1,['cache'],['cached']
Performance,"// We cached out at this point. Caching out is common due to us backtracking; // from the inlined function, which might spawn several paths.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/ExprEngine.cpp:6,cache,cached,6,interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/ExprEngine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/ExprEngine.cpp,1,['cache'],['cached']
Performance,"// We call this to discover whether any load/store pointers in the loop have; // negative strides. This will require extra work to reverse the loop; // predicate, which may be expensive.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp:40,load,load,40,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,1,['load'],['load']
Performance,"// We can add some values to the Visited set when processing load; // instructions which are also used by stores in NonVolatileStores.; // For example this can happen if we have following code:; //; // store %Derived* @foo, %Derived** bitcast (%Base** @bar to %Derived**); // %42 = load %Derived*, %Derived** bitcast (%Base** @bar to %Derived**); //; // After processing loads we'll add bitcast to the Visited set, and if; // we use the same set while processing stores, we'll never see store; // to @bar and @bar will be mistakenly treated as readonly.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ModuleSummaryAnalysis.cpp:61,load,load,61,interpreter/llvm-project/llvm/lib/Analysis/ModuleSummaryAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ModuleSummaryAnalysis.cpp,3,['load'],"['load', 'loads']"
Performance,// We can aggressively convert to the vector form because the backend can; // invert this transform if it does not result in a performance win.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VectorCombine.cpp:127,perform,performance,127,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VectorCombine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VectorCombine.cpp,2,['perform'],['performance']
Performance,"// We can assume that ptr is aligned at least to char2's alignment, but the; // load will assume that ptr is aligned to char2's alignment. This is only; // safe if alignof(c2) <= alignof(char2).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/__clang_cuda_intrinsics.h:80,load,load,80,interpreter/llvm-project/clang/lib/Headers/__clang_cuda_intrinsics.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/__clang_cuda_intrinsics.h,1,['load'],['load']
Performance,// We can be sure that the scavenged-register slot is within the range; // of the load offset.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARC/ARCRegisterInfo.cpp:82,load,load,82,interpreter/llvm-project/llvm/lib/Target/ARC/ARCRegisterInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARC/ARCRegisterInfo.cpp,1,['load'],['load']
Performance,// We can better optimize this case in DAGCombiner::foldAndOrOfSETCC.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,optimiz,optimize,17,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['optimiz'],['optimize']
Performance,"// We can build the appropriate control immediate by performing the logic; // operation we're matching using these constants for A, B, and C.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp:53,perform,performing,53,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,1,['perform'],['performing']
Performance,// We can bypass creating a target-independent constant expression and then; // folding it back into a ConstantInt. This is just a compile-time; // optimization.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp:148,optimiz,optimization,148,interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,1,['optimiz'],['optimization']
Performance,// We can coerce a constant load into a load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp:28,load,load,28,interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,2,['load'],['load']
Performance,"// We can do this optimization for non-constants in nosync + norecurse; // functions, but globals used in exactly one norecurse functions are already; // promoted to an alloca.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp:18,optimiz,optimization,18,interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,1,['optimiz'],['optimization']
Performance,// We can either use a special instruction to load over the low double or; // to move just the low double.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,load,load,46,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,"// We can eliminate in favor of non-simple loads, but we won't be able to; // eliminate the loads themselves.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp:43,load,loads,43,interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,2,['load'],['loads']
Performance,"// We can fall back to a libcall with an illegal type for the MUL if we; // have a libcall big enough.; // Also, we can fall back to a division in some cases, but that's a big; // performance hit in the general case.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp:180,perform,performance,180,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp,1,['perform'],['performance']
Performance,"// We can have macro expansion inside a conditional directive while; // reading the function macro arguments. To ensure, in that case, that; // MacroExpands callbacks still happen in source order, queue this; // callback to have it happen after the function macro callback.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/PPMacroExpansion.cpp:197,queue,queue,197,interpreter/llvm-project/clang/lib/Lex/PPMacroExpansion.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/PPMacroExpansion.cpp,1,['queue'],['queue']
Performance,"// We can init constant f16x2/v2i16/v4i8 with a single .b32 move. Normally it; // would get lowered as two constant loads and vector-packing move.; // Instead we want just a constant move:; // mov.b32 %r2, 0x40003C00",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:116,load,loads,116,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,1,['load'],['loads']
Performance,"// We can leverage the specific way the ""cvttps2dq/cvttpd2dq"" instruction; // behaves on out of range inputs to generate optimized conversions.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:121,optimiz,optimized,121,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['optimiz'],['optimized']
Performance,"// We can leverage the specific way the ""cvttss2si/cvttsd2si"" instruction; // behaves on out of range inputs to generate optimized conversions.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:121,optimiz,optimized,121,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['optimiz'],['optimized']
Performance,// We can load zero using LZ?R and negative zero using LZ?R;LC?BR.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:10,load,load,10,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,1,['load'],['load']
Performance,"// We can narrow (e.g.) 16-bit extending loads on 32-bit target to; // 8 bits, but have to be careful...",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp:41,load,loads,41,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp,1,['load'],['loads']
Performance,"// We can not replace a wide volatile load with a broadcast-from-memory,; // because that would narrow the load, which isn't legal for volatiles.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,load,load,38,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,2,['load'],['load']
Performance,// We can only correctly find a minimum type for a scalable vector when it is; // a splat. For splats of constant values the fpext is wrapped up as a; // ConstantExpr.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCasts.cpp:51,scalab,scalable,51,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCasts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCasts.cpp,1,['scalab'],['scalable']
Performance,// We can only create byte sized loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:33,load,loads,33,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['loads']
Performance,// We can only do the optimization if we can get immediates; // from both operands,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp:22,optimiz,optimization,22,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp,1,['optimiz'],['optimization']
Performance,"// We can only do this optimization if the output is a multiple of the input; // element size, or the input is a multiple of the output element size.; // Convert the input type to have the same element type as the output.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCasts.cpp:23,optimiz,optimization,23,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCasts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCasts.cpp,1,['optimiz'],['optimization']
Performance,"// We can only fold loads from constant globals with a definitive initializer.; // Check this upfront, to skip expensive offset calculations.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ConstantFolding.cpp:20,load,loads,20,interpreter/llvm-project/llvm/lib/Analysis/ConstantFolding.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ConstantFolding.cpp,1,['load'],['loads']
Performance,// We can only fold loads if the sources are unique.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp:20,load,loads,20,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,1,['load'],['loads']
Performance,// We can only fold the load if it is from a constant global with definitive; // initializer. Skip expensive logic if this is not the case.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InstructionSimplify.cpp:24,load,load,24,interpreter/llvm-project/llvm/lib/Analysis/InstructionSimplify.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InstructionSimplify.cpp,2,['load'],['load']
Performance,// We can only handle a register or an offseted load of a register.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/CodeViewDebug.cpp:48,load,load,48,interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/CodeViewDebug.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/CodeViewDebug.cpp,1,['load'],['load']
Performance,// We can only optimize AGPR/VGPR virtual register,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIOptimizeVGPRLiveRange.cpp:15,optimiz,optimize,15,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIOptimizeVGPRLiveRange.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIOptimizeVGPRLiveRange.cpp,2,['optimiz'],['optimize']
Performance,// We can only optimize non-volatile memcpy's.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp:15,optimiz,optimize,15,interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,1,['optimiz'],['optimize']
Performance,"// We can only optimize the index operand.; // In case we have str xA, [xA, #imm], this is two different uses; // of xA and we cannot fold, otherwise the xA stored may be wrong,; // even if #imm == 0.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64CollectLOH.cpp:15,optimiz,optimize,15,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64CollectLOH.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64CollectLOH.cpp,1,['optimiz'],['optimize']
Performance,"// We can only optimize the multiplies when there is a chain of more than; // three, such that a balanced tree might require fewer total multiplies.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/Reassociate.cpp:15,optimiz,optimize,15,interpreter/llvm-project/llvm/lib/Transforms/Scalar/Reassociate.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/Reassociate.cpp,1,['optimiz'],['optimize']
Performance,// We can only optimize this case if the BUILD_VECTOR elements are; // at least as wide as the extracted value.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:15,optimiz,optimize,15,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,1,['optimiz'],['optimize']
Performance,// We can only perform deduction for class templates.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp:15,perform,perform,15,interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,1,['perform'],['perform']
Performance,"// We can only prefix the observables after everything related the; // compiling of the compute graph for the normalization set is done. This; // is because of a subtlety in conditional RooProdPdfs, which stores the; // normalization sets for the individual pdfs in RooArgSets that are; // disconnected from the computation graph, so we have no control over; // them. An alternative would be to use recursive server re-direction,; // but this has more performance overhead.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooSimultaneous.cxx:452,perform,performance,452,roofit/roofitcore/src/RooSimultaneous.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooSimultaneous.cxx,1,['perform'],['performance']
Performance,"// We can only promote this argument if all the uses are loads at known; // offsets.; //; // Promoting the argument causes it to be loaded in the caller; // unconditionally. This is only safe if we can prove that either the load; // would have happened in the callee anyway (ie, there is a load in the entry; // block) or the pointer passed in at every call site is guaranteed to be; // valid.; // In the former case, invalid loads can happen, but would have happened; // anyway, in the latter case, invalid loads won't happen. This prevents us; // from introducing an invalid load that wouldn't have happened in the; // original code.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/ArgumentPromotion.cpp:57,load,loads,57,interpreter/llvm-project/llvm/lib/Transforms/IPO/ArgumentPromotion.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/ArgumentPromotion.cpp,7,['load'],"['load', 'loaded', 'loads']"
Performance,// We can only sink load instructions if there is nothing between the load and; // the end of block that could change the value.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp:20,load,load,20,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp,2,['load'],['load']
Performance,// We can only transform this if it is safe to push the loads into the; // predecessor blocks. The only thing to watch out for is that we can't put; // a possibly trapping load in the predecessor if it is a critical edge.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:56,load,loads,56,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,2,['load'],"['load', 'loads']"
Performance,"// We can optimize such a pattern:; // %1:gpr = LD_imm64 @""llvm.s:0:4$0:2""; // %2:gpr32 = LDW32 %1:gpr, 0; // %3:gpr = SUBREG_TO_REG 0, %2:gpr32, %subreg.sub_32; // %4:gpr = ADD_rr %0:gpr, %3:gpr; // or similar patterns below for non-alu32 case.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFMISimplifyPatchable.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Target/BPF/BPFMISimplifyPatchable.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFMISimplifyPatchable.cpp,1,['optimiz'],['optimize']
Performance,// We can optimize this.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/A15SDOptimizer.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Target/ARM/A15SDOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/A15SDOptimizer.cpp,1,['optimiz'],['optimize']
Performance,"// We can optimized a value operation when the content are strings",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/inc/TGenCollectionProxy.h:10,optimiz,optimized,10,io/io/inc/TGenCollectionProxy.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/inc/TGenCollectionProxy.h,1,['optimiz'],['optimized']
Performance,"// We can perform an integral promotion to the underlying type of the enum,; // even if that's not the promoted type. Note that the check for promoting; // the underlying type is based on the type alone, and does not consider; // the bitfield-ness of the actual source expression.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp:10,perform,perform,10,interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,1,['perform'],['perform']
Performance,// We can perform template argument deduction for the given non-type; // template parameter.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplateDeduction.cpp:10,perform,perform,10,interpreter/llvm-project/clang/lib/Sema/SemaTemplateDeduction.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplateDeduction.cpp,1,['perform'],['perform']
Performance,// We can perform template argument deduction for the given non-type; // template parameter.; // C++ [temp.deduct.type]p13:; // The type of N in the type T[N] is std::size_t.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplateDeduction.cpp:10,perform,perform,10,interpreter/llvm-project/clang/lib/Sema/SemaTemplateDeduction.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplateDeduction.cpp,1,['perform'],['perform']
Performance,"// We can perform the captured-before check against any instruction in the; // loop header, as the loop header is reachable from any instruction inside; // the loop.; // TODO: ReturnCaptures=true shouldn't be necessary here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp:10,perform,perform,10,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp,1,['perform'],['perform']
Performance,"// We can perform the conversion between vector types in the following cases:; // 1)vector types are equivalent AltiVec and GCC vector types; // 2)lax vector conversions are permitted and the vector types are of the; // same size; // 3)the destination type does not have the ARM MVE strict-polymorphism; // attribute, which inhibits lax vector conversion for overload resolution; // only",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp:10,perform,perform,10,interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,1,['perform'],['perform']
Performance,// We can perform this optimization only if SrcReg is sign-extending.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp:10,perform,perform,10,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,2,"['optimiz', 'perform']","['optimization', 'perform']"
Performance,"// We can perform this optimization, equality only, if SrcReg is; // zero-extending.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp:10,perform,perform,10,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,2,"['optimiz', 'perform']","['optimization', 'perform']"
Performance,// We can remove the select by ensuring the load zeros all lanes the; // select would have. We determine this by proving there is no overlap; // between the load and select masks.; // (i.e (load_mask & select_mask) == 0 == no overlap),MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineSelect.cpp:44,load,load,44,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineSelect.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineSelect.cpp,2,['load'],['load']
Performance,"// We can skip all invariant.start intrinsics since they only read memory,; // and we can forward values across it. For invariant starts without; // invariant ends, we can use the fact that the invariantness never ends to; // start a scope in the current generaton which is true for all future; // generations. Also, we dont need to consume the last store since the; // semantics of invariant.start allow us to perform DSE of the last; // store, if there was a store following invariant.start. Consider:; //; // store 30, i8* p; // invariant.start(p); // store 40, i8* p; // We can DSE the store to 30, since the store 40 to invariant location p; // causes undefined behaviour.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp:411,perform,perform,411,interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,1,['perform'],['perform']
Performance,// We can use a normal VEX encoded load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp:35,load,load,35,interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp,1,['load'],['load']
Performance,// We can use the SVE whilelo instruction to lower this intrinsic by; // creating the appropriate sequence of scalable vector operations and; // then extracting a fixed-width subvector from the scalable vector.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:110,scalab,scalable,110,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,2,['scalab'],['scalable']
Performance,"// We can use the context instruction (generically the ultimate instruction; // the calling pass is trying to simplify) here, even though the result of; // this function is generally cached when called from the solve* functions; // (and that cached result might be used with queries using a different; // context instruction), because when this function is called from the solve*; // functions, the context instruction is not provided. When called from; // LazyValueInfoImpl::getValueOnEdge, the context instruction is provided,; // but then the result is not cached.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LazyValueInfo.cpp:183,cache,cached,183,interpreter/llvm-project/llvm/lib/Analysis/LazyValueInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LazyValueInfo.cpp,3,['cache'],['cached']
Performance,// We can usually perform 64b vector operations.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64LegalizerInfo.cpp:18,perform,perform,18,interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64LegalizerInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64LegalizerInfo.cpp,1,['perform'],['perform']
Performance,"// We can't determine the VF of a scalable vector by looking at the vlen; // string (just 'x'), so say we successfully parsed it but return a 'true'; // for the scalable field with an invalid VF field so that we know to look; // up the actual VF based on element types from the parameters or return.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/VFABIDemangler.cpp:34,scalab,scalable,34,interpreter/llvm-project/llvm/lib/IR/VFABIDemangler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/VFABIDemangler.cpp,2,['scalab'],['scalable']
Performance,"// We can't do PRE safely on a critical edge, so instead we schedule; // the edge to be split and perform the PRE the next time we iterate; // on the function.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp:98,perform,perform,98,interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,1,['perform'],['perform']
Performance,// We can't fold a load if we are going to make two instructions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp:19,load,load,19,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,2,['load'],['load']
Performance,"// We can't fold if this vreg has no uses or more than one use. Multiple uses; // may mean that the instruction got lowered to multiple MIs, or the use of; // the loaded value ended up being multiple operands of the result.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/FastISel.cpp:163,load,loaded,163,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/FastISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/FastISel.cpp,1,['load'],['loaded']
Performance,// We can't handle loads that extend past the allocated memory.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:19,load,loads,19,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,1,['load'],['loads']
Performance,"// We can't handle this case efficiently. Allocate a sufficiently; // aligned object on the stack, store each operand into it, then load; // the result as a vector.; // Create the stack frame object.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp:132,load,load,132,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,1,['load'],['load']
Performance,"// We can't move the second load backward, past a write, to merge; // with the first load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMParallelDSP.cpp:28,load,load,28,interpreter/llvm-project/llvm/lib/Target/ARM/ARMParallelDSP.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMParallelDSP.cpp,2,['load'],['load']
Performance,// We can't optimize if return value is used.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp:12,optimiz,optimize,12,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp,1,['optimiz'],['optimize']
Performance,// We can't optimize scalable types.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp:12,optimiz,optimize,12,interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,2,"['optimiz', 'scalab']","['optimize', 'scalable']"
Performance,"// We can't optimize this global unless all uses of it are *known* to be; // of the malloc value, not of the null initializer value (consider a use; // that compares the global's value against zero to see if the malloc has; // been reached). To do this, we check to see if all uses of the global; // would trap if the global were null: this proves that they must all; // happen after the malloc.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp:12,optimiz,optimize,12,interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,1,['optimiz'],['optimize']
Performance,"// We can't optimize this if the malloc itself is used in a complex way,; // for example, being stored into multiple globals. This allows the; // malloc to be stored into the specified global, loaded, gep, icmp'd.; // These are all things we could transform to using the global for.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp:12,optimiz,optimize,12,interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,2,"['load', 'optimiz']","['loaded', 'optimize']"
Performance,// We can't perform any more checking for type-dependent expressions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp:12,perform,perform,12,interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,1,['perform'],['perform']
Performance,// We can't perform dynamic stack realignment if we can't reserve the; // frame pointer register.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsRegisterInfo.cpp:12,perform,perform,12,interpreter/llvm-project/llvm/lib/Target/Mips/MipsRegisterInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsRegisterInfo.cpp,1,['perform'],['perform']
Performance,// We can't perform this conversion or binding.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplate.cpp:12,perform,perform,12,interpreter/llvm-project/clang/lib/Sema/SemaTemplate.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplate.cpp,1,['perform'],['perform']
Performance,// We can't perform this conversion.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplate.cpp:12,perform,perform,12,interpreter/llvm-project/clang/lib/Sema/SemaTemplate.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplate.cpp,2,['perform'],['perform']
Performance,// We can't perform this optimization for data whose alignment; // is insufficient for the instruction encoding.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp:12,perform,perform,12,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,2,"['optimiz', 'perform']","['optimization', 'perform']"
Performance,// We can't reasonably handle cases where the load or store extends past; // the end of the alloca's type and into its padding.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:46,load,load,46,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,1,['load'],['load']
Performance,// We can't replace an atomic load with one which isn't also atomic.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp:30,load,load,30,interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,1,['load'],['load']
Performance,"// We can't seem to determine the result latency of the def, assume it's 2.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp:41,latency,latency,41,interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp,1,['latency'],['latency']
Performance,"// We can't sink an instruction if it is a phi node, is not in the loop,; // may have side effects or may read from memory.; // TODO Could dor more granular checking to allow sinking a load past non-store instructions.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:185,load,load,185,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,1,['load'],['load']
Performance,// We can't sink the load if the loaded value could be modified between the; // load and the PHI.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombinePHI.cpp:21,load,load,21,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombinePHI.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombinePHI.cpp,3,['load'],"['load', 'loaded']"
Performance,// We can't sink the load if the loaded value could be modified between; // the load and the PHI.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombinePHI.cpp:21,load,load,21,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombinePHI.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombinePHI.cpp,3,['load'],"['load', 'loaded']"
Performance,"// We can't slide this mask vector down, indexed by its i1 elements.; // This poses a problem when we wish to extract a scalable vector which; // can't be re-expressed as a larger type. Just choose the slow path and; // extend to a larger type, then truncate back down.; // TODO: We could probably improve this when extracting certain fixed; // from fixed, where we can extract as i8 and shift the correct element; // right to reach the desired subvector?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:120,scalab,scalable,120,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['scalab'],['scalable']
Performance,"// We can't slide this mask vector up indexed by its i1 elements.; // This poses a problem when we wish to insert a scalable vector which; // can't be re-expressed as a larger type. Just choose the slow path and; // extend to a larger type, then truncate back down.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:116,scalab,scalable,116,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['scalab'],['scalable']
Performance,// We can't track ranges involving scalable types.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp:35,scalab,scalable,35,interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,1,['scalab'],['scalable']
Performance,// We can't track scalable types,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp:18,scalab,scalable,18,interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,1,['scalab'],['scalable']
Performance,// We can't unroll or use shuffles for scalable vectors.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorOps.cpp:39,scalab,scalable,39,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorOps.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeVectorOps.cpp,1,['scalab'],['scalable']
Performance,"// We cannot allow unaligned ops for unordered load/store, so reject; // anything where the alignment isn't at least the element size.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopIdiomRecognize.cpp:47,load,load,47,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopIdiomRecognize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopIdiomRecognize.cpp,1,['load'],['load']
Performance,// We cannot both require hardening the def of a load and its address.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:49,load,load,49,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,1,['load'],['load']
Performance,"// We cannot change the arguments if this TU does not define the function or; // if the linker may choose a function body from another TU, even if the; // nominal linkage indicates that other copies of the function have the same; // semantics. In the below example, the dead load from %p may not have been; // eliminated from the linker-chosen copy of f, so replacing %p with poison; // in callers may introduce undefined behavior.; //; // define linkonce_odr void @f(i32* %p) {; // %v = load i32 %p; // ret void; // }",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/DeadArgumentElimination.cpp:275,load,load,275,interpreter/llvm-project/llvm/lib/Transforms/IPO/DeadArgumentElimination.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/DeadArgumentElimination.cpp,2,['load'],['load']
Performance,// We cannot describe the location of dllimport'd entities: the; // computation of their address requires loads from the IAT.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfUnit.cpp:106,load,loads,106,interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfUnit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfUnit.cpp,1,['load'],['loads']
Performance,// We cannot describe the location of dllimport'd variables: the; // computation of their address requires loads from the IAT.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfCompileUnit.cpp:107,load,loads,107,interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfCompileUnit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfCompileUnit.cpp,1,['load'],['loads']
Performance,"// We cannot do this optimization if any pair of {RLD, LLD} is a; // predecessor to {RLD, LLD, CondNode}. As we've already compared the; // Loads, we only need to check if CondNode is a successor to one of the; // loads. We can further avoid this if there's no use of their chain; // value.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:21,optimiz,optimization,21,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,3,"['Load', 'load', 'optimiz']","['Loads', 'loads', 'optimization']"
Performance,"// We cannot easily widen alloca to a scalable alloca, as; // the result would need to be a vector of pointers.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:38,scalab,scalable,38,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,1,['scalab'],['scalable']
Performance,// We cannot estimate how long this call will take.; // Artificially set an arbitrarily high latency (100cy).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MCA/InstrBuilder.cpp:93,latency,latency,93,interpreter/llvm-project/llvm/lib/MCA/InstrBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MCA/InstrBuilder.cpp,1,['latency'],['latency']
Performance,// We cannot fold a load instruction into a def.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InlineSpiller.cpp:20,load,load,20,interpreter/llvm-project/llvm/lib/CodeGen/InlineSpiller.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InlineSpiller.cpp,1,['load'],['load']
Performance,"// We cannot initialize this element, so let PerformCopyInitialization; // produce the appropriate diagnostic. We already checked that this; // initialization will fail.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp:45,Perform,PerformCopyInitialization,45,interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,1,['Perform'],['PerformCopyInitialization']
Performance,// We cannot optimize an unsupported compare opcode or; // a mix of 32-bit and 64-bit comparisons,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp:13,optimiz,optimize,13,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp,1,['optimiz'],['optimize']
Performance,// We cannot optimize if there are multiple case labels jumping to; // this block. This check may get expensive when there are many; // case labels so we test for it last.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:13,optimiz,optimize,13,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,1,['optimiz'],['optimize']
Performance,// We cannot perform this optimization without wchar_size metadata.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp:13,perform,perform,13,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp,2,"['optimiz', 'perform']","['optimization', 'perform']"
Performance,// We cannot perform whole program devirtualization analysis on a vtable; // with public LTO visibility.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/WholeProgramDevirt.cpp:13,perform,perform,13,interpreter/llvm-project/llvm/lib/Transforms/IPO/WholeProgramDevirt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/WholeProgramDevirt.cpp,2,['perform'],['perform']
Performance,"// We cannot preserve ninf if nnan flag is not set.; // If X is NaN and Y is Inf then in original program we had NaN * NaN,; // while in optimized version NaN * Inf and this is a poison with ninf flag.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineMulDivRem.cpp:137,optimiz,optimized,137,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineMulDivRem.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineMulDivRem.cpp,1,['optimiz'],['optimized']
Performance,"// We cannot preserve ninf if nnan flag is not set.; // If X is NaN and Y is Inf then in original program we had NaN + NaN,; // while in optimized version NaN + Inf and this is a poison with ninf flag.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp:137,optimiz,optimized,137,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp,1,['optimiz'],['optimized']
Performance,"// We cannot scalarize scalable vectors, so return Invalid.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h:23,scalab,scalable,23,interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/BasicTTIImpl.h,3,['scalab'],['scalable']
Performance,// We cannot sink a load across a critical edge - there may be stores in; // other code paths.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineSink.cpp:20,load,load,20,interpreter/llvm-project/llvm/lib/CodeGen/MachineSink.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineSink.cpp,2,['load'],['load']
Performance,"// We cannot use #pragma clang module import because the on-demand modules; // may load a module in the middle of a function body for example. In this; // case this triggers an error:; // fatal error: import of module '...' appears within function '...'; //; // if (declare(""#pragma clang module import \"""" + M->Name + ""\"""") ==; // kSuccess); // return true;; // FIXME: What about importing submodules such as std.blah. This disables; // this functionality.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/Interpreter.cpp:83,load,load,83,interpreter/cling/lib/Interpreter/Interpreter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/Interpreter.cpp,1,['load'],['load']
Performance,"// We cannot use HS.lookupModuleMapFile(DE, /*IsFramework*/ false);; // because its internal call to getFile has CacheFailure set to true.; // In our case, modulemaps can appear any time due to ACLiC.; // Code copied from HS.lookupModuleMapFile.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:113,Cache,CacheFailure,113,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,1,['Cache'],['CacheFailure']
Performance,"// We cannot use sp as source/dest register here, thus we're using r4 to; // perform the calculations. We're emitting the following sequence:; // mov r4, sp; // -- use emitAligningInstructions to produce best sequence to zero; // -- out lower bits in r4; // mov sp, r4; // FIXME: It will be better just to find spare register here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMFrameLowering.cpp:77,perform,perform,77,interpreter/llvm-project/llvm/lib/Target/ARM/ARMFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMFrameLowering.cpp,1,['perform'],['perform']
Performance,"// We check earlier that we are within the authorized range, but; // we might still be out of the (default) learning range and since; // this is called before any branch is added to the cache, this means; // that the user's first GetEntry is this one which is outside of the; // learning range ... so let's do something sensible-ish.; // Note: we probably should also fix the learning range but we may; // or may not have enough information to know if we can move it; // (for example fEntryMin (eminOld right now) might be the default or user provided)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx:186,cache,cache,186,tree/tree/src/TTreeCache.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx,1,['cache'],['cache']
Performance,// We check here that the size of the memory operand fits within the size of; // the MMO. This is because the MMO might indicate only a possible address; // range instead of specifying the affected memory addresses precisely.; // TODO: Make MachineMemOperands aware of scalable vectors.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp:269,scalab,scalable,269,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,1,['scalab'],['scalable']
Performance,// We chose to canonicalize all idempotent operations to an single; // operation code and constant. This makes it easier for the rest of the; // optimizer to match easily. The choices of or w/0 and fadd w/-0.0 are; // arbitrary.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAtomicRMW.cpp:145,optimiz,optimizer,145,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAtomicRMW.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAtomicRMW.cpp,1,['optimiz'],['optimizer']
Performance,// We consider any PHI or select that results in a direct load or store of; // the same offset to be a viable use for slicing purposes. These uses; // are considered unsplittable and the size is the maximum loaded or stored; // size.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:58,load,load,58,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,2,['load'],"['load', 'loaded']"
Performance,"// We consider bitcasts and zero GEPs to be the same pointer value. Start by; // stripping bitcasts and zero GEPs, then we will recursively look at loads; // and stores through bitcasts and zero GEPs.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp:148,load,loads,148,interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp,1,['load'],['loads']
Performance,"// We could allow extending/narrowing FP loads/stores, but codegen is; // too inefficient so reject this for now.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp:41,load,loads,41,interpreter/llvm-project/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp,1,['load'],['loads']
Performance,"// We could also add some code to acquire an actual; // lock to prevent multi-thread issues",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx:72,multi-thread,multi-thread,72,tree/tree/src/TTree.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx,1,['multi-thread'],['multi-thread']
Performance,"// We could be called with an integer-typed operands during SCEV rewrites.; // Since the operand is an integer already, just perform zext/trunc/self cast.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp:125,perform,perform,125,interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,1,['perform'],['perform']
Performance,"// We could consider forcing the displacement into a register and; // using it as an index, but it would need to be carefully tuned.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp:126,tune,tuned,126,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp,1,['tune'],['tuned']
Performance,"// We could copy the data only if we need to apply a relocation to it. After; // testing, it seems there is no performance downside to doing the copy; // unconditionally, and it makes the code simpler.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DWARFLinker/Classic/DWARFLinker.cpp:111,perform,performance,111,interpreter/llvm-project/llvm/lib/DWARFLinker/Classic/DWARFLinker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DWARFLinker/Classic/DWARFLinker.cpp,2,['perform'],['performance']
Performance,"// We could create all of the aligned loads, and generate the valigns; // at the location of the first load, but for large load groups, this; // could create highly suboptimal code (there have been groups of 140+; // loads in real code).; // Instead, place the loads/valigns as close to the users as possible.; // In any case we need to have a mapping from the blocks of VSpan (the; // span covered by the pre-existing loads) to ASpan (the span covered; // by the aligned loads). There is a small problem, though: ASpan needs; // to have pointers to the loads/valigns, but we don't have these loads; // because we don't know where to put them yet. We find out by creating; // a section of ASpan that corresponds to values (blocks) from VSpan,; // and checking where the new load should be placed. We need to attach; // this location information to each block in ASpan somehow, so we put; // distincts values for Seg.Val in each ASpan.Blocks[i], and use a map; // to store the location for each Seg.Val.; // The distinct values happen to be Blocks[i].Seg.Val = &Blocks[i],; // which helps with printing ByteSpans without crashing when printing; // Segments with these temporary identifiers in place of Val.; // Populate the blocks first, to avoid reallocations of the vector; // interfering with generating the placeholder addresses.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp:38,load,loads,38,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp,10,['load'],"['load', 'loads']"
Performance,"// We could do a single 64-bit load here, but it's likely that the basic; // 32-bit and extract sequence is already present, and it is probably easier; // to CSE this. The loads should be mergeable later anyway.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUPromoteAlloca.cpp:31,load,load,31,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUPromoteAlloca.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUPromoteAlloca.cpp,2,['load'],"['load', 'loads']"
Performance,"// We could perform the transform with non-constant index, but prefer leaving; // it as GEP of GEP rather than GEP of add for now.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/ConstantFold.cpp:12,perform,perform,12,interpreter/llvm-project/llvm/lib/IR/ConstantFold.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/ConstantFold.cpp,1,['perform'],['perform']
Performance,"// We could potentially update the cached values we have with the new value,; // but it's simpler to just treat the old value as invalidated.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/PhiValues.cpp:35,cache,cached,35,interpreter/llvm-project/llvm/lib/Analysis/PhiValues.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/PhiValues.cpp,1,['cache'],['cached']
Performance,// We could really use specific intrinsic classes for masked loads; // and stores in IntrinsicInst.h.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp:61,load,loads,61,interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,1,['load'],['loads']
Performance,"// We could reset all the location values too; however either loadFromArray; // or setMPhis should be called before this object is re-used. Just; // clear Masks, they're definitely not needed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.h:62,load,loadFromArray,62,interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.h,1,['load'],['loadFromArray']
Performance,"// We could simplify extracts from other values. Note that nested extracts may; // already be simplified implicitly by the above: extract (extract (insert) ); // will be translated into extract ( insert ( extract ) ) first and then just; // the value inserted, if appropriate. Similarly for extracts from single-use; // loads: extract (extract (load)) will be translated to extract (load (gep)); // and if again single-use then via load (gep (gep)) to load (gep).; // However, double extracts from e.g. function arguments or return values; // aren't handled yet.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp:320,load,loads,320,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp,5,['load'],"['load', 'loads']"
Performance,"// We could speed-up some of the search by adding (the equivalent of); //; // if (cl->GetState() == kInterpreter) return cl; //; // In this case, if a ROOT dictionary was available when the TClass; // was first requested it would have been used and if a ROOT dictionary is; // loaded later on TClassTable::Add will take care of updating the TClass.; // So as far as ROOT dictionary are concerned, if the current TClass is; // in interpreted state, we are sure there is nothing to load.; //; // However (see TROOT::LoadClass), the TClass can also be loaded/provided; // by a user provided TClassGenerator. We have no way of knowing whether; // those do (or even can) behave the same way as the ROOT dictionary and; // have the 'dictionary is now available for use' step informs the existing; // TClass that their dictionary is now available.; //we may pass here in case of a dummy class created by TVirtualStreamerInfo",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:277,load,loaded,277,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,4,"['Load', 'load']","['LoadClass', 'load', 'loaded']"
Performance,"// We could try to optimize this to a fstat, but it is not a common; // operation.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-ar/llvm-ar.cpp:19,optimiz,optimize,19,interpreter/llvm-project/llvm/tools/llvm-ar/llvm-ar.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-ar/llvm-ar.cpp,1,['optimiz'],['optimize']
Performance,"// We couldn't load the module file because it is out-of-date. If the; // client can handle out-of-date, return it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp:15,load,load,15,interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,1,['load'],['load']
Performance,"// We couldn't use the direct restoration above, so; // perform the opposite conversion: tPOP_RET to tPOP.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/Thumb1FrameLowering.cpp:56,perform,perform,56,interpreter/llvm-project/llvm/lib/Target/ARM/Thumb1FrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/Thumb1FrameLowering.cpp,1,['perform'],['perform']
Performance,"// We create vector phi nodes for both integer and floating-point induction; // variables. Here, we determine the kind of arithmetic we will perform.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlanRecipes.cpp:141,perform,perform,141,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlanRecipes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlanRecipes.cpp,1,['perform'],['perform']
Performance,// We currently can't generate an appropriate shuffle for a scalable vector.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:60,scalab,scalable,60,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['scalab'],['scalable']
Performance,// We defer this expensive clobber walk until the cheap checks; // have been done on the source inside performCallSlotOptzn.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp:103,perform,performCallSlotOptzn,103,interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,1,['perform'],['performCallSlotOptzn']
Performance,// We define our scalable vector types for lmul=1 to use a 64 bit known; // minimum size. e.g. <vscale x 2 x i32>. VLENB is in bytes so we calculate; // vscale as VLENB / 8.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:17,scalab,scalable,17,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['scalab'],['scalable']
Performance,// We delay loading of the redeclaration chain to avoid deeply nested calls.; // We temporarily set the first (canonical) declaration as the previous one; // which is the one that matters and mark the real previous DeclID to be; // loaded & attached later on.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp:12,load,loading,12,interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp,2,['load'],"['loaded', 'loading']"
Performance,// We depend on the UREM by constant optimization in DAGCombiner that requires; // high multiply.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp:37,optimiz,optimization,37,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp,1,['optimiz'],['optimization']
Performance,"// We did not find a cached result for negation of V. While there,; // let's temporairly cache a placeholder value, with the idea that if later; // during negation we fetch it from cache, we'll know we're in a cycle.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineNegator.cpp:21,cache,cached,21,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineNegator.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineNegator.cpp,3,['cache'],"['cache', 'cached']"
Performance,"// We did not handle HW dependences in previous for loop,; // and we normally set Latency = 0 for Anti deps,; // so may have nodes in same cycle with Anti denpendent on HW regs.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachinePipeliner.cpp:82,Latency,Latency,82,interpreter/llvm-project/llvm/lib/CodeGen/MachinePipeliner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachinePipeliner.cpp,1,['Latency'],['Latency']
Performance,"// We didn't find a constant load, fallback to a shuffle mask decode.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp:29,load,load,29,interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86MCInstLower.cpp,1,['load'],['load']
Performance,// We didn't find anything by following the LHS to its root; now check; // the RHS against the cached set of ancestors.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ASTContext.cpp:95,cache,cached,95,interpreter/llvm-project/clang/lib/AST/ASTContext.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ASTContext.cpp,1,['cache'],['cached']
Performance,// We do a trivial form of DSE if there are two stores to the same; // location with no intervening loads. Delete the earlier store.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp:100,load,loads,100,interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,1,['load'],['loads']
Performance,"// We do checks for both fixed vector types and scalable vector types.; // This is the number of elements of fixed vector types,; // or the minimum number of elements of scalable vector types.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VectorCombine.cpp:48,scalab,scalable,48,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VectorCombine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VectorCombine.cpp,2,['scalab'],['scalable']
Performance,"// We do not check for one-use of the vector load because a broadcast load; // is expected to be a win for code size, register pressure, and possibly; // uops even if the original vector load is not eliminated.; // Reduce the vector load and shuffle to a broadcasted scalar load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:45,load,load,45,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,5,['load'],['load']
Performance,// We do not expect segment information to change when deserializing from; // the same binary profile file. This can happen if dynamic libraries are; // loaded/unloaded between profile dumping.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ProfileData/RawMemProfReader.cpp:153,load,loaded,153,interpreter/llvm-project/llvm/lib/ProfileData/RawMemProfReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ProfileData/RawMemProfReader.cpp,1,['load'],['loaded']
Performance,"// We do not expect that forgetting cached data for SCEVConstants will ever; // open any prospects for sharpening or introduce any correctness issues,; // so we don't bother storing their dependencies.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp:36,cache,cached,36,interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,1,['cache'],['cached']
Performance,"// We do not need to serialize constrained FP intrinsics against; // each other or against (nonvolatile) loads, so they can be; // chained like loads.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp:105,load,loads,105,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,2,['load'],['loads']
Performance,// We do not need to touch the higher bits for regular loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPURegisterBankInfo.cpp:55,load,loads,55,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPURegisterBankInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPURegisterBankInfo.cpp,1,['load'],['loads']
Performance,"// We do not need to track data through LandingPadInst.; //; // For the C++ exceptions, if a value is thrown, this value will be stored; // in a memory location provided by __cxa_allocate_exception(...) (on the; // throw side) or __cxa_begin_catch(...) (on the catch side).; // This memory will have a shadow, so with the loads and stores we will be; // able to propagate labels on data thrown through exceptions, without any; // special handling of the LandingPadInst.; //; // The second element in the pair result of the LandingPadInst is a; // register value, but it is for a type ID and should never be tainted.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp:322,load,loads,322,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp,1,['load'],['loads']
Performance,"// We do not optimize branches for machine basic blocks ending sections, as; // their adjacent block might be reordered by the linker.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/BasicBlockSections.cpp:13,optimiz,optimize,13,interpreter/llvm-project/llvm/lib/CodeGen/BasicBlockSections.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/BasicBlockSections.cpp,1,['optimiz'],['optimize']
Performance,"// We do not propagate the old load's debug location, because the new; // load now lives in a different BB, and we want to avoid a jumpy line; // table.; // FIXME: How do we retain source locations without causing poor debugging; // behavior?; // Add the newly created load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp:31,load,load,31,interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,3,['load'],['load']
Performance,"// We do this custom legalization to convert G_GLOBAL_VALUE into target ADRP +; // G_ADD_LOW instructions.; // By splitting this here, we can optimize accesses in the small code model by; // folding in the G_ADD_LOW into the load/store offset.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64LegalizerInfo.cpp:142,optimiz,optimize,142,interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64LegalizerInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64LegalizerInfo.cpp,2,"['load', 'optimiz']","['load', 'optimize']"
Performance,"// We don't actually check at this point whether there is a valid; // copy/move constructor, since overloading just assumes that it; // exists. When we actually perform initialization, we'll find the; // appropriate constructor to copy the returned object, if needed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp:161,perform,perform,161,interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,1,['perform'],['perform']
Performance,"// We don't analyze GV references during attribute propagation, so; // GV with non-trivial initializer can be marked either read or; // write-only.; // Importing definiton of readonly GV with non-trivial initializer; // allows us doing some extra optimizations (like converting indirect; // calls to direct).; // Definition of writeonly GV with non-trivial initializer should also; // be imported. Not doing so will result in:; // a) GV internalization in source module (because it's writeonly); // b) Importing of GV declaration to destination module as a result; // of promotion.; // c) Link error (external declaration with internal definition).; // However we do not promote objects referenced by writeonly GV; // initializer by means of converting it to 'zeroinitializer'",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/ModuleSummaryIndex.cpp:247,optimiz,optimizations,247,interpreter/llvm-project/llvm/lib/IR/ModuleSummaryIndex.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/ModuleSummaryIndex.cpp,1,['optimiz'],['optimizations']
Performance,"// We don't consider globals as writable: While the physical memory is writable,; // we may not have provenance to perform the write.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/AliasAnalysis.cpp:115,perform,perform,115,interpreter/llvm-project/llvm/lib/Analysis/AliasAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/AliasAnalysis.cpp,1,['perform'],['perform']
Performance,"// We don't currently model the OOO reorder buffer, so consider all; // scheduled MOps to be ""retired"". We do loosely model in-order resource; // latency. If this instruction uses an in-order resource, account for any; // likely stall cycles.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp:146,latency,latency,146,interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp,1,['latency'],['latency']
Performance,"// We don't expect to get there, the Index is loaded when we encounter; // the offset.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Reader/MetadataLoader.cpp:46,load,loaded,46,interpreter/llvm-project/llvm/lib/Bitcode/Reader/MetadataLoader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Reader/MetadataLoader.cpp,1,['load'],['loaded']
Performance,"// We don't expect to see any of these, if we see one, give up on; // lazy-loading and fallback.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Reader/MetadataLoader.cpp:75,load,loading,75,interpreter/llvm-project/llvm/lib/Bitcode/Reader/MetadataLoader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Reader/MetadataLoader.cpp,1,['load'],['loading']
Performance,// We don't have a cached result. Lookup the variable declaration and create; // a new entry representing it.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ComparisonCategories.cpp:19,cache,cached,19,interpreter/llvm-project/clang/lib/AST/ComparisonCategories.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ComparisonCategories.cpp,1,['cache'],['cached']
Performance,// We don't have extending load instruction on vector registers.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:27,load,load,27,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,1,['load'],['load']
Performance,// We don't have stat information or can't defer looking this file up.; // Perform the lookup now.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/ModuleMap.cpp:75,Perform,Perform,75,interpreter/llvm-project/clang/lib/Lex/ModuleMap.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/ModuleMap.cpp,1,['Perform'],['Perform']
Performance,"// We don't have the ability to slide mask vectors down indexed by their i1; // elements; the smallest we can do is i8. Often we are able to bitcast to; // equivalent i8 vectors. Note that when extracting a fixed-length vector; // from a scalable one, we might not necessarily have enough scalable; // elements to safely divide by 8: v8i1 = extract nxv1i1 is valid.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:238,scalab,scalable,238,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,2,['scalab'],['scalable']
Performance,"// We don't have the ability to slide mask vectors up indexed by their i1; // elements; the smallest we can do is i8. Often we are able to bitcast to; // equivalent i8 vectors. Note that when inserting a fixed-length vector; // into a scalable one, we might not necessarily have enough scalable; // elements to safely divide by 8: nxv1i1 = insert nxv1i1, v4i1 is valid.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:235,scalab,scalable,235,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,2,['scalab'],['scalable']
Performance,"// We don't keep a cache entry for every physical register, that would use too; // much memory. Instead, a fixed number of cache entries are used in a round-; // robin manner.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterferenceCache.h:19,cache,cache,19,interpreter/llvm-project/llvm/lib/CodeGen/InterferenceCache.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterferenceCache.h,2,['cache'],['cache']
Performance,// We don't know the pointer alignment (could be unaligned SSE load!).; // Have to assume to worst case.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp:63,load,load,63,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp,1,['load'],['load']
Performance,// We don't know the size of scalable types at compile time so we cannot; // create an integer of the equivalent size.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:29,scalab,scalable,29,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['scalab'],['scalable']
Performance,"// We don't know whether this vector contains entirely base pointers or; // not. To be conservatively correct, we treat it as a BDV and will; // duplicate code as needed to construct a parallel vector of bases.; // TODO: There a number of local optimizations which could be applied here; // for particular sufflevector patterns.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp:245,optimiz,optimizations,245,interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,1,['optimiz'],['optimizations']
Performance,"// We don't need to do identifier table lookups in C++ modules (we preload; // all interesting declarations, and don't need to use the scope for name; // lookups). Perform the lookup in PCH files, though, since we don't build; // a complete initial identifier table if we're carrying on from a PCH.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp:164,Perform,Perform,164,interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,1,['Perform'],['Perform']
Performance,// We don't need to serialize loads against other loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp:30,load,loads,30,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,2,['load'],['loads']
Performance,// We don't optimize this case.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp:12,optimiz,optimize,12,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp,1,['optimiz'],['optimize']
Performance,// We don't perform ADL for implicit declarations of builtins.; // Verify that this was correctly set up.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp:12,perform,perform,12,interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,1,['perform'],['perform']
Performance,// We don't perform ADL in C.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp:12,perform,perform,12,interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,1,['perform'],['perform']
Performance,"// We don't retain the receiver in delegate init calls, and this is; // safe because the receiver value is always loaded from 'self',; // which we zero out. We don't want to Block_copy block receivers,; // though.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp:114,load,loaded,114,interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp,1,['load'],['loaded']
Performance,"// We don't set HasCalls on MFI here yet because call lowering may decide to; // optimize into tail calls. Instead, we defer that to selection where a final; // scan is done to check if any instructions are calls.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/IRTranslator.cpp:81,optimiz,optimize,81,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/IRTranslator.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/IRTranslator.cpp,1,['optimiz'],['optimize']
Performance,// We don't support other cases than those above for scalable vectors at; // the moment.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp:53,scalab,scalable,53,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,1,['scalab'],['scalable']
Performance,// We don't support post-load hardening of vectors.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:25,load,load,25,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,1,['load'],['load']
Performance,// We don't support scalable global variables.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalMerge.cpp:20,scalab,scalable,20,interpreter/llvm-project/llvm/lib/CodeGen/GlobalMerge.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalMerge.cpp,1,['scalab'],['scalable']
Performance,// We don't support scalable vectors at the moment.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp:20,scalab,scalable,20,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,2,['scalab'],['scalable']
Performance,// We don't support scalable vectors in this pass.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp:20,scalab,scalable,20,interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp,1,['scalab'],['scalable']
Performance,// We don't want to break loads with padding here as we'd loose; // the knowledge that padding exists for the rest of the pipeline.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp:26,load,loads,26,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp,2,['load'],['loads']
Performance,"// We don't want to double prefetch individual cache lines. If this; // access is known to be within one cache line of some other one that; // has already been prefetched, then don't prefetch this one as well.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopDataPrefetch.cpp:47,cache,cache,47,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopDataPrefetch.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopDataPrefetch.cpp,2,['cache'],['cache']
Performance,"// We don't want to get negative const from memory pool too early, as the; // created entry will not be deleted even if it has no users. Since all; // operand of Leaf and Root are virtual register, we use zero register; // here as a placeholder. When the InsInstrs is selected in; // MachineCombiner, we call finalizeInsInstrs to replace the zero register; // with a virtual register which is a load from constant pool.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp:395,load,load,395,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,1,['load'],['load']
Performance,// We don't want to go crazy with the recursion here. This isn't a super; // important optimization.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:87,optimiz,optimization,87,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['optimiz'],['optimization']
Performance,// We don't want to perform completeness checks on the main file or in; // system headers.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaType.cpp:20,perform,perform,20,interpreter/llvm-project/clang/lib/Sema/SemaType.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaType.cpp,1,['perform'],['perform']
Performance,// We don't want to propagate the extends unless there's a good chance that; // they'll be optimized in some way.; // Collect the unique incoming values.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:91,optimiz,optimized,91,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,1,['optimiz'],['optimized']
Performance,"// We don't want to put in the same block; // two high latency instructions that depend; // on each other.; // One way would be to check canAddEdge; // in both directions, but that currently is not; // enough because there the high latency order is; // enforced (via links).; // Instead, look at the dependencies between the; // high latency instructions and deduce if it is; // a data dependency or not.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMachineScheduler.cpp:55,latency,latency,55,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMachineScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMachineScheduler.cpp,3,['latency'],['latency']
Performance,"// We don't want to reason about speculating loads. Note -- at this point; // we should have already filtered out all of the other non-speculatable; // things, like calls and stores.; // We also do not want to hoist stores because it might change the memory; // while the FaultingMI may result in faulting.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ImplicitNullChecks.cpp:45,load,loads,45,interpreter/llvm-project/llvm/lib/CodeGen/ImplicitNullChecks.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ImplicitNullChecks.cpp,1,['load'],['loads']
Performance,// We don't yet handle removing loads with ordering of any kind.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp:32,load,loads,32,interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,1,['load'],['loads']
Performance,// We don't/shouldn't load the standard c++20 modules when preprocessing.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/Preprocessor.cpp:22,load,load,22,interpreter/llvm-project/clang/lib/Lex/Preprocessor.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/Preprocessor.cpp,1,['load'],['load']
Performance,// We either succeeded or failed to load the named module.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Lex/ModuleLoader.h:36,load,load,36,interpreter/llvm-project/clang/include/clang/Lex/ModuleLoader.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Lex/ModuleLoader.h,1,['load'],['load']
Performance,"// We emit the checksum info for files. This is used by debuggers to; // determine if a pdb matches the source before loading it. Visual Studio,; // for instance, will display a warning that the breakpoints are not valid if; // the pdb does not match the source.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/CodeViewDebug.cpp:118,load,loading,118,interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/CodeViewDebug.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/CodeViewDebug.cpp,1,['load'],['loading']
Performance,"// We encountered an error in parsing 'decltype(...)' so lets annotate all; // the tokens in the backtracking cache - that we likely had to skip over; // to get to a token that allows us to resume parsing, such as a; // semi-colon.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseDeclCXX.cpp:110,cache,cache,110,interpreter/llvm-project/clang/lib/Parse/ParseDeclCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseDeclCXX.cpp,1,['cache'],['cache']
Performance,"// We erase, from the ForwardedRegWorklist, those forwarding registers for; // which we successfully describe a loaded value (by using; // the describeLoadedValue()). For those remaining arguments in the working; // list, for which we do not describe a loaded value by; // the describeLoadedValue(), we try to generate an entry value expression; // for their call site value description, if the call is within the entry MBB.; // TODO: Handle situations when call site parameter value can be described; // as the entry value within basic blocks other than the first one.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfDebug.cpp:112,load,loaded,112,interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfDebug.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfDebug.cpp,2,['load'],['loaded']
Performance,"// We expect to see several GEP users, casted to the appropriate type and; // loaded.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerKernelAttributes.cpp:78,load,loaded,78,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerKernelAttributes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerKernelAttributes.cpp,1,['load'],['loaded']
Performance,// We explicitly allow unknown phis as long as they are already used by; // the loop exit test. This is legal since performing LFTR could not; // increase the number of undef users.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/IndVarSimplify.cpp:116,perform,performing,116,interpreter/llvm-project/llvm/lib/Transforms/Scalar/IndVarSimplify.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/IndVarSimplify.cpp,1,['perform'],['performing']
Performance,"// We explore the inputs of the shuffle in order to see if we find the; // source of the extract_vector_elt. If so, we can use it to modify the; // shuffle rather than perform an insert_vector_elt.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:168,perform,perform,168,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['perform'],['perform']
Performance,"// We failed to factorize two MULs, so now the Muls are left outside the; // queue... add them back.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp:77,queue,queue,77,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelDAGToDAG.cpp,1,['queue'],['queue']
Performance,"// We failed to load one of the dependency.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx:16,load,load,16,core/base/src/TSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx,1,['load'],['load']
Performance,// We faked up this definition data because we found a class for which we'd; // not yet loaded the definition. Replace it with the real thing now.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp:88,load,loaded,88,interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp,1,['load'],['loaded']
Performance,"// We first try with a lower MaxDepth, assuming that the path to common; // operands between From and To is relatively short. This significantly; // improves performance in the common case. The initial MaxDepth is big; // enough to avoid retry in the common case; the last MaxDepth is large; // enough to avoid having to use the fallback below (and protects from; // potential stack exhaustion from recursion).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp:158,perform,performance,158,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,1,['perform'],['performance']
Performance,"// We first use the same normalization set to re-evaluate, then a different; // one to confuse to first trigger the cache and then have a another; // reference.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/test/testRooAddPdf.cxx:116,cache,cache,116,roofit/roofitcore/test/testRooAddPdf.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/test/testRooAddPdf.cxx,1,['cache'],['cache']
Performance,// We found a load for each register. Let's check if each load satisfies the; // pattern.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:14,load,load,14,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,2,['load'],['load']
Performance,// We found a load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:14,load,load,14,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,1,['load'],['load']
Performance,// We found a match. Perform the conversions on the arguments and move on.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp:21,Perform,Perform,21,interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp,1,['Perform'],['Perform']
Performance,"// We found a remapping. Try to load the resulting, remapped source.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/ASTUnit.cpp:32,load,load,32,interpreter/llvm-project/clang/lib/Frontend/ASTUnit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/ASTUnit.cpp,1,['load'],['load']
Performance,"// We found a store forward block, break the memcpy's load and store; // into smaller copies such that each smaller store that was causing; // a store block would now be copied separately.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86AvoidStoreForwardingBlocks.cpp:54,load,load,54,interpreter/llvm-project/llvm/lib/Target/X86/X86AvoidStoreForwardingBlocks.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86AvoidStoreForwardingBlocks.cpp,1,['load'],['load']
Performance,// We found a store to the alloca before a load. The alloca is not; // actually live-in here.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp:43,load,load,43,interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp,1,['load'],['load']
Performance,"// We found a type within the ambiguous lookup; diagnose the; // ambiguity and then return that type. This might be the right; // answer, or it might not be, but it suppresses any attempt to; // perform the name lookup again.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp:195,perform,perform,195,interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp,1,['perform'],['perform']
Performance,// We found an instruction that may write to the loaded memory.; // We can try to promote at this position instead of the store; // position if nothing aliases the store memory after this and the store; // destination is not in the range.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp:49,load,loaded,49,interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,1,['load'],['loaded']
Performance,"// We found an opportunity. Reverse the operands from the add; // immediate and substitute them into the load or store. If; // needed, update the target flags for the immediate operand to; // reflect the necessary relocation information.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp:105,load,load,105,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,1,['load'],['load']
Performance,// We found indirect branches and targets that need to be instrumented to; // harden loads within them. Walk the blocks of the function (to get a stable; // ordering) and instrument each target of an indirect branch.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:85,load,loads,85,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,1,['load'],['loads']
Performance,// We found the symbol in our global table. It was probably in a; // Module that we loaded previously.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyld.cpp:84,load,loaded,84,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyld.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyld.cpp,1,['load'],['loaded']
Performance,"// We have Native ARC, so set nonlazybind attribute for performance",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp:56,perform,performance,56,interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp,2,['perform'],['performance']
Performance,"// We have a bunch of loads being OR'd together. Using the addresses + offsets; // we found before, check if this corresponds to a big or little endian byte; // pattern. If it does, then we can represent it using a load + possibly a; // BSWAP.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:22,load,loads,22,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,2,['load'],"['load', 'loads']"
Performance,"// We have a cache for repeated linkage/visibility computations. This saves us; // from exponential behavior in heavily templated code, such as:; //; // template <typename T, typename V> struct {};; // using A = int;; // using B = Foo<A, A>;; // using C = Foo<B, B>;; // using D = Foo<C, C>;; //; // The integer represents an LVComputationKind.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/Linkage.h:13,cache,cache,13,interpreter/llvm-project/clang/lib/AST/Linkage.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/Linkage.h,1,['cache'],['cache']
Performance,"// We have a cached item which is not a repeated but we might still; // have some Actions triggered by a rule that affect real; // data member(s).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TBranchElement.cxx:13,cache,cached,13,tree/tree/src/TBranchElement.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TBranchElement.cxx,1,['cache'],['cached']
Performance,"// We have a class for which the list was not loaded fully at; // first use.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:46,load,loaded,46,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,1,['load'],['loaded']
Performance,// We have a collection of non-OR instructions. Figure out how wide each of; // the small loads should be based off of the number of potential loads we; // found.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:90,load,loads,90,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,2,['load'],['loads']
Performance,"// We have a constant initializer, but a nontrivial destructor. We still; // need to perform a guarded ""initialization"" in order to register the; // destructor.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDecl.cpp:85,perform,perform,85,interpreter/llvm-project/clang/lib/CodeGen/CGDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDecl.cpp,1,['perform'],['perform']
Performance,// We have a derived-to-base cast that produces either an rvalue or an; // lvalue. Perform that cast.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp:83,Perform,Perform,83,interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,1,['Perform'],['Perform']
Performance,// We have a divergent offset. Emit a MUBUF buffer load instead. We can; // assume that the buffer is unswizzled.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:51,load,load,51,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,1,['load'],['load']
Performance,"// We have a fully cached result for this query then we can just return the; // cached results and populate the visited set. However, we have to verify; // that we don't already have conflicting results for these blocks. Check; // to ensure that if a block in the results set is in the visited set that; // it was for the same pointer query.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp:19,cache,cached,19,interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,2,['cache'],['cached']
Performance,"// We have a loaded class, let's make sure that if we have a collection; // it is also loaded.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfo.cxx:13,load,loaded,13,io/io/src/TStreamerInfo.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfo.cxx,2,['load'],['loaded']
Performance,"// We have a pointer mismatch in a block. Just return false, saying; // that something was clobbered in this result. We could also do a; // non-fully cached query, but there is little point in doing this.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp:150,cache,cached,150,interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,1,['cache'],['cached']
Performance,// We have a uniform instruction so we want to use an SMRD load,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPURegisterBankInfo.cpp:59,load,load,59,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPURegisterBankInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPURegisterBankInfo.cpp,1,['load'],['load']
Performance,"// We have already loaded the library.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:19,load,loaded,19,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,1,['load'],['loaded']
Performance,// We have already looked into the initial namespace; seed the queue; // with its using-children.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp:63,queue,queue,63,interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,1,['queue'],['queue']
Performance,// We have already performed the lookup into the translation unit.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp:19,perform,performed,19,interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp,1,['perform'],['performed']
Performance,"// We have an aggregate being loaded, split it apart.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:30,load,loaded,30,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,1,['load'],['loaded']
Performance,"// We have an extending-load. The instruction we selected operates on the; // smaller type, but the SDNode we are replacing has the larger type. We; // need to emit a CVT to make the types match.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp:24,load,load,24,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp,1,['load'],['load']
Performance,// We have an umbrella header or directory that doesn't actually include; // all of the headers within the directory it covers. Complain about; // this missing submodule and recover by forgetting that we ever saw; // this submodule.; // FIXME: Should we detect this at module load time? It seems fairly; // expensive (and rare).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp:276,load,load,276,interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,1,['load'],['load']
Performance,// We have at least added all these contexts to the queue.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp:52,queue,queue,52,interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,1,['queue'],['queue']
Performance,"// We have collected all loads and stores.; // FIXME: many of these accesses do not need to be checked for races; // (e.g. variables that do not escape, etc).; // Instrument memory accesses only if we want to report bugs in the function.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/ThreadSanitizer.cpp:25,load,loads,25,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/ThreadSanitizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/ThreadSanitizer.cpp,1,['load'],['loads']
Performance,"// We have dedicated lowering for unpredicated uniform loads and; // stores. Note that even with tail folding we know that at least; // one lane is active (i.e. generalized predication is not possible; // here), and the logic below depends on this fact.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:55,load,loads,55,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,1,['load'],['loads']
Performance,// We have finished with the filter processings. Now it's time to choose; // the best performing filter.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/DecoderEmitter.cpp:86,perform,performing,86,interpreter/llvm-project/llvm/utils/TableGen/DecoderEmitter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/DecoderEmitter.cpp,1,['perform'],['performing']
Performance,// We have identified all uses of GV into loads and stores. Now check if all; // of them are known not to depend on the value of the global at the function; // entry point. We do this by ensuring that every load is dominated by at; // least one store.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp:42,load,loads,42,interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalOpt.cpp,2,['load'],"['load', 'loads']"
Performance,// We have indexed loads for all legal index types. Indices are always; // zero extended,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:19,load,loads,19,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['load'],['loads']
Performance,"// We have no reason to disallow reducing the load width, so allow it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:46,load,load,46,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['load'],['load']
Performance,"// We have not been able to find a loaded TClass, return the Emulated; // TClass if we have one.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:35,load,loaded,35,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,1,['load'],['loaded']
Performance,"// We have not yet looked into these namespaces, much less added; // their ""using-children"" to the queue.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp:99,queue,queue,99,interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,1,['queue'],['queue']
Performance,"// We have resolved the scope specifier to a particular declaration; // contex, and will perform name lookup in that context.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp:89,perform,perform,89,interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,1,['perform'],['perform']
Performance,// We have sign-extended loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelLowering.cpp:25,load,loads,25,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonISelLowering.cpp,1,['load'],['loads']
Performance,// We have taken the address of a pointer to member; // function. Perform the computation here so that we get the; // appropriate pointer to member type.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp:66,Perform,Perform,66,interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,1,['Perform'],['Perform']
Performance,"// We have the dictionary but do not have the constructor wrapper,; // so the dictionary was not generated by rootcint (it was made either; // by cint or by some external mechanism). Let's try to create the; // object by having the interpreter call the new operator, either the; // class library is loaded and there is a default constructor we can; // call, or the class is interpreted and we will call the default; // constructor that way, or no default constructor is available and; // we fail.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:299,load,loaded,299,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,1,['load'],['loaded']
Performance,"// We have the dictionary but do not have the; // array delete wrapper, so the dictionary was; // not generated by rootcint. Let's try to; // delete the array by having the interpreter; // call the array delete operator, hopefully; // the class library is loaded and there will be; // a destructor we can call.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:256,load,loaded,256,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,1,['load'],['loaded']
Performance,"// We have the dictionary but do not have the; // constructor wrapper, so the dictionary was; // not generated by rootcint. Let's try to; // create the object by having the interpreter; // call the new operator, hopefully the class; // library is loaded and there will be a default; // constructor we can call.; // [This is very unlikely to work, but who knows!]",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:247,load,loaded,247,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,3,['load'],['loaded']
Performance,"// We have the dictionary but do not have the; // destruct/delete wrapper, so the dictionary was; // not generated by rootcint (it could have been; // created by cint or by some external mechanism).; // Let's have the interpreter call the destructor,; // either the code will be in a loaded library,; // or it will be interpreted, otherwise we fail; // because there is no destructor code at all.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:284,load,loaded,284,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,1,['load'],['loaded']
Performance,// We have the option to use the safe-divisor idiom to avoid predication.; // The cost based decision here will always select safe-divisor for; // scalable vectors as scalarization isn't legal.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:147,scalab,scalable,147,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,1,['scalab'],['scalable']
Performance,"// We have to check each of the operands of the token factor for ""small""; // token factors, so we queue them up. Adding the operands to the queue; // (stack) in reverse order maintains the original order and increases the; // likelihood that getNode will find a matching token factor (CSE.)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:98,queue,queue,98,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,['queue'],['queue']
Performance,// We have to disable runtime checks in order to enable optimizations. This is; // done for the entire file because the problem is actually observed in STL; // template functions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalityPredicates.cpp:56,optimiz,optimizations,56,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalityPredicates.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalityPredicates.cpp,1,['optimiz'],['optimizations']
Performance,// We have to enforce sequential consistency by performing a; // serialization operation after the store.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:48,perform,performing,48,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,2,['perform'],['performing']
Performance,"// We have to get the FAM via the MAM, rather than directly use a passed in; // FAM because if MAM has not cached the FAM, it won't invalidate function; // analyses in FAM.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/StandardInstrumentations.cpp:107,cache,cached,107,interpreter/llvm-project/llvm/lib/Passes/StandardInstrumentations.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/StandardInstrumentations.cpp,1,['cache'],['cached']
Performance,"// We have to maintain the illusion that the variable is; // zero-initialized. If the variable might be accessed in its; // initializer, zero-initialize before running the initializer, then; // actually perform the initialization with an assign.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDecl.cpp:203,perform,perform,203,interpreter/llvm-project/clang/lib/CodeGen/CGDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDecl.cpp,1,['perform'],['perform']
Performance,// We have to work around a name lookup bug here where negative lookup; // results for these names get cached in namespace lookup tables (these; // names should never be looked up in a namespace).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp:103,cache,cached,103,interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp,1,['cache'],['cached']
Performance,"// We haven't looked here before. Load a module map, if there is; // one.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/ModuleMap.cpp:34,Load,Load,34,interpreter/llvm-project/clang/lib/Lex/ModuleMap.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/ModuleMap.cpp,1,['Load'],['Load']
Performance,// We haven't processed this record type before.; // Queue up this vtable for possible deferred emission.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/MicrosoftCXXABI.cpp:53,Queue,Queue,53,interpreter/llvm-project/clang/lib/CodeGen/MicrosoftCXXABI.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/MicrosoftCXXABI.cpp,1,['Queue'],['Queue']
Performance,// We haven't seen this type before. Assign it a new ID and put it; // into the queue of types to emit.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp:80,queue,queue,80,interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp,1,['queue'],['queue']
Performance,// We hit this case with the lambda conversion-to-block optimization;; // we don't want any extra casts here.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp:56,optimiz,optimization,56,interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp,1,['optimiz'],['optimization']
Performance,// We identified the magic. Assume that we can load it -- we'll reset; // in the default case.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-jitlink/llvm-jitlink.cpp:47,load,load,47,interpreter/llvm-project/llvm/tools/llvm-jitlink/llvm-jitlink.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-jitlink/llvm-jitlink.cpp,1,['load'],['load']
Performance,"// We implicitly enable these when we have a write prefix supporting cache; // level OR if we have prfchw, but don't already have a read prefetch from; // 3dnow.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h:69,cache,cache,69,interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86Subtarget.h,1,['cache'],['cache']
Performance,// We introduce this threshold to help performance of instrumentation based; // PGO before we actually hook up inliner with analysis passes such as BPI and; // BFI.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InlineCost.cpp:39,perform,performance,39,interpreter/llvm-project/llvm/lib/Analysis/InlineCost.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/InlineCost.cpp,1,['perform'],['performance']
Performance,"// We introduced a cycle though, so update the loads operands, making sure; // to use the original store's chain as an incoming chain.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp:47,load,loads,47,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,1,['load'],['loads']
Performance,// We just loaded a module map file; check whether the module is; // available now.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp:11,load,loaded,11,interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/HeaderSearch.cpp,1,['load'],['loaded']
Performance,"// We keep our own list of retained types, because we need to look; // up the final type in the type cache.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp:101,cache,cache,101,interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp,1,['cache'],['cache']
Performance,"// We know S is for Ptr, the operand on a load/store, so doesn't wrap.; // If both parts are NonNegative, the end result will be NonNegative",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/DependenceAnalysis.cpp:42,load,load,42,interpreter/llvm-project/llvm/lib/Analysis/DependenceAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/DependenceAnalysis.cpp,1,['load'],['load']
Performance,"// We know it's safe to put the load at BasePos, but we'd prefer to put; // it at ""Where"". To see if the load is safe to be placed at Where, put; // it there first and then check if it's safe to move it to BasePos.; // If not, then the load needs to be placed at BasePos.; // We can't do this check proactively because we need the load to exist; // in order to check legality.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp:32,load,load,32,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp,4,['load'],['load']
Performance,// We know that all LoadInst are within the same BB. This guarantees that; // either everything or nothing is loaded.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp:20,Load,LoadInst,20,interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedLoadCombinePass.cpp,2,"['Load', 'load']","['LoadInst', 'loaded']"
Performance,"// We know that all PHIs in non-header blocks are converted into selects, so; // we don't have to worry about the insertion order and we can just use the; // builder. At this point we generate the predication tree. There may be; // duplications since this is a simple recursive scan, but future; // optimizations will clean it up.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:299,optimiz,optimizations,299,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,1,['optimiz'],['optimizations']
Performance,"// We know that all PHIs in non-header blocks are converted into; // selects, so we don't have to worry about the insertion order and we; // can just use the builder.; // At this point we generate the predication tree. There may be; // duplications since this is a simple recursive scan, but future; // optimizations will clean it up.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlanRecipes.cpp:303,optimiz,optimizations,303,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlanRecipes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlanRecipes.cpp,1,['optimiz'],['optimizations']
Performance,// We know that candidate stores are in order and of correct; // shape. While there is no mergeable sequence from the; // beginning one may start later in the sequence. The only; // reason a merge of size N could have failed where another of; // the same size would not have is if the alignment or either; // the load or store has improved. Drop as many candidates as we; // can here.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:313,load,load,313,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,"// We know that the derived-to-base conversion is ambiguous, and; // we're going to produce a diagnostic. Perform the derived-to-base; // search just one more time to compute all of the possible paths so; // that we can print them out. This is more expensive than any of; // the previous derived-to-base checks we've done, but at this point; // performance isn't as much of an issue.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp:106,Perform,Perform,106,interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp,2,"['Perform', 'perform']","['Perform', 'performance']"
Performance,"// We know that the load has a single use, but don't know what it is. If it; // isn't one of the folded instructions, then we can't succeed here. Handle; // this by scanning the single-use users of the load until we get to FoldInst.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/FastISel.cpp:20,load,load,20,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/FastISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/FastISel.cpp,2,['load'],['load']
Performance,"// We know that the stores in the candidate are adjacent.; // Now we need to check if any potential aliasing instructions recorded; // during the search alias with load/stores added to the candidate after.; // For example, if we have the candidate:; // C.Stores = [ST1, ST2, ST3, ST4]; // and after seeing ST2 we saw a load LD1, which did not alias with ST1 or; // ST2, then we would have recorded it into the PotentialAliases structure; // with the associated index value of ""1"". Then we see ST3 and ST4 and add; // them to the candidate group. We know that LD1 does not alias with ST1 or; // ST2, since we already did that check. However we don't yet know if it; // may alias ST3 and ST4, so we perform those checks now.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LoadStoreOpt.cpp:164,load,load,164,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LoadStoreOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LoadStoreOpt.cpp,3,"['load', 'perform']","['load', 'perform']"
Performance,// We know that this method is only called when the mem transfer fully; // provides the bits for the load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/VNCoercion.cpp:101,load,load,101,interpreter/llvm-project/llvm/lib/Transforms/Utils/VNCoercion.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/VNCoercion.cpp,2,['load'],['load']
Performance,"// We know we can hoist the load, but don't have a guaranteed store.; // Check whether the location is writable and thread-local. If it is, then we; // can insert stores along paths which originally didn't have them without; // violating the memory model.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp:28,load,load,28,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp,1,['load'],['load']
Performance,"// We lazily load the decls block, but we want to set up the; // DeclsCursor cursor to point into it. Clone our current bitcode; // cursor to it, enter the block and read the abbrevs in that block.; // With the main cursor, we just skip over it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp:13,load,load,13,interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,1,['load'],['load']
Performance,"// We lazy-load module-level metadata: we build an index for each record, and; // then load individual record as needed, starting with the named metadata.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Reader/MetadataLoader.cpp:11,load,load,11,interpreter/llvm-project/llvm/lib/Bitcode/Reader/MetadataLoader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Reader/MetadataLoader.cpp,2,['load'],['load']
Performance,"// We looking for a root node which is an ancestor to all mergable; // stores. We search up through a load, to our root and then down; // through all children. For instance we will find Store{1,2,3} if; // St is Store1, Store2. or Store3 where the root is not a load; // which always true for nonvolatile ops. TODO: Expand; // the search to find all valid candidates through multiple layers of loads.; //; // Root; // |-------|-------|; // Load Load Store3; // | |; // Store1 Store2; //; // FIXME: We should be able to climb and; // descend TokenFactors to find candidates as well.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:102,load,load,102,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,5,"['Load', 'load']","['Load', 'load', 'loads']"
Performance,// We lower FP->int64 into FISTP64 followed by a load from a temporary; // stack slot.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:49,load,load,49,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,"// We made changes, but also determined that there were no more optimization; // opportunities, so we don't need to reprocess the list",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SILoadStoreOptimizer.cpp:64,optimiz,optimization,64,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SILoadStoreOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SILoadStoreOptimizer.cpp,1,['optimiz'],['optimization']
Performance,// We match the loads and follow the uses to the extend instead of matching; // the extends and following the def to the load. This is because the load; // must remain in the same position for correctness (unless we also add code; // to find a safe place to sink it) whereas the extend is freely movable.; // It also prevents us from duplicating the load for the volatile case or just; // for performance.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:16,load,loads,16,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,5,"['load', 'perform']","['load', 'loads', 'performance']"
Performance,"// We may have a bitcast of something that has already had this bitcast; // combine performed on it, so skip past any VECTOR_REG_CASTs.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:84,perform,performed,84,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['perform'],['performed']
Performance,"// We may have a case where all predecessors have the instruction,; // and we just need to insert a phi node. Otherwise, perform; // insertion.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp:121,perform,perform,121,interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,1,['perform'],['perform']
Performance,"// We may have added values to the cache list before this PHI translation.; // If so, we haven't done anything to ensure that the cache remains sorted.; // Sort it now (if needed) so that recursive invocations of; // getNonLocalPointerDepFromBB and other routines that could reuse the cache; // value will only see properly sorted cache arrays.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp:35,cache,cache,35,interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,4,['cache'],['cache']
Performance,"// We may have already built this action as a part of the offloading; // toolchain, return the cached input if so.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/Driver.cpp:95,cache,cached,95,interpreter/llvm-project/clang/lib/Driver/Driver.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/Driver.cpp,1,['cache'],['cached']
Performance,"// We may have already loaded just the fields of this record, in which case; // we need to ignore them.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/DeclBase.cpp:23,load,loaded,23,interpreter/llvm-project/clang/lib/AST/DeclBase.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/DeclBase.cpp,1,['load'],['loaded']
Performance,// We may have cached a forward decl when we could have created; // a non-forward decl. Go ahead and create a non-forward decl; // now.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp:15,cache,cached,15,interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp,1,['cache'],['cached']
Performance,"// We may have inlined callees during pre-LTO compilation, in which case; // we need to rely on the inline stack from !dbg to mark context profile; // as inlined, instead of `MarkContextSamplesInlined` during inlining.; // Sample profile loader walks through all instructions to get profile,; // which calls this function. So once that is done, all previously inlined; // context profile should be marked properly.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/SampleContextTracker.cpp:238,load,loader,238,interpreter/llvm-project/llvm/lib/Transforms/IPO/SampleContextTracker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/SampleContextTracker.cpp,1,['load'],['loader']
Performance,"// We may have split loads where some of their stores are split stores. For; // such loads and stores, we can only pre-split them if their splits exactly; // match relative to their starting offset. We have to verify this prior to; // any rewriting.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:21,load,loads,21,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,2,['load'],['loads']
Performance,"// We may hoist some instructions out of loop. In case if they were cached; // as ""loop variant"" or ""loop computable"", these caches must be dropped.; // We also may fold basic blocks, so cached block dispositions also need; // to be dropped.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopRotationUtils.cpp:68,cache,cached,68,interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopRotationUtils.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopRotationUtils.cpp,3,['cache'],"['cached', 'caches']"
Performance,"// We may need to handle exotic cases, such as i16->i64 extloads, so insert; // the appropriate extension from the 32-bit load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:122,load,load,122,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,1,['load'],['load']
Performance,// We may need to perform implicit conversion of the argument.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDeclAttr.cpp:18,perform,perform,18,interpreter/llvm-project/clang/lib/Sema/SemaDeclAttr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDeclAttr.cpp,1,['perform'],['perform']
Performance,// We may need to perform overload resolution to determine whether a; // field can be moved if it's const or volatile qualified.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/DeclCXX.cpp:18,perform,perform,18,interpreter/llvm-project/clang/lib/AST/DeclCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/DeclCXX.cpp,1,['perform'],['perform']
Performance,"// We may not have yet loaded the library where the dictionary of this type is",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RRootDS.cxx:23,load,loaded,23,tree/dataframe/src/RRootDS.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RRootDS.cxx,1,['load'],['loaded']
Performance,// We may optimize twice here.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp:10,optimiz,optimize,10,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86EncodingOptimization.cpp,1,['optimiz'],['optimize']
Performance,"// We might be able to do better than this under some circumstances, but in; // general, fsel-based lowering of select is a finite-math-only optimization.; // For more information, see section F.3 of the 2.06 ISA specification.; // With ISA 3.0",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:141,optimiz,optimization,141,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['optimiz'],['optimization']
Performance,"// We might be able to express the shuffle as a bitrotate. But even if we; // don't have Zvkb and have to expand, the expanded sequence of approx. 2; // shifts and a vor will have a higher throughput than a vrgather.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:189,throughput,throughput,189,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['throughput'],['throughput']
Performance,// We might get here with a VarDecl in the case we're generating; // code for the initialization of globals. Do not record these decls; // as they will overwrite the actual VarDecl Decl in the cache.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp:193,cache,cache,193,interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp,1,['cache'],['cache']
Performance,"// We might have a vector load from an array. FIXME: for now we just bail; // out in this case, but we should be able to resolve and simplify such; // loads.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LoopUnrollAnalyzer.cpp:26,load,load,26,interpreter/llvm-project/llvm/lib/Analysis/LoopUnrollAnalyzer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LoopUnrollAnalyzer.cpp,2,['load'],"['load', 'loads']"
Performance,"// We might have autoload entries that don't have a rootmap entry; // (libCore) and no interpreter info (not yet loaded).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/rint/src/TTabCom.cxx:113,load,loaded,113,core/rint/src/TTabCom.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/rint/src/TTabCom.cxx,1,['load'],['loaded']
Performance,// We might not have a VST if there were no values in the; // summary. An empty summary block generated when we are; // performing ThinLTO compiles so we don't later invoke; // the regular LTO process on them.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Reader/BitcodeReader.cpp:120,perform,performing,120,interpreter/llvm-project/llvm/lib/Bitcode/Reader/BitcodeReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Reader/BitcodeReader.cpp,1,['perform'],['performing']
Performance,"// We might see a (re)definition of a module that we already have a; // definition for in four cases:; // - If we loaded one definition from an AST file and we've just found a; // corresponding definition in a module map file, or",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/ModuleMap.cpp:114,load,loaded,114,interpreter/llvm-project/clang/lib/Lex/ModuleMap.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/ModuleMap.cpp,1,['load'],['loaded']
Performance,// We might want to use a b16 load/store,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerModuleLDSPass.cpp:30,load,load,30,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerModuleLDSPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerModuleLDSPass.cpp,1,['load'],['load']
Performance,// We might want to use a b32 load/store,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerModuleLDSPass.cpp:30,load,load,30,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerModuleLDSPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerModuleLDSPass.cpp,1,['load'],['load']
Performance,// We might want to use a b64 load/store,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerModuleLDSPass.cpp:30,load,load,30,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerModuleLDSPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerModuleLDSPass.cpp,1,['load'],['load']
Performance,// We might want to use a b96 or b128 load/store,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerModuleLDSPass.cpp:38,load,load,38,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerModuleLDSPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULowerModuleLDSPass.cpp,1,['load'],['load']
Performance,"// We must be careful with atomic accesses, as they may allow another thread; // to touch this location, clobbering it. We are conservative: if the; // QueryInst is not a simple (non-atomic) memory access, we automatically; // return getClobber.; // If it is simple, we know based on the results of; // ""Compiler testing via a theory of sound optimisations in the C11/C++11; // memory model"" in PLDI 2013, that a non-atomic location can only be; // clobbered between a pair of a release and an acquire action, with no; // access to the location in between.; // Here is an example for giving the general intuition behind this rule.; // In the following code:; // store x 0;; // release action; [1]; // acquire action; [4]; // %val = load x;; // It is unsafe to replace %val by 0 because another thread may be running:; // acquire action; [2]; // store x 42;; // release action; [3]; // with synchronization from 1 to 2 and from 3 to 4, resulting in %val; // being 42. A key property of this program however is that if either; // 1 or 4 were missing, there would be a race between the store of 42; // either the store of 0 or the load (making the whole program racy).; // The paper mentioned above shows that the same property is respected; // by every program that can detect any optimization of that kind: either; // it is racy (undefined) or there is a release followed by an acquire; // between the pair of accesses under consideration.; // If the load is invariant, we ""know"" that it doesn't alias *any* write. We; // do want to respect mustalias results since defs are useful for value; // forwarding, but any mayalias write can be assumed to be noalias.; // Arguably, this logic should be pushed inside AliasAnalysis itself.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp:732,load,load,732,interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryDependenceAnalysis.cpp,4,"['load', 'optimiz']","['load', 'optimization']"
Performance,// We must either select the trivial copy constructor or reach an; // ambiguity; no need to actually perform overload resolution.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp:101,perform,perform,101,interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp,1,['perform'],['perform']
Performance,// We must ensure the relocation of derived pointer is defined after; // relocation of base pointer. If we find a relocation corresponding to base; // defined earlier than relocation of base then we move relocation of base; // right before found relocation. We consider only relocation in the same; // basic block as relocation of base. Relocations from other basic block will; // be skipped by optimization and we do not care about them.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:395,optimiz,optimization,395,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,1,['optimiz'],['optimization']
Performance,// We must have an 8- or 16-bit load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:32,load,load,32,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,1,['load'],['load']
Performance,// We must have loads at both ends of the repetition.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,load,loads,16,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['loads']
Performance,"// We must reference MCJIT in such a way that compilers will not; // delete it all as dead code, even with whole program optimization,; // yet is effectively a NO-OP. As the compiler isn't smart enough; // to know that getenv() never returns -1, this will do the job.; // This is so that globals in the translation units where these functions; // are defined are forced to be initialized, populating various; // registries.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ExecutionEngine/MCJIT.h:121,optimiz,optimization,121,interpreter/llvm-project/llvm/include/llvm/ExecutionEngine/MCJIT.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ExecutionEngine/MCJIT.h,1,['optimiz'],['optimization']
Performance,"// We must reference VMCore in such a way that compilers will not; // delete it all as dead code, even with whole program optimization,; // yet is effectively a NO-OP. As the compiler isn't smart enough; // to know that getenv() never returns -1, this will do the job.; // This is so that globals in the translation units where these functions; // are defined are forced to be initialized, populating various; // registries.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/LinkAllIR.h:122,optimiz,optimization,122,interpreter/llvm-project/llvm/include/llvm/LinkAllIR.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/LinkAllIR.h,1,['optimiz'],['optimization']
Performance,"// We must reference the passes in such a way that compilers will not; // delete it all as dead code, even with whole program optimization,; // yet is effectively a NO-OP. As the compiler isn't smart enough; // to know that getenv() never returns -1, this will do the job.; // This is so that globals in the translation units where these functions; // are defined are forced to be initialized, populating various; // registries.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/LinkAllPasses.h:126,optimiz,optimization,126,interpreter/llvm-project/llvm/include/llvm/LinkAllPasses.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/LinkAllPasses.h,2,['optimiz'],['optimization']
Performance,"// We must reference the plug-ins in such a way that compilers will not; // delete it all as dead code, even with whole program optimization,; // yet is effectively a NO-OP. As the compiler isn't smart enough; // to know that getenv() never returns -1, this will do the job.; // This is so that globals in the translation units where these functions; // are defined are forced to be initialized, populating various; // registries.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/LinkAllAsmWriterComponents.h:128,optimiz,optimization,128,interpreter/llvm-project/llvm/include/llvm/CodeGen/LinkAllAsmWriterComponents.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/LinkAllAsmWriterComponents.h,1,['optimiz'],['optimization']
Performance,// We must restrict the ordering to avoid generating loads with Release or; // ReleaseAcquire orderings.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:53,load,loads,53,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['loads']
Performance,"// We must search by the slow case of localUncachedLookup because that is; // working even if there is no LookupPtr for the DC. We could use; // DC::buildLookup() to create the LookupPtr, but that would load external; // decls again, we must avoid that case.; // Also, even if we had the LookupPtr, we must find Decls which are not; // in the LookupPtr, so we need the slow case.; // These cases are handled in ASTImporterLookupTable, but we cannot use; // that with LLDB since that traverses through the AST which initiates the; // load of external decls again via DC::decls(). And again, we must avoid; // loading external decls during the import.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ASTImporter.cpp:203,load,load,203,interpreter/llvm-project/clang/lib/AST/ASTImporter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ASTImporter.cpp,3,['load'],"['load', 'loading']"
Performance,"// We must set parameter MustBeSingleInstruction to true, since; // skipAlignedDPRCS2Spills expects exactly 3 instructions to perform; // stack alignment. Luckily, this can always be done since all ARM; // architecture versions that support Neon also support the BFC; // instruction.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMFrameLowering.cpp:126,perform,perform,126,interpreter/llvm-project/llvm/lib/Target/ARM/ARMFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMFrameLowering.cpp,1,['perform'],['perform']
Performance,"// We naively assume that an instruction propagates any loaded; // uses to all defs unless the instruction is a call, in which; // case all arguments will be treated as gadget sources during; // analysis of the callee function.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp:56,load,loaded,56,interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LoadValueInjectionLoadHardening.cpp,1,['load'],['loaded']
Performance,// We need a new const-pool entry to load from.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMExpandPseudoInsts.cpp:37,load,load,37,interpreter/llvm-project/llvm/lib/Target/ARM/ARMExpandPseudoInsts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMExpandPseudoInsts.cpp,1,['load'],['load']
Performance,"// We need a reference to the template instance static member in a concrete function in order; // to force its instantiation (even before the function is actually run); // Since we do have a reference to Dictionary (in T::Dictionary), using fgGenericInfo; // here will insure that it is initialized at process start or library load time.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/Rtypes.h:327,load,load,327,core/base/inc/Rtypes.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/Rtypes.h,1,['load'],['load']
Performance,"// We need a scratch register for spilling LR and for spilling CR. By default,; // we use two scratch registers to hide latency. However, if only one scratch; // register is available, we can adjust for that by not overlapping the spill; // code. However, if we need to realign the stack (i.e. have a base pointer); // and the stack frame is large, we need two scratch registers.; // Also, stack probe requires two scratch registers, one for old sp, one for; // large frame and large probe size.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCFrameLowering.cpp:120,latency,latency,120,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCFrameLowering.cpp,1,['latency'],['latency']
Performance,// We need a separate load before each actual use of the PHI,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/DemoteRegToStack.cpp:22,load,load,22,interpreter/llvm-project/llvm/lib/Transforms/Utils/DemoteRegToStack.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/DemoteRegToStack.cpp,1,['load'],['load']
Performance,"// We need a vector extract (or mfvsrld). Assume vector operation cost.; // The cost of the load constant for a vector extract is disregarded; // (invariant, easily schedulable).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp:92,load,load,92,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCTargetTransformInfo.cpp,1,['load'],['load']
Performance,"// We need custom load and store lowering for both externref, funcref and; // Other. The MVT::Other here represents tables of reference types.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp:18,load,load,18,interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp,1,['load'],['load']
Performance,// We need the base of the memory instruction to be same as the register; // where the null check is performed (i.e. PointerReg).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ImplicitNullChecks.cpp:101,perform,performed,101,interpreter/llvm-project/llvm/lib/CodeGen/ImplicitNullChecks.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ImplicitNullChecks.cpp,1,['perform'],['performed']
Performance,"// We need the subreg of Dst to make instruction verifier happy because the; // real machine instruction consumes and produces values of the same size and; // the registers the will be used here fall into different classes and this; // makes IV cry. We could use a bigger operation, but this will put some; // pressure on cache and memory, so no.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/M68k/M68kInstrInfo.cpp:322,cache,cache,322,interpreter/llvm-project/llvm/lib/Target/M68k/M68kInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/M68k/M68kInstrInfo.cpp,1,['cache'],['cache']
Performance,// We need to accumulate the splits required of each load or store where we; // can find them via a direct lookup. This is important to cross-check loads; // and stores against each other. We also track the slice so that we can kill; // all the slices that end up split.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:53,load,load,53,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,2,['load'],"['load', 'loads']"
Performance,// We need to add this separately from the scale above to help with; // SDAG consecutive load/store merging.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:89,load,load,89,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,1,['load'],['load']
Performance,// We need to adjust the pointer to the load by ShAmt bits in order to load; // the correct bytes.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:40,load,load,40,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,['load'],['load']
Performance,// We need to assign indexes before we perform layout because we need to know; // if we need large indexes or not. We can assign indexes first and check as; // we go to see if we will actully need large indexes.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/ELF/ELFObject.cpp:39,perform,perform,39,interpreter/llvm-project/llvm/lib/ObjCopy/ELF/ELFObject.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ObjCopy/ELF/ELFObject.cpp,1,['perform'],['perform']
Performance,// We need to avoid a situation in which the value from a VRRC register is; // spilled using an Altivec instruction and reloaded into a VSRC register; // using a VSX instruction. The issue with this is that the VSX; // load/store instructions swap the doublewords in the vector and the Altivec; // ones don't. The register classes on the spill/reload may be different if; // the register is defined using an Altivec instruction and is then used by a; // VSX instruction.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp:219,load,load,219,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCInstrInfo.cpp,2,['load'],['load']
Performance,// We need to bitcast and perform atomic op as integers,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Frontend/OpenMP/OMPIRBuilder.cpp:26,perform,perform,26,interpreter/llvm-project/llvm/lib/Frontend/OpenMP/OMPIRBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Frontend/OpenMP/OMPIRBuilder.cpp,1,['perform'],['perform']
Performance,"// We need to change the name of the function to avoid problems when we load more packages",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TPackMgr.cxx:72,load,load,72,proof/proof/src/TPackMgr.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TPackMgr.cxx,1,['load'],['load']
Performance,"// We need to check that the offset both falls within our range and is; // suitably aligned. We can check both properties at the same time by; // performing a right rotate by log2(alignment) followed by an integer; // comparison against the bitset size. The rotate will move the lower; // order bits that need to be zero into the higher order bits of the; // result, causing the comparison to fail if they are nonzero. The rotate; // also conveniently gives us a bit offset to use during the load from; // the bitset.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/LowerTypeTests.cpp:146,perform,performing,146,interpreter/llvm-project/llvm/lib/Transforms/IPO/LowerTypeTests.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/LowerTypeTests.cpp,2,"['load', 'perform']","['load', 'performing']"
Performance,"// We need to combine at least two loads into this type. Since the smallest; // possible load is into a byte, we need at least a 16-bit wide type.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:35,load,loads,35,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,2,['load'],"['load', 'loads']"
Performance,// We need to create a zextload/sextload. We cannot just create a load; // followed by a zext/zext node because LowerMUL is also run during normal; // operation legalization where we can't create illegal types.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:66,load,load,66,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['load'],['load']
Performance,"// We need to disambiguate a very ugly part of the C++ syntax:; //; // (T())x; - type-id; // (T())*x; - type-id; // (T())/x; - expression; // (T()); - expression; //; // The bad news is that we cannot use the specialized tentative parser, since; // it can only verify that the thing inside the parens can be parsed as; // type-id, it is not useful for determining the context past the parens.; //; // The good news is that the parser can disambiguate this part without; // making any unnecessary Action calls.; //; // It uses a scheme similar to parsing inline methods. The parenthesized; // tokens are cached, the context that follows is determined (possibly by; // parsing a cast-expression), and then we re-introduce the cached tokens; // into the token stream and parse them appropriately.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseExprCXX.cpp:603,cache,cached,603,interpreter/llvm-project/clang/lib/Parse/ParseExprCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseExprCXX.cpp,2,['cache'],['cached']
Performance,"// We need to distinguish between single threaded and multi-threaded runs.; // In single threaded mode, InitSlot is only called once and column readers have to be rewired; // to new page sources of the chain in GetEntryRanges. In multi-threaded mode, on the other hand,; // InitSlot is called for every returned range, thus rewiring the column readers takes place in; // InitSlot and FinalizeSlot.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RNTupleDS.cxx:54,multi-thread,multi-threaded,54,tree/dataframe/src/RNTupleDS.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RNTupleDS.cxx,2,['multi-thread'],['multi-threaded']
Performance,"// We need to emit only one of these. The prevailing module will keep it,; // but turned into a weak, while the others will drop it when possible.; // This is both a compile-time optimization and a correctness; // transformation. This is necessary for correctness when we have exported; // a reference - we need to convert the linkonce to weak to; // ensure a copy is kept to satisfy the exported reference.; // FIXME: We may want to split the compile time and correctness; // aspects into separate routines.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/LTO/LTO.cpp:179,optimiz,optimization,179,interpreter/llvm-project/llvm/lib/LTO/LTO.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/LTO/LTO.cpp,1,['optimiz'],['optimization']
Performance,// We need to ensure the load isn't atomic or volatile.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:25,load,load,25,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['load'],['load']
Performance,"// We need to establish an ordering of constructor and conversion function; // names, and they don't have an intrinsic ordering.; // First we try the easy case by forming the current context's constructor; // name and adding that name first. This is a very useful optimization to; // avoid walking the lexical declarations in many cases, and it also; // handles the only case where a constructor name can come from some other; // lexical context -- when that name is an implicit constructor merged from; // another declaration in the redecl chain. Any non-implicit constructor or; // conversion function which doesn't occur in all the lexical contexts; // would be an ODR violation.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp:264,optimiz,optimization,264,interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp,1,['optimiz'],['optimization']
Performance,"// We need to figure out if the optimizations for this line were the same; // in each function context. If not, then we want to group the similar; // function contexts together and display each group separately. If; // they're all the same, then we only display the line once without any; // additional markings.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-opt-report/OptReport.cpp:32,optimiz,optimizations,32,interpreter/llvm-project/llvm/tools/llvm-opt-report/OptReport.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-opt-report/OptReport.cpp,1,['optimiz'],['optimizations']
Performance,"// We need to figure out which CUDA version we're compiling for, as that; // determines how we load and launch GPU kernels.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp:95,load,load,95,interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp,1,['load'],['load']
Performance,"// We need to fold load after optimizeCmpInstr, since; // optimizeCmpInstr can enable folding by converting SUB to CMP.; // Save FoldAsLoadDefReg because optimizeLoadInstr() resets it and; // we need it for markUsesInDebugValueAsUndef().",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/PeepholeOptimizer.cpp:19,load,load,19,interpreter/llvm-project/llvm/lib/CodeGen/PeepholeOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/PeepholeOptimizer.cpp,4,"['load', 'optimiz']","['load', 'optimizeCmpInstr', 'optimizeLoadInstr']"
Performance,// We need to initialize CachedRTTIArg before CachedRTTIMode,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Driver/ToolChain.h:25,Cache,CachedRTTIArg,25,interpreter/llvm-project/clang/include/clang/Driver/ToolChain.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Driver/ToolChain.h,2,['Cache'],"['CachedRTTIArg', 'CachedRTTIMode']"
Performance,"// We need to insert these at the location of the old load, not at that of; // the extractvalue.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp:54,load,load,54,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp,1,['load'],['load']
Performance,// We need to instantiate and cache the desired type symbol.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DebugInfo/PDB/Native/SymbolCache.cpp:30,cache,cache,30,interpreter/llvm-project/llvm/lib/DebugInfo/PDB/Native/SymbolCache.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DebugInfo/PDB/Native/SymbolCache.cpp,1,['cache'],['cache']
Performance,"// We need to invalidate the loading of the current tree because its list; // of real friend is now obsolete. It is repairable only from LoadTree",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TChain.cxx:29,load,loading,29,tree/tree/src/TChain.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TChain.cxx,4,"['Load', 'load']","['LoadTree', 'loading']"
Performance,"// We need to invalidate the loading of the current tree because its list; // of real friends is now obsolete. It is repairable only from LoadTree.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TChain.cxx:29,load,loading,29,tree/tree/src/TChain.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TChain.cxx,4,"['Load', 'load']","['LoadTree', 'loading']"
Performance,"// We need to link all the builtin GCs when LLVM is used as a static library.; // The linker will quite happily remove the static constructors that register; // the builtin GCs if we don't use a function from that object. This function; // does nothing but we need to make sure it is (or at least could be, even; // with all optimisations enabled) called *somewhere*, and this is a good; // place to do that: if the GC strategies are being used then this function; // obviously can't be removed by the linker, and here it won't affect; // performance, since there's about to be a fatal error anyway.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/GCStrategy.cpp:539,perform,performance,539,interpreter/llvm-project/llvm/lib/IR/GCStrategy.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/GCStrategy.cpp,1,['perform'],['performance']
Performance,// We need to load the argument to a virtual register if we determined; // above that we ran out of physical registers of the appropriate type.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:14,load,load,14,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['load']
Performance,"// We need to make sure not to put loads and stores in the same clause if they; // use the same address. For now, just start a new clause whenever we see a; // store.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNHazardRecognizer.cpp:35,load,loads,35,interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNHazardRecognizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNHazardRecognizer.cpp,1,['load'],['loads']
Performance,"// We need to not do lazy parsing when we need thread safety as; // DWARFUnitVector, in lazy mode, will slowly add things to itself and; // will cause problems in a multi-threaded environment.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DebugInfo/DWARF/DWARFContext.cpp:165,multi-thread,multi-threaded,165,interpreter/llvm-project/llvm/lib/DebugInfo/DWARF/DWARFContext.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DebugInfo/DWARF/DWARFContext.cpp,1,['multi-thread'],['multi-threaded']
Performance,// We need to perform atomic op as integer,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Frontend/OpenMP/OMPIRBuilder.cpp:14,perform,perform,14,interpreter/llvm-project/llvm/lib/Frontend/OpenMP/OMPIRBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Frontend/OpenMP/OMPIRBuilder.cpp,1,['perform'],['perform']
Performance,"// We need to perform most of the semantic analysis for a C++0x for-range; // statememt before parsing the body, in order to be able to deduce the type; // of an auto-typed loop variable.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseStmt.cpp:14,perform,perform,14,interpreter/llvm-project/clang/lib/Parse/ParseStmt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseStmt.cpp,1,['perform'],['perform']
Performance,"// We need to perform run-time alias checks, but some pointers had bounds; // that couldn't be checked.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LoopAccessAnalysis.cpp:14,perform,perform,14,interpreter/llvm-project/llvm/lib/Analysis/LoopAccessAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LoopAccessAnalysis.cpp,1,['perform'],['perform']
Performance,// We need to perform the scope leaving in reverse order,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/CFG.cpp:14,perform,perform,14,interpreter/llvm-project/clang/lib/Analysis/CFG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/CFG.cpp,1,['perform'],['perform']
Performance,"// We need to produce the matcher tree for the patterns source pattern. To; // do this we need to match the structure as well as the types. To do the; // type matching, we want to figure out the fewest number of type checks we; // need to emit. For example, if there is only one integer type supported; // by a target, there should be no type comparisons at all for integer; // patterns!; //; // To figure out the fewest number of type checks needed, clone the pattern,; // remove the types, then perform type inference on the pattern as a whole.; // If there are unresolved types, emit an explicit check for those types,; // apply the type to the tree, then rerun type inference. Iterate until all; // types are resolved.; //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/DAGISelMatcherGen.cpp:497,perform,perform,497,interpreter/llvm-project/llvm/utils/TableGen/DAGISelMatcherGen.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/DAGISelMatcherGen.cpp,1,['perform'],['perform']
Performance,"// We need to remove the libraries that are dynamically loaded and not linked",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx:56,load,loaded,56,core/base/src/TSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx,1,['load'],['loaded']
Performance,"// We need to replace ptr0 in the following expression:; // x0 * offset0 + y0 * ptr0 = t0; // knowing that; // x1 * offset1 + y1 * ptr0 = t1 (the indexed load/store); //; // where x0, x1, y0 and y1 in {-1, 1} are given by the types of the; // indexed load/store and the expression that needs to be re-written.; //; // Therefore, we have:; // t0 = (x0 * offset0 - x1 * y0 * y1 *offset1) + (y0 * y1) * t1",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:154,load,load,154,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,['load'],['load']
Performance,"// We need to reset the cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/DeclUnloader.cpp:24,cache,cache,24,interpreter/cling/lib/Interpreter/DeclUnloader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/DeclUnloader.cpp,1,['cache'],['cache']
Performance,// We need to rewrite dst types for ASSIGN_TYPE instrs to be able; // to perform tblgen'erated selection and we can't do that on Legalizer; // as it operates on gMIR only.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SPIRV/SPIRVPreLegalizer.cpp:73,perform,perform,73,interpreter/llvm-project/llvm/lib/Target/SPIRV/SPIRVPreLegalizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SPIRV/SPIRVPreLegalizer.cpp,1,['perform'],['perform']
Performance,// We need to start watching the directory before we start scanning in order; // to not miss any event. By dispatching this on the same serial Queue as; // the FSEvents will be handled we manage to start watching BEFORE the; // inital scan and handling events ONLY AFTER the scan finishes.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/DirectoryWatcher/mac/DirectoryWatcher-mac.cpp:143,Queue,Queue,143,interpreter/llvm-project/clang/lib/DirectoryWatcher/mac/DirectoryWatcher-mac.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/DirectoryWatcher/mac/DirectoryWatcher-mac.cpp,1,['Queue'],['Queue']
Performance,"// We need to temorairly remove the assumption so we can insert the; // sanitizer check before it, else the check will be dropped by optimizations.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenFunction.cpp:133,optimiz,optimizations,133,interpreter/llvm-project/clang/lib/CodeGen/CodeGenFunction.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenFunction.cpp,1,['optimiz'],['optimizations']
Performance,"// We needs only one static object of this class; //_______________________________________________________________; //; // Just for fun, I introduce the class 'Tester' to collect; // a 'TNamed' objects. I use a objects of this class to perform a real; // tests.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/test/tcollbm.cxx:237,perform,perform,237,test/tcollbm.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/test/tcollbm.cxx,1,['perform'],['perform']
Performance,"// We never load namespaces on their own.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/dictgen/src/rootcling_impl.cxx:12,load,load,12,core/dictgen/src/rootcling_impl.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/dictgen/src/rootcling_impl.cxx,1,['load'],['load']
Performance,// We normally only need one spill instruction - a load or a store.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RegAllocGreedy.cpp:51,load,load,51,interpreter/llvm-project/llvm/lib/CodeGen/RegAllocGreedy.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RegAllocGreedy.cpp,1,['load'],['load']
Performance,"// We note the locations of these intrinsic calls so that we can; // delete them later if the optimization succeeds, this is safe; // since both llvm.lifetime.start and llvm.lifetime.end intrinsics; // practically fill all the bytes of the alloca with an undefined; // value, although conceptually marked as alive/dead.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp:94,optimiz,optimization,94,interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,1,['optimiz'],['optimization']
Performance,"// We now check for the TClass entry, w/o loading. Indeed we did that above.; // If the class is not found, it means that really it was not selected and we; // replace it with an empty placeholder with the status of kForwardDeclared.; // Interactivity will be of course possible but if IO is attempted, a warning; // will be issued.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TProtoClass.cxx:42,load,loading,42,core/meta/src/TProtoClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TProtoClass.cxx,1,['load'],['loading']
Performance,"// We now have a target-specific load, so delete the old one.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedAccessPass.cpp:33,load,load,33,interpreter/llvm-project/llvm/lib/CodeGen/InterleavedAccessPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/InterleavedAccessPass.cpp,1,['load'],['load']
Performance,// We only allow whole-alloca splittable loads and stores; // for a large alloca to avoid creating too large BitVector.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:41,load,loads,41,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,1,['load'],['loads']
Performance,// We only care about loading variants of these instructions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:22,load,loading,22,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,1,['load'],['loading']
Performance,// We only care about regular loads. The PPC-specific load intrinsics; // will not lead to a merge opportunity.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:30,load,loads,30,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,2,['load'],"['load', 'loads']"
Performance,// We only care if this load uses a POSTINC or PREDEC mode.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AVR/AVRISelDAGToDAG.cpp:24,load,load,24,interpreter/llvm-project/llvm/lib/Target/AVR/AVRISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AVR/AVRISelDAGToDAG.cpp,1,['load'],['load']
Performance,"// We only compute IDs for expressions if the warning is enabled, and; // cache the sizeof arg's ID.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaChecking.cpp:74,cache,cache,74,interpreter/llvm-project/clang/lib/Sema/SemaChecking.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaChecking.cpp,1,['cache'],['cache']
Performance,"// We only ever need one instance of TrueMatcherImpl, so we create a static; // instance and reuse it to reduce the overhead of the matcher and increase; // the chance of cache hits.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/ASTMatchers/ASTMatchersInternal.cpp:171,cache,cache,171,interpreter/llvm-project/clang/lib/ASTMatchers/ASTMatchersInternal.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/ASTMatchers/ASTMatchersInternal.cpp,1,['cache'],['cache']
Performance,"// We only generate virtual base registers for loads and stores, so; // return false for everything else.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVRegisterInfo.cpp:47,load,loads,47,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVRegisterInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVRegisterInfo.cpp,1,['load'],['loads']
Performance,"// We only handle ""native"" vector sizes for now, e.g. <4 x double> is not; // legal. We can (and should) split that into 2 loads of <2 x double> here; // but I'm leaving that as a TODO for now.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:123,load,loads,123,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,1,['load'],['loads']
Performance,// We only handle up to 64-bit values here as those are what matter for; // addressing mode optimizations.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp:92,optimiz,optimizations,92,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,2,['optimiz'],['optimizations']
Performance,"// We only have 1 VGPR offset, or 1 SGPR offset. We don't have a free; // SGPR, so perform the add as vector.; // We don't need a base SGPR in the kernel.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIRegisterInfo.cpp:83,perform,perform,83,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIRegisterInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIRegisterInfo.cpp,1,['perform'],['perform']
Performance,"// We only keep live symbols that are known to be non-prevailing if any are; // available_externally, linkonceodr, weakodr. Those symbols are discarded; // later in the EliminateAvailableExternally pass and setting them to; // not-live could break downstreams users of liveness information (PR36483); // or limit optimization opportunities.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionImport.cpp:313,optimiz,optimization,313,interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionImport.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionImport.cpp,1,['optimiz'],['optimization']
Performance,// We only need to use thread-safe statics for local non-TLS variables and; // inline variables; other global initialization is always single-threaded; // or (through lazy dynamic loading in multiple threads) unsequenced.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/ItaniumCXXABI.cpp:180,load,loading,180,interpreter/llvm-project/clang/lib/CodeGen/ItaniumCXXABI.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/ItaniumCXXABI.cpp,1,['load'],['loading']
Performance,// We only perform ODR checks for decls not in GMF.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp:11,perform,perform,11,interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp,4,['perform'],['perform']
Performance,// We only perform ODR checks for decls not in the explicit; // global module fragment.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp:11,perform,perform,11,interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,1,['perform'],['perform']
Performance,"// We only perform this transformation for specific branch kinds.; // We don't want to do this for do..while, for example.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/BugReporter.cpp:11,perform,perform,11,interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/BugReporter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/BugReporter.cpp,1,['perform'],['perform']
Performance,"// We only put pads on the worklist that aren't in the MemoMap. When; // we find an unwind dest for a pad we may update its ancestors, but; // the queue only ever contains uncles/great-uncles/etc. of CurrentPad,; // so they should never get updated while queued on the worklist.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/InlineFunction.cpp:147,queue,queue,147,interpreter/llvm-project/llvm/lib/Transforms/Utils/InlineFunction.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/InlineFunction.cpp,2,['queue'],"['queue', 'queued']"
Performance,"// We only reserve r2 if we need to use the TOC pointer. If we have no; // explicit uses of the TOC pointer (meaning we're a leaf function with; // no constant-pool loads, etc.) and we have no potential uses inside an; // inline asm block, then we can treat r2 has an ordinary callee-saved; // register.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCRegisterInfo.cpp:165,load,loads,165,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCRegisterInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCRegisterInfo.cpp,1,['load'],['loads']
Performance,// We only support LOAD/STORE and vector manipulation ops for vectors; // with > 4 elements.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:19,LOAD,LOAD,19,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,1,['LOAD'],['LOAD']
Performance,"// We only support widening vectors with equivalent element types and; // fixed/scalable properties. If a target needs to widen a fixed-length type; // to a scalable one, it should be possible to use INSERT_SUBVECTOR below.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp:80,scalab,scalable,80,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,2,['scalab'],['scalable']
Performance,"// We only use TTreeReaderArrays to read columns that users flagged as type `RVec`, so we need to check; // that the branch stores the array as contiguous memory that we can actually wrap in an `RVec`.; // Currently we need the first entry to have been loaded to perform the check; // TODO Move check to constructor once ROOT-10823 is fixed and TTreeReaderArray itself exposes this information",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RTreeColumnReader.hxx:253,load,loaded,253,tree/dataframe/inc/ROOT/RDF/RTreeColumnReader.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RTreeColumnReader.hxx,2,"['load', 'perform']","['loaded', 'perform']"
Performance,"// We only want to cluster the mem ops that have the same ctrl(non-data); // pred so that they didn't have ctrl dependency for each other. But for; // store instrs, we can still cluster them if the pred is load instr.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp:206,load,load,206,interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp,1,['load'],['load']
Performance,"// We only want to perform this transformation if it will not lead to; // additional code. This is true if either both sides of the select; // fold to a constant (in which case the icmp is replaced with a select; // which will usually simplify) or this is the only user of the; // select (in which case we are trading a select+icmp for a simpler; // select+icmp) or all uses of the select can be replaced based on; // dominance information (""Global cases"").",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCompares.cpp:19,perform,perform,19,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCompares.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCompares.cpp,1,['perform'],['perform']
Performance,"// We optimize BBs ending with a conditional branch.; // We check only for BCC here, not BCCLR, because BCCLR; // will be formed only later in the pipeline.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp:6,optimiz,optimize,6,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp,1,['optimiz'],['optimize']
Performance,// We optimize only if the condition code is used only by one BCC.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp:6,optimiz,optimize,6,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMIPeephole.cpp,1,['optimiz'],['optimize']
Performance,// We optimize the truncation of induction variables having constant; // integer steps. The cost of these truncations is the same as the scalar; // operation.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:6,optimiz,optimize,6,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,1,['optimiz'],['optimize']
Performance,// We optionally skip over an extend so long as both loads are extended in the; // same way from the same type.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:53,load,loads,53,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['loads']
Performance,// We pass an empty TypoCorrection to indicate no correction was performed.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/Sema.cpp:65,perform,performed,65,interpreter/llvm-project/clang/lib/Sema/Sema.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/Sema.cpp,1,['perform'],['performed']
Performance,// We pass this builtin onto the optimizer so that it can figure out the; // object size in more complex cases.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:33,optimiz,optimizer,33,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,1,['optimiz'],['optimizer']
Performance,// We perform a non-recursive top-down dominator tree walk.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp:6,perform,perform,6,interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp,1,['perform'],['perform']
Performance,"// We perform early indirect call promotion here, before globalopt.; // This is important for the ThinLTO backend phase because otherwise; // imported available_externally functions look unreferenced and are; // removed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp:6,perform,perform,6,interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,1,['perform'],['perform']
Performance,"// We perform now a lookup",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TListOfTypes.cxx:6,perform,perform,6,core/base/src/TListOfTypes.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TListOfTypes.cxx,1,['perform'],['perform']
Performance,"// We perform this check post-message so that if the super -dealloc; // calls a helper method and that this class overrides, any ivars released in; // the helper method will be recorded before checking.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/CheckObjCDealloc.cpp:6,perform,perform,6,interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/CheckObjCDealloc.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/CheckObjCDealloc.cpp,1,['perform'],['perform']
Performance,// We perform this optimization only for switches with; // unreachable default case.; // This assumtion will save us from checking if `Condition` is a power of two.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp:6,perform,perform,6,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp,2,"['optimiz', 'perform']","['optimization', 'perform']"
Performance,// We perform this optimization post type-legalization because; // the type-legalizer often scalarizes integer-promoted vectors.; // Performing this optimization before may cause legalizaton cycles.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:6,perform,perform,6,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,4,"['Perform', 'optimiz', 'perform']","['Performing', 'optimization', 'perform']"
Performance,// We perform this optimization post type-legalization because; // the type-legalizer often scalarizes integer-promoted vectors.; // Performing this optimization before may create bit-casts which; // will be type-legalized to complex code sequences.; // We perform this optimization only before the operation legalizer because we; // may introduce illegal operations.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:6,perform,perform,6,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,6,"['Perform', 'optimiz', 'perform']","['Performing', 'optimization', 'perform']"
Performance,"// We performed name lookup into the current instantiation, and there were; // dependent bases, so we treat this result the same way as any other; // dependent nested-name-specifier.; // C++ [temp.res]p2:; // A name used in a template declaration or definition and that is; // dependent on a template-parameter is assumed not to name a type; // unless the applicable name lookup finds a type name or the name is; // qualified by the keyword typename.; //; // FIXME: If the next token is '<', we might want to ask the parser to; // perform some heroics to see if we actually have a; // template-argument-list, which would indicate a missing 'template'; // keyword here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp:6,perform,performed,6,interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp,2,['perform'],"['perform', 'performed']"
Performance,"// We performed some kind of instantiation in the parent context,; // so now we need to look into the instantiated parent context to; // find the instantiation of the declaration D.; // If our context used to be dependent, we may need to instantiate; // it before performing lookup into that context.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplateInstantiateDecl.cpp:6,perform,performed,6,interpreter/llvm-project/clang/lib/Sema/SemaTemplateInstantiateDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplateInstantiateDecl.cpp,2,['perform'],"['performed', 'performing']"
Performance,// We permit the extend to hoist through basic blocks but this is only; // sensible if the target has extending loads. If you end up lowering back; // into a load and extend during the legalizer then the end result is; // hoisting the extend up to the load.; // Prefer defined extensions to undefined extensions as these are more; // likely to reduce the number of instructions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:112,load,loads,112,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,3,['load'],"['load', 'loads']"
Performance,"// We plan to hoist the load to preheader without introducing a new fault.; // In order to do it, we need to prove that we cannot side-exit the loop; // once loop header is first entered before execution of the load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp:24,load,load,24,interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,2,['load'],['load']
Performance,// We probably are in a function incorrectly marked with; // amdgpu-no-queue-ptr. This is undefined.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:71,queue,queue-ptr,71,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,1,['queue'],['queue-ptr']
Performance,"// We probably are in a function incorrectly marked with; // amdgpu-no-queue-ptr. This is undefined. We don't want to delete the; // trap, so just use a null pointer.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:71,queue,queue-ptr,71,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,1,['queue'],['queue-ptr']
Performance,"// We really want to check whether the expression we matched was a store. No; // easy way to do that. However, we can check that the class we found has a; // store, which, assuming the value numbering state is not corrupt, is; // sufficient, because we must also be equivalent to that store's expression; // for it to be in the same class as the load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp:346,load,load,346,interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,1,['load'],['load']
Performance,"// We record relocations by pushing to the end of a vector. Reverse the vector; // to get the relocations in the order they were created.; // In most cases that is not important, but it can be for special sections; // (.eh_frame) or specific relocations (TLS optimizations on SystemZ).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/ELFObjectWriter.cpp:259,optimiz,optimizations,259,interpreter/llvm-project/llvm/lib/MC/ELFObjectWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/ELFObjectWriter.cpp,1,['optimiz'],['optimizations']
Performance,"// We rely on this decision to inline being idemopotent and unrelated to the; // use-site. We know that if we inline a variable at one use site, we'll; // inline it elsewhere too (and reuse the constant pool entry). Fast-isel; // doesn't know about this optimization, so bail out if it's enabled else; // we could decide to inline here (and thus never emit the GV) but require; // the GV from fast-isel generated code.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:254,optimiz,optimization,254,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['optimiz'],['optimization']
Performance,"// We reorder declarations in RecordDecls because they may have another order; // in the ""to"" context than they have in the ""from"" context. This may happen; // e.g when we import a class like this:; // struct declToImport {; // int a = c + b;; // int b = 1;; // int c = 2;; // };; // During the import of `a` we import first the dependencies in sequence,; // thus the order would be `c`, `b`, `a`. We will get the normal order by; // first removing the already imported members and then adding them in the; // order as they appear in the ""from"" context.; //; // Keeping field order is vital because it determines structure layout.; //; // Here and below, we cannot call field_begin() method and its callers on; // ToDC if it has an external storage. Calling field_begin() will; // automatically load all the fields by calling; // LoadFieldsFromExternalStorage(). LoadFieldsFromExternalStorage() would; // call ASTImporter::Import(). This is because the ExternalASTSource; // interface in LLDB is implemented by the means of the ASTImporter. However,; // calling an import at this point would result in an uncontrolled import, we; // must avoid that.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ASTImporter.cpp:795,load,load,795,interpreter/llvm-project/clang/lib/AST/ASTImporter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ASTImporter.cpp,3,"['Load', 'load']","['LoadFieldsFromExternalStorage', 'load']"
Performance,"// We require all uses of both induction variables to match this pattern:; //; // (OuterPHI * InnerTripCount) + InnerPHI; //; // I.e., it needs to be a linear expression of the induction variables and the; // inner loop trip count. We keep track of all different expressions on which; // checks will be performed in this bookkeeping struct.; //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopFlatten.cpp:303,perform,performed,303,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopFlatten.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopFlatten.cpp,1,['perform'],['performed']
Performance,"// We scanned the old callgraph node, removing invalidated call sites and; // then added back newly found call sites. One thing that can happen is; // that an old indirect call site was deleted and replaced with a new direct; // call. In this case, we have devirtualized a call, and CGSCCPM would like; // to iteratively optimize the new code. Unfortunately, we don't really; // have a great way to detect when this happens. As an approximation, we; // just look at whether the number of indirect calls is reduced and the; // number of direct calls is increased. There are tons of ways to fool this; // (e.g. DCE'ing an indirect call and duplicating an unrelated block with a; // direct call) but this is close enough.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CallGraphSCCPass.cpp:321,optimiz,optimize,321,interpreter/llvm-project/llvm/lib/Analysis/CallGraphSCCPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CallGraphSCCPass.cpp,1,['optimiz'],['optimize']
Performance,"// We selected one of the surrogate functions that converts the; // object parameter to a function pointer. Perform the conversion; // on the object argument, then let BuildCallExpr finish the job.; // Create an implicit member expr to refer to the conversion operator.; // and then call it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp:108,Perform,Perform,108,interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,1,['Perform'],['Perform']
Performance,// We should be performing an xor against a truncated shift.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:16,perform,performing,16,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['perform'],['performing']
Performance,// We should care only about loads.; // The main idea is to add a constraint whenever we're loading a value from; // an annotated pointer type.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/NullabilityChecker.cpp:29,load,loads,29,interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/NullabilityChecker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/NullabilityChecker.cpp,2,['load'],"['loading', 'loads']"
Performance,// We should keep at most one definition on the chain.; // FIXME: Cache the definition once we've found it. Building a chain with; // N definitions currently takes O(N^2) time here.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp:66,Cache,Cache,66,interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp,1,['Cache'],['Cache']
Performance,"// We should never have 0 cycle latency between two instructions unless; // they can be packetized together. However, this decision can't be made; // here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonInstrInfo.cpp:32,latency,latency,32,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonInstrInfo.cpp,1,['latency'],['latency']
Performance,"// We should never see a loading instruction at this point, as those should; // have been unfolded.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:25,load,loading,25,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,1,['load'],['loading']
Performance,"// We should not perform a lookup within a transparent context, so find a; // non-transparent parent context.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/AST/Decl.h:17,perform,perform,17,interpreter/llvm-project/clang/include/clang/AST/Decl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/AST/Decl.h,1,['perform'],['perform']
Performance,"// We should only add the prevailing nodes. Otherwise we may try to clone; // in a weak copy that won't be linked (and may be different than the; // prevailing version).; // We only keep the memprof summary on the prevailing copy now when; // building the combined index, as a space optimization, however don't; // rely on this optimization. The linker doesn't resolve local linkage; // values so don't check whether those are prevailing.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/MemProfContextDisambiguation.cpp:283,optimiz,optimization,283,interpreter/llvm-project/llvm/lib/Transforms/IPO/MemProfContextDisambiguation.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/MemProfContextDisambiguation.cpp,2,['optimiz'],['optimization']
Performance,"// We should use Altivec/VSX loads and stores when available. For unaligned; // addresses, unaligned VSX loads are only fast starting with the P8.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:29,load,loads,29,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,2,['load'],['loads']
Performance,// We should use extra load for direct calls to dllimported functions in; // non-JIT mode.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/M68k/M68kISelLowering.cpp:23,load,load,23,interpreter/llvm-project/llvm/lib/Target/M68k/M68kISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/M68k/M68kISelLowering.cpp,1,['load'],['load']
Performance,"// We shouldn't need to form dedicated exits because the exit introduced; // here is the (just split by unswitching) preheader. However, after trivial; // unswitching it is possible to get new non-dedicated exits out of parent; // loop so let's conservatively form dedicated exit blocks and figure out; // if we can optimize later.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SimpleLoopUnswitch.cpp:316,optimiz,optimize,316,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SimpleLoopUnswitch.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SimpleLoopUnswitch.cpp,1,['optimiz'],['optimize']
Performance,// We shouldn't prefer using the FP to access fixed-sized stack objects when; // there are scalable (SVE) objects in between the FP and the fixed-sized; // objects.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FrameLowering.cpp:91,scalab,scalable,91,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64FrameLowering.cpp,1,['scalab'],['scalable']
Performance,// We skip debug instructions in the analysis. (Note that debug; // location information is still maintained by this optimization; // because it remains on the LXVD2X and STXVD2X instructions after; // the XXPERMDIs are removed.),MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp:117,optimiz,optimization,117,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCVSXSwapRemoval.cpp,1,['optimiz'],['optimization']
Performance,"// We sometimes end up with a 64-bit integer load, from which we extract; // two single-precision floating-point numbers. This happens with; // std::complex<float>, and other similar structures, because of the way we; // canonicalize structure copies. However, if we lack direct moves,; // then the final bitcasts from the extracted integer values to the; // floating-point numbers turn into store/load pairs. Even with direct moves,; // just loading the two floating-point numbers is likely better.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:45,load,load,45,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,3,['load'],"['load', 'loading']"
Performance,// We sometimes skip loading namespace-level results (they tend to be huge).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp:21,load,loading,21,interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,1,['load'],['loading']
Performance,"// We still have chance to sink MI if all stores between are not; // aliased to MI.; // Cache all store instructions, so that we don't need to go through; // all From reachable blocks for next load instruction.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineSink.cpp:88,Cache,Cache,88,interpreter/llvm-project/llvm/lib/CodeGen/MachineSink.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineSink.cpp,2,"['Cache', 'load']","['Cache', 'load']"
Performance,"// We still perform the exact same EXTRACT_SUBVECTOR, just on different; // operand[s]/index[es], so there is no point in checking for it's legality.; // Do not turn a legal shuffle into an illegal one.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:12,perform,perform,12,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['perform'],['perform']
Performance,"// We store extra information about the instruction here. The common case is; // expected to be nothing or a single pointer (typically a MMO or a symbol).; // We work to optimize this common case by storing it inline here rather than; // requiring a separate allocation, but we fall back to an allocation when; // multiple pointers are needed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineInstr.h:170,optimiz,optimize,170,interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineInstr.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineInstr.h,1,['optimiz'],['optimize']
Performance,// We subsequently fall through to later handling that; // will perform any additional cloning required for; // callers that were calling other function clones.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/MemProfContextDisambiguation.cpp:64,perform,perform,64,interpreter/llvm-project/llvm/lib/Transforms/IPO/MemProfContextDisambiguation.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/MemProfContextDisambiguation.cpp,1,['perform'],['perform']
Performance,// We successfully loaded the module file; remember the set of provided; // modules so that we don't try to load implicit modules for them.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp:19,load,loaded,19,interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,2,['load'],"['load', 'loaded']"
Performance,"// We take as unique identifier the declId of the class to; // treat the case where a class is loaded, an instance printed,; // the class unloaded and reloaded with changes.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/pythonizations/src/GenericPyz.cxx:95,load,loaded,95,bindings/pyroot/pythonizations/src/GenericPyz.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/pythonizations/src/GenericPyz.cxx,1,['load'],['loaded']
Performance,"// We then send a tuned loading request to the other workers",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProof.cxx:18,tune,tuned,18,proof/proof/src/TProof.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProof.cxx,2,"['load', 'tune']","['loading', 'tuned']"
Performance,"// We track what is on the current and pending worklist to avoid inserting; // the same thing twice. We could avoid this with a custom priority queue,; // but this is probably not worth it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.cpp:144,queue,queue,144,interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.cpp,1,['queue'],['queue']
Performance,"// We track what is on the pending worklist to avoid inserting the same; // thing twice. We could avoid this with a custom priority queue, but this; // is probably not worth it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/VarLocBasedImpl.cpp:132,queue,queue,132,interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/VarLocBasedImpl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/VarLocBasedImpl.cpp,1,['queue'],['queue']
Performance,"// We track what is on the pending worklist to avoid inserting the same; // thing twice. We could avoid this with a custom priority queue, but; // this is probably not worth it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AssignmentTrackingAnalysis.cpp:132,queue,queue,132,interpreter/llvm-project/llvm/lib/CodeGen/AssignmentTrackingAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AssignmentTrackingAnalysis.cpp,1,['queue'],['queue']
Performance,"// We treat __stosb as a volatile memset - it may not generate ""rep stosb""; // instruction, but it will create a memset that won't be optimized away.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:134,optimiz,optimized,134,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,1,['optimiz'],['optimized']
Performance,// We tried and failed to load a module file for this module. Fall; // back to textual inclusion for its headers.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp:26,load,load,26,interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,1,['load'],['load']
Performance,// We try to do as many non-overlapping loads as possible starting from the; // beginning.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp:40,load,loads,40,interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandMemCmp.cpp,1,['load'],['loads']
Performance,// We try to load it as YAML if the ELF load didn't work.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/XRay/InstrumentationMap.cpp:13,load,load,13,interpreter/llvm-project/llvm/lib/XRay/InstrumentationMap.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/XRay/InstrumentationMap.cpp,2,['load'],['load']
Performance,// We use 64 bits as the known part in the scalable vector types.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/TargetParser/RISCVTargetParser.h:43,scalab,scalable,43,interpreter/llvm-project/llvm/include/llvm/TargetParser/RISCVTargetParser.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/TargetParser/RISCVTargetParser.h,1,['scalab'],['scalable']
Performance,"// We use DSGF for 32-bit division. This means the first operand must; // always be 64-bit, and the second operand should be 32-bit whenever; // that is possible, to improve performance.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:174,perform,performance,174,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,1,['perform'],['performance']
Performance,"// We use EXTRACT_SUBVECTOR as a ""cast"" from scalable to fixed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:45,scalab,scalable,45,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,2,['scalab'],['scalable']
Performance,"// We use LMUL1 memory operations here for a non-obvious reason. Our caller; // has an expansion threshold, and we want the number of hardware memory; // operations to correspond roughly to that threshold. LMUL>1 operations; // are typically expanded linearly internally, and thus correspond to more; // than one actual memory operation. Note that store merging and load; // combining will typically form larger LMUL operations from the LMUL1; // operations emitted here, and that's okay because combining isn't; // introducing new memory operations; it's just merging existing ones.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:366,load,load,366,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['load'],['load']
Performance,"// We use a std::map here to be able to have a defined ordering when; // producing a hash for the cache entry.; // FIXME: we should be able to compute the caching hash for the entry based; // on the index, and nuke this map.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/LTO/ThinLTOCodeGenerator.cpp:98,cache,cache,98,interpreter/llvm-project/llvm/lib/LTO/ThinLTOCodeGenerator.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/LTO/ThinLTOCodeGenerator.cpp,1,['cache'],['cache']
Performance,"// We use alias analysis to check if an instruction may store to; // the memory we load from in between the load and the store. If; // such an instruction is found, we try to promote there instead; // of at the store position.; // TODO: Can use MSSA for this.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp:83,load,load,83,interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/MemCpyOptimizer.cpp,2,['load'],['load']
Performance,// We use cache values if curves and cache array are same length,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:10,cache,cache,10,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,4,['cache'],['cache']
Performance,"// We use ldg (i.e. ld.global.nc) for invariant loads from the global address; // space.; //; // We have two ways of identifying invariant loads: Loads may be explicitly; // marked as invariant, or we may infer them to be invariant.; //; // We currently infer invariance for loads from; // - constant global variables, and; // - kernel function pointer params that are noalias (i.e. __restrict) and; // never written to.; //; // TODO: Perform a more powerful invariance analysis (ideally IPO, and ideally; // not during the SelectionDAG phase).; //; // TODO: Infer invariance only at -O2. We still want to use ldg at -O0 for; // explicitly invariant loads because these are how clang tells us to use ldg; // when the user uses a builtin.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp:48,load,loads,48,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp,6,"['Load', 'Perform', 'load']","['Loads', 'Perform', 'loads']"
Performance,"// We use llvm::SmallVector as the underlying container for the following; // reasons:; //; // * Range sets are usually very simple, 1 or 2 ranges.; // That's why llvm::ImmutableSet is not perfect.; //; // * Ranges in sets are NOT overlapping, so it is natural to keep them; // sorted for efficient operations and queries. For this reason,; // llvm::SmallSet doesn't fit the requirements, it is not sorted when it; // is a vector.; //; // * Range set operations usually a bit harder than add/remove a range.; // Complex operations might do many of those for just one range set.; // Formerly it used to be llvm::ImmutableSet, which is inefficient for our; // purposes as we want to make these operations BOTH immutable AND; // efficient.; //; // * Iteration over ranges is widespread and a more cache-friendly; // structure is preferred.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/StaticAnalyzer/Core/PathSensitive/RangedConstraintManager.h:794,cache,cache-friendly,794,interpreter/llvm-project/clang/include/clang/StaticAnalyzer/Core/PathSensitive/RangedConstraintManager.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/StaticAnalyzer/Core/PathSensitive/RangedConstraintManager.h,1,['cache'],['cache-friendly']
Performance,// We use the Intel Architecture Code Analyzer(IACA) to measure the throughput; // and make it as the cost.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:68,throughput,throughput,68,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,2,['throughput'],['throughput']
Performance,"// We use the minimum store size here, since that's all we can guarantee; // for the scalable vector types.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:85,scalab,scalable,85,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['scalab'],['scalable']
Performance,"// We used ATLAS fully-split xAOD for testing, which is a rather unbalanced TTree, 10K branches,; // with 8K having baskets smaller than 512 bytes. To achieve good I/O performance ATLAS uses auto-flush 100,; // resulting in the smallest baskets being ~300-400 bytes, so this change increases their memory by about 8k*150B =~ 1MB,; // at the same time it significantly reduces the number of total baskets because it ensures that all 100 entries can be; // stored in a single basket (the old optimization tended to make baskets too small). In a toy example with fixed sized; // structures we found a factor of 2 fewer baskets needed in the new scheme.; // rounds up, increases basket size to ensure all entries fit into single basket as intended",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx:168,perform,performance,168,tree/tree/src/TTree.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx,2,"['optimiz', 'perform']","['optimization', 'performance']"
Performance,"// We used to use a dominator tree here to allow multi-block optimization.; // But that was problematic because:; // 1. It could cause a perf regression by hoisting the math op into the; // critical path.; // 2. It could cause a perf regression by creating a value that was live; // across multiple blocks and increasing register pressure.; // 3. Use of a dominator tree could cause large compile-time regression.; // This is because we recompute the DT on every change in the main CGP; // run-loop. The recomputing is probably unnecessary in many cases, so if; // that was fixed, using a DT here would be ok.; //; // There is one important particular case we still want to handle: if BO is; // the IV increment. Important properties that make it profitable:; // - We can speculate IV increment anywhere in the loop (as long as the; // indvar Phi is its only user);; // - Upon computing Cmp, we effectively compute something equivalent to the; // IV increment (despite it loops differently in the IR). So moving it up; // to the cmp point does not really increase register pressure.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:61,optimiz,optimization,61,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,1,['optimiz'],['optimization']
Performance,"// We usually have the interfering VRegs cached so collectInterferingVRegs(); // should be fast, we may need to recalculate if when different physregs; // overlap the same register unit so we had different SubRanges queried; // against it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RegAllocGreedy.cpp:41,cache,cached,41,interpreter/llvm-project/llvm/lib/CodeGen/RegAllocGreedy.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/RegAllocGreedy.cpp,1,['cache'],['cached']
Performance,"// We visit each operand even after successfully folding a previous; // one. This allows us to fold multiple loads into a single; // instruction. We do assume that optimizeLoadInstr doesn't insert; // foldable uses earlier in the argument list. Since we don't restart; // iteration, we'd miss such cases.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/PeepholeOptimizer.cpp:109,load,loads,109,interpreter/llvm-project/llvm/lib/CodeGen/PeepholeOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/PeepholeOptimizer.cpp,2,"['load', 'optimiz']","['loads', 'optimizeLoadInstr']"
Performance,"// We want the sign bit of the higher-order double. The bitcast we just; // did works as if the double-double was stored to memory and then; // read as an i128. The ""store"" will put the higher-order double in the; // lower address in both little- and big-Endian modes, but the ""load""; // will treat those bits as a different part of the i128: the low bits in; // little-Endian, the high bits in big-Endian. Therefore, on big-Endian; // we need to shift the high bits down to the low before truncating.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:278,load,load,278,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,1,['load'],['load']
Performance,"// We want to allow people to specify which columns they; // need so that we can think of upfront IO optimizations.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RArrowDS.cxx:101,optimiz,optimizations,101,tree/dataframe/src/RArrowDS.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RArrowDS.cxx,1,['optimiz'],['optimizations']
Performance,// We want to avoid folding a LOAD into an ICMP node if as a result; // we would be forced to spill the condition code into a GPR.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp:30,LOAD,LOAD,30,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp,1,['LOAD'],['LOAD']
Performance,"// We want to clone the module in a new context to multi-thread the; // codegen. We do it by serializing partition modules to bitcode; // (while still on the main thread, in order to avoid data races) and; // spinning up new threads which deserialize the partitions into; // separate contexts.; // FIXME: Provide a more direct way to do this in LLVM.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ParallelCG.cpp:51,multi-thread,multi-thread,51,interpreter/llvm-project/llvm/lib/CodeGen/ParallelCG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ParallelCG.cpp,2,['multi-thread'],['multi-thread']
Performance,"// We want to detect if Root is part of a tree which represents a bunch; // of loads being merged into a larger load. We'll try to recognize patterns; // like, for example:; //; // Reg Reg; // \ /; // OR_1 Reg; // \ /; // OR_2; // \ Reg; // .. /; // Root; //; // Reg Reg Reg Reg; // \ / \ /; // OR_1 OR_2; // \ /; // \ /; // ...; // Root; //; // Each ""Reg"" may have been produced by a load + some arithmetic. This; // function will save each of them.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:79,load,loads,79,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,3,['load'],"['load', 'loads']"
Performance,// We want to expand nodes that represent load-and-splat even if the; // loaded value is a floating point truncation or conversion to int.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:42,load,load-and-splat,42,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,2,['load'],"['load-and-splat', 'loaded']"
Performance,"// We want to find a load for each register. Each load should have some; // appropriate bit twiddling arithmetic. During this loop, we will also keep; // track of the load which uses the lowest index. Later, we will check if we; // can use its pointer in the final, combined load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:21,load,load,21,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,4,['load'],['load']
Performance,"// We want to find all load dependencies for long chains of stores to enable; // merging into very wide vectors. The problem is with vectors with > 4; // elements. MergeConsecutiveStores will attempt to merge these because x8/x16; // vectors are a legal type, even though we have to split the loads; // usually. When we can more precisely specify load legality per address; // space, we should be able to make FindBetterChain/MergeConsecutiveStores; // smarter so that they can figure out what to do in 2 iterations without all; // N > 4 stores on the same chain.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelLowering.cpp:23,load,load,23,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelLowering.cpp,3,['load'],"['load', 'loads']"
Performance,"// We want to find all possible modules that might contain this header, so; // search all enclosing directories for module maps and load them.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/PPDirectives.cpp:132,load,load,132,interpreter/llvm-project/clang/lib/Lex/PPDirectives.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/PPDirectives.cpp,1,['load'],['load']
Performance,"// We want to find out if the tail-predicated version of this loop will; // produce the same values as the loop in its original form. For this to; // be true, the newly inserted implicit predication must not change the; // the (observable) results.; // We're doing this because many instructions in the loop will not be; // predicated and so the conversion from VPT predication to tail-predication; // can result in different values being produced; due to the tail-predication; // preventing many instructions from updating their falsely predicated; // lanes. This analysis assumes that all the instructions perform lane-wise; // operations and don't perform any exchanges.; // A masked load, whether through VPT or tail predication, will write zeros; // to any of the falsely predicated bytes. So, from the loads, we know that; // the false lanes are zeroed and here we're trying to track that those false; // lanes remain zero, or where they change, the differences are masked away; // by their user(s).; // All MVE stores have to be predicated, so we know that any predicate load; // operands, or stored results are equivalent already. Other explicitly; // predicated instructions will perform the same operation in the original; // loop and the tail-predicated form too. Because of this, we can insert; // loads, stores and other predicated instructions into our Predicated; // set and build from there.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLowOverheadLoops.cpp:608,perform,perform,608,interpreter/llvm-project/llvm/lib/Target/ARM/ARMLowOverheadLoops.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLowOverheadLoops.cpp,7,"['load', 'perform']","['load', 'loads', 'perform']"
Performance,"// We want to immediately iterate on any allocas impacted by splitting; // this load, which is only relevant if it isn't a load of this alloca and; // thus we didn't already split the loads above. We also have to keep track; // of any promotable allocas we split loads on as they can no longer be; // promoted.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:80,load,load,80,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,4,['load'],"['load', 'loads']"
Performance,// We want to legalize this to an f64 load rather than an i64 load on; // 64-bit targets and two 32-bit loads on a 32-bit target. Similar for; // store.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:38,load,load,38,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,3,['load'],"['load', 'loads']"
Performance,// We want to load and autoreleaseReturnValue ARC __weak ivars.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp:14,load,load,14,interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp,1,['load'],['load']
Performance,"// We want to load only already created modules.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:14,load,load,14,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,1,['load'],['load']
Performance,// We want to merge the second load into the first by rewriting the usages of; // the same reg between first (incl.) and second (excl.). We don't need to care; // about any insns before FirstLoad or after SecondLoad.; // 1. The second load writes new value into the same reg.; // - The renaming is impossible to impact later use of the reg.; // - The second load always trash the value written by the first load which; // means the reg must be killed before the second load.; // 2. The first load must be a def for the same reg so we don't need to look; // into anything before it.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp:31,load,load,31,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp,6,['load'],['load']
Performance,"// We want to print a simplified absolute path, i. e. without ""dots"".; //; // The hardest part here are the paths like ""<part1>/<link>/../<part2>"".; // On Unix-like systems, we cannot just collapse ""<link>/.."", because; // paths are resolved sequentially, and, thereby, the path; // ""<part1>/<part2>"" may point to a different location. That is why; // we use FileManager::getCanonicalName(), which expands all indirections; // with llvm::sys::fs::real_path() and caches the result.; //; // On the other hand, it would be better to preserve as much of the; // original path as possible, because that helps a user to recognize it.; // real_path() expands all links, which is sometimes too much. Luckily,; // on Windows we can just use llvm::sys::path::remove_dots(), because,; // on that system, both aforementioned paths point to the same place.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/SARIFDiagnostic.cpp:463,cache,caches,463,interpreter/llvm-project/clang/lib/Frontend/SARIFDiagnostic.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/SARIFDiagnostic.cpp,1,['cache'],['caches']
Performance,"// We want to print a simplified absolute path, i. e. without ""dots"".; //; // The hardest part here are the paths like ""<part1>/<link>/../<part2>"".; // On Unix-like systems, we cannot just collapse ""<link>/.."", because; // paths are resolved sequentially, and, thereby, the path; // ""<part1>/<part2>"" may point to a different location. That is why; // we use FileManager::getCanonicalName(), which expands all indirections; // with llvm::sys::fs::real_path() and caches the result.; //; // On the other hand, it would be better to preserve as much of the; // original path as possible, because that helps a user to recognize it.; // real_path() expands all links, which sometimes too much. Luckily,; // on Windows we can just use llvm::sys::path::remove_dots(), because,; // on that system, both aforementioned paths point to the same place.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/TextDiagnostic.cpp:463,cache,caches,463,interpreter/llvm-project/clang/lib/Frontend/TextDiagnostic.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/TextDiagnostic.cpp,1,['cache'],['caches']
Performance,// We want to put an LFENCE before any instruction that; // may load or store. This LFENCE is intended to avoid leaking any secret; // data due to a given load or store. This results in closing the cache; // and memory timing side channels. We will treat terminators that load; // or store separately.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp:64,load,load,64,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeExecutionSideEffectSuppression.cpp,4,"['cache', 'load']","['cache', 'load']"
Performance,// We want to reanalyze all ObjC methods as top level to report Retain; // Count naming convention errors more aggressively. But we should tune down; // inlining when reanalyzing an already inlined function.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Frontend/AnalysisConsumer.cpp:139,tune,tune,139,interpreter/llvm-project/clang/lib/StaticAnalyzer/Frontend/AnalysisConsumer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Frontend/AnalysisConsumer.cpp,1,['tune'],['tune']
Performance,"// We want to reliably handle any conditional branch terminators in the; // MBB, so we manually analyze the branch. We can handle all of the; // permutations here, including ones that analyze branch cannot.; //; // The approach is to walk backwards across the terminators, resetting at; // any unconditional non-indirect branch, and track all conditional edges; // to basic blocks as well as the fallthrough or unconditional successor; // edge. For each conditional edge, we track the target and the opposite; // condition code in order to inject a ""no-op"" cmov into that successor; // that will harden the predicate. For the fallthrough/unconditional; // edge, we inject a separate cmov for each conditional branch with; // matching condition codes. This effectively implements an ""and"" of the; // condition flags, even if there isn't a single condition flag that would; // directly implement that. We don't bother trying to optimize either of; // these cases because if such an optimization is possible, LLVM should; // have optimized the conditional *branches* in that way already to reduce; // instruction count. This late, we simply assume the minimal number of; // branch instructions is being emitted and use that to guide our cmov; // insertion.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp:926,optimiz,optimize,926,interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86SpeculativeLoadHardening.cpp,3,['optimiz'],"['optimization', 'optimize', 'optimized']"
Performance,// We want to select dup(load) into LD1R.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64RegisterBankInfo.cpp:25,load,load,25,interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64RegisterBankInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64RegisterBankInfo.cpp,1,['load'],['load']
Performance,// We want to use MVC in preference to even a single load/store pair.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:53,load,load,53,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,1,['load'],['load']
Performance,"// We want to visit all of the instructions in this loop... that are not parts; // of our subloops (they have already had their invariants hoisted out of; // their loop, into this loop, so there is no need to process the BODIES of; // the subloops).; //; // Traverse the body of the loop in depth first order on the dominator tree so; // that we are guaranteed to see definitions before we see uses. This allows; // us to sink instructions in one pass, without iteration. After sinking; // instructions, we perform another pass to hoist them out of the loop.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp:507,perform,perform,507,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp,1,['perform'],['perform']
Performance,"// We were loaded before our templated declaration was. We've not set up; // its corresponding type yet (see VisitCXXRecordDeclImpl), so reconstruct; // it now.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp:11,load,loaded,11,interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp,1,['load'],['loaded']
Performance,"// We weren't able to make any changes, so delete the list so we don't; // process the same instructions the next time we try to optimize this; // block.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SILoadStoreOptimizer.cpp:129,optimiz,optimize,129,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SILoadStoreOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SILoadStoreOptimizer.cpp,1,['optimiz'],['optimize']
Performance,// We wil reuse the pointer from the load which ends up at byte offset 0. It; // may not use index 0.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:37,load,load,37,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,1,['load'],['load']
Performance,"// We will either select ds_read_b64/ds_write_b64 or ds_read2_b32/; // ds_write2_b32 depending on the alignment. In either case with either; // alignment there is no faster way of doing this.; // The numbers returned here and below are not additive, it is a 'speed; // rank'. They are just meant to be compared to decide if a certain way; // of lowering an operation is faster than another. For that purpose; // naturally aligned operation gets it bitsize to indicate that ""it; // operates with a speed comparable to N-bit wide load"". With the full; // alignment ds128 is slower than ds96 for example. If underaligned it; // is comparable to a speed of a single dword access, which would then; // mean 32 < 128 and it is faster to issue a wide load regardless.; // 1 is simply ""slow, don't do it"". I.e. comparing an aligned load to a; // wider load which will not be aligned anymore the latter is slower.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:528,load,load,528,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,4,['load'],['load']
Performance,// We will emit PPC::TD or PPC::TW if the 2nd and 3rd operands are reg +; // reg or imm + imm. The imm + imm form will be optimized to either an; // unconditional trap or a nop in a later pass.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp:122,optimiz,optimized,122,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,1,['optimiz'],['optimized']
Performance,// We will have an entry in the map for each block so we grow the; // structure to twice that size to keep the load factor low in the hash table.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/ADCE.cpp:111,load,load,111,interpreter/llvm-project/llvm/lib/Transforms/Scalar/ADCE.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/ADCE.cpp,1,['load'],['load']
Performance,// We won't need to flush pending loads if this asm doesn't touch; // memory and is nonvolatile.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp:34,load,loads,34,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,1,['load'],['loads']
Performance,// We won't optimize the globals that are referenced by an alias for now; // Ideally we should turn the alias into a global and duplicate the definition; // when needed.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/LTO/LTO.cpp:12,optimiz,optimize,12,interpreter/llvm-project/llvm/lib/LTO/LTO.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/LTO/LTO.cpp,1,['optimiz'],['optimize']
Performance,"// We would be able to merge only one extension in a load.; // Therefore, if we have more than 1 new extension we heuristically; // cut this search path, because it means we degrade the code quality.; // With exactly 2, the transformation is neutral, because we will merge; // one extension but leave one. However, we optimistically keep going,; // because the new extension may be removed too. Also avoid replacing a; // single free extension with multiple extensions, as this increases the; // number of IR instructions while not providing any savings.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:53,load,load,53,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,1,['load'],['load']
Performance,"// We would like to perform some checking on the given `operator new` call,; // but the PlacementArgs does not contain the implicit arguments,; // namely allocation size and maybe allocation alignment,; // so we need to conjure them.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp:20,perform,perform,20,interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExprCXX.cpp,1,['perform'],['perform']
Performance,// We'll also ignore MVT::i64 operands as this optimizations proves; // to be ineffective because of the required sign extensions as the result; // of a SETCC operator is always MVT::i32 for non-vector types.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.cpp:47,optimiz,optimizations,47,interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.cpp,1,['optimiz'],['optimizations']
Performance,// We'll need a libcall to perform double precision operations on a single; // precision only FPU.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp:27,perform,perform,27,interpreter/llvm-project/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp,1,['perform'],['perform']
Performance,"// We'll set up the real type in Visit, once we've finished loading the; // function.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp:60,load,loading,60,interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp,1,['load'],['loading']
Performance,"// We're called once per operand, but for some instructions, we need to; // compute known bits of both operands in order to determine the live bits of; // either (when both operands are instructions themselves). We don't,; // however, want to do this twice, so we cache the result in APInts that live; // in the caller. For the two-relevant-operands case, both operand values are; // provided here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/DemandedBits.cpp:264,cache,cache,264,interpreter/llvm-project/llvm/lib/Analysis/DemandedBits.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/DemandedBits.cpp,1,['cache'],['cache']
Performance,// We're creating a completely different type of load/store - LDM from LDR.; // For this reason we can't reuse the logic at the end of this function; we; // have to implement the MI building here.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/Thumb2SizeReduction.cpp:49,load,load,49,interpreter/llvm-project/llvm/lib/Target/ARM/Thumb2SizeReduction.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/Thumb2SizeReduction.cpp,1,['load'],['load']
Performance,"// We're entering tokens into the middle of our cached token stream. We; // can't represent that, so just insert the tokens into the buffer.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/PPLexerChange.cpp:48,cache,cached,48,interpreter/llvm-project/clang/lib/Lex/PPLexerChange.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/PPLexerChange.cpp,1,['cache'],['cached']
Performance,// We're loading one element.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUPromoteAlloca.cpp:9,load,loading,9,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUPromoteAlloca.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUPromoteAlloca.cpp,1,['load'],['loading']
Performance,// We're loading the full vector.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUPromoteAlloca.cpp:9,load,loading,9,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUPromoteAlloca.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUPromoteAlloca.cpp,1,['load'],['loading']
Performance,"// We're looking for a sequence like this:; // t13: i64,ch = load<LD8[%ref.tmp]> t0, t6, undef:i64; // t16: i64 = srl t13, Constant:i32<32>; // t17: i32 = truncate t16; // t18: f32 = bitcast t17; // t19: i32 = truncate t13; // t20: f32 = bitcast t19",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:61,load,load,61,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['load']
Performance,"// We're looking for stores after the first forwarding store until the end; // of the loop, then from the beginning of the loop until the last; // forwarded-to load. Collect the pointer for the stores.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp:160,load,load,160,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp,1,['load'],['load']
Performance,"// We're looking for the following pattern, for either load or store:; // %baseptr:_(p0) = ...; // G_STORE %val(s64), %baseptr(p0); // %offset:_(s64) = G_CONSTANT i64 -256; // %new_addr:_(p0) = G_PTR_ADD %baseptr, %offset(s64)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:55,load,load,55,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,1,['load'],['load']
Performance,"// We're messaging ""id"" as a type; provide all class/factory methods.; // If we have an external source, load the entire class method; // pool from the AST file.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaCodeComplete.cpp:105,load,load,105,interpreter/llvm-project/clang/lib/Sema/SemaCodeComplete.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaCodeComplete.cpp,1,['load'],['load']
Performance,"// We're messaging ""id"", so provide all instance methods we know; // about as code-completion results.; // If we have an external source, load the entire class method; // pool from the AST file.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaCodeComplete.cpp:138,load,load,138,interpreter/llvm-project/clang/lib/Sema/SemaCodeComplete.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaCodeComplete.cpp,1,['load'],['load']
Performance,// We're not doing validity checking here. That was done when checking; // if we should mark the load as indexed or not. We're just selecting; // the right instruction.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelDAGToDAG.cpp:97,load,load,97,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelDAGToDAG.cpp,1,['load'],['load']
Performance,"// We're not in the case above, so there is no conversion that; // we can perform.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp:74,perform,perform,74,interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,1,['perform'],['perform']
Performance,// We're only interested in loads that can be completely folded to a; // constant.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LoopUnrollAnalyzer.cpp:28,load,loads,28,interpreter/llvm-project/llvm/lib/Analysis/LoopUnrollAnalyzer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LoopUnrollAnalyzer.cpp,1,['load'],['loads']
Performance,"// We're past translation phase 6, so perform string literal concatenation; // before checking for """".",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseExprCXX.cpp:38,perform,perform,38,interpreter/llvm-project/clang/lib/Parse/ParseExprCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseExprCXX.cpp,1,['perform'],['perform']
Performance,"// We're performing an ""equal to zero"" compare. Swap the operands so we; // canonicalize on a ""not equal to zero"" compare.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:9,perform,performing,9,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['perform'],['performing']
Performance,"// We're simulating a load through a pointer that was bitcast to point to; // a different type, so we can try to walk down through the initial; // elements of an aggregate to see if some part of the aggregate is; // castable to implement the ""load"" semantic model.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ConstantFolding.cpp:22,load,load,22,interpreter/llvm-project/llvm/lib/Analysis/ConstantFolding.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ConstantFolding.cpp,2,['load'],['load']
Performance,"// We're trying to insert a regular store, S, and then a load, L. If the; // incoming value, O, is a load, we might just be able to have our load use the; // address used by O. However, we don't know if anything else will store to; // that address before we can load from it. To prevent this situation, we need; // to insert our load, L, into the chain as a peer of O. To do this, we give L; // the same chain operand as O, we create a token factor from the chain results; // of O and L, and we replace all uses of O's chain result with that token; // factor (see spliceIntoChain below for this last part).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:57,load,load,57,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,5,['load'],['load']
Performance,"// We're trying to minimize the number of instructions. If we have one; // group, using one of andi/andis can break even. If we have three; // groups, we can use both andi and andis and break even (to use both; // andi and andis we also need to or the results together). We need four; // groups if we also need to rotate. To use andi/andis we need to do more; // than break even because rotate-and-mask instructions tend to be easier; // to schedule.; // FIXME: We've biased here against using andi/andis, which is right for; // POWER cores, but not optimal everywhere. For example, on the A2,; // andi/andis have single-cycle latency whereas the rotate-and-mask; // instructions take two cycles, and it would be better to bias toward; // andi/andis in break-even cases.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp:627,latency,latency,627,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,1,['latency'],['latency']
Performance,// We're using a reference type. Drop the last zero offset load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/CodeViewDebug.cpp:59,load,load,59,interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/CodeViewDebug.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/CodeViewDebug.cpp,1,['load'],['load']
Performance,"// We're using a shifted mask, so the load now has an offset. This means; // that data has been loaded into the lower bytes than it would have been; // before, so we need to shl the loaded data into the correct position in the; // register.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:38,load,load,38,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,3,['load'],"['load', 'loaded']"
Performance,// We've already performed all of the name lookup that we need; // to for Objective-C methods; the next context will be the; // outer scope.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp:17,perform,performed,17,interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,1,['perform'],['performed']
Performance,"// We've already validated that any VPT predication within the loop will be; // equivalent when we perform the predication transformation; so we know that; // any VPT predicated instruction is predicated upon VCTP. Any live-out; // instruction needs to be predicated, so check this here. The instructions; // in NonPredicated have been found to be a reduction that we can ensure its; // legality. Any MQPRCopy found will need to validate its input as if it was; // live out.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLowOverheadLoops.cpp:99,perform,perform,99,interpreter/llvm-project/llvm/lib/Target/ARM/ARMLowOverheadLoops.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMLowOverheadLoops.cpp,1,['perform'],['perform']
Performance,"// We've created a new instruction. Queue users of the old instruction to; // be converted and the instruction itself to be deleted. We can't delete; // the old instruction yet, because it's still in use by a load somewhere.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXLowerArgs.cpp:36,Queue,Queue,36,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXLowerArgs.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXLowerArgs.cpp,2,"['Queue', 'load']","['Queue', 'load']"
Performance,// We've found a store and load that we need to split; // with mismatched relative splits. Just give up on them; // and remove both instructions from our list of; // candidates.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:27,load,load,27,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,1,['load'],['load']
Performance,// We've found the comparison category type. Build a new cache entry for; // it.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ComparisonCategories.cpp:57,cache,cache,57,interpreter/llvm-project/clang/lib/AST/ComparisonCategories.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ComparisonCategories.cpp,1,['cache'],['cache']
Performance,// We've loaded i1 as an i8 and now must truncate it back to i1,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:9,load,loaded,9,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,1,['load'],['loaded']
Performance,"// We've not actually loaded the ClassTemplateDecl yet, because we're; // currently being loaded as its pattern. Rely on it to set up our; // TypeForDecl (see VisitClassTemplateDecl).; //; // Beware: we do not yet know our canonical declaration, and may still; // get merged once the surrounding class template has got off the ground.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp:22,load,loaded,22,interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp,2,['load'],['loaded']
Performance,"// We've not seen this before, or the file is cached as non-existent.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/FileManager.cpp:46,cache,cached,46,interpreter/llvm-project/clang/lib/Basic/FileManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/FileManager.cpp,1,['cache'],['cached']
Performance,"// We've performed the shift by a CHAR_BIT * [_ShAmt / CHAR_BIT_]; // If we may still have a less-than-CHAR_BIT to shift by, do so now.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeIntegerTypes.cpp:9,perform,performed,9,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeIntegerTypes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeIntegerTypes.cpp,1,['perform'],['performed']
Performance,// We've seen enough strided loads that seeing more won't make a; // difference.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp:29,load,loads,29,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,1,['load'],['loads']
Performance,// We've successfully built the required types and expressions. Update; // the cache and return the newly cached value.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp:79,cache,cache,79,interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp,2,['cache'],"['cache', 'cached']"
Performance,"// WebAssembly constant offsets are performed as unsigned with infinite; // precision, so we need to check for NoUnsignedWrap so that we don't fold an; // offset for an add that needs wrapping.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelDAGToDAG.cpp:36,perform,performed,36,interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelDAGToDAG.cpp,1,['perform'],['performed']
Performance,// WebAssembly doesn't have:; // - Floating-point extending loads.; // - Floating-point truncating stores.; // - i1 extending loads.; // - truncating SIMD stores and most extending loads,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp:60,load,loads,60,interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp,3,['load'],['loads']
Performance,"// WebAssembly supports unaligned accesses, though it should be declared; // with the p2align attribute on loads and stores which do so, and there; // may be a performance impact. We tell LLVM they're ""fast"" because; // for the kinds of things that LLVM uses this for (merging adjacent stores; // of constants, etc.), WebAssembly implementations will either want the; // unaligned access or they'll split anyway.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp:107,load,loads,107,interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp,2,"['load', 'perform']","['loads', 'performance']"
Performance,"// Well since some emulated class is replaced by a real class, we can; // assume a new library has been loaded. If this is the case, we should; // check whether the class now exist (this would be the case for example; // for reading STL containers).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TStreamerElement.cxx:104,load,loaded,104,core/meta/src/TStreamerElement.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TStreamerElement.cxx,1,['load'],['loaded']
Performance,"// Whatever aliasing information we had for the orignal load must also; // hold for the smaller load, so propagate the annotations.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp:56,load,load,56,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp,2,['load'],['load']
Performance,"// Whatever the data source, initially set the ""new data block"" flag:; // - for TChains, this ensures that we don't skip the first data block because; // the correct tree is already loaded; // - for RDataSources and empty sources, which currently don't have data blocks, this; // ensures that we run once per task",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RLoopManager.cxx:182,load,loaded,182,tree/dataframe/src/RLoopManager.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RLoopManager.cxx,1,['load'],['loaded']
Performance,"// When -O0 is enabled, the Load Value Injection Hardening pass will fall back; // to using the Speculative Execution Side Effect Suppression pass for; // mitigation. This is to prevent slow downs due to; // analyses needed by the LVIHardening pass when compiling at -O0.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:28,Load,Load,28,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp,1,['Load'],['Load']
Performance,"// When AA isn't available, but if the load and the store have the same; // base, constant offsets and non-overlapping access ranges, ignore the; // store. This is a simple form of alias analysis that is used by the; // inliner. FIXME: use BasicAA if possible.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/Loads.cpp:39,load,load,39,interpreter/llvm-project/llvm/lib/Analysis/Loads.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/Loads.cpp,1,['load'],['load']
Performance,"// When LoadFuncsToBeUsed is false, we are using LLVM tool, need to read all; // profiles.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ProfileData/SampleProfReader.cpp:8,Load,LoadFuncsToBeUsed,8,interpreter/llvm-project/llvm/lib/ProfileData/SampleProfReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ProfileData/SampleProfReader.cpp,1,['Load'],['LoadFuncsToBeUsed']
Performance,"// When SrcReg is $zero, treat loaded value as immediate only.; // Ex. $a2 = ADDiu $zero, 10",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsInstrInfo.cpp:31,load,loaded,31,interpreter/llvm-project/llvm/lib/Target/Mips/MipsInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsInstrInfo.cpp,1,['load'],['loaded']
Performance,"// When UnifiedLTO is enabled, use the ThinLTO pre-link pipeline. This; // avoids compile-time performance regressions and keeps the pre-link; // LTO pipeline ""unified"" for both LTO modes.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilder.cpp:95,perform,performance,95,interpreter/llvm-project/llvm/lib/Passes/PassBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilder.cpp,1,['perform'],['performance']
Performance,"// When Zicond or XVentanaCondOps is present, emit CZERO_EQZ and CZERO_NEZ; // nodes to implement the SELECT. Performing the lowering here allows for; // greater control over when CZERO_{EQZ/NEZ} are used vs another branchless; // sequence or RISCVISD::SELECT_CC node (branch-based select).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:110,Perform,Performing,110,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['Perform'],['Performing']
Performance,// When a module is loaded we save the SectionID of the EH frame section; // in a table until we receive a request to register all unregistered; // EH frame sections with the memory manager.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.h:20,load,loaded,20,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.h,2,['load'],['loaded']
Performance,// When a module is loaded we save the SectionID of the unwind; // sections in a table until we receive a request to register all; // unregisteredEH frame sections with the memory manager.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldCOFFAArch64.h:20,load,loaded,20,interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldCOFFAArch64.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldCOFFAArch64.h,2,['load'],['loaded']
Performance,"// When a slot is loaded from in a block without being stored to in the; // same block, it is live-on-entry to this block. To avoid CFG analysis,; // consider this slot to be live-on-exit from all blocks.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonFrameLowering.cpp:18,load,loaded,18,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonFrameLowering.cpp,1,['load'],['loaded']
Performance,"// When adding a NEW PPCISD node please add it to the correct position in; // the enum. The order of elements in this enum matters!; // Values that are added after this entry:; // STBRX = ISD::FIRST_TARGET_MEMORY_OPCODE; // are considered memory opcodes and are treated differently than entries; // that come before it. For example, ADD or MUL should be placed before; // the ISD::FIRST_TARGET_MEMORY_OPCODE while a LOAD or STORE should come; // after it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.h:416,LOAD,LOAD,416,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.h,1,['LOAD'],['LOAD']
Performance,"// When aggressively optimizing for code size, we prefer to use a div; // instruction, as it is usually smaller than the alternative sequence.; // TODO: Add vector division?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:21,optimiz,optimizing,21,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['optimiz'],['optimizing']
Performance,"// When an application load is atomic, increase atomic ordering between; // atomic application loads and stores to ensure happen-before order; load; // shadow data after application data; store zero shadow data before; // application data. This ensure shadow loads return either labels of the; // initial application data or zeros.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp:23,load,load,23,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp,4,['load'],"['load', 'loads']"
Performance,"// When an application store is atomic, increase atomic ordering between; // atomic application loads and stores to ensure happen-before order; load; // shadow data after application data; store zero shadow data before; // application data. This ensure shadow loads return either labels of the; // initial application data or zeros.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp:96,load,loads,96,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp,3,['load'],"['load', 'loads']"
Performance,"// When an edge in the graph has been threaded, values that we could not; // determine a value for before (i.e. were marked overdefined) may be; // possible to solve now. We do NOT try to proactively update these values.; // Instead, we clear their entries from the cache, and allow lazy updating to; // recompute them when needed.; // The updating process is fairly simple: we need to drop cached info; // for all values that were marked overdefined in OldSucc, and for those same; // values in any successor of OldSucc (except NewSucc) in which they were; // also marked overdefined.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LazyValueInfo.cpp:266,cache,cache,266,interpreter/llvm-project/llvm/lib/Analysis/LazyValueInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LazyValueInfo.cpp,2,['cache'],"['cache', 'cached']"
Performance,"// When an input file is specified, exit immediately if the file cannot be; // read. If getOrCreateModuleInfo succeeds, symbolizeInput will reuse the; // cached file handle.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-symbolizer/llvm-symbolizer.cpp:154,cache,cached,154,interpreter/llvm-project/llvm/tools/llvm-symbolizer/llvm-symbolizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-symbolizer/llvm-symbolizer.cpp,1,['cache'],['cached']
Performance,"// When an instruction is retired after timeline-max-cycles,; // its CycleRetired is left at 0. However, it's possible for; // a 0 latency instruction to be retired during cycle 0 and we; // don't want to early exit in that case. The CycleExecuted; // attribute is set correctly whether or not it is greater; // than timeline-max-cycles so we can use that to ensure; // we don't early exit because of a 0 latency instruction.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-mca/Views/TimelineView.cpp:131,latency,latency,131,interpreter/llvm-project/llvm/tools/llvm-mca/Views/TimelineView.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-mca/Views/TimelineView.cpp,2,['latency'],['latency']
Performance,"// When bitcasting from scalar to fixed-length vector, insert the scalar; // into a one-element vector of the result type, and perform a vector; // bitcast.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:127,perform,perform,127,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['perform'],['perform']
Performance,"// When cache is enabled, reload from the cache if possible.; // Releasing the buffer from the heap and reloading it from the; // cache file with mmap helps us to lower memory pressure.; // The freed memory can be used for the next input file.; // The final binary link will read from the VFS cache (hopefully!); // or from disk (if the memory pressure was too high).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/LTO/ThinLTOCodeGenerator.cpp:8,cache,cache,8,interpreter/llvm-project/llvm/lib/LTO/ThinLTOCodeGenerator.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/LTO/ThinLTOCodeGenerator.cpp,4,['cache'],['cache']
Performance,"// When caching a virtual directory, we always cache its ancestors; // at the same time. Therefore, if DirName is already in the cache,; // we don't need to recurse as its ancestors must also already be in; // the cache (or it's a known non-virtual directory).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/FileManager.cpp:47,cache,cache,47,interpreter/llvm-project/clang/lib/Basic/FileManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/FileManager.cpp,3,['cache'],['cache']
Performance,"// When calling a lambda, both the call operator, and; // the conversion operator to function pointer; // are considered. But when constraint checking; // on the call operator fails, it will also fail on the; // conversion operator as the constraints are always the same.; // As the user probably does not intend to perform a surrogate call,; // we filter them out to produce better error diagnostics, ie to avoid; // showing 2 failed overloads instead of one.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp:316,perform,perform,316,interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,1,['perform'],['perform']
Performance,"// When collecting entries from input vfsoverlays, copy the external; // contents into the cache but still map from the source.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/ModuleDependencyCollector.cpp:91,cache,cache,91,interpreter/llvm-project/clang/lib/Frontend/ModuleDependencyCollector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/ModuleDependencyCollector.cpp,1,['cache'],['cache']
Performance,"// When compiling for the OpenMP device we want protected visibility by; // default. This prevents the device from accidentally preempting code on; // the host, makes the system more robust, and improves performance.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp:204,perform,performance,204,interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp,1,['perform'],['performance']
Performance,"// When computing known bits, use the GEPs as context instructions, since; // they likely are in the same BB as the load/store.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoadStoreVectorizer.cpp:116,load,load,116,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoadStoreVectorizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoadStoreVectorizer.cpp,1,['load'],['load']
Performance,"// When considering an associated namespace, the lookup is the; // same as the lookup performed when the associated namespace is; // used as a qualifier (3.4.3.2) except that:; //; // -- Any using-directives in the associated namespace are; // ignored.; //; // -- Any namespace-scope friend functions declared in; // associated classes are visible within their respective; // namespaces even if they are not visible during an ordinary; // lookup (11.4).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOpenMP.cpp:86,perform,performed,86,interpreter/llvm-project/clang/lib/Sema/SemaOpenMP.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOpenMP.cpp,1,['perform'],['performed']
Performance,"// When considering an associated namespace, the lookup is the; // same as the lookup performed when the associated namespace is; // used as a qualifier (3.4.3.2) except that:; //; // -- Any using-directives in the associated namespace are; // ignored.; //; // -- Any namespace-scope friend functions declared in; // associated classes are visible within their respective; // namespaces even if they are not visible during an ordinary; // lookup (11.4).; //; // C++20 [basic.lookup.argdep] p4.3; // -- are exported, are attached to a named module M, do not appear; // in the translation unit containing the point of the lookup, and; // have the same innermost enclosing non-inline namespace scope as; // a declaration of an associated entity attached to M.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp:86,perform,performed,86,interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,1,['perform'],['performed']
Performance,"// When converting a <N x iX> vector to <N x i1> to store or use as a scalar; // iN, we can use a trick that extracts the i^th bit from the i^th element and; // then performs a vector add to get a scalar bitmask. This requires that each; // element's bits are either all 1 or all 0.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:166,perform,performs,166,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['perform'],['performs']
Performance,"// When division is cheap or optimizing for minimum size,; // fall through to DIVREM creation by skipping this fold.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp:29,optimiz,optimizing,29,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/TargetLowering.cpp,1,['optimiz'],['optimizing']
Performance,"// When doing parseForModule avoid warning about the user code; // being loaded ... we probably might as well extend this to; // ALL warnings ... but this will suffice for now (working; // around a real bug in QT :().",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/Interpreter.cpp:73,load,loaded,73,interpreter/cling/lib/Interpreter/Interpreter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/Interpreter.cpp,1,['load'],['loaded']
Performance,"// When emitting Stable ABI instrumentation, force outlining calls and avoid; // inlining shadow memory poisoning. While this is a big performance burden; // for now it allows full abstraction from implementation details.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/SanitizerArgs.cpp:135,perform,performance,135,interpreter/llvm-project/clang/lib/Driver/SanitizerArgs.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/SanitizerArgs.cpp,1,['perform'],['performance']
Performance,"// When enabling tracking load instructions, we always use; // __dfsan_load_label_and_origin to reduce code size.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp:26,load,load,26,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp,1,['load'],['load']
Performance,"// When finding devirtualizable calls, it's possible to find the same; // vtable passed to multiple llvm.type.test or llvm.type.checked.load; // calls, which can cause duplicate call sites to be recorded in; // [Const]CallSites. If we've already found one of these; // call instances, just ignore it. It will be replaced later.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/WholeProgramDevirt.cpp:136,load,load,136,interpreter/llvm-project/llvm/lib/Transforms/IPO/WholeProgramDevirt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/WholeProgramDevirt.cpp,1,['load'],['load']
Performance,"// When fully building the reflection info in TClass, a deserialization; // could be triggered, which may result in request for building the; // reflection info for the same TClass. This in turn will clear the caches; // for the TClass in-flight and cause null ptr derefs.; // FIXME: This is a quick fix, solving most of the issues. The actual; // question is: Shouldn't TClass provide a lock mechanism on update or lock; // itself until the update is done.; //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:210,cache,caches,210,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,1,['cache'],['caches']
Performance,"// When hoisting, make sure we don't carry the debug location of; // the original instruction, as that's not correct and can cause; // unexpected jumps when debugging optimized code.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineCSE.cpp:167,optimiz,optimized,167,interpreter/llvm-project/llvm/lib/CodeGen/MachineCSE.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineCSE.cpp,1,['optimiz'],['optimized']
Performance,"// When inserting a smaller vector into the larger to store, we first; // use a shuffle vector to widen it with undef elements, and then; // a second shuffle vector to select between the loaded vector and the; // incoming vector.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:187,load,loaded,187,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,1,['load'],['loaded']
Performance,"// When loading a non-modular PCH files, this is used to restore module; // visibility.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Sema/Sema.h:8,load,loading,8,interpreter/llvm-project/clang/include/clang/Sema/Sema.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Sema/Sema.h,1,['load'],['loading']
Performance,// When loading a scalar and then shuffling it into a vector we can often do; // the insertion cheaply.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,load,loading,8,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,2,['load'],['loading']
Performance,"// When loading from constant pools, load the lower address part in; // the instruction itself. Example, instead of:; // lui $2, %hi($CPI1_0); // addiu $2, $2, %lo($CPI1_0); // lwc1 $f0, 0($2); // Generate:; // lui $2, %hi($CPI1_0); // lwc1 $f0, %lo($CPI1_0)($2)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/Mips16ISelDAGToDAG.cpp:8,load,loading,8,interpreter/llvm-project/llvm/lib/Target/Mips/Mips16ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/Mips16ISelDAGToDAG.cpp,4,['load'],"['load', 'loading']"
Performance,"// When lowering comparisons, we sometimes need to perform two compares instead; // of just one. Get the condition codes for both comparisons. If only one is; // needed, the second member of the pair is ARMCC::AL.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMInstructionSelector.cpp:51,perform,perform,51,interpreter/llvm-project/llvm/lib/Target/ARM/ARMInstructionSelector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMInstructionSelector.cpp,1,['perform'],['perform']
Performance,// When multiple cases share the same code they can be combined during; // optimization. In that case the weights of the branch will be the sum of; // the individual weights. Make sure the combined sum of all neutral cases; // doesn't exceed the value of a single likely attribute.; // The additions both avoid divisions by 0 and make sure the weights of None; // don't exceed the weight of Likely.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGStmt.cpp:75,optimiz,optimization,75,interpreter/llvm-project/clang/lib/CodeGen/CGStmt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGStmt.cpp,1,['optimiz'],['optimization']
Performance,"// When no alignment is specified for the load instruction,; // natural alignment is assumed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/AttributorAttributes.cpp:42,load,load,42,interpreter/llvm-project/llvm/lib/Transforms/IPO/AttributorAttributes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/AttributorAttributes.cpp,1,['load'],['load']
Performance,"// When not doing VFE, emit a normal load, as it allows more; // optimisations than type.checked.load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/ItaniumCXXABI.cpp:37,load,load,37,interpreter/llvm-project/clang/lib/CodeGen/ItaniumCXXABI.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/ItaniumCXXABI.cpp,2,['load'],['load']
Performance,"// When on the master, the master and/or slaves may share; // their file systems and cache. Therefore always make a; // check for the file. If the file already exists with the; // expected md5 the kPROOF_CHECKFILE command will cause the; // file to be copied from cache to slave sandbox.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProof.cxx:85,cache,cache,85,proof/proof/src/TProof.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProof.cxx,2,['cache'],['cache']
Performance,// When onLoad was called and url was deleted in `loading`,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/modules/three.mjs:50,load,loading,50,js/modules/three.mjs,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/modules/three.mjs,1,['load'],['loading']
Performance,"// When optimizations are requested, run KCIFPass after InstCombine to; // avoid unnecessary checks.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/BackendUtil.cpp:8,optimiz,optimizations,8,interpreter/llvm-project/clang/lib/CodeGen/BackendUtil.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/BackendUtil.cpp,1,['optimiz'],['optimizations']
Performance,"// When optimizing for size, call 'operator delete' unconditionally.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExprCXX.cpp:8,optimiz,optimizing,8,interpreter/llvm-project/clang/lib/CodeGen/CGExprCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExprCXX.cpp,1,['optimiz'],['optimizing']
Performance,"// When optimizing for size, generate up to 5 extra bytes for a broadcast; // instruction to save 8 or more bytes of constant pool data.; // TODO: If multiple splats are generated to load the same constant,; // it may be detrimental to overall size. There needs to be a way to detect; // that condition to know if this is truly a size win.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:8,optimiz,optimizing,8,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,2,"['load', 'optimiz']","['load', 'optimizing']"
Performance,"// When optimizing for size, selects are preferable over branches.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectOptimize.cpp:8,optimiz,optimizing,8,interpreter/llvm-project/llvm/lib/CodeGen/SelectOptimize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectOptimize.cpp,2,['optimiz'],['optimizing']
Performance,"// When optimizing for size, use LoopSize + 1 as threshold (we use < Threshold; // later), to (fully) unroll loops, if it does not increase code size.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopUnrollPass.cpp:8,optimiz,optimizing,8,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopUnrollPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopUnrollPass.cpp,1,['optimiz'],['optimizing']
Performance,"// When optimizing, if wasm-opt is available, run it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/WebAssembly.cpp:8,optimiz,optimizing,8,interpreter/llvm-project/clang/lib/Driver/ToolChains/WebAssembly.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/WebAssembly.cpp,1,['optimiz'],['optimizing']
Performance,"// When performing a scope lookup, we want to find local extern decls.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp:8,perform,performing,8,interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,2,['perform'],['performing']
Performance,// When performing left recursion:; // A & B => C [if] A => C or B => C; // When performing left recursion (negated):; // !(A & B) => C [if] !A | !B => C [===] !A => C and !B => C,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/ThreadSafetyLogical.cpp:8,perform,performing,8,interpreter/llvm-project/clang/lib/Analysis/ThreadSafetyLogical.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/ThreadSafetyLogical.cpp,2,['perform'],['performing']
Performance,// When performing left recursion:; // A | B => C [if] A => C and B => C; // When performing left recursion (negated):; // !(A | B) => C [if] !A & !B => C [===] !A => C or !B => C,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/ThreadSafetyLogical.cpp:8,perform,performing,8,interpreter/llvm-project/clang/lib/Analysis/ThreadSafetyLogical.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/ThreadSafetyLogical.cpp,2,['perform'],['performing']
Performance,"// When performing member access on a prvalue, materialize a temporary.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp:8,perform,performing,8,interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaOverload.cpp,1,['perform'],['performing']
Performance,"// When performing pointer casts, it's OK if the value is null.; // Skip the remaining checks in that case.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExpr.cpp:8,perform,performing,8,interpreter/llvm-project/clang/lib/CodeGen/CGExpr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExpr.cpp,1,['perform'],['performing']
Performance,// When performing right recursion:; // C => (A | B) [if] C => A or C => B; // When performing right recursion (negated):; // C => !(A | B) [if] C => !A & !B [===] C => !A and C => !B,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/ThreadSafetyLogical.cpp:8,perform,performing,8,interpreter/llvm-project/clang/lib/Analysis/ThreadSafetyLogical.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/ThreadSafetyLogical.cpp,2,['perform'],['performing']
Performance,// When performing right recursion:; // C => A & B [if] C => A and C => B; // When performing right recursion (negated):; // C => !(A & B) [if] C => !A | !B [===] C => !A or C => !B,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/ThreadSafetyLogical.cpp:8,perform,performing,8,interpreter/llvm-project/clang/lib/Analysis/ThreadSafetyLogical.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/ThreadSafetyLogical.cpp,2,['perform'],['performing']
Performance,// When performing tail call optimization the callee pops its arguments off; // the stack. Account for this here so these bytes can be pushed back on in; // PPCFrameLowering::eliminateCallFramePseudoInstr.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:8,perform,performing,8,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,2,"['optimiz', 'perform']","['optimization', 'performing']"
Performance,"// When processing loads, we need to propagate two bits of information to the; // sunk load: whether it is volatile, and what its alignment is.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombinePHI.cpp:19,load,loads,19,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombinePHI.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombinePHI.cpp,2,['load'],"['load', 'loads']"
Performance,"// When retrieving symbolic pointer and expecting a non-void pointer,; // wrap them into element regions of the expected type if necessary.; // It is necessary to make sure that the retrieved value makes sense,; // because there's no other cast in the AST that would tell us to cast; // it to the correct pointer type. We might need to do that for non-void; // pointers as well.; // FIXME: We really need a single good function to perform casts for us; // correctly every time we need it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/SValBuilder.cpp:431,perform,perform,431,interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/SValBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/SValBuilder.cpp,1,['perform'],['perform']
Performance,"// When returning, update the memoization cache.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/ASTMatchers/ASTMatchFinder.cpp:42,cache,cache,42,interpreter/llvm-project/clang/lib/ASTMatchers/ASTMatchFinder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/ASTMatchers/ASTMatchFinder.cpp,1,['cache'],['cache']
Performance,"// When scheduling a dot cur instruction, check if there is an instruction; // that can use the dot cur in the same packet. If so, we'll attempt to; // schedule it before other instructions. We only do this if the load has a; // single zero-latency use.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonHazardRecognizer.cpp:214,load,load,214,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonHazardRecognizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonHazardRecognizer.cpp,2,"['latency', 'load']","['latency', 'load']"
Performance,"// When scheduling bottom-up, use greater-than as the queue priority.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp:54,queue,queue,54,interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp,1,['queue'],['queue']
Performance,// When set to false no nullability information will be tracked in; // NullabilityMap. It is possible to catch errors like passing a null pointer; // to a callee that expects nonnull argument without the information that is; // stored in the NullabilityMap. This is an optimization.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/NullabilityChecker.cpp:269,optimiz,optimization,269,interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/NullabilityChecker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/NullabilityChecker.cpp,1,['optimiz'],['optimization']
Performance,"// When sinking a Def and its DBG_VALUEs, we shouldn't just remove the; // original DBG_VALUE instructions; we should set them to undef not to create; // an impossible combination of variable assignments in the original program.; // For example, this is the original program in order:; // %0 = CONST_I32 0; // DBG_VALUE %0, !""a"", !DIExpression() // a = 0, b = ?; // %1 = CONST_I32 1; // DBG_VALUE %1, !""b"", !DIExpression() // a = 0, b = 1; // %2 = CONST_I32 2; // DBG_VALUE %2, !""a"", !DIExpression() // a = 2, b = 1; // %3 = CONST_I32 3; // DBG_VALUE %3, !""b"", !DIExpression() // a = 2, b = 3; //; // If %2 were to sink below %3, if we just sink DBG_VALUE %1 with it, the; // debug info will show the variable ""b"" is updated to 2, creating the; // variable assignment combination of (a = 0, b = 3), which is not possible in; // the original program:; // %0 = CONST_I32 0; // DBG_VALUE %0, !""a"", !DIExpression() // a = 0, b = ?; // %1 = CONST_I32 1; // DBG_VALUE %1, !""b"", !DIExpression() // a = 0, b = 1; // %3 = CONST_I32 3; // DBG_VALUE %3, !""b"", !DIExpression() // a = 0, b = 3 (Incorrect!); // %2 = CONST_I32 2; // DBG_VALUE %2, !""a"", !DIExpression() // a = 2, b = 3; //; // To fix this,we leave an undef DBG_VALUE in its original place, so that the; // result will be; // %0 = CONST_I32 0; // DBG_VALUE %0, !""a"", !DIExpression() // a = 0, b = ?; // %1 = CONST_I32 1; // DBG_VALUE %1, !""b"", !DIExpression() // a = 0, b = 1; // DBG_VALUE $noreg, !""a"", !DIExpression() // a = ?, b = 1; // %3 = CONST_I32 3; // DBG_VALUE %3, !""b"", !DIExpression() // a = ?, b = 3; // %2 = CONST_I32 2; // DBG_VALUE %2, !""a"", !DIExpression() // a = 2, b = 3; // Now in the middle ""a"" will be shown as ""optimized out"", but it wouldn't; // show the impossible combination of (a = 0, b = 3).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyDebugValueManager.cpp:1685,optimiz,optimized,1685,interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyDebugValueManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyDebugValueManager.cpp,1,['optimiz'],['optimized']
Performance,"// When starting up ROOT, cling would load all modulemap files on the include; // paths. However, in a ROOT session, it is very common to run aclic which; // will invoke rootcling and possibly produce a modulemap and a module in; // the current folder.; //; // Before failing, try loading the modulemap in the current folder and try; // loading the requested module from it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:38,load,load,38,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,3,['load'],"['load', 'loading']"
Performance,"// When targeting a floating-point unit with only single-precision; // operations, f64 is legal for the few double-precision instructions which; // are present However, no double-precision operations other than moves,; // loads and stores are provided by the hardware.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:222,load,loads,222,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['load'],['loads']
Performance,"// When the byte size is small enough, we can load the shadow directly with; // just a few instructions.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp:46,load,load,46,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/DataFlowSanitizer.cpp,1,['load'],['load']
Performance,"// When the feeding operation is an add-immediate of some sort,; // determine whether we need to add relocation information to the; // target flags on the immediate operand when we fold it into the; // load instruction.; //; // For something like ADDItocL, the relocation information is; // inferred from the opcode; when we process it in the AsmPrinter,; // we add the necessary relocation there. A load, though, can receive; // relocation from various flavors of ADDIxxx, so we need to carry; // the relocation information in the target flags.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp:202,load,load,202,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,2,['load'],['load']
Performance,"// When the interactive ROOT starts, it can automatically load some frequently; // used includes. However, this introduces several overheads; // -The initialisation takes more time; // -Memory overhead when including <vector>; // In $ROOTSYS/etc/system.rootrc, you can set the variable Rint.Includes to 0; // to disable the loading of these includes at startup.; // You can set the variable to 1 (default) to load only <iostream>, <string> and <DllImport.h>; // You can set it to 2 to load in addition <vector> and <utility>; // We strongly recommend setting the variable to 2 if your scripts include <vector>; // and you execute your scripts multiple times.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/rint/src/TRint.cxx:58,load,load,58,core/rint/src/TRint.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/rint/src/TRint.cxx,4,['load'],"['load', 'loading']"
Performance,"// When the requested version does not exist we return; // the TVirtualStreamerInfo for the currently loaded class version.; // FIXME: This arguably makes no sense, we should warn and return nothing instead.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:102,load,loaded,102,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,2,['load'],['loaded']
Performance,"// When the requested version does not exist we return; // the TVirtualStreamerInfo for the currently loaded class version.; // FIXME: This arguably makes no sense, we should warn and return nothing instead.; // Note: This is done for STL collections; // Note: fClassVersion could be -1 here (for an emulated class).; // This is also the code path take for unversioned classes.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:102,load,loaded,102,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,1,['load'],['loaded']
Performance,"// When the shuffle is mirrored between the 128-bit lanes of the unit, we; // can use lower latency instructions that will operate on all four; // 128-bit lanes.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:92,latency,latency,92,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['latency'],['latency']
Performance,"// When the shuffle is mirrored between the 128-bit lanes of the unit, we; // can use lower latency instructions that will operate on both lanes.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:92,latency,latency,92,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['latency'],['latency']
Performance,"// When the value is a scalable vector, we save the pointer which points to; // the scalable vector value in the stack. The ValVT will be the pointer; // type, instead of the scalable vector type.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:23,scalab,scalable,23,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,3,['scalab'],['scalable']
Performance,"// When the workspaces get larger, traversing the linked list becomes a bottleneck:",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooWorkspace.cxx:72,bottleneck,bottleneck,72,roofit/roofitcore/src/RooWorkspace.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooWorkspace.cxx,1,['bottleneck'],['bottleneck']
Performance,"// When these options are used, the compiler is allowed to apply; // optimizations that may affect the final result. For example; // (x+y)+z is transformed to x+(y+z) but may not give the same; // final result; it's not value safe.; // Another example can be to simplify x/x to 1.0 but x could be 0.0, INF; // or NaN. Final result may then differ. An error is issued when the eval; // method is set with one of these options.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInvocation.cpp:69,optimiz,optimizations,69,interpreter/llvm-project/clang/lib/Frontend/CompilerInvocation.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInvocation.cpp,1,['optimiz'],['optimizations']
Performance,"// When true, performs RVO for the return object.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGCoroutine.cpp:14,perform,performs,14,interpreter/llvm-project/clang/lib/CodeGen/CGCoroutine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGCoroutine.cpp,1,['perform'],['performs']
Performance,"// When using FP to access scalable vector objects, we need to minus; // the frame size.; //; // |--------------------------| -- <-- FP; // | callee-allocated save | |; // | area for register varargs| |; // |--------------------------| |; // | callee-saved registers | |; // |--------------------------| | MFI.getStackSize(); // | scalar local variables | |; // |--------------------------| -- (Offset of RVV objects is from here.); // | RVV objects |; // |--------------------------|; // | VarSize objects |; // |--------------------------| <-- SP",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVFrameLowering.cpp:27,scalab,scalable,27,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVFrameLowering.cpp,1,['scalab'],['scalable']
Performance,"// When using an external thunk for retpolines, we pick names that match the; // names GCC happens to use as well. This helps simplify the implementation; // of the thunks for kernels where they have no easy ability to create; // aliases and are doing non-trivial configuration of the thunk's body. For; // example, the Linux kernel will do boot-time hot patching of the thunk; // bodies and cannot easily export aliases of these to loaded modules.; //; // Note that at any point in the future, we may need to change the semantics; // of how we implement retpolines and at that time will likely change the; // name of the called thunk. Essentially, there is no hard guarantee that; // LLVM will generate calls to specific thunks, we merely make a best-effort; // attempt to help out kernels and other systems where duplicating the; // thunks is costly.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:433,load,loaded,433,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['loaded']
Performance,"// When using both -save-temps and -emit-llvm, use a "".tmp.bc"" suffix for; // the unoptimized bitcode so that it does not get overwritten by the "".bc""; // optimized bitcode output.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/Driver.cpp:155,optimiz,optimized,155,interpreter/llvm-project/clang/lib/Driver/Driver.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/Driver.cpp,1,['optimiz'],['optimized']
Performance,"// When we change the post-inc loop set, cached expansions may no; // longer be valid.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Utils/ScalarEvolutionExpander.h:41,cache,cached,41,interpreter/llvm-project/llvm/include/llvm/Transforms/Utils/ScalarEvolutionExpander.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Utils/ScalarEvolutionExpander.h,1,['cache'],['cached']
Performance,"// When we have used up the cache, start a new cache and add; // some more events to it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAcceptReject.cxx:28,cache,cache,28,roofit/roofitcore/src/RooAcceptReject.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAcceptReject.cxx,2,['cache'],['cache']
Performance,"// When we hit an instruction that reads memory (load, call, etc), we must; // consider any store that may happen in the loop. For now, we assume the; // worst: there is a store in the loop that alias with this read.; // The case where the load is outside the loop is already covered by the; // dominator check above.; // TODO: relax this condition",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp:49,load,load,49,interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/NewGVN.cpp,2,['load'],['load']
Performance,"// When we know the load's address is loop invariant and the instruction; // in the original scalar loop was unconditionally executed then we; // don't need to mark it as a predicated instruction. Tail folding may; // introduce additional predication, but we're guaranteed to always have; // at least one active lane. We call Legal->blockNeedsPredication here; // because it doesn't query tail-folding. For stores, we need to prove; // both speculation safety (which follows from the same argument as loads),; // but also must prove the value being stored is correct. The easiest; // form of the later is to require that all values stored are the same.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:20,load,load,20,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,2,['load'],"['load', 'loads']"
Performance,"// When we merge a namespace, update its pointer to the first namespace.; // We cannot have loaded any redeclarations of this declaration yet, so; // there's nothing else that needs to be updated.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp:92,load,loaded,92,interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReaderDecl.cpp,1,['load'],['loaded']
Performance,"// When we're performing lookup for the purposes of redeclaration, just; // add the conversion function template. When we deduce template; // arguments for specializations, we'll end up unifying the return; // type of the new declaration with the type of the function template.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp:14,perform,performing,14,interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaLookup.cpp,1,['perform'],['performing']
Performance,// Whenever we perform SPMDzation we will insert; // __kmpc_get_hardware_thread_id_in_block calls.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp:15,perform,perform,15,interpreter/llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp,1,['perform'],['perform']
Performance,"// Whenever we perform SPMDzation with guarding we will insert; // __kmpc_simple_barrier_spmd calls. If SPMDzation failed, there is; // nothing to guard, or there are no parallel regions, we don't need; // the calls.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp:15,perform,perform,15,interpreter/llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp,1,['perform'],['perform']
Performance,"// Whenever we see a load from a typed memory region that's been annotated as; // 'nonnull', we want to trust the user on that and assume that it is is indeed; // non-null.; //; // We do so even if the value is known to have been assigned to null.; // The user should be warned on assigning the null value to a non-null pointer; // as opposed to warning on the later dereference of this pointer.; //; // \code; // int * _Nonnull var = 0; // we want to warn the user here...; // // . . .; // *var = 42; // ...and not here; // \endcode",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/NullabilityChecker.cpp:21,load,load,21,interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/NullabilityChecker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/NullabilityChecker.cpp,1,['load'],['load']
Performance,// Where in memory the load command is.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Object/MachO.h:23,load,load,23,interpreter/llvm-project/llvm/include/llvm/Object/MachO.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Object/MachO.h,1,['load'],['load']
Performance,"// Where in the stack slot is this value defined -- i.e., what size of value; // is this? An important question, because it could be loaded into a register; // from the stack at some point. Happily the memory operand will tell us; // the size written to the stack.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.cpp:133,load,loaded,133,interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LiveDebugValues/InstrRefBasedImpl.cpp,1,['load'],['loaded']
Performance,"// Whether an instruction can be included in an MVE tail-predicated loop,; // though extra validity checks may need to be performed too.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/MCTargetDesc/ARMBaseInfo.h:122,perform,performed,122,interpreter/llvm-project/llvm/lib/Target/ARM/MCTargetDesc/ARMBaseInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/MCTargetDesc/ARMBaseInfo.h,1,['perform'],['performed']
Performance,"// Whether cache is in learning phase",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/inc/TEventIter.h:11,cache,cache,11,proof/proofplayer/inc/TEventIter.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/inc/TEventIter.h,1,['cache'],['cache']
Performance,// Whether the cached value must be recomputed.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/CodeLayout.cpp:15,cache,cached,15,interpreter/llvm-project/llvm/lib/Transforms/Utils/CodeLayout.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/CodeLayout.cpp,1,['cache'],['cached']
Performance,// Whether the combined load width of group is 128 bits,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUIGroupLP.cpp:24,load,load,24,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUIGroupLP.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUIGroupLP.cpp,1,['load'],['load']
Performance,// Whether the consecutive loaded/stored addresses are in reverse order.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlan.h:27,load,loaded,27,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlan.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlan.h,1,['load'],['loaded']
Performance,// Whether the final relocation is a checked one (where a linker should; // perform a range-check on the final address) or not. Note that this field; // is unfortunately sometimes omitted from the assembly syntax. E.g. :lo12:; // on its own is a non-checked relocation. We side with ELF on being; // explicit about this!,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/MCTargetDesc/AArch64MCExpr.h:76,perform,perform,76,interpreter/llvm-project/llvm/lib/Target/AArch64/MCTargetDesc/AArch64MCExpr.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/MCTargetDesc/AArch64MCExpr.h,1,['perform'],['perform']
Performance,// Whether the loaded-from / stored-to addresses are consecutive.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlan.h:15,load,loaded-from,15,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlan.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/VPlan.h,1,['load'],['loaded-from']
Performance,// Whether this loop should be optimized for size based on profile guided size; // optimizatios.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:31,optimiz,optimized,31,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,2,['optimiz'],"['optimizatios', 'optimized']"
Performance,// Whether we actually perform setjmp/longjmp handling,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyLowerEmscriptenEHSjLj.cpp:23,perform,perform,23,interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyLowerEmscriptenEHSjLj.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyLowerEmscriptenEHSjLj.cpp,1,['perform'],['perform']
Performance,"// Which register is Rt and which is Rt2 depends on the offset order.; // However, for pre load/stores the Rt should be the one of the pre; // load/store.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp:91,load,load,91,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoadStoreOptimizer.cpp,2,['load'],['load']
Performance,"// While Available queue is not empty, grab the node with the highest; // priority. If it is not ready put it back. Schedule the node.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/PostRASchedulerList.cpp:19,queue,queue,19,interpreter/llvm-project/llvm/lib/CodeGen/PostRASchedulerList.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/PostRASchedulerList.cpp,3,['queue'],['queue']
Performance,"// While RVV has alignment restrictions, we should always be able to load as a; // legal equivalently-sized byte-typed vector instead. This method is; // responsible for re-expressing a ISD::LOAD via a correctly-aligned type. If; // the load is already correctly-aligned, it returns SDValue().",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:69,load,load,69,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,3,"['LOAD', 'load']","['LOAD', 'load']"
Performance,"// While `x += 1` (for `x` with width less than int) is modeled as; // promotion+arithmetics+demotion, and we can catch lossy demotion with; // ease; inc/dec with width less than int can't overflow because of; // promotion rules, so we omit promotion+demotion, which means that we can; // not catch lossy ""demotion"". Because we still want to catch these cases; // when the sanitizer is enabled, we perform the promotion, then perform; // the increment/decrement in the wider type, and finally; // perform the demotion. This will catch lossy demotions.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExprScalar.cpp:398,perform,perform,398,interpreter/llvm-project/clang/lib/CodeGen/CGExprScalar.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExprScalar.cpp,3,['perform'],['perform']
Performance,"// While examining uses, we ensure that the alloca has a covering load or; // store. We don't want to widen the integer operations only to fail to; // promote due to some other unsplittable entry (which we may make splittable; // later). However, if there are only splittable uses, go ahead and assume; // that we cover the alloca.; // FIXME: We shouldn't consider split slices that happen to start in the; // partition here...",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp:66,load,load,66,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SROA.cpp,1,['load'],['load']
Performance,"// While globals are generally bad, this one allows us to perform assertions; // liberally and somehow still trace them back to the def they indirectly; // came from.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/utils/TableGen/NeonEmitter.cpp:58,perform,perform,58,interpreter/llvm-project/clang/utils/TableGen/NeonEmitter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/utils/TableGen/NeonEmitter.cpp,1,['perform'],['perform']
Performance,"// While some warnings are attached to AST nodes (mostly path-sensitive; // checks), others are simply associated with a plain source location; // or range. Figuring out the node based on locations can be tricky,; // so instead, we traverse the whole body of the declaration and gather; // information on ALL suppressions. After that we can simply check if; // any of those suppressions affect the warning in question.; //; // Traversing AST of a function is not a heavy operation, but for; // large functions with a lot of bugs it can make a dent in performance.; // In order to avoid this scenario, we cache traversal results.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/BugSuppression.cpp:551,perform,performance,551,interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/BugSuppression.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/BugSuppression.cpp,2,"['cache', 'perform']","['cache', 'performance']"
Performance,"// While we can directly load/store ZMM, YMM, and 64-bit halves of XMM,; // for smaller widths (32/16/8) we have to insert/extract them separately.; // Again, it's free for the 0'th subreg (if op is 32/64 bit wide,; // but let's pretend that it is also true for 16/8 bit wide ops...)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:25,load,load,25,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,1,['load'],['load']
Performance,"// While we could change the other users of OrigOp to use freeze(OrigOp), that; // potentially reduces their optimization potential, so let's only do this iff; // the OrigOp is only used by the freeze.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp:109,optimiz,optimization,109,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp,1,['optimiz'],['optimization']
Performance,// WhileBB should contain the pattern of load & compare instructions. Match; // the pattern and find the GEP instructions used by the loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoopIdiomTransform.cpp:41,load,load,41,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoopIdiomTransform.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64LoopIdiomTransform.cpp,2,['load'],"['load', 'loads']"
Performance,"// Widen from vec3 to vec4 when the load is at least 8-byte aligned; // or 16-byte fully dereferenceable. Otherwise, split the vector load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelLowering.cpp:36,load,load,36,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelLowering.cpp,2,['load'],['load']
Performance,// Widen non-power-of-2 loads to the alignment if needed,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp:24,load,loads,24,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,1,['load'],['loads']
Performance,"// Widen subvectors to the full width rather than promoting integer; // elements. This is better because:; //; // (a) it means that we can handle the ABI for passing and returning; // sub-128 vectors without having to handle them as legal types.; //; // (b) we don't have instructions to extend on load and truncate on store,; // so promoting the integers is less efficient.; //; // (c) there are no multiplication instructions for the widest integer; // type (v2i64).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.h:298,load,load,298,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.h,1,['load'],['load']
Performance,// Widen suitably aligned loads by loading extra bytes. The standard; // legalization actions can't properly express widening memory operands.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp:26,load,loads,26,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,2,['load'],"['loading', 'loads']"
Performance,// Widen the LHS and RHS so we can perform a full division.; // Also make sure that there will be enough space for the shift below to not; // overflow,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/APFixedPoint.cpp:35,perform,perform,35,interpreter/llvm-project/llvm/lib/Support/APFixedPoint.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/APFixedPoint.cpp,1,['perform'],['perform']
Performance,// Widen the LHS and RHS so we can perform a full multiplication.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/APFixedPoint.cpp:35,perform,perform,35,interpreter/llvm-project/llvm/lib/Support/APFixedPoint.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/APFixedPoint.cpp,1,['perform'],['perform']
Performance,// Widen vec3 load to vec4.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:14,load,load,14,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,1,['load'],['load']
Performance,"// Widenable conditions will eventually lower into constants, so some; // operations with them will be trivially optimized away.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfoImpl.h:113,optimiz,optimized,113,interpreter/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfoImpl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfoImpl.h,1,['optimiz'],['optimized']
Performance,// Widening a scalable vector to another scalable vector is done by inserting; // the vector into a larger undef one.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp:14,scalab,scalable,14,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,2,['scalab'],['scalable']
Performance,"// Wiggle room and alignment (512 is same as in OptimizeBaskets)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TBasket.cxx:48,Optimiz,OptimizeBaskets,48,tree/tree/src/TBasket.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TBasket.cxx,1,['Optimiz'],['OptimizeBaskets']
Performance,// Will be converted to GPR load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp:28,load,load,28,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp,1,['load'],['load']
Performance,// Will process aliases as a post-pass because the reader wants all; // global to be loaded first.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Writer/BitcodeWriter.cpp:85,load,loaded,85,interpreter/llvm-project/llvm/lib/Bitcode/Writer/BitcodeWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Bitcode/Writer/BitcodeWriter.cpp,1,['load'],['loaded']
Performance,// Wire up the DeclContexts for Decls that we delayed setting until; // recursive loading is completed.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp:82,load,loading,82,interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTReader.cpp,1,['load'],['loading']
Performance,"// With -save-temps, we want to save the unoptimized bitcode output from the; // CompileJobAction, use -disable-llvm-passes to get pristine IR generated; // by the frontend.; // When -fembed-bitcode is enabled, optimized bitcode is emitted because it; // has slightly different breakdown between stages.; // FIXME: -fembed-bitcode -save-temps will save optimized bitcode instead of; // pristine IR generated by the frontend. Ideally, a new compile action should; // be added so both IR can be captured.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp:211,optimiz,optimized,211,interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Clang.cpp,2,['optimiz'],['optimized']
Performance,"// With 28 different fonts and 16 colors, we could in principle have; // as many as 448 different GCs. But in practice, a single page of; // HTML will typically have much less than this. So we won't try to; // keep all GCs on hand. Instead, we'll keep around the most recently; // used GCs and allocate new ones as necessary.; //; // The following structure is used to build a cache of GCs in the; // main widget object.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/guihtml/inc/TGHtml.h:377,cache,cache,377,gui/guihtml/inc/TGHtml.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/guihtml/inc/TGHtml.h,1,['cache'],['cache']
Performance,"// With AVX1, use vperm2f128 (below) to allow load folding. Otherwise,; // this will likely become vinsertf128 which can't fold a 256-bit memop.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:46,load,load,46,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,"// With C as a power of 2 and C != 0 and C != INT_MIN:; // icmp eq Abs(X) C ->; // (icmp eq A, C) | (icmp eq A, -C); // icmp ne Abs(X) C ->; // (icmp ne A, C) & (icmp ne A, -C); // Both of these patterns can be better optimized in; // DAGCombiner::foldAndOrOfSETCC. Note this only applies for scalar; // integers which is checked above.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:218,optimiz,optimized,218,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['optimiz'],['optimized']
Performance,"// With MOVDDUP (v2f64) we can broadcast from a register or a load, otherwise; // we can only broadcast from a register with AVX2.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:62,load,load,62,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,"// With a fatal failure in the module loader, we abort parsing.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/Lexer.cpp:38,load,loader,38,interpreter/llvm-project/clang/lib/Lex/Lexer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/Lexer.cpp,3,['load'],['loader']
Performance,"// With a variable index, we can't perform the operation in a smaller type, so; // we're forced to expand this.; //; // TODO: We could emit a chain of compare/select to figure out which piece to; // index.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalizerHelper.cpp:35,perform,perform,35,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalizerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/LegalizerHelper.cpp,1,['perform'],['perform']
Performance,"// With an index of 0 this is a cast-like subvector, which can be performed; // with subregister operations.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:66,perform,performed,66,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['perform'],['performed']
Performance,"// With binary profile correlation, profile data is not loaded into memory.; // profile data must reference profile counter with an absolute relocation.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/InstrProfiling.cpp:56,load,loaded,56,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/InstrProfiling.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/InstrProfiling.cpp,1,['load'],['loaded']
Performance,"// With compilation database, we may open different files; // concurrently or we may write the same file concurrently. So we; // use a map here to allow multiple compile commands to write to the; // same file. Also we need a lock here to avoid data race.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-scan-deps/ClangScanDeps.cpp:62,concurren,concurrently,62,interpreter/llvm-project/clang/tools/clang-scan-deps/ClangScanDeps.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-scan-deps/ClangScanDeps.cpp,2,['concurren'],['concurrently']
Performance,"// With expensive checks, check that the type we compute matches the; // cached type.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenTypes.cpp:73,cache,cached,73,interpreter/llvm-project/clang/lib/CodeGen/CodeGenTypes.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenTypes.cpp,1,['cache'],['cached']
Performance,"// With opaque pointers we may have loads from the same pointer with; // different result types, which should be disambiguated.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVNHoist.cpp:36,load,loads,36,interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVNHoist.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVNHoist.cpp,1,['load'],['loads']
Performance,"// With optimization enabled, take advantage of the fact that; // the blocks runtime guarantees a memcpy of the block data, and; // just emit a retain of the src field.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBlocks.cpp:8,optimiz,optimization,8,interpreter/llvm-project/clang/lib/CodeGen/CGBlocks.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBlocks.cpp,1,['optimiz'],['optimization']
Performance,"// With optimization, dead code should already be eliminated. However; // there is one known exception: lowered code for arguments that are only; // used by tail calls, where the tail calls reuse the incoming stack; // arguments directly (see t11 in test/CodeGen/X86/sibcall.ll).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/CodeGenPassBuilder.h:8,optimiz,optimization,8,interpreter/llvm-project/llvm/include/llvm/CodeGen/CodeGenPassBuilder.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/CodeGenPassBuilder.h,3,['optimiz'],['optimization']
Performance,"// With the exception of data-predicate transitions, no instructions are; // required to cast between legal scalable vector types. However:; // 1. Packed and unpacked types have different bit lengths, meaning BITCAST; // is not universally useable.; // 2. Most unpacked integer types are not legal and thus integer extends; // cannot be used to convert between unpacked and packed types.; // These can make ""bitcasting"" a multiphase process. REINTERPRET_CAST is used; // to transition between unpacked and packed types of the same element type,; // with BITCAST used otherwise.; // This function does not handle predicate bitcasts.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.h:108,scalab,scalable,108,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.h,1,['scalab'],['scalable']
Performance,"// With the incompatible ABI, this will need to be replaced with a direct; // reference to the class symbol. For the compatible nonfragile ABI we are; // still performing this lookup at run time but emitting the symbol for the; // class externally so that we can make the switch later.; //; // Libobjc2 contains an LLVM pass that replaces calls to objc_lookup_class; // with memoized versions or with static references if it's safe to do so.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjCGNU.cpp:160,perform,performing,160,interpreter/llvm-project/clang/lib/CodeGen/CGObjCGNU.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjCGNU.cpp,1,['perform'],['performing']
Performance,// With vector support a Load->Store combination may be combined to either; // an MVC or vector operations and it seems to work best to allow the; // vector addressing mode.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp:25,Load,Load,25,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.cpp,1,['Load'],['Load']
Performance,"// Without AVX512DQ, we need to use a scalar type for v2i1/v4i1/v8i1 loads.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:69,load,loads,69,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['loads']
Performance,"// Without memoperands, loadRegFromAddr and storeRegToStackSlot will; // conservatively assume the address is unaligned. That's bad for; // performance.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp:24,load,loadRegFromAddr,24,interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstrInfo.cpp,2,"['load', 'perform']","['loadRegFromAddr', 'performance']"
Performance,"// Without pointer analysis, we conservatively assume values loaded from; // generic or local address space are divergent.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXTargetTransformInfo.cpp:61,load,loaded,61,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXTargetTransformInfo.cpp,1,['load'],['loaded']
Performance,"// Without this setb optimization, the outer SELECT_CC will be manually; // selected to SELECT_CC_I4/SELECT_CC_I8 Pseudo, then expand-isel-pseudos pass; // transforms pseudo instruction to isel instruction. When there are more than; // one use for result like zext/sext, with current optimization we only see; // isel is replaced by setb but can't see any significant gain. Since; // setb has longer latency than original isel, we should avoid this. Another; // point is that setb requires comparison always kept, it can break the; // opportunity to get the comparison away if we have in future.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp:21,optimiz,optimization,21,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,3,"['latency', 'optimiz']","['latency', 'optimization']"
Performance,// Work around an extremely aggressive peephole optimization in; // EmitScalarConversion which assumes that all other uses of a; // value are extant.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenFunction.h:48,optimiz,optimization,48,interpreter/llvm-project/clang/lib/CodeGen/CodeGenFunction.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenFunction.h,1,['optimiz'],['optimization']
Performance,// Work queue of CFG edges.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/BitTracker.h:8,queue,queue,8,interpreter/llvm-project/llvm/lib/Target/Hexagon/BitTracker.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/BitTracker.h,1,['queue'],['queue']
Performance,// Work queue of register uses.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/BitTracker.h:8,queue,queue,8,interpreter/llvm-project/llvm/lib/Target/Hexagon/BitTracker.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/BitTracker.h,1,['queue'],['queue']
Performance,// Workaround for LegalizeDAG asserting on expansion of i1 vector loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/R600ISelLowering.cpp:66,load,loads,66,interpreter/llvm-project/llvm/lib/Target/AMDGPU/R600ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/R600ISelLowering.cpp,1,['load'],['loads']
Performance,"// Workaround for multi-threaded environment; // Ensure main thread id picked when canvas implementation is created -; // otherwise it may be assigned in other thread and screw-up gPad access.; // Workaround may not work if main thread id was wrongly initialized before; // This resolves issue https://github.com/root-project/root/issues/15498",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/webgui6/src/TWebCanvas.cxx:18,multi-thread,multi-threaded,18,gui/webgui6/src/TWebCanvas.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/webgui6/src/TWebCanvas.cxx,1,['multi-thread'],['multi-threaded']
Performance,// Worklist maintains our depth-first queue of loops in this nest to process.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopSimplify.cpp:38,queue,queue,38,interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopSimplify.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopSimplify.cpp,1,['queue'],['queue']
Performance,// Would be true if the Optimization level isn't O0.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Coroutines/CoroSplit.h:24,Optimiz,Optimization,24,interpreter/llvm-project/llvm/include/llvm/Transforms/Coroutines/CoroSplit.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Coroutines/CoroSplit.h,1,['Optimiz'],['Optimization']
Performance,// Would deadlock waiting for itself.; // Wait for all threads to complete and the queue to be empty,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/ThreadPool.cpp:83,queue,queue,83,interpreter/llvm-project/llvm/lib/Support/ThreadPool.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/ThreadPool.cpp,1,['queue'],['queue']
Performance,// Wrapper for all String/Memory Library Call Optimizations,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Utils/SimplifyLibCalls.h:46,Optimiz,Optimizations,46,interpreter/llvm-project/llvm/include/llvm/Transforms/Utils/SimplifyLibCalls.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Utils/SimplifyLibCalls.h,1,['Optimiz'],['Optimizations']
Performance,// Wrapper for all floating point library call optimizations,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Utils/SimplifyLibCalls.h:47,optimiz,optimizations,47,interpreter/llvm-project/llvm/include/llvm/Transforms/Utils/SimplifyLibCalls.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Utils/SimplifyLibCalls.h,1,['optimiz'],['optimizations']
Performance,// Wraps a TargetGlobalAddress that should be loaded using PC-relative; // accesses (LARL). Operand 0 is the address.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.h:46,load,loaded,46,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.h,1,['load'],['loaded']
Performance,// Write MachO header and debug section load commands.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/Debugging/DebuggerSupportPlugin.cpp:40,load,load,40,interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/Debugging/DebuggerSupportPlugin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/Debugging/DebuggerSupportPlugin.cpp,1,['load'],['load']
Performance,"// Write a new timestamp file so that nobody else attempts to prune.; // There is a benign race condition here, if two Clang instances happen to; // notice at the same time that the timestamp is out-of-date.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp:91,race condition,race condition,91,interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,1,['race condition'],['race condition']
Performance,"// Write a new timestamp file so that nobody else attempts to prune.; // There is a benign race condition here, if two processes happen to; // notice at the same time that the timestamp is out-of-date.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/CachePruning.cpp:91,race condition,race condition,91,interpreter/llvm-project/llvm/lib/Support/CachePruning.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/CachePruning.cpp,1,['race condition'],['race condition']
Performance,// Write latency. Number of cycles before write-back stage.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/Instruction.h:9,latency,latency,9,interpreter/llvm-project/llvm/include/llvm/MCA/Instruction.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/MCA/Instruction.h,1,['latency'],['latency']
Performance,// Write out identifiers if either the ID is local or the identifier has; // changed since it was loaded.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp:98,load,loaded,98,interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp,1,['load'],['loaded']
Performance,// Write out the specific module cache path that contains the module files.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp:33,cache,cache,33,interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp,1,['cache'],['cache']
Performance,// Write the __DWARF segment load command to the output file.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/dsymutil/MachOUtils.cpp:29,load,load,29,interpreter/llvm-project/llvm/tools/dsymutil/MachOUtils.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/dsymutil/MachOUtils.cpp,1,['load'],['load']
Performance,"// Write the data-in-code load command, if used.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp:26,load,load,26,interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp,1,['load'],['load']
Performance,// Write the linker options load commands.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp:28,load,load,28,interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp,1,['load'],['load']
Performance,// Write the load command for the __DWARF segment.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/dsymutil/MachOUtils.cpp:13,load,load,13,interpreter/llvm-project/llvm/tools/dsymutil/MachOUtils.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/dsymutil/MachOUtils.cpp,1,['load'],['load']
Performance,// Write the load commands for the segments and sections we 'import' from; // the original binary.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/dsymutil/MachOUtils.cpp:13,load,load,13,interpreter/llvm-project/llvm/tools/dsymutil/MachOUtils.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/dsymutil/MachOUtils.cpp,1,['load'],['load']
Performance,// Write the load commands.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/dsymutil/MachOUtils.cpp:13,load,load,13,interpreter/llvm-project/llvm/tools/dsymutil/MachOUtils.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/dsymutil/MachOUtils.cpp,1,['load'],['load']
Performance,"// Write the loh load command, if used.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp:17,load,load,17,interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp,1,['load'],['load']
Performance,"// Write the prolog, starting with the header and load command...",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp:50,load,load,50,interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp,1,['load'],['load']
Performance,// Write the source-location offsets table into the AST block. This; // table is used for lazily loading source-location information.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp:97,load,loading,97,interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Serialization/ASTWriter.cpp,1,['load'],['loading']
Performance,"// Write the symbol table load command, if used.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp:26,load,load,26,interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MachObjectWriter.cpp,1,['load'],['load']
Performance,// Write to a temporary to avoid race condition,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/Caching.cpp:33,race condition,race condition,33,interpreter/llvm-project/llvm/lib/Support/Caching.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/Caching.cpp,1,['race condition'],['race condition']
Performance,"// Writing.; // Calculate cache properties first.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TBaseClass.cxx:26,cache,cache,26,core/meta/src/TBaseClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TBaseClass.cxx,1,['cache'],['cache']
Performance,"// X and Y are splatted values, so perform the binary operation on those; // values followed by a splat followed by the 2nd binary operation:; // bo (splat X), (bo Y, OtherOp) --> bo (splat (bo X, Y)), OtherOp",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp:35,perform,perform,35,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstructionCombining.cpp,1,['perform'],['perform']
Performance,"// X11 is optional use in function linkage, should be the least used one; // Use it as scratch reg to load immediate.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/PowerPC/Target.cpp:102,load,load,102,interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/PowerPC/Target.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/PowerPC/Target.cpp,1,['load'],['load']
Performance,"// X86 has 8, 16, and 32-bit zero-extending loads.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:44,load,loads,44,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['loads']
Performance,"// X86 target has bfloat16 emulation support in the backend, where; // bfloat16 is treated as a 32-bit float, arithmetic operations are; // performed in 32-bit, and the result is converted back to bfloat16.; // Truncation and extension between bfloat16 and 32-bit float are supported; // by the compiler-rt library. However, native bfloat16 support is currently; // not available in the X86 target. Hence, HasFullBFloat16 will be false; // until native bfloat16 support is available. HasFullBFloat16 is used to; // determine whether to automatically use excess floating point precision; // for bfloat16 arithmetic operations in the front-end.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/X86.cpp:140,perform,performed,140,interpreter/llvm-project/clang/lib/Basic/Targets/X86.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/X86.cpp,1,['perform'],['performed']
Performance,// XCore target does not yet support tail call optimization.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp:47,optimiz,optimization,47,interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/XCore/XCoreISelLowering.cpp,1,['optimiz'],['optimization']
Performance,// XOP can efficiently perform BITREVERSE with VPPERM.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,perform,perform,23,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['perform'],['perform']
Performance,// XROS always uses the build version load command.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MCStreamer.cpp:38,load,load,38,interpreter/llvm-project/llvm/lib/MC/MCStreamer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MCStreamer.cpp,1,['load'],['load']
Performance,"// XXX - be careful of dataless loads; // getNamedOperandIdx returns the index for MachineInstrs. Since they; // include the output in the operand list, but SDNodes don't, we need to; // subtract the index by one.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp:32,load,loads,32,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp,1,['load'],['loads']
Performance,"// XXX: We have an opportunity here to optimize the ""branch into if"" case; // here. Branch into if looks like this:; // entry; // / |; // diamond_head branch_from; // / \ |; // diamond_false diamond_true; // \ /; // done; //; // The diamond_head block begins the ""if"" and the diamond_true block; // is the block being ""branched into"".; //; // If MigrateTrue is true, then TrueBB is the block being ""branched into""; // and if MigrateFalse is true, then FalseBB is the block being; // ""branched into""; //; // Here is the pseudo code for how I think the optimization should work:; // 1. Insert MOV GPR0, 0 before the branch instruction in diamond_head.; // 2. Insert MOV GPR0, 1 before the branch instruction in branch_from.; // 3. Move the branch instruction from diamond_head into its own basic; // block (new_block).; // 4. Add an unconditional branch from diamond_head to new_block; // 5. Replace the branch instruction in branch_from with an unconditional; // branch to new_block. If branch_from has multiple predecessors, then; // we need to replace the True/False block in the branch; // instruction instead of replacing it.; // 6. Change the condition of the branch instruction in new_block from; // COND to (COND || GPR0); //; // In order insert these MOV instruction, we will need to use the; // RegisterScavenger. Usually liveness stops being tracked during; // the late machine optimization passes, however if we implement; // bool TargetRegisterInfo::requiresRegisterScavenging(; // const MachineFunction &MF); // and have it return true, liveness will be tracked correctly; // by generic optimization passes. We will also need to make sure that; // all of our target-specific passes that run after regalloc and before; // the CFGStructurizer track liveness and we will need to modify this pass; // to correctly track liveness.; //; // After the above changes, the new CFG should look like this:; // entry; // / |; // diamond_head branch_from; // \ /; // new_block; // / |; // diamond_false ",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/R600MachineCFGStructurizer.cpp:39,optimiz,optimize,39,interpreter/llvm-project/llvm/lib/Target/AMDGPU/R600MachineCFGStructurizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/R600MachineCFGStructurizer.cpp,2,['optimiz'],"['optimization', 'optimize']"
Performance,"// Xor/and/or are indifferent to the swizzle operation (shuffle of one value).; // Simplify xor/and/or (shuff(A), shuff(B)) -> shuff(op (A,B)); // If both shuffles use the same mask, and both shuffle within a single; // vector, then it is worthwhile to move the swizzle after the operation.; // The type-legalizer generates this pattern when loading illegal; // vector types from memory. In many cases this allows additional shuffle; // optimizations.; // There are other cases where moving the shuffle after the xor/and/or; // is profitable even if shuffles don't perform a swizzle.; // If both shuffles use the same mask, and both shuffles have the same first; // or second operand, then it might still be profitable to move the shuffle; // after the xor/and/or operation.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:342,load,loading,342,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,3,"['load', 'optimiz', 'perform']","['loading', 'optimizations', 'perform']"
Performance,"// Yeah, we have a task, grab it and release the lock on the queue; // We first need to signal that we are active before popping the queue; // in order for wait() to properly detect that even if the queue is; // empty, there is still a task in flight.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/ThreadPool.cpp:61,queue,queue,61,interpreter/llvm-project/llvm/lib/Support/ThreadPool.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/ThreadPool.cpp,3,['queue'],['queue']
Performance,"// Yep, no additional predication needed. Perform the transform.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:42,Perform,Perform,42,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['Perform'],['Perform']
Performance,// You shouldn't load to the same register twice in an instruction...,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/Disassembler/AArch64Disassembler.cpp:17,load,load,17,interpreter/llvm-project/llvm/lib/Target/AArch64/Disassembler/AArch64Disassembler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/Disassembler/AArch64Disassembler.cpp,2,['load'],['load']
Performance,"// You would expect straight-line code between call-frame setup and; // call-frame destroy. You would be wrong. There are circumstances (e.g.; // CMOV_GR8 expansion of a select that feeds a function call!) where we can; // end up with the setup and the destroy in different basic blocks.; // This is bad, and breaks SP adjustment.; // So, check that all of the frames in the function are closed inside; // the same block, and, for good measure, that there are no nested frames.; //; // If any call allocates more argument stack memory than the stack; // probe size, don't do this optimization. Otherwise, this pass; // would need to synthesize additional stack probe calls to allocate; // memory for arguments.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86CallFrameOptimization.cpp:580,optimiz,optimization,580,interpreter/llvm-project/llvm/lib/Target/X86/X86CallFrameOptimization.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86CallFrameOptimization.cpp,1,['optimiz'],['optimization']
Performance,"// Z / pow(X, Y) --> Z * pow(X, -Y); // Z / exp{2}(Y) --> Z * exp{2}(-Y); // In the general case, this creates an extra instruction, but fmul allows; // for better canonicalization and optimization than fdiv.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineMulDivRem.cpp:185,optimiz,optimization,185,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineMulDivRem.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineMulDivRem.cpp,1,['optimiz'],['optimization']
Performance,// ZEXTLOAD will match without needing to change the size of the value being; // loaded.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:81,load,loaded,81,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['loaded']
Performance,// Zap masked loads with a zero mask.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:14,load,loads,14,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['loads']
Performance,// Zap the fully redundant load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/ObjCARC/ObjCARCOpts.cpp:27,load,load,27,interpreter/llvm-project/llvm/lib/Transforms/ObjCARC/ObjCARCOpts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/ObjCARC/ObjCARCOpts.cpp,2,['load'],['load']
Performance,// Zero Mask - masked load instruction creates a zero vector.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstCombineIntrinsic.cpp:22,load,load,22,interpreter/llvm-project/llvm/lib/Target/X86/X86InstCombineIntrinsic.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InstCombineIntrinsic.cpp,1,['load'],['load']
Performance,"// Zero _norm pointer in RooAbsPdf if it is points to our cache payload",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsPdf.cxx:58,cache,cache,58,roofit/roofitcore/src/RooAbsPdf.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsPdf.cxx,1,['cache'],['cache']
Performance,"// Zero latency instructions have the same value for CycleDispatched,; // CycleIssued and CycleExecuted.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-mca/Views/TimelineView.cpp:8,latency,latency,8,interpreter/llvm-project/llvm/tools/llvm-mca/Views/TimelineView.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-mca/Views/TimelineView.cpp,1,['latency'],['latency']
Performance,"// Zero-extending load itself cannot be optimized. So, it is not; // interesting by itself though it gives useful information.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp:18,load,load,18,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,2,"['load', 'optimiz']","['load', 'optimized']"
Performance,// Zero-latency weak edges may be added purely for heuristic ordering. Don't; // add them if another kind of edge already exists.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ScheduleDAG.cpp:8,latency,latency,8,interpreter/llvm-project/llvm/lib/CodeGen/ScheduleDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ScheduleDAG.cpp,1,['latency'],['latency']
Performance,// Zero-size loads and stores do not access memory.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/StackSafetyAnalysis.cpp:13,load,loads,13,interpreter/llvm-project/llvm/lib/Analysis/StackSafetyAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/StackSafetyAnalysis.cpp,1,['load'],['loads']
Performance,// Zexts are free if they can be combined with a load.; // Don't advertise i32->i64 zextload as being free for LA64. It interacts; // poorly with type legalization of compares preferring sext.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/LoongArch/LoongArchISelLowering.cpp:49,load,load,49,interpreter/llvm-project/llvm/lib/Target/LoongArch/LoongArchISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/LoongArch/LoongArchISelLowering.cpp,1,['load'],['load']
Performance,// Zexts are free if they can be combined with a load.; // Don't advertise i32->i64 zextload as being free for RV64. It interacts; // poorly with type legalization of compares preferring sext.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:49,load,load,49,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['load'],['load']
Performance,// [ queues : ],MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseOpenACC.cpp:5,queue,queues,5,interpreter/llvm-project/clang/lib/Parse/ParseOpenACC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseOpenACC.cpp,1,['queue'],['queues']
Performance,"// [-256, -2] is Thumb1 movs+bics, legal immediate for ARM/Thumb2.; // FIXME: Prefer a contiguous sequence of bits for other optimizations.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:125,optimiz,optimizations,125,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['optimiz'],['optimizations']
Performance,"// [1, 255] is Thumb1 movs+ands, legal immediate for ARM/Thumb2.; // FIXME: Prefer a contiguous sequence of bits for other optimizations.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:123,optimiz,optimizations,123,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['optimiz'],['optimizations']
Performance,"// [class.copy.elision]p3:; // In some copy-initialization contexts, a two-stage overload resolution; // is performed.; // If the first overload resolution selects a deleted function, we also; // need the initialization sequence to decide whether to perform the second; // overload resolution.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp:108,perform,performed,108,interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,2,['perform'],"['perform', 'performed']"
Performance,"// [class.copy.elision]p3:; // In some copy-initialization contexts, a two-stage overload resolution; // is performed.; // If the first overload resolution selects a deleted function, we also; // need the initialization sequence to decide whether to perform the second; // overload resolution.; // For deleted functions in other contexts, there is no need to get the; // initialization sequence.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp:108,perform,performed,108,interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,2,['perform'],"['perform', 'performed']"
Performance,"// [dcl.fct.def.coroutine]5.7; // promise-constructor-arguments is determined as follows: overload; // resolution is performed on a promise constructor call created by; // assembling an argument list q_1 ... q_n . If a viable constructor is; // found ([over.match.viable]), then promise-constructor-arguments is ( q_1; // , ..., q_n ), otherwise promise-constructor-arguments is empty.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaCoroutine.cpp:117,perform,performed,117,interpreter/llvm-project/clang/lib/Sema/SemaCoroutine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaCoroutine.cpp,1,['perform'],['performed']
Performance,"// [dcl.fct.def.coroutine]p12; // The deallocation function's name is looked up by searching for it in the; // scope of the promise type. If nothing is found, a search is performed in; // the global scope.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaCoroutine.cpp:171,perform,performed,171,interpreter/llvm-project/clang/lib/Sema/SemaCoroutine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaCoroutine.cpp,1,['perform'],['performed']
Performance,"// [dcl.fct.def.coroutine]p9; // If no viable function is found ([over.match.viable]), overload; // resolution; // is performed again on a function call created by passing just the amount; // of space required as an argument of type std::size_t.; //; // Proposed Change of [dcl.fct.def.coroutine]p9 in P2014R0:; // Otherwise, overload resolution is performed again on a function call; // created; // by passing the amount of space requested as an argument of type; // std::size_t as the first argument, and the requested alignment as; // an argument of type std:align_val_t as the second argument.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaCoroutine.cpp:118,perform,performed,118,interpreter/llvm-project/clang/lib/Sema/SemaCoroutine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaCoroutine.cpp,2,['perform'],['performed']
Performance,"// [dcl.fct.def.coroutine]p9; // The allocation function's name is looked up by searching for it in the; // scope of the promise type.; // - If any declarations are found, ...; // - If no declarations are found in the scope of the promise type, a search; // is performed in the global scope.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaCoroutine.cpp:261,perform,performed,261,interpreter/llvm-project/clang/lib/Sema/SemaCoroutine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaCoroutine.cpp,1,['perform'],['performed']
Performance,"// [temp.constr.atomic]p3: To determine if an atomic constraint is; // satisfied, the parameter mapping and template arguments are first; // substituted into its expression. If substitution results in an; // invalid type or expression, the constraint is not satisfied.; // Otherwise, the lvalue-to-rvalue conversion is performed if necessary,; // and E shall be a constant expression of type bool.; //; // Perform the L to R Value conversion if necessary. We do so for all; // non-PRValue categories, else we fail to extend the lifetime of; // temporaries, and that fails the constant expression check.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaConcept.cpp:319,perform,performed,319,interpreter/llvm-project/clang/lib/Sema/SemaConcept.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaConcept.cpp,2,"['Perform', 'perform']","['Perform', 'performed']"
Performance,"// \p Index is 0, 1, and 2 for x, y, and z dimension, respectively.; /// Emit code based on Code Object ABI version.; /// COV_4 : Emit code to use dispatch ptr; /// COV_5 : Emit code to use implicitarg ptr; /// COV_NONE : Emit code to load a global variable ""__oclc_ABI_version""; /// and use its value for COV_4 or COV_5 approach. It is used for; /// compiling device libraries in an ABI-agnostic way.; ///; /// Note: ""__oclc_ABI_version"" is supposed to be emitted and intialized by; /// clang during compilation of user code.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp:235,load,load,235,interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBuiltin.cpp,1,['load'],['load']
Performance,// \returns true if it's beneficial on this subtarget for the scheduler to; // cluster stores as well as loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSubtarget.h:105,load,loads,105,interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSubtarget.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSubtarget.h,1,['load'],['loads']
Performance,// \returns true if the subtarget supports DWORDX3 load/store instructions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSubtarget.h:51,load,load,51,interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSubtarget.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNSubtarget.h,1,['load'],['load']
Performance,// _REV instruction should not appear before encoding optimization,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/X86CompressEVEXTablesEmitter.cpp:54,optimiz,optimization,54,interpreter/llvm-project/llvm/utils/TableGen/X86CompressEVEXTablesEmitter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/X86CompressEVEXTablesEmitter.cpp,1,['optimiz'],['optimization']
Performance,// __bf16 is always available as a load/store only type on AMDGCN.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/AMDGPU.cpp:35,load,load,35,interpreter/llvm-project/clang/lib/Basic/Targets/AMDGPU.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/AMDGPU.cpp,1,['load'],['load']
Performance,// __bf16 is always available as a load/store only type.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/NVPTX.cpp:35,load,load,35,interpreter/llvm-project/clang/lib/Basic/Targets/NVPTX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/NVPTX.cpp,1,['load'],['load']
Performance,"// __declspec(dllimport) must be handled very carefully:; // We must never initialize an expression with the thunk in C++.; // Doing otherwise would allow the same id-expression to yield; // different addresses for the same function in different translation; // units. However, this means that we must dynamically initialize the; // expression with the contents of the import address table at runtime.; //; // The C language has no notion of ODR; furthermore, it has no notion of; // dynamic initialization. This means that we are permitted to; // perform initialization with the address of the thunk.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ExprConstant.cpp:548,perform,perform,548,interpreter/llvm-project/clang/lib/AST/ExprConstant.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ExprConstant.cpp,1,['perform'],['perform']
Performance,"// __kmpc_fork_call expects extra arguments as pointers. If the input; // already has a pointer type, everything is fine. Otherwise, store the; // value onto stack and load it back inside the to-be-outlined region. This; // will ensure only the pointer will be passed to the function.; // FIXME: if there are more than 15 trailing arguments, they must be; // additionally packed in a struct.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Frontend/OpenMP/OMPIRBuilder.cpp:168,load,load,168,interpreter/llvm-project/llvm/lib/Frontend/OpenMP/OMPIRBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Frontend/OpenMP/OMPIRBuilder.cpp,1,['load'],['load']
Performance,"// __linux__; // Instruction can have some variable operands, and we may want to see how; // different operands affect performance. So for each operand position,; // precompute all the possible choices we might care about,; // and greedily generate all the possible combinations of choices.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/X86/Target.cpp:119,perform,performance,119,interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/X86/Target.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/X86/Target.cpp,1,['perform'],['performance']
Performance,"// __sanitizer_unaligned_{load,store} functions may be called by users; // and always expects shadows in the TLS. So don't check them.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp:26,load,load,26,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp,1,['load'],['load']
Performance,"// _yatX = 0 ;; // _calcX = 0 ;; // Must do this here too: fillCache() may not be called if cache contents is retrieved from EOcache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/src/RooIntegralMorph.cxx:92,cache,cache,92,roofit/roofit/src/RooIntegralMorph.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/src/RooIntegralMorph.cxx,1,['cache'],['cache']
Performance,"// `ERROR` and `PI` are from loading R related modules, which conflict with; // user's code.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:29,load,loading,29,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,1,['load'],['loading']
Performance,"// `MI` is a br_table instruction with a dummy default target argument. This; // function finds and adds the default target argument and removes any redundant; // range check preceding the br_table. Returns the MBB that the br_table is; // moved into so it can be removed from further consideration, or nullptr if the; // br_table cannot be optimized.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyFixBrTableDefaults.cpp:341,optimiz,optimized,341,interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyFixBrTableDefaults.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyFixBrTableDefaults.cpp,1,['optimiz'],['optimized']
Performance,"// `Offset` can be in bytes or in ""scalable bytes"".",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64InstrInfo.cpp:35,scalab,scalable,35,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64InstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64InstrInfo.cpp,1,['scalab'],['scalable']
Performance,"// `WatchedLiteralsSolver` is an implementation of Algorithm D from Knuth's; // The Art of Computer Programming Volume 4: Satisfiability, Fascicle 6. It is; // based on the backtracking DPLL algorithm [1], keeps references to a single; // ""watched"" literal per clause, and uses a set of ""active"" variables to perform; // unit propagation.; //; // The solver expects that its input is a boolean formula in conjunctive normal; // form that consists of clauses of at least one literal. A literal is either a; // boolean variable or its negation. Below we define types, data structures, and; // utilities that are used to represent boolean formulas in conjunctive normal; // form.; //; // [1] https://en.wikipedia.org/wiki/DPLL_algorithm; /// Boolean variables are represented as positive integers.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/FlowSensitive/WatchedLiteralsSolver.cpp:309,perform,perform,309,interpreter/llvm-project/clang/lib/Analysis/FlowSensitive/WatchedLiteralsSolver.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Analysis/FlowSensitive/WatchedLiteralsSolver.cpp,1,['perform'],['perform']
Performance,"// `a = a & ~b`, optimized for few bit sets in B and no allocation.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/RegisterAliasing.h:17,optimiz,optimized,17,interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/RegisterAliasing.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/RegisterAliasing.h,1,['optimiz'],['optimized']
Performance,"// `checkForAllInstructions` is much more cheaper than going through all; // instructions, try it first.; // The queue pointer is not needed if aperture regs is present.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUAttributor.cpp:113,queue,queue,113,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUAttributor.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUAttributor.cpp,1,['queue'],['queue']
Performance,// `get_active_lane_mask` performs an implicit less-than comparison.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandVectorPredication.cpp:26,perform,performs,26,interpreter/llvm-project/llvm/lib/CodeGen/ExpandVectorPredication.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ExpandVectorPredication.cpp,1,['perform'],['performs']
Performance,"// `kInvalidDescriptorId` is used as a marker for thread cancellation. Such item causes the; // thread to terminate; thus, it must appear last in the queue.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RClusterPool.cxx:150,queue,queue,150,tree/ntuple/v7/src/RClusterPool.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RClusterPool.cxx,1,['queue'],['queue']
Performance,// a few special control instructions don't perform a wait operation,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InsertWait.cpp:44,perform,perform,44,interpreter/llvm-project/llvm/lib/Target/X86/X86InsertWait.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InsertWait.cpp,1,['perform'],['perform']
Performance,"// a filter upstream returned false, cache the result",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RFilter.hxx:37,cache,cache,37,tree/dataframe/inc/ROOT/RDF/RFilter.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RFilter.hxx,3,['cache'],['cache']
Performance,"// accept this cached event?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAcceptReject.cxx:15,cache,cached,15,roofit/roofitcore/src/RooAcceptReject.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAcceptReject.cxx,1,['cache'],['cached']
Performance,"// acquire<TFile>(name); // acquire file to ensure stays open while we have the workspace; // actually it appears we don't need to keep the file open once we've loaded the workspace, but should be; // no harm doing so; // otherwise the workspace doesn't saveas",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:161,load,loaded,161,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,1,['load'],['loaded']
Performance,"// adaptive volume; // -----------------------------------------------------------------------; // TODO: optimize, perhaps multi stage with broadening limits,; // or a different root finding method entirely,",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodPDERS.cxx:105,optimiz,optimize,105,tmva/tmva/src/MethodPDERS.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodPDERS.cxx,1,['optimiz'],['optimize']
Performance,"// adc, sbc instructions; // To avoid stack clash, allocation is performed by block and each block is; // probed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.h:65,perform,performed,65,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.h,1,['perform'],['performed']
Performance,"// add a different name when cache is built in case nsetIn is not an empty list",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsCachedPdf.cxx:29,cache,cache,29,roofit/roofitcore/src/RooAbsCachedPdf.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsCachedPdf.cxx,1,['cache'],['cache']
Performance,"// add all libs loaded before libSystem.B.dylib",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/unix/src/TUnixSystem.cxx:16,load,loaded,16,core/unix/src/TUnixSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/unix/src/TUnixSystem.cxx,1,['load'],['loaded']
Performance,"// add any pars that are const here that aren't in constPars list because they may have been; // const-optimized and their values cached with the dataset, so if subsequently floated the; // nll wont evaluate correctly; // fConstVars.reset( fFuncVars->selectByAttrib(""Constant"",true) );; // before returning, flag which of the constPars were actually global observables",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx:103,optimiz,optimized,103,roofit/xroofit/src/xRooNLLVar.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx,2,"['cache', 'optimiz']","['cached', 'optimized']"
Performance,"// add bins in the fCells partition. We need to add the TH2PolyBin objects; // of the new copied histograms. For this we call AddBinToPartition; // we could probably optimize this by implementing a copy of the partition",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TH2Poly.cxx:166,optimiz,optimize,166,hist/hist/src/TH2Poly.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TH2Poly.cxx,1,['optimiz'],['optimize']
Performance,"// add colors after painting is performed - new colors may be generated only during painting",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/webgui6/src/TWebCanvas.cxx:32,perform,performed,32,gui/webgui6/src/TWebCanvas.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/webgui6/src/TWebCanvas.cxx,1,['perform'],['performed']
Performance,"// add current set-up to cache, and return index..",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooProduct.cxx:25,cache,cache,25,roofit/roofitcore/src/RooProduct.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooProduct.cxx,1,['cache'],['cache']
Performance,"// add here so checked for when loading from cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx:32,load,loading,32,roofit/xroofit/src/xRooFit.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx,2,"['cache', 'load']","['cache', 'loading']"
Performance,"// add pragma for optimization of the formula",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TFormula.cxx:18,optimiz,optimization,18,hist/hist/src/TFormula.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TFormula.cxx,1,['optimiz'],['optimization']
Performance,"// add special connection which only used to perform updates",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/webgui6/src/TWebCanvas.cxx:45,perform,perform,45,gui/webgui6/src/TWebCanvas.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/webgui6/src/TWebCanvas.cxx,1,['perform'],['perform']
Performance,"// adding this method with force the auto-loading of the library",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/inc/Math/PdfFuncMathMore.h:42,load,loading,42,math/mathmore/inc/Math/PdfFuncMathMore.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/inc/Math/PdfFuncMathMore.h,1,['load'],['loading']
Performance,"// addr should be a void** right now. Load, then cast the result; // to byref*.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBlocks.cpp:38,Load,Load,38,interpreter/llvm-project/clang/lib/CodeGen/CGBlocks.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGBlocks.cpp,1,['Load'],['Load']
Performance,// address valid for load/store opaque types wider; // than 128-bits,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp:21,load,load,21,interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp,1,['load'],['load']
Performance,"// aka COND_NZ; // Minor optimization: if LHS is a constant, swap operands, then the; // constant can be folded into comparison.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/MSP430/MSP430ISelLowering.cpp:25,optimiz,optimization,25,interpreter/llvm-project/llvm/lib/Target/MSP430/MSP430ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/MSP430/MSP430ISelLowering.cpp,1,['optimiz'],['optimization']
Performance,"// aka COND_Z; // Minor optimization: if LHS is a constant, swap operands, then the; // constant can be folded into comparison.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/MSP430/MSP430ISelLowering.cpp:24,optimiz,optimization,24,interpreter/llvm-project/llvm/lib/Target/MSP430/MSP430ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/MSP430/MSP430ISelLowering.cpp,1,['optimiz'],['optimization']
Performance,"// algorithm is based on standard iterative tree traversal with priority queues",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx:73,queue,queues,73,geom/geom/src/TGeoParallelWorld.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx,1,['queue'],['queues']
Performance,"// allocated in class (not in the 'nearest' method) for better performance",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/CDT/KDTree.h:63,perform,performance,63,math/mathcore/src/CDT/KDTree.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/CDT/KDTree.h,1,['perform'],['performance']
Performance,// already available in cache?,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/GenericUniformityImpl.h:24,cache,cache,24,interpreter/llvm-project/llvm/include/llvm/ADT/GenericUniformityImpl.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/ADT/GenericUniformityImpl.h,1,['cache'],['cache']
Performance,"// already cached",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/RuleEnsemble.cxx:11,cache,cached,11,tmva/tmva/src/RuleEnsemble.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/RuleEnsemble.cxx,1,['cache'],['cached']
Performance,"// already loaded",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/x11ttf/src/TGX11TTF.cxx:11,load,loaded,11,graf2d/x11ttf/src/TGX11TTF.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/x11ttf/src/TGX11TTF.cxx,1,['load'],['loaded']
Performance,"// always lower memset, memcpy, and memmove intrinsics to load/store; // instructions, rather; // then generating calls to memset, mempcy or memmove.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:58,load,load,58,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,1,['load'],['load']
Performance,"// always perform a copy",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RTreeColumnReader.hxx:10,perform,perform,10,tree/dataframe/inc/ROOT/RDF/RTreeColumnReader.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RTreeColumnReader.hxx,1,['perform'],['perform']
Performance,"// an example of a filter's prolog::; // %0 = call ptr @llvm.eh.recoverfp(@""?fin$0@0@main@@"",..); // %1 = call ptr @llvm.localrecover(@""?fin$0@0@main@@"",..); // %2 = load ptr, ptr %1, align 8; // ==> %2 is the frame-pointer of outermost host function",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGException.cpp:166,load,load,166,interpreter/llvm-project/clang/lib/CodeGen/CGException.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGException.cpp,1,['load'],['load']
Performance,"// and (srl x, c), mask => shl (bfe x, nb + c, mask >> nb), nb; // nb = number of trailing zeroes in mask; // It can be optimized out using SDWA for GFX8+ in the SDWA peephole pass,; // given that we are selecting 8 or 16 bit fields starting at byte boundary.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:120,optimiz,optimized,120,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,1,['optimiz'],['optimized']
Performance,"// anonymous namespace; /// Define debug info level for the NVPTX devices. If the debug info for both; /// the host and device are disabled (-g0/-ggdb0 or no debug options at all). If; /// only debug directives are requested for the both host and device; /// (-gline-directvies-only), or the debug info only for the device is disabled; /// (optimization is on and --cuda-noopt-device-debug was not specified), the; /// debug directves only must be emitted for the device. Otherwise, use the same; /// debug info level just like for the host (with the limitations of only; /// supported DWARF2 standard).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Cuda.cpp:341,optimiz,optimization,341,interpreter/llvm-project/clang/lib/Driver/ToolChains/Cuda.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Cuda.cpp,1,['optimiz'],['optimization']
Performance,"// apply range filter logic, cache the result",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RRange.hxx:29,cache,cache,29,tree/dataframe/inc/ROOT/RDF/RRange.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RRange.hxx,1,['cache'],['cache']
Performance,"// are we actually generating anything? (the cache always contains at least our function value)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAcceptReject.cxx:45,cache,cache,45,roofit/roofitcore/src/RooAcceptReject.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAcceptReject.cxx,1,['cache'],['cache']
Performance,// assume( (load addr) != null ) -> add 'nonnull' metadata to load; // (if assume is valid at the load),MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp:12,load,load,12,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp,3,['load'],['load']
Performance,"// at the cost of ~10% performance, don't abort the interpreter on any signal",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.cxx:23,perform,performance,23,bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.cxx,1,['perform'],['performance']
Performance,"// at this point, the dispatcher only lives in C++, as opposed to regular classes; // that are part of the hierarchy in Python, so create it, which will cache it for; // later use by e.g. the MemoryRegulator",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Dispatcher.cxx:153,cache,cache,153,bindings/pyroot/cppyy/CPyCppyy/src/Dispatcher.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Dispatcher.cxx,1,['cache'],['cache']
Performance,"// atomic.notify instruction does not really load the memory specified with; // this argument, but MachineMemOperand should either be load or store, so; // we set this to a load.; // FIXME Volatile isn't really correct, but currently all LLVM atomic; // instructions are treated as volatiles in the backend, so we should be; // consistent. The same applies for wasm_atomic_wait intrinsics too.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp:45,load,load,45,interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/WebAssemblyISelLowering.cpp,3,['load'],['load']
Performance,"// atomicrmw conceptually includes both a load and store from; // the same location.; // As with a store, the location being accessed is not captured,; // but the value being stored is.; // Volatile stores make the address observable.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CaptureTracking.cpp:42,load,load,42,interpreter/llvm-project/llvm/lib/Analysis/CaptureTracking.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CaptureTracking.cpp,1,['load'],['load']
Performance,"// attach our function clone to the cache dataset",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsNumGenerator.cxx:36,cache,cache,36,roofit/roofitcore/src/RooAbsNumGenerator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsNumGenerator.cxx,1,['cache'],['cache']
Performance,"// attempt to load next object as TClass clCast",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TBufferFile.cxx:14,load,load,14,io/io/src/TBufferFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TBufferFile.cxx,2,['load'],['load']
Performance,"// avoid auto flushing again later; // When we are in one-basket-per-cluster mode, there is no need to optimize basket:; // they will automatically grow to the size needed for an event cluster (with the basket; // shrinking preventing them from growing too much larger than the actually-used space).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx:103,optimiz,optimize,103,tree/tree/src/TTree.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx,1,['optimiz'],['optimize']
Performance,"// avoids calls to LoadClassInfo() if info is already loaded",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:19,Load,LoadClassInfo,19,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,2,"['Load', 'load']","['LoadClassInfo', 'loaded']"
Performance,// base+displacement+index for load address operands,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp:31,load,load,31,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp,1,['load'],['load']
Performance,// base+displacement+index for load and store operands,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp:31,load,load,31,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelDAGToDAG.cpp,1,['load'],['load']
Performance,"// because the poller may now have a waiting update from master over the SUB socket,; // but the queue socket could be first in the poll_result vector, and during handling; // of a new task it is possible we need to already receive the updated state over SUB,; // we have to then flip this boolean so that in the for loop when we reach the SUB; // socket's result, we can skip it (otherwise we will hang there, because no more; // updated state will be coming):",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/worker.cxx:97,queue,queue,97,roofit/multiprocess/src/worker.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/worker.cxx,1,['queue'],['queue']
Performance,"// before creating, clear away caches if any if pdf is in ws",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx:31,cache,caches,31,roofit/xroofit/src/xRooNLLVar.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx,1,['cache'],['caches']
Performance,"// before display tree or geometry ensure that they read and cached inside element",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/browserv7/src/RBrowser.cxx:61,cache,cached,61,gui/browserv7/src/RBrowser.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/browserv7/src/RBrowser.cxx,1,['cache'],['cached']
Performance,"// before saving, clear the eocache of all owned nodes; // because causes memory leak when read back in (workspace streamer immediately overwrites the caches); // fixed in: https://github.com/root-project/root/pull/12024",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:151,cache,caches,151,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,1,['cache'],['caches']
Performance,// binary data can be send only as addition to draw message; // here data can be placed in the queue and processed when all other prerequicities are done,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/ui5/tree/controller/TreeViewer.controller.js:95,queue,queue,95,ui5/tree/controller/TreeViewer.controller.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/ui5/tree/controller/TreeViewer.controller.js,1,['queue'],['queue']
Performance,// binary data can be send only as addition to draw message; // here data can be placed in the queue and processed when all other prerequisites are done,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/ui5/geom/controller/GeomHierarchy.controller.js:95,queue,queue,95,ui5/geom/controller/GeomHierarchy.controller.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/ui5/geom/controller/GeomHierarchy.controller.js,2,['queue'],['queue']
Performance,"// bit offset of the next packed item inside the currently loaded word",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RColumnElement.cxx:59,load,loaded,59,tree/ntuple/v7/src/RColumnElement.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RColumnElement.cxx,1,['load'],['loaded']
Performance,"// bitconvert(build_pair(ld, ld)) -> ld iff load locations are consecutive.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:44,load,load,44,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,"// bool ARCOptAddrMode::canSinkLoadStoreTo(MachineInstr *Ldst, MachineInstr *To) {; // // Can only sink load/store within same BB; // if (Ldst->getParent() != To->getParent()); // return false;; // MachineBasicBlock::const_iterator MI(Ldst), ME(To),; // End(Ldst->getParent()->end());; // bool IsStore = Ldst->mayStore();; // bool IsLoad = Ldst->mayLoad();; // Register ValReg = IsLoad ? Ldst->getOperand(0).getReg() : Register();; // for (; MI != ME && MI != End; ++MI) {; // if (MI->isDebugValue()); // continue;; // if (MI->mayStore() || MI->isCall() || MI->isInlineAsm() ||; // MI->hasUnmodeledSideEffects()); // return false;; // if (IsStore && MI->mayLoad()); // return false;; // if (ValReg && MI->readsVirtualRegister(ValReg)); // return false;; // }; // return true;; // }",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARC/ARCOptAddrMode.cpp:104,load,load,104,interpreter/llvm-project/llvm/lib/Target/ARC/ARCOptAddrMode.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARC/ARCOptAddrMode.cpp,1,['load'],['load']
Performance,"// boolean operation optimizer",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TFormula_v5.cxx:21,optimiz,optimizer,21,hist/hist/src/TFormula_v5.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TFormula_v5.cxx,4,['optimiz'],['optimizer']
Performance,"// br(!x, t, f) -> br(x, f, t); // Avoid doing this optimization when instrumenting a condition for MC/DC.; // LNot is taken as part of the condition for simplicity, and changing its; // sense negatively impacts test vector tracking.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenFunction.cpp:52,optimiz,optimization,52,interpreter/llvm-project/clang/lib/CodeGen/CodeGenFunction.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenFunction.cpp,1,['optimiz'],['optimization']
Performance,"// build a string equivalent to; // ""(RInterface<nodetype*>*)(this)->Cache<Ts...>(*(ColumnNames_t*)(&columnList))""",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx:69,Cache,Cache,69,tree/dataframe/inc/ROOT/RDF/RInterface.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx,1,['Cache'],['Cache']
Performance,"// build cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoNavigator.cxx:9,cache,cache,9,geom/geom/src/TGeoNavigator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoNavigator.cxx,1,['cache'],['cache']
Performance,// build line with trying optimize many vertical moves,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:26,optimiz,optimize,26,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['optimiz'],['optimize']
Performance,"// build_vector (load ptr), hi -> load_d16_lo ptr, hi; // build_vector (zextload ptr from i8), hi -> load_d16_lo_u8 ptr, hi; // build_vector (sextload ptr from i8), hi -> load_d16_lo_i8 ptr, hi",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelDAGToDAG.cpp:17,load,load,17,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelDAGToDAG.cpp,1,['load'],['load']
Performance,"// build_vector lo, (load ptr) -> load_d16_hi ptr, lo; // build_vector lo, (zextload ptr from i8) -> load_d16_hi_u8 ptr, lo; // build_vector lo, (sextload ptr from i8) -> load_d16_hi_i8 ptr, lo; // Need to check for possible indirect dependencies on the other half of the; // vector to avoid introducing a cycle.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelDAGToDAG.cpp:21,load,load,21,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUISelDAGToDAG.cpp,1,['load'],['load']
Performance,// builtin_vectorelements supports both fixed-sized and scalable vectors.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp:56,scalab,scalable,56,interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp,1,['scalab'],['scalable']
Performance,"// bypassSlowDivision may create new BBs, but we don't want to reapply the; // optimization to those blocks.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp:79,optimiz,optimization,79,interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp,1,['optimiz'],['optimization']
Performance,// c.ntl.all + c.load/c.store,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVInstrInfo.cpp:17,load,load,17,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVInstrInfo.cpp,1,['load'],['load']
Performance,// c.ntl.all + load/store,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVInstrInfo.cpp:15,load,load,15,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVInstrInfo.cpp,1,['load'],['load']
Performance,// cache CPU related strings,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp:3,cache,cache,3,interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp,1,['cache'],['cache']
Performance,"// cache Error, Result and Status of integration",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/inc/Math/GSLIntegrator.h:3,cache,cache,3,math/mathmore/inc/Math/GSLIntegrator.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/inc/Math/GSLIntegrator.h,2,['cache'],['cache']
Performance,"// cache Parameters for Gradient",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/inc/Math/Polynomial.h:3,cache,cache,3,math/mathmore/inc/Math/Polynomial.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/inc/Math/Polynomial.h,1,['cache'],['cache']
Performance,// cache TargetParser info,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp:3,cache,cache,3,interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp,1,['cache'],['cache']
Performance,"// cache argument types for fast comparison",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TPluginManager.cxx:3,cache,cache,3,core/base/src/TPluginManager.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TPluginManager.cxx,1,['cache'],['cache']
Performance,// cache entry does not exist so far,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:3,cache,cache,3,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['cache'],['cache']
Performance,"// cache got sterilized, trigger repopulation of this slot, then try again...",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAddition.cxx:3,cache,cache,3,roofit/roofitcore/src/RooAddition.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAddition.cxx,2,['cache'],['cache']
Performance,"// cache information",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx:3,cache,cache,3,geom/geom/src/TGeoParallelWorld.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx,1,['cache'],['cache']
Performance,"// cache input layer and output neuron for fast access",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodANNBase.cxx:3,cache,cache,3,tmva/tmva/src/MethodANNBase.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodANNBase.cxx,1,['cache'],['cache']
Performance,// cache is always NULL.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp:3,cache,cache,3,interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp,2,['cache'],['cache']
Performance,"// cache lock file",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/inc/TProof.h:3,cache,cache,3,proof/proof/inc/TProof.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/inc/TProof.h,1,['cache'],['cache']
Performance,"// cache lookup for low level views",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPDataMember.cxx:3,cache,cache,3,bindings/pyroot/cppyy/CPyCppyy/src/CPPDataMember.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPDataMember.cxx,1,['cache'],['cache']
Performance,// cache lookups,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/TargetProcess/JITLoaderPerf.cpp:3,cache,cache,3,interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/TargetProcess/JITLoaderPerf.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/TargetProcess/JITLoaderPerf.cpp,2,['cache'],['cache']
Performance,"// cache max bin sum for auto scale",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/src/TEveCalo.cxx:3,cache,cache,3,graf3d/eve/src/TEveCalo.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/src/TEveCalo.cxx,2,['cache'],['cache']
Performance,"// cache miss, need to actually save the string",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/StringSaver.cpp:3,cache,cache,3,interpreter/llvm-project/llvm/lib/Support/StringSaver.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/StringSaver.cpp,1,['cache'],['cache']
Performance,"// cache mode properties are not transferred in copy constructor",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooObjCacheManager.cxx:3,cache,cache,3,roofit/roofitcore/src/RooObjCacheManager.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooObjCacheManager.cxx,1,['cache'],['cache']
Performance,"// cache number of Parameters for speed efficiency",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/inc/Math/ParamFunction.h:3,cache,cache,3,math/mathmore/inc/Math/ParamFunction.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/inc/Math/ParamFunction.h,1,['cache'],['cache']
Performance,"// cache of IsSTLContainer()",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TBaseClass.h:3,cache,cache,3,core/meta/inc/TBaseClass.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TBaseClass.h,1,['cache'],['cache']
Performance,"// cache order = number of params - 1)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/inc/Math/Polynomial.h:3,cache,cache,3,math/mathmore/inc/Math/Polynomial.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/inc/Math/Polynomial.h,1,['cache'],['cache']
Performance,"// cache pointers to synapses for fast access, the order matters",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodANNBase.cxx:3,cache,cache,3,tmva/tmva/src/MethodANNBase.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodANNBase.cxx,1,['cache'],['cache']
Performance,"// cache stuff about x",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/src/RooKeysPdf.cxx:3,cache,cache,3,roofit/roofit/src/RooKeysPdf.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/src/RooKeysPdf.cxx,1,['cache'],['cache']
Performance,"// cache the new maker (TODO: does it make sense to use weakrefs?)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Utility.cxx:3,cache,cache,3,bindings/pyroot/cppyy/CPyCppyy/src/Utility.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Utility.cxx,1,['cache'],['cache']
Performance,"// cache the new wrapper",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Converters.cxx:3,cache,cache,3,bindings/pyroot/cppyy/CPyCppyy/src/Converters.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Converters.cxx,1,['cache'],['cache']
Performance,"// cache the range limits in a flat vector",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooFitImplHelpers.cxx:3,cache,cache,3,roofit/roofitcore/src/RooFitImplHelpers.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooFitImplHelpers.cxx,1,['cache'],['cache']
Performance,"// cache the result",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPScope.cxx:3,cache,cache,3,bindings/pyroot/cppyy/CPyCppyy/src/CPPScope.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPScope.cxx,2,['cache'],['cache']
Performance,"// cache the result for future lookups and return",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/ProxyWrappers.cxx:3,cache,cache,3,bindings/pyroot/cppyy/CPyCppyy/src/ProxyWrappers.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/ProxyWrappers.cxx,1,['cache'],['cache']
Performance,"// cache the sorted status",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/cont/src/TClonesArray.cxx:3,cache,cache,3,core/cont/src/TClonesArray.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/cont/src/TClonesArray.cxx,1,['cache'],['cache']
Performance,// cache the subtarget here,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.h:3,cache,cache,3,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.h,1,['cache'],['cache']
Performance,"// cache the template on its clean name",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPScope.cxx:3,cache,cache,3,bindings/pyroot/cppyy/CPyCppyy/src/CPPScope.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPScope.cxx,1,['cache'],['cache']
Performance,"// cache training events",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodFDA.cxx:3,cache,cache,3,tmva/tmva/src/MethodFDA.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodFDA.cxx,1,['cache'],['cache']
Performance,"// cache values here",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/src/TEveProjectionAxesGL.cxx:3,cache,cache,3,graf3d/eve/src/TEveProjectionAxesGL.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/src/TEveProjectionAxesGL.cxx,1,['cache'],['cache']
Performance,"// cache->ReleaseInfo(); // no hierarchical use",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx:3,cache,cache,3,geom/geom/src/TGeoParallelWorld.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx,1,['cache'],['cache']
Performance,"// cache._rearrangedDen->printComponentTree("""",0,5) ;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooProdPdf.cxx:3,cache,cache,3,roofit/roofitcore/src/RooProdPdf.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooProdPdf.cxx,1,['cache'],['cache']
Performance,"// cache._rearrangedNum->printComponentTree("""",0,5) ;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooProdPdf.cxx:3,cache,cache,3,roofit/roofitcore/src/RooProdPdf.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooProdPdf.cxx,1,['cache'],['cache']
Performance,// cacheLengths must be recalculated.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:3,cache,cacheLengths,3,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['cache'],['cacheLengths']
Performance,// cachePolicy,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:3,cache,cachePolicy,3,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,1,['cache'],['cachePolicy']
Performance,"// cached",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/inc/TEveCaloData.h:3,cache,cached,3,graf3d/eve/inc/TEveCaloData.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/inc/TEveCaloData.h,10,['cache'],['cached']
Performance,"// cached RAM in MB",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h:3,cache,cached,3,core/base/inc/TSystem.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h,1,['cache'],['cached']
Performance,// cached and complete!,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/DeclObjC.cpp:3,cache,cached,3,interpreter/llvm-project/clang/lib/AST/DeclObjC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/DeclObjC.cpp,1,['cache'],['cached']
Performance,"// cached coordinates (or parameter values in case of gradientpar)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/FitUtil.cxx:3,cache,cached,3,math/mathcore/src/FitUtil.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/FitUtil.cxx,1,['cache'],['cached']
Performance,"// cached info on variable",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/inc/RooKeysPdf.h:3,cache,cached,3,roofit/roofit/inc/RooKeysPdf.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/inc/RooKeysPdf.h,2,['cache'],['cached']
Performance,"// cached inv denominator for computing barycentric coordinates (see above)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Math/Delaunay2D.h:3,cache,cached,3,math/mathcore/inc/Math/Delaunay2D.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Math/Delaunay2D.h,1,['cache'],['cached']
Performance,"// cached reshaped data tensor; // counter of trained batches for computing testing and variance means",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/DNN/BatchNormLayer.h:3,cache,cached,3,tmva/tmva/inc/TMVA/DNN/BatchNormLayer.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/DNN/BatchNormLayer.h,1,['cache'],['cached']
Performance,"// cached swap in MB",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h:3,cache,cached,3,core/base/inc/TSystem.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h,1,['cache'],['cached']
Performance,"// cached tensor used for Cudnn to get correct shape",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/DNN/BatchNormLayer.h:3,cache,cached,3,tmva/tmva/inc/TMVA/DNN/BatchNormLayer.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/DNN/BatchNormLayer.h,1,['cache'],['cached']
Performance,"// cached value for voxel half diagonal length",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoVoxelGrid.h:3,cache,cached,3,geom/geom/inc/TGeoVoxelGrid.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoVoxelGrid.h,1,['cache'],['cached']
Performance,"// cached value of dimension; //std::vector<double> fParams; // cached vector with parameter values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/inc/Math/WrappedMultiTF1.h:3,cache,cached,3,hist/hist/inc/Math/WrappedMultiTF1.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/inc/Math/WrappedMultiTF1.h,2,['cache'],['cached']
Performance,"// cached value that doubles as initialized flag (uninitialized if -1)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.h:3,cache,cached,3,bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.h,1,['cache'],['cached']
Performance,"// cached values for propagator",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/src/TEveTrackPropagator.cxx:3,cache,cached,3,graf3d/eve/src/TEveTrackPropagator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/src/TEveTrackPropagator.cxx,1,['cache'],['cached']
Performance,"// cached vector",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Math/WrappedParamFunction.h:3,cache,cached,3,math/mathcore/inc/Math/WrappedParamFunction.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Math/WrappedParamFunction.h,2,['cache'],['cached']
Performance,"// cached vector of gradient values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/src/GSLNLSMinimizer.cxx:3,cache,cached,3,math/mathmore/src/GSLNLSMinimizer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/src/GSLNLSMinimizer.cxx,1,['cache'],['cached']
Performance,"// cached vector to avoid re-allocating every time a new one",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/src/GSLMultiFit.h:3,cache,cached,3,math/mathmore/src/GSLMultiFit.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/src/GSLMultiFit.h,4,['cache'],['cached']
Performance,// cachepolicy,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:3,cache,cachepolicy,3,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,12,['cache'],['cachepolicy']
Performance,"// cachepolicy, swizzled buffer",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:3,cache,cachepolicy,3,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,8,['cache'],['cachepolicy']
Performance,"// cachepolicy, swizzled buffer(imm)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp:3,cache,cachepolicy,3,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPULegalizerInfo.cpp,4,['cache'],['cachepolicy']
Performance,"// calculating how many files from TDSet are not cached on; // any slave",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/src/TPacketizerAdaptive.cxx:49,cache,cached,49,proof/proofplayer/src/TPacketizerAdaptive.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/src/TPacketizerAdaptive.cxx,1,['cache'],['cached']
Performance,"// call Update again, return before actual drawing will be performed by the browser",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/rcanvas/rcanvas_update.cxx:59,perform,performed,59,tutorials/rcanvas/rcanvas_update.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/rcanvas/rcanvas_update.cxx,1,['perform'],['performed']
Performance,"// call once and cache the result to reduce lock contention",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TPluginManager.cxx:17,cache,cache,17,core/base/src/TPluginManager.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TPluginManager.cxx,1,['cache'],['cache']
Performance,"// called when loading a new file; // get branch pointers",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/tree/h1analysis.h:15,load,loading,15,tutorials/tree/h1analysis.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/tree/h1analysis.h,1,['load'],['loading']
Performance,"// calling fTransform() like here was not thread safe because it was using a cached vector; // return Fcn()( fTransform(v) );; // make a new thread-safe implementation creating a vector each time; // a bit slower few% in stressFit and 10% in Rosenbrock function but it is negligible in big fits; // get first initial values of parameter (in case some one is fixed)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/MnUserFcn.cxx:77,cache,cached,77,math/minuit2/src/MnUserFcn.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/MnUserFcn.cxx,1,['cache'],['cached']
Performance,"// calling loadSnapshot will also copy the current parameter values in the workspaces; // since we do not want to change the model parameters - we restore the previous ones",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/ModelConfig.cxx:11,load,loadSnapshot,11,roofit/roofitcore/src/ModelConfig.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/ModelConfig.cxx,1,['load'],['loadSnapshot']
Performance,// camera matrices cache,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:19,cache,cache,19,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['cache'],['cache']
Performance,"// can only analyze simple loads and stores, i.e., no calls, invokes, etc.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/DependenceAnalysis.cpp:27,load,loads,27,interpreter/llvm-project/llvm/lib/Analysis/DependenceAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/DependenceAnalysis.cpp,1,['load'],['loads']
Performance,"// can try to do a readOnly in case can load from cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx:40,load,load,40,roofit/xroofit/src/xRooNLLVar.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx,8,"['cache', 'load']","['cache', 'load']"
Performance,"// canHandle makes sure that we _can_ correctly analyze the dependencies; // between A and B here -- for instance, we should not be dealing with heap; // load-store dependencies here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ImplicitNullChecks.cpp:154,load,load-store,154,interpreter/llvm-project/llvm/lib/CodeGen/ImplicitNullChecks.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/ImplicitNullChecks.cpp,1,['load'],['load-store']
Performance,"// canOptimizeTLSDFormToXForm - Optimize TLS accesses when an ADD_TLS; // instruction is present. An ADD_TLS instruction, followed by a D-Form memory; // operation, can be optimized to use an X-Form load or store, allowing the; // ADD_TLS node to be removed completely.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp:32,Optimiz,Optimize,32,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,3,"['Optimiz', 'load', 'optimiz']","['Optimize', 'load', 'optimized']"
Performance,"// case 2 - lxvr[hb]x; // 2.1: load result is at most i16;; // 2.2: build a vector with above loaded value;; // 2.3: the vector has only one value at index 0, others are all undef;; // 2.4: on LE target, so that lxvr[hb]x does not need any permute.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:31,load,load,31,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,2,['load'],"['load', 'loaded']"
Performance,"// cerr << ""got point above upper bound:""; // << double(_x) << "" > "" << _hi; // << "" -- performing linear extrapolation..."" << endl;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/src/RooKeysPdf.cxx:88,perform,performing,88,roofit/roofit/src/RooKeysPdf.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/src/RooKeysPdf.cxx,1,['perform'],['performing']
Performance,"// cerr << ""got point below lower bound:""; // << double(_x) << "" < "" << _lo; // << "" -- performing linear extrapolation..."" << endl;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/src/RooKeysPdf.cxx:88,perform,performing,88,roofit/roofit/src/RooKeysPdf.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/src/RooKeysPdf.cxx,1,['perform'],['performing']
Performance,// change only min or max side; // AMT tmp workaround / event queue not enabled,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/ui5/eve7/controller/Ged.controller.js:62,queue,queue,62,ui5/eve7/controller/Ged.controller.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/ui5/eve7/controller/Ged.controller.js,1,['queue'],['queue']
Performance,// change range; // AMT tmp workaround / event queue not enabled,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/ui5/eve7/controller/Ged.controller.js:47,queue,queue,47,ui5/eve7/controller/Ged.controller.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/ui5/eve7/controller/Ged.controller.js,1,['queue'],['queue']
Performance,"// check file in cache directory",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProofServ.cxx:17,cache,cache,17,proof/proof/src/TProofServ.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProofServ.cxx,1,['cache'],['cache']
Performance,"// check first if we can load the SOFIE parser library",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RSofieReader.hxx:25,load,load,25,tmva/tmva/inc/TMVA/RSofieReader.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RSofieReader.hxx,1,['load'],['load']
Performance,"// check for specific optimizer parameters",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodDL.cxx:22,optimiz,optimizer,22,tmva/tmva/src/MethodDL.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodDL.cxx,1,['optimiz'],['optimizer']
Performance,// check if basket already loaded in the branch,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:27,load,loaded,27,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['load'],['loaded']
Performance,// check if code already loaded - to avoid duplication,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:25,load,loaded,25,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['load'],['loaded']
Performance,"// check if file is in the cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx:27,cache,cache,27,io/io/src/TFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx,1,['cache'],['cache']
Performance,"// check if font is in cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/graf/src/TTF.cxx:23,cache,cache,23,graf2d/graf/src/TTF.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/graf/src/TTF.cxx,1,['cache'],['cache']
Performance,"// check if optimizer has default values for this specific parameters",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodDL.cxx:12,optimiz,optimizer,12,tmva/tmva/src/MethodDL.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodDL.cxx,1,['optimiz'],['optimizer']
Performance,// check if requests are needed to load part in the begin of the list,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/ui5/browser/model/BrowserModel.js:35,load,load,35,ui5/browser/model/BrowserModel.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/ui5/browser/model/BrowserModel.js,1,['load'],['load']
Performance,// check if simple reading can be performed and there are direct data in branch,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:34,perform,performed,34,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['perform'],['performed']
Performance,"// check if we read through a file cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx:35,cache,cache,35,io/io/src/TFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx,1,['cache'],['cache']
Performance,"// check if we should draw markers or error marks directly, skipping optimization",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:69,optimiz,optimization,69,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['optimiz'],['optimization']
Performance,"// check in the source manager if the file is actually loaded",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:55,load,loaded,55,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,1,['load'],['loaded']
Performance,"// check that none of the libs failed to load",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx:41,load,load,41,core/base/src/TSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx,1,['load'],['load']
Performance,"// check that rdfentry_ contains all expected values,; // also in multi-thread runs over multiple ROOT files",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_regression.cxx:66,multi-thread,multi-thread,66,tree/dataframe/test/dataframe_regression.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_regression.cxx,1,['multi-thread'],['multi-thread']
Performance,"// check that segment is inside cached area",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/net/src/TWebFile.cxx:32,cache,cached,32,net/net/src/TWebFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/net/src/TWebFile.cxx,1,['cache'],['cached']
Performance,"// check the last clean-up in the cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx:34,cache,cache,34,io/io/src/TFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx,1,['cache'],['cache']
Performance,"// check the time passed since last cache cleanup",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx:36,cache,cache,36,io/io/src/TFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx,1,['cache'],['cache']
Performance,"// check-for-unused-options is performed; may be overridden by derived classes",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Classification.cxx:31,perform,performed,31,tmva/tmva/src/Classification.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Classification.cxx,2,['perform'],['performed']
Performance,"// clang-format off; /**; * \class ROOT::RDataFrame; * \ingroup dataframe; * \brief ROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree , CSV and other data formats, in C++ or Python. In addition, multi-threading and other low-level optimisations allow users to exploit all the resources available; on their machines completely transparently.<br>; Skip to the [class reference](#reference) or keep reading for the user guide. In a nutshell:; ~~~{.cpp}; ROOT::EnableImplicitMT(); // Tell ROOT you want to go parallel; ROOT::RDataFrame d(""myTree"", ""file_*.root""); // Interface to TTree and TChain; auto myHisto = d.Histo1D(""Branch_A""); // This books the (lazy) filling of a histogram; myHisto->Draw(); // Event loop is run here, upon first access to a result; ~~~. Calculations are expressed in terms of a type-safe *functional chain of actions and transformations*, RDataFrame takes; care of their execution. The implementation automatically puts in place several low level optimisations such as; multi-thread parallelization and caching. \htmlonly; <a href=""https://doi.org/10.5281/zenodo.260230""><img src=""https://zenodo.org/badge/DOI/10.5281/zenodo.260230.svg""; alt=""DOI""></a>; \endhtmlonly. ## For the impatient user; You can directly see RDataFrame in action in our [tutorials](https://root.cern/doc/master/group__tutorial__dataframe.html), in C++ or Python. ## Table of Contents; - [Cheat sheet](\ref cheatsheet); - [Introduction](\ref introduction); - [Crash course](\ref crash-course); - [Working with collections](\ref collections); - [Transformations: manipulating data](\ref transformations); - [Actions: getting results](\ref actions); - [Distributed execution in Python](\ref distrdf); - [Performance tips and parallel execution](\ref parallel-execution); - [More features](\ref more-features); - [Systematic variations](\ref systematics); - [RDataFrame objects as function arguments and return values](\ref rnode); - [Storing RDataFrame objects in",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RDataFrame.cxx:238,multi-thread,multi-threading,238,tree/dataframe/src/RDataFrame.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RDataFrame.cxx,1,['multi-thread'],['multi-threading']
Performance,"// clang-format off; /**; \class ROOT::Experimental::Detail::RNTupleAtomicCounter; \ingroup NTuple; \brief A thread-safe integral performance counter; */; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RNTupleMetrics.hxx:130,perform,performance,130,tree/ntuple/v7/inc/ROOT/RNTupleMetrics.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RNTupleMetrics.hxx,1,['perform'],['performance']
Performance,"// clang-format off; /**; \class ROOT::Experimental::Detail::RNTuplePerfCounter; \ingroup NTuple; \brief A performance counter with a name and a unit, which can be activated on demand. Derived classes decide on the counter type and implement printing of the value.; */; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RNTupleMetrics.hxx:107,perform,performance,107,tree/ntuple/v7/inc/ROOT/RNTupleMetrics.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RNTupleMetrics.hxx,1,['perform'],['performance']
Performance,"// clang-format off; /**; \class ROOT::Experimental::Detail::RNTuplePlainCounter; \ingroup NTuple; \brief A non thread-safe integral performance counter; */; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RNTupleMetrics.hxx:133,perform,performance,133,tree/ntuple/v7/inc/ROOT/RNTupleMetrics.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RNTupleMetrics.hxx,1,['perform'],['performance']
Performance,"// clang-format off; /**; \class ROOT::Experimental::Internal::RClusterPool; \ingroup NTuple; \brief Managed a set of clusters containing compressed and packed pages. The cluster pool steers the preloading of (partial) clusters. There is a two-step pipeline: in a first step,; compressed pages are read from clusters into a memory buffer. The second pipeline step decompresses the pages; and pushes them into the page pool. The actual logic of reading and unzipping is implemented by the page source.; The cluster pool only orchestrates the work queues for reading and unzipping. It uses one extra I/O thread for; reading waits for data from storage and generates no CPU load. The unzipping step of the pipeline therefore behaves differently depending on whether or not implicit multi-threading; is turned on. If it is turned off, i.e. in a single-threaded environment, the cluster pool will only read the; compressed pages and the page source has to uncompresses pages at a later point when data from the page is requested.; */; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RClusterPool.hxx:546,queue,queues,546,tree/ntuple/v7/inc/ROOT/RClusterPool.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RClusterPool.hxx,3,"['load', 'multi-thread', 'queue']","['load', 'multi-threading', 'queues']"
Performance,"// clang-format off; /**; \class ROOT::Experimental::Internal::RNTupleSerializer; \ingroup NTuple; \brief A helper class for serializing and deserialization of the RNTuple binary format. All serialization and deserialization routines return the number of bytes processed (written or read). The serialization routines can be called with a nullptr buffer, in which case only the size required to perform; a serialization is returned. Deserialization routines must be called with a buffer that is sufficiently large. Deserialization errors throw exceptions. Only when indicated or when passed as a parameter is the buffer size checked.; */; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RNTupleSerialize.hxx:394,perform,perform,394,tree/ntuple/v7/inc/ROOT/RNTupleSerialize.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RNTupleSerialize.hxx,1,['perform'],['perform']
Performance,"// clang-format off; /**; \class ROOT::Experimental::Internal::RPageAllocator; \ingroup NTuple; \brief Abstract interface to allocate and release pages. The page allocator acquires and releases memory for pages. It does not load the page data, the returned pages; are empty but guaranteed to have enough contiguous space for the given number of elements.; The page allocator must be thread-safe.; */; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RPageAllocator.hxx:224,load,load,224,tree/ntuple/v7/inc/ROOT/RPageAllocator.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RPageAllocator.hxx,1,['load'],['load']
Performance,"// clang-format off; /**; \class ROOT::Experimental::Internal::RPagePool; \ingroup NTuple; \brief A thread-safe cache of pages loaded from the page source. The page pool is used as a cache for pages loaded from a page source.; In this way, identical page needed at the same time, only need to be loaded once.; Page sources also use the page pool to stage (preload) pages unsealed by IMT tasks.; */; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RPagePool.hxx:112,cache,cache,112,tree/ntuple/v7/inc/ROOT/RPagePool.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RPagePool.hxx,5,"['cache', 'load']","['cache', 'loaded']"
Performance,"// clang-format off; /**; \class ROOT::RDF::RDataSource; \ingroup dataframe; \brief RDataSource defines an API that RDataFrame can use to read arbitrary data formats. A concrete RDataSource implementation (i.e. a class that inherits from RDataSource and implements all of its pure; methods) provides an adaptor that RDataFrame can leverage to read any kind of tabular data formats.; RDataFrame calls into RDataSource to retrieve information about the data, retrieve (thread-local) readers or ""cursors""; for selected columns and to advance the readers to the desired data entry. The sequence of calls that RDataFrame (or any other client of a RDataSource) performs is the following:. - SetNSlots() : inform RDataSource of the desired level of parallelism; - GetColumnReaders() : retrieve from RDataSource per-thread readers for the desired columns; - Initialize() : inform RDataSource that an event-loop is about to start; - GetEntryRanges() : retrieve from RDataSource a set of ranges of entries that can be processed concurrently; - InitSlot() : inform RDataSource that a certain thread is about to start working on a certain range of entries; - SetEntry() : inform RDataSource that a certain thread is about to start working on a certain entry; - FinalizeSlot() : inform RDataSource that a certain thread finished working on a certain range of entries; - Finalize() : inform RDataSource that an event-loop finished. RDataSource implementations must support running multiple event-loops consecutively (although sequentially) on the same dataset.; - \b SetNSlots() is called once per RDataSource object, typically when it is associated to a RDataFrame.; - \b GetColumnReaders() can be called several times, potentially with the same arguments, also in-between event-loops, but not during an event-loop.; - \b GetEntryRanges() will be called several times, including during an event loop, as additional ranges are needed. It will not be called concurrently.; - \b Initialize() and \b Finalize() are cal",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDataSource.hxx:655,perform,performs,655,tree/dataframe/inc/ROOT/RDataSource.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDataSource.hxx,1,['perform'],['performs']
Performance,"// clang-format off; /**; \class ROnDiskPage; \ingroup NTuple; \brief A page as being stored on disk, that is packed and compressed. Used by the cluster pool to cache pages from the physical storage. Such pages generally need to be; uncompressed and unpacked before they can be used by RNTuple upper layers.; */; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RCluster.hxx:161,cache,cache,161,tree/ntuple/v7/inc/ROOT/RCluster.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RCluster.hxx,1,['cache'],['cache']
Performance,"// clang-format off; /// Create a graphviz representation of the dataframe computation graph, return it as a string.; /// \param[in] node any node of the graph. Called on the head (first) node, it prints the entire graph. Otherwise, only the branch the node belongs to.; ///; /// The output can be displayed with a command akin to `dot -Tpng output.dot > output.png && open output.png`.; ///; /// Note that ""hanging"" Defines, i.e. Defines without downstream nodes, will not be displayed by SaveGraph as they are; /// effectively optimized away from the computation graph.; ///; /// Note that SaveGraph is not thread-safe and must not be called concurrently from different threads.; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDFHelpers.hxx:529,optimiz,optimized,529,tree/dataframe/inc/ROOT/RDFHelpers.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDFHelpers.hxx,2,"['concurren', 'optimiz']","['concurrently', 'optimized']"
Performance,"// clang-format off; /// Create a graphviz representation of the dataframe computation graph, write it to the specified file.; /// \param[in] node any node of the graph. Called on the head (first) node, it prints the entire graph. Otherwise, only the branch the node belongs to.; /// \param[in] outputFile file where to save the representation.; ///; /// The output can be displayed with a command akin to `dot -Tpng output.dot > output.png && open output.png`.; ///; /// Note that ""hanging"" Defines, i.e. Defines without downstream nodes, will not be displayed by SaveGraph as they are; /// effectively optimized away from the computation graph.; ///; /// Note that SaveGraph is not thread-safe and must not be called concurrently from different threads.; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDFHelpers.hxx:604,optimiz,optimized,604,tree/dataframe/inc/ROOT/RDFHelpers.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDFHelpers.hxx,2,"['concurren', 'optimiz']","['concurrently', 'optimized']"
Performance,"// clang-format off; /// EReadWrite Enumerator; /// | Enum Constant | Description |; /// |-------------|--------------------|; /// | kBase | Base class element |; /// | kOffsetL | Fixed size array |; /// | kOffsetP | Pointer to object |; /// | kCounter | Counter for array size |; /// | kCharStar | Pointer to array of char |; /// | kLegacyChar | Equal to TDataType's kchar |; /// | kBits | TObject::fBits in case of a referenced object |; /// | kObject | Class derived from TObject, or for TStreamerSTL::fCtype non-pointer elements |; /// | kObjectp | Class* derived from TObject and with comment field //->Class, or for TStreamerSTL::fCtype: pointer elements |; /// | kObjectP | Class* derived from TObject and with NO comment field //->Class |; /// | kAny | Class not derived from TObject |; /// | kAnyp | Class* not derived from TObject with comment field //->Class |; /// | kAnyP | Class* not derived from TObject with NO comment field //->Class |; /// | kAnyPnoVT | Class* not derived from TObject with NO comment field //->Class and Class has NO virtual table |; /// | kSTLp | Pointer to STL container |; /// | kTString | TString, special case |; /// | kTObject | TObject, special case |; /// | kTNamed | TNamed , special case |; /// | kCache | Cache the value in memory than is not part of the object but is accessible via a SchemaRule |; /// | kNoType | Indicator that we don't know the current type because the member does not exist in memory |; /// | kUnsupportedConversion | The member type onfile and in memory can not be converted |; /// | kUnset | default value |",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TVirtualStreamerInfo.h:1252,Cache,Cache,1252,core/meta/inc/TVirtualStreamerInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TVirtualStreamerInfo.h,1,['Cache'],['Cache']
Performance,"// clang-format off; /// Register a callback that RDataFrame will execute in each worker thread concurrently on that thread's partial result.; ///; /// \param[in] everyNEvents Frequency at which the callback will be called by each thread, as a number of events processed; /// \param[in] callback A callable with signature `void(unsigned int, Value_t&)` where Value_t is the type of the value contained in this RResultPtr; /// \return this RResultPtr, to allow chaining of OnPartialResultSlot with other calls; ///; /// See `OnPartialResult` for a generic explanation of the callback mechanism.; /// Compared to `OnPartialResult`, this method has two major differences:; /// - all worker threads invoke the callback once every specified number of events. The event count is per-thread,; /// and callback invocation might happen concurrently (i.e. the callback must be thread-safe); /// - the callable must take an extra `unsigned int` parameter corresponding to a multi-thread ""processing slot"":; /// this is a ""helper value"" to simplify writing thread-safe callbacks: different worker threads might invoke the; /// callback concurrently but always with different `slot` numbers.; /// - a value of 0 for everyNEvents indicates the callback must be executed once _per slot_.; ///; /// For example, the following snippet prints out a thread-safe progress bar of the events processed by RDataFrame; /// \code; /// auto c = tdf.Count(); // any action would do, but `Count` is the most lightweight; /// std::string progress;; /// std::mutex bar_mutex;; /// c.OnPartialResultSlot(nEvents / 100, [&progress, &bar_mutex](unsigned int, ULong64_t &) {; /// std::lock_guard<std::mutex> lg(bar_mutex);; /// progress.push_back('#');; /// std::cout << ""\r["" << std::left << std::setw(100) << progress << ']' << std::flush;; /// });; /// std::cout << ""Analysis running..."" << std::endl;; /// *c; // trigger the event loop by accessing an action's result; /// std::cout << ""\nDone!"" << std::endl;; /// \endcode; // cla",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RResultPtr.hxx:96,concurren,concurrently,96,tree/dataframe/inc/ROOT/RResultPtr.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RResultPtr.hxx,2,['concurren'],['concurrently']
Performance,"// clang-format off; /// Trigger the event loop of multiple RDataFrames concurrently; /// \param[in] handles A vector of RResultHandles; /// \return The number of distinct computation graphs that have been processed; ///; /// This function triggers the event loop of all computation graphs which relate to the; /// given RResultHandles. The advantage compared to running the event loop implicitly by accessing the; /// RResultPtr is that the event loops will run concurrently. Therefore, the overall; /// computation of all results is generally more efficient.; /// It should be noted that user-defined operations (e.g., Filters and Defines) of the different RDataFrame graphs are assumed to be safe to call concurrently.; ///; /// ~~~{.cpp}; /// ROOT::RDataFrame df1(""tree1"", ""file1.root"");; /// auto r1 = df1.Histo1D(""var1"");; ///; /// ROOT::RDataFrame df2(""tree2"", ""file2.root"");; /// auto r2 = df2.Sum(""var2"");; ///; /// // RResultPtr -> RResultHandle conversion is automatic; /// ROOT::RDF::RunGraphs({r1, r2});; /// ~~~; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDFHelpers.hxx:72,concurren,concurrently,72,tree/dataframe/inc/ROOT/RDFHelpers.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDFHelpers.hxx,3,['concurren'],['concurrently']
Performance,"// clang-format off; /// \brief Inform RDataSource of the number of processing slots (i.e. worker threads) used by the associated RDataFrame.; /// Slots numbers are used to simplify parallel execution: RDataFrame guarantees that different threads will always; /// pass different slot values when calling methods concurrently.; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDataSource.hxx:312,concurren,concurrently,312,tree/dataframe/inc/ROOT/RDataSource.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDataSource.hxx,1,['concurren'],['concurrently']
Performance,"// clang-format off; ////////////////////////////////////////////////////////////////////////////////; /// Enables the global mutex to make ROOT thread safe/aware.; ///; /// The following becomes safe:; /// - concurrent construction and destruction of TObjects, including the ones registered in ROOT's global lists (e.g. gROOT->GetListOfCleanups(), gROOT->GetListOfFiles()); /// - concurrent usage of _different_ ROOT objects from different threads, including ones with global state (e.g. TFile, TTree, TChain) with the exception of graphics classes (e.g. TCanvas); /// - concurrent calls to ROOT's type system classes, e.g. TClass and TEnum; /// - concurrent calls to the interpreter through gInterpreter; /// - concurrent loading of ROOT plug-ins; ///; /// In addition, gDirectory, gFile and gPad become a thread-local variable.; /// In all threads, gDirectory defaults to gROOT, a singleton which supports thread-safe insertion and deletion of contents.; /// gFile and gPad default to nullptr, as it is for single-thread programs.; ///; /// The ROOT graphics subsystem is not made thread-safe by this method. In particular drawing or printing different; /// canvases from different threads (and analogous operations such as invoking `Draw` on a `TObject`) is not thread-safe.; ///; /// Note that there is no `DisableThreadSafety()`. ROOT's thread-safety features cannot be disabled once activated.; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TROOT.cxx:209,concurren,concurrent,209,core/base/src/TROOT.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TROOT.cxx,6,"['concurren', 'load']","['concurrent', 'loading']"
Performance,"// clang-format off; ////////////////////////////////////////////////////////////////////////////; /// \brief Creates a node that filters entries based on range: [begin, end).; /// \param[in] begin Initial entry number considered for this range.; /// \param[in] end Final entry number (excluded) considered for this range. 0 means that the range goes until the end of the dataset.; /// \param[in] stride Process one entry of the [begin, end) range every `stride` entries. Must be strictly greater than 0.; /// \return the first node of the computation graph for which the event loop is limited to a certain range of entries.; ///; /// Note that in case of previous Ranges and Filters the selected range refers to the transformed dataset.; /// Ranges are only available if EnableImplicitMT has _not_ been called. Multi-thread ranges are not supported.; ///; /// ### Example usage:; /// ~~~{.cpp}; /// auto d_0_30 = d.Range(0, 30); // Pick the first 30 entries; /// auto d_15_end = d.Range(15, 0); // Pick all entries from 15 onwards; /// auto d_15_end_3 = d.Range(15, 0, 3); // Stride: from event 15, pick an event every 3; /// ~~~; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx:812,Multi-thread,Multi-thread,812,tree/dataframe/inc/ROOT/RDF/RInterface.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx,1,['Multi-thread'],['Multi-thread']
Performance,"// clang-format off; ////////////////////////////////////////////////////////////////////////////; /// \brief Define a new column that is updated when the input sample changes.; /// \param[in] name The name of the defined column.; /// \param[in] expression A C++ callable that computes the new value of the defined column.; /// \return the first node of the computation graph for which the new quantity is defined.; ///; /// The signature of the callable passed as second argument should be `T(unsigned int slot, const ROOT::RDF::RSampleInfo &id)`; /// where:; /// - `T` is the type of the defined column; /// - `slot` is a number in the range [0, nThreads) that is different for each processing thread. This can simplify; /// the definition of thread-safe callables if you are interested in using parallel capabilities of RDataFrame.; /// - `id` is an instance of a ROOT::RDF::RSampleInfo object which contains information about the sample which is; /// being processed (see the class docs for more information).; ///; /// DefinePerSample() is useful to e.g. define a quantity that depends on which TTree in which TFile is being; /// processed or to inject a callback into the event loop that is only called when the processing of a new sample; /// starts rather than at every entry.; ///; /// The callable will be invoked once per input TTree or once per multi-thread task, whichever is more often.; ///; /// ### Example usage:; /// ~~~{.cpp}; /// ROOT::RDataFrame df{""mytree"", {""sample1.root"",""sample2.root""}};; /// df.DefinePerSample(""weightbysample"",; /// [](unsigned int slot, const ROOT::RDF::RSampleInfo &id); /// { return id.Contains(""sample1"") ? 1.0f : 2.0f; });; /// ~~~; // clang-format on; // TODO we could SFINAE on F's signature to provide friendlier compilation errors in case of signature mismatch",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx:1357,multi-thread,multi-thread,1357,tree/dataframe/inc/ROOT/RDF/RInterface.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx,1,['multi-thread'],['multi-thread']
Performance,"// clang-format off; ////////////////////////////////////////////////////////////////////////////; /// \brief Execute a user-defined function on each entry (*instant action*).; /// \param[in] f Function, lambda expression, functor class or any other callable object performing user defined calculations.; /// \param[in] columns Names of the columns/branches in input to the user function.; ///; /// The callable `f` is invoked once per entry. This is an *instant action*:; /// upon invocation, an event loop as well as execution of all scheduled actions; /// is triggered.; /// Users are responsible for the thread-safety of this callable when executing; /// with implicit multi-threading enabled (i.e. ROOT::EnableImplicitMT).; ///; /// ### Example usage:; /// ~~~{.cpp}; /// myDf.Foreach([](int i){ std::cout << i << std::endl;}, {""myIntColumn""});; /// ~~~; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx:266,perform,performing,266,tree/dataframe/inc/ROOT/RDF/RInterface.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx,2,"['multi-thread', 'perform']","['multi-threading', 'performing']"
Performance,"// clang-format off; ////////////////////////////////////////////////////////////////////////////; /// \brief Execute a user-defined function requiring a processing slot index on each entry (*instant action*).; /// \param[in] f Function, lambda expression, functor class or any other callable object performing user defined calculations.; /// \param[in] columns Names of the columns/branches in input to the user function.; ///; /// Same as `Foreach`, but the user-defined function takes an extra; /// `unsigned int` as its first parameter, the *processing slot index*.; /// This *slot index* will be assigned a different value, `0` to `poolSize - 1`,; /// for each thread of execution.; /// This is meant as a helper in writing thread-safe `Foreach`; /// actions when using `RDataFrame` after `ROOT::EnableImplicitMT()`.; /// The user-defined processing callable is able to follow different; /// *streams of processing* indexed by the first parameter.; /// `ForeachSlot` works just as well with single-thread execution: in that; /// case `slot` will always be `0`.; ///; /// ### Example usage:; /// ~~~{.cpp}; /// myDf.ForeachSlot([](unsigned int s, int i){ std::cout << ""Slot "" << s << "": ""<< i << std::endl;}, {""myIntColumn""});; /// ~~~; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx:300,perform,performing,300,tree/dataframe/inc/ROOT/RDF/RInterface.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx,1,['perform'],['performing']
Performance,"// clang-format off; ////////////////////////////////////////////////////////////////////////////; /// \brief Execute a user-defined reduce operation on the values of a column.; /// \tparam F The type of the reduce callable. Automatically deduced.; /// \tparam T The type of the column to apply the reduction to. Automatically deduced.; /// \param[in] f A callable with signature `T(T,T)`; /// \param[in] columnName The column to be reduced. If omitted, the first default column is used instead.; /// \return the reduced quantity wrapped in a ROOT::RDF:RResultPtr.; ///; /// A reduction takes two values of a column and merges them into one (e.g.; /// by summing them, taking the maximum, etc). This action performs the; /// specified reduction operation on all processed column values, returning; /// a single value of the same type. The callable f must satisfy the general; /// requirements of a *processing function* besides having signature `T(T,T)`; /// where `T` is the type of column columnName.; ///; /// The returned reduced value of each thread (e.g. the initial value of a sum) is initialized to a; /// default-constructed T object. This is commonly expected to be the neutral/identity element for the specific; /// reduction operation `f` (e.g. 0 for a sum, 1 for a product). If a default-constructed T does not satisfy this; /// requirement, users should explicitly specify an initialization value for T by calling the appropriate `Reduce`; /// overload.; ///; /// ### Example usage:; /// ~~~{.cpp}; /// auto sumOfIntCol = d.Reduce([](int x, int y) { return x + y; }, ""intCol"");; /// ~~~; ///; /// This action is *lazy*: upon invocation of this method the calculation is; /// booked but not executed. Also see RResultPtr.; // clang-format on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx:707,perform,performs,707,tree/dataframe/inc/ROOT/RDF/RInterface.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx,1,['perform'],['performs']
Performance,"// clang-format on; // clang-format off; ////////////////////////////////////////////////////////////////////////////; /// \brief Define a new column with a value dependent on the processing slot and the current entry.; /// \param[in] name The name of the defined column.; /// \param[in] expression Function, lambda expression, functor class or any other callable object producing the defined value. Returns the value that will be assigned to the defined column.; /// \param[in] columns Names of the columns/branches in input to the producer function (excluding slot and entry).; /// \return the first node of the computation graph for which the new quantity is defined.; ///; /// This alternative implementation of `Define` is meant as a helper in writing entry-specific, thread-safe custom; /// columns. The expression must be a callable of signature R(unsigned int, ULong64_t, T1, T2, ...) where `T1, T2...`; /// are the types of the columns that the expression takes as input. The first parameter is reserved for an unsigned; /// integer representing a ""slot number"". RDataFrame guarantees that different threads will invoke the expression with; /// different slot numbers - slot numbers will range from zero to ROOT::GetThreadPoolSize()-1. The second parameter; /// is reserved for a `ULong64_t` representing the current entry being processed by the current thread.; ///; /// The following two `Define`s are equivalent, although `DefineSlotEntry` is slightly more performant:; /// ~~~{.cpp}; /// int function(unsigned int, ULong64_t, double, double);; /// Define(""x"", function, {""rdfslot_"", ""rdfentry_"", ""column1"", ""column2""}); /// DefineSlotEntry(""x"", function, {""column1"", ""column2""}); /// ~~~; ///; /// See Define() for more information.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx:1469,perform,performant,1469,tree/dataframe/inc/ROOT/RDF/RInterface.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx,1,['perform'],['performant']
Performance,"// clang-format on; // clang-format off; ////////////////////////////////////////////////////////////////////////////; /// \brief Define a new column with a value dependent on the processing slot.; /// \param[in] name The name of the defined column.; /// \param[in] expression Function, lambda expression, functor class or any other callable object producing the defined value. Returns the value that will be assigned to the defined column.; /// \param[in] columns Names of the columns/branches in input to the producer function (excluding the slot number).; /// \return the first node of the computation graph for which the new quantity is defined.; ///; /// This alternative implementation of `Define` is meant as a helper to evaluate new column values in a thread-safe manner.; /// The expression must be a callable of signature R(unsigned int, T1, T2, ...) where `T1, T2...` are the types; /// of the columns that the expression takes as input. The first parameter is reserved for an unsigned integer; /// representing a ""slot number"". RDataFrame guarantees that different threads will invoke the expression with; /// different slot numbers - slot numbers will range from zero to ROOT::GetThreadPoolSize()-1.; ///; /// The following two calls are equivalent, although `DefineSlot` is slightly more performant:; /// ~~~{.cpp}; /// int function(unsigned int, double, double);; /// df.Define(""x"", function, {""rdfslot_"", ""column1"", ""column2""}); /// df.DefineSlot(""x"", function, {""column1"", ""column2""}); /// ~~~; ///; /// See Define() for more information.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx:1302,perform,performant,1302,tree/dataframe/inc/ROOT/RDF/RInterface.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx,1,['perform'],['performant']
Performance,"// clang-format on; ////////////////////////////////////////////////////////////////////////////; /// \brief Save selected columns in memory.; /// \tparam ColumnTypes variadic list of branch/column types.; /// \param[in] columnList columns to be cached in memory.; /// \return a `RDataFrame` that wraps the cached dataset.; ///; /// This action returns a new `RDataFrame` object, completely detached from; /// the originating `RDataFrame`. The new dataframe only contains the cached; /// columns and stores their content in memory for fast, zero-copy subsequent access.; ///; /// Use `Cache` if you know you will only need a subset of the (`Filter`ed) data that; /// fits in memory and that will be accessed many times.; ///; /// \note Cache will refuse to process columns with names of the form `#columnname`. These are special columns; /// made available by some data sources (e.g. RNTupleDS) that represent the size of column `columnname`, and are; /// not meant to be written out with that name (which is not a valid C++ variable name). Instead, go through an; /// Alias(): `df.Alias(""nbar"", ""#bar"").Cache<std::size_t>(..., {""nbar""})`.; ///; /// ### Example usage:; ///; /// **Types and columns specified:**; /// ~~~{.cpp}; /// auto cache_some_cols_df = df.Cache<double, MyClass, int>({""col0"", ""col1"", ""col2""});; /// ~~~; ///; /// **Types inferred and columns specified (this invocation relies on jitting):**; /// ~~~{.cpp}; /// auto cache_some_cols_df = df.Cache({""col0"", ""col1"", ""col2""});; /// ~~~; ///; /// **Types inferred and columns selected with a regexp (this invocation relies on jitting):**; /// ~~~{.cpp}; /// auto cache_all_cols_df = df.Cache(myRegexp);; /// ~~~",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx:246,cache,cached,246,tree/dataframe/inc/ROOT/RDF/RInterface.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RInterface.hxx,9,"['Cache', 'cache']","['Cache', 'cached']"
Performance,"// clang.arc.attachedcall bundles are now required to have an operand.; // If they don't, it's okay to drop them entirely: when there is an operand,; // the ""attachedcall"" is meaningful and required, but without an operand,; // it's just a marker NOP. Dropping it merely prevents an optimization.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/AutoUpgrade.cpp:283,optimiz,optimization,283,interpreter/llvm-project/llvm/lib/IR/AutoUpgrade.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/AutoUpgrade.cpp,1,['optimiz'],['optimization']
Performance,// class BasePainter; /** @summary Load and initialize JSDOM from nodes; * @return {Promise} with d3 selection for d3_body; * @private */,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:35,Load,Load,35,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['Load'],['Load']
Performance,"// class for visibility, activity and optimization attributes for volumes/nodes",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoAtt.h:38,optimiz,optimization,38,geom/geom/inc/TGeoAtt.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoAtt.h,1,['optimiz'],['optimization']
Performance,"// class to load RooFitMore library",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitmore/inc/RooFitMoreLib.h:12,load,load,12,roofit/roofitmore/inc/RooFitMoreLib.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitmore/inc/RooFitMoreLib.h,1,['load'],['load']
Performance,"// class to load basic configuration for all classification tests,; // like environment variables and data in the DataLoader.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/test/envelope/testClassification.cxx:12,load,load,12,tmva/tmva/test/envelope/testClassification.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/test/envelope/testClassification.cxx,1,['load'],['load']
Performance,"// clear all caches",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/jsoninterface/src/RYMLParser.cxx:13,cache,caches,13,roofit/jsoninterface/src/RYMLParser.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/jsoninterface/src/RYMLParser.cxx,1,['cache'],['caches']
Performance,"// clear dirty flag as cache is up-to-date upon creation; // Introduce formal dependency of RooHistFunc on parameters so that const optimization code; // makes the correct decisions",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsCachedReal.cxx:23,cache,cache,23,roofit/roofitcore/src/RooAbsCachedReal.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsCachedReal.cxx,2,"['cache', 'optimiz']","['cache', 'optimization']"
Performance,"// clear dirty flag as cache is up-to-date upon creation; // Introduce formal dependency of RooHistPdf on parameters so that const optimization code; // makes the correct decisions",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsCachedPdf.cxx:23,cache,cache,23,roofit/roofitcore/src/RooAbsCachedPdf.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsCachedPdf.cxx,2,"['cache', 'optimiz']","['cache', 'optimization']"
Performance,"// clear now to avoid concurrent destruction of output trees and input tree (which has them listed as fClones)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx:22,concurren,concurrent,22,tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx,1,['concurren'],['concurrent']
Performance,"// clear old cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/src/TEveCalo.cxx:13,cache,cache,13,graf3d/eve/src/TEveCalo.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/src/TEveCalo.cxx,4,['cache'],['cache']
Performance,// closures have awful performance,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:23,perform,performance,23,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['perform'],['performance']
Performance,"// cmpxchg conceptually includes both a load and store from the same; // location. So, like store, the value being stored is what matters.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/StackProtector.cpp:40,load,load,40,interpreter/llvm-project/llvm/lib/CodeGen/StackProtector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/StackProtector.cpp,1,['load'],['load']
Performance,"// cmpxchg conceptually includes both a load and store from; // the same location.; // As with a store, the location being accessed is not captured,; // but the value being stored is.; // Volatile stores make the address observable.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CaptureTracking.cpp:40,load,load,40,interpreter/llvm-project/llvm/lib/Analysis/CaptureTracking.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CaptureTracking.cpp,1,['load'],['load']
Performance,// combined matrix cache,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:19,cache,cache,19,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['cache'],['cache']
Performance,"// comment out this line and recompile if you want to gain additional; // performance (the gain is mainly for ""simple"" functions which are easy; // to calculate and vanishes quickly if going to cost-intensive functions); // the library is no longer thread save however",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/inc/Minuit2/StackAllocator.h:74,perform,performance,74,math/minuit2/inc/Minuit2/StackAllocator.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/inc/Minuit2/StackAllocator.h,1,['perform'],['performance']
Performance,// compare current value with cached entry,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:30,cache,cached,30,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['cache'],['cached']
Performance,// complete JSROOT TGeo functionality is loaded,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/ui5/geom/controller/GeomViewer.controller.js:41,load,loaded,41,ui5/geom/controller/GeomViewer.controller.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/ui5/geom/controller/GeomViewer.controller.js,1,['load'],['loaded']
Performance,"// complete type for JobManager::queue()",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/JobManager.cxx:33,queue,queue,33,roofit/multiprocess/src/JobManager.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/JobManager.cxx,3,['queue'],['queue']
Performance,"// compute numerical throughput",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/test/DNN/TestOptimization.h:21,throughput,throughput,21,tmva/tmva/test/DNN/TestOptimization.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/test/DNN/TestOptimization.h,1,['throughput'],['throughput']
Performance,"// compute the empirical CDF and cache in a vector",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/SamplingDistribution.cxx:33,cache,cache,33,roofit/roostats/src/SamplingDistribution.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/SamplingDistribution.cxx,1,['cache'],['cache']
Performance,"// compute the gradients; // Perform the operation in place by readding the result on the same gradient matrix; // e.g. W += D * X; // Weights gradients",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/DNN/Architectures/Cpu/RecurrentPropagation.hxx:29,Perform,Perform,29,tmva/tmva/src/DNN/Architectures/Cpu/RecurrentPropagation.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/DNN/Architectures/Cpu/RecurrentPropagation.hxx,1,['Perform'],['Perform']
Performance,// computeKnownBits not yet implemented for scalable vectors.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp:44,scalab,scalable,44,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp,1,['scalab'],['scalable']
Performance,"// console.log( 'THREE.Cache', 'Adding key:', key );",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:23,Cache,Cache,23,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['Cache'],['Cache']
Performance,"// console.log( 'THREE.Cache', 'Checking key:', key );",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:23,Cache,Cache,23,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['Cache'],['Cache']
Performance,"// const AFloat alpha = 1,; // const AFloat beta = 1);; /** @name Backward Propagation in Convolutional Layer; */; ///@{; /** Perform the complete backward propagation step in a Convolutional Layer.; * If the provided \p activationGradientsBackward matrix is not empty, compute the; * gradients of the objective function with respect to the activations; * of the previous layer (backward direction).; * Also compute the weight and the bias gradients. Modifies the values; * in \p df and thus produces only a valid result, if it is applied the; * first time after the corresponding forward propagation has been per-; * formed. */",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/DNN/Architectures/TCudnn.h:126,Perform,Perform,126,tmva/tmva/inc/TMVA/DNN/Architectures/TCudnn.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/DNN/Architectures/TCudnn.h,1,['Perform'],['Perform']
Performance,"// constant term optimization",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooAbsArg.h:17,optimiz,optimization,17,roofit/roofitcore/inc/RooAbsArg.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooAbsArg.h,1,['optimiz'],['optimization']
Performance,// constpool + load + tbl,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp:15,load,load,15,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,4,['load'],['load']
Performance,// constpool + load + tbl; // Reverse can be lowered with `rev`.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp:15,load,load,15,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,1,['load'],['load']
Performance,"// constructor inclusion; // convenience method to quickly clear/reset the queue (instead of having to pop one by one)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx:75,queue,queue,75,geom/geom/src/TGeoParallelWorld.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx,1,['queue'],['queue']
Performance,// continue if the operand is not a load instruction,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:36,load,load,36,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,"// control synchronization of cache and packet sizes",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/inc/TPacketizerAdaptive.h:30,cache,cache,30,proof/proofplayer/inc/TPacketizerAdaptive.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/inc/TPacketizerAdaptive.h,1,['cache'],['cache']
Performance,"// copy file to cache if not a PAR file",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProofServ.cxx:16,cache,cache,16,proof/proof/src/TProofServ.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProofServ.cxx,1,['cache'],['cache']
Performance,"// could delete the file selname+"".h""; // However this would remove the optimization of avoiding a useless; // recompilation if the user ask for the same thing twice!",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/src/TTreePlayer.cxx:72,optimiz,optimization,72,tree/treeplayer/src/TTreePlayer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/src/TTreePlayer.cxx,1,['optimiz'],['optimization']
Performance,"// cout << ""RRI::ctor("" << GetName() << "") setting expensive object cache to "" << &expensiveObjectCache() << "" as taken from "" << function.GetName() << std::endl ;; // Use objects integrator configuration if none is specified",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooRealIntegral.cxx:68,cache,cache,68,roofit/roofitcore/src/RooRealIntegral.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooRealIntegral.cxx,1,['cache'],['cache']
Performance,"// cout << ""RooAbsOptTestStatistic::optimizeCaching("" << GetName() << "","" << this << "")"" << endl ;; // Trigger create of all object caches now in nodes that have deferred object creation; // so that cache contents can be processed immediately",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsOptTestStatistic.cxx:36,optimiz,optimizeCaching,36,roofit/roofitcore/src/RooAbsOptTestStatistic.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsOptTestStatistic.cxx,3,"['cache', 'optimiz']","['cache', 'caches', 'optimizeCaching']"
Performance,"// cout << ""RooFactoryWSTool::process() "" << expr << endl ;; // First perform basic syntax check",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooFactoryWSTool.cxx:70,perform,perform,70,roofit/roofitcore/src/RooFactoryWSTool.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooFactoryWSTool.cxx,1,['perform'],['perform']
Performance,"// cout << ""RooRealMPFE::calculate("" << GetName() << "") performing Inline calculation NOW"" << endl ;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooRealMPFE.cxx:56,perform,performing,56,roofit/roofitcore/src/RooRealMPFE.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooRealMPFE.cxx,1,['perform'],['performing']
Performance,"// cout << ""RooVectorDataStore::cacheArgs() cached node "" << arg->GetName() << "" has a conditional observable set specification CATCondSet = "" << catCset << endl ;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooVectorDataStore.cxx:32,cache,cacheArgs,32,roofit/roofitcore/src/RooVectorDataStore.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooVectorDataStore.cxx,2,['cache'],"['cacheArgs', 'cached']"
Performance,"// cout << ""RooVectorDataStore::cacheArgs() cached node "" << arg->GetName() << "" has a normalization set specification CATNormSet = "" << catNset << endl ;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooVectorDataStore.cxx:32,cache,cacheArgs,32,roofit/roofitcore/src/RooVectorDataStore.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooVectorDataStore.cxx,2,['cache'],"['cacheArgs', 'cached']"
Performance,"// cout << ""using cached value of integral"" << GetName() << std::endl ;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooRealIntegral.cxx:18,cache,cached,18,roofit/roofitcore/src/RooRealIntegral.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooRealIntegral.cxx,1,['cache'],['cached']
Performance,"// cpu load average over 1 m",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h:7,load,load,7,core/base/inc/TSystem.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h,2,['load'],['load']
Performance,"// cpu load average over 15 m",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h:7,load,load,7,core/base/inc/TSystem.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h,2,['load'],['load']
Performance,"// cpu load average over 5 m",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h:7,load,load,7,core/base/inc/TSystem.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h,2,['load'],['load']
Performance,"// cpu sys load in percentage",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h:11,load,load,11,core/base/inc/TSystem.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h,2,['load'],['load']
Performance,"// cpu user load in percentage",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h:12,load,load,12,core/base/inc/TSystem.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h,2,['load'],['load']
Performance,"// cpu user+sys load in percentage",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h:16,load,load,16,core/base/inc/TSystem.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h,2,['load'],['load']
Performance,"// create a new dataset to cache trial events and function values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsNumGenerator.cxx:27,cache,cache,27,roofit/roofitcore/src/RooAbsNumGenerator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsNumGenerator.cxx,1,['cache'],['cache']
Performance,"// create a weight tensor/matrix from another tensor using its shape; // static Matrix_t CreateWeightTensor( Matrix_t & A) {; // return Matrix_t( A.GetNrows(), A.GetNcols());; // }; // create a weight tensor/matrix vector from another tensor/weight vector using the given tensor shapes; // this function is used by the optimizers to store intermediate weights representations",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/DNN/Architectures/Cuda.h:319,optimiz,optimizers,319,tmva/tmva/inc/TMVA/DNN/Architectures/Cuda.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/DNN/Architectures/Cuda.h,1,['optimiz'],['optimizers']
Performance,"// create a weight tensor/matrix vector from another tensor/weight vector using the given tensor shapes; // this function is used by the optimizers to store intermediate weights representations",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/DNN/Architectures/Cpu.h:137,optimiz,optimizers,137,tmva/tmva/inc/TMVA/DNN/Architectures/Cpu.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/DNN/Architectures/Cpu.h,2,['optimiz'],['optimizers']
Performance,"// create cache if wanted",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx:10,cache,cache,10,tree/tree/src/TTree.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx,6,['cache'],['cache']
Performance,"// create class in namespace, if it exists (no load, silent)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/TPyClassGenerator.cxx:47,load,load,47,bindings/pyroot/cppyy/CPyCppyy/src/TPyClassGenerator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/TPyClassGenerator.cxx,2,['load'],['load']
Performance,"// create entry in settings for this optimizer parameter",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodDL.cxx:37,optimiz,optimizer,37,tmva/tmva/src/MethodDL.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodDL.cxx,1,['optimiz'],['optimizer']
Performance,"// create huffman tree from u8 ""map"": index -> code length for code index; // mb (max bits) must be at most 15; // TODO: optimize/split up?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:121,optimiz,optimize,121,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['optimiz'],['optimize']
Performance,"// create parameter points to perform construction (private data member fPointsToTest)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/FeldmanCousins.cxx:30,perform,perform,30,roofit/roostats/src/FeldmanCousins.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/FeldmanCousins.cxx,1,['perform'],['perform']
Performance,"// create timer to process Qt events from inside ROOT process events; // very much improve performance, even when Qt even loop runs by QApplication normally",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/qt6webdisplay/rootqt6.cpp:91,perform,performance,91,gui/qt6webdisplay/rootqt6.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/qt6webdisplay/rootqt6.cpp,1,['perform'],['performance']
Performance,"// create timer to process Qt events from inside ROOT process events; // very much improve performance, even when Qt event loop runs by QApplication normally",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/qt5webdisplay/rootqt5.cpp:91,perform,performance,91,gui/qt5webdisplay/rootqt5.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/qt5webdisplay/rootqt5.cpp,1,['perform'],['performance']
Performance,// createLanaiMemAluCombinerPass - This pass combines loads/stores and; // arithmetic operations.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Lanai/Lanai.h:54,load,loads,54,interpreter/llvm-project/llvm/lib/Target/Lanai/Lanai.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Lanai/Lanai.h,1,['load'],['loads']
Performance,"// creating loader for sub-seed",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Factory.cxx:12,load,loader,12,tmva/tmva/src/Factory.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Factory.cxx,2,['load'],['loader']
Performance,"// data cell ids cache state",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/inc/TEveCalo.h:17,cache,cache,17,graf3d/eve/inc/TEveCalo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/inc/TEveCalo.h,2,['cache'],['cache']
Performance,"// data loader need at least one variable; // creating loader for seed",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Factory.cxx:8,load,loader,8,tmva/tmva/src/Factory.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Factory.cxx,6,['load'],['loader']
Performance,"// data member cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPInstance.h:15,cache,cache,15,bindings/pyroot/cppyy/CPyCppyy/src/CPPInstance.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPInstance.h,1,['cache'],['cache']
Performance,"// dataloader need at least one variable; // creating loader for seed",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/VariableImportance.cxx:54,load,loader,54,tmva/tmva/src/VariableImportance.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/VariableImportance.cxx,3,['load'],['loader']
Performance,"// debatable, but since the iterator is cached, this",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/TupleOfInstances.cxx:40,cache,cached,40,bindings/pyroot/cppyy/CPyCppyy/src/TupleOfInstances.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/TupleOfInstances.cxx,1,['cache'],['cached']
Performance,"// default behavior: type + held pointer value defines identity; if both are; // CPPInstance objects, perform an additional autocast if need be",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPInstance.cxx:102,perform,perform,102,bindings/pyroot/cppyy/CPyCppyy/src/CPPInstance.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPInstance.cxx,1,['perform'],['perform']
Performance,"// default cache subdirectory",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/inc/TDataSetManagerFile.h:11,cache,cache,11,proof/proof/inc/TDataSetManagerFile.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/inc/TDataSetManagerFile.h,1,['cache'],['cache']
Performance,// define a lambda expression to load value,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/GISel/PPCCallLowering.cpp:33,load,load,33,interpreter/llvm-project/llvm/lib/Target/PowerPC/GISel/PPCCallLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/GISel/PPCCallLowering.cpp,1,['load'],['load']
Performance,"// define the array to load the data with the CFITSIO functions; // a fixed arrays is needed as argument to the fits_read_col function; // so a vector is defined and then its `.data()` pointer is passed; // to fits_read_col; //; // TODO: add all type cases, for now only short, long, float and double are considered; //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/fitsio/src/TFITS.cxx:23,load,load,23,graf2d/fitsio/src/TFITS.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/fitsio/src/TFITS.cxx,1,['load'],['load']
Performance,// defined(__OPENCL_CPP_VERSION__) || (__OPENCL_C_VERSION__ >= CL_VERSION_1_2); /**; * Multiply two 24-bit integer values x and y and add; * the 32-bit integer result to the 32-bit integer z.; * Refer to definition of mul24 to see how the 24-bit; * integer multiplication is performed.; */,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/opencl-c.h:275,perform,performed,275,interpreter/llvm-project/clang/lib/Headers/opencl-c.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/opencl-c.h,1,['perform'],['performed']
Performance,"// defines (the ellipse semi-axis in Y)/(the ellipse semi-axis in X); // Internal cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/g3d/inc/TTUBE.h:82,cache,cache,82,graf3d/g3d/inc/TTUBE.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/g3d/inc/TTUBE.h,1,['cache'],['cache']
Performance,"// delete cachedFit;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx:10,cache,cachedFit,10,roofit/xroofit/src/xRooFit.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx,1,['cache'],['cachedFit']
Performance,"// delete existing cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx:19,cache,cache,19,tree/tree/src/TTree.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx,1,['cache'],['cache']
Performance,"// descriptorGuard; // Clear the cache from clusters not the in the look-ahead or the look-back window",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RClusterPool.cxx:33,cache,cache,33,tree/ntuple/v7/src/RClusterPool.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RClusterPool.cxx,1,['cache'],['cache']
Performance,"// destructor. clears the cache.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/jsoninterface/src/RYMLParser.cxx:26,cache,cache,26,roofit/jsoninterface/src/RYMLParser.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/jsoninterface/src/RYMLParser.cxx,1,['cache'],['cache']
Performance,// determine if we should load from reg_save_area or overflow_area,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:26,load,load,26,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['load']
Performance,"// disable cache to avoid infinite recursion",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFileCacheRead.cxx:11,cache,cache,11,io/io/src/TFileCacheRead.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFileCacheRead.cxx,1,['cache'],['cache']
Performance,"// disable const optimization; // warning - if the nll was previously activated then it seems like deactivating may break it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx:17,optimiz,optimization,17,roofit/xroofit/src/xRooFit.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx,1,['optimiz'],['optimization']
Performance,"// disable const-optimization at the construction step ... can happen in the minimization though",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx:17,optimiz,optimization,17,roofit/xroofit/src/xRooFit.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx,1,['optimiz'],['optimization']
Performance,"// disable eager execution (model will evaluate > 100 faster); // need to be done before loading the model",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/pymva/src/MethodPyKeras.cxx:89,load,loading,89,tmva/pymva/src/MethodPyKeras.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/pymva/src/MethodPyKeras.cxx,1,['load'],['loading']
Performance,"// disable the cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/inc/TDataSetManager.h:15,cache,cache,15,proof/proof/inc/TDataSetManager.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/inc/TDataSetManager.h,1,['cache'],['cache']
Performance,"// disable the cluster cache so we can catch the exception that happens on LoadEntry",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/test/ntuple_compat.cxx:23,cache,cache,23,tree/ntuple/v7/test/ntuple_compat.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/test/ntuple_compat.cxx,2,"['Load', 'cache']","['LoadEntry', 'cache']"
Performance,"// do not cache parameter values (it is not thread safe); //func.SetParameters(p);; // get fit option and check case if using integral of bins",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Fit/FitUtil.h:10,cache,cache,10,math/mathcore/inc/Fit/FitUtil.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Fit/FitUtil.h,2,['cache'],['cache']
Performance,// do not reorder memory load/stores by default load/stores are re-ordered; // and by default loads can be re-ordered,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/MCTargetDesc/HexagonMCInstrInfo.h:25,load,load,25,interpreter/llvm-project/llvm/lib/Target/Hexagon/MCTargetDesc/HexagonMCInstrInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/MCTargetDesc/HexagonMCInstrInfo.h,3,['load'],"['load', 'loads']"
Performance,// do not try color draw optimization as with plain th2 while; // bins are not rectangular and drawings artifacts are nasty; // therefore draw each bin separately when doing color draw,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:25,optimiz,optimization,25,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['optimiz'],['optimization']
Performance,"// do this so profile will cache inside the absolute minimum and; // minimum values of nuisance parameters; // (no need to this here); // profile->getVal();; //RooMsgService::instance().setGlobalKillBelow(RooFit::DEBUG) ;; // profile->Print();",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/ProfileLikelihoodCalculator.cxx:27,cache,cache,27,roofit/roostats/src/ProfileLikelihoodCalculator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/ProfileLikelihoodCalculator.cxx,1,['cache'],['cache']
Performance,"// doBidiReorder( text, sourceToTargetMap, levels ); // Performs Bidi reordering by implementing Unicode Bidi algorithm.; // Returns reordered string; // @text [String]:; // - input string to be reordered, this is input parameter; // $sourceToTargetMap [Array] (optional); // - resultant mapping between input and output strings, this is output parameter; // $levels [Array] (optional); // - array of calculated Bidi levels, , this is output parameter",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:56,Perform,Performs,56,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['Perform'],['Performs']
Performance,// dominates - Return true if A dominates B. This performs the; // special checks necessary if A and B are in the same basic block.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineDominators.h:50,perform,performs,50,interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineDominators.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/MachineDominators.h,1,['perform'],['performs']
Performance,// dominates - Return true if Def dominates a use in User. This performs; // the special checks necessary if Def and User are in the same basic block.; // Note that Def doesn't dominate a use in Def itself!,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/Dominators.cpp:64,perform,performs,64,interpreter/llvm-project/llvm/lib/IR/Dominators.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/Dominators.cpp,1,['perform'],['performs']
Performance,"// don't load it or any of its dependencies",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx:9,load,load,9,core/base/src/TSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx,1,['load'],['load']
Performance,"// don't load libraries that have already been loaded",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx:9,load,load,9,core/base/src/TSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx,2,['load'],"['load', 'loaded']"
Performance,"// don't use cache as user can call chdir() directly somewhere else; //if (fWdpath != """" ); // return fWdpath;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/winnt/src/TWinNTSystem.cxx:13,cache,cache,13,core/winnt/src/TWinNTSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/winnt/src/TWinNTSystem.cxx,1,['cache'],['cache']
Performance,"// don't use cache as user can call chdir() directly somewhere else; //if (fWdpath != """"); // return fWdpath.Data();",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/unix/src/TUnixSystem.cxx:13,cache,cache,13,core/unix/src/TUnixSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/unix/src/TUnixSystem.cxx,1,['cache'],['cache']
Performance,"// done if cache is already setup",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.cxx:11,cache,cache,11,bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.cxx,1,['cache'],['cache']
Performance,"// downcast to real class for object returns, unless pinned; // TODO: should the memory regulator for klass be searched first, so that if; // successful, no down-casting is attempted?; // TODO: optimize for final classes",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/ProxyWrappers.cxx:194,optimiz,optimize,194,bindings/pyroot/cppyy/CPyCppyy/src/ProxyWrappers.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/ProxyWrappers.cxx,1,['optimiz'],['optimize']
Performance,"// dummy method called to force auto-loading of MathMore Library; //; // note: a typedef MathMoreLIb to MathMoreLibrary has been introduced because for unknown reasons; // loading on the MathMoreLibrary does not work while it works for the class name MathMoreLib; // see ROOT-8455",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/src/PdfFuncMathMore.cxx:37,load,loading,37,math/mathmore/src/PdfFuncMathMore.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/src/PdfFuncMathMore.cxx,2,['load'],['loading']
Performance,"// duplicate function here, used before loading any other functionality",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/scripts/JSRoot.core.js:40,load,loading,40,js/scripts/JSRoot.core.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/scripts/JSRoot.core.js,1,['load'],['loading']
Performance,"// eliminate loads, when all loads eliminated, eliminate all stores.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonFrameLowering.cpp:13,load,loads,13,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonFrameLowering.cpp,2,['load'],['loads']
Performance,// else: keep current OtherAccess since it lies between U and Load,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp:62,Load,Load,62,interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,1,['Load'],['Load']
Performance,"// emitCmdValueForGetterSetterBody - Handle emitting the load necessary for; // the `_cmd` selector argument for getter/setter bodies. For direct methods,; // this returns an undefined/poison value; this matches behavior prior to `_cmd`; // being removed from the direct method ABI as the getter/setter caller would; // never load one. For non-direct methods, this emits a load of the implicit; // `_cmd` storage.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp:57,load,load,57,interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjC.cpp,3,['load'],['load']
Performance,// emitFieldFromInstruction - Emit the templated helper function; // fieldFromInstruction().; // On Windows we make sure that this function is not inlined when; // using the VS compiler. It has a bug which causes the function; // to be optimized out in some circumstances. See llvm.org/pr38292,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/DecoderEmitter.cpp:236,optimiz,optimized,236,interpreter/llvm-project/llvm/utils/TableGen/DecoderEmitter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/DecoderEmitter.cpp,1,['optimiz'],['optimized']
Performance,"// enable draw optimization, reduced data set will be send to clients",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/rcanvas/rh1_large.cxx:15,optimiz,optimization,15,tutorials/rcanvas/rh1_large.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/rcanvas/rh1_large.cxx,2,['optimiz'],['optimization']
Performance,"// enable draw optimization, reduced data set will be send to clients; // auto stat = canvas->Draw<RHist2StatBox>(pHist, ""hist"");; // stat->fill.color = RColor::kBlue;; // stat->fill.style = RAttrFill::kSolid;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/rcanvas/rh3_large.cxx:15,optimiz,optimization,15,tutorials/rcanvas/rh3_large.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/rcanvas/rh3_large.cxx,1,['optimiz'],['optimization']
Performance,"// enabling optimization (at least -O2) automatically unrolls the for-loop",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/builtins/zlib/deflate_cf.c:12,optimiz,optimization,12,builtins/zlib/deflate_cf.c,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/builtins/zlib/deflate_cf.c,1,['optimiz'],['optimization']
Performance,"// enabling optimization (at least -O2) automatically unrolls the inner for-loop",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/builtins/zlib/deflate_cf.c:12,optimiz,optimization,12,builtins/zlib/deflate_cf.c,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/builtins/zlib/deflate_cf.c,2,['optimiz'],['optimization']
Performance,"// end anonymous namespace.; //===----------------------------------------------------------------------===//; // Utilities; //===----------------------------------------------------------------------===//; /// EmitAggLoadOfLValue - Given an expression with aggregate type that; /// represents a value lvalue, this method emits the address of the lvalue,; /// then loads the result into DestPtr.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExprAgg.cpp:365,load,loads,365,interpreter/llvm-project/clang/lib/CodeGen/CGExprAgg.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExprAgg.cpp,1,['load'],['loads']
Performance,// end anonymous namespace; // Generates instructions to load an immediate value into a register.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/Mips/Target.cpp:57,load,load,57,interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/Mips/Target.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/Mips/Target.cpp,1,['load'],['load']
Performance,// end anonymous namespace; // Perform the transformation to calls with errno set by domain error.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LibCallsShrinkWrap.cpp:31,Perform,Perform,31,interpreter/llvm-project/llvm/lib/Transforms/Utils/LibCallsShrinkWrap.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LibCallsShrinkWrap.cpp,1,['Perform'],['Perform']
Performance,"// end anonymous namespace; // Try to optimize (i64 (and (zext/sext (i32 X), C1))) if C1 has bit 31 set,; // but bits 63:32 are zero. If we know that bit 31 of X is 0, we can fill; // the upper 32 bits with ones.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVCodeGenPrepare.cpp:38,optimiz,optimize,38,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVCodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVCodeGenPrepare.cpp,1,['optimiz'],['optimize']
Performance,"// end anonymous namespace; /// Cast a given SVal to another SVal using given QualType's.; /// \param V -- SVal that should be casted.; /// \param CastTy -- QualType that V should be casted according to.; /// \param OriginalTy -- QualType which is associated to V. It provides; /// additional information about what type the cast performs from.; /// \returns the most appropriate casted SVal.; /// Note: Many cases don't use an exact OriginalTy. It can be extracted; /// from SVal or the cast can performs unconditionaly. Always pass OriginalTy!; /// It can be crucial in certain cases and generates different results.; /// FIXME: If `OriginalTy.isNull()` is true, then cast performs based on CastTy; /// only. This behavior is uncertain and should be improved.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/SValBuilder.cpp:330,perform,performs,330,interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/SValBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/SValBuilder.cpp,3,['perform'],['performs']
Performance,"// end anonymous namespace; /// Check if the store dominates all latches, so as long as there is no; /// intervening store this value will be loaded in the next iteration.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp:142,load,loaded,142,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp,1,['load'],['loaded']
Performance,"// end anonymous namespace; /// Create the fragile-ABI read and write hazards based on the current; /// state of the function, which is presumed to be immediately prior; /// to a @try block. These hazards are used to maintain correct; /// semantics in the face of optimization and the fragile ABI's; /// cavalier use of setjmp/longjmp.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp:264,optimiz,optimization,264,interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp,1,['optimiz'],['optimization']
Performance,"// end anonymous namespace; /// Determine if the memory referenced by LaterInst is from the same heap; /// version as EarlierInst.; /// This is currently called in two scenarios:; ///; /// load p; /// ...; /// load p; ///; /// and; ///; /// x = load p; /// ...; /// store x, p; ///; /// in both cases we want to verify that there are no possible writes to the; /// memory referenced by p between the earlier and later instruction.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp:189,load,load,189,interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,3,['load'],['load']
Performance,"// end anonymous namespace; /// Emit an instruction sequence that will align the address in; /// register Reg by zero-ing out the lower bits. For versions of the; /// architecture that support Neon, this must be done in a single; /// instruction, since skipAlignedDPRCS2Spills assumes it is done in a; /// single instruction. That function only gets called when optimizing; /// spilling of D registers on a core with the Neon instruction set; /// present.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMFrameLowering.cpp:362,optimiz,optimizing,362,interpreter/llvm-project/llvm/lib/Target/ARM/ARMFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMFrameLowering.cpp,1,['optimiz'],['optimizing']
Performance,"// end anonymous namespace; /// Figure out if the loop is worth full unrolling.; ///; /// Complete loop unrolling can make some loads constant, and we need to know; /// if that would expose any further optimization opportunities. This routine; /// estimates this optimization. It computes cost of unrolled loop; /// (UnrolledCost) and dynamic cost of the original loop (RolledDynamicCost). By; /// dynamic cost we mean that we won't count costs of blocks that are known not; /// to be executed (i.e. if we have a branch in the loop and we know that at the; /// given iteration its condition would be resolved to true, we won't add up the; /// cost of the 'false'-block).; /// \returns Optional value, holding the RolledDynamicCost and UnrolledCost. If; /// the analysis failed (no benefits expected from the unrolling, or the loop is; /// too big to analyze), the returned value is std::nullopt.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopUnrollPass.cpp:128,load,loads,128,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopUnrollPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopUnrollPass.cpp,3,"['load', 'optimiz']","['loads', 'optimization']"
Performance,// end anonymous namespace; /// Given a LoadInst LI this adds assume(LI != null) after it.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp:40,Load,LoadInst,40,interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/PromoteMemoryToRegister.cpp,1,['Load'],['LoadInst']
Performance,// end anonymous namespace; /// Iteratively perform simplification on a worklist of IV users. Each; /// successive simplification may push more users which may themselves be; /// candidates for simplification.; ///; /// Sign/Zero extend elimination is interleaved with IV simplification.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/IndVarSimplify.cpp:44,perform,perform,44,interpreter/llvm-project/llvm/lib/Transforms/Scalar/IndVarSimplify.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/IndVarSimplify.cpp,1,['perform'],['perform']
Performance,// end anonymous namespace; /// Perform an increment or decrement on LVal.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ExprConstant.cpp:32,Perform,Perform,32,interpreter/llvm-project/clang/lib/AST/ExprConstant.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ExprConstant.cpp,1,['Perform'],['Perform']
Performance,"// end anonymous namespace; /// Rebuilds a type within the context of the current instantiation.; ///; /// The type \p T is part of the type of an out-of-line member definition of; /// a class template (or class template partial specialization) that was parsed; /// and constructed before we entered the scope of the class template (or; /// partial specialization thereof). This routine will rebuild that type now; /// that we have entered the declarator's scope, which may produce different; /// canonical types, e.g.,; ///; /// \code; /// template<typename T>; /// struct X {; /// typedef T* pointer;; /// pointer data();; /// };; ///; /// template<typename T>; /// typename X<T>::pointer X<T>::data() { ... }; /// \endcode; ///; /// Here, the type ""typename X<T>::pointer"" will be created as a DependentNameType,; /// since we do not know that we can look into X<T> when we parsed the type.; /// This function will rebuild the type, performing the lookup of ""pointer""; /// in X<T> and returning an ElaboratedType whose canonical type is the same; /// as the canonical type of T*, allowing the return types of the out-of-line; /// definition and the declaration to match.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplate.cpp:936,perform,performing,936,interpreter/llvm-project/clang/lib/Sema/SemaTemplate.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplate.cpp,1,['perform'],['performing']
Performance,"// end anonymous namespace; /// Return a vector shuffle operation which; /// performs the same shuffle in terms of order or result bytes, but on a type; /// whose vector element type is narrower than the original shuffle type.; /// e.g. <v4i32> <0, 1, 0, 1> -> v8i16 <0, 1, 2, 3, 0, 1, 2, 3>",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp:77,perform,performs,77,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,1,['perform'],['performs']
Performance,"// end anonymous namespace; /// This is a helper function which builds instructions to provide; /// values necessary for partword atomic operations. It takes an; /// incoming address, Addr, and ValueType, and constructs the address,; /// shift-amounts and masks needed to work with a larger value of size; /// WordSize.; ///; /// AlignedAddr: Addr rounded down to a multiple of WordSize; ///; /// ShiftAmt: Number of bits to right-shift a WordSize value loaded; /// from AlignAddr for it to have the same value as if; /// ValueType was loaded from Addr.; ///; /// Mask: Value to mask with the value loaded from AlignAddr to; /// include only the part that would've been loaded from Addr.; ///; /// Inv_Mask: The inverse of Mask.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp:454,load,loaded,454,interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AtomicExpandPass.cpp,4,['load'],['loaded']
Performance,"// end anonymous namespace; /// Tries to perform unqualified lookup of the type decls in bases for; /// dependent class.; /// \return \a NotFound if no any decls is found, \a FoundNotType if found not a; /// type decl, \a FoundType if only type decls are found.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp:41,perform,perform,41,interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDecl.cpp,1,['perform'],['perform']
Performance,"// end anonymous namespace; /// When generating a defaulted copy or move assignment operator, if a field; /// should be copied with __builtin_memcpy rather than via explicit assignments,; /// do so. This optimization only applies for arrays of scalars, and for arrays; /// of class type where the selected copy/move-assignment operator is trivial.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp:204,optimiz,optimization,204,interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaDeclCXX.cpp,1,['optimiz'],['optimization']
Performance,// end anonymous namespace; ///Perform cse of induction variable instructions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp:31,Perform,Perform,31,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp,1,['Perform'],['Perform']
Performance,"// end namespace ARMCP; /// ARMConstantPoolValue - ARM specific constantpool value. This is used to; /// represent PC-relative displacement between the address of the load; /// instruction and the constant being loaded, i.e. (&GV-(LPIC+8)).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMConstantPoolValue.h:167,load,load,167,interpreter/llvm-project/llvm/lib/Target/ARM/ARMConstantPoolValue.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMConstantPoolValue.h,2,['load'],"['load', 'loaded']"
Performance,// end namespace FileMgr; /// Cached information about one directory (either on disk or in; /// the virtual file system).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Basic/DirectoryEntry.h:30,Cache,Cached,30,interpreter/llvm-project/clang/include/clang/Basic/DirectoryEntry.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Basic/DirectoryEntry.h,1,['Cache'],['Cached']
Performance,"// end namespace ISD; //===----------------------------------------------------------------------===//; /// Unlike LLVM values, Selection DAG nodes may return multiple; /// values as the result of a computation. Many nodes return multiple values,; /// from loads (which define a token and a return value) to ADDC (which returns; /// a result and a carry value), to calls (which may return an arbitrary number; /// of values).; ///; /// As such, each use of a SelectionDAG computation must indicate the node that; /// computes it as well as which return value to use from that node. This pair; /// of information is represented with the SDValue value type.; ///",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/SelectionDAGNodes.h:257,load,loads,257,interpreter/llvm-project/llvm/include/llvm/CodeGen/SelectionDAGNodes.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/SelectionDAGNodes.h,1,['load'],['loads']
Performance,"// end namespace ROOT; // make a fake class to auto-load functions from MathMore",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/inc/Math/PdfFuncMathMore.h:52,load,load,52,math/mathmore/inc/Math/PdfFuncMathMore.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/inc/Math/PdfFuncMathMore.h,1,['load'],['load']
Performance,"// end namespace detail; /// A class that does preorder or postorder; /// depth-first traversal on the entire Clang AST and visits each node.; ///; /// This class performs three distinct tasks:; /// 1. traverse the AST (i.e. go to each node);; /// 2. at a given node, walk up the class hierarchy, starting from; /// the node's dynamic type, until the top-most class (e.g. Stmt,; /// Decl, or Type) is reached.; /// 3. given a (node, class) combination, where 'class' is some base; /// class of the dynamic type of 'node', call a user-overridable; /// function to actually visit the node.; ///; /// These tasks are done by three groups of methods, respectively:; /// 1. TraverseDecl(Decl *x) does task #1. It is the entry point; /// for traversing an AST rooted at x. This method simply; /// dispatches (i.e. forwards) to TraverseFoo(Foo *x) where Foo; /// is the dynamic type of *x, which calls WalkUpFromFoo(x) and; /// then recursively visits the child nodes of x.; /// TraverseStmt(Stmt *x) and TraverseType(QualType x) work; /// similarly.; /// 2. WalkUpFromFoo(Foo *x) does task #2. It does not try to visit; /// any child node of x. Instead, it first calls WalkUpFromBar(x); /// where Bar is the direct parent class of Foo (unless Foo has; /// no parent), and then calls VisitFoo(x) (see the next list item).; /// 3. VisitFoo(Foo *x) does task #3.; ///; /// These three method groups are tiered (Traverse* > WalkUpFrom* >; /// Visit*). A method (e.g. Traverse*) may call methods from the same; /// tier (e.g. other Traverse*) or one tier lower (e.g. WalkUpFrom*).; /// It may not call methods from a higher tier.; ///; /// Note that since WalkUpFromFoo() calls WalkUpFromBar() (where Bar; /// is Foo's super class) before calling VisitFoo(), the result is; /// that the Visit*() methods for a given node are called in the; /// top-down order (e.g. for a node of type NamespaceDecl, the order will; /// be VisitDecl(), VisitNamedDecl(), and then VisitNamespaceDecl()).; ///; /// This scheme guara",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/AST/RecursiveASTVisitor.h:163,perform,performs,163,interpreter/llvm-project/clang/include/clang/AST/RecursiveASTVisitor.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/AST/RecursiveASTVisitor.h,1,['perform'],['performs']
Performance,"// end namespace gvn; /// A set of parameters to control various transforms performed by GVN pass.; // Each of the optional boolean parameters can be set to:; /// true - enabling the transformation.; /// false - disabling the transformation.; /// None - relying on a global default.; /// Intended use is to create a default object, modify parameters with; /// additional setters and then pass it to GVN.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Scalar/GVN.h:76,perform,performed,76,interpreter/llvm-project/llvm/include/llvm/Transforms/Scalar/GVN.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Scalar/GVN.h,1,['perform'],['performed']
Performance,"// end namespace jumpthreading; /// This pass performs 'jump threading', which looks at blocks that have; /// multiple predecessors and multiple successors. If one or more of the; /// predecessors of the block can be proven to always jump to one of the; /// successors, we forward the edge from the predecessor to the successor by; /// duplicating the contents of this block.; ///; /// An example of when this can occur is code like this:; ///; /// if () { ...; /// X = 4;; /// }; /// if (X < 3) {; ///; /// In this case, the unconditional branch at the end of the first if can be; /// revectored to the false side of the second if.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Scalar/JumpThreading.h:46,perform,performs,46,interpreter/llvm-project/llvm/include/llvm/Transforms/Scalar/JumpThreading.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/Scalar/JumpThreading.h,1,['perform'],['performs']
Performance,"// end namespace llvm; // Sorting all the loads/stores first, then for each load/store, checking the; // following load/store one by one, until reach the first non-dependent one and; // call target hook to see if they can cluster.; // If FastCluster is enabled, we assume that, all the loads/stores have been; // preprocessed and now, they didn't have dependencies on each other.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp:42,load,loads,42,interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachineScheduler.cpp,4,['load'],"['load', 'loads']"
Performance,"// end namespace llvm; /// Optimize the uses in a given block This is basically the SSA renaming; /// algorithm, with one caveat: We are able to use a single stack for all; /// MemoryUses. This is because the set of *possible* reaching MemoryDefs is; /// the same for every MemoryUse. The *actual* clobbering MemoryDef is just; /// going to be some position in that stack of possible ones.; ///; /// We track the stack positions that each MemoryLocation needs; /// to check, and last ended at. This is because we only want to check the; /// things that changed since last time. The same MemoryLocation should; /// get clobbered by the same store (getModRefInfo does not use invariantness or; /// things like this, and if they start, we can modify MemoryLocOrCall to; /// include relevant data)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp:27,Optimiz,Optimize,27,interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemorySSA.cpp,1,['Optimiz'],['Optimize']
Performance,"// end namespace llvm; /// When a new SCC is created for the graph we first update the; /// FunctionAnalysisManager in the Proxy's result.; /// As there might be function analysis results cached for the functions now in; /// that SCC, two forms of updates are required.; ///; /// First, a proxy from the SCC to the FunctionAnalysisManager needs to be; /// created so that any subsequent invalidation events to the SCC are; /// propagated to the function analysis results cached for functions within it.; ///; /// Second, if any of the functions within the SCC have analysis results with; /// outer analysis dependencies, then those dependencies would point to the; /// *wrong* SCC's analysis result. We forcibly invalidate the necessary; /// function analyses so that they don't retain stale handles.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CGSCCPassManager.cpp:188,cache,cached,188,interpreter/llvm-project/llvm/lib/Analysis/CGSCCPassManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/CGSCCPassManager.cpp,2,['cache'],['cached']
Performance,"// end namespace; // Let's study one class hierarchy as an example:; // struct A {; // virtual void f();; // int x;; // };; //; // struct B : virtual A {; // virtual void f();; // };; //; // Record layouts:; // struct A:; // 0 | (A vftable pointer); // 4 | int x; //; // struct B:; // 0 | (B vbtable pointer); // 4 | struct A (virtual base); // 4 | (A vftable pointer); // 8 | int x; //; // Let's assume we have a pointer to the A part of an object of dynamic type B:; // B b;; // A *a = (A*)&b;; // a->f();; //; // In this hierarchy, f() belongs to the vftable of A, so B::f() expects; // ""this"" parameter to point at the A subobject, which is B+4.; // In the B::f() prologue, it adjusts ""this"" back to B by subtracting 4,; // performed as a *static* adjustment.; //; // Interesting thing happens when we alter the relative placement of A and B; // subobjects in a class:; // struct C : virtual B { };; //; // C c;; // A *a = (A*)&c;; // a->f();; //; // Respective record layout is:; // 0 | (C vbtable pointer); // 4 | struct A (virtual base); // 4 | (A vftable pointer); // 8 | int x; // 12 | struct B (virtual base); // 12 | (B vbtable pointer); //; // The final overrider of f() in class C is still B::f(), so B+4 should be; // passed as ""this"" to that code. However, ""a"" points at B-8, so the respective; // vftable entry should hold a thunk that adds 12 to the ""this"" argument before; // performing a tail call to B::f().; //; // With this example in mind, we can now calculate the 'this' argument offset; // for the given method, relative to the beginning of the MostDerivedClass.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/VTableBuilder.cpp:728,perform,performed,728,interpreter/llvm-project/clang/lib/AST/VTableBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/VTableBuilder.cpp,2,['perform'],"['performed', 'performing']"
Performance,// end namespace; /// Select a source for loading the named module and compute the filename to; /// load it from.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp:42,load,loading,42,interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Frontend/CompilerInstance.cpp,2,['load'],"['load', 'loading']"
Performance,"// enough space in cache to load font?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/graf/src/TTF.cxx:19,cache,cache,19,graf2d/graf/src/TTF.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/graf/src/TTF.cxx,2,"['cache', 'load']","['cache', 'load']"
Performance,"// ensure place in the queue for the send snapshot operation",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/canvaspainter/src/RCanvasPainter.cxx:23,queue,queue,23,gui/canvaspainter/src/RCanvasPainter.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/canvaspainter/src/RCanvasPainter.cxx,1,['queue'],['queue']
Performance,"// ensure that ranges are properly handled, even if the ranges are invalid; // let: start = desired start, end = desired end, last = actually last entry; // possible cases: default: 0 = start < last < end = max (already implicitly tested above); // 0. start < end <= last; // 1. similar to above but test the case the start is after the first tree); // * In MT runs, there is the additional optimization: once the desired end is reached,; // stop processing further trees, i.e. range asked is [1, 3] and the df has 2 trees; // of 5 entries each -> the second tree is not open.; // 2. 0 = start < last < end < max; // 3. 0 < start < last < end < max; // 4. start = end <= last -> enter the RLoopManager and do no work there (no sanity checks); // 5. start = end > last -> enter the RLoopManager and do no work there (no sanity checks); // 6. last = start < end -> error after getting the number of entries; // 7. last + 1 = start < end -> error after getting the number of entries; // 8. last < start < end -> error after getting the number of entries; // start > end -> error in the spec directly",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_datasetspec.cxx:391,optimiz,optimization,391,tree/dataframe/test/dataframe_datasetspec.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_datasetspec.cxx,1,['optimiz'],['optimization']
Performance,"// entries with kTRUE must not be transformed; // perform event loop",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/VariableGaussTransform.cxx:50,perform,perform,50,tmva/tmva/src/VariableGaussTransform.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/VariableGaussTransform.cxx,1,['perform'],['perform']
Performance,// enum ISD::LoadExtType,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/SelectionDAGNodes.h:13,Load,LoadExtType,13,interpreter/llvm-project/llvm/include/llvm/CodeGen/SelectionDAGNodes.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/SelectionDAGNodes.h,1,['Load'],['LoadExtType']
Performance,"// error situation - conversion cannot be performed",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/gpadv7/src/RAttrMap.cxx:42,perform,performed,42,graf2d/gpadv7/src/RAttrMap.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/gpadv7/src/RAttrMap.cxx,1,['perform'],['performed']
Performance,"// evaluate this define expression, cache the result",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RDefaultValueFor.hxx:36,cache,cache,36,tree/dataframe/inc/ROOT/RDF/RDefaultValueFor.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RDefaultValueFor.hxx,2,['cache'],['cache']
Performance,"// evaluate this filter, cache the result",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RFilter.hxx:25,cache,cache,25,tree/dataframe/inc/ROOT/RDF/RFilter.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RFilter.hxx,3,['cache'],['cache']
Performance,"// evaluate using cached function; /**; evaluate the Integral over the defined interval (a,b) using the function previously set with GSLIntegrator::SetFunction method; @param a lower value of the integration interval; @param b upper value of the integration interval; */",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/inc/Math/GSLIntegrator.h:18,cache,cached,18,math/mathmore/inc/Math/GSLIntegrator.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/inc/Math/GSLIntegrator.h,1,['cache'],['cached']
Performance,"// evaluates the event using the ensemble of rules; // the following uses fEventCache, that is per event saved in cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RuleEnsemble.h:114,cache,cache,114,tmva/tmva/inc/TMVA/RuleEnsemble.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RuleEnsemble.h,1,['cache'],['cache']
Performance,"// eventually store this matrix as static member to optimize speed",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/fumili/src/TFumiliMinimizer.cxx:52,optimiz,optimize,52,math/fumili/src/TFumiliMinimizer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/fumili/src/TFumiliMinimizer.cxx,1,['optimiz'],['optimize']
Performance,"// every time the texture cache key changes, it's necessary to check if an instance of; // WebGLTexture can be deleted in order to avoid a memory leak.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:26,cache,cache,26,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['cache'],['cache']
Performance,"// existing cache was created by the user, don't change it",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx:12,cache,cache,12,tree/tree/src/TTree.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx,1,['cache'],['cache']
Performance,// expandVSXLoadForLE - Convert VSX loads (which may be intrinsics for; // builtins) into loads with swaps.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:36,load,loads,36,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,2,['load'],['loads']
Performance,"// extract (vector load $addr), i --> load $addr + i * size",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:19,load,load,19,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,['load'],['load']
Performance,// extract data from the cache hash; // remove metadata on each item; // and return as array,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:25,cache,cache,25,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['cache'],['cache']
Performance,"// extractelt (select %x, %vec1, %vec2), %const ->; // select %x, %vec1[%const], %vec2[%const]; // TODO: Support constant folding of multiple select operands:; // extractelt (select %x, %vec1, %vec2), (select %x, %c1, %c2); // If the extractelement will for instance try to do out of bounds accesses; // because of the values of %c1 and/or %c2, the sequence could be optimized; // early. This is currently not possible because constant folding will reach; // an unreachable assertion if it doesn't find a constant operand.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineVectorOps.cpp:367,optimiz,optimized,367,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineVectorOps.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineVectorOps.cpp,1,['optimiz'],['optimized']
Performance,"// fCheckSum is an atomic variable. Also once it has; // transition from a zero Value it never changes. If two; // thread reach past this if statement and calculated the; // 'kLastestCheckSum', they will by definition obtain the; // same value, so technically we could simply have:; // if (fCheckSum && code == kCurrentCheckSum) return fCheckSum;; // However save a little bit of barrier time by calling load(); // only once.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:404,load,load,404,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,1,['load'],['load']
Performance,"// fNStopsReceived < fNChildren is always true at the moment as we don't support event loop early quitting in; // multi-thread runs, but it costs nothing to be safe and future-proof in case we add support for that later.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RLoopManager.cxx:114,multi-thread,multi-thread,114,tree/dataframe/src/RLoopManager.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RLoopManager.cxx,1,['multi-thread'],['multi-thread']
Performance,"// fObjPointers can grow due to a concurrent operation on this TThreadedObject, need to lock",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/thread/inc/ROOT/TThreadedObject.hxx:34,concurren,concurrent,34,core/thread/inc/ROOT/TThreadedObject.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/thread/inc/ROOT/TThreadedObject.hxx,2,['concurren'],['concurrent']
Performance,"// fScope and fMethod handled separately; // do not copy caches",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.cxx:57,cache,caches,57,bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.cxx,1,['cache'],['caches']
Performance,"// fVec are the cached coordinate values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/FitUtil.cxx:16,cache,cached,16,math/mathcore/src/FitUtil.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/FitUtil.cxx,1,['cache'],['cached']
Performance,"// fVec are the cached parameter values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/FitUtil.cxx:16,cache,cached,16,math/mathcore/src/FitUtil.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/FitUtil.cxx,2,['cache'],['cached']
Performance,"// fWriteCurrent was local and is now none.; // std::cerr << ""#"" << ""0x"" << std::hex << local << "" zero and cleaned : "" << std::dec << fWriteCurrentRecurse; // << "" 0x"" << std::hex << fWriteCurrent.load() << "" lock:"" << this << std::endl;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/cont/src/TCollection.cxx:198,load,load,198,core/cont/src/TCollection.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/cont/src/TCollection.cxx,1,['load'],['load']
Performance,"// fWriteCurrent was not local, just live it as is.; // std::cerr << ""#"" << ""0x"" << std::hex << local << "" zero but somebody else : "" << ""0x"" << std::hex <<; // fWriteCurrent.load() << "" lock:"" << this << std::endl;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/cont/src/TCollection.cxx:175,load,load,175,core/cont/src/TCollection.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/cont/src/TCollection.cxx,1,['load'],['load']
Performance,// fastcc with -tailcallopt is intended to provide a guaranteed; // tail call optimization. Fastisel doesn't know how to do that.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FastISel.cpp:78,optimiz,optimization,78,interpreter/llvm-project/llvm/lib/Target/X86/X86FastISel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FastISel.cpp,2,['optimiz'],['optimization']
Performance,"// file cache dir, under WorkDir",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/inc/TProof.h:8,cache,cache,8,proof/proof/inc/TProof.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/inc/TProof.h,1,['cache'],['cache']
Performance,"// file is in the cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx:18,cache,cache,18,io/io/src/TFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx,1,['cache'],['cache']
Performance,"// file not in the cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/net/src/TApplicationRemote.cxx:19,cache,cache,19,net/net/src/TApplicationRemote.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/net/src/TApplicationRemote.cxx,1,['cache'],['cache']
Performance,"// filename of an optional user script that will be executed before loading the Keras model",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/pymva/inc/TMVA/MethodPyKeras.h:68,load,loading,68,tmva/pymva/inc/TMVA/MethodPyKeras.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/pymva/inc/TMVA/MethodPyKeras.h,1,['load'],['loading']
Performance,"// filename of the user script that will be executed before loading the PyTorch model",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/pymva/inc/TMVA/MethodPyTorch.h:60,load,loading,60,tmva/pymva/inc/TMVA/MethodPyTorch.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/pymva/inc/TMVA/MethodPyTorch.h,1,['load'],['loading']
Performance,"// files.size() is greater the number of inputs by one. However, a timestamp; // file is created and stored in the cache directory if --thinlto-cache-policy; // option is used. Therefore, files.size() is used as ActualNums.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/CachePruning.cpp:115,cache,cache,115,interpreter/llvm-project/llvm/lib/Support/CachePruning.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/CachePruning.cpp,2,['cache'],"['cache', 'cache-policy']"
Performance,"// fill a new entry in our cache dataset for this point",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAcceptReject.cxx:27,cache,cache,27,roofit/roofitcore/src/RooAcceptReject.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAcceptReject.cxx,1,['cache'],['cache']
Performance,"// fill all the tuning parameters that should be optimized into a map:",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodBDT.cxx:49,optimiz,optimized,49,tmva/tmva/src/MethodBDT.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodBDT.cxx,1,['optimiz'],['optimized']
Performance,"// fill cached values of rule/linear respons",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RuleEnsemble.h:8,cache,cached,8,tmva/tmva/inc/TMVA/RuleEnsemble.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RuleEnsemble.h,1,['cache'],['cached']
Performance,"// filter out this option and change the target cache name",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx:48,cache,cache,48,io/io/src/TFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx,1,['cache'],['cache']
Performance,"// find best possible entry in cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/browserv7/src/RBrowserData.cxx:31,cache,cache,31,gui/browserv7/src/RBrowserData.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/browserv7/src/RBrowserData.cxx,1,['cache'],['cache']
Performance,"// find corresponding histogram from cached indices",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodLikelihood.cxx:37,cache,cached,37,tmva/tmva/src/MethodLikelihood.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodLikelihood.cxx,1,['cache'],['cached']
Performance,"// find the best tau - returns the number of steps performed in scan",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/RuleFitParams.cxx:51,perform,performed,51,tmva/tmva/src/RuleFitParams.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/RuleFitParams.cxx,1,['perform'],['performed']
Performance,"// find the function minimum performing a parameter scan (using MnParameterScan class); // function gradient is not used",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/ScanBuilder.cxx:29,perform,performing,29,math/minuit2/src/ScanBuilder.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/ScanBuilder.cxx,1,['perform'],['performing']
Performance,"// first Take triggers the computation of i, then the Filter executes, then Take accesses the cached value of i; // hopefully it won't have changed in the meanwhile!",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_concurrency.cxx:94,cache,cached,94,tree/dataframe/test/dataframe_concurrency.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_concurrency.cxx,1,['cache'],['cached']
Performance,// first cache rule/lin response; /* Double_t val = */,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/RuleFitParams.cxx:9,cache,cache,9,tmva/tmva/src/RuleFitParams.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/RuleFitParams.cxx,1,['cache'],['cache']
Performance,"// first call also loads dependent libraries declared via the rootmap file",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TPluginManager.cxx:19,load,loads,19,core/base/src/TPluginManager.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TPluginManager.cxx,1,['load'],['loads']
Performance,"// first check direct match in cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/browserv7/src/RBrowserData.cxx:31,cache,cache,31,gui/browserv7/src/RBrowserData.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/browserv7/src/RBrowserData.cxx,1,['cache'],['cache']
Performance,"// first process requests in the queue",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/http/src/THttpServer.cxx:33,queue,queue,33,net/http/src/THttpServer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/src/THttpServer.cxx,1,['queue'],['queue']
Performance,"// first the queue-worker sockets; // do resize instead of reserve so that the unique_ptrs are initialized; // (to nullptr) so that we can do reset below, alternatively you can do; // push/emplace_back with move or something",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/Messenger.cxx:13,queue,queue-worker,13,roofit/multiprocess/src/Messenger.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/Messenger.cxx,1,['queue'],['queue-worker']
Performance,"// first, load values from the prototype dataset, if one was provided",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsGenContext.cxx:10,load,load,10,roofit/roofitcore/src/RooAbsGenContext.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsGenContext.cxx,1,['load'],['load']
Performance,"// flag whether model is loaded, needed for getMvaValue during evaluation",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/pymva/inc/TMVA/MethodPyTorch.h:25,load,loaded,25,tmva/pymva/inc/TMVA/MethodPyTorch.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/pymva/inc/TMVA/MethodPyTorch.h,1,['load'],['loaded']
Performance,// fold (VMOVhr (load x)) -> (load (f16*)x),MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:17,load,load,17,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,2,['load'],['load']
Performance,// fold (VMOVrh (load x)) -> (zextload (i16*)x),MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:17,load,load,17,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['load'],['load']
Performance,"// fold ([s|z]ext (load x)) -> ([s|z]ext (truncate ([s|z]extload x))); // Only generate vector extloads when 1) they're legal, and 2) they are; // deemed desirable by the target.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:19,load,load,19,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,"// fold (aext (load x)) -> (aext (truncate (extload x))); // None of the supported targets knows how to perform load and any_ext; // on vectors in one instruction, so attempt to fold to zext instead.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:15,load,load,15,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,3,"['load', 'perform']","['load', 'perform']"
Performance,"// fold (aext (truncate (load x))) -> (aext (smaller load x)); // fold (aext (truncate (srl (load x), c))) -> (aext (small load (x+c/n)))",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:25,load,load,25,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,4,['load'],['load']
Performance,"// fold (and (load x), 255) -> (zextload x, i8); // fold (and (extload x, i16), 255) -> (zextload x, i8)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:14,load,load,14,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,"// fold (bitconvert (fneg x)) -> (xor (bitconvert x), signbit); // fold (bitconvert (fabs x)) -> (and (bitconvert x), (not signbit)); //; // For ppc_fp128:; // fold (bitcast (fneg x)) ->; // flipbit = signbit; // (xor (bitcast x) (build_pair flipbit, flipbit)); //; // fold (bitcast (fabs x)) ->; // flipbit = (and (extract_element (bitcast x), 0), signbit); // (xor (bitcast x) (build_pair flipbit, flipbit)); // This often reduces constant pool loads.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:447,load,loads,447,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['loads']
Performance,// fold (conv (load x)) -> (load (conv*)x); // If the resultant load doesn't need a higher alignment than the original!,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:15,load,load,15,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,3,['load'],['load']
Performance,// fold (fpext (load x)) -> (fpext (fptrunc (extload x))),MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:16,load,load,16,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,// fold (fpext (load x)) -> (fpext (fptrunc (extload x))); // We purposefully don't care about legality of the nodes here as we know; // they can be split down into something legal.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:16,load,load,16,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['load'],['load']
Performance,"// fold (sext (and/or/xor (load x), cst)) ->; // (and/or/xor (sextload x), (sext cst))",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:27,load,load,27,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,// fold (sext (load x)) to multiple smaller sextloads.; // Only on illegal but splittable vectors.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:15,load,load,15,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,"// fold (sext (load x)) to multiple smaller sextloads; same for zext.; // For example, on a target with legal v4i32, but illegal v8i32, turn:; // (v8i32 (sext (v8i16 (load x)))); // into:; // (v8i32 (concat_vectors (v4i32 (sextload x)),; // (v4i32 (sextload (x + 16))))); // Where uses of the original load, i.e.:; // (v8i16 (load x)); // are replaced with:; // (v8i16 (truncate; // (v8i32 (concat_vectors (v4i32 (sextload x)),; // (v4i32 (sextload (x + 16))))))); //; // This combine is only applicable to illegal, but splittable, vectors.; // All legal types, and illegal non-vector types, are handled elsewhere.; // This combine is controlled by TargetLowering::isVectorLoadExtDesirable.; //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:15,load,load,15,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,4,['load'],['load']
Performance,"// fold (sext (truncate (load x))) -> (sext (smaller load x)); // fold (sext (truncate (srl (load x), c))) -> (sext (smaller load (x+c/n)))",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:25,load,load,25,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,4,['load'],['load']
Performance,"// fold (sext_in_reg (load x)) -> (smaller sextload x); // fold (sext_in_reg (srl (load x), c)) -> (smaller sextload (x+c/evtbits))",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:22,load,load,22,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,['load'],['load']
Performance,"// fold (sext_inreg (extload x)) -> (sextload x); // If sextload is not supported by target, we can only do the combine when; // load has one use. Doing otherwise can block folding the extload with other; // extends that the target does support.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:129,load,load,129,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,// fold (sext_inreg (masked_load x)) -> (sext_masked_load x); // ignore it if the masked load is already sign extended,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:89,load,load,89,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,// fold (sext_inreg (zextload x)) -> (sextload x) iff load has one use,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:54,load,load,54,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,"// fold (truncate (load x)) -> (smaller load x); // fold (truncate (srl (load x), c)) -> (smaller load (x+c/evtbits))",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:19,load,load,19,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,4,['load'],['load']
Performance,"// fold (zext (and/or/xor (load x), cst)) ->; // (and/or/xor (zextload x), (zext cst)); // Unless (and (load x) cst) will match as a zextload already and has; // additional users, or the zext is already free.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:27,load,load,27,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,['load'],['load']
Performance,"// fold (zext (and/or/xor (shl/shr (load x), cst), cst)) ->; // (and/or/xor (shl/shr (zextload x), (zext cst)), (zext cst))",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:36,load,load,36,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,2,['load'],['load']
Performance,// fold (zext (load x)) to multiple smaller zextloads.; // Only on illegal but splittable vectors.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:15,load,load,15,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,"// fold (zext (truncate (load x))) -> (zext (smaller load x)); // fold (zext (truncate (srl (load x), c))) -> (zext (smaller load (x+c/n)))",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:25,load,load,25,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,4,['load'],['load']
Performance,// fold (zext_inreg (extload x)) -> (zextload x); // fold (zext_inreg (sextload x)) -> (zextload x) iff load has one use,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:104,load,load,104,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,"// for (auto * dataMember : fData) {; // //printf(""add data member for class %s - member %s \n"",GetName(), dataMember->GetName() );; // cl->fData->Add(dataMember);; // }; // // set loaded bit to true to avoid re-loading the data members; // cl->fData->SetIsLoaded();*; //cl->fData = (TListOfDataMembers*)fData;; // The TDataMember were passed along.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TProtoClass.cxx:181,load,loaded,181,core/meta/src/TProtoClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TProtoClass.cxx,2,['load'],"['loaded', 'loading']"
Performance,"// for auto-loading namespaces",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/histfactory/inc/LinkDef.h:12,load,loading,12,roofit/histfactory/inc/LinkDef.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/histfactory/inc/LinkDef.h,2,['load'],['loading']
Performance,"// for auto-loading of mathmore; // one can do it by doing using namespace ROOT::Math::MathMore",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/inc/Math/LinkDef_Func.h:12,load,loading,12,math/mathmore/inc/Math/LinkDef_Func.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/inc/Math/LinkDef_Func.h,1,['load'],['loading']
Performance,"// for automatic loading",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/LinkDef2.h:17,load,loading,17,math/mathcore/inc/LinkDef2.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/LinkDef2.h,1,['load'],['loading']
Performance,"// for data loading",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooFuncWrapper.cxx:12,load,loading,12,roofit/roofitcore/src/RooFuncWrapper.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooFuncWrapper.cxx,1,['load'],['loading']
Performance,"// for graphical comparison of performance",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/test/testIntegrationMultiDim.cxx:31,perform,performance,31,math/mathcore/test/testIntegrationMultiDim.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/test/testIntegrationMultiDim.cxx,2,['perform'],['performance']
Performance,"// for negative singular values perform change of sign",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/matrix/src/TDecompSVD.cxx:32,perform,perform,32,math/matrix/src/TDecompSVD.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/src/TDecompSVD.cxx,1,['perform'],['perform']
Performance,"// for optimized alfa's",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/SVWorkingSet.cxx:7,optimiz,optimized,7,tmva/tmva/src/SVWorkingSet.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/SVWorkingSet.cxx,1,['optimiz'],['optimized']
Performance,"// for performance reasons instead of std::vector<Bool_t> useVariable(fNvars);",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/DecisionTree.cxx:7,perform,performance,7,tmva/tmva/src/DecisionTree.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/DecisionTree.cxx,4,['perform'],['performance']
Performance,"// for regression compute performance from correlation with target value; // write histograms",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/TransformationHandler.cxx:26,perform,performance,26,tmva/tmva/src/TransformationHandler.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/TransformationHandler.cxx,1,['perform'],['performance']
Performance,"// for safety force a refresh of the cache (and tracking) in the nll; // DO NOT do a ConfigChange ... this is just a deactivate-reactivate of caching; // but it seems like doing this breaks the const optimization and function is badly behaved; // so once its turned on never turn it off.; // nll.constOptimizeTestStatistic(RooAbsArg::ConfigChange, constOptimize>1 /* do tracking too if >1 */); //; // trigger a re-evaluate of which nodes to cache-and-track; // the next line seems safe to do but wont bother doing it because not bothering with above; // need to understand why turning the cache off and on again breaks it??; // nll.constOptimizeTestStatistic(RooAbsArg::ValueChange, constOptimize>1); // update the cache values -- is; // this needed??",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx:37,cache,cache,37,roofit/xroofit/src/xRooFit.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx,5,"['cache', 'optimiz']","['cache', 'cache-and-track', 'optimization']"
Performance,"// for std::string std::iostream.; // Load user functions",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/net/src/TApplicationServer.cxx:38,Load,Load,38,net/net/src/TApplicationServer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/net/src/TApplicationServer.cxx,2,['Load'],['Load']
Performance,"// for std::string std::iostream.; // The following libs are also useful to have, make sure they are loaded...; //gROOT->LoadClass(""TMinuit"", ""Minuit"");; //gROOT->LoadClass(""TPostScript"", ""Postscript"");; // Load user functions",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProofServ.cxx:101,load,loaded,101,proof/proof/src/TProofServ.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProofServ.cxx,4,"['Load', 'load']","['Load', 'LoadClass', 'loaded']"
Performance,"// for the other case perform a minimization; // make a function of the length of the posterior interval as a function of lower bound",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TEfficiency.cxx:22,perform,perform,22,hist/hist/src/TEfficiency.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TEfficiency.cxx,1,['perform'],['perform']
Performance,"// for use with RooSimultaneous::generate in mixed mode; // Enable the binned likelihood optimization",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/histfactory/src/HistoToWorkspaceFactoryFast.cxx:89,optimiz,optimization,89,roofit/histfactory/src/HistoToWorkspaceFactoryFast.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/histfactory/src/HistoToWorkspaceFactoryFast.cxx,1,['optimiz'],['optimization']
Performance,"// force loading of the ROOT module",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/tpython/src/TPython.cxx:9,load,loading,9,bindings/tpython/src/TPython.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/tpython/src/TPython.cxx,1,['load'],['loading']
Performance,"// force loading of the cppyy module",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/API.cxx:9,load,loading,9,bindings/pyroot/cppyy/CPyCppyy/src/API.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/API.cxx,1,['load'],['loading']
Performance,"// force restoring the cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TClingCallbacks.cxx:23,cache,cache,23,core/metacling/src/TClingCallbacks.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TClingCallbacks.cxx,1,['cache'],['cache']
Performance,"// force the usage of cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/inc/TDataSetManager.h:22,cache,cache,22,proof/proof/inc/TDataSetManager.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/inc/TDataSetManager.h,1,['cache'],['cache']
Performance,"// force to create message queue",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/winnt/src/TWinNTSystem.cxx:27,queue,queue,27,core/winnt/src/TWinNTSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/winnt/src/TWinNTSystem.cxx,1,['queue'],['queue']
Performance,"// fprintf(stderr,""DEBUG: Load for %s unloadPoint is %p\n"", file.str().c_str(), unloadPoint);",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:26,Load,Load,26,interpreter/cling/lib/MetaProcessor/MetaSema.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/MetaProcessor/MetaSema.cpp,1,['Load'],['Load']
Performance,"// from now all operations performed with sub-element,; // stack should be repaired at the end",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TBufferJSON.cxx:27,perform,performed,27,io/io/src/TBufferJSON.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TBufferJSON.cxx,1,['perform'],['performed']
Performance,"// from queue socket",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/worker.cxx:8,queue,queue,8,roofit/multiprocess/src/worker.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/worker.cxx,1,['queue'],['queue']
Performance,"// function building string with optimizer parameters values for logging",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodDL.cxx:33,optimiz,optimizer,33,tmva/tmva/src/MethodDL.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodDL.cxx,1,['optimiz'],['optimizer']
Performance,"// function performing outer product using mndspr (DSPR) routine from BLAS",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/LaOuterProduct.cxx:12,perform,performing,12,math/minuit2/src/LaOuterProduct.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/LaOuterProduct.cxx,1,['perform'],['performing']
Performance,"// function performing the minimum searches using the FUMILI algorithm; // after the modification when I iterate on this functions, so it can be called many times,; // the seed is used here only to get precision and construct the returned FunctionMinimum object; /*; Three options were possible:. 1) create two parallel and completely separate hierarchies, in which case; the FumiliMinimizer would NOT inherit from ModularFunctionMinimizer,; FumiliBuilder would not inherit from MinimumBuilder etc. 2) Use the inheritance (base classes of ModularFunctionMinimizer,; MinimumBuilder etc), but recreate the member functions Minimize() and; Minimum() respectively (naming them for example minimize2() and; minimum2()) so that they can take FumiliFCNBase as Parameter instead FCNBase; (otherwise one wouldn't be able to call the Fumili-specific methods). 3) Cast in the daughter classes derived from ModularFunctionMinimizer,; MinimumBuilder. The first two would mean to duplicate all the functionality already existent,; which is a very bad practice and Error-prone. The third one is the most; elegant and effective solution, where the only constraint is that the user; must know that they have to pass a subclass of FumiliFCNBase to the FumiliMinimizer; and not just a subclass of FCNBase.; BTW, the first two solutions would have meant to recreate also a parallel; structure for MnFcn...; **/; // const FumiliFCNBase* tmpfcn = dynamic_cast<const FumiliFCNBase*>(&(fcn.Fcn()));",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/FumiliBuilder.cxx:12,perform,performing,12,math/minuit2/src/FumiliBuilder.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/FumiliBuilder.cxx,1,['perform'],['performing']
Performance,"// function performing the minimum searches using the Variable Metric algorithm (MIGRAD); // perform first a line search in the - Vg direction and then update using the Davidon formula (Davidon Error; // updator) stop when edm reached is less than required (edmval); // after the modification when I iterate on this functions, so it can be called many times,; // the seed is used here only to get precision and construct the returned FunctionMinimum object",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/VariableMetricBuilder.cxx:12,perform,performing,12,math/minuit2/src/VariableMetricBuilder.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/VariableMetricBuilder.cxx,2,['perform'],"['perform', 'performing']"
Performance,"// gClient, cached and queried through CINT",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/html/inc/THtml.h:12,cache,cached,12,html/inc/THtml.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/html/inc/THtml.h,1,['cache'],['cached']
Performance,"// gGeoManager is defined in the Geom libraries and we want to make sure we; // do not load it when autoloading is off. We can only test this in modules; // mode because gGeoManager is not part of the PCH and non-modular ROOT has; // header parsing and autoloading coupled leading to redundant load of; // libGeom at gROOT->GetGlobal time.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/test/TClingDataMemberInfoTests.cxx:87,load,load,87,core/metacling/test/TClingDataMemberInfoTests.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/test/TClingDataMemberInfoTests.cxx,2,['load'],['load']
Performance,"// gShowPrefixStack determines how messages are printed, it acts on all threads;; // race conditions when writing to this do not cause failures",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/MnPrint.cxx:85,race condition,race conditions,85,math/minuit2/src/MnPrint.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/MnPrint.cxx,1,['race condition'],['race conditions']
Performance,"// genShuffleBland - Creates shuffle according to two vectors.This function is; // only works on instructions with lane inside 256 registers. According to; // the mask 'Mask' creates a new Mask 'Out' by the offset of the mask. The; // offset amount depends on the two integer, 'LowOffset' and 'HighOffset'.; // Where the 'LowOffset' refers to the first vector and the highOffset refers to; // the second vector.; // |a0....a5,b0....b4,c0....c4|a16..a21,b16..b20,c16..c20|; // |c5...c10,a5....a9,b5....b9|c21..c26,a22..a26,b21..b25|; // |b10..b15,c11..c15,a10..a15|b26..b31,c27..c31,a27..a31|; // For the sequence to work as a mirror to the load.; // We must consider the elements order as above.; // In this function we are combining two types of shuffles.; // The first one is vpshufed and the second is a type of ""blend"" shuffle.; // By computing the shuffle on a sequence of 16 elements(one lane) and add the; // correct offset. We are creating a vpsuffed + blend sequence between two; // shuffles.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InterleavedAccess.cpp:640,load,load,640,interpreter/llvm-project/llvm/lib/Target/X86/X86InterleavedAccess.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86InterleavedAccess.cpp,1,['load'],['load']
Performance,"// general case of loading a C array pointer (void* + type code) as function argument",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Converters.cxx:19,load,loading,19,bindings/pyroot/cppyy/CPyCppyy/src/Converters.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Converters.cxx,1,['load'],['loading']
Performance,"// generate code for class member function LoadTree()",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/src/TTreePlayer.cxx:43,Load,LoadTree,43,tree/treeplayer/src/TTreePlayer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/src/TTreePlayer.cxx,1,['Load'],['LoadTree']
Performance,"// generate initial cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/PdfProposal.cxx:20,cache,cache,20,roofit/roostats/src/PdfProposal.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/PdfProposal.cxx,1,['cache'],['cache']
Performance,"// generate new cache if necessary",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/PdfProposal.cxx:16,cache,cache,16,roofit/roostats/src/PdfProposal.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/PdfProposal.cxx,1,['cache'],['cache']
Performance,"// generic = kTRUE; // for the base class one cannot call TClass::Streamer() as performed for the normal object",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfoActions.cxx:80,perform,performed,80,io/io/src/TStreamerInfoActions.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TStreamerInfoActions.cxx,1,['perform'],['performed']
Performance,"// get canonical path name and check if already loaded",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/DynamicLibraryManager.cpp:48,load,loaded,48,interpreter/cling/lib/Interpreter/DynamicLibraryManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/DynamicLibraryManager.cpp,1,['load'],['loaded']
Performance,"// get loading info",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RChunkLoader.hxx:7,load,loading,7,tmva/tmva/inc/TMVA/RChunkLoader.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RChunkLoader.hxx,1,['load'],['loading']
Performance,"// getAddrOfVTable may return 0 if asked to get an address of a vtable which; // shouldn't be used in the given record type. We want to cache this result in; // VFTablesMap, thus a simple zero check is not sufficient.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/MicrosoftCXXABI.cpp:136,cache,cache,136,interpreter/llvm-project/clang/lib/CodeGen/MicrosoftCXXABI.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/MicrosoftCXXABI.cpp,1,['cache'],['cache']
Performance,"// getCompilationDataBase - If -compilation-database is set, load the; // compilation database from the specified file. Otherwise if the we're; // generating P1689 format, trying to generate the compilation database; // form specified command line after the positional parameter ""--"".",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-scan-deps/ClangScanDeps.cpp:61,load,load,61,interpreter/llvm-project/clang/tools/clang-scan-deps/ClangScanDeps.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-scan-deps/ClangScanDeps.cpp,1,['load'],['load']
Performance,"// getDecomposedLoc may have failed to return a valid FileID because, e.g. it; // is a serialized one referring to a file that was removed after we loaded; // the PCH.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/SourceManager.cpp:148,load,loaded,148,interpreter/llvm-project/clang/lib/Basic/SourceManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/SourceManager.cpp,1,['load'],['loaded']
Performance,"// getLoad needs a vector type, but it can't handle; // vectors which contain v2f16 or v2bf16 elements. So we must load; // using i32 here and then bitcast back.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:115,load,load,115,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,1,['load'],['load']
Performance,"// getStringType can be called multiple times with Cache being null, and; // the local cache should be discarded when that occurs.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/LookupHelper.cpp:51,Cache,Cache,51,interpreter/cling/lib/Interpreter/LookupHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/LookupHelper.cpp,2,"['Cache', 'cache']","['Cache', 'cache']"
Performance,"// getTypeInfoDataSizeInChars - Return the size of a type, in; // chars. If the type is a record, its data size is returned. This is; // the size of the memcpy that's performed when assigning this type; // using a trivial copy/move assignment operator.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ASTContext.cpp:167,perform,performed,167,interpreter/llvm-project/clang/lib/AST/ASTContext.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/ASTContext.cpp,1,['perform'],['performed']
Performance,"// gets the qualname of the decl, no checks performed",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/dictgen/res/SelectionRules.h:44,perform,performed,44,core/dictgen/res/SelectionRules.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/dictgen/res/SelectionRules.h,1,['perform'],['performed']
Performance,"// getting number of variables and variable names from loader",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Factory.cxx:55,load,loader,55,tmva/tmva/src/Factory.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Factory.cxx,6,['load'],['loader']
Performance,"// handling will be performed in following http request handler",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/http/src/THttpWSHandler.cxx:20,perform,performed,20,net/http/src/THttpWSHandler.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/src/THttpWSHandler.cxx,1,['perform'],['performed']
Performance,"// hasFnAttribute() is expensive to call on every BRCOND selection, so; // cache it here for each run of the selector.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp:75,cache,cache,75,interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/GISel/AArch64InstructionSelector.cpp,1,['cache'],['cache']
Performance,"// have to reinitialize if const par values have changed - const optimization forces this; // TODO: currently changes to globs also triggers this since the vars includes globs (vars are the non-obs pars); // std::cout << ""Reinitializing because of change of const parameters:"" << f->contentsString() << std::endl;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx:65,optimiz,optimization,65,roofit/xroofit/src/xRooNLLVar.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx,1,['optimiz'],['optimization']
Performance,"// here processing of received data should be performed; // this is task for the implemented windows",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/webdisplay/src/RWebWindow.cxx:46,perform,performed,46,gui/webdisplay/src/RWebWindow.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/webdisplay/src/RWebWindow.cxx,1,['perform'],['performed']
Performance,"// high resolution performance counter",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TUUID.cxx:19,perform,performance,19,core/base/src/TUUID.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TUUID.cxx,1,['perform'],['performance']
Performance,"// high water mark for master-queue sending, which can be quite a busy channel, especially at the start of a run",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/Messenger.cxx:30,queue,queue,30,roofit/multiprocess/src/Messenger.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/Messenger.cxx,1,['queue'],['queue']
Performance,// hold up the constant values replacing loads.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFISelDAGToDAG.cpp:41,load,loads,41,interpreter/llvm-project/llvm/lib/Target/BPF/BPFISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFISelDAGToDAG.cpp,1,['load'],['loads']
Performance,"// http://man7.org/linux/man-pages/man7/inotify.7.html; // Some systems cannot read integer variables if they are not; // properly aligned. On other systems, incorrect alignment may; // decrease performance. Hence, the buffer used for reading from; // the inotify file descriptor should have the same alignment as; // struct inotify_event.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/DirectoryWatcher/linux/DirectoryWatcher-linux.cpp:195,perform,performance,195,interpreter/llvm-project/clang/lib/DirectoryWatcher/linux/DirectoryWatcher-linux.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/DirectoryWatcher/linux/DirectoryWatcher-linux.cpp,1,['perform'],['performance']
Performance,"// humm we did not find it ... maybe it's a typedef that has not been loaded yet.; // (this can happen if the executable does not have a TApplication object).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TDataMember.cxx:70,load,loaded,70,core/meta/src/TDataMember.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TDataMember.cxx,1,['load'],['loaded']
Performance,// i1 is loaded/stored as i8.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:9,load,loaded,9,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,1,['load'],['loaded']
Performance,// i128 immediates loads from Constant Pool,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp:19,load,loads,19,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZTargetTransformInfo.cpp,1,['load'],['loads']
Performance,// i32 load from higher address.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEISelLowering.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEISelLowering.cpp,1,['load'],['load']
Performance,// i32 load from lower address.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEISelLowering.cpp:7,load,load,7,interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEISelLowering.cpp,1,['load'],['load']
Performance,// i64 SRA needs to be performed as partial shifts.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:23,perform,performed,23,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['perform'],['performed']
Performance,"// if (!_yatX) {; // _yatX = new double[_x->numBins(""cache"")+1] ;; // _calcX = new double[_x->numBins(""cache"")+1] ;; // }",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/src/RooIntegralMorph.cxx:53,cache,cache,53,roofit/roofit/src/RooIntegralMorph.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/src/RooIntegralMorph.cxx,2,['cache'],['cache']
Performance,"// if (findInGlobalModuleIndex(Tag->getDeclName(), /*loadFirstMatchOnly*/false)); // return true;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TClingCallbacks.cxx:53,load,loadFirstMatchOnly,53,core/metacling/src/TClingCallbacks.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TClingCallbacks.cxx,1,['load'],['loadFirstMatchOnly']
Performance,"// if (lowSearch && !TMath::IsNaN(fUpperLimit)) return fLowerLimit;; // if (!lowSearch && !TMath::IsNaN(fLowerLimit)) return fUpperLimit;; // // is this needed ?; // // we call again the function for the upper limits; // // now perform the opposite search on the complement interval; // if (lowSearch) {; // xmin = xmax;; // xmax = varmax;; // } else {; // xmax = xmin;; // xmin = varmin;; // }; // double limit2 = GetGraphX(graph, target, !lowSearch, xmin, xmax);; // if (!lowSearch) fLowerLimit = limit2;; // else fUpperLimit = limit2;; // CalculateEstimatedError( target, !lowSearch, xmin, xmax);; // #ifdef DO_DEBUG; // std::cout << ""other limit is "" << limit2 << std::endl;; // #endif; // return (lowSearch) ? fLowerLimit : fUpperLimit;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/HypoTestInverterResult.cxx:228,perform,perform,228,roofit/roostats/src/HypoTestInverterResult.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/HypoTestInverterResult.cxx,1,['perform'],['perform']
Performance,"// if 0 will disable constant term optimization and cache-and-track of the; // NLL. 1 = just caching, 2 = cache and track",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx:35,optimiz,optimization,35,roofit/xroofit/src/xRooFit.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx,3,"['cache', 'optimiz']","['cache', 'cache-and-track', 'optimization']"
Performance,"// if VGPR usage is extremely high, try other good performing variants; // which could lead to lower VGPR usage",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMachineScheduler.cpp:51,perform,performing,51,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMachineScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMachineScheduler.cpp,1,['perform'],['performing']
Performance,"// if VGPR usage is still extremely high, we may spill. Try other variants; // which are less performing, but that could lead to lower VGPR usage.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMachineScheduler.cpp:94,perform,performing,94,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMachineScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIMachineScheduler.cpp,1,['perform'],['performing']
Performance,"// if a file was not specified, try to load the class via the interpreter;; // this returns 0 (== failure) in the case the class is already in memory; // but does not have a dictionary, so we just raise a flag for better; // diagnostic in the case the class is not found in the CINT ClassInfo table.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TSelector.cxx:39,load,load,39,tree/tree/src/TSelector.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TSelector.cxx,1,['load'],['load']
Performance,"// if cache is valid, just use it",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoNavigator.cxx:6,cache,cache,6,geom/geom/src/TGeoNavigator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoNavigator.cxx,1,['cache'],['cache']
Performance,"// if content was removed from the buffer, or the buffer was enlarged then; // empty the prefetch lists and prime to fill the cache again",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx:126,cache,cache,126,tree/tree/src/TTreeCache.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx,1,['cache'],['cache']
Performance,"// if fAutomatic == true you need a validation sample to optimize pruning",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodBDT.cxx:57,optimiz,optimize,57,tmva/tmva/src/MethodBDT.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodBDT.cxx,1,['optimiz'],['optimize']
Performance,"// if file content was cached, reuse it",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/net/src/TWebFile.cxx:23,cache,cached,23,net/net/src/TWebFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/net/src/TWebFile.cxx,1,['cache'],['cached']
Performance,"// if it isn't first piece, alignment must be 1; // For scalable vectors the scalable part is currently handled; // by individual targets, so we just use the known minimum size here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp:56,scalab,scalable,56,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp,2,['scalab'],['scalable']
Performance,"// if just loaded value equal to 0,return true.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/Speculation.cpp:11,load,loaded,11,interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/Speculation.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/Speculation.cpp,1,['load'],['loaded']
Performance,// if load; // TODO: Handle this with the AsmOperandClass.PredicateMethod.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/AsmParser/MipsAsmParser.cpp:6,load,load,6,interpreter/llvm-project/llvm/lib/Target/Mips/AsmParser/MipsAsmParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/AsmParser/MipsAsmParser.cpp,1,['load'],['load']
Performance,"// if not valid, simply reset the hash function so as to not kill performance",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPInstance.cxx:66,perform,performance,66,bindings/pyroot/cppyy/CPyCppyy/src/CPPInstance.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPInstance.cxx,1,['perform'],['performance']
Performance,"// if optimizing cwn ntuple then look up bufpos and adjust integers to be shorts or chars",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/main/src/h2root.cxx:6,optimiz,optimizing,6,main/src/h2root.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/main/src/h2root.cxx,1,['optimiz'],['optimizing']
Performance,"// if overtraining check, load additional histograms",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmvagui/src/mvas.cxx:26,load,load,26,tmva/tmvagui/src/mvas.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmvagui/src/mvas.cxx,2,['load'],['load']
Performance,"// if queued operation registered, ignore next calls, indx === 0 is running operation",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:6,queue,queued,6,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,4,['queue'],['queued']
Performance,"// if size(a) == size(b), perform in place computation",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/matrix/src/TMatrixT.cxx:26,perform,perform,26,math/matrix/src/TMatrixT.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/src/TMatrixT.cxx,2,['perform'],['perform']
Performance,"// if the ClassInfo was loaded for a class with a TClass Init and it; // gets unloaded, should we guess it can be reloaded?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx:24,load,loaded,24,core/meta/src/TClass.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/src/TClass.cxx,1,['load'],['loaded']
Performance,"// if the cache grew too large, start replacing in a round-robin fashion",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooNormSetCache.cxx:10,cache,cache,10,roofit/roofitcore/src/RooNormSetCache.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooNormSetCache.cxx,1,['cache'],['cache']
Performance,"// if the file is writable, non local, and not opened in raw mode; // we create a default write cache of 512 KBytes",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx:96,cache,cache,96,io/io/src/TFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx,1,['cache'],['cache']
Performance,"// if the parent is a _finally, the passed-in ParentFP is the FP; // of parent _finally, not Establisher's FP (FP of outermost function).; // Establkisher FP is 2nd paramenter passed into parent _finally.; // Fortunately, it's always saved in parent's frame. The following; // code retrieves it, and escapes it so that spill instruction won't be; // optimized away.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGException.cpp:350,optimiz,optimized,350,interpreter/llvm-project/clang/lib/CodeGen/CGException.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGException.cpp,1,['optimiz'],['optimized']
Performance,// if the type is scalable and the constant is not zero (vscale * n * 0 =; // 0) bailout.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/Operator.cpp:18,scalab,scalable,18,interpreter/llvm-project/llvm/lib/IR/Operator.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/Operator.cpp,1,['scalab'],['scalable']
Performance,"// if there's no file or we are not a plain tree (e.g. if we're a TChain); // do not create a cache, only record the size if one was given",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx:94,cache,cache,94,tree/tree/src/TTree.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx,1,['cache'],['cache']
Performance,"// if this instance's class has a relation to the requested one, calculate the; // offset, erase if from any caches, and update the pointer and type",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPyCppyyModule.cxx:109,cache,caches,109,bindings/pyroot/cppyy/CPyCppyy/src/CPyCppyyModule.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPyCppyyModule.cxx,1,['cache'],['caches']
Performance,"// if true, most operations are performed locally without involving server",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/ui5/browser/controller/Browser.controller.js:32,perform,performed,32,ui5/browser/controller/Browser.controller.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/ui5/browser/controller/Browser.controller.js,1,['perform'],['performed']
Performance,"// if true, the population will make copies of the first individuals; // avoid for speed performance.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/GeneticAlgorithm.h:89,perform,performance,89,tmva/tmva/inc/TMVA/GeneticAlgorithm.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/GeneticAlgorithm.h,1,['perform'],['performance']
Performance,"// if we're using an automatically calculated size and the existing; // cache is already almost large enough don't resize",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx:72,cache,cache,72,tree/tree/src/TTree.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx,1,['cache'],['cache']
Performance,"// if write cache is active check if data still in write cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx:12,cache,cache,12,io/io/src/TFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx,2,['cache'],['cache']
Performance,"// if wrks is specified the macro should already be loaded on the master.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProof.cxx:52,load,loaded,52,proof/proof/src/TProof.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProof.cxx,2,['load'],['loaded']
Performance,"// if(fitConfig.MinimizerOptions().ExtraOptions()) {; // //for loading hesse options; // double a;; // if(fitConfig.MinimizerOptions().ExtraOptions()->GetValue(""HessianStepTolerance"",a)) {; // ROOT::Math::MinimizerOptions::Default(""Minuit2"").SetValue(""HessianStepTolerance"",a);; // }; // if(fitConfig.MinimizerOptions().ExtraOptions()->GetValue(""HessianG2Tolerance"",a)) {; // ROOT::Math::MinimizerOptions::Default(""Minuit2"").SetValue(""HessianG2Tolerance"",a);; // }; // }",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx:63,load,loading,63,roofit/xroofit/src/xRooFit.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx,1,['load'],['loading']
Performance,"// ignore libCore - it's already loaded",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx:33,load,loaded,33,core/base/src/TSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx,1,['load'],['loaded']
Performance,"// iii) update the cached frustum planes so we can get eye point/direction",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/src/TGLPerspectiveCamera.cxx:19,cache,cached,19,graf3d/gl/src/TGLPerspectiveCamera.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/src/TGLPerspectiveCamera.cxx,1,['cache'],['cached']
Performance,"// implement explicitly using cached parameter values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/test/stress/StatFunction.h:30,cache,cached,30,math/mathcore/test/stress/StatFunction.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/test/stress/StatFunction.h,2,['cache'],['cached']
Performance,"// important to cache the paramPoint b/c test statistic might; // modify it from event to event",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/ToyMCSampler.cxx:16,cache,cache,16,roofit/roostats/src/ToyMCSampler.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/ToyMCSampler.cxx,1,['cache'],['cache']
Performance,"// in case a web file is specified, use the cacheread option to cache; // this file in the cache directory",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoManager.cxx:44,cache,cacheread,44,geom/geom/src/TGeoManager.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoManager.cxx,3,['cache'],"['cache', 'cacheread']"
Performance,"// in case of a ntupla/tree based histogram with number of entries not exceeding the TTreePlayer cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/ged/src/TH1Editor.cxx:97,cache,cache,97,gui/ged/src/TH1Editor.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/src/TH1Editor.cxx,1,['cache'],['cache']
Performance,"// in case we are writing and reading to/from this file, we much check; // if this buffer is in the write cache (not yet written to the file)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFileCacheRead.cxx:106,cache,cache,106,io/io/src/TFileCacheRead.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFileCacheRead.cxx,1,['cache'],['cache']
Performance,"// in case we are writing and reading to/from this file, we must check; // if this buffer is in the write cache (not yet written to the file)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFileCacheRead.cxx:106,cache,cache,106,io/io/src/TFileCacheRead.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFileCacheRead.cxx,1,['cache'],['cache']
Performance,"// increment optimizer step that is used in some algorithms (e.g. ADAM)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodDL.cxx:13,optimiz,optimizer,13,tmva/tmva/src/MethodDL.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodDL.cxx,1,['optimiz'],['optimizer']
Performance,"// indication that draw and hierarchy is loaded, create css",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:41,load,loaded,41,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['load'],['loaded']
Performance,"// info cache for class documentation",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/html/inc/TDocInfo.h:8,cache,cache,8,html/inc/TDocInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/html/inc/TDocInfo.h,1,['cache'],['cache']
Performance,"// initialize the cache at this voxel",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx:18,cache,cache,18,geom/geom/src/TGeoParallelWorld.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx,1,['cache'],['cache']
Performance,"// instance of the tree cache for the tree",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/inc/TEventIter.h:24,cache,cache,24,proof/proofplayer/inc/TEventIter.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/inc/TEventIter.h,1,['cache'],['cache']
Performance,"// instantiate multi-thread tests",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_datasetspec.cxx:15,multi-thread,multi-thread,15,tree/dataframe/test/dataframe_datasetspec.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_datasetspec.cxx,4,['multi-thread'],['multi-thread']
Performance,"// integration method using cached function; /**; evaluate the Integral over the defined interval (a,b) using the function previously set with Integrator::SetFunction method; @param a lower value of the integration interval; @param b upper value of the integration interval; */",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Math/Integrator.h:28,cache,cached,28,math/mathcore/inc/Math/Integrator.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Math/Integrator.h,1,['cache'],['cached']
Performance,"// interaction between small buffer optimization and memory adoption",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/vecops/test/vecops_rvec.cxx:36,optimiz,optimization,36,math/vecops/test/vecops_rvec.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/test/vecops_rvec.cxx,1,['optimiz'],['optimization']
Performance,"// internal method to calculate single partial derivative; // assume cached vector fVec is already set",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/FitUtil.cxx:69,cache,cached,69,math/mathcore/src/FitUtil.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/FitUtil.cxx,1,['cache'],['cached']
Performance,// internal state cache,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:18,cache,cache,18,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['cache'],['cache']
Performance,"// internals performance counters, requires that EnableMetrics() was called",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RNTupleReader.hxx:13,perform,performance,13,tree/ntuple/v7/inc/ROOT/RNTupleReader.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/inc/ROOT/RNTupleReader.hxx,1,['perform'],['performance']
Performance,// inttoptrs in an integral address space are currently ill-defined. We; // treat them as defining base pointers here for consistency with the; // constant rule above and because we don't really have a better semantic; // to give them. Note that the optimizer is always free to insert undefined; // behavior on dynamically dead paths as well.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp:250,optimiz,optimizer,250,interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,1,['optimiz'],['optimizer']
Performance,"// invalidate path cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/unix/src/TUnixSystem.cxx:19,cache,cache,19,core/unix/src/TUnixSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/unix/src/TUnixSystem.cxx,2,['cache'],['cache']
Performance,"// invalidate the cache.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TClingClassInfo.cxx:18,cache,cache,18,core/metacling/src/TClingClassInfo.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TClingClassInfo.cxx,5,['cache'],['cache']
Performance,"// invalidate the cached pointers",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/BayesianCalculator.cxx:18,cache,cached,18,roofit/roostats/src/BayesianCalculator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/BayesianCalculator.cxx,1,['cache'],['cached']
Performance,"// invariant.start on memory location implies that the referenced memory; // location is constant and unchanging. This is no longer true after; // RewriteStatepointsForGC runs because there can be calls to gc.statepoint; // which frees the entire heap and the presence of invariant.start allows; // the optimizer to sink the load of a memory location past a statepoint,; // which is incorrect.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp:303,optimiz,optimizer,303,interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/RewriteStatepointsForGC.cpp,2,"['load', 'optimiz']","['load', 'optimizer']"
Performance,// inverse throughput.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/Analysis.cpp:11,throughput,throughput,11,interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/Analysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/Analysis.cpp,1,['throughput'],['throughput']
Performance,"// invoke callback if not yet performed",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/browserv7/src/RFileDialog.cxx:30,perform,performed,30,gui/browserv7/src/RFileDialog.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/browserv7/src/RFileDialog.cxx,1,['perform'],['performed']
Performance,"// iret |= gSystem->Load(""libMathCore"");; // iret |= gSystem->Load(""libMathMore"");; // if (iret !=0) return iret;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/test/stressMathCore.cxx:20,Load,Load,20,test/stressMathCore.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/test/stressMathCore.cxx,2,['Load'],['Load']
Performance,"// isLegalAddressingMode - Return true if the addressing mode represented; // by AM is legal for this target, for a load/store of the specified type.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:116,load,load,116,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['load']
Performance,"// isProfitable() is structured to avoid endless loop interchange.; // If loop cache analysis could decide the profitability then,; // profitability check will stop and return the analysis result.; // If cache analysis failed to analyze the loopnest (e.g.,; // due to delinearization issues) then only check whether it is; // profitable for InstrOrderCost. Likewise, if InstrOrderCost failed to; // analysis the profitability then only, isProfitableForVectorization; // will decide.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopInterchange.cpp:79,cache,cache,79,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopInterchange.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopInterchange.cpp,2,['cache'],['cache']
Performance,"// isolate each item in the loaded word",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RColumnElement.cxx:28,load,loaded,28,tree/ntuple/v7/src/RColumnElement.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RColumnElement.cxx,1,['load'],['loaded']
Performance,"// it is a header: add the libname to the list of libs to be loaded.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx:61,load,loaded,61,core/metacling/src/TCling.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TCling.cxx,1,['load'],['loaded']
Performance,"// it makes no sense to read local files through a file cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx:56,cache,cache,56,io/io/src/TFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx,1,['cache'],['cache']
Performance,"// iterate over all pairs of load, store",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/AliasAnalysisEvaluator.cpp:29,load,load,29,interpreter/llvm-project/llvm/lib/Analysis/AliasAnalysisEvaluator.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/AliasAnalysisEvaluator.cpp,1,['load'],['load']
Performance,"// iterate over methods and optimize",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Factory.cxx:28,optimiz,optimize,28,tmva/tmva/src/Factory.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Factory.cxx,1,['optimiz'],['optimize']
Performance,"// iterate over the cache variables for this dataset",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooTreeDataStore.cxx:20,cache,cache,20,roofit/roofitcore/src/RooTreeDataStore.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooTreeDataStore.cxx,1,['cache'],['cache']
Performance,"// iterativelySimplifyCFG can (rarely) make some loops dead. If this happens,; // removeUnreachableBlocks is needed to nuke them, which means we should; // iterate between the two optimizations. We structure the code like this to; // avoid rerunning iterativelySimplifyCFG if the second pass of; // removeUnreachableBlocks doesn't do anything.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SimplifyCFGPass.cpp:180,optimiz,optimizations,180,interpreter/llvm-project/llvm/lib/Transforms/Scalar/SimplifyCFGPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/SimplifyCFGPass.cpp,1,['optimiz'],['optimizations']
Performance,"// just in case the class is not loaded.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFileMerger.cxx:33,load,loaded,33,io/io/src/TFileMerger.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFileMerger.cxx,1,['load'],['loaded']
Performance,"// just load the first library - TSystem will do the rest.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx:8,load,load,8,core/base/src/TSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx,1,['load'],['load']
Performance,"// kSize bits per baskets (loaded, used, vetoed); /// Update the pedestal to be less or equal to basketNumber, shift the bits if needed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/inc/TBranchCacheInfo.h:27,load,loaded,27,tree/tree/inc/TBranchCacheInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/inc/TBranchCacheInfo.h,1,['load'],['loaded']
Performance,"// keep a copy; // Now perform fetch and add of the two components buffers.; // Note we assume that composite shapes are always completely added; // so don't bother to get addDaughters flag from viewer->AddObject(); // Setup matrix and fetch/add the left component buffer",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoBoolNode.cxx:23,perform,perform,23,geom/geom/src/TGeoBoolNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoBoolNode.cxx,1,['perform'],['perform']
Performance,"// keep pruning the tree until reach the limit fAlpha; // build a wrapper tree to perform work on",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/CCPruner.cxx:82,perform,perform,82,tmva/tmva/src/CCPruner.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/CCPruner.cxx,1,['perform'],['perform']
Performance,"// let allocate special thread which will be used to perform data sending via websocket; // should reduce consumption of webwindow thread when big data are send; // gEnv->SetValue(""WebGui.SenderThrds"", ""yes"");; // create window",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/ping.cxx:53,perform,perform,53,tutorials/webgui/ping/ping.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/ping.cxx,1,['perform'],['perform']
Performance,"// level 2 cache size in KB",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h:11,cache,cache,11,core/base/inc/TSystem.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/inc/TSystem.h,2,['cache'],['cache']
Performance,"// li rx, si; // load rt, ra, rx; // The dependent operand index in the second op(load). And the negative means; // it could be any one. ",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMacroFusion.cpp:17,load,load,17,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMacroFusion.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCMacroFusion.cpp,2,['load'],['load']
Performance,"// libCling symbols are intentionally hidden from the process, and libCling must not be; // dlopened. Instead, symbols must be resolved by specifically querying the dynlib handle of; // libCling, which by definition is loaded - else we could not call this code. The handle; // is made available as argument to `CreateInterpreter`.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TClingCallbacks.cxx:219,load,loaded,219,core/metacling/src/TClingCallbacks.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/src/TClingCallbacks.cxx,1,['load'],['loaded']
Performance,"// libunwind is unable to load compact unwind dynamically, so we must generate; // DWARF unwind info for the JIT.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LLVMTargetMachine.cpp:26,load,load,26,interpreter/llvm-project/llvm/lib/CodeGen/LLVMTargetMachine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/LLVMTargetMachine.cpp,1,['load'],['load']
Performance,"// like this the order is ""right"". Always keep the; // order in the vector ""pars"" the same as the iterator; // iterates through the tuneParameters !!!!",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/OptimizeConfigParameters.cxx:132,tune,tuneParameters,132,tmva/tmva/src/OptimizeConfigParameters.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/OptimizeConfigParameters.cxx,1,['tune'],['tuneParameters']
Performance,"// likelihood fit; // perform a weighted likelihood fit by applying weight correction to errors",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/HFitImpl.cxx:22,perform,perform,22,hist/hist/src/HFitImpl.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/HFitImpl.cxx,1,['perform'],['perform']
Performance,// link debug info for loaded object files.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/dsymutil/DwarfLinkerForBinary.cpp:23,load,loaded,23,interpreter/llvm-project/llvm/tools/dsymutil/DwarfLinkerForBinary.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/dsymutil/DwarfLinkerForBinary.cpp,1,['load'],['loaded']
Performance,// list of loaded fonts including handling of multiple simultaneous requests,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:11,load,loaded,11,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['load'],['loaded']
Performance,// llvmGetPassPluginInfo should be resolved to the definition from the plugin; // we are currently loading.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassPlugin.cpp:99,load,loading,99,interpreter/llvm-project/llvm/lib/Passes/PassPlugin.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassPlugin.cpp,1,['load'],['loading']
Performance,// load,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:3,load,load,3,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,1,['load'],['load']
Performance,"// load $vr, FI; // copy ccond, $vr",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEFrameLowering.cpp:3,load,load,3,interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEFrameLowering.cpp,1,['load'],['load']
Performance,"// load $vr0, FI; // copy lo, $vr0; // load $vr1, FI + 4; // copy hi, $vr1",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEFrameLowering.cpp:3,load,load,3,interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEFrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEFrameLowering.cpp,2,['load'],['load']
Performance,"// load (display) temp file in text view",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/sessionviewer/src/TSessionViewer.cxx:3,load,load,3,gui/sessionviewer/src/TSessionViewer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/sessionviewer/src/TSessionViewer.cxx,2,['load'],['load']
Performance,"// load (select (Cond, &V1, &V2)) --> select(Cond, load &V1, load &V2).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp:3,load,load,3,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp,3,['load'],['load']
Performance,"// load (select (cond, P, null)) -> load P",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp:3,load,load,3,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp,2,['load'],['load']
Performance,"// load (select (cond, null, P)) -> load P",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp:3,load,load,3,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp,2,['load'],['load']
Performance,// load + update AddrIn,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:3,load,load,3,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['load'],['load']
Performance,"// load 8 bytes from src[i] into MM0",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/asimage/src/libAfterImage/imencdec.c:3,load,load,3,graf2d/asimage/src/libAfterImage/imencdec.c,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/asimage/src/libAfterImage/imencdec.c,1,['load'],['load']
Performance,"// load WIC's PNG decoder",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/winnt/src/Win32Splash.cxx:3,load,load,3,core/winnt/src/Win32Splash.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/winnt/src/Win32Splash.cxx,1,['load'],['load']
Performance,"// load a yml file defining the export keys",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/hs3/src/JSONIO.cxx:3,load,load,3,roofit/hs3/src/JSONIO.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/hs3/src/JSONIO.cxx,1,['load'],['load']
Performance,"// load a yml file defining the factory expressions",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/hs3/src/JSONIO.cxx:3,load,load,3,roofit/hs3/src/JSONIO.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/hs3/src/JSONIO.cxx,1,['load'],['load']
Performance,"// load all components",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/foam/src/TFoamCell.cxx:3,load,load,3,math/foam/src/TFoamCell.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/foam/src/TFoamCell.cxx,4,['load'],['load']
Performance,"// load all converter factories in the global map 'gConvFactories'",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Converters.cxx:3,load,load,3,bindings/pyroot/cppyy/CPyCppyy/src/Converters.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Converters.cxx,1,['load'],['load']
Performance,"// load all executor factories in the global map 'gExecFactories'",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Executors.cxx:3,load,load,3,bindings/pyroot/cppyy/CPyCppyy/src/Executors.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Executors.cxx,1,['load'],['load']
Performance,"// load all public methods and data members",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/ProxyWrappers.cxx:3,load,load,3,bindings/pyroot/cppyy/CPyCppyy/src/ProxyWrappers.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/ProxyWrappers.cxx,1,['load'],['load']
Performance,"// load any dependent libraries",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx:3,load,load,3,core/base/src/TSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx,1,['load'],['load']
Performance,// load array of images e.g CubeTexture,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/modules/three.mjs:3,load,load,3,js/modules/three.mjs,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/modules/three.mjs,2,['load'],['load']
Performance,"// load buffer",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/sessionviewer/src/TProofProgressDialog.cxx:3,load,load,3,gui/sessionviewer/src/TProofProgressDialog.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/sessionviewer/src/TProofProgressDialog.cxx,3,['load'],['load']
Performance,"// load coords from the nullDist globs list",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx:3,load,load,3,roofit/xroofit/src/xRooNLLVar.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx,1,['load'],['load']
Performance,"// load data",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RChunkLoader.hxx:3,load,load,3,tmva/tmva/inc/TMVA/RChunkLoader.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RChunkLoader.hxx,2,['load'],['load']
Performance,"// load default font (arialbd)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/graf/src/TTF.cxx:3,load,load,3,graf2d/graf/src/TTF.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/graf/src/TTF.cxx,1,['load'],['load']
Performance,"// load empty entry",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/test/readerarray_iterator.cxx:3,load,load,3,tree/treeplayer/test/readerarray_iterator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/test/readerarray_iterator.cxx,1,['load'],['load']
Performance,"// load events if no filters are given",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RChunkLoader.hxx:3,load,load,3,tmva/tmva/inc/TMVA/RChunkLoader.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RChunkLoader.hxx,1,['load'],['load']
Performance,"// load first entry of the branch. Yes, this is bad, and might have; // unexpected side effects for the user, esp as already looking at; // (and not just drawing) a branch triggers it.; // To prove just how ugly it is, we'll also have to const_cast the; // branch...",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TBranchBrowsable.cxx:3,load,load,3,tree/tree/src/TBranchBrowsable.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TBranchBrowsable.cxx,1,['load'],['load']
Performance,"// load first entry of the branch. Yes, this is bad, and might have; // unexpected side effects for the user, esp as already looking at; // (and not just drawing) a branch triggers it.; // To prove just how ugly it is, we'll also have to const_cast the; // branch...; //if (branch->GetReadEntry()==-1) branchNonCost->GetEntry(0);; // now get element; //TLeafObject* lo=(TLeafElement*)branchNonCost->GetListOfLeaves()->First();; //TObject* objContainer=(TObject*)((TBranchElement*)branch)->GetValuePointer();; //if (objContainer && objContainer->IsA()==TClonesArray::Class()); // contained=((TClonesArray*)objContainer)->GetClass();; // Currently we can peer into the nested TClonesArray, we need; // to update TBranchElement::GetValuePointer.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TBranchBrowsable.cxx:3,load,load,3,tree/tree/src/TBranchBrowsable.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TBranchBrowsable.cxx,1,['load'],['load']
Performance,"// load frequently used headers",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:3,load,load,3,bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx,1,['load'],['load']
Performance,"// load full entry",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/test/readerarray_iterator.cxx:3,load,load,3,tree/treeplayer/test/readerarray_iterator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/test/readerarray_iterator.cxx,1,['load'],['load']
Performance,"// load gs:0 -> GS segment register.; // load fs:0 -> FS segment register.; //; // This optimization is generally valid because the GNU TLS model defines that; // gs:0 (or fs:0 on X86-64) contains its own address. However, for X86-64 mode; // with 32-bit registers, as we get in ILP32 mode, those registers are first; // zero-extended to 64 bits and then added it to the base address, which gives; // unwanted results when the register holds a negative value.; // For more information see http://people.redhat.com/drepper/tls.pdf",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp:3,load,load,3,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,3,"['load', 'optimiz']","['load', 'optimization']"
Performance,// load hardening implies CFI protection,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Arch/X86.cpp:3,load,load,3,interpreter/llvm-project/clang/lib/Driver/ToolChains/Arch/X86.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Arch/X86.cpp,1,['load'],['load']
Performance,"// load histograms",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/histfactory/test/testHistFactoryPlotting.cxx:3,load,load,3,roofit/histfactory/test/testHistFactoryPlotting.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/histfactory/test/testHistFactoryPlotting.cxx,1,['load'],['load']
Performance,"// load input dies, resize Info structures array.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DWARFLinker/Parallel/DWARFLinkerCompileUnit.cpp:3,load,load,3,interpreter/llvm-project/llvm/lib/DWARFLinker/Parallel/DWARFLinkerCompileUnit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/DWARFLinker/Parallel/DWARFLinkerCompileUnit.cpp,1,['load'],['load']
Performance,"// load log2(e)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/batchcompute/res/RooHeterogeneousMath.h:3,load,load,3,roofit/batchcompute/res/RooHeterogeneousMath.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/batchcompute/res/RooHeterogeneousMath.h,1,['load'],['load']
Performance,"// load macros in alphabetical order",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TPluginManager.cxx:3,load,load,3,core/base/src/TPluginManager.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TPluginManager.cxx,1,['load'],['load']
Performance,"// load multiclass foams",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodPDEFoam.cxx:3,load,load,3,tmva/tmva/src/MethodPDEFoam.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodPDEFoam.cxx,1,['load'],['load']
Performance,"// load mva values and type to results object",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodBase.cxx:3,load,load,3,tmva/tmva/src/MethodBase.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodBase.cxx,1,['load'],['load']
Performance,// load null is undefined.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SCCPSolver.cpp:3,load,load,3,interpreter/llvm-project/llvm/lib/Transforms/Utils/SCCPSolver.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SCCPSolver.cpp,1,['load'],['load']
Performance,// load of a __strong object.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExpr.cpp:3,load,load,3,interpreter/llvm-project/clang/lib/CodeGen/CGExpr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExpr.cpp,1,['load'],['load']
Performance,// load of a __weak object.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExpr.cpp:3,load,load,3,interpreter/llvm-project/clang/lib/CodeGen/CGExpr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGExpr.cpp,2,['load'],['load']
Performance,"// load plugin",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/gui/src/TGuiBuilder.cxx:3,load,load,3,gui/gui/src/TGuiBuilder.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/gui/src/TGuiBuilder.cxx,2,['load'],['load']
Performance,"// load shadow tag in X6, X5 contains shadow base",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVAsmPrinter.cpp:3,load,load,3,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVAsmPrinter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVAsmPrinter.cpp,1,['load'],['load']
Performance,// load single image,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/modules/three.mjs:3,load,load,3,js/modules/three.mjs,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/modules/three.mjs,2,['load'],['load']
Performance,"// load snapshot value from the workspace",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/ModelConfig.cxx:3,load,load,3,roofit/roofitcore/src/ModelConfig.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/ModelConfig.cxx,1,['load'],['load']
Performance,"// load the PNG",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/winnt/src/Win32Splash.cxx:3,load,load,3,core/winnt/src/Win32Splash.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/winnt/src/Win32Splash.cxx,1,['load'],['load']
Performance,"// load the PNG image data into a stream",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/winnt/src/Win32Splash.cxx:3,load,load,3,core/winnt/src/Win32Splash.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/winnt/src/Win32Splash.cxx,1,['load'],['load']
Performance,"// load the bitmap with WIC",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/winnt/src/Win32Splash.cxx:3,load,load,3,core/winnt/src/Win32Splash.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/winnt/src/Win32Splash.cxx,1,['load'],['load']
Performance,// load the constructed double,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp:3,load,load,3,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/LegalizeDAG.cpp,1,['load'],['load']
Performance,"// load the first frame (i.e., the image)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/winnt/src/Win32Splash.cxx:3,load,load,3,core/winnt/src/Win32Splash.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/winnt/src/Win32Splash.cxx,1,['load'],['load']
Performance,"// load the glyph image (in its native format)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/graf/src/TTF.cxx:3,load,load,3,graf2d/graf/src/TTF.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/graf/src/TTF.cxx,1,['load'],['load']
Performance,"// load the next word, containing some packed items",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RColumnElement.cxx:3,load,load,3,tree/ntuple/v7/src/RColumnElement.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RColumnElement.cxx,1,['load'],['load']
Performance,"// load the pllType",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx:3,load,load,3,roofit/xroofit/src/xRooNLLVar.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx,1,['load'],['load']
Performance,"// load the plugin",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProofServ.cxx:3,load,load,3,proof/proof/src/TProofServ.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProofServ.cxx,1,['load'],['load']
Performance,"// load the toys",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx:3,load,load,3,roofit/xroofit/src/xRooNLLVar.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx,1,['load'],['load']
Performance,"// load the tree via the interpreter",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/treeviewer/src/TTreeViewer.cxx:3,load,load,3,tree/treeviewer/src/TTreeViewer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/treeviewer/src/TTreeViewer.cxx,1,['load'],['load']
Performance,"// load the tree via the interpreter; // define a global ""tree"" variable for the same tree",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/treeviewer/src/TTreeViewer.cxx:3,load,load,3,tree/treeviewer/src/TTreeViewer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/treeviewer/src/TTreeViewer.cxx,2,['load'],['load']
Performance,"// load track dictionary",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/genvector/test/testVectorIO.cxx:3,load,load,3,math/genvector/test/testVectorIO.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/test/testVectorIO.cxx,2,['load'],['load']
Performance,"// load track dictionary; // gSystem->Load(""libTrackDict"");",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/genvector/test/testVectorIO.cxx:3,load,load,3,math/genvector/test/testVectorIO.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/test/testVectorIO.cxx,2,"['Load', 'load']","['Load', 'load']"
Performance,// load v7 only by demand,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:3,load,load,3,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['load'],['load']
Performance,"// load(gep null, ...) -> unreachable; // load null/undef -> unreachable; // TODO: Consider a target hook for valid address spaces for this xforms.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp:3,load,load,3,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineLoadStoreAlloca.cpp,2,['load'],['load']
Performance,// load/store,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp:3,load,load,3,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVISelLowering.cpp,1,['load'],['load']
Performance,// load/store: add more corner cases,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86LegalizerInfo.cpp:3,load,load,3,interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86LegalizerInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/GISel/X86LegalizerInfo.cpp,1,['load'],['load']
Performance,// loadENDF; /* -------- BinSearch -------- */,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/test/periodic/NdbMTReactionXS.cxx:3,load,loadENDF,3,test/periodic/NdbMTReactionXS.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/test/periodic/NdbMTReactionXS.cxx,1,['load'],['loadENDF']
Performance,"// loaded style (from workspace?) so put in list and use that",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:3,load,loaded,3,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,1,['load'],['loaded']
Performance,"// loader is now in the output file, we dont need to save again",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Envelope.cxx:3,load,loader,3,tmva/tmva/src/Envelope.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Envelope.cxx,2,['load'],['loader']
Performance,"// loading val into error already, so move it over",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:3,load,loading,3,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,1,['load'],['loading']
Performance,// loadquery() was successful.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/libclang/CIndexer.cpp:3,load,loadquery,3,interpreter/llvm-project/clang/tools/libclang/CIndexer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/libclang/CIndexer.cpp,1,['load'],['loadquery']
Performance,"// loads current coordinates and populates coordRange, if any",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:3,load,loads,3,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,1,['load'],['loads']
Performance,// loads with vmovsh:,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/avx512fp16intrin.h:3,load,loads,3,interpreter/llvm-project/clang/lib/Headers/avx512fp16intrin.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/avx512fp16intrin.h,1,['load'],['loads']
Performance,"// location required to load files; // also it is name of modules path used in importmap",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/webcanv/triangle.cxx:24,load,load,24,tutorials/webcanv/triangle.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webcanv/triangle.cxx,1,['load'],['load']
Performance,"// log2(Cond ? X : Y) -> Cond ? log2(X) : log2(Y); // FIXME: missed optimization: if one of the hands of select is/contains; // undef, just directly pick the other one.; // FIXME: can both hands contain undef?; // FIXME: Require one use?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineMulDivRem.cpp:68,optimiz,optimization,68,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineMulDivRem.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineMulDivRem.cpp,1,['optimiz'],['optimization']
Performance,"// lookup can be re-entered recursively if running on a single thread. Run any; // outstanding MUs in case this query depends on them, otherwise this lookup; // will starve waiting for a result from an MU that is stuck in the queue.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/Core.cpp:226,queue,queue,226,interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/Core.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/Core.cpp,1,['queue'],['queue']
Performance,"// loop on j variables for not fixed i variables (forget that matrix is symmetric) - could be optimized",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/MinimTransformFunction.cxx:94,optimiz,optimized,94,math/mathcore/src/MinimTransformFunction.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/MinimTransformFunction.cxx,1,['optimiz'],['optimized']
Performance,"// loop over bins in this dimension and load _xin[] with new bin edges",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooGrid.cxx:40,load,load,40,roofit/roofitcore/src/RooGrid.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooGrid.cxx,1,['load'],['load']
Performance,"// loop over cache, and sum...",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAddition.cxx:13,cache,cache,13,roofit/roofitcore/src/RooAddition.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAddition.cxx,1,['cache'],['cache']
Performance,"// loop:; // %x = load %gep_i; // = ... %x; // store %y, %gep_i_plus_1; //; // =>; //; // ph:; // %x.initial = load %gep_0; // loop:; // %x.storeforward = phi [%x.initial, %ph] [%y, %loop]; // %x = load %gep_i <---- now dead; // = ... %x.storeforward; // store %y, %gep_i_plus_1",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp:18,load,load,18,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopLoadElimination.cpp,3,['load'],['load']
Performance,"// low level views are expensive to create, so cache them on the object instead",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPDataMember.cxx:47,cache,cache,47,bindings/pyroot/cppyy/CPyCppyy/src/CPPDataMember.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPDataMember.cxx,1,['cache'],['cache']
Performance,"// maddu and madd are unusual instructions in that on MIPS64 bits 63..31; // must be in canonical form, i.e. sign extended. For MIPS32, the operands; // of the multiply must have 32 or more sign bits, otherwise we cannot; // perform this optimization. We have to check this here as we're performing; // this optimization pre-legalization.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.cpp:225,perform,perform,225,interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsISelLowering.cpp,4,"['optimiz', 'perform']","['optimization', 'perform', 'performing']"
Performance,"// make sure that the Gpad and GUI libs are loaded",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/gui/src/TBrowser.cxx:44,load,loaded,44,core/gui/src/TBrowser.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/gui/src/TBrowser.cxx,3,['load'],['loaded']
Performance,"// make sure to always receive last on master, so that master knows when queue is done,; // which means workers are done as well, so if master is done everything is done:",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/Messenger.cxx:73,queue,queue,73,roofit/multiprocess/src/Messenger.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/Messenger.cxx,1,['queue'],['queue']
Performance,"// map ""pars"" to the map of Tuneparameter, make sure; // you never screw up this order!!",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/OptimizeConfigParameters.cxx:28,Tune,Tuneparameter,28,tmva/tmva/src/OptimizeConfigParameters.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/OptimizeConfigParameters.cxx,1,['Tune'],['Tuneparameter']
Performance,// mapping structure fontName > fontStyle > font key - performance layer. See addFont(),MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:55,perform,performance,55,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['perform'],['performance']
Performance,"// master fills queue with tasks",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/test/NoopJob.h:16,queue,queue,16,roofit/multiprocess/test/NoopJob.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/test/NoopJob.h,4,['queue'],['queue']
Performance,"// match variations of a^2 + 2*a*b + b^2; //; // to reuse the code between the FP and Int versions, the instruction OpCodes; // and constant types have been turned into template parameters.; //; // Mul2Rhs: The constant to perform the multiplicative equivalent of X*2 with;; // should be `m_SpecificFP(2.0)` for FP and `m_SpecificInt(1)` for Int; // (we're matching `X<<1` instead of `X*2` for Int)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp:223,perform,perform,223,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp,1,['perform'],['perform']
Performance,"// matrix-vector product:; // use apply(i) function for matrices. Tested (11/05/06) with using (i,j) but; // performances are slightly worse (not clear why); //==============================================================================; // meta_row_dot; //==============================================================================",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/inc/Math/MatrixFunctions.h:109,perform,performances,109,math/smatrix/inc/Math/MatrixFunctions.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/inc/Math/MatrixFunctions.h,1,['perform'],['performances']
Performance,"// max file entries to avg allowed ratio for cache-to-packet sync",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/inc/TPacketizerAdaptive.h:45,cache,cache-to-packet,45,proof/proofplayer/inc/TPacketizerAdaptive.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/inc/TPacketizerAdaptive.h,1,['cache'],['cache-to-packet']
Performance,"// maximize read event throughput",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/inc/ROOT/RIoUring.hxx:23,throughput,throughput,23,io/io/inc/ROOT/RIoUring.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/inc/ROOT/RIoUring.hxx,1,['throughput'],['throughput']
Performance,"// maximum of our slaves' performance index",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/inc/TPacketizer.h:26,perform,performance,26,proof/proofplayer/inc/TPacketizer.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/inc/TPacketizer.h,2,['perform'],['performance']
Performance,// maybe it is worth to check the performance improvement with the below formula??; // double X_pos(double y) const {return (std::sqrt(y/fA + fB*fB/(4.*fA*fA) - fC/fA) - fB/(2.*fA));}; /**. Calculates the smaller of the two x values corresponding to the; given y Value. <p>. ???????!!!!!!!!! And when there is none?? it looks like it will; crash?? what is sqrt (-1.0) ?. @param y the y Value for which the x Value is to be calculated. @return the smaller one of the two corresponding values. */,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/inc/Minuit2/MnParabola.h:34,perform,performance,34,math/minuit2/inc/Minuit2/MnParabola.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/inc/Minuit2/MnParabola.h,1,['perform'],['performance']
Performance,"// memVT is bogus. These intrinsics have IntrInaccessibleMemOnly attribute; // in order to model data exchange with other threads, but perform no real; // memory accesses.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:135,perform,perform,135,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,1,['perform'],['perform']
Performance,"// message comes from the master/queue socket (first element):",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/Messenger.cxx:33,queue,queue,33,roofit/multiprocess/src/Messenger.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/Messenger.cxx,2,['queue'],['queue']
Performance,"// message queue mutex",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/win32gdk/src/TGWin32.cxx:11,queue,queue,11,graf2d/win32gdk/src/TGWin32.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/win32gdk/src/TGWin32.cxx,1,['queue'],['queue']
Performance,"// method->SetBaseDir(eigenes base dir, gucken ob Fisher dir existiert, sonst erzeugen ); // check-for-unused-options is performed; may be overridden by derived; // classes",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodCategory.cxx:121,perform,performed,121,tmva/tmva/src/MethodCategory.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodCategory.cxx,1,['perform'],['performed']
Performance,"// minim.optimizeConst(true);",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/inc/RooStats/MaxLikelihoodEstimateTestStat.h:9,optimiz,optimizeConst,9,roofit/roostats/inc/RooStats/MaxLikelihoodEstimateTestStat.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/inc/RooStats/MaxLikelihoodEstimateTestStat.h,1,['optimiz'],['optimizeConst']
Performance,"// minimal allowed angle between up and fCamTrans Z vector; // Internal cached matrices and frustum planes",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLCamera.h:72,cache,cached,72,graf3d/gl/inc/TGLCamera.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLCamera.h,1,['cache'],['cached']
Performance,// minimal latency,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/ui5/canv/controller/Panel.controller.js:11,latency,latency,11,ui5/canv/controller/Panel.controller.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/ui5/canv/controller/Panel.controller.js,3,['latency'],['latency']
Performance,"// minimal timeout to reduce load, generate dummy only if client not submit new request immediately",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/modules/webwindow.mjs:29,load,load,29,js/modules/webwindow.mjs,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/modules/webwindow.mjs,1,['load'],['load']
Performance,"// move Error updator after Gradient since the Value is cached inside",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/FumiliBuilder.cxx:56,cache,cached,56,math/minuit2/src/FumiliBuilder.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/FumiliBuilder.cxx,1,['cache'],['cached']
Performance,// movq loads is a subset of reloc_riprel_4byte_relax_rex. It is a; // special case because COFF and Mach-O don't support ELF's more; // flexible R_X86_64_REX_GOTPCRELX relaxation.; // TODO: Support new relocation for REX2.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp:8,load,loads,8,interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp,1,['load'],['loads']
Performance,"// multi-thread execution might have scrambled events w.r.t. the original file, so we just check overall properties",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_snapshot.cxx:3,multi-thread,multi-thread,3,tree/dataframe/test/dataframe_snapshot.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_snapshot.cxx,1,['multi-thread'],['multi-thread']
Performance,"// multi-thread snapshot",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/InterfaceUtils.hxx:3,multi-thread,multi-thread,3,tree/dataframe/inc/ROOT/RDF/InterfaceUtils.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/InterfaceUtils.hxx,1,['multi-thread'],['multi-thread']
Performance,"// multikeySort(Vec.slice(I, J - I), Pos + 1), but with; // tail call optimization.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/StringTableBuilder.cpp:70,optimiz,optimization,70,interpreter/llvm-project/llvm/lib/MC/StringTableBuilder.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/StringTableBuilder.cpp,1,['optimiz'],['optimization']
Performance,"// mutable std::map<const RooHistPdf*,CacheAuxInfo*> _cacheAuxInfo ; //! Auxiliary Cache information (do not persist)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooFFTConvPdf.h:38,Cache,CacheAuxInfo,38,roofit/roofitcore/inc/RooFFTConvPdf.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooFFTConvPdf.h,2,['Cache'],"['Cache', 'CacheAuxInfo']"
Performance,"// namespace CSKYCP; /// CSKYConstantPoolValue - CSKY specific constantpool value. This is used to; /// represent PC-relative displacement between the address of the load; /// instruction and the constant being loaded, i.e. (&GV-(LPIC+8)).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/CSKY/CSKYConstantPoolValue.h:166,load,load,166,interpreter/llvm-project/llvm/lib/Target/CSKY/CSKYConstantPoolValue.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/CSKY/CSKYConstantPoolValue.h,2,['load'],"['load', 'loaded']"
Performance,"// namespace HistFactory; /**; * \ingroup HistFactory; * main function of the hist2workspace executable.; * It creates RooFit models from an xml config and files with histograms.; * See MakeModelAndMeasurementFast(), for further instructions.; * \param[in] argc number of CLI arguments; * \param[in] argv pointer to arguments; *; * -h Help; * -v Switch HistFactory message stream to INFO level.; * -vv Switch HistFactory message stream to DEBUG level.; * -disable_binned_fit_optimization Disable the binned fit optimization used in HistFactory since ROOT 6.28.; */",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/histfactory/src/hist2workspace.cxx:511,optimiz,optimization,511,roofit/histfactory/src/hist2workspace.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/histfactory/src/hist2workspace.cxx,1,['optimiz'],['optimization']
Performance,"// namespace Internal; /** \class RHistBufferedFill; Buffers calls to Fill(). Once the buffer is full, on destruction of when calling Flush(), it sends the; buffers off as an ideally vectorizable FillN() operation. It also serves as a; multi-threaded way of filling the same histogram, reducing the locking; frequency. The HIST template can be either a RHist instance, a RHistImpl instance, or; a RHistLockedFill instance.; **/",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/histv7/inc/ROOT/RHistBufferedFill.hxx:236,multi-thread,multi-threaded,236,hist/histv7/inc/ROOT/RHistBufferedFill.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/histv7/inc/ROOT/RHistBufferedFill.hxx,1,['multi-thread'],['multi-threaded']
Performance,"// namespace Internal; /// A replacement for the TMVA::Reader legacy interface.; /// Performs inference for TMVA models stored as XML files.; /// For neural network inference consider using [SOFIE](https://github.com/root-project/root/blob/master/tmva/sofie/README.md) instead.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RReader.hxx:85,Perform,Performs,85,tmva/tmva/inc/TMVA/RReader.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RReader.hxx,1,['Perform'],['Performs']
Performance,"// namespace Loc; //===----------------------------------------------------------------------===//; /// This class is used to track local variable information.; ///; /// Variables that have been optimized out hold the \c monostate alternative.; /// This is not distinguished from the case of a constructed \c DbgVariable; /// which has not be initialized yet.; ///; /// Variables can be created from allocas, in which case they're generated from; /// the MMI table. Such variables hold the \c Loc::MMI alternative which can; /// have multiple expressions and frame indices.; ///; /// Variables can be created from the entry value of registers, in which case; /// they're generated from the MMI table. Such variables hold the \c; /// EntryValueLoc alternative which can either have a single expression or; /// multiple *fragment* expressions.; ///; /// Variables can be created from \c DBG_VALUE instructions. Those whose; /// location changes over time hold a \c Loc::Multi alternative which uses \c; /// DebugLocListIndex and (optionally) \c DebugLocListTagOffset, while those; /// with a single location hold a \c Loc::Single alternative which use \c; /// ValueLoc and (optionally) a single \c Expr.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfDebug.h:195,optimiz,optimized,195,interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfDebug.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/AsmPrinter/DwarfDebug.h,1,['optimiz'],['optimized']
Performance,"// namespace clang; // operator new and delete aren't allowed inside namespaces.; /// Placement new for using the ASTContext's allocator.; ///; /// This placement form of operator new uses the ASTContext's allocator for; /// obtaining memory.; ///; /// IMPORTANT: These are also declared in clang/AST/ASTContextAllocate.h!; /// Any changes here need to also be made there.; ///; /// We intentionally avoid using a nothrow specification here so that the calls; /// to this operator will not perform a null check on the result -- the; /// underlying allocator never returns null pointers.; ///; /// Usage looks like this (assuming there's an ASTContext 'Context' in scope):; /// @code; /// // Default alignment (8); /// IntegerLiteral *Ex = new (Context) IntegerLiteral(arguments);; /// // Specific alignment; /// IntegerLiteral *Ex2 = new (Context, 4) IntegerLiteral(arguments);; /// @endcode; /// Memory allocated through this placement new operator does not need to be; /// explicitly freed, as ASTContext will free all of this memory when it gets; /// destroyed. Please note that you cannot use delete on the pointer.; ///; /// @param Bytes The number of bytes to allocate. Calculated by the compiler.; /// @param C The ASTContext that provides the allocator.; /// @param Alignment The alignment of the allocated memory (if the underlying; /// allocator supports it).; /// @return The allocated memory. Could be nullptr.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/AST/ASTContext.h:490,perform,perform,490,interpreter/llvm-project/clang/include/clang/AST/ASTContext.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/AST/ASTContext.h,1,['perform'],['perform']
Performance,"// namespace detail; /// The name of a declaration. In the common case, this just stores; /// an IdentifierInfo pointer to a normal name. However, it also provides; /// encodings for Objective-C selectors (optimizing zero- and one-argument; /// selectors, which make up 78% percent of all selectors in Cocoa.h),; /// special C++ names for constructors, destructors, and conversion functions,; /// and C++ overloaded operators.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/AST/DeclarationName.h:206,optimiz,optimizing,206,interpreter/llvm-project/clang/include/clang/AST/DeclarationName.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/AST/DeclarationName.h,1,['optimiz'],['optimizing']
Performance,"// namespace details; // Stores the number of elements for a type and whether this type is fixed; // (N-Elements) or scalable (e.g., SVE).; // - ElementCount::getFixed(1) : A scalar value.; // - ElementCount::getFixed(2) : A vector type holding 2 values.; // - ElementCount::getScalable(4) : A scalable vector type holding 4 values.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Support/TypeSize.h:117,scalab,scalable,117,interpreter/llvm-project/llvm/include/llvm/Support/TypeSize.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Support/TypeSize.h,2,['scalab'],['scalable']
Performance,// namespace llvm; // Algorithm-specific params for Ext-TSP. The values are tuned for the best; // performance of large-scale front-end bound binaries.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/CodeLayout.cpp:76,tune,tuned,76,interpreter/llvm-project/llvm/lib/Transforms/Utils/CodeLayout.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/CodeLayout.cpp,2,"['perform', 'tune']","['performance', 'tuned']"
Performance,"// namespace llvm; /// Fully generic combining of x86 shuffle instructions.; ///; /// This should be the last combine run over the x86 shuffle instructions. Once; /// they have been fully optimized, this will recursively consider all chains; /// of single-use shuffle instructions, build a generic model of the cumulative; /// shuffle operation, and check for simpler instructions which implement this; /// operation. We use this primarily for two purposes:; ///; /// 1) Collapse generic shuffles to specialized single instructions when; /// equivalent. In most cases, this is just an encoding size win, but; /// sometimes we will collapse multiple generic shuffles into a single; /// special-purpose shuffle.; /// 2) Look for sequences of shuffle instructions with 3 or more total; /// instructions, and replace them with the slightly more expensive SSSE3; /// PSHUFB instruction if available. We do this as the last combining step; /// to ensure we avoid using PSHUFB if we can implement the shuffle with; /// a suitable short sequence of other instructions. The PSHUFB will either; /// use a register or have to read from memory and so is slightly (but only; /// slightly) more expensive than the other shuffle instructions.; ///; /// Because this is inherently a quadratic operation (for each shuffle in; /// a chain, we recurse up the chain), the depth is limited to 8 instructions.; /// This should never be an issue in practice as the shuffle lowering doesn't; /// produce sequences of more than 8 instructions.; ///; /// FIXME: We will currently miss some cases where the redundant shuffling; /// would simplify under the threshold for PSHUFB formation because of; /// combine-ordering. To fix this, we should do the redundant instruction; /// combining in this recursive walk.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:188,optimiz,optimized,188,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['optimiz'],['optimized']
Performance,"// namespace llvm; /// cleanup - After running all passes, clean up pass manager cache.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/LegacyPassManager.cpp:81,cache,cache,81,interpreter/llvm-project/llvm/lib/IR/LegacyPassManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/LegacyPassManager.cpp,1,['cache'],['cache']
Performance,// namespace omp; /// OpenMP optimizations pass.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/IPO/OpenMPOpt.h:29,optimiz,optimizations,29,interpreter/llvm-project/llvm/include/llvm/Transforms/IPO/OpenMPOpt.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/IPO/OpenMPOpt.h,1,['optimiz'],['optimizations']
Performance,"// namespace sys; /// This interface provides simple read-only access to a block of memory, and; /// provides simple methods for reading files and standard input into a memory; /// buffer. In addition to basic access to the characters in the file, this; /// interface guarantees you can read one character past the end of the file,; /// and that this character will read as '\0'.; ///; /// The '\0' guarantee is needed to support an optimization -- it's intended to; /// be more efficient for clients which are reading all the data to stop; /// reading when they encounter a '\0' than to continually check the file; /// position to see if it has reached the end of the file.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Support/MemoryBuffer.h:433,optimiz,optimization,433,interpreter/llvm-project/llvm/include/llvm/Support/MemoryBuffer.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Support/MemoryBuffer.h,1,['optimiz'],['optimization']
Performance,// namespace vfs; /// The sample profiler data loader pass.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/IPO/SampleProfile.h:47,load,loader,47,interpreter/llvm-project/llvm/include/llvm/Transforms/IPO/SampleProfile.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Transforms/IPO/SampleProfile.h,1,['load'],['loader']
Performance,"// namespace; // --- Begin AlignVectors; // For brevity, only consider loads. We identify a group of loads where we; // know the relative differences between their addresses, so we know how they; // are laid out in memory (relative to one another). These loads can overlap,; // can be shorter or longer than the desired vector length.; // Ultimately we want to generate a sequence of aligned loads that will load; // every byte that the original loads loaded, and have the program use these; // loaded values instead of the original loads.; // We consider the contiguous memory area spanned by all these loads.; //; // Let's say that a single aligned vector load can load 16 bytes at a time.; // If the program wanted to use a byte at offset 13 from the beginning of the; // original span, it will be a byte at offset 13+x in the aligned data for; // some x>=0. This may happen to be in the first aligned load, or in the load; // following it. Since we generally don't know what the that alignment value; // is at compile time, we proactively do valigns on the aligned loads, so that; // byte that was at offset 13 is still at offset 13 after the valigns.; //; // This will be the starting point for making the rest of the program use the; // data loaded by the new loads.; // For each original load, and its users:; // %v = load ...; // ... = %v; // ... = %v; // we create; // %new_v = extract/combine/shuffle data from loaded/valigned vectors so; // it contains the same value as %v did before; // then replace all users of %v with %new_v.; // ... = %new_v; // ... = %new_v",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp:71,load,loads,71,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonVectorCombine.cpp,20,['load'],"['load', 'loaded', 'loads']"
Performance,"// namespace; //- static public members ----------------------------------------------------; /// Initialization method: setup the python interpreter and load the; /// ROOT module.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/tpython/src/TPython.cxx:154,load,load,154,bindings/tpython/src/TPython.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/tpython/src/TPython.cxx,1,['load'],['load']
Performance,"// namespace; /// Deduce the template arguments by comparing the list of parameter; /// types to the list of argument types, as in the parameter-type-lists of; /// function types (C++ [temp.deduct.type]p10).; ///; /// \param S The semantic analysis object within which we are deducing; ///; /// \param TemplateParams The template parameters that we are deducing; ///; /// \param Params The list of parameter types; ///; /// \param NumParams The number of types in \c Params; ///; /// \param Args The list of argument types; ///; /// \param NumArgs The number of types in \c Args; ///; /// \param Info information about the template argument deduction itself; ///; /// \param Deduced the deduced template arguments; ///; /// \param TDF bitwise OR of the TemplateDeductionFlags bits that describe; /// how template argument deduction is performed.; ///; /// \param PartialOrdering If true, we are performing template argument; /// deduction for during partial ordering for a call; /// (C++0x [temp.deduct.partial]).; ///; /// \returns the result of template argument deduction so far. Note that a; /// ""success"" result means that template argument deduction has not yet failed,; /// but it may still fail, later, for other reasons.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplateDeduction.cpp:835,perform,performed,835,interpreter/llvm-project/clang/lib/Sema/SemaTemplateDeduction.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaTemplateDeduction.cpp,2,['perform'],"['performed', 'performing']"
Performance,"// namespace; /// Does the analysis of the provided shuffle masks and performs the requested; /// actions on the vectors with the given shuffle masks. It tries to do it in; /// several steps.; /// 1. If the Base vector is not undef vector, resizing the very first mask to; /// have common VF and perform action for 2 input vectors (including non-undef; /// Base). Other shuffle masks are combined with the resulting after the 1 stage; /// and processed as a shuffle of 2 elements.; /// 2. If the Base is undef vector and have only 1 shuffle mask, perform the; /// action only for 1 vector with the given mask, if it is not the identity; /// mask.; /// 3. If > 2 masks are used, perform the remaining shuffle actions for 2; /// vectors, combing the masks properly between the steps.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp:70,perform,performs,70,interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp,4,['perform'],"['perform', 'performs']"
Performance,// namespace; /// Lazily initialize cache for required identifier information.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/NonnullGlobalConstantsChecker.cpp:36,cache,cache,36,interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/NonnullGlobalConstantsChecker.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Checkers/NonnullGlobalConstantsChecker.cpp,1,['cache'],['cache']
Performance,// namespace; /// Run checkers for load/store of a location.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/CheckerManager.cpp:35,load,load,35,interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/CheckerManager.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/Core/CheckerManager.cpp,1,['load'],['load']
Performance,"// namespace; /// Try to promote memory values to scalars by sinking stores out of the; /// loop and moving loads to before the loop. We do this by looping over; /// the stores in the loop, looking for stores to Must pointers which are; /// loop invariant.; ///",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp:108,load,loads,108,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LICM.cpp,1,['load'],['loads']
Performance,"// namespace; /// all_declared_ivar_begin - return first ivar declared in this class,; /// its extensions and its implementation. Lazily build the list on first; /// access.; ///; /// Caveat: The list returned by this method reflects the current; /// state of the parser. The cache will be updated for every ivar; /// added by an extension or the implementation when they are; /// encountered.; /// See also ObjCIvarDecl::Create().",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/DeclObjC.cpp:276,cache,cache,276,interpreter/llvm-project/clang/lib/AST/DeclObjC.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/DeclObjC.cpp,1,['cache'],['cache']
Performance,"// namespace; ////////////////////////////////////////////////////////////////////////////////; /// Write object to I/O buffer.; ///; /// This function assumes that the value in 'obj' is the value stored in; /// a pointer to a ""ptrClass"". The actual type of the object pointed to; /// can be any class derived from ""ptrClass"".; /// Return:; /// - 0: failure; /// - 1: success; /// - 2: truncated success (i.e actual class is missing. Only ptrClass saved.); ///; /// If 'cacheReuse' is true (default) upon seeing an object address a second time,; /// we record the offset where its was written the first time rather than streaming; /// the object a second time.; /// If 'cacheReuse' is false, we always stream the object. This allows the (re)use; /// of temporary object to store different data in the same buffer.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TBufferIO.cxx:470,cache,cacheReuse,470,io/io/src/TBufferIO.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TBufferIO.cxx,2,['cache'],['cacheReuse']
Performance,"// namespace; ///////////////////////////////////////////////////////////////////////////////; // CacheElem magic ////////////////////////////////////////////////////////////; ///////////////////////////////////////////////////////////////////////////////",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/src/RooLagrangianMorphFunc.cxx:98,Cache,CacheElem,98,roofit/roofit/src/RooLagrangianMorphFunc.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/src/RooLagrangianMorphFunc.cxx,1,['Cache'],['CacheElem']
Performance,"// need TFile::Open to load plugins if need be",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/src/TTreeProcessorMT.cxx:23,load,load,23,tree/treeplayer/src/TTreeProcessorMT.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/src/TTreeProcessorMT.cxx,1,['load'],['load']
Performance,"// need to clear the cache of the created integral - do this before deleting things!",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:21,cache,cache,21,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,1,['cache'],['cache']
Performance,"// need to ensure coefs, if any, are included in fit result retrieval so all pars are loaded",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:86,load,loaded,86,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,1,['load'],['loaded']
Performance,// need to fill cached value line numvischld,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:16,cache,cached,16,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['cache'],['cached']
Performance,"// need to set th epdf to clear the cache in ToyMCSampler; // pdf we must use is background pdf",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/HypoTestInverter.cxx:36,cache,cache,36,roofit/roostats/src/HypoTestInverter.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/HypoTestInverter.cxx,1,['cache'],['cache']
Performance,"// needsFrameIndexResolution - Do we need to perform FI resolution for; // this function. Normally, this is required only when the function; // has any stack objects. However, FI resolution actually has another job,; // not apparent from the title - it resolves callframesetup/destroy; // that were not simplified earlier.; // So, this is required for x86 functions that have push sequences even; // when there are no stack objects.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FrameLowering.cpp:45,perform,perform,45,interpreter/llvm-project/llvm/lib/Target/X86/X86FrameLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86FrameLowering.cpp,1,['perform'],['perform']
Performance,"// needsFrameIndexResolution - Do we need to perform FI resolution for; // this function. Normally, this is required only when the function; // has any stack objects. However, targets may want to override this.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/TargetFrameLowering.h:45,perform,perform,45,interpreter/llvm-project/llvm/include/llvm/CodeGen/TargetFrameLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/CodeGen/TargetFrameLowering.h,1,['perform'],['perform']
Performance,"// no Py_INCREF as no ownership; // perform the call, nullptr 'this' makes the other side allocate the memory",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPConstructor.cxx:36,perform,perform,36,bindings/pyroot/cppyy/CPyCppyy/src/CPPConstructor.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPConstructor.cxx,1,['perform'],['perform']
Performance,"// no change.; // GV is a declaration with no definition. Make sure to prevent any; // optimization that tries to take advantage of the actual definition; // being ""local"" because we have no influence on the memory layout of; // data sections and how ""close"" they are to the code.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/BackendPasses.cpp:87,optimiz,optimization,87,interpreter/cling/lib/Interpreter/BackendPasses.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/BackendPasses.cpp,1,['optimiz'],['optimization']
Performance,"// no existing cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx:15,cache,cache,15,tree/tree/src/TTree.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx,1,['cache'],['cache']
Performance,// no optimization,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:6,optimiz,optimization,6,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['optimiz'],['optimization']
Performance,// no ticks position optimization,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:21,optimiz,optimization,21,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,6,['optimiz'],['optimization']
Performance,// non-computable results can be safely cached,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryBuiltins.cpp:40,cache,cached,40,interpreter/llvm-project/llvm/lib/Analysis/MemoryBuiltins.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/MemoryBuiltins.cpp,1,['cache'],['cached']
Performance,"// not a leave node ... for further traversal,; // we inject the children into priority queue based on distance to it's bounding box",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx:88,queue,queue,88,geom/geom/src/TGeoParallelWorld.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx,2,['queue'],['queue']
Performance,// not actually a queue.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/CXXInheritance.cpp:18,queue,queue,18,interpreter/llvm-project/clang/lib/AST/CXXInheritance.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/CXXInheritance.cpp,1,['queue'],['queue']
Performance,"// not cached or failed call; try instantiation",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/TemplateProxy.cxx:7,cache,cached,7,bindings/pyroot/cppyy/CPyCppyy/src/TemplateProxy.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/TemplateProxy.cxx,1,['cache'],['cached']
Performance,"// not loaded yet so nothing to do",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx:7,load,loaded,7,roofit/xroofit/src/xRooNLLVar.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx,1,['load'],['loaded']
Performance,"// not relevant as the CPU load and the background may vary...",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/test/stressGUI.cxx:27,load,load,27,test/stressGUI.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/test/stressGUI.cxx,1,['load'],['load']
Performance,"// not so nice to use const_cast here, but the non-const version will only live in the cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/jsoninterface/src/JSONParser.cxx:87,cache,cache,87,roofit/jsoninterface/src/JSONParser.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/jsoninterface/src/JSONParser.cxx,1,['cache'],['cache']
Performance,"// note ... it may be sufficient here to do:; // nll.constOptimizeTestStatistic(RooAbsArg::ConfigChange, constOptimize>1 /* do tracking too if >1 */); //; // trigger a re-evaluate of which nodes to cache-and-track nll.constOptimizeTestStatistic(RooAbsArg::ValueChange,; // constOptimize>1); // update the cache values -- is this needed??; // this forces the optimization to be redone; // for now leave as a reinitialize though, until had a chance to test this properly",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx:198,cache,cache-and-track,198,roofit/xroofit/src/xRooNLLVar.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx,3,"['cache', 'optimiz']","['cache', 'cache-and-track', 'optimization']"
Performance,"// now construct normalization set for component from cset/nset spec; // if (normSet) {; // cout << ""RooVectorDaraStore::cacheArgs() component "" << arg->GetName() << "" has custom normalization set "" << *normSet << endl ;; // }",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooVectorDataStore.cxx:121,cache,cacheArgs,121,roofit/roofitcore/src/RooVectorDataStore.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooVectorDataStore.cxx,1,['cache'],['cacheArgs']
Performance,"// now hide all primitives to perform I/O",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/webgui6/src/TWebCanvas.cxx:30,perform,perform,30,gui/webgui6/src/TWebCanvas.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/webgui6/src/TWebCanvas.cxx,1,['perform'],['perform']
Performance,"// now loaded!",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:7,load,loaded,7,bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx,1,['load'],['loaded']
Performance,"// now loop over all the parameters and get for each combination the figure of merit; // in order to loop over all the parameters, I first create an ""array"" (tune parameters); // of arrays (the different values of the tune parameter)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/OptimizeConfigParameters.cxx:158,tune,tune,158,tmva/tmva/src/OptimizeConfigParameters.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/OptimizeConfigParameters.cxx,2,['tune'],['tune']
Performance,"// now we know the best enclosing R; // **and** we can fill the candidate set from the leaf priority queue easily",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx:101,queue,queue,101,geom/geom/src/TGeoParallelWorld.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx,1,['queue'],['queue']
Performance,"// now we know the best enclosing R; // **and** we can fill the candidate set from the priority queue easily",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx:96,queue,queue,96,geom/geom/src/TGeoParallelWorld.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx,1,['queue'],['queue']
Performance,"// npoints; // set parameters of the function to cache integral value",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Fit/FitUtil.h:49,cache,cache,49,math/mathcore/inc/Fit/FitUtil.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Fit/FitUtil.h,1,['cache'],['cache']
Performance,// ntl.all + load/store,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVInstrInfo.cpp:13,load,load,13,interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVInstrInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/RISCV/RISCVInstrInfo.cpp,1,['load'],['load']
Performance,"// nullptr is a valid value in the cache, so use find rather than []",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenTBAA.cpp:35,cache,cache,35,interpreter/llvm-project/clang/lib/CodeGen/CodeGenTBAA.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenTBAA.cpp,1,['cache'],['cache']
Performance,"// number of allowed entries in the window queue",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/webviewer/src/RGeomViewer.cxx:43,queue,queue,43,geom/webviewer/src/RGeomViewer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/webviewer/src/RGeomViewer.cxx,5,['queue'],['queue']
Performance,"// number of events in the real data for bin 'i'; // Cache the weighted fractions and the number of observed MC events; // Sanity check: none of the fractions should be == 0",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TFractionFitter.cxx:53,Cache,Cache,53,hist/hist/src/TFractionFitter.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TFractionFitter.cxx,1,['Cache'],['Cache']
Performance,"// nvvm.atomic.load.add.{f32.p,f64.p}",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/AutoUpgrade.cpp:15,load,load,15,interpreter/llvm-project/llvm/lib/IR/AutoUpgrade.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/AutoUpgrade.cpp,1,['load'],['load']
Performance,"// obtain a node from the node cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/jsoninterface/src/RYMLParser.cxx:31,cache,cache,31,roofit/jsoninterface/src/RYMLParser.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/jsoninterface/src/RYMLParser.cxx,1,['cache'],['cache']
Performance,"// obtain a string from the string cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/jsoninterface/src/RYMLParser.cxx:35,cache,cache,35,roofit/jsoninterface/src/RYMLParser.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/jsoninterface/src/RYMLParser.cxx,1,['cache'],['cache']
Performance,"// ok if buffer exists (can't perform any useful size checks)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Converters.cxx:30,perform,perform,30,bindings/pyroot/cppyy/CPyCppyy/src/Converters.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Converters.cxx,2,['perform'],['perform']
Performance,// on PIC code Load GA,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/Mips16ISelDAGToDAG.cpp:15,Load,Load,15,interpreter/llvm-project/llvm/lib/Target/Mips/Mips16ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/Mips16ISelDAGToDAG.cpp,2,['Load'],['Load']
Performance,// only HVX vgather instructions handled; // TODO: extend the pass to other vector load/store operations,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonOptAddrMode.cpp:83,load,load,83,interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonOptAddrMode.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/HexagonOptAddrMode.cpp,1,['load'],['load']
Performance,// only perform resize for certain image types,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:8,perform,perform,8,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['perform'],['perform']
Performance,// only perform resize if necessary,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:8,perform,perform,8,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['perform'],['perform']
Performance,"// optimization",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/guihtml/src/TGHtmlTable.cxx:3,optimiz,optimization,3,gui/guihtml/src/TGHtmlTable.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/guihtml/src/TGHtmlTable.cxx,1,['optimiz'],['optimization']
Performance,"// optimization, try to pre-allocate tris",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/CDT/Triangulation.h:3,optimiz,optimization,3,math/mathcore/src/CDT/Triangulation.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/CDT/Triangulation.h,1,['optimiz'],['optimization']
Performance,// optimization: hasDVA() is true only with explicit visibility.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/Decl.cpp:3,optimiz,optimization,3,interpreter/llvm-project/clang/lib/AST/Decl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/AST/Decl.cpp,1,['optimiz'],['optimization']
Performance,"// optimize all booked methods (well, if desired by the method)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/Factory.h:3,optimiz,optimize,3,tmva/tmva/inc/TMVA/Factory.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/Factory.h,1,['optimiz'],['optimize']
Performance,"// optimize the pruning sequence",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/CostComplexityPruneTool.h:3,optimiz,optimize,3,tmva/tmva/inc/TMVA/CostComplexityPruneTool.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/CostComplexityPruneTool.h,1,['optimiz'],['optimize']
Performance,"// optimize tuning parameters",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/MethodBase.h:3,optimiz,optimize,3,tmva/tmva/inc/TMVA/MethodBase.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/MethodBase.h,2,['optimiz'],['optimize']
Performance,"// optimize tuning parameters; // virtual std::map<TString,Double_t> OptimizeTuningParameters(TString fomType=""ROCIntegral"", TString; // fitType=""FitGA""); virtual void SetTuneParameters(std::map<TString,Double_t> tuneParameters);; // training method",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/MethodCrossValidation.h:3,optimiz,optimize,3,tmva/tmva/inc/TMVA/MethodCrossValidation.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/MethodCrossValidation.h,3,"['Optimiz', 'optimiz', 'tune']","['OptimizeTuningParameters', 'optimize', 'tuneParameters']"
Performance,"// optimize with fdiv.fast:; //; // a/b -> fdiv.fast(a, b) when !fpmath >= 2.5ulp with denormals flushed.; //; // 1/x -> fdiv.fast(1,x) when !fpmath >= 2.5ulp.; //; // NOTE: optimizeWithRcp should be tried first because rcp is the preference.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUCodeGenPrepare.cpp:3,optimiz,optimize,3,interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUCodeGenPrepare.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/AMDGPUCodeGenPrepare.cpp,2,['optimiz'],"['optimize', 'optimizeWithRcp']"
Performance,// optimizeExtInstr might have created new instructions after MI; // and before the already incremented MII. Adjust MII so that the; // next iteration sees the new instructions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/PeepholeOptimizer.cpp:3,optimiz,optimizeExtInstr,3,interpreter/llvm-project/llvm/lib/CodeGen/PeepholeOptimizer.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/PeepholeOptimizer.cpp,1,['optimiz'],['optimizeExtInstr']
Performance,"// optimized __iadd__",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx:3,optimiz,optimized,3,bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx,1,['optimiz'],['optimized']
Performance,"// optimizer etc passes",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:3,optimiz,optimizer,3,interpreter/cling/lib/Interpreter/IncrementalExecutor.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/Interpreter/IncrementalExecutor.h,1,['optimiz'],['optimizer']
Performance,"// optimizer functions",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/DNN/Architectures/Cpu.h:3,optimiz,optimizer,3,tmva/tmva/inc/TMVA/DNN/Architectures/Cpu.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/DNN/Architectures/Cpu.h,3,['optimiz'],['optimizer']
Performance,"// optimizer update functions; /// Update functions for ADAM optimizer",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h:3,optimiz,optimizer,3,tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h,2,['optimiz'],['optimizer']
Performance,"// optimizes model for evaluation",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/pymva/inc/TMVA/MethodPyKeras.h:3,optimiz,optimizes,3,tmva/pymva/inc/TMVA/MethodPyKeras.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/pymva/inc/TMVA/MethodPyKeras.h,1,['optimiz'],['optimizes']
Performance,"// or return a reasonable cache estimate for safety",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoNavigator.h:26,cache,cache,26,geom/geom/inc/TGeoNavigator.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoNavigator.h,1,['cache'],['cache']
Performance,"// otherwise we need to evaluate it and update the cache; // we evaluate this with saf_max = infinity to get the best; // possible safety value",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoNavigator.cxx:51,cache,cache,51,geom/geom/src/TGeoNavigator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoNavigator.cxx,1,['cache'],['cache']
Performance,"// otherwise, just use module optimization",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp:30,optimiz,optimization,30,interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Passes/PassBuilderPipelines.cpp,1,['optimiz'],['optimization']
Performance,"// overload stops here; // A successful instantiation needs to be cached to pre-empt future instantiations. There; // are two names involved, the original asked (which may be partial) and the received.; //; // Caching scheme: if the match is exact, simply add the overload to the pre-existing; // one, or create a new overload for later lookups. If the match is not exact, do the; // same, but also create an alias. Only add exact matches to the set of known template; // instantiations, to prevent piling on from different partial instantiations.; //; // TODO: this caches the lookup method before the call, meaning that failing overloads; // can add already existing overloads to the set of methods.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/TemplateProxy.cxx:66,cache,cached,66,bindings/pyroot/cppyy/CPyCppyy/src/TemplateProxy.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/TemplateProxy.cxx,2,['cache'],"['cached', 'caches']"
Performance,"// paramhistfunc requires the binnings to be loaded as default at construction time; // so load binning temporarily",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:45,load,loaded,45,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,2,['load'],"['load', 'loaded']"
Performance,"// path of the cached files.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFilePrefetch.cxx:15,cache,cached,15,io/io/src/TFilePrefetch.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFilePrefetch.cxx,1,['cache'],['cached']
Performance,"// perform Cholesky decomposition of matrix: M = L L^T; // only thing that can go wrong: trying to take square; // root of negative number or zero (matrix is; // ill-conditioned or singular in these cases); // element L(i,j) is at array position (i * (i+1)) / 2 + j; // quirk: we may need to invert L later anyway, so we can; // invert elements on diagonal straight away (we only; // ever need their reciprocals!); // cache starting address of rows of L for speed reasons",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/inc/Math/CholeskyDecomp.h:3,perform,perform,3,math/smatrix/inc/Math/CholeskyDecomp.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/inc/Math/CholeskyDecomp.h,2,"['cache', 'perform']","['cache', 'perform']"
Performance,"// perform K-S test",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmvagui/src/mvas.cxx:3,perform,perform,3,tmva/tmvagui/src/mvas.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmvagui/src/mvas.cxx,2,['perform'],['perform']
Performance,"// perform a chi2 fit on a set of binned data",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx:3,perform,perform,3,math/mathcore/src/Fitter.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx,1,['perform'],['perform']
Performance,"// perform a global fit of the likelihood letting with all parameter of interest and; // nuisance parameters; // keep the list of fitted parameters",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/ProfileLikelihoodCalculator.cxx:3,perform,perform,3,roofit/roostats/src/ProfileLikelihoodCalculator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/ProfileLikelihoodCalculator.cxx,1,['perform'],['perform']
Performance,"// perform a likelihood fit on a set of binned data; // The fit is extended (Poisson logl_ by default",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx:3,perform,perform,3,math/mathcore/src/Fitter.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx,1,['perform'],['perform']
Performance,"// perform a likelihood fit on a set of unbinned data",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx:3,perform,perform,3,math/mathcore/src/Fitter.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx,1,['perform'],['perform']
Performance,"// perform a linear fit on a set of binned data",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx:3,perform,perform,3,math/mathcore/src/Fitter.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx,1,['perform'],['perform']
Performance,"// perform a log binning if specified by user (option=""Log"") or if some conditions are met; // and the user explicitly does not specify a Linear binning option",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TF1.cxx:3,perform,perform,3,hist/hist/src/TF1.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TF1.cxx,1,['perform'],['perform']
Performance,"// perform a scan of the function in the parameter par",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/MnScan.cxx:3,perform,perform,3,math/minuit2/src/MnScan.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/MnScan.cxx,1,['perform'],['perform']
Performance,"// perform actual method call",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Dispatcher.cxx:3,perform,perform,3,bindings/pyroot/cppyy/CPyCppyy/src/Dispatcher.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Dispatcher.cxx,1,['perform'],['perform']
Performance,"// perform an iteration and update values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/src/GSLMinimizer1D.cxx:3,perform,perform,3,math/mathmore/src/GSLMinimizer1D.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/src/GSLMinimizer1D.cxx,1,['perform'],['perform']
Performance,"// perform calculation of Hessian",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit/src/TMinuitMinimizer.cxx:3,perform,perform,3,math/minuit/src/TMinuitMinimizer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit/src/TMinuitMinimizer.cxx,1,['perform'],['perform']
Performance,"// perform cast (the call will check TClass and addr, and set python errors)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/API.cxx:3,perform,perform,3,bindings/pyroot/cppyy/CPyCppyy/src/API.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/API.cxx,1,['perform'],['perform']
Performance,"// perform cast (the call will check TClass and addr, and set python errors); // give ownership, for ref-counting, to the python side, if so requested",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/tpython/src/TPython.cxx:3,perform,perform,3,bindings/tpython/src/TPython.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/tpython/src/TPython.cxx,1,['perform'],['perform']
Performance,"// perform event loop",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/DataSetFactory.cxx:3,perform,perform,3,tmva/tmva/src/DataSetFactory.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/DataSetFactory.cxx,5,['perform'],['perform']
Performance,"// perform fit of histograms, or graphs using new fitting classes; // use same routines for fitting both graphs and histograms",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/HFitImpl.cxx:3,perform,perform,3,hist/hist/src/HFitImpl.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/HFitImpl.cxx,1,['perform'],['perform']
Performance,"// perform inverse transformation",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodLD.cxx:3,perform,perform,3,tmva/tmva/src/MethodLD.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodLD.cxx,1,['perform'],['perform']
Performance,"// perform login",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/rpdutils/src/rpdutils.cxx:3,perform,perform,3,net/rpdutils/src/rpdutils.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/rpdutils/src/rpdutils.cxx,1,['perform'],['perform']
Performance,"// perform monitor operation at each interior-point iteration",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/quadp/inc/TQpSolverBase.h:3,perform,perform,3,math/quadp/inc/TQpSolverBase.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/quadp/inc/TQpSolverBase.h,1,['perform'],['perform']
Performance,"// perform permutation on matrix v",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/matrix/src/TDecompSVD.cxx:3,perform,perform,3,math/matrix/src/TDecompSVD.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/src/TDecompSVD.cxx,1,['perform'],['perform']
Performance,"// perform permutation on singular values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/matrix/src/TDecompSVD.cxx:3,perform,perform,3,math/matrix/src/TDecompSVD.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/src/TDecompSVD.cxx,1,['perform'],['perform']
Performance,"// perform permutation on vector u",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/matrix/src/TDecompSVD.cxx:3,perform,perform,3,math/matrix/src/TDecompSVD.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/src/TDecompSVD.cxx,1,['perform'],['perform']
Performance,"// perform product of matrix cov * hes * cov; // since we do not want to add matrix dependence do product by hand; // first do hes * cov",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx:3,perform,perform,3,math/mathcore/src/Fitter.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx,1,['perform'],['perform']
Performance,"// perform series of validation tests",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/PDF.h:3,perform,perform,3,tmva/tmva/inc/TMVA/PDF.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/PDF.h,1,['perform'],['perform']
Performance,// perform subdivision,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/modules/three.mjs:3,perform,perform,3,js/modules/three.mjs,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/modules/three.mjs,1,['perform'],['perform']
Performance,"// perform the actual fit; // set the fit to be a binned likelihood fit; // so use as chi2 for goodness of fit Baker&Cousins LR",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TBinomialEfficiencyFitter.cxx:3,perform,perform,3,hist/hist/src/TBinomialEfficiencyFitter.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TBinomialEfficiencyFitter.cxx,1,['perform'],['perform']
Performance,"// perform the actual solve using the factors produced in; // factor.; // rhs on input contains the aggregated right-hand side of; // the augmented system; on output contains the solution in; // aggregated form",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/quadp/inc/TQpLinSolverBase.h:3,perform,perform,3,math/quadp/inc/TQpLinSolverBase.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/quadp/inc/TQpLinSolverBase.h,1,['perform'],['perform']
Performance,"// perform the evaluation",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Classification.cxx:3,perform,perform,3,tmva/tmva/src/Classification.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Classification.cxx,2,['perform'],['perform']
Performance,"// perform the fit",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/genetic/test/GAMinTutorial.cxx:3,perform,perform,3,math/genetic/test/GAMinTutorial.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genetic/test/GAMinTutorial.cxx,4,['perform'],['perform']
Performance,"// perform the fit only if nuisance parameters are available; // get nuisance parameters; // nuisance parameters are the non const parameters from the likelihood parameters",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/ProfileLikelihoodCalculator.cxx:3,perform,perform,3,roofit/roostats/src/ProfileLikelihoodCalculator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/ProfileLikelihoodCalculator.cxx,1,['perform'],['perform']
Performance,"// perform the fit: if a fit is selected use only that one (order starts from 1)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/test/stressHistoFit.cxx:3,perform,perform,3,test/stressHistoFit.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/test/stressHistoFit.cxx,1,['perform'],['perform']
Performance,"// perform the minimization",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx:3,perform,perform,3,math/mathcore/src/Fitter.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx,1,['perform'],['perform']
Performance,"// perform the minimization (assume we have already initialized the minimizer)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx:3,perform,perform,3,math/mathcore/src/Fitter.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx,1,['perform'],['perform']
Performance,"// perform the minimization initializing the minimizer starting from a given obj function",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx:3,perform,perform,3,math/mathcore/src/Fitter.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx,1,['perform'],['perform']
Performance,"// perform the minimization initializing the minimizer starting from a given obj function; // and apply afterwards the correction for weights. This applies only for logL fitting",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx:3,perform,perform,3,math/mathcore/src/Fitter.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx,1,['perform'],['perform']
Performance,"// perform the minimization using the algorithm chosen previously by the user; // By default Migrad is used.; // Return true if the found minimum is valid and update internal cached values of; // minimum values, errors and covariance matrix.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/fumili/src/TFumiliMinimizer.cxx:3,perform,perform,3,math/fumili/src/TFumiliMinimizer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/fumili/src/TFumiliMinimizer.cxx,2,"['cache', 'perform']","['cached', 'perform']"
Performance,"// perform the minimization using the algorithm chosen previously by the user; // By default Migrad is used.; // Return true if the found minimum is valid and update internal cached values of; // minimum values, errors and covariance matrix.; // Status of minimizer is set to:; // migradResult + 10*minosResult + 100*hesseResult + 1000*improveResult",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit/src/TMinuitMinimizer.cxx:3,perform,perform,3,math/minuit/src/TMinuitMinimizer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit/src/TMinuitMinimizer.cxx,2,"['cache', 'perform']","['cached', 'perform']"
Performance,"// perform the minimization; // perform the minimization (assume we have already initialized the minimizer)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooMinimizer.cxx:3,perform,perform,3,roofit/roofitcore/src/RooMinimizer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooMinimizer.cxx,2,['perform'],['perform']
Performance,"// perform the minimization; // store a copy of FunctionMinimum",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/Minuit2Minimizer.cxx:3,perform,perform,3,math/minuit2/src/Minuit2Minimizer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/Minuit2Minimizer.cxx,1,['perform'],['perform']
Performance,"// perform the network prediction",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodDL.cxx:3,perform,perform,3,tmva/tmva/src/MethodDL.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodDL.cxx,1,['perform'],['perform']
Performance,"// perform the prediction",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodDL.cxx:3,perform,perform,3,tmva/tmva/src/MethodDL.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodDL.cxx,1,['perform'],['perform']
Performance,"// perform the projection operation required by Gondzio; // algorithm: replace each component r3_i of the; // complementarity component of the residuals by; // r3p_i-r3_i, where r3p_i is the projection of r3_i onto; // the box [rmin, rmax]. Then if the resulting value is; // less than -rmax, replace it by -rmax.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/quadp/inc/TQpResidual.h:3,perform,perform,3,math/quadp/inc/TQpResidual.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/quadp/inc/TQpResidual.h,1,['perform'],['perform']
Performance,"// performPRE() will trigger assert if it comes across an instruction without; // associated val-num. As it normally has far more live instructions than dead; // instructions, it makes more sense just to ""fabricate"" a val-number for the; // dead code than checking if instruction involved is dead or not.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp:3,perform,performPRE,3,interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/GVN.cpp,1,['perform'],['performPRE']
Performance,// performSelector families,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Basic/IdentifierTable.h:3,perform,performSelector,3,interpreter/llvm-project/clang/include/clang/Basic/IdentifierTable.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/include/clang/Basic/IdentifierTable.h,1,['perform'],['performSelector']
Performance,"// performance and mapping flags",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/winnt/src/TWinNTSystem.cxx:3,perform,performance,3,core/winnt/src/TWinNTSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/winnt/src/TWinNTSystem.cxx,3,['perform'],['performance']
Performance,"// performance evaluation",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/Factory.h:3,perform,performance,3,tmva/tmva/inc/TMVA/Factory.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/Factory.h,1,['perform'],['performance']
Performance,"// performing post-boosting actions",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodBoost.cxx:3,perform,performing,3,tmva/tmva/src/MethodBoost.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodBoost.cxx,1,['perform'],['performing']
Performance,"// performs a copy to float values which are internally used by all methods",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Reader.cxx:3,perform,performs,3,tmva/tmva/src/Reader.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Reader.cxx,1,['perform'],['performs']
Performance,"// performs classifier testing",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/pymva/inc/TMVA/MethodPyAdaBoost.h:3,perform,performs,3,tmva/pymva/inc/TMVA/MethodPyAdaBoost.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/pymva/inc/TMVA/MethodPyAdaBoost.h,7,['perform'],['performs']
Performance,"// performs classifier training",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/MethodCompositeBase.h:3,perform,performs,3,tmva/tmva/inc/TMVA/MethodCompositeBase.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/MethodCompositeBase.h,1,['perform'],['performs']
Performance,"// performs classifier training; // calls methods Train() implemented by derived classes",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/MethodBase.h:3,perform,performs,3,tmva/tmva/inc/TMVA/MethodBase.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/MethodBase.h,1,['perform'],['performs']
Performance,"// performs multiclass classifier testing",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/MethodBase.h:3,perform,performs,3,tmva/tmva/inc/TMVA/MethodBase.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/MethodBase.h,1,['perform'],['performs']
Performance,"// performs regression testing",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/MethodBase.h:3,perform,performs,3,tmva/tmva/inc/TMVA/MethodBase.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/MethodBase.h,1,['perform'],['performs']
Performance,"// performs the MethodBase testing + testing of each boosted classifier",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/MethodBoost.h:3,perform,performs,3,tmva/tmva/inc/TMVA/MethodBoost.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/MethodBoost.h,1,['perform'],['performs']
Performance,"// pow(1, inf) is defined to be 1 but exp2(log2(1) * inf) evaluates to NaN.; // Luckily optimizePow has already handled the x == 1 case.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp:88,optimiz,optimizePow,88,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp,1,['optimiz'],['optimizePow']
Performance,// prevent concurrent dumps from messing up the output file,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/TargetProcess/JITLoaderPerf.cpp:11,concurren,concurrent,11,interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/TargetProcess/JITLoaderPerf.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/ExecutionEngine/Orc/TargetProcess/JITLoaderPerf.cpp,2,['concurren'],['concurrent']
Performance,"// prevent more jobs from being added to the queue",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/thread/inc/TThreadPool.h:45,queue,queue,45,core/thread/inc/TThreadPool.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/thread/inc/TThreadPool.h,1,['queue'],['queue']
Performance,"// printf(""Basket size is greater than the cache size.\n"");",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx:43,cache,cache,43,tree/tree/src/TTreeCache.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx,1,['cache'],['cache']
Performance,"// printf(""Checking the miss cache for offset=%ld, length=%d\n"", pos, len);; // First, binary search to see if the desired basket is already cached.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx:29,cache,cache,29,tree/tree/src/TTreeCache.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx,2,['cache'],"['cache', 'cached']"
Performance,"// printf(""Data not in miss cache.\n"");; // Update the cache, looking for this (pos, len).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx:28,cache,cache,28,tree/tree/src/TTreeCache.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx,2,['cache'],['cache']
Performance,"// printf(""Expecting data at offset %ld in miss cache.\n"", offset);",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx:48,cache,cache,48,tree/tree/src/TTreeCache.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx,1,['cache'],['cache']
Performance,"// printf(""Reading %lu bytes into miss cache for %lu entries.\n"", cumulative, fEntries->size());",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx:39,cache,cache,39,tree/tree/src/TTreeCache.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx,1,['cache'],['cache']
Performance,"// printf(""Returning data from pos=%ld in miss cache.\n"", offset);",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx:47,cache,cache,47,tree/tree/src/TTreeCache.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx,1,['cache'],['cache']
Performance,"// printf(""TGLScene::SmartRefresh found cached: %p '%s' [%s] for %p\n"",; // l_shape, l_shape->GetExternal()->GetName(),; // l_shape->GetExternal()->IsA()->GetName(), (void*) ID);",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/src/TGLScene.cxx:40,cache,cached,40,graf3d/gl/src/TGLScene.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/src/TGLScene.cxx,1,['cache'],['cached']
Performance,"// printf(""Unable to pull data into miss cache.\n"");",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx:41,cache,cache,41,tree/tree/src/TTreeCache.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTreeCache.cxx,1,['cache'],['cache']
Performance,"// printf(""first send message to queue...\n"");",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/test/test_Messenger.cxx:33,queue,queue,33,roofit/multiprocess/test/test_Messenger.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/test/test_Messenger.cxx,1,['queue'],['queue']
Performance,"// printf(""performing calculations for merged set\n"");",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/physics/src/TRobustEstimator.cxx:11,perform,performing,11,math/physics/src/TRobustEstimator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/physics/src/TRobustEstimator.cxx,1,['perform'],['performing']
Performance,"// printf(""received %d on queue\n"", number);",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/test/test_Messenger.cxx:26,queue,queue,26,roofit/multiprocess/test/test_Messenger.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/test/test_Messenger.cxx,1,['queue'],['queue']
Performance,"// printf(""received %d on queue\n"", number);; /*number =*/",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/test/test_Messenger.cxx:26,queue,queue,26,roofit/multiprocess/test/test_Messenger.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/test/test_Messenger.cxx,1,['queue'],['queue']
Performance,"// printf(""send another message to queue...\n"");",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/test/test_Messenger.cxx:35,queue,queue,35,roofit/multiprocess/test/test_Messenger.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/test/test_Messenger.cxx,1,['queue'],['queue']
Performance,"// profitability - want hot exit in analyzeable set; // At this point, we have found an analyzeable latch, and a widenable; // condition above the loop. If we have a widenable exit within the loop; // (for which we can't compute exit counts), drop the ability to further; // widen so that we gain ability to analyze it's exit count and perform this; // transform. TODO: It'd be nice to know for sure the exit became; // analyzeable after dropping widenability.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopPredication.cpp:336,perform,perform,336,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopPredication.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopPredication.cpp,1,['perform'],['perform']
Performance,"// ptxas does not accept -g option if optimization is enabled, so; // we ignore the compiler's -O* options if we want debug info.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Cuda.cpp:38,optimiz,optimization,38,interpreter/llvm-project/clang/lib/Driver/ToolChains/Cuda.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Driver/ToolChains/Cuda.cpp,1,['optimiz'],['optimization']
Performance,// ptxas does not have a way to specify half-precision floats.; // Instead we have to print and load fp16 constants as .b16,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXMCExpr.cpp:96,load,load,96,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXMCExpr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXMCExpr.cpp,1,['load'],['load']
Performance,"// python strings kept for performance reasons",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/PyStrings.h:27,perform,performance,27,bindings/pyroot/cppyy/CPyCppyy/src/PyStrings.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/PyStrings.h,1,['perform'],['performance']
Performance,"// queue all pages waiting for consumption in the pipe before we give an; // answer",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/BidirMMapPipe.cxx:3,queue,queue,3,roofit/roofitcore/src/BidirMMapPipe.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/BidirMMapPipe.cxx,2,['queue'],['queue']
Performance,"// queue any pages available for reading we can without blocking",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/BidirMMapPipe.cxx:3,queue,queue,3,roofit/roofitcore/src/BidirMMapPipe.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/BidirMMapPipe.cxx,2,['queue'],['queue']
Performance,"// queue depth rounds up to next power of 2",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/test/RIoUring.cxx:3,queue,queue,3,io/io/test/RIoUring.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/test/RIoUring.cxx,1,['queue'],['queue']
Performance,"// queue for sending",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/BidirMMapPipe.cxx:3,queue,queue,3,roofit/roofitcore/src/BidirMMapPipe.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/BidirMMapPipe.cxx,1,['queue'],['queue']
Performance,// quick optimization to avoid having to intern strings that are already; // stored reliably elsewhere,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp:9,optimiz,optimization,9,interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGDebugInfo.cpp,1,['optimiz'],['optimization']
Performance,"// re-define the default error handler when loading the library",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/src/GSLError.cxx:44,load,loading,44,math/mathmore/src/GSLError.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/src/GSLError.cxx,1,['load'],['loading']
Performance,// re-queue uses of the now modified binary operator and fall; // through to the checks that remain.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyIndVar.cpp:6,queue,queue,6,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyIndVar.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyIndVar.cpp,1,['queue'],['queue']
Performance,// real drawing will be perform at the end,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:24,perform,perform,24,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['perform'],['perform']
Performance,"// real update will be performed by CheckDataToSend()",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/canvaspainter/src/RCanvasPainter.cxx:23,perform,performed,23,gui/canvaspainter/src/RCanvasPainter.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/canvaspainter/src/RCanvasPainter.cxx,1,['perform'],['performed']
Performance,"// rebinding to a Python-side class, create a fresh instance first to be able to; // perform a lookup of the original dispatch object and if found, return original",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPyCppyyModule.cxx:85,perform,perform,85,bindings/pyroot/cppyy/CPyCppyy/src/CPyCppyyModule.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPyCppyyModule.cxx,1,['perform'],['perform']
Performance,"// received draw messages; // if true, most operations are performed locally without involving server",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/ui5/geom/controller/GeomViewer.controller.js:59,perform,performed,59,ui5/geom/controller/GeomViewer.controller.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/ui5/geom/controller/GeomViewer.controller.js,2,['perform'],['performed']
Performance,"// recursive through all clients and sterlize their normalization caches",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:66,cache,caches,66,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,1,['cache'],['caches']
Performance,"// reference the cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/dcache/src/TDCacheFile.cxx:17,cache,cache,17,io/dcache/src/TDCacheFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/dcache/src/TDCacheFile.cxx,1,['cache'],['cache']
Performance,"// refuse loading of default web page without token",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/webdisplay/src/RWebWindowWSHandler.hxx:10,load,loading,10,gui/webdisplay/src/RWebWindowWSHandler.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/webdisplay/src/RWebWindowWSHandler.hxx,1,['load'],['loading']
Performance,"// refuse loading of default web page without valid key",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/webdisplay/src/RWebWindowWSHandler.hxx:10,load,loading,10,gui/webdisplay/src/RWebWindowWSHandler.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/webdisplay/src/RWebWindowWSHandler.hxx,1,['load'],['loading']
Performance,"// regularly call Process() method of engine to let perform actions in ROOT context",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/http/src/THttpServer.cxx:52,perform,perform,52,net/http/src/THttpServer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/src/THttpServer.cxx,1,['perform'],['perform']
Performance,"// relocation insn is a load, store or shift insn.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BTFDebug.cpp:24,load,load,24,interpreter/llvm-project/llvm/lib/Target/BPF/BTFDebug.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BTFDebug.cpp,1,['load'],['load']
Performance,"// remember that the user has requested an explicit cache setup",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx:52,cache,cache,52,tree/tree/src/TTree.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx,1,['cache'],['cache']
Performance,"// remember user has requested this cache setting",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TChain.cxx:36,cache,cache,36,tree/tree/src/TChain.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TChain.cxx,1,['cache'],['cache']
Performance,"// remove cached low level view, if any (will be restored upon reaeding)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPDataMember.cxx:10,cache,cached,10,bindings/pyroot/cppyy/CPyCppyy/src/CPPDataMember.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPDataMember.cxx,1,['cache'],['cached']
Performance,"// rename nll so if caching fit results will cache into subdir",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx:45,cache,cache,45,roofit/xroofit/src/xRooNLLVar.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx,1,['cache'],['cache']
Performance,"// replace the loaded object by a clone, as the loaded folder will delete the original; // can use a static_cast - confirmed validity by initial cast above.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/src/RooLagrangianMorphFunc.cxx:15,load,loaded,15,roofit/roofit/src/RooLagrangianMorphFunc.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/src/RooLagrangianMorphFunc.cxx,2,['load'],['loaded']
Performance,"// rescale legend box size; // current box size has been tuned for 3 MVAs + 1 title",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmvagui/src/efficiencies.cxx:57,tune,tuned,57,tmva/tmvagui/src/efficiencies.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmvagui/src/efficiencies.cxx,2,['tune'],['tuned']
Performance,"// reset cached limit values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/HypoTestInverterResult.cxx:9,cache,cached,9,roofit/roostats/src/HypoTestInverterResult.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/HypoTestInverterResult.cxx,2,['cache'],['cached']
Performance,"// reset map with cached limits - called every time the test size or CL has been changed",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/LikelihoodInterval.cxx:18,cache,cached,18,roofit/roostats/src/LikelihoodInterval.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/LikelihoodInterval.cxx,1,['cache'],['cached']
Performance,"// reset our cache status tracking in case existing cache was added; // by the user without using one of the TTree methods",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx:13,cache,cache,13,tree/tree/src/TTree.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx,2,['cache'],['cache']
Performance,"// reset the reading from the second line, because the first line is already loaded in `columns`",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RCsvDS.cxx:77,load,loaded,77,tree/dataframe/src/RCsvDS.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/src/RCsvDS.cxx,1,['load'],['loaded']
Performance,"// restore ignore level; // Retry by loading first the libraries listed in TQueryResult, if any",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/src/TProofPlayer.cxx:37,load,loading,37,proof/proofplayer/src/TProofPlayer.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proofplayer/src/TProofPlayer.cxx,1,['load'],['loading']
Performance,"// restore the cache to every node",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:15,cache,cache,15,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,1,['cache'],['cache']
Performance,"// resume.entry:; // %index.addr = getelementptr inbounds %f.Frame, %f.Frame* %FramePtr, i32 0,; // i32 2; // % index = load i32, i32* %index.addr; // switch i32 %index, label %unreachable [; // i32 0, label %resume.0; // i32 1, label %resume.1; // ...; // ]",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Coroutines/CoroSplit.cpp:120,load,load,120,interpreter/llvm-project/llvm/lib/Transforms/Coroutines/CoroSplit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Coroutines/CoroSplit.cpp,1,['load'],['load']
Performance,"// retrieve from cache worked, no need to generate dataset",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx:17,cache,cache,17,roofit/xroofit/src/xRooNLLVar.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx,4,['cache'],['cache']
Performance,// return Promise with mathjax loading,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:31,load,loading,31,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['load'],['loading']
Performance,"// return cached value",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/src/GSLRootFinder.cxx:10,cache,cached,10,math/mathmore/src/GSLRootFinder.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/src/GSLRootFinder.cxx,2,['cache'],['cached']
Performance,"// return std::shared_ptr<RooFitResult>(cachedFit,[](RooFitResult*){}); // dir owns the; // fitResult - this means dir needs to stay open for fits to be valid return; // std::make_shared<RooFitResult>(*cachedFit); // return a copy ... dir doesn't need to stay; // open, but fit result isn't shared",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx:40,cache,cachedFit,40,roofit/xroofit/src/xRooFit.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx,2,['cache'],['cachedFit']
Performance,"// revive the (sterilized) cache; //cout << ""RooRealSumPdf(""<<this<<"")::analyticalIntegralWN:""<<GetName()<<""(""<<code<<"",""<<(normSet2?*normSet2:RooArgSet())<<"",""<<(rangeName?rangeName:""<none>"") << "": reviving cache ""<< endl;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooRealSumPdf.cxx:27,cache,cache,27,roofit/roofitcore/src/RooRealSumPdf.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooRealSumPdf.cxx,2,['cache'],['cache']
Performance,"// run multi-thread tests",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_incomplete_entries.cxx:7,multi-thread,multi-thread,7,tree/dataframe/test/dataframe_incomplete_entries.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_incomplete_entries.cxx,3,['multi-thread'],['multi-thread']
Performance,// runOnLoop - This method should be implemented by the subclass to perform; // whatever action is necessary for the specified Loop.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/LoopPass.h:68,perform,perform,68,interpreter/llvm-project/llvm/include/llvm/Analysis/LoopPass.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Analysis/LoopPass.h,1,['perform'],['perform']
Performance,// running first pass with TargetOccupancy = 0 mimics previous scheduling; // approach and is a performance magic,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNIterativeScheduler.cpp:96,perform,performance,96,interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNIterativeScheduler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/GCNIterativeScheduler.cpp,1,['perform'],['performance']
Performance,"// s_buffer_load, because of how it's optimized, can't be volatile; // so reject ones with the volatile bit set.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:38,optimiz,optimized,38,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,1,['optimiz'],['optimized']
Performance,"// sancov_pcs parallels the other metadata section(s). Optimizers (e.g.; // GlobalOpt/ConstantMerge) may not discard sancov_pcs and the other; // section(s) as a unit, so we conservatively retain all unconditionally in; // the compiler.; //; // With comdat (COFF/ELF), the linker can guarantee the associated sections; // will be retained or discarded as a unit, so llvm.compiler.used is; // sufficient. Otherwise, conservatively make all of them retained by the; // linker.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/SanitizerCoverage.cpp:55,Optimiz,Optimizers,55,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/SanitizerCoverage.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/SanitizerCoverage.cpp,1,['Optimiz'],['Optimizers']
Performance,"// sanitizeWS(); // clears the caches that might exist up to now, as well interfere with getParameters calls",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:31,cache,caches,31,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,1,['cache'],['caches']
Performance,"// save PDF to a file as a TH2F *, TTree * or both; // this is so that you only need to compute the PDF once and; // are free to use the much faster Roo2DHistPdf class in order; // to perform fits/do toy studies etc.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/inc/Roo2DKeysPdf.h:184,perform,perform,184,roofit/roofit/inc/Roo2DKeysPdf.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/inc/Roo2DKeysPdf.h,1,['perform'],['perform']
Performance,"// save a lot of GetName() calls if compiler does not already optimize this",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/MCMCInterval.cxx:62,optimiz,optimize,62,roofit/roostats/src/MCMCInterval.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/MCMCInterval.cxx,1,['optimiz'],['optimize']
Performance,"// save any fitDatabase that is loaded in memory too; // TODO: We should do this as well for SaveAs on a scan object",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:32,load,loaded,32,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,1,['load'],['loaded']
Performance,// scalable vector,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp:3,scalab,scalable,3,interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/GlobalISel/CombinerHelper.cpp,2,['scalab'],['scalable']
Performance,"// second argument is 1 because this rounding; // is always exact.; // The output of the permutation is our loaded result, the TokenFactor is; // our new chain.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp:108,load,loaded,108,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelLowering.cpp,1,['load'],['loaded']
Performance,// section is not loaded,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MCParser/COFFAsmParser.cpp:18,load,loaded,18,interpreter/llvm-project/llvm/lib/MC/MCParser/COFFAsmParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/MC/MCParser/COFFAsmParser.cpp,1,['load'],['loaded']
Performance,"// seems I have to remake the function each time, as haven't figured out what cache needs clearing?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:78,cache,cache,78,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,2,['cache'],['cache']
Performance,"// select(mask, mload(,,mask,0), 0) -> mload(,,mask,0); // Load inst is intentionally not checked for hasOneUse()",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineSelect.cpp:59,Load,Load,59,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineSelect.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineSelect.cpp,1,['Load'],['Load']
Performance,"// selectany symbols are externally visible, so use weak instead of; // linkonce. MSVC optimizes away references to const selectany globals, so; // all definitions should be the same and ODR linkage should be used.; // http://msdn.microsoft.com/en-us/library/5tkz6s71.aspx",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenModule.cpp:87,optimiz,optimizes,87,interpreter/llvm-project/clang/lib/CodeGen/CodeGenModule.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CodeGenModule.cpp,1,['optimiz'],['optimizes']
Performance,"// set a 10 MBytes cache (useless when writing local files)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/test/MainEvent.cxx:19,cache,cache,19,test/MainEvent.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/test/MainEvent.cxx,1,['cache'],['cache']
Performance,"// set flag to compute Minos error to false in FitConfig to avoid that; // following minimizaiton calls perform unwanted Minos error calculations; /// fConfig.SetMinosErrors(false);",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx:104,perform,perform,104,math/mathcore/src/Fitter.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/Fitter.cxx,1,['perform'],['perform']
Performance,"// set initial values and create cached vector",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/src/GSLMultiRootSolver.h:33,cache,cached,33,math/mathmore/src/GSLMultiRootSolver.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/src/GSLMultiRootSolver.h,1,['cache'],['cached']
Performance,"// set isTailCall to false for now, until we figure out how to express; // tail call optimization in PTX",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:85,optimiz,optimization,85,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,1,['optimiz'],['optimization']
Performance,"// set isWeakAccess to true, to mean that there will be an implicit; // load which requires a cleanup.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp:72,load,load,72,interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaInit.cpp,1,['load'],['load']
Performance,"// set of classes to compare the performance of STL vector versus; // native Root TClonesArray.; // See main program bench.cxx",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/test/TBench.cxx:33,perform,performance,33,test/TBench.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/test/TBench.cxx,1,['perform'],['performance']
Performance,"// set parameters of the function to cache integral value",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Fit/FitUtil.h:37,cache,cache,37,math/mathcore/inc/Fit/FitUtil.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Fit/FitUtil.h,3,['cache'],['cache']
Performance,"// set server state and update the queue under lock; //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve7/src/REveManager.cxx:35,queue,queue,35,graf3d/eve7/src/REveManager.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve7/src/REveManager.cxx,1,['queue'],['queue']
Performance,"// set the integrand function and create required wrapper; // to perform integral in (x) of a generic f(x,p)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Fit/FitUtil.h:65,perform,perform,65,math/mathcore/inc/Fit/FitUtil.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Fit/FitUtil.h,1,['perform'],['perform']
Performance,"// set the parameter values in the cached fX vector; // make const because it might be called from const methods",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Math/WrappedParamFunction.h:35,cache,cached,35,math/mathcore/inc/Math/WrappedParamFunction.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Math/WrappedParamFunction.h,1,['cache'],['cached']
Performance,"// sets up the matrix for the main linear system in; // ""augmented system"" form. The actual factorization is; // performed by a routine specific to either the sparse; // or dense case",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/quadp/inc/TQpLinSolverBase.h:113,perform,performed,113,math/quadp/inc/TQpLinSolverBase.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/quadp/inc/TQpLinSolverBase.h,1,['perform'],['performed']
Performance,"// setup NoneType for referencing and create weakref cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/MemoryRegulator.cxx:53,cache,cache,53,bindings/pyroot/cppyy/CPyCppyy/src/MemoryRegulator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/MemoryRegulator.cxx,1,['cache'],['cache']
Performance,"// setup the dispatch cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.cxx:22,cache,cache,22,bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPMethod.cxx,1,['cache'],['cache']
Performance,"// setups the needed variables, loads the model",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/pymva/inc/TMVA/MethodPyKeras.h:32,load,loads,32,tmva/pymva/inc/TMVA/MethodPyKeras.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/pymva/inc/TMVA/MethodPyKeras.h,2,['load'],['loads']
Performance,"// should maybe be optimized ???",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/test/WrapperRooPdf.h:19,optimiz,optimized,19,roofit/roofit/test/WrapperRooPdf.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/test/WrapperRooPdf.h,1,['optimiz'],['optimized']
Performance,"// shouldIgnoreMacro() in ASTWriter also stops at macros from the; // predefines buffer in module builds. However, in module builds, modules; // are loaded completely before predefines are processed, so StoredMD; // will be nullptr for them when they're loaded. StoredMD should only be; // non-nullptr for builtins read from a pch file.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/PPMacroExpansion.cpp:149,load,loaded,149,interpreter/llvm-project/clang/lib/Lex/PPMacroExpansion.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Lex/PPMacroExpansion.cpp,2,['load'],['loaded']
Performance,"// shuffle_vector can only interleave fixed length vectors - for scalable; // vectors, see the @llvm.experimental.vector.interleave2 intrinsic",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/Instructions.cpp:65,scalab,scalable,65,interpreter/llvm-project/llvm/lib/IR/Instructions.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/IR/Instructions.cpp,1,['scalab'],['scalable']
Performance,// signed gather loads,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:17,load,loads,17,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['load'],['loads']
Performance,"// similarly fold (and (X (load ([non_ext|any_ext|zero_ext] V))), c) ->; // (X (load ([non_ext|zero_ext] V))) if 'and' only clears top bits which must; // already be zero by virtue of the width of the base type of the load.; //; // the 'X' node here can either be nothing or an extract_vector_elt to catch; // more cases.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp:27,load,load,27,interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp,3,['load'],['load']
Performance,// simple workaround to wait until modules are loaded,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/scripts/geoworker.js:47,load,loaded,47,js/scripts/geoworker.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/scripts/geoworker.js,1,['load'],['loaded']
Performance,"// simply generate and load kDim uniform random numbers",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/foam/src/TFoam.cxx:23,load,load,23,math/foam/src/TFoam.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/foam/src/TFoam.cxx,2,['load'],['load']
Performance,"// simply use relative move from point, can optimize in the future",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:44,optimiz,optimize,44,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,4,['optimiz'],['optimize']
Performance,"// simulate some latency",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/RStreamingDS.hxx:17,latency,latency,17,tree/dataframe/test/RStreamingDS.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/RStreamingDS.hxx,1,['latency'],['latency']
Performance,"// since sDiag(k) == 0 perform Givens transform with result oDiag[k] = 0",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/matrix/src/TDecompSVD.cxx:23,perform,perform,23,math/matrix/src/TDecompSVD.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/src/TDecompSVD.cxx,1,['perform'],['perform']
Performance,"// sint_to_fp (fp_to_sint X) --> extelt (sint_to_fp (fp_to_sint (s2v X))), 0; //; // We are not defining the high elements (for example, zero them) because; // that could nullify any performance advantage that we hoped to gain from; // this vector op hack. We do not expect any adverse effects (like denorm; // penalties) with cast ops.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:183,perform,performance,183,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['perform'],['performance']
Performance,"// skip 'CACHE' sets because they are auto-removed when sanitizing workspaces, which will invalidate these; // children",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:9,CACHE,CACHE,9,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,1,['CACHE'],['CACHE']
Performance,"// skip the implied multiplication.; // For consistency and for Optimize to work correctly; // we need to remove the ""-1"" string in fExpr",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TFormula_v5.cxx:64,Optimiz,Optimize,64,hist/hist/src/TFormula_v5.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TFormula_v5.cxx,1,['Optimiz'],['Optimize']
Performance,// slm addq\subq throughput is 4,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:17,throughput,throughput,17,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,1,['throughput'],['throughput']
Performance,// slm pblendvb/blendvpd/blendvps throughput is 4,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:34,throughput,throughput,34,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,1,['throughput'],['throughput']
Performance,// slm pcmpeq/pcmpgt throughput is 2,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:21,throughput,throughput,21,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,1,['throughput'],['throughput']
Performance,"// so that caller caches the method on full name",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPScope.cxx:18,cache,caches,18,bindings/pyroot/cppyy/CPyCppyy/src/CPPScope.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPScope.cxx,1,['cache'],['caches']
Performance,"// some common numeric types (separated out for performance: checking for; // __cpp_name__ and/or __name__ is rather expensive)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Utility.cxx:48,perform,performance,48,bindings/pyroot/cppyy/CPyCppyy/src/Utility.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Utility.cxx,1,['perform'],['performance']
Performance,"// some enums are not loaded as they are not considered part of; // the global scope, but of the enum scope; get them w/o checking",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:22,load,loaded,22,bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx,1,['load'],['loaded']
Performance,"// sort again each variable for all events - needs this before Optimize(); // rescaling has changed variable values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/ModulekNN.cxx:63,Optimiz,Optimize,63,tmva/tmva/src/ModulekNN.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/ModulekNN.cxx,1,['Optimiz'],['Optimize']
Performance,"// sort each variable for all events - needs this before Optimize() and ComputeMetric()",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/ModulekNN.cxx:57,Optimiz,Optimize,57,tmva/tmva/src/ModulekNN.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/ModulekNN.cxx,1,['Optimiz'],['Optimize']
Performance,"// sort slaves by descending performance index",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProof.cxx:29,perform,performance,29,proof/proof/src/TProof.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/proof/src/TProof.cxx,1,['perform'],['performance']
Performance,"// sort, so that we can perform a binary search",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachinePipeliner.cpp:24,perform,perform,24,interpreter/llvm-project/llvm/lib/CodeGen/MachinePipeliner.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/MachinePipeliner.cpp,1,['perform'],['perform']
Performance,"// special cases:; // 1) for Thumb1 code we sometimes materialize the constant via constpool; // load.; // 2) for Thumb1 execute only code we materialize the constant via the; // following pattern:; // movs r3, #:upper8_15:<const>; // lsls r3, #8; // adds r3, #:upper0_7:<const>; // lsls r3, #8; // adds r3, #:lower8_15:<const>; // lsls r3, #8; // adds r3, #:lower0_7:<const>; // So we need to special-case MOVS, ADDS and LSLS, and keep track of; // where we are in the sequence with the simplest of state machines.; // 3) for Thumb2 execute only code we materialize the constant via; // immediate constants in 2 separate instructions (MOVW/MOVT).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMAsmPrinter.cpp:97,load,load,97,interpreter/llvm-project/llvm/lib/Target/ARM/ARMAsmPrinter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMAsmPrinter.cpp,1,['load'],['load']
Performance,"// special mode when window communication performed in THttpServer::ProcessRequests; // used only with python which create special thread - but is has to be ignored!!!; // therefore use main thread id to detect callbacks which are invoked only from that main thread",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/webdisplay/src/RWebWindowsManager.cxx:42,perform,performed,42,gui/webdisplay/src/RWebWindowsManager.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/webdisplay/src/RWebWindowsManager.cxx,1,['perform'],['performed']
Performance,"// specify which extra module should be loaded,; // ""tutorials_webcanv/"" is registered path from server locations",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/webcanv/triangle.cxx:40,load,loaded,40,tutorials/webcanv/triangle.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webcanv/triangle.cxx,1,['load'],['loaded']
Performance,// ssa_copy intrinsics are introduced by the SCCP solver. These intrinsics; // interfere with the promoteConstantStackValues() optimization.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionSpecialization.cpp:127,optimiz,optimization,127,interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionSpecialization.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/FunctionSpecialization.cpp,1,['optimiz'],['optimization']
Performance,"// stack store/load sequence, if not optimized to anything else.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.h:15,load,load,15,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.h,2,"['load', 'optimiz']","['load', 'optimized']"
Performance,// start loading the image as early as possible,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:9,load,loading,9,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['load'],['loading']
Performance,"// state of each input to whether the dynamic output of the instruction; // produces poison.; // 3) A creation rule which validates any poison producing flags on the; // instruction itself (e.g. checks for overflow on nsw).; // 4) A check rule which traps (to a handler function) if this instruction must; // execute undefined behavior given the poison state of it's inputs.; //; // This is a must analysis based transform; that is, the resulting code may; // produce a false negative result (not report UB when actually exists; // according to the LangRef spec), but should never produce a false positive; // (report UB where it doesn't exist).; //; // Use cases for this pass include:; // - Understanding (and testing!) the implications of the definition of poison; // from the LangRef.; // - Validating the output of a IR fuzzer to ensure that all programs produced; // are well defined on the specific input used.; // - Finding/confirming poison specific miscompiles by checking the poison; // status of an input/IR pair is the same before and after an optimization; // transform.; // - Checking that a bugpoint reduction does not introduce UB which didn't; // exist in the original program being reduced.; //; // The major sources of inaccuracy are currently:; // - Most validation rules not yet implemented for instructions with poison; // relavant flags. At the moment, only nsw/nuw on add/sub are supported.; // - UB which is control dependent on a branch on poison is not yet; // reported. Currently, only data flow dependence is modeled.; // - Poison which is propagated through memory is not modeled. As such,; // storing poison to memory and then reloading it will cause a false negative; // as we consider the reloaded value to not be poisoned.; // - Poison propagation across function boundaries is not modeled. At the; // moment, all arguments and return values are assumed not to be poison.; // - Undef is not modeled. In particular, the optimizer's freedom to pick; // concrete values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/PoisonChecking.cpp:2148,optimiz,optimization,2148,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/PoisonChecking.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/PoisonChecking.cpp,1,['optimiz'],['optimization']
Performance,"// state shared between different runs for performance gains",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/CDT/Triangulation.h:43,perform,performance,43,math/mathcore/src/CDT/Triangulation.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/CDT/Triangulation.h,1,['perform'],['performance']
Performance,"// static bool IsSupportedClass(TClass *cl); // {; // // Check if the Class is of an unsupported type; // using namespace ROOT::TMetaUtils;; //; // // Check if this is a collection of unique_ptrs; // if (ROOT::ESTLType::kNotSTL != cl->GetCollectionType()) {; // std::vector<std::string> out;; // int i;; // TClassEdit::GetSplit(cl->GetName(), out, i);; // std::string_view containedObjectTypeName(out[1].c_str());; // if (TClassEdit::IsUniquePtr(containedObjectTypeName)) {; // auto clName = cl->GetName();; // // Here we can use the new name for the error message; // Error(""CloseStreamerInfoROOTFile"", ""A collection of unique pointers was selected: %s. These are not supported. If you wish to perform I/O operations with %s, just select the same collection of raw C pointers.\n"", clName, clName);; // return false;; // }; // }; // return true;; //; // }",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/rootpcm/src/rootclingIO.cxx:695,perform,perform,695,io/rootpcm/src/rootclingIO.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/rootpcm/src/rootclingIO.cxx,1,['perform'],['perform']
Performance,"// static x(4); // 'x' is not a type; // x(int n); // 'x' is not a type; // x (*p)[]; // 'x' is a type; //; // Since we're in an error case, we can afford to perform a tentative; // parse to determine which case we're in.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseDecl.cpp:158,perform,perform,158,interpreter/llvm-project/clang/lib/Parse/ParseDecl.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Parse/ParseDecl.cpp,1,['perform'],['perform']
Performance,"// std::cerr << ""#"" << ""0x"" << std::hex << local << "" ended with : "" << std::dec << fWriteCurrentRecurse << "" 0x"" <<; // std::hex << fWriteCurrent.load() << "" lock:"" << this << std::endl;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/cont/src/TCollection.cxx:147,load,load,147,core/cont/src/TCollection.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/cont/src/TCollection.cxx,1,['load'],['load']
Performance,"// std::copy(p, p+paramSize, params.begin() );; // // different parameters; // // compute the integral and update the cached param vector; // // this needs to be locked because is a non-const part; // ComputeIntegrals(p);; // }",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/test/fit/testLogLExecPolicy.cxx:118,cache,cached,118,math/mathcore/test/fit/testLogLExecPolicy.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/test/fit/testLogLExecPolicy.cxx,1,['cache'],['cached']
Performance,"// std::cout << "" Still within cached safety ... remaining safety would be "" << ls_eval - std::sqrt(r) << ""\n"";",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx:31,cache,cached,31,geom/geom/src/TGeoParallelWorld.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx,1,['cache'],['cached']
Performance,"// std::cout << ""3D Safety GRID cache: Determined N to be "" << N << ""\n"";",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx:32,cache,cache,32,geom/geom/src/TGeoParallelWorld.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx,1,['cache'],['cache']
Performance,"// std::cout << ""Loaded "" << nllDir->GetPath() << ""/"" << k->GetName() << "" : "" << k->GetTitle(); // << std::endl;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx:17,Load,Loaded,17,roofit/xroofit/src/xRooFit.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooFit.cxx,1,['Load'],['Loaded']
Performance,"// std::cout << ""Perform inversion of matrix \n"" << smat << std::endl;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/test/testSMatrix.cxx:17,Perform,Perform,17,math/smatrix/test/testSMatrix.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/test/testSMatrix.cxx,1,['Perform'],['Perform']
Performance,"// std::cout << cachedFit->GetName() << "" "";; // for(auto ff: constPars) std::cout << ff.first << ""="" <<; // ff.second << "" ""; std::cout << std::endl;",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooHypoSpace.cxx:16,cache,cachedFit,16,roofit/xroofit/src/xRooHypoSpace.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooHypoSpace.cxx,1,['cache'],['cachedFit']
Performance,"// std::set<T> defines its own compariso ""operator<"", but it; // performs a lexicographical comparison by T's innate comparison; // for some reason. We don't want non-deterministic pointer; // comparisons so use this instead.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/AsmMatcherEmitter.cpp:65,perform,performs,65,interpreter/llvm-project/llvm/utils/TableGen/AsmMatcherEmitter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/AsmMatcherEmitter.cpp,1,['perform'],['performs']
Performance,"// std::shared_ptr<TStyle> style; // use to keep alive for access from GetStyle below, in case getObject; // has decided to return the owning ptr (for some reason) std::string _title =; // strlen(dataGraph->GetTitle()) ? dataGraph->GetTitle() : GetName(); if (!gROOT->GetStyle(_title.c_str())); // {; // if ( (style = getObject<TStyle>(_title)) ) {; // // loaded style (from workspace?) so put in list and use that; // gROOT->GetListOfStyles()->Add(style.get());; // } else {; // // create new style - gets put in style list automatically so don't have to delete; // // acquire them so saved to workspaces for auto reload ...; // style = const_cast<xRooNode&>(*this).acquireNew<TStyle>(_title.c_str(),; // TString::Format(""Style for %s component"", _title.c_str()));; // (TAttLine &) (*style) = *dynamic_cast<TAttLine *>(dataGraph);; // (TAttFill &) (*style) = *dynamic_cast<TAttFill *>(dataGraph);; // (TAttMarker &) (*style) = *dynamic_cast<TAttMarker *>(dataGraph);; // gROOT->GetListOfStyles()->Add(style.get());; // }; // }",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:356,load,loaded,356,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,1,['load'],['loaded']
Performance,"// std::shared_ptr<TStyle> style; // use to keep alive for access from GetStyle below, in case; // getObject has decided to return the owning ptr (for some reason) if; // (!gROOT->GetStyle(h->GetTitle())) {; // if ( (style = getObject<TStyle>(h->GetTitle())) ) {; // // loaded style (from workspace?) so put in list and use that; // gROOT->GetListOfStyles()->Add(style.get());; // } else {; // // create new style - gets put in style list automatically so don't have to delete; // // acquire them so saved to workspaces for auto reload ...; // style = acquireNew<TStyle>(h->GetTitle(),; // TString::Format(""Style for %s component"", h->GetTitle()));; // (TAttLine &) (*style) = *dynamic_cast<TAttLine *>(h);; // (TAttFill &) (*style) = *dynamic_cast<TAttFill *>(h);; // (TAttMarker &) (*style) = *dynamic_cast<TAttMarker *>(h);; // gROOT->GetListOfStyles()->Add(style.get());; // }; // }; // (TAttLine&)(*h) = *(gROOT->GetStyle(h->GetTitle()) ? gROOT->GetStyle(h->GetTitle()) : gStyle);; // (TAttFill&)(*h) = *(gROOT->GetStyle(h->GetTitle()) ? gROOT->GetStyle(h->GetTitle()) : gStyle);; // (TAttMarker&)(*h) = *(gROOT->GetStyle(h->GetTitle()) ? gROOT->GetStyle(h->GetTitle()) : gStyle);",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:270,load,loaded,270,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,1,['load'],['loaded']
Performance,"// step 2: Emit the N-ary addition.; // Note that at most three instructions are involved in Fadd-InstCombine: the; // addition in question, and at most two neighboring instructions.; // The resulting optimized addition should have at least one less instruction; // than the original addition expression tree. This implies that the resulting; // N-ary addition has at most two instructions, and we don't need to worry; // about tree-height when constructing the N-ary addition.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp:201,optimiz,optimized,201,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp,1,['optimiz'],['optimized']
Performance,"// step 3: order singular values and perform permutations",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/matrix/src/TDecompSVD.cxx:37,perform,perform,37,math/matrix/src/TDecompSVD.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/src/TDecompSVD.cxx,1,['perform'],['perform']
Performance,"// step 4: Find the instruction which count the CTLZ: cnt.next = cnt + 1; // or cnt.next = cnt + -1.; // TODO: We can skip the step. If loop trip count is known (CTLZ),; // then all uses of ""cnt.next"" could be optimized to the trip count; // plus ""cnt0"". Currently it is not optimized.; // This step could be used to detect POPCNT instruction:; // cnt.next = cnt + (x.next & 1)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopIdiomRecognize.cpp:210,optimiz,optimized,210,interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopIdiomRecognize.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/LoopIdiomRecognize.cpp,2,['optimiz'],['optimized']
Performance,// step 4: Try to optimize Opnd0 + Opnd1_0 [+ Opnd1_1],MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp:18,optimiz,optimize,18,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp,1,['optimiz'],['optimize']
Performance,// step 5: Try to optimize Opnd1 + Opnd0_0 [+ Opnd0_1],MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp:18,optimiz,optimize,18,interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp,1,['optimiz'],['optimize']
Performance,"// sterilize first so that cache elements don't appear in the client list; // safety net in case sterilizing one client deletes another one of our clients; // monitor for change in clients list size; // found this was only case in 6.26 (valgrind shows invalid read), in 6.28 these went away; // might be in 6.28 the client list iterator became able to handle in-loop edits but didn't see; // in test case that client count changed so just resterilizing if that's the case.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx:27,cache,cache,27,roofit/xroofit/src/xRooNode.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNode.cxx,1,['cache'],['cache']
Performance,"// stl container of simple type are always 'loaded'",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/src/TBranchProxyClassDescriptor.cxx:44,load,loaded,44,tree/treeplayer/src/TBranchProxyClassDescriptor.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/src/TBranchProxyClassDescriptor.cxx,1,['load'],['loaded']
Performance,"// stop the loop when the loading is not active anymore",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RBatchGenerator.hxx:26,load,loading,26,tmva/tmva/inc/TMVA/RBatchGenerator.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/RBatchGenerator.hxx,1,['load'],['loading']
Performance,"// store fitting result in the backward compatible TVirtualFitter object; // lock in case running in a multi-thread enabled mode",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/HFitImpl.cxx:103,multi-thread,multi-thread,103,hist/hist/src/HFitImpl.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/HFitImpl.cxx,1,['multi-thread'],['multi-thread']
Performance,"// store found handle in cache, can reuse later",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:25,cache,cache,25,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['cache'],['cache']
Performance,// store references to cache key and WebGLTexture object,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:23,cache,cache,23,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['cache'],['cache']
Performance,"// strncat(x, s, c) -> strcat(x, s); // s is constant so the strcat can be optimized further.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp:75,optimiz,optimized,75,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyLibCalls.cpp,1,['optimiz'],['optimized']
Performance,// struct AssignSym; //=========================================================================; /**; Evaluate the expression performing a += operation; Need to check whether creating a temporary object with the expression result; (like in op: A += A * B ); */,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/inc/Math/HelperOps.h:127,perform,performing,127,math/smatrix/inc/Math/HelperOps.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/inc/Math/HelperOps.h,1,['perform'],['performing']
Performance,// struct PlusEquals; //=========================================================================; /**; Evaluate the expression performing a -= operation; Need to check whether creating a temporary object with the expression result; (like in op: A -= A * B ); */,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/inc/Math/HelperOps.h:128,perform,performing,128,math/smatrix/inc/Math/HelperOps.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/inc/Math/HelperOps.h,1,['perform'],['performing']
Performance,// struct _class_t {; // struct _class_t *isa;; // struct _class_t * const superclass;; // void *cache;; // IMP *vtable;; // struct class_ro_t *ro;; // },MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp:97,cache,cache,97,interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp,1,['cache'],['cache']
Performance,// struct _objc_class {; // Class isa;; // Class super_class;; // char *name;; // long version;; // long info;; // long instance_size;; // struct _objc_ivar_list *ivars;; // struct _objc_method_list *methods;; // struct _objc_cache *cache;; // struct _objc_protocol_list *protocols;; // char *ivar_layout;; // struct _objc_class_ext *ext;; // };,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp:233,cache,cache,233,interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGObjCMac.cpp,1,['cache'],['cache']
Performance,"// subpd; // v2i64/v4i64 mul is custom lowered as a series of long:; // multiplies(3), shifts(3) and adds(2); // slm muldq version throughput is 2 and addq throughput 4; // thus: 3X2 (muldq throughput) + 3X1 (shift throughput) +; // 3X4 (addq throughput) = 17",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp:131,throughput,throughput,131,interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86TargetTransformInfo.cpp,5,['throughput'],['throughput']
Performance,// sunpklo(sext(pred)) -> sext(extract_low_half(pred)); // This transform works in partnership with performSetCCPunpkCombine to; // remove unnecessary transfer of predicates into standard registers and back,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:100,perform,performSetCCPunpkCombine,100,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['perform'],['performSetCCPunpkCombine']
Performance,// svg images are always loaded without @2,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/ui5/canv/controller/ColorButton.js:25,load,loaded,25,ui5/canv/controller/ColorButton.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/ui5/canv/controller/ColorButton.js,1,['load'],['loaded']
Performance,"// swifterror pointers can only be used by a load or store; sinking a load; // or store would require introducing a select for the pointer operand,; // which isn't allowed for swifterror pointers.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp:45,load,load,45,interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/SimplifyCFG.cpp,2,['load'],['load']
Performance,"// tMOVi8 usually doesn't start long dependency chains, and there are a lot; // of them, so always shrink them when CPSR doesn't have high latency.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/Thumb2SizeReduction.cpp:139,latency,latency,139,interpreter/llvm-project/llvm/lib/Target/ARM/Thumb2SizeReduction.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/Thumb2SizeReduction.cpp,1,['latency'],['latency']
Performance,"// take the last loaded PID",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TBufferIO.cxx:17,load,loaded,17,io/io/src/TBufferIO.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TBufferIO.cxx,1,['load'],['loaded']
Performance,"// taylor expansion can be performed only for order 0, 1, 2 currently",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooPolyFunc.cxx:27,perform,performed,27,roofit/roofitcore/src/RooPolyFunc.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooPolyFunc.cxx,1,['perform'],['performed']
Performance,"// template proxy was already created in sync_templates call above, so; // add only here, not to the cache of collected methods",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/ProxyWrappers.cxx:101,cache,cache,101,bindings/pyroot/cppyy/CPyCppyy/src/ProxyWrappers.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/ProxyWrappers.cxx,1,['cache'],['cache']
Performance,"// temporary variable used during optimization",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/inc/v5/TFormula.h:34,optimiz,optimization,34,hist/hist/inc/v5/TFormula.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/inc/v5/TFormula.h,1,['optimiz'],['optimization']
Performance,"// test for a estimator function which optimizes on the whole background-rejection signal-efficiency plot; // get the backg-reject. and sig-eff for the parameters given to this function; // effS, effB; // get best background rejection for given signal efficiency",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodCuts.cxx:39,optimiz,optimizes,39,tmva/tmva/src/MethodCuts.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodCuts.cxx,1,['optimiz'],['optimizes']
Performance,"// test multi-thread Snapshotting from many tasks per worker thread",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_snapshot.cxx:8,multi-thread,multi-thread,8,tree/dataframe/test/dataframe_snapshot.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_snapshot.cxx,1,['multi-thread'],['multi-thread']
Performance,"// test of multidimentional Integration; // Calculates an integral of a function; // in 2,3,..., 8 dimensions; // by using adaptive Genz Malik cubature; // and MonteCarlo methods:; // --PLAIN; // --VEGAS; // --MISER; //; // from; // IntegratorMultiDim class; // and GSLMCIntegrator class; //; // Compares time performance; // for different dimensions; // draws a graph; //; // Author: Magdalena Slawinska; //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/test/testMCIntegration.cxx:310,perform,performance,310,math/mathmore/test/testMCIntegration.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/test/testMCIntegration.cxx,1,['perform'],['performance']
Performance,"// test performance of all vectors operations +,- and *; // results on mactelm g++ 4.01 showing ROOT::Math performs best overall; //v3 = v1+v2 v2 += v1 v3 = v1-v2 v2 -= v1 v2 = a*v1 v1 *= a v2 = v1/a v1 /= a; // 0.59 0.57 0.58 0.56 0.69 0.7 1.65 1.64 2D; // 0.79 0.79 0.78 0.8 0.97 0.95 1.85 1.84 3D; // 1.07 1.07 1.07 1.07 1.32 1.31 1.72 1.71 4D; // ROOT Physics Vector (TVector's):; //v3 = v1+v2 v2 += v1 v3 = v1-v2 v2 -= v1 v2 = a*v1 v1 *= a; // 4.4 0.97 4.41 0.96 4.43 1.13 2D; // 5.44 1.25 5.48 1.24 6.12 1.46 3D; // 17.65 7.32 17.65 7.35 10.25 7.79 4D; // CLHEP Vector (HepVector's):; //v3 = v1+v2 v2 += v1 v3 = v1-v2 v2 -= v1 v2 = a*v1 v1 *= a; // 0.57 0.55 0.56 0.55 0.7 0.7 2D; // 0.8 0.79 0.78 0.77 0.96 0.94 2.7 3.7 3D; // 1.06 1.02 1.06 1.02 1.26 1.26 2.99 3.98 4D",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/genvector/test/vectorOperation.cxx:8,perform,performance,8,math/genvector/test/vectorOperation.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/test/vectorOperation.cxx,2,['perform'],"['performance', 'performs']"
Performance,"// test unuran using the string interface to generate numbers according to the normal distributions; // compare CPU performancecwith TRandom::Gaus and opitonally GSL (using MathMore ) and CLHEP for; // generating normal distributed random numbers; //; // run within ROOT (.x unuranSimple.cxx+) or pass any extra parameter in the command line to get; // a graphics output; //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/unuran/test/unuranSimple.cxx:116,perform,performancecwith,116,math/unuran/test/unuranSimple.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/unuran/test/unuranSimple.cxx,1,['perform'],['performancecwith']
Performance,"// test using 1D Distribution object interface; // and compare results and CPU performances using TF1::GetRandom; //; // run within ROOT (.x unuranDistr.cxx+) or pass any extra parameter in the command line to get; // a graphics output",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/unuran/test/unuranDistr.cxx:79,perform,performances,79,math/unuran/test/unuranDistr.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/unuran/test/unuranDistr.cxx,1,['perform'],['performances']
Performance,"// test using Multi-dim (2D) Distribution object interface; // and compare results and CPU performances using TF2::GetRandom; //; // run within ROOT (.x unuranMulti2D.cxx+) or pass any extra parameter in the command line to get; // a graphics output",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/unuran/test/unuranMulti2D.cxx:91,perform,performances,91,math/unuran/test/unuranMulti2D.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/unuran/test/unuranMulti2D.cxx,1,['perform'],['performances']
Performance,"// test using Multi-dim Distribution object interface; // and compare results and CPU performances using TF3::GetRandom in case of 3D; // and test also case of dim = 10 and 100; //; // run within ROOT (.x unuranMultiDim.cxx+) or pass any extra parameter in the command line to get; // a graphics output",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/unuran/test/unuranMultiDim.cxx:86,perform,performances,86,math/unuran/test/unuranMultiDim.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/unuran/test/unuranMultiDim.cxx,1,['perform'],['performances']
Performance,"// texture<> objects get magically converted into a texture reference. However,; // there's no way to convert them to cudaTextureObject_t on C++ level. So, we; // cheat a bit and use inline assembly to do it. It costs us an extra register; // and a move, but that is easy for ptxas to optimize away.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/__clang_cuda_texture_intrinsics.h:285,optimiz,optimize,285,interpreter/llvm-project/clang/lib/Headers/__clang_cuda_texture_intrinsics.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/__clang_cuda_texture_intrinsics.h,1,['optimiz'],['optimize']
Performance,// the DCI.xxxx conditions are provided to postpone the optimization as; // late as possible.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:56,optimiz,optimization,56,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['optimiz'],['optimization']
Performance,"// the RVec<simple type> field optimization should ignore the mask",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/test/ntuple_bulk.cxx:31,optimiz,optimization,31,tree/ntuple/v7/test/ntuple_bulk.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/test/ntuple_bulk.cxx,1,['optimiz'],['optimization']
Performance,"// the cached data is too large to fit in the new buffer size mark data unavailable",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFileCacheRead.cxx:7,cache,cached,7,io/io/src/TFileCacheRead.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFileCacheRead.cxx,1,['cache'],['cached']
Performance,// the difference between the last subscripts must be less than the cache line; // size.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LoopCacheAnalysis.cpp:68,cache,cache,68,interpreter/llvm-project/llvm/lib/Analysis/LoopCacheAnalysis.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/LoopCacheAnalysis.cpp,1,['cache'],['cache']
Performance,"// the script has already been loaded in interpreted mode; // Let's warn the user and unload it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx:31,load,loaded,31,core/base/src/TSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/base/src/TSystem.cxx,1,['load'],['loaded']
Performance,"// the shortest garbage collector in the world - one long line of PERL - unlinks files only,; // if there is a symbolic link with '.ROOT.cachefile' for safety ;-)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx:137,cache,cachefile,137,io/io/src/TFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx,1,['cache'],['cachefile']
Performance,"// the stuff that the clients have cached may depend on the normalization range",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsPdf.cxx:35,cache,cached,35,roofit/roofitcore/src/RooAbsPdf.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsPdf.cxx,2,['cache'],['cached']
Performance,"// then from each forked node, spin up another set of workers+queue!",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/test/test_ProcessManager.cxx:62,queue,queue,62,roofit/multiprocess/test/test_ProcessManager.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/test/test_ProcessManager.cxx,1,['queue'],['queue']
Performance,"// then the master-queue sockets",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/Messenger.cxx:19,queue,queue,19,roofit/multiprocess/src/Messenger.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/Messenger.cxx,1,['queue'],['queue']
Performance,"// there seems to be a nasty bug somewhere that can make the cache become invalid, so clear it here",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx:61,cache,cache,61,roofit/xroofit/src/xRooNLLVar.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooNLLVar.cxx,1,['cache'],['cache']
Performance,"// this can be optimized if needed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/physics/src/TRolke.cxx:15,optimiz,optimized,15,math/physics/src/TRolke.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/physics/src/TRolke.cxx,1,['optimiz'],['optimized']
Performance,"// this can be probably optimized",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/FitUtil.cxx:24,optimiz,optimized,24,math/mathcore/src/FitUtil.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/FitUtil.cxx,1,['optimiz'],['optimized']
Performance,"// this can take a few minutes in some configurations; // TEST(RWLock, VeryLargeconcurrentReadsAndWritesSpin); // {; // concurrentReadsAndWrites(gRWMutexSpin,10,200,gRepetition / 100000);; // }",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/thread/test/testRWLock.cxx:120,concurren,concurrentReadsAndWrites,120,core/thread/test/testRWLock.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/thread/test/testRWLock.cxx,1,['concurren'],['concurrentReadsAndWrites']
Performance,"// this changes the RVec from memory adoption mode to ""long"" mode, even if the size is small; // currently we don't allow going from memory adoption to small buffer mode directly, it could be future optimization",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/vecops/test/vecops_rvec.cxx:199,optimiz,optimization,199,math/vecops/test/vecops_rvec.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/test/vecops_rvec.cxx,1,['optimiz'],['optimization']
Performance,"// this function modifies cache state ---> make writing thread-safe",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx:26,cache,cache,26,geom/geom/src/TGeoParallelWorld.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx,1,['cache'],['cache']
Performance,"// this happens when loaded hypoSpace from a hypoSpaceInverterResult; // set relUncert to infinity so that we don't test any new points",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooHypoSpace.cxx:21,load,loaded,21,roofit/xroofit/src/xRooHypoSpace.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooHypoSpace.cxx,2,['load'],['loaded']
Performance,"// this is a regression test for an issue that was hidden by RVec's small buffer optimization; // when the variations don't fit in the smalll buffer and we are varying multiple columns simultaneously,; // RVariation was changing the address of the varied values between entries, resulting in invalid reads; // on the part of the RVariationReader.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_vary.cxx:81,optimiz,optimization,81,tree/dataframe/test/dataframe_vary.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/test/dataframe_vary.cxx,1,['optimiz'],['optimization']
Performance,"// this is a remote file and worthwhile to be put into the local cache; // now create cachepath to put it",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx:65,cache,cache,65,io/io/src/TFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx,2,['cache'],"['cache', 'cachepath']"
Performance,"// this is plain creation of points, no need for texture loading",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:57,load,loading,57,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['load'],['loading']
Performance,"// this one stays cached",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/rint/src/TTabCom.cxx:18,cache,cached,18,core/rint/src/TTabCom.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/rint/src/TTabCom.cxx,2,['cache'],['cached']
Performance,"// this part typically read from the header, no need to optimize",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:56,optimiz,optimize,56,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['optimiz'],['optimize']
Performance,"// this test program compares the I/O performance obtained with; // all STL collections of objects or pointers to objects and also; // Root collection class TClonesArray.; // Trees in compression and non compression mode are created for each; // of the following cases:; // -STLcollection<THit>; // -STLcollection<THit*>; // -TClonesArray(TObjHit) in no split mode; // -TClonesArray(TObjHit) in split mode; // where:; // THit is a class not derived from TObject; // TObjHit derives from TObject and THit; //; // run with; // bench; // or; // bench -m to stream objects memberwise; //; // The test prints a summary table comparing performances for all above cases; // (CPU, file size, compression factors).; // Reference numbers on a Pentium IV 2.4 Ghz machine are given as reference.; // Authors: Rene Brun, Markus Frank",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/test/bench.cxx:38,perform,performance,38,test/bench.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/test/bench.cxx,2,['perform'],"['performance', 'performances']"
Performance,"// thread to run Ps(): perform every 5 seconds a TThread::Ps()",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/test/threads.cxx:23,perform,perform,23,test/threads.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/test/threads.cxx,1,['perform'],['perform']
Performance,"// three checks are required to ensure safety:; // . Offset >= 0 (since the offset is given from the base ptr); // . Size >= Offset (unsigned); // . Size - Offset >= NeededSize (unsigned); //; // optimization: if Size >= 0 (signed), skip 1st check; // FIXME: add NSW/NUW here? -- we dont care if the subtraction overflows",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/BoundsChecking.cpp:196,optimiz,optimization,196,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/BoundsChecking.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/BoundsChecking.cpp,1,['optimiz'],['optimization']
Performance,"// tileload.scalarize.cols.body:; // Calculate %idxmem and %idxvec; // %eltptr = getelementptr i32, i32* %base, i64 %idxmem; // %elt = load i32, i32* %ptr; // %ResVec = insertelement <256 x i32> %vec.phi, i32 %elt, i16 %idxvec",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp:135,load,load,135,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXIntrinsics.cpp,1,['load'],['load']
Performance,"// to be optimized",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TFormula_v5.cxx:9,optimiz,optimized,9,hist/hist/src/TFormula_v5.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TFormula_v5.cxx,8,['optimiz'],['optimized']
Performance,"// to optimize likelihood calculations",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/ProfileLikelihoodCalculator.cxx:6,optimiz,optimize,6,roofit/roostats/src/ProfileLikelihoodCalculator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/ProfileLikelihoodCalculator.cxx,1,['optimiz'],['optimize']
Performance,"// tracking optimization attributes",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoAtt.h:12,optimiz,optimization,12,geom/geom/inc/TGeoAtt.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoAtt.h,1,['optimiz'],['optimization']
Performance,"// transform bitcast to <store, load> instructions.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp:32,load,load,32,interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86LowerAMXType.cpp,1,['load'],['load']
Performance,"// transformInstruction - Perform the transformation of an instruction; // to its equivalant AdvSIMD scalar instruction. Update inputs and outputs; // to be the correct register class, minimizing cross-class copies.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64AdvSIMDScalarPass.cpp:26,Perform,Perform,26,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64AdvSIMDScalarPass.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64AdvSIMDScalarPass.cpp,2,['Perform'],['Perform']
Performance,"// trap loading of all dylibs to register dylib name,; // sets also ROOTSYS if built without ROOTPREFIX",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/unix/src/TUnixSystem.cxx:8,load,loading,8,core/unix/src/TUnixSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/unix/src/TUnixSystem.cxx,1,['load'],['loading']
Performance,"// trigger loading of the contents of the TTreeReaderArray; // the address of the first element in the reader array is not necessarily equal to; // the address returned by the GetAddress method",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RTreeColumnReader.hxx:11,load,loading,11,tree/dataframe/inc/ROOT/RDF/RTreeColumnReader.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/RTreeColumnReader.hxx,1,['load'],['loading']
Performance,"// try again with a smaller queue for ENOMEM",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/inc/ROOT/RIoUring.hxx:28,queue,queue,28,io/io/inc/ROOT/RIoUring.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/inc/ROOT/RIoUring.hxx,1,['queue'],['queue']
Performance,"// try all outstanding using namespaces in turn to find the attribute (will cache; // locally later; TODO: doing so may cause pathological cases)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPScope.cxx:76,cache,cache,76,bindings/pyroot/cppyy/CPyCppyy/src/CPPScope.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/CPPScope.cxx,1,['cache'],['cache']
Performance,"// try to load discriminator foam",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodPDEFoam.cxx:10,load,load,10,tmva/tmva/src/MethodPDEFoam.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodPDEFoam.cxx,1,['load'],['load']
Performance,"// try to load font (font must be in Root.TTFontPath resource)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/graf/src/TTF.cxx:10,load,load,10,graf2d/graf/src/TTF.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/graf/src/TTF.cxx,3,['load'],['load']
Performance,"// try to load font (font must be in Root.TTFontPath resource); // to see which fontset we have available",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/graf/src/TTF.cxx:10,load,load,10,graf2d/graf/src/TTF.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/graf/src/TTF.cxx,1,['load'],['load']
Performance,"// try to load necessary libraries",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/browserv7/src/RBrowserWidget.cxx:10,load,load,10,gui/browserv7/src/RBrowserWidget.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/browserv7/src/RBrowserWidget.cxx,2,['load'],['load']
Performance,"// try to load the foam from the file",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodPDEFoam.cxx:10,load,load,10,tmva/tmva/src/MethodPDEFoam.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/MethodPDEFoam.cxx,1,['load'],['load']
Performance,"// try to read file content into cache and than reuse it, limit cache by 2 GB",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/net/src/TWebFile.cxx:33,cache,cache,33,net/net/src/TWebFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/net/src/TWebFile.cxx,2,['cache'],['cache']
Performance,"// tryCaptureVariable is called every time a DeclRef is formed,; // it can therefore have non-negigible impact on performances.; // For local variables and when there is no capturing scope,; // we can bailout early.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp:114,perform,performances,114,interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Sema/SemaExpr.cpp,1,['perform'],['performances']
Performance,"// tryFoldPhiAGPR will aggressively try to create AGPR PHIs.; // For GFX90A and later, this is pretty much always a good thing, but for GFX908; // there's cases where it can create a lot more AGPR-AGPR copies, which are; // expensive on this architecture due to the lack of V_ACCVGPR_MOV.; //; // This function looks at all AGPR PHIs in a basic block and collects their; // operands. Then, it checks for register that are used more than once across; // all PHIs and caches them in a VGPR. This prevents ExpandPostRAPseudo from; // having to create one VGPR temporary per use, which can get very messy if; // these PHIs come from a broken-up large PHI (e.g. 32 AGPR phis, one per vector; // element).; //; // Example; // a:; // %in:agpr_256 = COPY %foo:vgpr_256; // c:; // %x:agpr_32 = ..; // b:; // %0:areg = PHI %in.sub0:agpr_32, %a, %x, %c; // %1:areg = PHI %in.sub0:agpr_32, %a, %y, %c; // %2:areg = PHI %in.sub0:agpr_32, %a, %z, %c; // =>; // a:; // %in:agpr_256 = COPY %foo:vgpr_256; // %tmp:vgpr_32 = V_ACCVGPR_READ_B32_e64 %in.sub0:agpr_32; // %tmp_agpr:agpr_32 = COPY %tmp; // c:; // %x:agpr_32 = ..; // b:; // %0:areg = PHI %tmp_agpr, %a, %x, %c; // %1:areg = PHI %tmp_agpr, %a, %y, %c; // %2:areg = PHI %tmp_agpr, %a, %z, %c",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIFoldOperands.cpp:466,cache,caches,466,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIFoldOperands.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIFoldOperands.cpp,1,['cache'],['caches']
Performance,// tryTLSXFormLoad - Convert an ISD::LOAD fed by a PPCISD::ADD_TLS into; // an X-Form load instruction with the offset being a relocation coming from; // the PPCISD::ADD_TLS.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp:37,LOAD,LOAD,37,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,2,"['LOAD', 'load']","['LOAD', 'load']"
Performance,"// type.checked.load with a non-constant offset, so assume every entry; // in every matching vtable is used.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalDCE.cpp:16,load,load,16,interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalDCE.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/IPO/GlobalDCE.cpp,1,['load'],['load']
Performance,// udiv/urem because this optimization only handles positive numbers.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/BypassSlowDivision.cpp:26,optimiz,optimization,26,interpreter/llvm-project/llvm/lib/Transforms/Utils/BypassSlowDivision.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/BypassSlowDivision.cpp,1,['optimiz'],['optimization']
Performance,"// unaligned loads, fixme",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp:13,load,loads,13,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelDAGToDAG.cpp,1,['load'],['loads']
Performance,// unnamed namespace; // Try to find any invariant memory reads that will become dereferenceable in; // the remainder loop after peeling. The load must also be used (transitively); // by an exit condition. Returns the number of iterations to peel off (at the; // moment either 0 or 1).,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopPeel.cpp:142,load,load,142,interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopPeel.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Utils/LoopPeel.cpp,1,['load'],['load']
Performance,// unsigned 12-bit fixups for load and store instructions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/MCTargetDesc/AArch64FixupKinds.h:30,load,load,30,interpreter/llvm-project/llvm/lib/Target/AArch64/MCTargetDesc/AArch64FixupKinds.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/MCTargetDesc/AArch64FixupKinds.h,1,['load'],['load']
Performance,// unsigned gather loads,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:19,load,loads,19,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['load'],['loads']
Performance,// unused value for load insts; // Bits of TH for atomics,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIDefines.h:20,load,load,20,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIDefines.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIDefines.h,1,['load'],['load']
Performance,"// update error cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/SVWorkingSet.cxx:16,cache,cache,16,tmva/tmva/src/SVWorkingSet.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/SVWorkingSet.cxx,1,['cache'],['cache']
Performance,"// update of weights using Adam algorithm; // we use the formulation defined before section 2.1 in the original paper; // 'Adam: A method for stochastic optimization, D. Kingma, J. Ba, see https://arxiv.org/abs/1412.6980",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/DNN/Adam.h:153,optimiz,optimization,153,tmva/tmva/inc/TMVA/DNN/Adam.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/inc/TMVA/DNN/Adam.h,1,['optimiz'],['optimization']
Performance,"// update ours sets of category and real args to refer to the cache dataset",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsNumGenerator.cxx:62,cache,cache,62,roofit/roofitcore/src/RooAbsNumGenerator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooAbsNumGenerator.cxx,1,['cache'],['cache']
Performance,"// update the cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/src/TTreeFormula.cxx:14,cache,cache,14,tree/treeplayer/src/TTreeFormula.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/src/TTreeFormula.cxx,1,['cache'],['cache']
Performance,"// update the cache to ensure it records the user has explicitly; // requested it",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx:14,cache,cache,14,tree/tree/src/TTree.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx,1,['cache'],['cache']
Performance,"// update the priority queue of leaf bounding boxes",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx:23,queue,queue,23,geom/geom/src/TGeoParallelWorld.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx,1,['queue'],['queue']
Performance,"// use TClass directly, to enable auto-loading; class may be stubbed (eg. for; // function returns) or forward declared, leading to a non-null TClass that is; // otherwise invalid/unusable",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:39,load,loading,39,bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx,1,['load'],['loading']
Performance,"// use approximate formulas for large N; // cache Sum( 1 / i)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/GoFTest.cxx:44,cache,cache,44,math/mathcore/src/GoFTest.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/src/GoFTest.cxx,1,['cache'],['cache']
Performance,"// use cached integral values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/test/fit/testLogLExecPolicy.cxx:7,cache,cached,7,math/mathcore/test/fit/testLogLExecPolicy.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/test/fit/testLogLExecPolicy.cxx,1,['cache'],['cached']
Performance,"// use esplicity cached param values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/test/stressMathMore.cxx:17,cache,cached,17,test/stressMathMore.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/test/stressMathMore.cxx,1,['cache'],['cached']
Performance,"// use explicitly cached param values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/test/StatFunction.h:18,cache,cached,18,math/mathmore/test/StatFunction.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/test/StatFunction.h,1,['cache'],['cached']
Performance,"// use in a different basic block, If there is a call or; // load/store insn before this instruction in this basic; // block. Most likely it cannot be hoisted out. Skip it.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFAdjustOpt.cpp:61,load,load,61,interpreter/llvm-project/llvm/lib/Target/BPF/BPFAdjustOpt.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/BPF/BPFAdjustOpt.cpp,1,['load'],['load']
Performance,"// use nojQuery while we are already load jquery and jquery-ui, later one can use directly sap-ui-core.js; // this is location of openui5 scripts when working with THttpServer or when scripts are installed inside JSROOT",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:37,load,load,37,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['load'],['load']
Performance,// use optimized handling with relative position,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:7,optimiz,optimized,7,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['optimiz'],['optimized']
Performance,"// use the data member cache to store extra state on the iterator object,; // without it being visible on the Python side",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx:23,cache,cache,23,bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx,1,['cache'],['cache']
Performance,"// use the fact that other were check before - see bool optimize",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TFormula_v5.cxx:56,optimiz,optimize,56,hist/hist/src/TFormula_v5.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TFormula_v5.cxx,1,['optimiz'],['optimize']
Performance,"// use this order for safety on library loading",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/histfactory/src/HistoToWorkspaceFactoryFast.cxx:40,load,loading,40,roofit/histfactory/src/HistoToWorkspaceFactoryFast.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/histfactory/src/HistoToWorkspaceFactoryFast.cxx,1,['load'],['loading']
Performance,"// used as a once only control for automatic cache setup",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx:45,cache,cache,45,tree/tree/src/TTree.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/src/TTree.cxx,1,['cache'],['cache']
Performance,"// used for cache together with the parameter tracker",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooFit/TestStatistics/RooBinnedL.h:12,cache,cache,12,roofit/roofitcore/inc/RooFit/TestStatistics/RooBinnedL.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooFit/TestStatistics/RooBinnedL.h,2,['cache'],['cache']
Performance,"// usual case ... cachedFit has more constPars than one of the fits we have already encountered; // (the ufit); // => cachedFit is a cfit of key fr ...",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooHypoSpace.cxx:18,cache,cachedFit,18,roofit/xroofit/src/xRooHypoSpace.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/xroofit/src/xRooHypoSpace.cxx,2,['cache'],['cachedFit']
Performance,"// v128.{load,store}{8,16,32,64}_lane has both a memarg and a lane; // index. We need to avoid parsing an extra alignment operand for the; // lane index.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/AsmParser/WebAssemblyAsmParser.cpp:9,load,load,9,interpreter/llvm-project/llvm/lib/Target/WebAssembly/AsmParser/WebAssemblyAsmParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/AsmParser/WebAssemblyAsmParser.cpp,1,['load'],['load']
Performance,"// v16i8 LD_SPLAT addr; // ======>; // Mask = LVSR/LVSL 0, addr; // LoadLow = LVX 0, addr; // Perm = VPERM LoadLow, LoadLow, Mask; // Splat = VSPLTB 15/0, Perm; //; // v8i16 LD_SPLAT addr; // ======>; // Mask = LVSR/LVSL 0, addr; // LoadLow = LVX 0, addr; // LoadHigh = LVX (LI, 1), addr; // Perm = VPERM LoadLow, LoadHigh, Mask; // Splat = VSPLTH 7/0, Perm",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp:68,Load,LoadLow,68,interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp,7,['Load'],"['LoadHigh', 'LoadLow']"
Performance,"// v16i8 is a special case, as we have 16 entries but only 8 positional bits; // per entry. We split it into two halves, apply the mask, zip the halves to; // create 8x 16-bit values, and the perform the vector reduce.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:192,perform,perform,192,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,1,['perform'],['perform']
Performance,// v2f16 was loaded as an i32. Now we must bitcast it back.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:13,load,loaded,13,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,1,['load'],['loaded']
Performance,// v2f16/v2bf16/v2i16 is loaded using ld.b32,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp:25,load,loaded,25,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp,1,['load'],['loaded']
Performance,"// v2f16/v2bf16/v2i16/v4i8 are legal, so we can't rely on legalizer to handle; // unaligned loads and have to handle it here.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:92,load,loads,92,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,1,['load'],['loads']
Performance,// v2i64 BUILD_VECTOR must be performed via v4i32 so split into i32's.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEISelLowering.cpp:30,perform,performed,30,interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsSEISelLowering.cpp,1,['perform'],['performed']
Performance,// v3 and v4 loads are supported for private and global memory.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:13,load,loads,13,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,1,['load'],['loads']
Performance,// v3 loads not supported on SI.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp:6,load,loads,6,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIISelLowering.cpp,2,['load'],['loads']
Performance,// v4i8 types are lowered to scalar a load/store and sshll/xtn.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp:38,load,load,38,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64TargetTransformInfo.cpp,1,['load'],['load']
Performance,"// v8f16 is a special case. PTX doesn't have ld.v8.f16; // instruction. Instead, we split the vector into v2f16 chunks and; // load them with ld.v4.b32.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp:127,load,load,127,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp,1,['load'],['load']
Performance,// v8i16/v16i16: perform unsigned multiply hi/lo and OR the results.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:17,perform,perform,17,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['perform'],['perform']
Performance,"// v8x16 is a special case. PTX doesn't have ld.v8.16; // instruction. Instead, we split the vector into v2x16 chunks and; // load them with ld.v4.b32.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp:126,load,load,126,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp,1,['load'],['load']
Performance,"// vXi32 -> vXi8 must be performed as PACKUSWB(PACKSSDW,PACKSSDW).",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:25,perform,performed,25,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['perform'],['performed']
Performance,// valid address for Neon doubleword vector load/store,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp:44,load,load,44,interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp,1,['load'],['load']
Performance,// valid address for Neon element and structure load/store,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp:48,load,load,48,interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp,1,['load'],['load']
Performance,// valid address for non-offset loads/stores of quad-word; // values in four ARM registers,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp:32,load,loads,32,interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Basic/Targets/ARM.cpp,1,['load'],['loads']
Performance,"// validate cache - removes no longer actual elements",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/browserv7/src/RBrowserData.cxx:12,cache,cache,12,gui/browserv7/src/RBrowserData.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/browserv7/src/RBrowserData.cxx,1,['cache'],['cache']
Performance,"// vbroadcast(scalarload X) -> vbroadcast_load X; // For float loads, extract other uses of the scalar from the broadcast.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:63,load,loads,63,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['loads']
Performance,// vbroadcast(vector load X) -> vbroadcast_load,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:21,load,load,21,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,1,['load'],['load']
Performance,// vccz could be incorrect at a basic block boundary if a predecessor wrote; // to vcc and then issued an smem load.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInsertWaitcnts.cpp:111,load,load,111,interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInsertWaitcnts.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AMDGPU/SIInsertWaitcnts.cpp,1,['load'],['load']
Performance,// vector of counter load/store pairs to be register promoted.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/InstrProfiling.cpp:21,load,load,21,interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/InstrProfiling.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Instrumentation/InstrProfiling.cpp,1,['load'],['load']
Performance,"// vector-optimized iterator protocol",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx:10,optimiz,optimized,10,bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx,1,['optimiz'],['optimized']
Performance,"// vector<bool> does not allow concurrent writing of different elements",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx:31,concurren,concurrent,31,tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx,1,['concurren'],['concurrent']
Performance,"// vectorize.enable is set if:; // 1) loop hint vectorize.enable is set, or; // 2) it is implied when vectorize.predicate is set, or; // 3) it is implied when vectorize.width is set to a value > 1; // 4) it is implied when vectorize.scalable.enable is true; // 5) it is implied when vectorize.width is unset (0) and the user; // explicitly requested fixed-width vectorization, i.e.; // vectorize.scalable.enable is false.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGLoopInfo.cpp:233,scalab,scalable,233,interpreter/llvm-project/clang/lib/CodeGen/CGLoopInfo.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/CodeGen/CGLoopInfo.cpp,2,['scalab'],['scalable']
Performance,// vectors of 16bits type are loaded/stored as multiples of v2x16 elements.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp:30,load,loaded,30,interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/NVPTX/NVPTXISelDAGToDAG.cpp,1,['load'],['loaded']
Performance,// very simple - openui5 was loaded before and will be used as is,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:29,load,loaded,29,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['load'],['loaded']
Performance,"// vi) Load up any picking rect and reset the perspective using the; // correct near/far clips distances",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/src/TGLPerspectiveCamera.cxx:7,Load,Load,7,graf3d/gl/src/TGLPerspectiveCamera.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/src/TGLPerspectiveCamera.cxx,1,['Load'],['Load']
Performance,"// virtual void SetUp() { }; // FIXME: We cannot rely on TearDown because it is executed at the end of; // every test. This triggers another bug in the dictionary generation phase,; // possibly due to concurrent file system operations.; //virtual void TearDown() {; // If there are failures we want to keep the created files.; //if (!::testing::Test::HasFatalFailure()); // cleanup();; //}",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/metacling/test/TClingTests.cxx:201,concurren,concurrent,201,core/metacling/test/TClingTests.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/metacling/test/TClingTests.cxx,1,['concurren'],['concurrent']
Performance,"// vmin and vmax aren't available in a scalar form, so we can use; // a NEON instruction with an undef lane instead. This has a performance; // penalty on some cores, so we don't do this unless we have been; // asked to by the core tuning model.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:128,perform,performance,128,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['perform'],['performance']
Performance,"// vmovrrd(load f64) -> (load i32), (load i32)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:11,load,load,11,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,3,['load'],['load']
Performance,"// void SetCache(const TGeoNodeCache *cache) {fCache = (TGeoNodeCache*)cache;}; //--- stack manipulation",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoNavigator.h:38,cache,cache,38,geom/geom/inc/TGeoNavigator.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoNavigator.h,2,['cache'],['cache']
Performance,// volatile loads with MVE intrinsics not supported,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp:12,load,loads,12,interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/ARMISelLowering.cpp,1,['load'],['loads']
Performance,// volatile loads with NEON intrinsics not supported,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp:12,load,loads,12,interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp,4,['load'],['loads']
Performance,"// wait because there is a chance that message queue does not exist yet",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/win32gdk/src/TGWin32ProxyBase.cxx:47,queue,queue,47,graf2d/win32gdk/src/TGWin32ProxyBase.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/win32gdk/src/TGWin32ProxyBase.cxx,1,['queue'],['queue']
Performance,"// wait for handshake from queue or update from SUB socket",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/worker.cxx:27,queue,queue,27,roofit/multiprocess/src/worker.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/worker.cxx,1,['queue'],['queue']
Performance,"// wait for queue to drain",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/thread/inc/TThreadPool.h:12,queue,queue,12,core/thread/inc/TThreadPool.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/thread/inc/TThreadPool.h,1,['queue'],['queue']
Performance,"// we always poll for readability; this allows us to queue pages; // early",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/BidirMMapPipe.cxx:53,queue,queue,53,roofit/roofitcore/src/BidirMMapPipe.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/BidirMMapPipe.cxx,1,['queue'],['queue']
Performance,"// we do not want to ignore the weights; // if (bEffective && (pass->GetSumw2()->fN == 0 || total->GetSumw2()->fN == 0) ) {; // Warning(""Divide"",""histogram have been computed with weights but the sum of weight squares are not stored in the histogram. Error calculation is performed ignoring the weights"");; // bEffective = false;; // }; //parse option",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TGraphAsymmErrors.cxx:272,perform,performed,272,hist/hist/src/TGraphAsymmErrors.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TGraphAsymmErrors.cxx,1,['perform'],['performed']
Performance,"// we do not want to ignore the weights; // if (bEffective && (pass->GetSumw2()->fN == 0 || total->GetSumw2()->fN == 0) ) {; // Warning(""Divide"",""histogram have been computed with weights but the sum of weight squares are not stored in the; // histogram. Error calculation is performed ignoring the weights""); bEffective = false;; // }; // parse option",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TGraphMultiErrors.cxx:276,perform,performed,276,hist/hist/src/TGraphMultiErrors.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/src/TGraphMultiErrors.cxx,1,['perform'],['performed']
Performance,"// we have to merge the tokens from the queue until we reach eof token or; // space token",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/MetaProcessor/MetaParser.cpp:40,queue,queue,40,interpreter/cling/lib/MetaProcessor/MetaParser.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/lib/MetaProcessor/MetaParser.cpp,1,['queue'],['queue']
Performance,"// we need silent file here because we need fast classification results; // getting number of variables and variable names from loader",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Factory.cxx:128,load,loader,128,tmva/tmva/src/Factory.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/src/Factory.cxx,1,['load'],['loader']
Performance,"// we need to be a bit careful: A returned safety value of TGeoShape::Big(); // is not the actual safety and should not be cached",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoNavigator.cxx:123,cache,cached,123,geom/geom/src/TGeoNavigator.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoNavigator.cxx,1,['cache'],['cached']
Performance,"// we only need one queue-worker pipe on the worker",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/Messenger.cxx:20,queue,queue-worker,20,roofit/multiprocess/src/Messenger.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/Messenger.cxx,1,['queue'],['queue-worker']
Performance,"// we select current pad, where all drawing is performed",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:47,perform,performed,47,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['perform'],['performed']
Performance,"// we start from the top BVH node; // algorithm is based on standard iterative tree traversal with priority queues",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx:108,queue,queues,108,geom/geom/src/TGeoParallelWorld.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/src/TGeoParallelWorld.cxx,1,['queue'],['queues']
Performance,"// we symlink this file as a ROOT cached file",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx:34,cache,cached,34,io/io/src/TFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/src/TFile.cxx,1,['cache'],['cached']
Performance,"// we're now on queue",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/ProcessManager.cxx:16,queue,queue,16,roofit/multiprocess/src/ProcessManager.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/multiprocess/src/ProcessManager.cxx,1,['queue'],['queue']
Performance,"// when cache allocation failed, try without cache",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/net/src/TWebFile.cxx:8,cache,cache,8,net/net/src/TWebFile.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/net/src/TWebFile.cxx,2,['cache'],['cache']
Performance,// when default value not specified - openui tries to load custom,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/ui5/eve7/controller/Ged.controller.js:54,load,load,54,ui5/eve7/controller/Ged.controller.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/ui5/eve7/controller/Ged.controller.js,2,['load'],['load']
Performance,"// when dialog used in standalone mode, ui5 panel will be loaded",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/browserv7/src/RFileDialog.cxx:58,load,loaded,58,gui/browserv7/src/RFileDialog.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/browserv7/src/RFileDialog.cxx,1,['load'],['loaded']
Performance,"// when libSystem.B.dylib is loaded we have finished loading all dylibs; // explicitly linked against the executable. Additional dylibs; // come when they are explicitly linked against loaded so's, currently; // we are not interested in these",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/unix/src/TUnixSystem.cxx:29,load,loaded,29,core/unix/src/TUnixSystem.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/unix/src/TUnixSystem.cxx,3,['load'],"['loaded', 'loading']"
Performance,"// when not all childs from very beginning is loaded, but may be required",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/ui5/browser/model/BrowserModel.js:46,load,loaded,46,ui5/browser/model/BrowserModel.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/ui5/browser/model/BrowserModel.js,1,['load'],['loaded']
Performance,"// when send queue below threshold, ignore highlight",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/ui5/eve7/lib/EveScene.js:13,queue,queue,13,ui5/eve7/lib/EveScene.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/ui5/eve7/lib/EveScene.js,1,['queue'],['queue']
Performance,"// when the second derivatives are negative perform a line search along Parameter which gives; // negative second derivative and magnitude equal to the Gradient step size.; // Recalculate the gradients for all the Parameter after the correction and; // continue iteration in case the second derivatives are still negative; //",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/NegativeG2LineSearch.cxx:44,perform,perform,44,math/minuit2/src/NegativeG2LineSearch.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/NegativeG2LineSearch.cxx,1,['perform'],['perform']
Performance,// when using stack locations for not load/store instructions; // print the same way as all normal 3 operand instructions.,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsAsmPrinter.cpp:38,load,load,38,interpreter/llvm-project/llvm/lib/Target/Mips/MipsAsmPrinter.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MipsAsmPrinter.cpp,2,['load'],['load']
Performance,"// where to jump in case of optimized boolen",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/inc/v5/TFormula.h:28,optimiz,optimized,28,hist/hist/inc/v5/TFormula.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/inc/v5/TFormula.h,1,['optimiz'],['optimized']
Performance,// while complete geo drawing can be removed until dat is loaded - just check and ignore callback,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:58,load,loaded,58,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['load'],['loaded']
Performance,"// why evaluate the last point again, can't we cache it?; // kbelasco: commenting out lines below to add/test caching support; //RooStats::SetParameters(&x, &fParameters);; //xL = fFunction->getVal();",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/MetropolisHastings.cxx:47,cache,cache,47,roofit/roostats/src/MetropolisHastings.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roostats/src/MetropolisHastings.cxx,1,['cache'],['cache']
Performance,// with the first readbuffer we read bigger amount to create header cache,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:68,cache,cache,68,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['cache'],['cache']
Performance,"// work queue lock guard",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RClusterPool.cxx:8,queue,queue,8,tree/ntuple/v7/src/RClusterPool.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/src/RClusterPool.cxx,1,['queue'],['queue']
Performance,// workaround for openui5 problem - called before actual dimension of HTML element is assigned; // issue longer resize timeout; // normall ui5 resize event with short timeout should follow very fast; // only then one can check size of element and perform rendering,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/ui5/canv/controller/CanvasPanel.controller.js:247,perform,perform,247,ui5/canv/controller/CanvasPanel.controller.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/ui5/canv/controller/CanvasPanel.controller.js,1,['perform'],['perform']
Performance,"// write a TTree and its friend to the same file:; // when t1 is read back, it automatically also loads its friend",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/test/regressions.cxx:98,load,loads,98,tree/treeplayer/test/regressions.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/treeplayer/test/regressions.cxx,1,['load'],['loads']
Performance,"// write back DSE - If we write back the same value we just loaded from; // the same location and haven't passed any intervening writes or ordering; // operations, we can remove the write. The primary benefit is in allowing; // the available load table to remain valid and value forward past where; // the store originally was.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp:60,load,loaded,60,interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Transforms/Scalar/EarlyCSE.cpp,2,['load'],"['load', 'loaded']"
Performance,"// wve adjust for variable bin sizes; ////////////////////////////////////////////////////////////////////////////////; /// Perform boundary safe 'intOrder'-th interpolation of weights in dimension 'dim'; /// at current value 'xval'; /// \param[in] iDim Index of the histogram dimension along which to interpolate.; /// \param[in] xval Value of histogram variable at dimension `iDim` for which; /// we want to interpolate the histogram weight.; /// \param[in] centralIdx Index of the bin that the point at which we; /// interpolate the histogram weight falls into; /// (can be obtained with `RooDataHist::calcTreeIndex`).; /// \param[in] intOrder Interpolation order, i.e. how many neighbouring bins are; /// used for the interpolation.; /// \param[in] correctForBinSize Enable the inverse bin volume correction factor.; /// \param[in] cdfBoundaries Enable the special boundary condition for a cdf:; /// underflow bins are assumed to have weight zero and; /// overflow bins have weight one. Otherwise, the; /// histogram is mirrored at the boundaries for the; /// interpolation.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooDataHist.cxx:124,Perform,Perform,124,roofit/roofitcore/src/RooDataHist.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/src/RooDataHist.cxx,1,['Perform'],['Perform']
Performance,"// x86 allows load folding with blendvb from the 2nd source operand. But; // we are still using LLVM select here (see comment below), so that's V1.; // If V2 can be load-folded and V1 cannot be load-folded, then commute to; // allow that load-folding possibility.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp:14,load,load,14,interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/X86ISelLowering.cpp,4,['load'],"['load', 'load-folded', 'load-folding']"
Performance,"// yes, CINT (GetOffset() is both wrong; // and caches that wrong result!",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:48,cache,caches,48,bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx,1,['cache'],['caches']
Performance,// z/OS XPLINK ADA Entry; // Wraps a TargetGlobalAddress that should be loaded from a function's; // AssociatedData Area (ADA). Tha ADA is passed to the function by the; // caller in the XPLink ABI defined register R5.; // Operand 0: the GlobalValue/External Symbol; // Operand 1: the ADA register; // Operand 2: the offset (0 for the first and 8 for the second element in the; // function descriptor),MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.h:72,load,loaded,72,interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/SystemZISelLowering.h,1,['load'],['loaded']
Performance,"// zext(C + x + y + ...) --> (zext(D) + zext((C - D) + x + y + ...)); // if D + (C - D + x + y + ...) could be proven to not unsigned wrap; // where D maximizes the number of trailing zeros of (C - D + x + y + ...); //; // Often address arithmetics contain expressions like; // (zext (add (shl X, C1), C2)), for instance, (zext (5 + (4 * X))).; // This transformation is useful while proving that such expressions are; // equal or differ by a small constant amount, see LoadStoreVectorizer pass.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp:470,Load,LoadStoreVectorizer,470,interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Analysis/ScalarEvolution.cpp,1,['Load'],['LoadStoreVectorizer']
Performance,"// { sums: cache, sum: sum }; Sum is in the last element.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js:11,cache,cache,11,js/build/jsroot.js,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/build/jsroot.js,2,['cache'],['cache']
Performance,"// {'deviance', 'exponential'}, optional (default='deviance'); //loss function to be optimized. 'deviance' refers to; //deviance (= logistic regression) for classification; //with probabilistic outputs. For loss 'exponential' gradient; //boosting recovers the AdaBoost algorithm.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/pymva/inc/TMVA/MethodPyGTB.h:85,optimiz,optimized,85,tmva/pymva/inc/TMVA/MethodPyGTB.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/pymva/inc/TMVA/MethodPyGTB.h,1,['optimiz'],['optimized']
Performance,"// } // namespace detail; //===----------------------------------------------------------------------===//; // CastIsPossible; //===----------------------------------------------------------------------===//; /// This struct provides a way to check if a given cast is possible. It provides; /// a static function called isPossible that is used to check if a cast can be; /// performed. It should be overridden like this:; ///; /// template<> struct CastIsPossible<foo, bar> {; /// static inline bool isPossible(const bar &b) {; /// return bar.isFoo();; /// }; /// };",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Support/Casting.h:375,perform,performed,375,interpreter/llvm-project/llvm/include/llvm/Support/Casting.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/include/llvm/Support/Casting.h,1,['perform'],['performed']
Performance,// } Load & Store,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/VE/VETargetTransformInfo.h:5,Load,Load,5,interpreter/llvm-project/llvm/lib/Target/VE/VETargetTransformInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/VE/VETargetTransformInfo.h,1,['Load'],['Load']
Performance,// }:mem_noshuf; // Loads must keep the original order ONLY if; // isMemReorderDisabled() == true,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/MCTargetDesc/HexagonShuffler.cpp:20,Load,Loads,20,interpreter/llvm-project/llvm/lib/Target/Hexagon/MCTargetDesc/HexagonShuffler.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Hexagon/MCTargetDesc/HexagonShuffler.cpp,1,['Load'],['Loads']
Performance,"// ~ISTRIP - do not strip 8th char bit; // ~IXOFF - software flow ctrl disabled for input queue",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/textinput/src/textinput/StreamReaderUnix.cpp:90,queue,queue,90,core/textinput/src/textinput/StreamReaderUnix.cpp,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/textinput/src/textinput/StreamReaderUnix.cpp,1,['queue'],['queue']
Performance,// ~NdbMTDir; /* -------- LoadENDF -------- */,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/test/periodic/NdbMTDir.cxx:26,Load,LoadENDF,26,test/periodic/NdbMTDir.cxx,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/test/periodic/NdbMTDir.cxx,1,['Load'],['LoadENDF']
Performance,"//! A regular 3D cache layer for fast point-based safety lookups",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoParallelWorld.h:17,cache,cache,17,geom/geom/inc/TGeoParallelWorld.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoParallelWorld.h,1,['cache'],['cache']
Performance,"//! Cached isConstant status",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooAbsArg.h:4,Cache,Cached,4,roofit/roofitcore/inc/RooAbsArg.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooAbsArg.h,1,['Cache'],['Cached']
Performance,"//! Length of cache entry.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/inc/TTreeCache.h:14,cache,cache,14,tree/tree/inc/TTreeCache.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/inc/TTreeCache.h,1,['cache'],['cache']
Performance,"//! Manager of cache with coefficient projections and transformations",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooAddPdf.h:15,cache,cache,15,roofit/roofitcore/inc/RooAddPdf.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooAddPdf.h,1,['cache'],['cache']
Performance,"//! Mark whether Load was executed.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TListOfDataMembers.h:17,Load,Load,17,core/meta/inc/TListOfDataMembers.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TListOfDataMembers.h,2,['Load'],['Load']
Performance,"//! Mutex for concurrent operations",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoVolume.h:14,concurren,concurrent,14,geom/geom/inc/TGeoVolume.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoVolume.h,1,['concurren'],['concurrent']
Performance,"//! Object owning cache contents",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooTreeDataStore.h:18,cache,cache,18,roofit/roofitcore/inc/RooTreeDataStore.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooTreeDataStore.h,1,['cache'],['cache']
Performance,"//! Pointer to global cache manager for any expensive components created by this object",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooAbsArg.h:22,cache,cache,22,roofit/roofitcore/inc/RooAbsArg.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooAbsArg.h,1,['cache'],['cache']
Performance,"//! Position in file of cache entry.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/tree/inc/TTreeCache.h:24,cache,cache,24,tree/tree/inc/TTreeCache.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/tree/inc/TTreeCache.h,1,['cache'],['cache']
Performance,//! Prevent 'AlwaysDirty' mode for this node; /* RooArgSet _leafNodeCache ; //! Cached leaf nodes */; /* RooArgSet _branchNodeCache //! Cached branch nodes */,MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooAbsArg.h:80,Cache,Cached,80,roofit/roofitcore/inc/RooAbsArg.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooAbsArg.h,2,['Cache'],['Cached']
Performance,"//! Represent interpreter state when we last did a full load.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TListOfDataMembers.h:56,load,load,56,core/meta/inc/TListOfDataMembers.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TListOfDataMembers.h,2,['load'],['load']
Performance,"//! TTree holding the cached function values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooTreeDataStore.h:22,cache,cached,22,roofit/roofitcore/inc/RooTreeDataStore.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooTreeDataStore.h,1,['cache'],['cached']
Performance,"//! The cache manager",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/inc/RooLagrangianMorphFunc.h:8,cache,cache,8,roofit/roofit/inc/RooLagrangianMorphFunc.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofit/inc/RooLagrangianMorphFunc.h,7,['cache'],['cache']
Performance,"//! The integration cache manager",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooRealSumFunc.h:20,cache,cache,20,roofit/roofitcore/inc/RooRealSumFunc.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooRealSumFunc.h,1,['cache'],['cache']
Performance,"//! box axes in global frame - cached for speed",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLBoundingBox.h:31,cache,cached,31,graf3d/gl/inc/TGLBoundingBox.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLBoundingBox.h,1,['cache'],['cached']
Performance,"//! box volume - cached for speed",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLBoundingBox.h:17,cache,cached,17,graf3d/gl/inc/TGLBoundingBox.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLBoundingBox.h,1,['cache'],['cached']
Performance,"//! cache for information; // Optimized expression",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/inc/v5/TFormula.h:4,cache,cache,4,hist/hist/inc/v5/TFormula.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/inc/v5/TFormula.h,2,"['Optimiz', 'cache']","['Optimized', 'cache']"
Performance,"//! cache logicals during scene rebuilds",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLScenePad.h:4,cache,cache,4,graf3d/gl/inc/TGLScenePad.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLScenePad.h,1,['cache'],['cache']
Performance,"//! cache logicals during scene rebuilds; // Debug tracing (for scene rebuilds)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLViewer.h:4,cache,cache,4,graf3d/gl/inc/TGLViewer.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLViewer.h,1,['cache'],['cache']
Performance,"//! cache of pid to index in fProcessGUIDs",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/cont/inc/TRefTable.h:4,cache,cache,4,core/cont/inc/TRefTable.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/cont/inc/TRefTable.h,1,['cache'],['cache']
Performance,"//! cache of states",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoNavigator.h:4,cache,cache,4,geom/geom/inc/TGeoNavigator.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoNavigator.h,1,['cache'],['cache']
Performance,"//! cache of the list of proxies. Avoids type casting.; // Debug stuff",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooAbsArg.h:4,cache,cache,4,roofit/roofitcore/inc/RooAbsArg.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooAbsArg.h,1,['cache'],['cache']
Performance,"//! cache; // Methods",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLPhysicalShape.h:4,cache,cache,4,graf3d/gl/inc/TGLPhysicalShape.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLPhysicalShape.h,1,['cache'],['cache']
Performance,"//! cached items dirty?",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLCamera.h:4,cache,cached,4,graf3d/gl/inc/TGLCamera.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLCamera.h,1,['cache'],['cached']
Performance,"//! cached value of maximum integer value generated",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Math/StdEngine.h:4,cache,cached,4,math/mathcore/inc/Math/StdEngine.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/inc/Math/StdEngine.h,1,['cache'],['cached']
Performance,"//! cached vector for x value (needed for TF1::EvalPar signature); //std::vector<double> fParams; // cached vector with parameter values",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/inc/Math/WrappedTF1.h:4,cache,cached,4,hist/hist/inc/Math/WrappedTF1.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/inc/Math/WrappedTF1.h,2,['cache'],['cached']
Performance,"//! current pointer to cached global matrix",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoNavigator.h:23,cache,cached,23,geom/geom/inc/TGeoNavigator.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/TGeoNavigator.h,1,['cache'],['cached']
Performance,"//! frustum planes (cached)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLCamera.h:20,cache,cached,20,graf3d/gl/inc/TGLCamera.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLCamera.h,1,['cache'],['cached']
Performance,"//! largest box diagonal seen in OfInterest() - used when; //! bootstrapping interest box; // Internal cache update - const as the actual camera configuration is unaffected",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLCamera.h:103,cache,cache,103,graf3d/gl/inc/TGLCamera.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLCamera.h,1,['cache'],['cache']
Performance,"//! list of caches; // Proxy management",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooAbsArg.h:12,cache,caches,12,roofit/roofitcore/inc/RooAbsArg.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/roofitcore/inc/RooAbsArg.h,1,['cache'],['caches']
Performance,"//! max box diagonal - cached for speed",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLBoundingBox.h:23,cache,cached,23,graf3d/gl/inc/TGLBoundingBox.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLBoundingBox.h,1,['cache'],['cached']
Performance,"//! modelView matrix (cached)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLCamera.h:22,cache,cached,22,graf3d/gl/inc/TGLCamera.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLCamera.h,1,['cache'],['cached']
Performance,"//! no-pick projection matrix (cached)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLCamera.h:31,cache,cached,31,graf3d/gl/inc/TGLCamera.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLCamera.h,1,['cache'],['cached']
Performance,"//! normalised box axes in global frame - cached for speed; // Methods",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLBoundingBox.h:42,cache,cached,42,graf3d/gl/inc/TGLBoundingBox.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLBoundingBox.h,1,['cache'],['cached']
Performance,"//! object space clip matrix (cached)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLCamera.h:30,cache,cached,30,graf3d/gl/inc/TGLCamera.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLCamera.h,1,['cache'],['cached']
Performance,"//! projection matrix (cached)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLCamera.h:23,cache,cached,23,graf3d/gl/inc/TGLCamera.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/inc/TGLCamera.h,1,['cache'],['cached']
Performance,"//! true if the StreamerInfo has been optimized",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TVirtualStreamerInfo.h:38,optimiz,optimized,38,core/meta/inc/TVirtualStreamerInfo.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TVirtualStreamerInfo.h,1,['optimiz'],['optimized']
Performance,"//!Current 'state' of the class (Emulated,Interpreted,Loaded)",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TClass.h:54,Load,Loaded,54,core/meta/inc/TClass.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TClass.h,1,['Load'],['Loaded']
Performance,"//!Number of operators after optimization",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/hist/inc/v5/TFormula.h:29,optimiz,optimization,29,hist/hist/inc/v5/TFormula.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hist/inc/v5/TFormula.h,1,['optimiz'],['optimization']
Performance,"//!Whether info was loaded from a root pcm.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TClass.h:20,load,loaded,20,core/meta/inc/TClass.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TClass.h,1,['load'],['loaded']
Performance,"//!cached current streamer info.",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TClass.h:3,cache,cached,3,core/meta/inc/TClass.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TClass.h,1,['cache'],['cached']
Performance,"//!cached of the streaming method to use",MatchSource.CODE_COMMENT,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TClass.h:3,cache,cached,3,core/meta/inc/TClass.h,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/meta/inc/TClass.h,1,['cache'],['cached']
