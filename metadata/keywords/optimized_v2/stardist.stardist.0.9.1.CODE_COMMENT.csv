quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,filename,wiki,url,total_similar,target_keywords,target_matched_words
Availability," leave=True); # labels_eliminated = set(); # # TODO: inelegant to have so much duplicated code here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1597,mask,mask,1597,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['mask'],['mask']
Availability," the index in the polys dict; # """"""; # assert output.ndim in (2,3); # if show_progress:; # labels = tqdm(labels, leave=True); # labels_eliminated = set(); # # TODO: inelegant to have so much duplicated code here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays,",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1443,mask,mask,1443,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,2,['mask'],['mask']
Availability,""""""" Fluorescence microscopy image and mask from the 2018 kaggle DSB challenge. Caicedo et al. ""Nucleus segmentation across imaging experiments: the 2018 Data Science Bowl."" Nature methods 16.12; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/data/__init__.py:38,mask,mask,38,stardist/data/__init__.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/data/__init__.py,1,['mask'],['mask']
Availability,"""""""; Returns all indices of an image that ; - can be used as center points for sampling patches of a given patch_size, and; - are part of the boolean mask given by the function patch_filter (if provided). img: np.ndarray; patch_size: tuple of ints ; the width of patches per img dimension, ; patch_filter: None or callable; a function with signature patch_filter(img, patch_size) returning a boolean mask ; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py:150,mask,mask,150,stardist/sample_patches.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py,2,['mask'],['mask']
Availability,"""""""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate ",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:830,down,down,830,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['down'],['down']
Availability,"""""""Optimize two thresholds (probability, NMS overlap) necessary for predicting object instances. Note that the default thresholds yield good results in many cases, but optimizing; the thresholds for a particular dataset can further improve performance. The optimized thresholds are automatically used for all further predictions; and also written to the model directory. See ``utils.optimize_threshold`` for details and possible choices for ``optimize_kwargs``. Parameters; ----------; X_val : list of ndarray; (Validation) input images (must be normalized) to use for threshold tuning.; Y_val : list of ndarray; (Validation) label images to use for threshold tuning.; nms_threshs : list of float; List of overlap thresholds to be considered for NMS.; For each value in this list, optimization is run to find a corresponding prob_thresh value.; iou_threshs : list of float; List of intersection over union (IOU) thresholds for which; the (average) matching performance is considered to tune the thresholds.; predict_kwargs: dict; Keyword arguments for ``predict`` function of this class.; (If not provided, will guess value for `n_tiles` to prevent out of memory errors.); optimize_kwargs: dict; Keyword arguments for ``utils.optimize_threshold`` function. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1163,error,errors,1163,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['error'],['errors']
Availability,"""""""Predict. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool or callable; If boolean, indicates whether to show progress (via tqdm) during tiled prediction.; If callable, must be a drop-in replacement for tqdm.; show_tile_progress: bool; Whether to show progress during tiled prediction.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model. Returns; -------; (:class:`numpy.ndarray`, :class:`numpy.ndarray`, [:class:`numpy.ndarray`]); Returns the tuple (`prob`, `dist`, [`prob_class`]) of per-pixel object probabilities and star-convex polygon/polyhedra distances.; In multiclass prediction mode, `prob_class` is the probability map for each of the 1+'n_classes' classes (first class is background). """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:440,error,errors,440,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['error'],['errors']
Availability,"""""""Renders an image that shows segmentation errors between y_true and y_pred . Correctly matched objects (TP) are colored green (with transparency tp_alpha); Erronously detected objects (FP) are colored red (with transparency fp_alpha); MIssing GT objects (FN) are colored blue (with transparency fn_alpha). Parameters; ----------; y_true: np.ndarray of dtype np.uint16; The 2D GT label image ; y_pred: np.ndarray of dtype np.uint16; The 2D prediction label image ; img: np.ndarray ; The array to overlay the label image with (optional); cmap_img: string or callable; The colormap of img (optional); tp_alpha: float ; The alpha value of the TP ; fp_alpha: float ; The alpha value of the FP ; fn_alpha: float ; The alpha value of the FN ; matching_kwargs: dict; The parameters of stardist.matching.matching that are used to compute the TP/FP/FN; normalize_img: bool; If True, normalizes the img (if given). Returns; -------; img: np.ndarray; the (m,n,4) RGBA image of the rendered image. Example; ------- . from scipy.ndimage import label, zoom ; img = zoom(np.random.uniform(0,1,(16,16)),(8,8),order=3); y_true = label(img>.9)[0]; y_pred = label(img>.02)[0]; plt.imshow(render_label_pred(y_true, y_pred, img=img)). """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py:44,error,errors,44,stardist/plot/render.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py,1,['error'],['errors']
Availability,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:209,mask,masks,209,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,4,['mask'],"['mask', 'masks']"
Availability,"""""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_si",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1029,down,down,1029,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['down'],['down']
Availability,"# TODO: downsample here before stacking?",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:8,down,downsample,8,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['down'],['downsample']
Availability,"# TODO: investigate downsampling via simple indexing vs. using 'zoom'; # prob_class = prob_class[self.ss_grid]; # 'zoom' might lead to better registered maps (especially if upscaled later)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:20,down,downsampling,20,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,2,['down'],['downsampling']
Availability,"# assert np.all(p.mask == mask_i) # few pixels are sometimes different, why?",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:18,mask,mask,18,tests/test_big.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py,1,['mask'],['mask']
Availability,"# download the full model content to a temporary folder",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:2,down,download,2,stardist/bioimageio_utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py,1,['down'],['download']
Availability,"# if e.args[0]: # object larger than block write region; # assert any(o >= b for o,b in zip(shape_object,shape_block_write)); # # problem, since this object will probably be saved by another block too; # raise RuntimeError(f""Found object of shape {shape_object}, larger than an entire block's write region of shape {shape_block_write}. Increase 'block_size' to avoid this problem.""); # # print(""found object larger than 'block_size'""); # else:; # assert any(o >= b for o,b in zip(shape_object,shape_min_overlap)); # # print(""found object larger than 'min_overlap'""); # # keep object, because will be dealt with later, i.e.; # # render the poly again into the label image, but this is not; # # ideal since the assumption is that the object outside that; # # region is not reliable because it's in the context; # labels_filtered[slices][r.image] = r.label; # problem_ids.append(r.label)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:771,reliab,reliable,771,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['reliab'],['reliable']
Availability,"# ignore image boundary, since predictions may not be reliable",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py:54,reliab,reliable,54,stardist/utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py,1,['reliab'],['reliable']
Availability,"# mask = prob > prob_thresh; # if b is not None and b > 0:; # _mask = np.zeros_like(mask); # _mask[b:-b,b:-b] = True; # mask &= _mask",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py:2,mask,mask,2,stardist/nms.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py,6,['mask'],['mask']
Availability,"# mask of object with id i in label image (not occluded since nms_thresh=0)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:2,mask,mask,2,tests/test_big.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py,2,['mask'],['mask']
Availability,"# mask to make labels negative",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:2,mask,mask,2,tests/test_model2D.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py,2,['mask'],['mask']
Availability,"# no foreground pixels available",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:23,avail,available,23,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['avail'],['available']
Availability,"# thanks to @jaimergp (https://github.com/conda-forge/staged-recipes/pull/17766); # issue: qhull has a mix of c and c++ source files; # gcc warns about passing -std=c++11 for c files, but clang errors out",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/setup.py:194,error,errors,194,setup.py,,https://github.com/stardist/stardist/tree/0.9.1/setup.py,1,['error'],['errors']
Availability,"# x[s][mask] = labels[mask] # doesn't work with zarr",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:7,mask,mask,7,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,2,['mask'],['mask']
Availability,"-------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable t",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1066,down,down-sampling,1066,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['down'],['down-sampling']
Availability,"=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # if len(labels_eliminated) > 0:; # ind = [i-1 for i in labels_eliminated]; # for k,v in polys.items():; # if k in OBJECT_KEYS:; # polys[k] = np.delete(v, ind, axis=0); ############",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:2679,mask,mask,2679,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,8,['mask'],['mask']
Availability,"coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # if len(labels_eliminated) > 0:; # ind = [i-1 for i in labels_eliminated]; # for k,v in polys.items():; # if k in OBJECT_KEYS:; # polys[k] = np.delete(v, ind, axis=0); ",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:2289,mask,mask,2289,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['mask'],['mask']
Availability,"de here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # ",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1707,mask,mask,1707,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,2,['mask'],['mask']
Availability,"labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1815,mask,mask,1815,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['mask'],['mask']
Availability,"n probability scores.; # Does modify 'output' and 'polys' in-place, but will only write sparsely to 'output' where needed.; # output: numpy.ndarray or similar; # Label image (integer-valued); # labels: iterable of int; # List of integer label ids that occur in output; # polys: dict; # Dictionary of polygon/polyhedra properties.; # Assumption is that the label id (-1) corresponds to the index in the polys dict; # """"""; # assert output.ndim in (2,3); # if show_progress:; # labels = tqdm(labels, leave=True); # labels_eliminated = set(); # # TODO: inelegant to have so much duplicated code here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhe",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1047,mask,mask,1047,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['mask'],['mask']
Availability,"nts``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : floa",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1792,down,downsampling,1792,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['down'],['downsampling']
Availability,"of int; # List of integer label ids that occur in output; # polys: dict; # Dictionary of polygon/polyhedra properties.; # Assumption is that the label id (-1) corresponds to the index in the polys dict; # """"""; # assert output.ndim in (2,3); # if show_progress:; # labels = tqdm(labels, leave=True); # labels_eliminated = set(); # # TODO: inelegant to have so much duplicated code here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; #",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1393,mask,mask,1393,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['mask'],['mask']
Availability,"ormalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; sparse: bool; If true, aggregate probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; overlap_label: scalar or None; if not None, label the regions where polygons overlap with that value; return_predict: bool; Also return the outputs of :func:`predict` (in a separate tuple); If True, implies sparse = False. Returns; -------; (:class:`numpy.ndarray`, dict), (optional: return tuple of :func:`pr",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1308,error,errors,1308,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['error'],['errors']
Availability,"tionary of polygon/polyhedra properties.; # Assumption is that the label id (-1) corresponds to the index in the polys dict; # """"""; # assert output.ndim in (2,3); # if show_progress:; # labels = tqdm(labels, leave=True); # labels_eliminated = set(); # # TODO: inelegant to have so much duplicated code here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1407,mask,mask,1407,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['mask'],['mask']
Availability,"umber of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be s",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1269,down,down-sampling,1269,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['down'],['down-sampling']
Deployability,"""""""; //*******************************************************************; // Date: July-2021; // Credits: StarDist, DeepImageJ; // URL:; // https://github.com/stardist/stardist; // https://deepimagej.github.io/deepimagej; // This macro was adapted from; // https://github.com/deepimagej/imagej-macros/blob/648caa867f6ccb459649d4d3799efa1e2e0c5204/StarDist2D_Post-processing.ijm; // Please cite the respective contributions when using this code.; //*******************************************************************; // Macro to run StarDist postprocessing on 2D images.; // StarDist and deepImageJ plugins need to be installed.; // The macro assumes that the image to process is a stack in which; // the first channel corresponds to the object probability map; // and the remaining channels are the radial distances from each; // pixel to the object boundary.; //*******************************************************************. // Get the name of the image to call it; getDimensions(width, height, channels, slices, frames);; name=getTitle();. probThresh={probThresh};; nmsThresh={nmsThresh};. // Isolate the detection probability scores; run(""Make Substack..."", ""channels=1"");; rename(""scores"");. // Isolate the oriented distances; run(""Fire"");; selectWindow(name);; run(""Delete Slice"", ""delete=channel"");; selectWindow(name);; run(""Properties..."", ""channels="" + maxOf(channels, slices) - 1 + "" slices=1 frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=1.0000"");; rename(""distances"");; run(""royal"");. // Run StarDist plugin; run(""Command From Macro"", ""command=[de.csbdresden.stardist.StarDist2DNMS], args=['prob':'scores', 'dist':'distances', 'probThresh':'"" + probThresh + ""', 'nmsThresh':'"" + nmsThresh + ""', 'outputType':'Both', 'excludeBoundary':'2', 'roiPosition':'Stack', 'verbose':'false'], process=[false]"");; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:620,install,installed,620,stardist/bioimageio_utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py,1,['install'],['installed']
Deployability,"""""""; Returns all indices of an image that ; - can be used as center points for sampling patches of a given patch_size, and; - are part of the boolean mask given by the function patch_filter (if provided). img: np.ndarray; patch_size: tuple of ints ; the width of patches per img dimension, ; patch_filter: None or callable; a function with signature patch_filter(img, patch_size) returning a boolean mask ; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py:88,patch,patches,88,stardist/sample_patches.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py,2,['patch'],['patches']
Deployability,"""""""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate ",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:713,configurat,configuration,713,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['configurat'],['configuration']
Deployability,"""""""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_s",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:912,configurat,configuration,912,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['configurat'],['configuration']
Deployability,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:505,configurat,configuration,505,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,2,['configurat'],['configuration']
Deployability,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:505,configurat,configuration,505,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,2,['configurat'],['configuration']
Deployability,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1396,patch,patches,1396,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,2,['patch'],['patches']
Deployability,"# TODO: option to update labels in-place",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:18,update,update,18,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['update'],['update']
Deployability,"# ask to train only with foreground patches when there are none; # include a constant label image that must trigger a warning",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:36,patch,patches,36,tests/test_model2D.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py,2,['patch'],['patches']
Deployability,"# build the list of class ids per label via majority vote; # zoom prob_class to img_shape; # prob_class_up = zoom(prob_class,; # tuple(s2/s1 for s1, s2 in zip(prob_class.shape[:3], img_shape))+(1,),; # order=0); # class_id, label_ids = [], []; # for reg in regionprops(labels):; # m = labels[reg.slice]==reg.label; # cls_id = np.argmax(np.mean(prob_class_up[reg.slice][m], axis = 0)); # class_id.append(cls_id); # label_ids.append(reg.label); # # just a sanity check whether labels where in sorted order; # assert all(x <= y for x,y in zip(label_ids, label_ids[1:])); # res_dict.update(dict(classes = class_id)); # res_dict.update(dict(labels = label_ids)); # self.p = prob_class_up",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:579,update,update,579,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,2,['update'],['update']
Deployability,"# copied from scikit-image master for now (remove when part of a release)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py:65,release,release,65,stardist/matching.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py,1,['release'],['release']
Deployability,"# def _instances_from_prediction_old(self, img_shape, prob, dist,points = None, prob_class = None, prob_thresh=None, nms_thresh=None, overlap_label = None, **nms_kwargs):; # from stardist.geometry.geom2d import _polygons_to_label_old, _dist_to_coord_old; # from stardist.nms import _non_maximum_suppression_old; # if prob_thresh is None: prob_thresh = self.thresholds.prob; # if nms_thresh is None: nms_thresh = self.thresholds.nms; # if overlap_label is not None: raise NotImplementedError(""overlap_label not supported for 2D yet!""); # coord = _dist_to_coord_old(dist, grid=self.config.grid); # inds = _non_maximum_suppression_old(coord, prob, grid=self.config.grid,; # prob_thresh=prob_thresh, nms_thresh=nms_thresh, **nms_kwargs); # labels = _polygons_to_label_old(coord, prob, inds, shape=img_shape); # # sort 'inds' such that ids in 'labels' map to entries in polygon dictionary entries; # inds = inds[np.argsort(prob[inds[:,0],inds[:,1]])]; # # adjust for grid; # points = inds*np.array(self.config.grid); # res_dict = dict(coord=coord[inds[:,0],inds[:,1]], points=points, prob=prob[inds[:,0],inds[:,1]]); # if prob_class is not None:; # prob_class = np.asarray(prob_class); # res_dict.update(dict(class_prob = prob_class)); # return labels, res_dict",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1192,update,update,1192,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['update'],['update']
Deployability,"# integration test",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:2,integrat,integration,2,tests/test_model2D.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py,2,['integrat'],['integration']
Deployability,"# monkey patch the _compile method",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/setup.py:9,patch,patch,9,setup.py,,https://github.com/stardist/stardist/tree/0.9.1/setup.py,1,['patch'],['patch']
Deployability,"# warnings.warn(""Could not find package edt... \nConsider installing it with \n pip install edt\nto improve training data generation performance."")",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py:58,install,installing,58,stardist/utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py,4,['install'],"['install', 'installing']"
Deployability,"-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1885,patch,patches,1885,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['patch'],['patches']
Deployability,"=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # if len(labels_eliminated) > 0:; # ind = [i-1 for i in labels_eliminated]; # for k,v in polys.items():; # if k in OBJECT_KEYS:; # polys[k] = np.delete(v, ind, axis=0); ############",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:3155,update,update,3155,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['update'],['update']
Deployability,"els (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:2018,patch,patch,2018,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,4,"['patch', 'update']","['patch', 'patches', 'update']"
Deployability,"kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard f",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1673,patch,patches,1673,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['patch'],['patches']
Deployability,"ling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:2242,patch,patches,2242,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['patch'],['patches']
Deployability,"np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # cr",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1850,update,update,1850,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['update'],['update']
Deployability,"nt; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1574,patch,patches,1574,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['patch'],['patches']
Deployability,"tion layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:2375,patch,patch,2375,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,4,"['patch', 'update']","['patch', 'patches', 'update']"
Deployability,"up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_n_val_patches : int; Number of patches to be extracted from validation images",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:2030,patch,patches,2030,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['patch'],['patches']
Energy Efficiency,"""""""; //*******************************************************************; // Date: July-2021; // Credits: StarDist, DeepImageJ; // URL:; // https://github.com/stardist/stardist; // https://deepimagej.github.io/deepimagej; // This macro was adapted from; // https://github.com/deepimagej/imagej-macros/blob/648caa867f6ccb459649d4d3799efa1e2e0c5204/StarDist2D_Post-processing.ijm; // Please cite the respective contributions when using this code.; //*******************************************************************; // Macro to run StarDist postprocessing on 2D images.; // StarDist and deepImageJ plugins need to be installed.; // The macro assumes that the image to process is a stack in which; // the first channel corresponds to the object probability map; // and the remaining channels are the radial distances from each; // pixel to the object boundary.; //*******************************************************************. // Get the name of the image to call it; getDimensions(width, height, channels, slices, frames);; name=getTitle();. probThresh={probThresh};; nmsThresh={nmsThresh};. // Isolate the detection probability scores; run(""Make Substack..."", ""channels=1"");; rename(""scores"");. // Isolate the oriented distances; run(""Fire"");; selectWindow(name);; run(""Delete Slice"", ""delete=channel"");; selectWindow(name);; run(""Properties..."", ""channels="" + maxOf(channels, slices) - 1 + "" slices=1 frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=1.0000"");; rename(""distances"");; run(""royal"");. // Run StarDist plugin; run(""Command From Macro"", ""command=[de.csbdresden.stardist.StarDist2DNMS], args=['prob':'scores', 'dist':'distances', 'probThresh':'"" + probThresh + ""', 'nmsThresh':'"" + nmsThresh + ""', 'outputType':'Both', 'excludeBoundary':'2', 'roiPosition':'Stack', 'verbose':'false'], process=[false]"");; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:242,adapt,adapted,242,stardist/bioimageio_utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py,1,['adapt'],['adapted']
Energy Efficiency,"""""""; h0 = 0 -> red; h0 = 0.33 -> green; h0 = 0.66 -> blue; h0 = 0.833 -> magenta; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py:33,green,green,33,stardist/plot/render.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py,1,['green'],['green']
Energy Efficiency,"""""""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate ",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:214,power,power,214,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,2,['power'],"['power', 'powers']"
Energy Efficiency,"""""""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_s",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:373,power,powers,373,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['power'],['powers']
Energy Efficiency,"""""""Relabel arbitrary labels to {`offset`, ... `offset` + number_of_labels}. This function also returns the forward map (mapping the original labels to; the reduced labels) and the inverse map (mapping the reduced labels back; to the original ones). Parameters; ----------; label_field : numpy array of int, arbitrary shape; An array of labels, which must be non-negative integers.; offset : int, optional; The return labels will start at `offset`, which should be; strictly positive. Returns; -------; relabeled : numpy array of int, same shape as `label_field`; The input label field with labels mapped to; {offset, ..., number_of_labels + offset - 1}.; The data type will be the same as `label_field`, except when; offset + number_of_labels causes overflow of the current data type.; forward_map : numpy array of int, shape ``(label_field.max() + 1,)``; The map from the original label space to the returned label; space. Can be used to re-apply the same mapping. See examples; for usage. The data type will be the same as `relabeled`.; inverse_map : 1D numpy array of int, of length offset + number of labels; The map from the new label space to the original space. This; can be used to reconstruct the original label field from the; relabeled one. The data type will be the same as `relabeled`. Notes; -----; The label 0 is assumed to denote the background and is never remapped. The forward map can be extremely big for some inputs, since its; length is given by the maximum of the label field. However, in most; situations, ``label_field.max()`` is much smaller than; ``label_field.size``, and in these cases the forward map is; guaranteed to be smaller than either the input or output images. Examples; --------; >>> from skimage.segmentation import relabel_sequential; >>> label_field = np.array([1, 1, 5, 5, 8, 99, 42]); >>> relab, fw, inv = relabel_sequential(label_field); >>> relab; array([1, 1, 2, 2, 3, 5, 4]); >>> fw; array([0, 1, 0, 0, 0, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py:156,reduce,reduced,156,stardist/matching.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py,2,['reduce'],['reduced']
Energy Efficiency,"""""""Renders an image that shows segmentation errors between y_true and y_pred . Correctly matched objects (TP) are colored green (with transparency tp_alpha); Erronously detected objects (FP) are colored red (with transparency fp_alpha); MIssing GT objects (FN) are colored blue (with transparency fn_alpha). Parameters; ----------; y_true: np.ndarray of dtype np.uint16; The 2D GT label image ; y_pred: np.ndarray of dtype np.uint16; The 2D prediction label image ; img: np.ndarray ; The array to overlay the label image with (optional); cmap_img: string or callable; The colormap of img (optional); tp_alpha: float ; The alpha value of the TP ; fp_alpha: float ; The alpha value of the FP ; fn_alpha: float ; The alpha value of the FN ; matching_kwargs: dict; The parameters of stardist.matching.matching that are used to compute the TP/FP/FN; normalize_img: bool; If True, normalizes the img (if given). Returns; -------; img: np.ndarray; the (m,n,4) RGBA image of the rendered image. Example; ------- . from scipy.ndimage import label, zoom ; img = zoom(np.random.uniform(0,1,(16,16)),(8,8),order=3); y_true = label(img>.9)[0]; y_pred = label(img>.02)[0]; plt.imshow(render_label_pred(y_true, y_pred, img=img)). """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py:122,green,green,122,stardist/plot/render.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py,1,['green'],['green']
Energy Efficiency,"# TODO: relabel_sequential is not very memory-efficient (will allocate memory proportional to label_offset); # this should not change the order of labels",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:46,efficient,efficient,46,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,2,"['allocate', 'efficient']","['allocate', 'efficient']"
Energy Efficiency,"# green",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py:2,green,green,2,stardist/plot/render.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py,1,['green'],['green']
Energy Efficiency,"_instances` and assemble all the partial results. If used as intended, the result; should be the same as if `predict_instances` was used directly on the whole image. **Important**: The crucial assumption is that all predicted object instances are smaller than; the provided `min_overlap`. Also, it must hold that: min_overlap + 2*context < block_size. Example; -------; >>> img.shape; (20000, 20000); >>> labels, polys = model.predict_instances_big(img, axes='YX', block_size=4096,; min_overlap=128, context=128, n_tiles=(4,4)). Parameters; ----------; img: :class:`numpy.ndarray` or similar; Input image; axes: str; Axes of the input ``img`` (such as 'YX', 'ZYX', 'YXC', etc.); block_size: int or iterable of int; Process input image in blocks of the provided shape.; (If a scalar value is given, it is used for all spatial image dimensions.); min_overlap: int or iterable of int; Amount of guaranteed overlap between blocks.; (If a scalar value is given, it is used for all spatial image dimensions.); context: int or iterable of int, or None; Amount of image context on all sides of a block, which is discarded.; If None, uses an automatic estimate that should work in many cases.; (If a scalar value is given, it is used for all spatial image dimensions.); labels_out: :class:`numpy.ndarray` or similar, or None, or False; numpy array or similar (must be of correct shape) to which the label image is written.; If None, will allocate a numpy array of the correct shape and data type ``labels_out_dtype``.; If False, will not write the label image (useful if only the dictionary is needed).; labels_out_dtype: str or dtype; Data type of returned label image if ``labels_out=None`` (has no effect otherwise).; show_progress: bool; Show progress bar for block processing.; kwargs: dict; Keyword arguments for ``predict_instances``. Returns; -------; (:class:`numpy.ndarray` or False, dict); Returns the label image and a dictionary with the details (coordinates, etc.) of the polygons/polyhedra. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1676,allocate,allocate,1676,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['allocate'],['allocate']
Energy Efficiency,"els (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:2682,monitor,monitoring,2682,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['monitor'],['monitoring']
Energy Efficiency,"tion layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:2920,monitor,monitoring,2920,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['monitor'],['monitoring']
Integrability,"""""""; creates labeled image from stardist representations. :param dist: array of shape (n_points,n_rays); the list of distances for each point and ray; :param points: array of shape (n_points, 3); the list of center points; :param rays: Rays object; Ray object (e.g. `stardist.Rays_GoldenSpiral`) defining; vertices and faces; :param shape: (nz,ny,nx); output shape of the image; :param prob: array of length/shape (n_points,) or None; probability per polyhedron; :param thr: scalar; probability threshold (only polyhedra with prob>thr are labeled); :param labels: array of length/shape (n_points,) or None; labels to use; :param mode: str; labeling mode, can be ""full"", ""kernel"", ""hull"", ""bbox"" or ""debug""; :param verbose: bool; enable to print some debug messages; :param overlap_label: scalar or None; if given, will label each pixel that belongs ot more than one polyhedron with that label; :return: array of given shape; labeled image; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/geometry/geom3d.py:756,message,messages,756,stardist/geometry/geom3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/geometry/geom3d.py,1,['message'],['messages']
Integrability,"""""""Export stardist model into bioimage.io format, https://github.com/bioimage-io/spec-bioimage-io. Parameters; ----------; model: StarDist2D, StarDist3D; the model to convert; outpath: str, Path; where to save the model; test_input: np.ndarray; input image for generating test data; test_input_axes: str or None; the axes of the test input, for example 'YX' for a 2d image or 'ZYX' for a 3d volume; using None assumes that axes of test_input are the same as those of model; test_input_norm_axes: str; the axes of the test input which will be jointly normalized, for example 'ZYX' for all spatial dimensions ('Z' ignored for 2D input); use 'ZYXC' to also jointly normalize channels (e.g. for RGB input images); name: str; the name of this model (default: None); if None, uses the (folder) name of the model (i.e. `model.name`); mode: str; the export type for this model (default: ""tensorflow_saved_model_bundle""); min_percentile: float; min percentile to be used for image normalization (default: 1.0); max_percentile: float; max percentile to be used for image normalization (default: 99.8); overwrite_spec_kwargs: dict or None; spec keywords that should be overloaded (default: None); generate_default_deps: bool; not required for bioimage.io, i.e. StarDist models don't need a dependencies field in rdf.yaml (default: False); if True, generate an environment.yaml file recording the python, bioimageio.core, stardist and tensorflow requirements; from which a conda environment can be recreated to run this export; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:1279,depend,dependencies,1279,stardist/bioimageio_utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py,1,['depend'],['dependencies']
Integrability,"# dependencies that start with the name ""bioimageio"" will be added as conda dependencies",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:2,depend,dependencies,2,stardist/bioimageio_utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py,2,['depend'],['dependencies']
Integrability,"# integration test",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:2,integrat,integration,2,tests/test_model2D.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py,2,['integrat'],['integration']
Integrability,"# only stardist and tensorflow as pip dependencies",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:38,depend,dependencies,38,stardist/bioimageio_utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py,1,['depend'],['dependencies']
Integrability,"# the reason why the actual computation happens as a generator function; # (in '_predict_instances_generator') is that the generator is called; # from the stardist napari plugin, which has its benefits regarding; # control flow and progress display. however, typical use cases should; # almost always use this function ('predict_instances'), and shouldn't; # even notice (thanks to @functools.wraps) that it wraps the generator; # function. note that similar reasoning applies to 'predict' and; # 'predict_sparse'.; # return last ""yield""ed value of generator",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:393,wrap,wraps,393,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,2,['wrap'],['wraps']
Integrability,"e probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; overlap_label: scalar or None; if not None, label the regions where polygons overlap with that value; return_predict: bool; Also return the outputs of :func:`predict` (in a separate tuple); If True, implies sparse = False. Returns; -------; (:class:`numpy.ndarray`, dict), (optional: return tuple of :func:`predict`); Returns a tuple of the label instances image and also; a dictionary with the details (coordinates, etc.) of all remaining polygons/polyhedra. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1749,message,messages,1749,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['message'],['messages']
Modifiability," the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_r",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1142,layers,layers,1142,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['layers'],['layers']
Modifiability,"""""""; //*******************************************************************; // Date: July-2021; // Credits: StarDist, DeepImageJ; // URL:; // https://github.com/stardist/stardist; // https://deepimagej.github.io/deepimagej; // This macro was adapted from; // https://github.com/deepimagej/imagej-macros/blob/648caa867f6ccb459649d4d3799efa1e2e0c5204/StarDist2D_Post-processing.ijm; // Please cite the respective contributions when using this code.; //*******************************************************************; // Macro to run StarDist postprocessing on 2D images.; // StarDist and deepImageJ plugins need to be installed.; // The macro assumes that the image to process is a stack in which; // the first channel corresponds to the object probability map; // and the remaining channels are the radial distances from each; // pixel to the object boundary.; //*******************************************************************. // Get the name of the image to call it; getDimensions(width, height, channels, slices, frames);; name=getTitle();. probThresh={probThresh};; nmsThresh={nmsThresh};. // Isolate the detection probability scores; run(""Make Substack..."", ""channels=1"");; rename(""scores"");. // Isolate the oriented distances; run(""Fire"");; selectWindow(name);; run(""Delete Slice"", ""delete=channel"");; selectWindow(name);; run(""Properties..."", ""channels="" + maxOf(channels, slices) - 1 + "" slices=1 frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=1.0000"");; rename(""distances"");; run(""royal"");. // Run StarDist plugin; run(""Command From Macro"", ""command=[de.csbdresden.stardist.StarDist2DNMS], args=['prob':'scores', 'dist':'distances', 'probThresh':'"" + probThresh + ""', 'nmsThresh':'"" + nmsThresh + ""', 'outputType':'Both', 'excludeBoundary':'2', 'roiPosition':'Stack', 'verbose':'false'], process=[false]"");; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:242,adapt,adapted,242,stardist/bioimageio_utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py,3,"['adapt', 'plugin']","['adapted', 'plugin', 'plugins']"
Modifiability,"""""""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate ",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:713,config,configuration,713,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,3,"['config', 'layers']","['configuration', 'layers']"
Modifiability,"""""""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_s",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:912,config,configuration,912,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['config'],['configuration']
Modifiability,"""""""Export model to TensorFlow's SavedModel format that can be used e.g. in the Fiji plugin. Parameters; ----------; fname : str; Path of the zip file to store the model; If None, the default path ""<modeldir>/TF_SavedModel.zip"" is used; single_output: bool; If set, concatenates the two model outputs into a single output (note: this is currently mandatory for further use in Fiji); upsample_grid: bool; If set, upsamples the output to the input shape (note: this is currently mandatory for further use in Fiji); """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:84,plugin,plugin,84,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['plugin'],['plugin']
Modifiability,"""""""Predict instance segmentation from input image. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; sparse: bool; If true, aggregate probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; ov",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:231,config,config,231,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['config'],['config']
Modifiability,"""""""Predict. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool or callable; If boolean, indicates whether to show progress (via tqdm) during tiled prediction.; If callable, must be a drop-in replacement for tqdm.; show_tile_progress: bool; Whether to show progress during tiled prediction.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model. Returns; -------; (:class:`numpy.ndarray`, :class:`numpy.ndarray`, [:class:`numpy.ndarray`]); Returns the tuple (`prob`, `dist`, [`prob_class`]) of per-pixel object probabilities and star-convex polygon/polyhedra distances.; In multiclass prediction mode, `prob_class` is the probability map for each of the 1+'n_classes' classes (first class is background). """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:192,config,config,192,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['config'],['config']
Modifiability,"""""""Prepare for neural network training. Compiles the model and creates; `Keras Callbacks <https://keras.io/callbacks/>`_ to be used for training. Note that this method will be implicitly called once by :func:`train`; (with default arguments) if not done so explicitly beforehand. Parameters; ----------; optimizer : obj or None; Instance of a `Keras Optimizer <https://keras.io/optimizers/>`_ to be used for training.; If ``None`` (default), uses ``Adam`` with the learning rate specified in ``config``. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:494,config,config,494,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['config'],['config']
Modifiability,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:45,config,config,45,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,7,['config'],"['config', 'configuration']"
Modifiability,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:45,config,config,45,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,7,['config'],"['config', 'configuration']"
Modifiability,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:738,config,config,738,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,6,['config'],['config']
Modifiability,"""""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_si",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1046,layers,layers,1046,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['layers'],['layers']
Modifiability,"# CSBDeep Fiji plugin needs same size input/output; # -> we need to upsample the outputs if grid > (1,1); # note: upsampling prob with a transposed convolution creates sparse; # prob output with less candidates than with standard upsampling",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:15,plugin,plugin,15,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['plugin'],['plugin']
Modifiability,"# TODO: refactor 'fill_label_holes' and 'edt_prob' to share code",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py:8,refactor,refactor,8,stardist/utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py,1,['refactor'],['refactor']
Modifiability,"# def _axes_tile_overlap(self, query_axes):; # self.config.backbone == 'unet' or _raise(NotImplementedError()); # query_axes = axes_check_and_normalize(query_axes); # assert len(self.config.unet_pool) == len(self.config.grid) == len(self.config.unet_kernel_size); # # TODO: compute this properly when any value of grid > 1; # # all(g==1 for g in self.config.grid) or warnings.warn('FIXME'); # overlap = dict(zip(; # self.config.axes.replace('C',''),; # tuple(tile_overlap(self.config.unet_n_depth + int(np.log2(g)), k, p); # for p,k,g in zip(self.config.unet_pool,self.config.unet_kernel_size,self.config.grid)); # )); # return tuple(overlap.get(a,0) for a in query_axes)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:52,config,config,52,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,10,['config'],['config']
Modifiability,"# def _instances_from_prediction_old(self, img_shape, prob, dist,points = None, prob_class = None, prob_thresh=None, nms_thresh=None, overlap_label = None, **nms_kwargs):; # from stardist.geometry.geom2d import _polygons_to_label_old, _dist_to_coord_old; # from stardist.nms import _non_maximum_suppression_old; # if prob_thresh is None: prob_thresh = self.thresholds.prob; # if nms_thresh is None: nms_thresh = self.thresholds.nms; # if overlap_label is not None: raise NotImplementedError(""overlap_label not supported for 2D yet!""); # coord = _dist_to_coord_old(dist, grid=self.config.grid); # inds = _non_maximum_suppression_old(coord, prob, grid=self.config.grid,; # prob_thresh=prob_thresh, nms_thresh=nms_thresh, **nms_kwargs); # labels = _polygons_to_label_old(coord, prob, inds, shape=img_shape); # # sort 'inds' such that ids in 'labels' map to entries in polygon dictionary entries; # inds = inds[np.argsort(prob[inds[:,0],inds[:,1]])]; # # adjust for grid; # points = inds*np.array(self.config.grid); # res_dict = dict(coord=coord[inds[:,0],inds[:,1]], points=points, prob=prob[inds[:,0],inds[:,1]]); # if prob_class is not None:; # prob_class = np.asarray(prob_class); # res_dict.update(dict(class_prob = prob_class)); # return labels, res_dict",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:580,config,config,580,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,3,['config'],['config']
Modifiability,"# def _predict_instances_old(self, img, axes=None, normalizer=None,; # sparse = False,; # prob_thresh=None, nms_thresh=None,; # n_tiles=None, show_tile_progress=True,; # verbose = False,; # predict_kwargs=None, nms_kwargs=None, overlap_label=None):; # """"""; # old version, should be removed....; # """"""; # if predict_kwargs is None:; # predict_kwargs = {}; # if nms_kwargs is None:; # nms_kwargs = {}; # nms_kwargs.setdefault(""verbose"", verbose); # _axes = self._normalize_axes(img, axes); # _axes_net = self.config.axes; # _permute_axes = self._make_permute_axes(_axes, _axes_net); # _shape_inst = tuple(s for s,a in zip(_permute_axes(img).shape, _axes_net) if a != 'C'); # res = self.predict(img, axes=axes, normalizer=normalizer,; # n_tiles=n_tiles,; # show_tile_progress=show_tile_progress,; # **predict_kwargs); # res = tuple(res) + (None,); # if self._is_multiclass():; # prob, dist, prob_class, points = res; # else:; # prob, dist, points = res; # prob_class = None; # return self._instances_from_prediction_old(_shape_inst, prob, dist,; # points = points,; # prob_class = prob_class,; # prob_thresh=prob_thresh,; # nms_thresh=nms_thresh,; # overlap_label=overlap_label,; # **nms_kwargs)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:507,config,config,507,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['config'],['config']
Modifiability,"# default config (can be overwritten by kwargs below)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:10,config,config,10,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,2,['config'],['config']
Modifiability,"# img has no dedicated channel axis, but 'C' always part of config axes",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:60,config,config,60,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['config'],['config']
Modifiability,"# labels, fwd_map, _ = relabel_sequential(labels, label_offset); # if len(incomplete) > 0:; # problem_ids.extend([fwd_map[i] for i in incomplete]); # if show_progress:; # blocks.set_postfix_str(f""found {len(problem_ids)} problematic {'object' if len(problem_ids)==1 else 'objects'}"")",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:106,extend,extend,106,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['extend'],['extend']
Modifiability,"# save the config and threshold to json, and weights to hdf5 to enable loading as stardist model; # copy bioimageio files to separate sub-folder",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:11,config,config,11,stardist/bioimageio_utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py,1,['config'],['config']
Modifiability,"# the reason why the actual computation happens as a generator function; # (in '_predict_instances_generator') is that the generator is called; # from the stardist napari plugin, which has its benefits regarding; # control flow and progress display. however, typical use cases should; # almost always use this function ('predict_instances'), and shouldn't; # even notice (thanks to @functools.wraps) that it wraps the generator; # function. note that similar reasoning applies to 'predict' and; # 'predict_sparse'.; # return last ""yield""ed value of generator",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:171,plugin,plugin,171,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['plugin'],['plugin']
Modifiability,"(int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_s",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1362,layers,layers,1362,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['layers'],['layers']
Modifiability,"ays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; ",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1155,layers,layers,1155,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['layers'],['layers']
Performance,""""""". Command line script to perform prediction in 2D. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict2d.py:28,perform,perform,28,stardist/scripts/predict2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict2d.py,1,['perform'],['perform']
Performance,""""""". Command line script to perform prediction in 3D. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict3d.py:28,perform,perform,28,stardist/scripts/predict3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict3d.py,1,['perform'],['perform']
Performance,"""""""Import stardist model from bioimage.io format, https://github.com/bioimage-io/spec-bioimage-io. Load a model in bioimage.io format from the given `source` (e.g. path to zip file, URL); and convert it to a regular stardist model, which will be saved in the folder `outpath`. Parameters; ----------; source: str, Path; bioimage.io resource (e.g. path, URL); outpath: str, Path; folder to save the stardist model (must not exist previously). Returns; -------; StarDist2D or StarDist3D; stardist model loaded from `outpath`. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:501,load,loaded,501,stardist/bioimageio_utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py,1,['load'],['loaded']
Performance,"""""""Optimize two thresholds (probability, NMS overlap) necessary for predicting object instances. Note that the default thresholds yield good results in many cases, but optimizing; the thresholds for a particular dataset can further improve performance. The optimized thresholds are automatically used for all further predictions; and also written to the model directory. See ``utils.optimize_threshold`` for details and possible choices for ``optimize_kwargs``. Parameters; ----------; X_val : list of ndarray; (Validation) input images (must be normalized) to use for threshold tuning.; Y_val : list of ndarray; (Validation) label images to use for threshold tuning.; nms_threshs : list of float; List of overlap thresholds to be considered for NMS.; For each value in this list, optimization is run to find a corresponding prob_thresh value.; iou_threshs : list of float; List of intersection over union (IOU) thresholds for which; the (average) matching performance is considered to tune the thresholds.; predict_kwargs: dict; Keyword arguments for ``predict`` function of this class.; (If not provided, will guess value for `n_tiles` to prevent out of memory errors.); optimize_kwargs: dict; Keyword arguments for ``utils.optimize_threshold`` function. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:168,optimiz,optimizing,168,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,6,"['optimiz', 'perform', 'tune']","['optimization', 'optimized', 'optimizing', 'performance', 'tune']"
Performance,"""""""Prepare for neural network training. Compiles the model and creates; `Keras Callbacks <https://keras.io/callbacks/>`_ to be used for training. Note that this method will be implicitly called once by :func:`train`; (with default arguments) if not done so explicitly beforehand. Parameters; ----------; optimizer : obj or None; Instance of a `Keras Optimizer <https://keras.io/optimizers/>`_ to be used for training.; If ``None`` (default), uses ``Adam`` with the learning rate specified in ``config``. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:304,optimiz,optimizer,304,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,2,['optimiz'],"['optimizer', 'optimizers']"
Performance,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:157,load,loaded,157,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,2,['load'],['loaded']
Performance,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:157,load,loaded,157,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,2,['load'],['loaded']
Performance,"""""""optimized version of csbdeep.data.sample_patches_from_multiple_stacks; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py:3,optimiz,optimized,3,stardist/sample_patches.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py,1,['optimiz'],['optimized']
Performance,"# 1. grow object slice by 1 for all interior object bounding boxes; # 2. perform (correct) EDT for object with label id i; # 3. extract EDT for object of original slice and normalize; # 4. store edt for object only for pixels of given label id i",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py:73,perform,perform,73,stardist/utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py,1,['perform'],['perform']
Performance,"# save the config and threshold to json, and weights to hdf5 to enable loading as stardist model; # copy bioimageio files to separate sub-folder",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:71,load,loading,71,stardist/bioimageio_utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py,1,['load'],['loading']
Performance,"# warnings.warn(""Could not find package edt... \nConsider installing it with \n pip install edt\nto improve training data generation performance."")",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py:133,perform,performance,133,stardist/utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py,2,['perform'],['performance']
Safety,""""""" Shared setup code between `predict` and `predict_sparse` """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:31,predict,predict,31,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['predict'],['predict']
Safety,""""""" Sparse version of model.predict(); Returns; -------; (prob, dist, [prob_class], points) flat list of probs, dists, (optional prob_class) and points; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:28,predict,predict,28,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['predict'],['predict']
Safety,""""""". Command line script to perform prediction in 2D. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict2d.py:36,predict,prediction,36,stardist/scripts/predict2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict2d.py,1,['predict'],['prediction']
Safety,""""""". Command line script to perform prediction in 3D. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict3d.py:36,predict,prediction,36,stardist/scripts/predict3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict3d.py,1,['predict'],['prediction']
Safety,"""""""2D coordinates of the polys that survive from a given prediction (prob, coord). prob.shape = (Ny,Nx); coord.shape = (Ny,Nx,2,n_rays). b: don't use pixel closer than b pixels to the image boundary. returns retained points; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py:57,predict,prediction,57,stardist/nms.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py,1,['predict'],['prediction']
Safety,"""""""; //*******************************************************************; // Date: July-2021; // Credits: StarDist, DeepImageJ; // URL:; // https://github.com/stardist/stardist; // https://deepimagej.github.io/deepimagej; // This macro was adapted from; // https://github.com/deepimagej/imagej-macros/blob/648caa867f6ccb459649d4d3799efa1e2e0c5204/StarDist2D_Post-processing.ijm; // Please cite the respective contributions when using this code.; //*******************************************************************; // Macro to run StarDist postprocessing on 2D images.; // StarDist and deepImageJ plugins need to be installed.; // The macro assumes that the image to process is a stack in which; // the first channel corresponds to the object probability map; // and the remaining channels are the radial distances from each; // pixel to the object boundary.; //*******************************************************************. // Get the name of the image to call it; getDimensions(width, height, channels, slices, frames);; name=getTitle();. probThresh={probThresh};; nmsThresh={nmsThresh};. // Isolate the detection probability scores; run(""Make Substack..."", ""channels=1"");; rename(""scores"");. // Isolate the oriented distances; run(""Fire"");; selectWindow(name);; run(""Delete Slice"", ""delete=channel"");; selectWindow(name);; run(""Properties..."", ""channels="" + maxOf(channels, slices) - 1 + "" slices=1 frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=1.0000"");; rename(""distances"");; run(""royal"");. // Run StarDist plugin; run(""Command From Macro"", ""command=[de.csbdresden.stardist.StarDist2DNMS], args=['prob':'scores', 'dist':'distances', 'probThresh':'"" + probThresh + ""', 'nmsThresh':'"" + nmsThresh + ""', 'outputType':'Both', 'excludeBoundary':'2', 'roiPosition':'Stack', 'verbose':'false'], process=[false]"");; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:1116,detect,detection,1116,stardist/bioimageio_utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py,1,['detect'],['detection']
Safety,"""""""; Prediction script for a 2D stardist model, usage: stardist-predict -i input.tif -m model_folder_or_pretrained_name -o output_folder. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict2d.py:64,predict,predict,64,stardist/scripts/predict2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict2d.py,1,['predict'],['predict']
Safety,"""""""; Prediction script for a 3D stardist model, usage: stardist-predict -i input.tif -m model_folder_or_pretrained_name -o output_folder. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict3d.py:64,predict,predict,64,stardist/scripts/predict3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict3d.py,1,['predict'],['predict']
Safety,"""""""; if points is None -> dense prediction; if points is not None -> sparse prediction. if prob_class is None -> single class prediction; if prob_class is not None -> multi class prediction; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:32,predict,prediction,32,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,8,['predict'],['prediction']
Safety,"""""""Calculate detection/instance segmentation metrics between ground truth and predicted label images. Currently, the following metrics are implemented:. 'fp', 'tp', 'fn', 'precision', 'recall', 'accuracy', 'f1', 'criterion', 'thresh', 'n_true', 'n_pred', 'mean_true_score', 'mean_matched_score', 'panoptic_quality'. Corresponding objects of y_true and y_pred are counted as true positives (tp), false positives (fp), and false negatives (fn); whether their intersection over union (IoU) >= thresh (for criterion='iou', which can be changed). * mean_matched_score is the mean IoUs of matched true positives. * mean_true_score is the mean IoUs of matched true positives but normalized by the total number of GT objects. * panoptic_quality defined as in Eq. 1 of Kirillov et al. ""Panoptic Segmentation"", CVPR 2019. Parameters; ----------; y_true: ndarray; ground truth label image (integer valued); y_pred: ndarray; predicted label image (integer valued); thresh: float; threshold for matching criterion (default 0.5); criterion: string; matching criterion (default IoU); report_matches: bool; if True, additionally calculate matched_pairs and matched_scores (note, that this returns even gt-pred pairs whose scores are below 'thresh'). Returns; -------; Matching object with different metrics as attributes. Examples; --------; >>> y_true = np.zeros((100,100), np.uint16); >>> y_true[10:20,10:20] = 1; >>> y_pred = np.roll(y_true,5,axis = 0). >>> stats = matching(y_true, y_pred); >>> print(stats); Matching(criterion='iou', thresh=0.5, fp=1, tp=0, fn=1, precision=0, recall=0, accuracy=0, f1=0, n_true=1, n_pred=1, mean_true_score=0.0, mean_matched_score=0.0, panoptic_quality=0.0). """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py:13,detect,detection,13,stardist/matching.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py,3,"['detect', 'predict']","['detection', 'predicted']"
Safety,"""""""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate ",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:410,predict,predict,410,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,2,['predict'],"['predict', 'prediction']"
Safety,"""""""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_s",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:420,predict,predict,420,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,2,['predict'],"['predict', 'prediction']"
Safety,"""""""Optimize two thresholds (probability, NMS overlap) necessary for predicting object instances. Note that the default thresholds yield good results in many cases, but optimizing; the thresholds for a particular dataset can further improve performance. The optimized thresholds are automatically used for all further predictions; and also written to the model directory. See ``utils.optimize_threshold`` for details and possible choices for ``optimize_kwargs``. Parameters; ----------; X_val : list of ndarray; (Validation) input images (must be normalized) to use for threshold tuning.; Y_val : list of ndarray; (Validation) label images to use for threshold tuning.; nms_threshs : list of float; List of overlap thresholds to be considered for NMS.; For each value in this list, optimization is run to find a corresponding prob_thresh value.; iou_threshs : list of float; List of intersection over union (IOU) thresholds for which; the (average) matching performance is considered to tune the thresholds.; predict_kwargs: dict; Keyword arguments for ``predict`` function of this class.; (If not provided, will guess value for `n_tiles` to prevent out of memory errors.); optimize_kwargs: dict; Keyword arguments for ``utils.optimize_threshold`` function. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:68,predict,predicting,68,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,3,['predict'],"['predict', 'predicting', 'predictions']"
Safety,"""""""Predict instance segmentation from input image. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; sparse: bool; If true, aggregate probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; ov",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:342,predict,prediction,342,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,3,['predict'],"['predicted', 'prediction']"
Safety,"""""""Predict instance segmentation from very large input images. Intended to be used when `predict_instances` cannot be used due to memory limitations.; This function will break the input image into blocks and process them individually; via `predict_instances` and assemble all the partial results. If used as intended, the result; should be the same as if `predict_instances` was used directly on the whole image. **Important**: The crucial assumption is that all predicted object instances are smaller than; the provided `min_overlap`. Also, it must hold that: min_overlap + 2*context < block_size. Example; -------; >>> img.shape; (20000, 20000); >>> labels, polys = model.predict_instances_big(img, axes='YX', block_size=4096,; min_overlap=128, context=128, n_tiles=(4,4)). Parameters; ----------; img: :class:`numpy.ndarray` or similar; Input image; axes: str; Axes of the input ``img`` (such as 'YX', 'ZYX', 'YXC', etc.); block_size: int or iterable of int; Process input image in blocks of the provided shape.; (If a scalar value is given, it is used for all spatial image dimensions.); min_overlap: int or iterable of int; Amount of guaranteed overlap between blocks.; (If a scalar value is given, it is used for all spatial image dimensions.); context: int or iterable of int, or None; Amount of image context on all sides of a block, which is discarded.; If None, uses an automatic estimate that should work in many cases.; (If a scalar value is given, it is used for all spatial image dimensions.); labels_out: :class:`numpy.ndarray` or similar, or None, or False; numpy array or similar (must be of correct shape) to which the label image is written.; If None, will allocate a numpy array of the correct shape and data type ``labels_out_dtype``.; If False, will not write the label image (useful if only the dictionary is needed).; labels_out_dtype: str or dtype; Data type of returned label image if ``labels_out=None`` (has no effect otherwise).; show_progress: bool; Show progress bar for",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:463,predict,predicted,463,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['predict'],['predicted']
Safety,"""""""Predict. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool or callable; If boolean, indicates whether to show progress (via tqdm) during tiled prediction.; If callable, must be a drop-in replacement for tqdm.; show_tile_progress: bool; Whether to show progress during tiled prediction.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model. Returns; -------; (:class:`numpy.ndarray`, :class:`numpy.ndarray`, [:class:`numpy.ndarray`]); Returns the tuple (`prob`, `dist`, [`prob_class`]) of per-pixel object probabilities and star-convex polygon/polyhedra distances.; In multiclass prediction mode, `prob_class` is the probability map for each of the 1+'n_classes' classes (first class is background). """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:303,predict,prediction,303,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,6,"['avoid', 'predict']","['avoid', 'predict', 'prediction']"
Safety,"""""""Renders an image that shows segmentation errors between y_true and y_pred . Correctly matched objects (TP) are colored green (with transparency tp_alpha); Erronously detected objects (FP) are colored red (with transparency fp_alpha); MIssing GT objects (FN) are colored blue (with transparency fn_alpha). Parameters; ----------; y_true: np.ndarray of dtype np.uint16; The 2D GT label image ; y_pred: np.ndarray of dtype np.uint16; The 2D prediction label image ; img: np.ndarray ; The array to overlay the label image with (optional); cmap_img: string or callable; The colormap of img (optional); tp_alpha: float ; The alpha value of the TP ; fp_alpha: float ; The alpha value of the FP ; fn_alpha: float ; The alpha value of the FN ; matching_kwargs: dict; The parameters of stardist.matching.matching that are used to compute the TP/FP/FN; normalize_img: bool; If True, normalizes the img (if given). Returns; -------; img: np.ndarray; the (m,n,4) RGBA image of the rendered image. Example; ------- . from scipy.ndimage import label, zoom ; img = zoom(np.random.uniform(0,1,(16,16)),(8,8),order=3); y_true = label(img>.9)[0]; y_pred = label(img>.02)[0]; plt.imshow(render_label_pred(y_true, y_pred, img=img)). """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py:169,detect,detected,169,stardist/plot/render.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py,2,"['detect', 'predict']","['detected', 'prediction']"
Safety,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:541,predict,prediction,541,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,2,['predict'],['prediction']
Safety,"""""""computes a safe divide which returns 0 if y is zero""""""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py:14,safe,safe,14,stardist/matching.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py,1,['safe'],['safe']
Safety,"# avoid small dist values to prevent problems with Qhull",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:2,avoid,avoid,2,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['avoid'],['avoid']
Safety,"# build the list of class ids per label via majority vote; # zoom prob_class to img_shape; # prob_class_up = zoom(prob_class,; # tuple(s2/s1 for s1, s2 in zip(prob_class.shape[:3], img_shape))+(1,),; # order=0); # class_id, label_ids = [], []; # for reg in regionprops(labels):; # m = labels[reg.slice]==reg.label; # cls_id = np.argmax(np.mean(prob_class_up[reg.slice][m], axis = 0)); # class_id.append(cls_id); # label_ids.append(reg.label); # # just a sanity check whether labels where in sorted order; # assert all(x <= y for x,y in zip(label_ids, label_ids[1:])); # res_dict.update(dict(classes = class_id)); # res_dict.update(dict(labels = label_ids)); # self.p = prob_class_up",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:454,sanity check,sanity check,454,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['sanity check'],['sanity check']
Safety,"# def _predict_instances_old(self, img, axes=None, normalizer=None,; # sparse = False,; # prob_thresh=None, nms_thresh=None,; # n_tiles=None, show_tile_progress=True,; # verbose = False,; # predict_kwargs=None, nms_kwargs=None, overlap_label=None):; # """"""; # old version, should be removed....; # """"""; # if predict_kwargs is None:; # predict_kwargs = {}; # if nms_kwargs is None:; # nms_kwargs = {}; # nms_kwargs.setdefault(""verbose"", verbose); # _axes = self._normalize_axes(img, axes); # _axes_net = self.config.axes; # _permute_axes = self._make_permute_axes(_axes, _axes_net); # _shape_inst = tuple(s for s,a in zip(_permute_axes(img).shape, _axes_net) if a != 'C'); # res = self.predict(img, axes=axes, normalizer=normalizer,; # n_tiles=n_tiles,; # show_tile_progress=show_tile_progress,; # **predict_kwargs); # res = tuple(res) + (None,); # if self._is_multiclass():; # prob, dist, prob_class, points = res; # else:; # prob, dist, points = res; # prob_class = None; # return self._instances_from_prediction_old(_shape_inst, prob, dist,; # points = points,; # prob_class = prob_class,; # prob_thresh=prob_thresh,; # nms_thresh=nms_thresh,; # overlap_label=overlap_label,; # **nms_kwargs)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:684,predict,predict,684,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['predict'],['predict']
Safety,"# def test_repaint2D(model2d):; # np.random.seed(42); # model = model2d; # img = real_image2d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.97)[1]; # polys['coord'] += np.random.normal(scale=3, size=polys['coord'].shape[:2]+(1,)); # labels = render_polygons(polys, img.shape); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = render_polygons(polys2, img.shape); # assert not np.all(labels == labels2); # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.all(labels == labels2); # def test_repaint3D(model3d):; # np.random.seed(42); # model = model3d; # img = real_image3d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.95)[1]; # polys['dist'] += np.random.normal(scale=3, size=polys['dist'].shape[:1]+(1,)); # polys['dist'] = np.maximum(1, polys['dist']); # labels = polyhedron_to_label(polys['dist'], polys['points'], polys['rays'], img.shape, prob=polys['prob']); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() if isinstance(v,np.ndarray) else v for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = polyhedron_to_label(polys2['dist'], polys2['points'], polys2['rays'], img.shape, prob=polys2['prob']); # assert np.count_nonzero(labels != labels2) > 10000; # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.count_nonzero(labels != labels2) < 10 # TODO: why not 0?",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:161,predict,predictions,161,tests/test_big.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py,2,['predict'],['predictions']
Safety,"# dense prediction",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:8,predict,prediction,8,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,2,['predict'],['prediction']
Safety,"# if (block_size[i], min_overlap[i], context[i]) != (None, None, None):; # print(""Ignoring values of 'block_size', 'min_overlap', and 'context' for channel axis "" +; # ""(set to 'None' to avoid this warning)."", file=sys.stderr, flush=True)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:187,avoid,avoid,187,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['avoid'],['avoid']
Safety,"# if e.args[0]: # object larger than block write region; # assert any(o >= b for o,b in zip(shape_object,shape_block_write)); # # problem, since this object will probably be saved by another block too; # raise RuntimeError(f""Found object of shape {shape_object}, larger than an entire block's write region of shape {shape_block_write}. Increase 'block_size' to avoid this problem.""); # # print(""found object larger than 'block_size'""); # else:; # assert any(o >= b for o,b in zip(shape_object,shape_min_overlap)); # # print(""found object larger than 'min_overlap'""); # # keep object, because will be dealt with later, i.e.; # # render the poly again into the label image, but this is not; # # ideal since the assumption is that the object outside that; # # region is not reliable because it's in the context; # labels_filtered[slices][r.image] = r.label; # problem_ids.append(r.label)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:361,avoid,avoid,361,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['avoid'],['avoid']
Safety,"# ignore image boundary, since predictions may not be reliable",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py:31,predict,predictions,31,stardist/utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py,1,['predict'],['predictions']
Safety,"# in some cases need to add extra context to prevent overlapping write regions of non-neighboring blocks; # cf. https://forum.image.sc/t/trouble-using-stardist-predict-instances-big/88871/6",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:160,predict,predict-instances-big,160,tests/test_big.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py,1,['predict'],['predict-instances-big']
Safety,"# indicate that prediction is starting",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:16,predict,prediction,16,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['predict'],['prediction']
Safety,"# multi class prediction",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:14,predict,prediction,14,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['predict'],['prediction']
Safety,"# only take first two elements of predict in case multi class is activated",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:34,predict,predict,34,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['predict'],['predict']
Safety,"# print(); [print(t) for t in first]; # add extra context to avoid overlapping write regions of non-neighboring blocks",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:61,avoid,avoid,61,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['avoid'],['avoid']
Safety,"# print(); [print(t) for t in first]; # sanity checks",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:40,sanity check,sanity checks,40,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['sanity check'],['sanity checks']
Safety,"# sanity checks",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:2,sanity check,sanity checks,2,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['sanity check'],['sanity checks']
Safety,"# sparse prediction",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:9,predict,prediction,9,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,2,['predict'],['prediction']
Safety,"# the reason why the actual computation happens as a generator function; # (in '_predict_instances_generator') is that the generator is called; # from the stardist napari plugin, which has its benefits regarding; # control flow and progress display. however, typical use cases should; # almost always use this function ('predict_instances'), and shouldn't; # even notice (thanks to @functools.wraps) that it wraps the generator; # function. note that similar reasoning applies to 'predict' and; # 'predict_sparse'.; # return last ""yield""ed value of generator",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:481,predict,predict,481,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['predict'],['predict']
Safety,"_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlate",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1791,predict,predictions,1791,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['predict'],['predictions']
Safety,"alized.; sparse: bool; If true, aggregate probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; overlap_label: scalar or None; if not None, label the regions where polygons overlap with that value; return_predict: bool; Also return the outputs of :func:`predict` (in a separate tuple); If True, implies sparse = False. Returns; -------; (:class:`numpy.ndarray`, dict), (optional: return tuple of :func:`predict`); Returns a tuple of the label instances image and also; a dictionary with the details (coordinates, etc.) ",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1362,avoid,avoid,1362,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['avoid'],['avoid']
Safety,"ch of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter u",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1370,predict,predict,1370,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['predict'],['predict']
Safety,"e probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; overlap_label: scalar or None; if not None, label the regions where polygons overlap with that value; return_predict: bool; Also return the outputs of :func:`predict` (in a separate tuple); If True, implies sparse = False. Returns; -------; (:class:`numpy.ndarray`, dict), (optional: return tuple of :func:`predict`); Returns a tuple of the label instances image and also; a dictionary with the details (coordinates, etc.) of all remaining polygons/polyhedra. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1694,predict,prediction,1694,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,4,['predict'],"['predict', 'prediction']"
Safety,"ution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlate",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:2148,predict,predictions,2148,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['predict'],['predictions']
Security,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:909,validat,validation,909,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,6,['validat'],['validation']
Security,"# TODO: which functions to expose here? all?",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/__init__.py:27,expose,expose,27,stardist/__init__.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/__init__.py,1,['expose'],['expose']
Security,"# expose data generator as member for general diagnostics",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:2,expose,expose,2,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,2,['expose'],['expose']
Security,"# generate validation data and store in numpy arrays",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:11,validat,validation,11,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,2,['validat'],['validation']
Security,"# set validation batchsize to training batchsize (only works for tf >= 2.2)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:6,validat,validation,6,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['validat'],['validation']
Security,"# set validation batchsize to training batchsize (only works in tf 2.x)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:6,validat,validation,6,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['validat'],['validation']
Security,"els (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:2580,validat,validation,2580,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['validat'],['validation']
Security,"tion layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:3017,validat,validation,3017,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['validat'],['validation']
Testability,""""""" test whether an already star-convex label image gets perfectly relabeld""""""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_stardist2D.py:4,test,test,4,tests/test_stardist2D.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_stardist2D.py,2,['test'],['test']
Testability,"""""""Export stardist model into bioimage.io format, https://github.com/bioimage-io/spec-bioimage-io. Parameters; ----------; model: StarDist2D, StarDist3D; the model to convert; outpath: str, Path; where to save the model; test_input: np.ndarray; input image for generating test data; test_input_axes: str or None; the axes of the test input, for example 'YX' for a 2d image or 'ZYX' for a 3d volume; using None assumes that axes of test_input are the same as those of model; test_input_norm_axes: str; the axes of the test input which will be jointly normalized, for example 'ZYX' for all spatial dimensions ('Z' ignored for 2D input); use 'ZYXC' to also jointly normalize channels (e.g. for RGB input images); name: str; the name of this model (default: None); if None, uses the (folder) name of the model (i.e. `model.name`); mode: str; the export type for this model (default: ""tensorflow_saved_model_bundle""); min_percentile: float; min percentile to be used for image normalization (default: 1.0); max_percentile: float; max percentile to be used for image normalization (default: 99.8); overwrite_spec_kwargs: dict or None; spec keywords that should be overloaded (default: None); generate_default_deps: bool; not required for bioimage.io, i.e. StarDist models don't need a dependencies field in rdf.yaml (default: False); if True, generate an environment.yaml file recording the python, bioimageio.core, stardist and tensorflow requirements; from which a conda environment can be recreated to run this export; """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:272,test,test,272,stardist/bioimageio_utils.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py,3,['test'],['test']
Testability,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:761,log,logdir,761,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['log'],['logdir']
Testability,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:761,log,logdir,761,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['log'],['logdir']
Testability,"# 2024-01-25: failed on github actions: ""windows-latest"" in combination with tensorflow 2.15.0 (python 3.9, 3.10, and 3.11); # (m.mean_true_score was 0.9999979271079009); # assert (1.0, 1.0) == (m.accuracy, m.mean_true_score)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:173,assert,assert,173,tests/test_big.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py,1,['assert'],['assert']
Testability,"# TF2: add as first callback to put 'lr' in the logs for TensorBoard",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:48,log,logs,48,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['log'],['logs']
Testability,"# assert len(problem_ids) == 0",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:2,assert,assert,2,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['assert'],['assert']
Testability,"# assert not (bmin == 0 and bmax >= r_start and not self.at_begin), [(r_start,r_end), bbox, self]",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:2,assert,assert,2,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['assert'],['assert']
Testability,"# assert np.all(p.mask == mask_i) # few pixels are sometimes different, why?",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:2,assert,assert,2,tests/test_big.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py,1,['assert'],['assert']
Testability,"# assert tp+fp == n_pred; # assert tp+fn == n_true; # the score sum over all matched objects (tp)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py:2,assert,assert,2,stardist/matching.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py,2,['assert'],['assert']
Testability,"# build the list of class ids per label via majority vote; # zoom prob_class to img_shape; # prob_class_up = zoom(prob_class,; # tuple(s2/s1 for s1, s2 in zip(prob_class.shape[:3], img_shape))+(1,),; # order=0); # class_id, label_ids = [], []; # for reg in regionprops(labels):; # m = labels[reg.slice]==reg.label; # cls_id = np.argmax(np.mean(prob_class_up[reg.slice][m], axis = 0)); # class_id.append(cls_id); # label_ids.append(reg.label); # # just a sanity check whether labels where in sorted order; # assert all(x <= y for x,y in zip(label_ids, label_ids[1:])); # res_dict.update(dict(classes = class_id)); # res_dict.update(dict(labels = label_ids)); # self.p = prob_class_up",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:507,assert,assert,507,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['assert'],['assert']
Testability,"# deactivate as order of labels might not be the same; # assert all(np.allclose(u,v) for u,v in zip(ref,res))",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:57,assert,assert,57,tests/test_model2D.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py,2,['assert'],['assert']
Testability,"# def _axes_tile_overlap(self, query_axes):; # self.config.backbone == 'unet' or _raise(NotImplementedError()); # query_axes = axes_check_and_normalize(query_axes); # assert len(self.config.unet_pool) == len(self.config.grid) == len(self.config.unet_kernel_size); # # TODO: compute this properly when any value of grid > 1; # # all(g==1 for g in self.config.grid) or warnings.warn('FIXME'); # overlap = dict(zip(; # self.config.axes.replace('C',''),; # tuple(tile_overlap(self.config.unet_n_depth + int(np.log2(g)), k, p); # for p,k,g in zip(self.config.unet_pool,self.config.unet_kernel_size,self.config.grid)); # )); # return tuple(overlap.get(a,0) for a in query_axes)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:167,assert,assert,167,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['assert'],['assert']
Testability,"# def repaint_labels(output, labels, polys, show_progress=True):; # """"""Repaint object instances in correct order based on probability scores.; # Does modify 'output' and 'polys' in-place, but will only write sparsely to 'output' where needed.; # output: numpy.ndarray or similar; # Label image (integer-valued); # labels: iterable of int; # List of integer label ids that occur in output; # polys: dict; # Dictionary of polygon/polyhedra properties.; # Assumption is that the label id (-1) corresponds to the index in the polys dict; # """"""; # assert output.ndim in (2,3); # if show_progress:; # labels = tqdm(labels, leave=True); # labels_eliminated = set(); # # TODO: inelegant to have so much duplicated code here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: p",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:543,assert,assert,543,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['assert'],['assert']
Testability,"# def test_repaint2D(model2d):; # np.random.seed(42); # model = model2d; # img = real_image2d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.97)[1]; # polys['coord'] += np.random.normal(scale=3, size=polys['coord'].shape[:2]+(1,)); # labels = render_polygons(polys, img.shape); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = render_polygons(polys2, img.shape); # assert not np.all(labels == labels2); # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.all(labels == labels2); # def test_repaint3D(model3d):; # np.random.seed(42); # model = model3d; # img = real_image3d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.95)[1]; # polys['dist'] += np.random.normal(scale=3, size=polys['dist'].shape[:1]+(1,)); # polys['dist'] = np.maximum(1, polys['dist']); # labels = polyhedron_to_label(polys['dist'], polys['points'], polys['rays'], img.shape, prob=polys['prob']); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() if isinstance(v,np.ndarray) else v for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = polyhedron_to_label(polys2['dist'], polys2['points'], polys2['rays'], img.shape, prob=polys2['prob']); # assert np.count_nonzero(labels != labels2) > 10000; # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.count_nonzero(labels != labels2) < 10 # TODO: why not 0?",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:614,assert,assert,614,tests/test_big.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py,4,['assert'],['assert']
Testability,"# if e.args[0]: # object larger than block write region; # assert any(o >= b for o,b in zip(shape_object,shape_block_write)); # # problem, since this object will probably be saved by another block too; # raise RuntimeError(f""Found object of shape {shape_object}, larger than an entire block's write region of shape {shape_block_write}. Increase 'block_size' to avoid this problem.""); # # print(""found object larger than 'block_size'""); # else:; # assert any(o >= b for o,b in zip(shape_object,shape_min_overlap)); # # print(""found object larger than 'min_overlap'""); # # keep object, because will be dealt with later, i.e.; # # render the poly again into the label image, but this is not; # # ideal since the assumption is that the object outside that; # # region is not reliable because it's in the context; # labels_filtered[slices][r.image] = r.label; # problem_ids.append(r.label)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:59,assert,assert,59,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,2,['assert'],['assert']
Testability,"# integration test",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:14,test,test,14,tests/test_model2D.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py,2,['test'],['test']
Testability,"# labels3, res3 = model.predict_instances_big(img, axes=""YX"" if img.ndim==2 else ""YXC"",; # block_size=640, min_overlap=32, context=96, **kwargs); # assert matching(labels1, labels3, thresh=0.99).f1 == 1",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:148,assert,assert,148,tests/test_model2D.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py,1,['assert'],['assert']
Testability,"# test exported model",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_bioimageio.py:2,test,test,2,tests/test_bioimageio.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_bioimageio.py,1,['test'],['test']
Testability,"# test that model and imported exported model are equal",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_bioimageio.py:2,test,test,2,tests/test_bioimageio.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_bioimageio.py,1,['test'],['test']
Testability,"# this test has to be at the end of the model",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:7,test,test,7,tests/test_model2D.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py,2,['test'],['test']
Testability,"# x = zoom(x, (0.5,0.5) if x.ndim==2 else (0.5,0.5,1), order=1) # to speed test up",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:75,test,test,75,tests/test_model2D.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py,1,['test'],['test']
Testability,"# y2, res2 = model._instances_from_prediction_old(img.shape,prob,dist, nms_thresh=.3); # # reorder as polygons is inverted in newer versions; # res2 = dict((k,v[::-1]) for k,v in res2.items()); # y2[y2>0] = np.max(y2)-y2[y2>0]+1; # for k in res1.keys():; # if isinstance(res1[k], np.ndarray):; # assert np.allclose(res1[k],res2[k]); # assert np.allclose(y1,y2); # return y1, res1, y2, res2",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:296,assert,assert,296,tests/test_model2D.py,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py,2,['assert'],['assert']
Testability,"coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # if len(labels_eliminated) > 0:; # ind = [i-1 for i in labels_eliminated]; # for k,v in polys.items():; # if k in OBJECT_KEYS:; # polys[k] = np.delete(v, ind, axis=0); ",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:2306,assert,assert,2306,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['assert'],['assert']
Testability,"n probability scores.; # Does modify 'output' and 'polys' in-place, but will only write sparsely to 'output' where needed.; # output: numpy.ndarray or similar; # Label image (integer-valued); # labels: iterable of int; # List of integer label ids that occur in output; # polys: dict; # Dictionary of polygon/polyhedra properties.; # Assumption is that the label id (-1) corresponds to the index in the polys dict; # """"""; # assert output.ndim in (2,3); # if show_progress:; # labels = tqdm(labels, leave=True); # labels_eliminated = set(); # # TODO: inelegant to have so much duplicated code here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhe",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1064,assert,assert,1064,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['assert'],['assert']
Usability,"""""""N-dimensional block. Each BlockND simply consists of a 1-dimensional Block per axis and also; has an id (which should be unique). The n-dimensional region represented; by each BlockND is the intersection of all 1D Blocks per axis. Also see `Block`. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:37,simpl,simply,37,stardist/big.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py,1,['simpl'],['simply']
Usability,"""""""Prepare for neural network training. Compiles the model and creates; `Keras Callbacks <https://keras.io/callbacks/>`_ to be used for training. Note that this method will be implicitly called once by :func:`train`; (with default arguments) if not done so explicitly beforehand. Parameters; ----------; optimizer : obj or None; Instance of a `Keras Optimizer <https://keras.io/optimizers/>`_ to be used for training.; If ``None`` (default), uses ``Adam`` with the learning rate specified in ``config``. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:465,learn,learning,465,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['learn'],['learning']
Usability,"""""""Renders a label image and optionally overlays it with another image. Used for generating simple output images to asses the label quality. Parameters; ----------; lbl: np.ndarray of dtype np.uint16; The 2D label image ; img: np.ndarray ; The array to overlay the label image with (optional); cmap: string, tuple, or callable; The label colormap. If given as rgb(a) only a single color is used, if None uses a random colormap ; cmap_img: string or callable; The colormap of img (optional); alpha: float ; The alpha value of the overlay. Set alpha=1 to get fully opaque labels; alpha_boundary: float; The alpha value of the boundary (if None, use the same as for labels, i.e. no boundaries are visible); normalize_img: bool; If True, normalizes the img (if given). Returns; -------; img: np.ndarray; the (m,n,4) RGBA image of the rendered label . Example; -------. from scipy.ndimage import label, zoom ; img = zoom(np.random.uniform(0,1,(16,16)),(8,8),order=3) ; lbl,_ = label(img>.8); u1 = render_label(lbl, img = img, alpha = .7); u2 = render_label(lbl, img = img, alpha = 0, alpha_boundary =.8); plt.subplot(1,2,1);plt.imshow(u1); plt.subplot(1,2,2);plt.imshow(u2). """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py:92,simpl,simple,92,stardist/plot/render.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py,1,['simpl'],['simple']
Usability,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:696,guid,guide,696,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['guid'],['guide']
Usability,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:696,guid,guide,696,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['guid'],['guide']
Usability,"# TODO: investigate downsampling via simple indexing vs. using 'zoom'; # prob_class = prob_class[self.ss_grid]; # 'zoom' might lead to better registered maps (especially if upscaled later)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:37,simpl,simple,37,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,2,['simpl'],['simple']
Usability,"# need to undo the scaling given by the scale dict, e.g. scale = dict(X=0.5,Y=0.5):; # 1. re-scale points (origins of polygons); # 2. re-scale coordinates (computed from distances) of (zero-origin) polygons",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:10,undo,undo,10,stardist/models/model2d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py,1,['undo'],['undo']
Usability,"# need to undo the scaling given by the scale dict, e.g. scale = dict(X=0.5,Y=0.5,Z=1.0):; # 1. re-scale points (origins of polyhedra); # 2. re-scale vectors of rays object (computed from distances)",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:10,undo,undo,10,stardist/models/model3d.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py,1,['undo'],['undo']
Usability,"_instances` and assemble all the partial results. If used as intended, the result; should be the same as if `predict_instances` was used directly on the whole image. **Important**: The crucial assumption is that all predicted object instances are smaller than; the provided `min_overlap`. Also, it must hold that: min_overlap + 2*context < block_size. Example; -------; >>> img.shape; (20000, 20000); >>> labels, polys = model.predict_instances_big(img, axes='YX', block_size=4096,; min_overlap=128, context=128, n_tiles=(4,4)). Parameters; ----------; img: :class:`numpy.ndarray` or similar; Input image; axes: str; Axes of the input ``img`` (such as 'YX', 'ZYX', 'YXC', etc.); block_size: int or iterable of int; Process input image in blocks of the provided shape.; (If a scalar value is given, it is used for all spatial image dimensions.); min_overlap: int or iterable of int; Amount of guaranteed overlap between blocks.; (If a scalar value is given, it is used for all spatial image dimensions.); context: int or iterable of int, or None; Amount of image context on all sides of a block, which is discarded.; If None, uses an automatic estimate that should work in many cases.; (If a scalar value is given, it is used for all spatial image dimensions.); labels_out: :class:`numpy.ndarray` or similar, or None, or False; numpy array or similar (must be of correct shape) to which the label image is written.; If None, will allocate a numpy array of the correct shape and data type ``labels_out_dtype``.; If False, will not write the label image (useful if only the dictionary is needed).; labels_out_dtype: str or dtype; Data type of returned label image if ``labels_out=None`` (has no effect otherwise).; show_progress: bool; Show progress bar for block processing.; kwargs: dict; Keyword arguments for ``predict_instances``. Returns; -------; (:class:`numpy.ndarray` or False, dict); Returns the label image and a dictionary with the details (coordinates, etc.) of the polygons/polyhedra. """"""",MatchSource.CODE_COMMENT,stardist,stardist,0.9.1,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1985,progress bar,progress bar,1985,stardist/models/base.py,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py,1,['progress bar'],['progress bar']
