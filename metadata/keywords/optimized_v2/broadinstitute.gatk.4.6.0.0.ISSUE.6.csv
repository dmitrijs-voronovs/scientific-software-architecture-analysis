quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Deployability,Github actions tests reported job failures from actions build [6041242949](https://github.com/broadinstitute/gatk/actions/runs/6041242949); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6041242949.11](https://github.com/broadinstitute/gatk/actions/runs/6041242949/job/16393773586) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041242949.11/tests/test/index.html) |; | integration | 11 | [6041242949.12](https://github.com/broadinstitute/gatk/actions/runs/6041242949/job/16393773740) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041242949.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701617540:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701617540,1,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [6041548152](https://github.com/broadinstitute/gatk/actions/runs/6041548152); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6041548152.11](https://github.com/broadinstitute/gatk/actions/runs/6041548152/job/16394743636) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041548152.11/tests/test/index.html) |; | unit | 11 | [6041548152.13](https://github.com/broadinstitute/gatk/actions/runs/6041548152/job/16394744048) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041548152.13/tests/test/index.html) |; | integration | 11 | [6041548152.12](https://github.com/broadinstitute/gatk/actions/runs/6041548152/job/16394743832) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041548152.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701677371:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701677371,1,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [6041869902](https://github.com/broadinstitute/gatk/actions/runs/6041869902); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6041869902.11](https://github.com/broadinstitute/gatk/actions/runs/6041869902/job/16395792759) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041869902.11/tests/test/index.html) |; | unit | 11 | [6041869902.13](https://github.com/broadinstitute/gatk/actions/runs/6041869902/job/16395793003) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041869902.13/tests/test/index.html) |; | integration | 11 | [6041869902.12](https://github.com/broadinstitute/gatk/actions/runs/6041869902/job/16395792880) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041869902.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701724937:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701724937,1,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [6042319707](https://github.com/broadinstitute/gatk/actions/runs/6042319707); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6042319707.11](https://github.com/broadinstitute/gatk/actions/runs/6042319707/job/16397171544) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6042319707.11/tests/test/index.html) |; | unit | 11 | [6042319707.13](https://github.com/broadinstitute/gatk/actions/runs/6042319707/job/16397171864) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6042319707.13/tests/test/index.html) |; | integration | 11 | [6042319707.12](https://github.com/broadinstitute/gatk/actions/runs/6042319707/job/16397171702) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6042319707.12/tests/test/index.html) |; | integration | 8 | [6042319707.0](https://github.com/broadinstitute/gatk/actions/runs/6042319707/job/16397698607) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6042319707.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1701786870:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1701786870,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [6042371878](https://github.com/broadinstitute/gatk/actions/runs/6042371878); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6042371878.11](https://github.com/broadinstitute/gatk/actions/runs/6042371878/job/16397346871) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6042371878.11/tests/test/index.html) |; | unit | 11 | [6042371878.13](https://github.com/broadinstitute/gatk/actions/runs/6042371878/job/16397347119) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6042371878.13/tests/test/index.html) |; | integration | 11 | [6042371878.12](https://github.com/broadinstitute/gatk/actions/runs/6042371878/job/16397346988) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6042371878.12/tests/test/index.html) |; | integration | 8 | [6042371878.0](https://github.com/broadinstitute/gatk/actions/runs/6042371878/job/16398082223) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6042371878.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1701796781:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1701796781,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [6042485207](https://github.com/broadinstitute/gatk/actions/runs/6042485207); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6042485207.11](https://github.com/broadinstitute/gatk/actions/runs/6042485207/job/16397690832) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8510/merge_6042485207.11/tests/test/index.html) |; | integration | 11 | [6042485207.12](https://github.com/broadinstitute/gatk/actions/runs/6042485207/job/16397691068) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8510/merge_6042485207.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8510#issuecomment-1701820013:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8510#issuecomment-1701820013,1,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [6316280004](https://github.com/broadinstitute/gatk/actions/runs/6316280004); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6316280004.11](https://github.com/broadinstitute/gatk/actions/runs/6316280004/job/17150554514) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8531/merge_6316280004.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6316280004.0](https://github.com/broadinstitute/gatk/actions/runs/6316280004/job/17151473162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8531/merge_6316280004.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8531#issuecomment-1736046844:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8531#issuecomment-1736046844,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [6316614080](https://github.com/broadinstitute/gatk/actions/runs/6316614080); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6316614080.11](https://github.com/broadinstitute/gatk/actions/runs/6316614080/job/17151618497) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8531/merge_6316614080.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6316614080.0](https://github.com/broadinstitute/gatk/actions/runs/6316614080/job/17152824309) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8531/merge_6316614080.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8531#issuecomment-1736096032:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8531#issuecomment-1736096032,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [6317259261](https://github.com/broadinstitute/gatk/actions/runs/6317259261); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6317259261.11](https://github.com/broadinstitute/gatk/actions/runs/6317259261/job/17153654271) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8531/merge_6317259261.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6317259261.0](https://github.com/broadinstitute/gatk/actions/runs/6317259261/job/17154755203) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8531/merge_6317259261.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8531#issuecomment-1736210346:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8531#issuecomment-1736210346,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [6384614693](https://github.com/broadinstitute/gatk/actions/runs/6384614693); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6384614693.11](https://github.com/broadinstitute/gatk/actions/runs/6384614693/job/17327645653) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8538/merge_6384614693.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6384614693.0](https://github.com/broadinstitute/gatk/actions/runs/6384614693/job/17328498137) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8538/merge_6384614693.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8538#issuecomment-1743692264:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8538#issuecomment-1743692264,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [6384923533](https://github.com/broadinstitute/gatk/actions/runs/6384923533); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6384923533.11](https://github.com/broadinstitute/gatk/actions/runs/6384923533/job/17328588432) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8538/merge_6384923533.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6384923533.0](https://github.com/broadinstitute/gatk/actions/runs/6384923533/job/17329501887) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8538/merge_6384923533.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8538#issuecomment-1743745525:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8538#issuecomment-1743745525,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [6385319684](https://github.com/broadinstitute/gatk/actions/runs/6385319684); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6385319684.11](https://github.com/broadinstitute/gatk/actions/runs/6385319684/job/17329812414) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8538/merge_6385319684.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6385319684.0](https://github.com/broadinstitute/gatk/actions/runs/6385319684/job/17330706422) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8538/merge_6385319684.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8538#issuecomment-1743797305:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8538#issuecomment-1743797305,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [6789554372](https://github.com/broadinstitute/gatk/actions/runs/6789554372); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6789554372.11](https://github.com/broadinstitute/gatk/actions/runs/6789554372/job/18457022627) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8576/merge_6789554372.11/tests/testOnPackagedReleaseJar/index.html) |; | variantcalling | 17.0.6+10 | [6789554372.2](https://github.com/broadinstitute/gatk/actions/runs/6789554372/job/18457717644) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8576/merge_6789554372.2/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6789554372.0](https://github.com/broadinstitute/gatk/actions/runs/6789554372/job/18457717112) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8576/merge_6789554372.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8576#issuecomment-1800034428:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8576#issuecomment-1800034428,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [6791158196](https://github.com/broadinstitute/gatk/actions/runs/6791158196); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6791158196.11](https://github.com/broadinstitute/gatk/actions/runs/6791158196/job/18462089758) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8577/merge_6791158196.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6791158196.0](https://github.com/broadinstitute/gatk/actions/runs/6791158196/job/18462671872) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8577/merge_6791158196.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8577#issuecomment-1800418349:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8577#issuecomment-1800418349,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [6895762275](https://github.com/broadinstitute/gatk/actions/runs/6895762275); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6895762275.11](https://github.com/broadinstitute/gatk/actions/runs/6895762275/job/18760424597) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8438/merge_6895762275.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6895762275.0](https://github.com/broadinstitute/gatk/actions/runs/6895762275/job/18761169421) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8438/merge_6895762275.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8438#issuecomment-1815257468:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8438#issuecomment-1815257468,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [6896352136](https://github.com/broadinstitute/gatk/actions/runs/6896352136); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6896352136.11](https://github.com/broadinstitute/gatk/actions/runs/6896352136/job/18762290246) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8438/merge_6896352136.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6896352136.0](https://github.com/broadinstitute/gatk/actions/runs/6896352136/job/18763038038) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8438/merge_6896352136.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8438#issuecomment-1815337019:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8438#issuecomment-1815337019,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [6906804987](https://github.com/broadinstitute/gatk/actions/runs/6906804987); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 21 | [6906804987.12](https://github.com/broadinstitute/gatk/actions/runs/6906804987/job/18792647185) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8589/merge_6906804987.12/tests/testOnPackagedReleaseJar/index.html) |; | cloud | 21 | [6906804987.10](https://github.com/broadinstitute/gatk/actions/runs/6906804987/job/18792646673) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8589/merge_6906804987.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 21 | [6906804987.11](https://github.com/broadinstitute/gatk/actions/runs/6906804987/job/18792646928) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8589/merge_6906804987.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8589#issuecomment-1816781546:762,integrat,integration,762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8589#issuecomment-1816781546,1,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [7120763686](https://github.com/broadinstitute/gatk/actions/runs/7120763686); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [7120763686.10](https://github.com/broadinstitute/gatk/actions/runs/7120763686/job/19388722321) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8598/merge_7120763686.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7120763686.11](https://github.com/broadinstitute/gatk/actions/runs/7120763686/job/19388722680) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8598/merge_7120763686.11/tests/testOnPackagedReleaseJar/index.html) |; | variantcalling | 17.0.6+10 | [7120763686.2](https://github.com/broadinstitute/gatk/actions/runs/7120763686/job/19389414633) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8598/merge_7120763686.2/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7120763686.0](https://github.com/broadinstitute/gatk/actions/runs/7120763686/job/19389414172) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8598/merge_7120763686.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8598#issuecomment-1843776739:513,integrat,integration,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8598#issuecomment-1843776739,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [7131188447](https://github.com/broadinstitute/gatk/actions/runs/7131188447); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [7131188447.10](https://github.com/broadinstitute/gatk/actions/runs/7131188447/job/19419221705) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8464/merge_7131188447.10/tests/testOnPackagedReleaseJar/index.html) |; | variantcalling | 17.0.6+10 | [7131188447.2](https://github.com/broadinstitute/gatk/actions/runs/7131188447/job/19420081818) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8464/merge_7131188447.2/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7131188447.0](https://github.com/broadinstitute/gatk/actions/runs/7131188447/job/19420081036) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8464/merge_7131188447.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8464#issuecomment-1845719692:784,integrat,integration,784,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8464#issuecomment-1845719692,1,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [7184026360](https://github.com/broadinstitute/gatk/actions/runs/7184026360); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7184026360.11](https://github.com/broadinstitute/gatk/actions/runs/7184026360/job/19564156491) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8561/merge_7184026360.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1852393379:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1852393379,1,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [7186584675](https://github.com/broadinstitute/gatk/actions/runs/7186584675); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7186584675.11](https://github.com/broadinstitute/gatk/actions/runs/7186584675/job/19572299359) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8561/merge_7186584675.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1852751599:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1852751599,1,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [7186790110](https://github.com/broadinstitute/gatk/actions/runs/7186790110); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7186790110.11](https://github.com/broadinstitute/gatk/actions/runs/7186790110/job/19572967047) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8561/merge_7186790110.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7186790110.11](https://github.com/broadinstitute/gatk/actions/runs/7186790110/job/19576556694) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8561/merge_7186790110.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1852787065:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1852787065,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [7405843720](https://github.com/broadinstitute/gatk/actions/runs/7405843720); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [7405843720.12](https://github.com/broadinstitute/gatk/actions/runs/7405843720/job/20149400857) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8639/merge_7405843720.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7405843720.11](https://github.com/broadinstitute/gatk/actions/runs/7405843720/job/20149400666) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8639/merge_7405843720.11/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [7405843720.1](https://github.com/broadinstitute/gatk/actions/runs/7405843720/job/20149740095) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8639/merge_7405843720.1/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7405843720.0](https://github.com/broadinstitute/gatk/actions/runs/7405843720/job/20149740046) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8639/merge_7405843720.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8639#issuecomment-1876373370:512,integrat,integration,512,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8639#issuecomment-1876373370,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [7891988613](https://github.com/broadinstitute/gatk/actions/runs/7891988613); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7891988613.11](https://github.com/broadinstitute/gatk/actions/runs/7891988613/job/21537494791) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8689/merge_7891988613.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7891988613.0](https://github.com/broadinstitute/gatk/actions/runs/7891988613/job/21538268383) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8689/merge_7891988613.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8689#issuecomment-1942405438:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8689#issuecomment-1942405438,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [7905273867](https://github.com/broadinstitute/gatk/actions/runs/7905273867); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7905273867.11](https://github.com/broadinstitute/gatk/actions/runs/7905273867/job/21577524746) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8689/merge_7905273867.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7905273867.0](https://github.com/broadinstitute/gatk/actions/runs/7905273867/job/21578446531) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8689/merge_7905273867.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8689#issuecomment-1944365526:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8689#issuecomment-1944365526,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [7920773846](https://github.com/broadinstitute/gatk/actions/runs/7920773846); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7920773846.11](https://github.com/broadinstitute/gatk/actions/runs/7920773846/job/21624558365) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7920773846.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7920773846.0](https://github.com/broadinstitute/gatk/actions/runs/7920773846/job/21625457399) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7920773846.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947033740:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947033740,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [7920955548](https://github.com/broadinstitute/gatk/actions/runs/7920955548); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7920955548.11](https://github.com/broadinstitute/gatk/actions/runs/7920955548/job/21625179661) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7920955548.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947096700:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947096700,1,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [7921949505](https://github.com/broadinstitute/gatk/actions/runs/7921949505); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7921949505.11](https://github.com/broadinstitute/gatk/actions/runs/7921949505/job/21628408055) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7921949505.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7921949505.0](https://github.com/broadinstitute/gatk/actions/runs/7921949505/job/21629187149) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7921949505.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947340306:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947340306,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [7921992136](https://github.com/broadinstitute/gatk/actions/runs/7921992136); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7921992136.11](https://github.com/broadinstitute/gatk/actions/runs/7921992136/job/21628545390) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7921992136.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7921992136.0](https://github.com/broadinstitute/gatk/actions/runs/7921992136/job/21629407362) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7921992136.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947344522:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947344522,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [7922661849](https://github.com/broadinstitute/gatk/actions/runs/7922661849); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7922661849.11](https://github.com/broadinstitute/gatk/actions/runs/7922661849/job/21630756683) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7922661849.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7922661849.0](https://github.com/broadinstitute/gatk/actions/runs/7922661849/job/21631484142) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7922661849.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947428539:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947428539,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [8161782218](https://github.com/broadinstitute/gatk/actions/runs/8161782218); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8161782218.11](https://github.com/broadinstitute/gatk/actions/runs/8161782218/job/22311279082) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8715/merge_8161782218.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [8161782218.0](https://github.com/broadinstitute/gatk/actions/runs/8161782218/job/22312090528) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8715/merge_8161782218.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8715#issuecomment-1979517535:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8715#issuecomment-1979517535,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [8164035876](https://github.com/broadinstitute/gatk/actions/runs/8164035876); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8164035876.11](https://github.com/broadinstitute/gatk/actions/runs/8164035876/job/22318490548) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8715/merge_8164035876.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [8164035876.0](https://github.com/broadinstitute/gatk/actions/runs/8164035876/job/22319181115) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8715/merge_8164035876.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8715#issuecomment-1979799202:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8715#issuecomment-1979799202,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [8176966441](https://github.com/broadinstitute/gatk/actions/runs/8176966441); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8176966441.11](https://github.com/broadinstitute/gatk/actions/runs/8176966441/job/22357552500) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8718/merge_8176966441.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [8176966441.0](https://github.com/broadinstitute/gatk/actions/runs/8176966441/job/22358473526) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8718/merge_8176966441.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8718#issuecomment-1981582998:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8718#issuecomment-1981582998,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [8177733856](https://github.com/broadinstitute/gatk/actions/runs/8177733856); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8177733856.11](https://github.com/broadinstitute/gatk/actions/runs/8177733856/job/22360049221) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8718/merge_8177733856.11/tests/test/index.html) |; | integration | 17.0.6+10 | [8177733856.0](https://github.com/broadinstitute/gatk/actions/runs/8177733856/job/22361011218) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8718/merge_8177733856.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8718#issuecomment-1981697888:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8718#issuecomment-1981697888,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [8509671598](https://github.com/broadinstitute/gatk/actions/runs/8509671598); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8509671598.11](https://github.com/broadinstitute/gatk/actions/runs/8509671598/job/23305710482) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8756/merge_8509671598.11/tests/test/index.html) |; | integration | 17.0.6+10 | [8509671598.0](https://github.com/broadinstitute/gatk/actions/runs/8509671598/job/23306610390) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8756/merge_8509671598.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8756#issuecomment-2029982633:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8756#issuecomment-2029982633,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [8524189026](https://github.com/broadinstitute/gatk/actions/runs/8524189026); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8524189026.11](https://github.com/broadinstitute/gatk/actions/runs/8524189026/job/23348239562) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524189026.11/tests/test/index.html) |; | variantcalling | 17.0.6+10 | [8524189026.2](https://github.com/broadinstitute/gatk/actions/runs/8524189026/job/23349497146) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524189026.2/tests/test/index.html) |; | integration | 17.0.6+10 | [8524189026.0](https://github.com/broadinstitute/gatk/actions/runs/8524189026/job/23349496223) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524189026.0/tests/test/index.html) |; | unit | 17.0.6+10 | [8524189026.12](https://github.com/broadinstitute/gatk/actions/runs/8524189026/job/23348239909) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524189026.12/tests/test/index.html) |; | unit | 17.0.6+10 | [8524189026.1](https://github.com/broadinstitute/gatk/actions/runs/8524189026/job/23349496656) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524189026.1/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2032228356:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2032228356,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [8524495307](https://github.com/broadinstitute/gatk/actions/runs/8524495307); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [8524495307.12](https://github.com/broadinstitute/gatk/actions/runs/8524495307/job/23349224262) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524495307.12/tests/test/index.html) |; | integration | 17.0.6+10 | [8524495307.11](https://github.com/broadinstitute/gatk/actions/runs/8524495307/job/23349223900) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524495307.11/tests/test/index.html) |; | unit | 17.0.6+10 | [8524495307.1](https://github.com/broadinstitute/gatk/actions/runs/8524495307/job/23350493955) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524495307.1/tests/test/index.html) |; | variantcalling | 17.0.6+10 | [8524495307.2](https://github.com/broadinstitute/gatk/actions/runs/8524495307/job/23350494281) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524495307.2/tests/test/index.html) |; | integration | 17.0.6+10 | [8524495307.0](https://github.com/broadinstitute/gatk/actions/runs/8524495307/job/23350493586) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524495307.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2032255571:492,integrat,integration,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2032255571,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [8541176894](https://github.com/broadinstitute/gatk/actions/runs/8541176894); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8541176894.11](https://github.com/broadinstitute/gatk/actions/runs/8541176894/job/23399915907) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8541176894.11/tests/test/index.html) |; | variantcalling | 17.0.6+10 | [8541176894.2](https://github.com/broadinstitute/gatk/actions/runs/8541176894/job/23401028686) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8541176894.2/tests/test/index.html) |; | integration | 17.0.6+10 | [8541176894.0](https://github.com/broadinstitute/gatk/actions/runs/8541176894/job/23401027987) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8541176894.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2034980199:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2034980199,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [8545290623](https://github.com/broadinstitute/gatk/actions/runs/8545290623); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8545290623.11](https://github.com/broadinstitute/gatk/actions/runs/8545290623/job/23413247429) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8545290623.11/tests/test/index.html) |; | variantcalling | 17.0.6+10 | [8545290623.2](https://github.com/broadinstitute/gatk/actions/runs/8545290623/job/23414070801) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8545290623.2/tests/test/index.html) |; | integration | 17.0.6+10 | [8545290623.0](https://github.com/broadinstitute/gatk/actions/runs/8545290623/job/23414070420) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8545290623.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2035612373:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2035612373,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [8570036475](https://github.com/broadinstitute/gatk/actions/runs/8570036475); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8570036475.11](https://github.com/broadinstitute/gatk/actions/runs/8570036475/job/23487147373) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8570036475.11/tests/test/index.html) |; | integration | 17.0.6+10 | [8570036475.0](https://github.com/broadinstitute/gatk/actions/runs/8570036475/job/23488077738) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8570036475.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2039788908:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2039788908,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [8648792151](https://github.com/broadinstitute/gatk/actions/runs/8648792151); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [8648792151.12](https://github.com/broadinstitute/gatk/actions/runs/8648792151/job/23713495402) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8771/merge_8648792151.12/tests/test/index.html) |; | integration | 17.0.6+10 | [8648792151.11](https://github.com/broadinstitute/gatk/actions/runs/8648792151/job/23713495044) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8771/merge_8648792151.11/tests/test/index.html) |; | unit | 17.0.6+10 | [8648792151.1](https://github.com/broadinstitute/gatk/actions/runs/8648792151/job/23714601757) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8771/merge_8648792151.1/tests/test/index.html) |; | integration | 17.0.6+10 | [8648792151.0](https://github.com/broadinstitute/gatk/actions/runs/8648792151/job/23714601308) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8771/merge_8648792151.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8771#issuecomment-2049933470:492,integrat,integration,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8771#issuecomment-2049933470,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [8854148674](https://github.com/broadinstitute/gatk/actions/runs/8854148674); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8854148674.11](https://github.com/broadinstitute/gatk/actions/runs/8854148674/job/24316579325) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8796/merge_8854148674.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8796#issuecomment-2080186235:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8796#issuecomment-2080186235,1,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [8882582500](https://github.com/broadinstitute/gatk/actions/runs/8882582500); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8882582500.11](https://github.com/broadinstitute/gatk/actions/runs/8882582500/job/24387605743) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8796/merge_8882582500.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8796#issuecomment-2083371351:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8796#issuecomment-2083371351,1,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [8883008459](https://github.com/broadinstitute/gatk/actions/runs/8883008459); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8883008459.11](https://github.com/broadinstitute/gatk/actions/runs/8883008459/job/24388921100) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8799/merge_8883008459.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8799#issuecomment-2083846921:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8799#issuecomment-2083846921,1,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [8992751464](https://github.com/broadinstitute/gatk/actions/runs/8992751464); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8992751464.11](https://github.com/broadinstitute/gatk/actions/runs/8992751464/job/24703225763) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8819/merge_8992751464.11/tests/test/index.html) |; | integration | 17.0.6+10 | [8992751464.0](https://github.com/broadinstitute/gatk/actions/runs/8992751464/job/24703962607) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8819/merge_8992751464.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8819#issuecomment-2099410966:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8819#issuecomment-2099410966,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [9085418098](https://github.com/broadinstitute/gatk/actions/runs/9085418098); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9085418098.11](https://github.com/broadinstitute/gatk/actions/runs/9085418098/job/24968705742) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8832/merge_9085418098.11/tests/test/index.html) |; | integration | 17.0.6+10 | [9085418098.0](https://github.com/broadinstitute/gatk/actions/runs/9085418098/job/24969675014) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8832/merge_9085418098.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8832#issuecomment-2111091907:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8832#issuecomment-2111091907,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [9085946968](https://github.com/broadinstitute/gatk/actions/runs/9085946968); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9085946968.11](https://github.com/broadinstitute/gatk/actions/runs/9085946968/job/24970476460) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8832/merge_9085946968.11/tests/test/index.html) |; | integration | 17.0.6+10 | [9085946968.0](https://github.com/broadinstitute/gatk/actions/runs/9085946968/job/24971377026) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8832/merge_9085946968.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8832#issuecomment-2111156268:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8832#issuecomment-2111156268,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [9368869663](https://github.com/broadinstitute/gatk/actions/runs/9368869663); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9368869663.11](https://github.com/broadinstitute/gatk/actions/runs/9368869663/job/25791969117) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8832/merge_9368869663.11/tests/test/index.html) |; | integration | 17.0.6+10 | [9368869663.0](https://github.com/broadinstitute/gatk/actions/runs/9368869663/job/25793353779) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8832/merge_9368869663.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8832#issuecomment-2147749326:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8832#issuecomment-2147749326,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [9386157234](https://github.com/broadinstitute/gatk/actions/runs/9386157234); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [9386157234.12](https://github.com/broadinstitute/gatk/actions/runs/9386157234/job/25846033405) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9386157234.12/tests/test/index.html) |; | integration | 17.0.6+10 | [9386157234.11](https://github.com/broadinstitute/gatk/actions/runs/9386157234/job/25846033042) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9386157234.11/tests/test/index.html) |; | unit | 17.0.6+10 | [9386157234.1](https://github.com/broadinstitute/gatk/actions/runs/9386157234/job/25847284448) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9386157234.1/tests/test/index.html) |; | integration | 17.0.6+10 | [9386157234.0](https://github.com/broadinstitute/gatk/actions/runs/9386157234/job/25847283864) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9386157234.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2150295571:492,integrat,integration,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2150295571,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [9454902078](https://github.com/broadinstitute/gatk/actions/runs/9454902078); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9454902078.11](https://github.com/broadinstitute/gatk/actions/runs/9454902078/job/26043508758) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8862/merge_9454902078.11/tests/test/index.html) |; | integration | 17.0.6+10 | [9454902078.0](https://github.com/broadinstitute/gatk/actions/runs/9454902078/job/26044426261) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8862/merge_9454902078.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8862#issuecomment-2159253862:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8862#issuecomment-2159253862,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [9470383170](https://github.com/broadinstitute/gatk/actions/runs/9470383170); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [9470383170.12](https://github.com/broadinstitute/gatk/actions/runs/9470383170/job/26091160198) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9470383170.12/tests/test/index.html) |; | integration | 17.0.6+10 | [9470383170.11](https://github.com/broadinstitute/gatk/actions/runs/9470383170/job/26091159923) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9470383170.11/tests/test/index.html) |; | unit | 17.0.6+10 | [9470383170.1](https://github.com/broadinstitute/gatk/actions/runs/9470383170/job/26092096141) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9470383170.1/tests/test/index.html) |; | integration | 17.0.6+10 | [9470383170.0](https://github.com/broadinstitute/gatk/actions/runs/9470383170/job/26092095804) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9470383170.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2161344780:492,integrat,integration,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2161344780,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [9685898135](https://github.com/broadinstitute/gatk/actions/runs/9685898135); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [9685898135.12](https://github.com/broadinstitute/gatk/actions/runs/9685898135/job/26727088598) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9685898135.12/tests/test/index.html) |; | integration | 17.0.6+10 | [9685898135.11](https://github.com/broadinstitute/gatk/actions/runs/9685898135/job/26727088323) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9685898135.11/tests/test/index.html) |; | unit | 17.0.6+10 | [9685898135.1](https://github.com/broadinstitute/gatk/actions/runs/9685898135/job/26727998365) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9685898135.1/tests/test/index.html) |; | integration | 17.0.6+10 | [9685898135.0](https://github.com/broadinstitute/gatk/actions/runs/9685898135/job/26727998072) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9685898135.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2192548316:492,integrat,integration,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2192548316,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [9688050367](https://github.com/broadinstitute/gatk/actions/runs/9688050367); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [9688050367.12](https://github.com/broadinstitute/gatk/actions/runs/9688050367/job/26733866970) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9688050367.12/tests/test/index.html) |; | integration | 17.0.6+10 | [9688050367.11](https://github.com/broadinstitute/gatk/actions/runs/9688050367/job/26733866854) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9688050367.11/tests/test/index.html) |; | unit | 17.0.6+10 | [9688050367.1](https://github.com/broadinstitute/gatk/actions/runs/9688050367/job/26734370526) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9688050367.1/tests/test/index.html) |; | integration | 17.0.6+10 | [9688050367.0](https://github.com/broadinstitute/gatk/actions/runs/9688050367/job/26734370399) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9688050367.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2192792284:492,integrat,integration,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2192792284,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [9688780153](https://github.com/broadinstitute/gatk/actions/runs/9688780153); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [9688780153.12](https://github.com/broadinstitute/gatk/actions/runs/9688780153/job/26735949170) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9688780153.12/tests/test/index.html) |; | integration | 17.0.6+10 | [9688780153.11](https://github.com/broadinstitute/gatk/actions/runs/9688780153/job/26735949043) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9688780153.11/tests/test/index.html) |; | unit | 17.0.6+10 | [9688780153.1](https://github.com/broadinstitute/gatk/actions/runs/9688780153/job/26736488133) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9688780153.1/tests/test/index.html) |; | integration | 17.0.6+10 | [9688780153.0](https://github.com/broadinstitute/gatk/actions/runs/9688780153/job/26736487991) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9688780153.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2192866266:492,integrat,integration,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2192866266,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [9690704227](https://github.com/broadinstitute/gatk/actions/runs/9690704227); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [9690704227.12](https://github.com/broadinstitute/gatk/actions/runs/9690704227/job/26740984048) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9690704227.12/tests/test/index.html) |; | integration | 17.0.6+10 | [9690704227.11](https://github.com/broadinstitute/gatk/actions/runs/9690704227/job/26740983925) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9690704227.11/tests/test/index.html) |; | unit | 17.0.6+10 | [9690704227.1](https://github.com/broadinstitute/gatk/actions/runs/9690704227/job/26741470210) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9690704227.1/tests/test/index.html) |; | integration | 17.0.6+10 | [9690704227.0](https://github.com/broadinstitute/gatk/actions/runs/9690704227/job/26741470114) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9690704227.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2193694066:492,integrat,integration,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2193694066,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [9690907019](https://github.com/broadinstitute/gatk/actions/runs/9690907019); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9690907019.11](https://github.com/broadinstitute/gatk/actions/runs/9690907019/job/26741532368) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9690907019.11/tests/test/index.html) |; | integration | 17.0.6+10 | [9690907019.0](https://github.com/broadinstitute/gatk/actions/runs/9690907019/job/26742056381) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9690907019.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2193773007:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2193773007,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [9699861398](https://github.com/broadinstitute/gatk/actions/runs/9699861398); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9699861398.11](https://github.com/broadinstitute/gatk/actions/runs/9699861398/job/26769897173) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9699861398.11/tests/test/index.html) |; | integration | 17.0.6+10 | [9699861398.0](https://github.com/broadinstitute/gatk/actions/runs/9699861398/job/26770925465) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9699861398.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2195179629:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2195179629,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [9702596193](https://github.com/broadinstitute/gatk/actions/runs/9702596193); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [9702596193.10](https://github.com/broadinstitute/gatk/actions/runs/9702596193/job/26778809125) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8888/merge_9702596193.10/tests/test/index.html) |; | integration | 17.0.6+10 | [9702596193.11](https://github.com/broadinstitute/gatk/actions/runs/9702596193/job/26778809399) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8888/merge_9702596193.11/tests/test/index.html) |; | unit | 17.0.6+10 | [9702596193.12](https://github.com/broadinstitute/gatk/actions/runs/9702596193/job/26778809607) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8888/merge_9702596193.12/tests/test/index.html) |; | variantcalling | 17.0.6+10 | [9702596193.2](https://github.com/broadinstitute/gatk/actions/runs/9702596193/job/26779620275) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8888/merge_9702596193.2/tests/test/index.html) |; | integration | 17.0.6+10 | [9702596193.0](https://github.com/broadinstitute/gatk/actions/runs/9702596193/job/26779619836) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8888/merge_9702596193.0/tests/test/index.html) |; | unit | 17.0.6+10 | [9702596193.1](https://github.com/broadinstitute/gatk/actions/runs/9702596193/job/26779620060) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8888/merge_9702596193.1/tests/test/index.html) |; | conda | 17.0.6+10 | [9702596193.3](https://github.com/broadinstitute/gatk/actions/runs/9702596193/job/26779620516) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8888/merge_9702596193.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8888#issuecomment-2195558811:493,integrat,integration,493,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8888#issuecomment-2195558811,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [9859920680](https://github.com/broadinstitute/gatk/actions/runs/9859920680); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9859920680.11](https://github.com/broadinstitute/gatk/actions/runs/9859920680/job/27224817827) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8521/merge_9859920680.11/tests/test/index.html) |; | integration | 17.0.6+10 | [9859920680.0](https://github.com/broadinstitute/gatk/actions/runs/9859920680/job/27225663620) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8521/merge_9859920680.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8521#issuecomment-2218092798:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8521#issuecomment-2218092798,2,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [9860282479](https://github.com/broadinstitute/gatk/actions/runs/9860282479); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9860282479.11](https://github.com/broadinstitute/gatk/actions/runs/9860282479/job/27226057661) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8561/merge_9860282479.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2218139213:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2218139213,1,['integrat'],['integration']
Deployability,Github actions tests reported job failures from actions build [9860496699](https://github.com/broadinstitute/gatk/actions/runs/9860496699); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9860496699.11](https://github.com/broadinstitute/gatk/actions/runs/9860496699/job/27226809021) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8561/merge_9860496699.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2218189122:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2218189122,1,['integrat'],['integration']
Deployability,"Given that the tools in this PR are marked as experimental, I think it should be possible @lucidtronix. It would be good, though, if we could recruit someone (@samuelklee ? @mbabadi ?) to do a review pass on the Python side of this branch, as I don't think it's had a proper code review yet. We should also make sure that @cmnbroad is satisfied that the new tools are covered by good end-to-end integration tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367397138:395,integrat,integration,395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367397138,1,['integrat'],['integration']
Deployability,"Given the thumbs up from David, I will go ahead and merge these doc updates.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4310#issuecomment-362010747:68,update,updates,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4310#issuecomment-362010747,1,['update'],['updates']
Deployability,"Glad to see we're not the only one's noticing this. We have been using 4.0.11.x for quite a while with success. During a recent revalidation effort, we have been working with 4.2.x versions and missing quite a few calls we consider ""truth"", while making these calls with other variant callers. We have since verified v4.1.8.0 is performing acceptably, so our data supports the issue occurring during the 4.1.9.0 update.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1171550473:412,update,update,412,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1171550473,1,['update'],['update']
Deployability,"Glad you were able to resolve your issue. Not sure if this is specific to the CNV tool or if the exception caused by the Spark configuration is more general. Tagging engine team @droazen, but closing for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5686#issuecomment-467510488:127,configurat,configuration,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686#issuecomment-467510488,1,['configurat'],['configuration']
Deployability,"Goal was to get WGS coverage collection at 100bp at ~15 cents per sample. Since this is I/O bound (takes ~2 hours to stream or localize a BAM, or about the same to decompress a CRAM), cost reduction can be most easily achieved by reducing the memory requirements and moving down to a cheaper VM. . Memory requirements at 100bp are dominated by manipulations of the list of ~30M intervals. There were a few easy fixes to reduce requirements that did not require changing the collection method (which can be easily modified for future investigations, see #4551):. -removed WellformedReadFilter. See #5233. EDIT: We decided after PR review to retain this filter by default and disable it at the WDL level when Best Practices is released. Leaving the issue open.; -initialized HashMultiSet capacity; -removed unnecessary call to OverlapDetector.getAll; -avoided a redundant defensive copy in SimpleCountCollection; -used per-contig OverlapDetectors, rather than a global one. This brought the cost down to ~9 cents per sample using n1-standard-2's with 7.5GB of memory when collecting on BAMs with NIO. Note that I didn't optimize disk size, which accounts for ~50% of the total cost and is unused when running with NIO, so we are closer to ~5 cents per sample. It is possible that using CRAMs with or without NIO and with or without SSDs might be cheaper. Note that OverlapDetectors may be overkill for our case, since bins are guaranteed to be sorted and non-overlapping and queries are also sorted. We could probably roll something that is O(1) in memory. However, since we are I/O bound, as long as we are satisfied with the current cost, I am willing to sacrifice memory for implementation and maintenance costs, as well as the option to change strategies easily. In any case, @lbergelson found some easy wins in OverlapDetector that may further bring the memory usage down, and will issue a fix in htsjdk soon.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5715:725,release,released,725,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5715,1,['release'],['released']
Deployability,"Going ahead and making this change so TAG team can start trying out the ModelSegments pipeline. It's possible that we could use NIO for other files (reference, interval lists), but this will not have as much impact as using it for BAMs (and in some cases, decreases performance, see comments in #4806). Closes #4806.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5015:86,pipeline,pipeline,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5015,1,['pipeline'],['pipeline']
Deployability,"Going forward, @droazen, who should we ask that for review for these minor documentation updates?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5658#issuecomment-462369317:89,update,updates,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5658#issuecomment-462369317,1,['update'],['updates']
Deployability,"Gonna do some rebasing and splitting into commits, copying some bits from the current git log here for posterity:. ```; commit 28174871c5b2e99a3044a30c0de24a63d2fee5bc (HEAD -> sl_python_version_update, origin/sl_python_version_update); Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 13 00:59:52 2023 -0500. update gCNV WDL tests. commit 31a204b9e900849b5a313e161893de34a2094bb0; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 13 00:14:34 2023 -0500. staged base rc1. commit 74f8fa724dfac142ccd7ac79a757c0e5ac3bb06c; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 13 00:01:38 2023 -0500. minor pymc/pytensor version upgrades, fix 2-interval edge case, update some theano docs. commit 9c9d0c570dd2712631739e0a9d41e90c4ccd3456; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 23:36:55 2023 -0500. update VETS expected, verbose conda env create, pin torch CPU MKL, add pysam, fixed more tests. commit c0a17dfcf9fa1139927570d2f16125bc15a2c19f; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 20:07:08 2023 -0500. fix CNV plotting. commit dd2dd503a92e6fbb5a49be6a88d2e813eb8bf85b; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 15:14:08 2023 -0500. update gCNV expected results, generated on WSL Ubuntu 20.04.2. commit 27d76e8f22d61df90eeb337e033ae128ce07ab90; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 14:53:04 2023 -0500. update python env integration tests. commit 348df9192235f7d1ea941d0b31e5c96acc0d6491; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 10:59:23 2023 -0500. disable CNN tests, add deprecation message. commit ed59372b4be226785af1d3fb1b1a39a9ad3b4f6a; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 09:55:24 2023 -0500. clean up rebase. commit 18e530db26f803ee46a0006843cb36d4ed4194b4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 11:31:46 2023 -0500. postprocess fixed. commit f510c2e9f10d7066c15f1835669d676964b8a4cb; Author: Samuel Lee <le",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322:320,update,update,320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322,4,"['update', 'upgrade']","['update', 'upgrades']"
Deployability,Good news: there's been a release since so we don't even need to rely on snapshot.; Pull Request #2488 does the update. However I'm going to have to merge in @lbergelson's fix as well.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2441#issuecomment-287831517:26,release,release,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2441#issuecomment-287831517,2,"['release', 'update']","['release', 'update']"
Deployability,"Good point, here's the PR in dsde-pipelines: https://github.com/broadinstitute/dsde-pipelines/pull/718/files. It just updates the Picard version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5818#issuecomment-474850615:34,pipeline,pipelines,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5818#issuecomment-474850615,3,"['pipeline', 'update']","['pipelines', 'updates']"
Deployability,"Google is deprecating and removing their implementation of the old style GA4GH read and reference API's. . > ; > Reads API functionality is now replaced by the htsget protocol ; > ; > This year, the GA4GH team introduced the htsget protocol to allow users to download read data for subsections of the genome in which they are interested. This is a richer and more flexible approach to working with reads data. It allows you to keep your genomics data in a common BAM file format on Google Cloud Storage and work with it efficiently from your computation pipelines, using standard bioinformatics tools. We have already launched our own open source implementation of this protocol, which you can use to access your reads data. Many popular tools such as samtools and htslib have been updated by the community to support htsget. Documentation is provided here. The Reads API is now deprecated, and will be decommissioned after one year, or after there has been no API activity for one month by those receiving this notice, whichever comes first. ; > ; > Variants API is now replaced by htsget and Variant Transforms ; > ; > The GA4GH team also plans to extend the htsget protocol to cover variant data, and we will extend our implementation of htsget to cover this use case. ; > ; > After analyzing usage of the Variants API, we found that users primarily used it to import variant data and then export it to BigQuery. To save time and effort, we created Variant Transforms, an open source tool for directly importing VCF data into BigQuery. Variant Transforms and its documentation are published here. Variant Transforms is more scalable than the legacy Variants API, and it has a robust roadmap with a dedicated team. We also welcome collaborators on this project as it advances. ; > ; > The Variants API is now deprecated, and will be decommissioned after one year, or after there has been no API activity for one month, whichever comes first. ; > ; > We are excited to move in step with the global ge",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4166:554,pipeline,pipelines,554,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166,2,"['pipeline', 'update']","['pipelines', 'updated']"
Deployability,"Google made an incompatible change to the dataproc api which is causing all builds to fail. We're seeing errors like this:; ```; ERROR: (gcloud.beta.dataproc.clusters.create) The required property [region] is not currently set.; It can be set on a per-command basis by re-running your command with the [--region] flag. You may set it for your current workspace by running:. $ gcloud config set dataproc/region VALUE. or it can be set temporarily by the environment variable [CLOUDSDK_DATAPROC_REGION]; ```. It's mentioned in gcloud release notes here:; ```; 260.0.0 (2019-08-27); Breaking Changes; (Cloud Dataproc) Modified --region flag to be mandatory.; To use Cloud Dataproc commands, pass the --region flag on every invocation, or set the dataproc/region configuration variable via gcloud config set dataproc/region.; For gcloud beta dataproc commands, this flag/config value is required.; For gcloud dataproc commands, the default will remain global until January 2020.; ```. I'm going to set the environment variable in our travis config right now, and then open a separate PR to specify region in all the commands.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6129:532,release,release,532,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6129,2,"['configurat', 'release']","['configuration', 'release']"
Deployability,Google released a hotfix which fixed the problem.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5003#issuecomment-404316063:7,release,released,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5003#issuecomment-404316063,2,"['hotfix', 'release']","['hotfix', 'released']"
Deployability,"Got another one in the same branch at https://travis-ci.com/github/broadinstitute/gatk/jobs/300319727, this time in HaplotypeCallerSparkIntegrationTest.testNonStrictVCFModeIsConsistentWithPastResults. @lbergelson this branch already updates the base image to 18.04, but I haven't yet made any updates to .travis.yml as you do in https://github.com/broadinstitute/gatk/tree/lb_update_docker_ubuntu. Think that could be causing these issues?. I'll try to debug a bit once I sort out the python stuff. ```; org.broadinstitute.hellbender.tools.HaplotypeCallerSparkIntegrationTest > testNonStrictVCFModeIsConsistentWithPastResults[0](/gatkCloneMountPoint/src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam, /gatkCloneMountPoint/src/test/resources/large/human_g1k_v37.20.21.fasta) FAILED; org.apache.spark.SparkException: Job aborted.; at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:100); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1083); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1081); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1081); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); at org.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopDataset(PairRDDFunctions.scala:1081); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopFile$2.apply$mcV$sp(PairRDDFunctions.scala:1000); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopFile$2.apply(PairRDDFunctions.scala:991); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopFile$2.apply(PairRDDFunctions.scala:991); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationS",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:233,update,updates,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,2,['update'],['updates']
Deployability,"Got the tests to pass by generating a new expected result as mentioned in @kgururaj comment for expected.testGenomicsDBImportWithNonDiploidData.vcf and by using the GenomicsDBImports folder for expected results as some of the vcf files were updated as part of PR 5170. * testGenomicsDBImportFileInputsAgainstCombineGVCFWithNonDiploidData; * testGenomicsDBImportFileInputs_newMQ. @droazen, please feel free to merge. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5397#issuecomment-454623888:241,update,updated,241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5397#issuecomment-454623888,1,['update'],['updated']
Deployability,"Gradle 2.12 just released which includes some improvements we've been waiting for. It includes a ""compileOnly"" scope which should make some of our spark configuration unnecessary. We should investigate if we can simplify the sparkJar setup using the new scope, and possible improve things for gatk-protected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1578:17,release,released,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1578,2,"['configurat', 'release']","['configuration', 'released']"
Deployability,"Great news! I'm looking forward to seeing your detailed results tomorrow. This can be low priority unless it's a dramatic improvement over what's in the current Talkowski Lab pipeline. (I remember when we met with Ryan and Harrison a while ago that their approach wasn't as sophisticated, but it seems to get the job done.) I'll talk to Harrison about it tomorrow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-415068602:175,pipeline,pipeline,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-415068602,1,['pipeline'],['pipeline']
Deployability,Great! Let me update my pull request then.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2822#issuecomment-306581248:14,update,update,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2822#issuecomment-306581248,1,['update'],['update']
Deployability,"Great, thanks @nalinigans ! Does this require a GenomicsDB upgrade to put it into effect?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6514#issuecomment-603837722:59,upgrade,upgrade,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6514#issuecomment-603837722,1,['upgrade'],['upgrade']
Deployability,"Great, thanks @vdauwera. I'm having trouble placing images into the Monday.com issue ticket so will note my updates here. Studying the LaTeX issue, it appears that three of the equations do not render correctly but five do. This is the case for the <https://software.broadinstitute.org/gatk/documentation/article?id=11074> view. For the forum view at <https://gatkforums.broadinstitute.org/gatk/discussion/11074>, none of the equations render. . CORRECT RENDERING:; ---; ![screenshot 2019-01-15 10 24 43](https://user-images.githubusercontent.com/11543866/51190403-270d3b00-18b0-11e9-9b52-61835cb64646.png); ---. DO NOT RENDER:; ---; ![screenshot 2019-01-15 10 22 30](https://user-images.githubusercontent.com/11543866/51190414-2aa0c200-18b0-11e9-97d9-55cf5b148003.png); ---; ![screenshot 2019-01-15 10 23 12](https://user-images.githubusercontent.com/11543866/51190419-2d031c00-18b0-11e9-9a4e-1e5c479f1a65.png). ---. I will keep the LaTeX formatted text in HTML comment tags so the docs retain them and they remain untouched and also place in PNG images of the rendered equations, like so:. ![screenshot 2019-01-15 10 36 53](https://user-images.githubusercontent.com/11543866/51191023-83bd2580-18b1-11e9-8262-c6937b763731.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-454436594:108,update,updates,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-454436594,1,['update'],['updates']
Deployability,"Great, thanks for noting that! I might just have to ignore them for now... The segfault seems to be more pernicious and occurs at a higher rate---I only saw tests passing once. I suspect it has something to do with the upgrade to 18.04 + Scala 2.12 + Java 11, but I'm not sure...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-602838299:219,upgrade,upgrade,219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-602838299,1,['upgrade'],['upgrade']
Deployability,"Great, thanks!. On Mon, Dec 3, 2018 at 10:15 AM David Benjamin <notifications@github.com>; wrote:. > @meganshand <https://github.com/meganshand> I ran the ""Full Pipeline""; > workflows in a clone of your FC workspace:; > https://portal.firecloud.org/#workspaces/broad-firecloud-dsde/copy-of-megans-m2-mito-validations.; > I did not run any of the things that generate graphs because they were; > harder for me to understand. To compare the new results to your previous; > ones, I took all variants that were either PASS or had only the; > contamination filter applied, extracted just the locus and alleles columns,; > then manually inspected the diff. For the 5% and 50% spike-ins there were; > usually no differences at all, while for the 1% spike-in the difference was; > usually 2-5 variants that straddled the LOD threshold.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5473#issuecomment-443745103>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMwCcuQyzMweZjxWrXBODTCBaOSIks5u1T_-gaJpZM4Y9STI>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5473#issuecomment-443751026:161,Pipeline,Pipeline,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5473#issuecomment-443751026,1,['Pipeline'],['Pipeline']
Deployability,"Greetings, ; I am running into a similar issue trying Gatk DetermineGermlineContigPloidy (through a Snakemake pipeline). The exact **command** is: . `gatk --java-options {params.java_opts} DetermineGermlineContigPloidy -L {input.interval_list} -I {params.files} --contig-ploidy-priors {input.priors} --output-prefix {params.prefix} -imr OVERLAPPING_ONLY -O {output.ploidy_calls}`. When solved, {params.files} creates something like ""-I sample1.hdf5 -I sample2.hdf5"" etc... Involved **software versions**:; **gcnvkernel** = 0.7; **gatk** = 4.2.0.0; **Python** = 3.6.10. **Complete log**: . ```; Using GATK jar /software/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -jar /software/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar DetermineGermlineContigPloidy -L results/cnv/targets.preprocessed.interval_list -I results/cnv/hdf5/MGM20-0848_S4.hdf5 -I results/cnv/hdf5/MGM20-0872_S2.hdf5 -I results/cnv/hdf5/MGM20-1121_S4.hdf5 -I results/cnv/hdf5/MGM20-1543_S10.hdf5 --contig-ploidy-priors resources/contig_ploidy_priors.tsv --output-prefix ploidy -imr OVERLAPPING_ONLY -O results/cnv/ploidy; 15:09:27.326 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/software/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 18, 2021 3:09:27 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 15:09:27.686 INFO DetermineGermlineContigPloidy - ------------------------------------------------------------; 15:09:27.686 INFO DetermineGermlineContigPloidy - The Genome Analysis Toolkit (GATK) v4.2.0.0; 15:09:27.687 INFO DetermineGermlineContigPloidy - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:09:27.687 INFO DetermineGermli",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:110,pipeline,pipeline,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['pipeline'],['pipeline']
Deployability,"Greetings,. I would like to be able to run spark reads pipeline from the jar file without the gatk wrapper script. My reason for this is that I already have existing infra for spark jobs that I would like to use. Specifically, I would like to be able to run gatk jobs with the kubernetes [spark operator](https://github.com/GoogleCloudPlatform/spark-on-k8s-operator). This requires being able to give the SparkApplication CRD a main class location and a jar file. Is this feasible with gatk?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6198:55,pipeline,pipeline,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6198,1,['pipeline'],['pipeline']
Deployability,GroundTruthScorer doc update,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8597:22,update,update,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8597,1,['update'],['update']
Deployability,"GvsCreateFilterSet.wdl failed recently for Morgan because of this bug. When run in a brand new project, filter model creation fails because we expect the project to have a hard coded dataset named ""temp_tables"" which is likely does not have. The workaround is simply to manually create one. This ticket removes the need for this dataset altogether. This is removed, and instead, the default dataset is used (that the many other tables created in this pipeline use as the default). able to reproduce with a dummy dataset name:; <img width=""1278"" alt=""Screen Shot 2022-03-03 at 10 44 39 PM"" src=""https://user-images.githubusercontent.com/6863459/156822409-a99d7068-169c-48a2-83ff-5bcc81cdbd2e.png"">. tested here:; https://app.terra.bio/#workspaces/broad-dsp-spec-ops-fc/gvs_testing_ingest/job_history/1dd27d90-82c4-44e6-8172-15c10c8a9c7f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7704:451,pipeline,pipeline,451,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7704,1,['pipeline'],['pipeline']
Deployability,HDF5 integration.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/498:5,integrat,integration,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/498,1,['integrat'],['integration']
Deployability,HI @droazen I see you were on this issue and generated a PR but could not merge because test case failures. I wanted to check if you were able to make progress on this. Within my organization infosec independently reviewed and have denied use of GATK :( . Let me know if you have an ETA for security fix update. Thank you!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1678986791:304,update,update,304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1678986791,1,['update'],['update']
Deployability,"HI @sooheelee, could you take a look at the updated documentation?; Thank you, Marton",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3989:44,update,updated,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3989,1,['update'],['updated']
Deployability,"Hacked together a proof-of-principle in sl_indexed_counts. This enables streaming of indexed counts (when they are specified by a bucket, although we should change this to trigger on the presence of an index) only for the requested intervals in the gCNV step, which would cut disk costs to practically zero. We could enable this in the contig-ploidy step as well, although the cost benefit is not as great there since the tool is short running. The relevant code clocks in at around +250 lines and could be even more minimal after some cleanup and extraction, but we'd need to update documentation and the WDLs. All previous behavior is preserved.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-469695181:577,update,update,577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-469695181,1,['update'],['update']
Deployability,"Hadoop-BAM 7.5.0 has not been released yet, so this will fail.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1817:30,release,released,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1817,1,['release'],['released']
Deployability,"Hadoop-BAM and htsjdk upgrades, Spark tool changes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1469:22,upgrade,upgrades,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1469,1,['upgrade'],['upgrades']
Deployability,"HaplotypeCaller, GenotypeGVCFs, and GenomicsDBImport integration tests are all passing locally. I'll check Travis in the morning to see what tests are left to update.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5484#issuecomment-457893993:53,integrat,integration,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5484#issuecomment-457893993,2,"['integrat', 'update']","['integration', 'update']"
Deployability,HaplotypeCaller: add a good integration test for the --max-alternate-alleles argument,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4497:28,integrat,integration,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4497,1,['integrat'],['integration']
Deployability,HaplotypeCaller: omnibus updates and fixes for 4.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3519:25,update,updates,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3519,1,['update'],['updates']
Deployability,HaplotypeCallerIntegrationTest: add a boolean toggle to update the expected outputs for all exact-match-based tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5324:46,toggle,toggle,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5324,2,"['toggle', 'update']","['toggle', 'update']"
Deployability,"Happy New Year, @davidbenjamin! Coming back to your comment from October, did you perhaps have the chance to look at the new panel of normals and whether is solves the issue? It has been almost exactly half a year now, since we reported the bug, and given the severity of the issue regarding clinical applications it would be important to get a better understanding of whether the updated PON fixes it. Thanks a bunch!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1403334919:381,update,updated,381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1403334919,1,['update'],['updated']
Deployability,"Happy to chat more @samuelklee, but for now in our use case this isn't super important to have this tuning step fully integrated into the tool. Of course I didn't respond to your first comment quickly enough and I completely agree with the approach you laid out in the second comment. . I can try adding this new workflow to the WDL and testing it out as well. I have some GIAB samples so the test you mention about comparing the LL to an orthogonal F1 should be doable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1066852670:118,integrat,integrated,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1066852670,1,['integrat'],['integrated']
Deployability,Has anyone reported the new release 4.0.12.0 CalculateContamination's BUG?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5536:28,release,release,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5536,1,['release'],['release']
Deployability,Has it? I don't [see](https://mvnrepository.com/artifact/com.google.cloud/google-cloud-nio) any June release listed yet (?) The latest as of this writing is 0.18.0-alpha.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2822#issuecomment-306580555:101,release,release,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2822#issuecomment-306580555,1,['release'],['release']
Deployability,Has there been any progress on this? The [CPTAC NCI consortium](https://proteomics.cancer.gov/programs/cptac) is going with GENCODE 42; it would be great if it was more straightforward to update the GENCODE version in our local data source.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7385#issuecomment-1297584435:188,update,update,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7385#issuecomment-1297584435,1,['update'],['update']
Deployability,Has this been fixed in 4.1.4.1 or should I wait for the next release? Had the same issue with GenotypeGVCFs in 4.1.4.0 using a GenomicsDB database with five GVCFs with pooled samples (12 samples per pool).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-573176753:61,release,release,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-573176753,1,['release'],['release']
Deployability,Has updated optical duplicate finding code for MarkDuplicatesSpark.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5597:4,update,updated,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5597,1,['update'],['updated']
Deployability,"Have been having the following issue running StructuralVariationDiscoveryPipeline on previous and the newest release of GATK(4.1.0.0). Currently attempting to use on a computing cluster without spark enabled. . Command line used:; gatk/gatk-4.1.0.0/gatk StructuralVariationDiscoveryPipelineSpark \; -I $CRAM \; -R $Hg38 \; --aligner-index-image reference.fasta.Hg38.img \; --kmers-to-ignore kmers_to_ignore_hg38.txt \; --contig-sam-file aligned_contigs.sam \; -O ${base}_GATK_SV_output.vcf . **Error Log**:; 19/02/01 21:28:27 INFO TaskSetManager: Starting task 700.0 in stage 5.0 (TID 4405, localhost, executor driver, partition 700, PROCESS_LOCAL, 4940 bytes); 19/02/01 21:28:27 INFO Executor: Running task 700.0 in stage 5.0 (TID 4405); 19/02/01 21:28:27 INFO TaskSetManager: Finished task 668.0 in stage 5.0 (TID 4373) in 37331 ms on localhost (executor driver) (669/741); 19/02/01 21:28:27 INFO BlockManagerInfo: Removed taskresult_4373 on 10.120.16.54:34926 in memory (size: 1645.1 KB, free: 15.8 GB); 19/02/01 21:28:27 INFO NewHadoopRDD: Input split: file: /cram8/1-00004__CG0000-1789.GMKF2.cram:23488102400+33554432; 19/02/01 21:28:28 ERROR Executor: Exception in task 698.0 in stage 5.0 (TID 4403); **java.lang.IllegalArgumentException: provided start is negative: -24**; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.ha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5647:109,release,release,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5647,1,['release'],['release']
Deployability,Have started testing snapshot releases from genomicsdb.org in nalini_new_genomicsdb_jar branch. Will wait for @kgururaj to finish his work and release a final jar from com.intel before finally moving gatk to the new fork.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5277#issuecomment-429598919:30,release,releases,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5277#issuecomment-429598919,2,['release'],"['release', 'releases']"
Deployability,Have updated the gatk override jar with a fresh build (ah_var_store on 7/8/2022); And updated the docker similarly.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7934:5,update,updated,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7934,2,['update'],['updated']
Deployability,"Have you addressed all of @cmnbroad 's comments? If you think this branch is good to go, we might be able to get it in for this release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5985#issuecomment-518389916:128,release,release,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5985#issuecomment-518389916,1,['release'],['release']
Deployability,Have you confirmed that with this patch the original issue with picard interval lists + expansion is resolved? Can you add a test for that (using an actual Picard interval list) as well?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4270#issuecomment-360815340:34,patch,patch,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4270#issuecomment-360815340,1,['patch'],['patch']
Deployability,Have you run an integration test?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8847#issuecomment-2135781130:16,integrat,integration,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8847#issuecomment-2135781130,1,['integrat'],['integration']
Deployability,Heap Space error in PopulateFilterSetInfo. Passing Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/50d867c5-3f6f-405b-8e7b-a714ab7e806f).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8575:51,Integrat,Integration,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8575,1,['Integrat'],['Integration']
Deployability,Hellbender should export unit/integration testing utils as a maven artifact.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/525:30,integrat,integration,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/525,1,['integrat'],['integration']
Deployability,"Hello - I'm writing to check on these PRs again. I appreciate these are not GATK's priority, but they're blocking #6973 and we've been stuck for a long time here. If there is additional work, testing or anything needed on this I am happy to offer my time if there's anything that would help get this done. For example, while this PR creates the VC comparison code, it doesnt integrate it into existing tests. if doing this would help accelerate approving this I would be willing to take a stab at this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7021#issuecomment-814233123:375,integrat,integrate,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7021#issuecomment-814233123,1,['integrat'],['integrate']
Deployability,"Hello @SZLux,. This looks suspiciously like #3050. I suspect this isn't a PathSeq issue, but to be sure can you please try to run another GATK Spark tool such as CountReadsSpark? If that does not work, it's likely an issue with your configuration or Spark/Java versions being incompatible. . What kind of environment are you running in? My suspicion is you are running on a cluster and have the correct Spark/Java version on the driver (master node) but perhaps not on the workers.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383712768:233,configurat,configuration,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383712768,1,['configurat'],['configuration']
Deployability,Hello @Tangerine-ljy what version of GATK are you using for this work? We just changed that code but have not released it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8394#issuecomment-1613290796:110,release,released,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8394#issuecomment-1613290796,1,['release'],['released']
Deployability,"Hello @bharathramh thank you for your question. We just recently merged the bulk of the code for DRAGEN-GATK (#6634) which means that we are slated to release the DRAGEN-GATK for the next release of GATK. When that happens we will also be releasing an official wdl workflow to use all the new features together. . As for STR variants, one of the code improvements in the new genotyping engine is to better model STR errors by performing a per-sample pre-processing step where a table of empirically generated STR priors is generated by the tools `ComposeSTRTableFile` and `CallibrateDragstrModel`. These work by modifying the priors for genotying to be more in line with the sample PCR/Sequencing errors and can't really be thought of as a feature to ""find STRs"" (except `ComposeSTRTableFile` which is used to find STRs in the reference). These will be featured in the published wdls with appropriate commands. . I would recommend in the future that you direct questions like this one to our forums since this ticket tracker is used to track bugs/ongoing development on the GATK and our Comms Team is better equipped to answer questions there: https://gatk.broadinstitute.org/hc/en-us/community/topics",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6912#issuecomment-716747266:151,release,release,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6912#issuecomment-716747266,2,['release'],['release']
Deployability,Hello @ldgauthier how are you ? Any news about the updates about the fix with the DRAGEN data ? thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7589#issuecomment-1066732798:51,update,updates,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7589#issuecomment-1066732798,1,['update'],['updates']
Deployability,"Hello @ldgauthier,; Thank you for your answer; I came up with this problem because we have many patients resulting from Dragen pipeline that we want to analyze. Right now we can use Hail to analyze all 22 Chr from Gnarly pipe, but the sexual Chr is missing, and they are important for many syndromes. We can try doing manual filtering as you mentioned, but I'm just pointing out this bug we came across. If you have any other tip/faq/""forums discussion"" to share, I'd be thankful. . Anyway, I'll wait for any news regarding this topic. Let us know if something new pops up. . Best :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7690#issuecomment-1049269442:127,pipeline,pipeline,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7690#issuecomment-1049269442,1,['pipeline'],['pipeline']
Deployability,"Hello @nalinigans,. As part of gatk-sv pipeline we are using GATK : v4.1.8.1 which doesn't have bypass-feature-reader option. Also, we didn’t capture strace for the run with just ""--genomicsdb-shared-posixfs-optimizations"" so wont be able to share the FUTEX process counts. So after using v4.2.4.1 we get below results. 	- Using ""--genomicsdb-shared-posixfs-optimizations"" & ""--bypass-feature-reader"" the process took 118 mins.; ""FUTEX_WAIT_PRIVATE, 0, NULL"" : 1266. 	- Using ""--genomicsdb-shared-posixfs-optimizations"" & ""--bypass-feature-reader"" and ; TILEDB_UPLOAD_BUFFER_SIZE=5242880 as env variable the process took 113 mins.; 	""FUTEX_WAIT_PRIVATE, 0, NULL"" : 3. 	- Even using 10 MB as buffer size resulted in same execution time of 113 mins.; 	- Using a buffer size bigger i.e. 50 MBs caused the process to run slower so we aborted it. Please let us know if we can improve it further.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7646#issuecomment-1040947845:39,pipeline,pipeline,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7646#issuecomment-1040947845,1,['pipeline'],['pipeline']
Deployability,"Hello @yixuanw99. This sounds like a problem that we shold look into. However, there is a workaround in master that should be in the next release. Namely we have introduced an `--inverted-read-filter` argument (#8724) that allows you to flip the logic of any read filter in the GATK easily which should serve as an easy workaround in this case. Furthermore the tool itself has a built in argument `--invert-soft-clip-ratio-filter` which should allow you to tailor the behavior to your liking.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8887#issuecomment-2186664550:138,release,release,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8887#issuecomment-2186664550,1,['release'],['release']
Deployability,"Hello GATK team!. ## Bug Report. ### Affected tool(s) or class(es). mutect2. ### Affected version(s); - Latest public release version: 4.2.6.1. ### Description . getting fail for all scatter task with the argument ""--emit-ref-confidence GVCF"", no fails without it. error:; ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx3000m -jar /root/gatk.jar GetSampleName -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://cclebams/hg38_wes/CDS-ce3y1s.hg38.bam -O tumor_name.txt -encode --gcs-project-for-requester-pays broad-firecloud-ccle; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.b3fd1830; 14:13:40.205 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 14:13:40.275 INFO Mutect2 - ------------------------------------------------------------; 14:13:40.276 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.2.6.1; 14:13:40.277 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:13:40.277 INFO Mutect2 - Executing as root@0b46ce3a6ba5 on Linux v5.10.107+ amd64; 14:13:40.277 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 14:13:40.278 INFO Mutect2 - Start Date/Time: May 13, 2022 2:13:40 PM GMT; 14:13:40.278 INFO Mutect2 - ------------------------------------------------------------; 14:13:40.278 INFO Mutect2 - ------------------------------------------------------------; 14:13:40.279 INFO Mutect2 - HTSJDK Version: 2.24.1; 14:13:40.280 INFO Mutect2 - Picard Version: 2.27.1; 14:13:40.284 INFO Mutect2 - Built for Spark Version: 2.4.5; 14:13:40.284 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:13:40.284 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:13:40.285 INFO Mutect2 - H",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7849:118,release,release,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7849,1,['release'],['release']
Deployability,"Hello Team,; Any update on this bug.Are there any fixes. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-274315540:17,update,update,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-274315540,1,['update'],['update']
Deployability,"Hello again, I have not been able to solve the problem with the launch ReadsPipelineSparkMulticore.wdl. :(; ![qoKs8pEt_-0](https://user-images.githubusercontent.com/55628707/161521914-49b7b10f-3264-43d5-8f5c-739d924656a1.jpg); I use this command:; `java -jar ../cromwell-77.jar run ReadsPipelineSparkMulticore.wdl -i exome/ReadsPiplineSpark_exome.json`; This is my json file:; ![qo2S-PSVs_xNXb5ZysWT8g](https://user-images.githubusercontent.com/55628707/164080985-ae983a19-104a-4742-9401-82ea938ef69e.jpeg); Here is my configuration (CPU and RAM):; ![PEP_IbcPaXyZtql0oefE_A](https://user-images.githubusercontent.com/55628707/164081131-58958f86-5aaf-450f-b985-d7885d4a8de4.jpeg); ![FDmF-6wr4RelT11qqByfGA](https://user-images.githubusercontent.com/55628707/164081137-2d07fe83-845e-463e-ab17-7a5cecb415e0.jpeg). Found this error in my stderr file:; 22/04/06 15:36:17 ERROR Executor: Exception in task 10.0 in stage 11.0 (TID 1596); java.lang.OutOfMemoryError: GC overhead limit exceeded; 	at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.calculateFractionalErrorArray(BaseRecalibrationEngine.java:440); 	at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:141); 	at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.lambda$null$0(BaseRecalibratorSparkFn.java:33); 	at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn$$Lambda$705/136574652.accept(Unknown Source); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at org.broadinstitute.hellbender.utils.iterators.CloseAtEndIterator.forEachRemaining(CloseAtEndIterator.java:47); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:647); 	at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.lambda$apply$6ed74b3e$1(BaseRecalibratorSparkFn.java:33); 	at or",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7796:519,configurat,configuration,519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7796,1,['configurat'],['configuration']
Deployability,"Hello all,. Thank you. My pipeline is as @wangshun1121 describes as well - I run regions in parallel. I would prefer if this argument remained optional, as this will permanently break pipelines running Mutect2 on regions in parallel. Does anyone know offhand what old version I can pin to as a work around? . @lbergelson",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6102#issuecomment-525361625:26,pipeline,pipeline,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6102#issuecomment-525361625,2,['pipeline'],"['pipeline', 'pipelines']"
Deployability,"Hello there,. ## Documentation request. It would be awesome if each major/minor release of GATK contained benchmarking results run against a truth set. For calling short germline variants, you could evaluate precision and recall using one of the NIST samples (i.e. HG002) and for calling short somatic variants you could use the SEQC2 tumor-normal pair. . I would like to see how new releases of GATK and how your recommendations/best practices impact precision and recall against a known truth set. This transparency would help anyone using your tools decide if it's worth upgrading to a new release of GATK, or if their implementation of your recommended set of best practices is performing as expected. . If this information could be added to the best practices pages, a relevant tutorial, or a new section of the documentation (containing hap.py/som.py benchmarking information and run times for a set of tested tools and/or workflows), that would be great!. Please let me know what you think, and if you have any questions. Best regards,; @skchronicles",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9019:80,release,release,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9019,3,['release'],"['release', 'releases']"
Deployability,"Hello!. Any update on this? . Best,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716#issuecomment-1077622128:12,update,update,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716#issuecomment-1077622128,1,['update'],['update']
Deployability,"Hello, . I have the same problem, . path_input_file=/work/gr-fe/archive/sample_repository/all_exome_gvcfs_hg38/FVH/exomes #patient GVCF; path_name_individu=/work/gr-fe/sboutry/excalibur/input/11_12_23_gvcf_FVH/patient_name.txt; path_output=/work/gr-fe/sboutry/excalibur/input/11_12_23_gvcf_FVH/patient_data.vcf.gz; tmp_folder=/scratch/sboutry/logs/combine_gvcf_file; nbr_groups=2. #Path to database and programs; REF=/work/gr-fe/saadat/Reference_Genome/GRCH38_no_alt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa.gz; BCFTOOLS=/work/gr-fe/sboutry/tools/bcftools/install/bin/bcftools; export BCFTOOLS_PLUGINS=/work/gr-fe/sboutry/tools/bcftools/bcftools/plugins; TABIX=/work/gr-fe/sboutry/tools/tabix/tabix-0.2.6/tabix; GATK=/work/gr-fe/sboutry/tools/gatk/gatk-4.2.2.0/gatk. cd ${path_input_file}. ${GATK} --java-options ""-Xmx180G -XX:ParallelGCThreads=36"" CombineGVCFs -R ${REF} --variant ${path_name_individu} -O ${path_output}/patient_data.g.vcf.gz. where all my files are like this . JL0015.g.vcf.gz; JL0016.g.vcf.gz; JL0017.g.vcf.gz; JL0018.g.vcf.gz; JL0019.g.vcf.gz; JL0020.g.vcf.gz; JL0182.g.vcf.gz; JL0183.g.vcf.gz; JL0184.g.vcf.gz; JL0185.g.vcf.gz; JL0186.g.vcf.gz; JL0234.g.vcf.gz; JL0278.g.vcf.gz; JL0412.g.vcf.gz; JL0417.g.vcf.gz; JL0515.g.vcf.gz. A USER ERROR has occurred: Cannot read file:///work/gr-fe/sboutry/excalibur/input/11_12_23_gvcf_FVH/patient_name.txt because no suitable codecs found. Thanks a lot for any help . Best, . Simon",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8255#issuecomment-1918989841:562,install,install,562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8255#issuecomment-1918989841,1,['install'],['install']
Deployability,"Hello, ; Just checking in to see if there is any new release for GATK mitochondria pipeline? Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-475701980:53,release,release,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-475701980,2,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"Hello, @oldmikeyang I'm in the middle of doing a tie out for MarkDuplicatesSpark right now. I just recently fixed (and it will hopefully be released soon) some counting issues involving the metrics collection (it was over-counting the number of duplicate pairs marked compared to picard) I suspect it is likely that the actual bam output is correct. I will have a branch soon that I would ask you to try markDuplicatesSpark again on and tell me if it's still causing problems, unfortunately an unrelated fix requires a change to go into picard https://github.com/broadinstitute/picard/pull/1230. . I will let you know when the PR is open, as I would love to know if it fixes this mismatch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427388821:140,release,released,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427388821,1,['release'],['released']
Deployability,"Hello, Any updates on this?. This seems like an important debug because most people that would want to look at germlines would likely also be interested in having a GVCF format.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7849#issuecomment-1147531376:11,update,updates,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7849#issuecomment-1147531376,1,['update'],['updates']
Deployability,"Hello, i'm trying to run GATK4 BaseRecalibratorSpark in local in a nextflow pipeline, but I got every time the same error with this command :. **gatk-launch BaseRecalibratorSpark --spark-runner LOCAL --spark-master local[23] -R $indexbit -I ${input_bam} --known-sites ${params.dbsnpAll} -L ${params.targetBed} -O ${output_name}-recalibration_report.grp**. Here is the full error output, basically, the failure seems to be linked to an absence of activity of the BaseRecalibratorSpark during 12s which kill the spark heartbeat and then the processus :. ```; 18/03/09 09:22:08 WARN Executor: Issue communicating with driver in heartbeater; java.lang.NullPointerException; at org.apache.spark.storage.memory.MemoryStore.getSize(MemoryStore.scala:127); at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$getCurrentBlockStatus(BlockManager.scala:387); at org.apache.spark.storage.BlockManager$$anonfun$reportAllBlocks$3.apply(BlockManager.scala:218); at org.apache.spark.storage.BlockManager$$anonfun$reportAllBlocks$3.apply(BlockManager.scala:217); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at org.apache.spark.storage.BlockManager.reportAllBlocks(BlockManager.scala:217); at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:236); at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:522); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515:76,pipeline,pipeline,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515,1,['pipeline'],['pipeline']
Deployability,"Hello, sorry you're having this problem. I'm not sure exactly what's going on here. It sounds like it's a corrupted .gz file. You said these were created by HaplotypeCaller and then CombineGvcfs? I have a few questions and suggestions. 1. Were there any other steps in the pipeline that touch the vcfs?; 2. Are you sure the combine stage completed without error? This could potentially be caused by a failure in the step beforehand that silently truncates a file.; 2. Did you run all steps of the pipeline with --use-jdk-deflater & --use-jdk-inflate or just the final one that crashes?; 3. Can you try running PrintBGZFBlockInformation on the file and see what the output of that says?; 4. Is it reproducible on a small file you could share with us?; 5. It might be worth trying with the newest version of GATK because we upgraded to a new version of the intel deflater in 4.2.1.0 which fixed a lot of issues possibly including this one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7614#issuecomment-1004305052:273,pipeline,pipeline,273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7614#issuecomment-1004305052,3,"['pipeline', 'upgrade']","['pipeline', 'upgraded']"
Deployability,"Hello, thanks for great software.; After GATK 4.1.8.0 release we updated our internal Docker containers (from GATK v4.1.7.0) and noticed changes in Haplotype Caller results:. [check_against_37.woRandomLine.vcf.txt](https://github.com/broadinstitute/gatk/files/4864731/check_against_37.woRandomLine.vcf.txt); [test_v37.haplotypecaller.woRandomLine.vcf.txt](https://github.com/broadinstitute/gatk/files/4864733/test_v37.haplotypecaller.woRandomLine.vcf.txt). Here is the difference:; ```; 17	7571487	rs17880560	A	AGCCGTG	166.10	.	AC=2;AF=1.00;AN=2;DB;DP=4;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=28.73;SOR=0.693	GT:AD:DP:GQ:PL	1/1:0,4:4:12:180,12,0; 17	7571487	rs17880560;rs79948390	A	AGCCGTG	166.10	.	AC=2;AF=1.00;AN=2;DB;DP=4;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=28.73;SOR=0.693	GT:AD:DP:GQ:PL	1/1:0,4:4:12:180,12,0; ```; ```; 17	7578711	rs141204613	CTTT	C	232.93	.	AC=2;AF=1.00;AN=2;DB;DP=13;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.83;QD=30.97;SOR=1.329	GT:AD:DP:GQ:PL	1/1:0,6:6:18:247,18,0; 17	7578711	rs141204613;rs5819162	CTTT	C	232.93	.	AC=2;AF=1.00;AN=2;DB;DP=13;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.83;QD=30.97;SOR=1.329	GT:AD:DP:GQ:PL	1/1:0,6:6:18:247,18,0; ```; ```; 17	7579643	rs150200764	CCCCCAGCCCTCCAGGT	C	1834.03	.	AC=2;AF=1.00;AN=2;DB;DP=52;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=61.03;QD=27.24;SOR=0.843	GT:AD:DP:GQ:PL	1/1:0,41:41:99:1848,125,0; 17	7579643	rs150200764;rs146534833;rs59758982	CCCCCAGCCCTCCAGGT	C	1834.03	.	AC=2;AF=1.00;AN=2;DB;DP=52;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=61.03;QD=27.24;SOR=0.843	GT:AD:DP:GQ:PL	1/1:0,41:41:99:1848,125,0; ```; New file (test_v37) contains multiple `rsID` in `ID` field. Is that expected behavior or not? ; I can't find any info about in in changelog.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6690:54,release,release,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6690,2,"['release', 'update']","['release', 'updated']"
Deployability,"Hello,. Do you have an estimate on when you might be releasing the next minor GATK release? I'm hoping to pick up the GenomicsDB update (https://github.com/broadinstitute/gatk/commit/8796404cab594b716d43755f61fd405c92208141). I realize we could build our own, but for one of our projects we release a public dataset with documentation on the tools, and it's nicer to use official releases. Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7322:83,release,release,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7322,4,"['release', 'update']","['release', 'releases', 'update']"
Deployability,"Hello,. I am trying to set up a python environment to use gatk DetermineGermlineContigPloidy module. I cannot use conda. I have tried to install in a virtual python environment the dependencies found in these two files:. gatk/scripts/gatkcondaenv.yml.template ; gatk/src/main/python/org/broadinstitute/hellbender/setup_gcnvkernel.py. I have installed gcnvkernel in my virtual environment. . ----. This is the error message I get when I try to import gcnvkernel: python -c ""import gcnvkernel"". Traceback (most recent call last):; File ""/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.6.10/lib/python3.6/configparser.py"", line 1138, in _unify_values; sectiondict = self._sections[section]; KeyError: 'blas'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/configparser.py"", line 168, in fetch_val_for_key; return theano_cfg.get(section, option); File ""/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.6.10/lib/python3.6/configparser.py"", line 781, in get; d = self._unify_values(section, vars); File ""/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.6.10/lib/python3.6/configparser.py"", line 1141, in _unify_values; raise NoSectionError(section); configparser.NoSectionError: No section: 'blas'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/configparser.py"", line 328, in __get__; delete_key=delete_key); File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/configparser.py"", line 172, in fetch_val_for_key; raise KeyError(key); KeyError: 'blas.ldflags'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File """,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8387:137,install,install,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8387,2,['install'],"['install', 'installed']"
Deployability,"Hello,. I am trying to use gatk/4.1.4.1 and picard/2.22.0 to do joint variant calling of PacBio HiFi reads and Illumina short-reads. ; My pipeline is basically the recommended one (without base recalibration) where after HaplotypeCaller, I use GenomicsDBImport and GenotypeGVCFs and end up with the vcf file. The HiFI reads have normal hifi phred scores up to 93 and the illumina are encoded with phred33 quality scores. The output of the joint variant calling is strange and it causes issues when I try to use it with tools like plink and it makes me wonder if the joint variant calling went badly as well. This is even after variant filtration where I filter for QUAL<30 and QD<2. Here is an example of what the first few lines of my vcf calls look like. Notice the QUAL column that looks like Num,Num:. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Illumina_sample0 sample1 sample2 sample_3 sample4 sample5 sample6 hifi_sample; Chr1 10608 . GCA G 174,34 PASS AC=2;AF=0.143;AN=14;BaseQRankSum=0.00;DP=55;ExcessHet=3.3579;FS=7.404;MLEAC=2;MLEAF=0.143;MQ=57.97;MQRankSum=0.00;QD=15.85;ReadPosRankSum=1.00;SOR=3.611 GT:AD:DP:GQ:PL ./.:0,0:0:.:0,0,0 0/1:3,3:6:99:117,0,117 0/0:5,0:5:15:0,15,141 0/1:3,2:5:71:71,0,120 0/0:3,0:3:9:0,9,113 0/0:7,0:7:21:0,21,190 0/0:5,0:5:15:0,15,175 0/0:20,0:20:60:0,60,900; Chr1 10616 . G A 903,42 PASS AC=8;AF=0.571;AN=14;BaseQRankSum=0.00;DP=66;ExcessHet=0.7136;FS=9.277;MLEAC=9;MLEAF=0.643;MQ=59.80;MQRankSum=0.00;QD=20.08;ReadPosRankSum=1.00;SOR=0.251 GT:AD:DP:GQ:PL ./.:0,0:0:.:0,0,0 0/0:10,0:10:30:0,30,367 1/1:0,5:5:15:141,15,0 0/1:2,3:5:75:110,0,75 0/0:3,0:3:9:0,9,113 1/1:0,8:8:24:232,24,0 1/1:0,7:7:21:224,21,0 0/1:14,6:20:99:210,0,570. ```. I believe this can be reproduced with any illumina+hifi samples. Are you aware of this problem? Could the snp calling be wrong because of the different phred score encoding? What do you suggest to do in these cases?. I have read your response in this issue: ; https://gatk.broadinstitute.org/hc/en-us/community/pos",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8372:138,pipeline,pipeline,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8372,1,['pipeline'],['pipeline']
Deployability,"Hello,. I'm trying to use the CNVGermline Pipeline with Nextflow and a GATK Singularity image pulled from your Docker image. . As you can see, I'm trying to run the DetermineGermlineContigPloidy with 57 samples, and I got a permission error within my Singularity container. This error is directly related to Singularity permissions to create a directory ('/root/.theano/compiledir_Linux-4.10--generic-x86_64-with-debian-stretch-sid-x86_64-3.6.2-64'), because it's running fine with Singularity when I'm root and Docker (without root). So it's not really a GATK4 problem but more a singularity-GATK4 related problem. Maybe your GATK4 Germline CNV calling pipeline is not designed to work as a Singularity container (which is quite understandable), because for tools like HaplotypeCaller, MarkDuplicates ... It's working fine. I didn't know where to post this error, singularity or GATK github, so why not both ! . Do you have any idea make it run properly ? Change a bit the design of your CNV pipeline to make it compatible with Singularity ?. ## Version of softwares:. Singularity : 2.5.1, GATK : 4.0.4.0. ### Command. Singularity : ; singularity build gatk-4.0.4.0.img docker://broadinstitute/gatk:4.0.4.0. GATK4 : ; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/build/libs/gatk-package-4.0.4.0-local.jar DetermineGermlineContigPloidy --input 2044098202-8046_S5_sample.counts.hdf5 --input 2045946179-9076_S2_sample.counts.hdf5 --input 2045946166-9075_S1_sample.counts.hdf5 --input 2048220927-11022_S4_sample.counts.hdf5 --input 2045599261-9046ci_S1_sample.counts.hdf5 --input 2046745668-1007_S5_sample.counts.hdf5 --input 2044098101-8043_S2_sample.counts.hdf5 --input 2044098168-8044_S3_sample.counts.hdf5 --input 2046746598-1012_S4_sample.counts.hdf5 --input 2044395763-8064ci_S4_sample.counts.hdf5 --input 2044395647-8061ci_S1_sample.counts.hdf5 --input 70-20-CI_S3_sample",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782:42,Pipeline,Pipeline,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782,3,"['Pipeline', 'pipeline']","['Pipeline', 'pipeline']"
Deployability,"Hello,. I'm using the GATK4 docker image to evaluate the efficiency of my targeted experiment. After googling around, I realize that CollectHsMetrics is the tool to use from now on (correct me if i'm wrong). The old DepthOfCoverage, CalculateTargetCoverage, CalculateHsMetrics are not available anymore, so I'm trying to implement this utility in our pipeline. Given the fact I'm providing the same file as the BAITS_INTERVALS and TARGETS_INTERVALS, I'd expect the PCT_OFF_BAIT and PCT_EXC_OFF_TARGET to be the same, but then I [read here](https://gatkforums.broadinstitute.org/gatk/discussion/7442/collecthsmetrics) that the ON_BAIT_BASES and ON_TARGET_BASES may actually differ due to the fact one relies on the NEAR_DISTANCE argument (that only applies on the ON_BAIT_BASES) and other depends on some read filters (MINIMUM_BASE_QUALITY and MINIMUM_MAPPING_QUALITY that may apply to ON_TARGET_BASES, didn't find any documention on that). Indeed, I observed the described differences in the ON_BAIT_BASES/ON_TARGET_BASES metrics:. > ON_BAIT_BASES 1733719583; ON_TARGET_BASES 1274990601. which was reflected in the PCT_SELECTED_BASES (Fraction of bases from reads passing the filters located on or near a baited region):; > PCT_SELECTED_BASES 0.690911. Then, for the PCT_EXC_OFF_TARGET (Fraction of aligned bases that were filtered out because they did not align over a target base.) I got:; >PCT_EXC_OFF_TARGET 0.731878. which doesn't make sense to be so high. Shouldn't this value be close to the result of (`1-PCT_SELECTED_BASES`) , given that the BAITS and TARGETS intervals file is the same ?. Sending this example attached.; [H2106.1_HS_metrics.txt](https://github.com/broadinstitute/gatk/files/1643326/H2106.1_HS_metrics.txt). Best,; Pedro Barbosa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4200:351,pipeline,pipeline,351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4200,1,['pipeline'],['pipeline']
Deployability,"Hello,. I'm using the latest docker image to test GATK4 pipeline (v 4.0.1.2) and I'm struggling to get it done. Apparently it has to do with the task manager service, please find attached the full log of one of my runs.; [65670_gatk_hc.log](https://github.com/broadinstitute/gatk/files/1717363/65670_gatk_hc.log). Best,; Pedro",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4393:56,pipeline,pipeline,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4393,1,['pipeline'],['pipeline']
Deployability,"Hello,. It seems the parameter `--sequence-dictionary` does not change the dictionary looked by **HaplotypeCaller**. ```; averdier@bioinfo:~/test/dna-seq-pipeline$ ./dna-seq-pipeline.pl -1 CACTTCGA-ACACGACC_S156_L003_R1_001.fastq.gz -2 CACTTCGA-ACACGACC_S156_L003_R2_001.fastq.gz -r Triticum_aestivum_Claire_EIv1.1.fa.gz -s ClaireTest --nb_threads 30; --mem_limit 100; Mapping; Mark Duplicates; Variants Calling; 09:54:54.531 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/gatk/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Sep 11, 2020 9:54:54 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:54:54.730 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.731 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.7.0; 09:54:54.731 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:54:54.731 INFO HaplotypeCaller - Executing as averdier@bioinfo on Linux v4.4.0-178-generic amd64; 09:54:54.731 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-8u265-b01-0ubuntu2~18.04-b01; 09:54:54.731 INFO HaplotypeCaller - Start Date/Time: September 11, 2020 9:54:54 AM CEST; 09:54:54.731 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.731 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Version: 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6808:154,pipeline,pipeline,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808,2,['pipeline'],['pipeline']
Deployability,"Hello,. There was at least one prior conversation about migrating or not migrating GATK3 CombineVariants to GATK4. My understanding is that there was a decision in GATK not to migrate CombineVariants, and instead push people to use Picard MergeVcfs. As you know, Picard MergeVcfs is somewhat similar; however, it doesnt merge genotypes. That is a pretty big difference in function. . CombineVariants is one of the few GATK3 tools my lab is still using. I'd like to move us off GATK3 in the coming months. Given GATK has already decided not to migrate it, I would first like to propose that we could port and take it over in my lab's DISCVRseq project (https://github.com/bimberlab/discvrseq). I'm happy to give attribution to GATK, etc. I would likely rename it MergeVcfsAndGenotypes (this is more intuitive to me), but I would otherwise not change functionality much. I'd prefer to do this instead of porting to GATK4 because porting to GATK is going to throw up a lot more obstacles and probably require that I modernize/update a good amount of that tool's code. I appreciate why this is required, but it takes a lot more work from us. If you did not like this, I'm open to considering porting to GATK4. In my initial review, it looked like CombineVariants was fairly self-contained and that most of the accessory code (merging genotypes is the most complex thing) was already migrated to GATK4. Some of you may have already done a more thorough review of it. . What do you think?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7038:1023,update,update,1023,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7038,1,['update'],['update']
Deployability,"Hello,. To our thinking, one of the compelling reasons to use GenomicsDB over Combined gVCFs is that ability to incrementally append samples, and this is supported through --genomicsdb-update-workspace-path. However, you docs state: ""It is recommended that users backup existing genomicsdb workspaces before adding new samples using --genomicsdb-update-workspace-path. If the tool fails during incremental import for any reason, the workspace may be in an inconsistent/corrupted state"". These files are not small. Given that recommendation, wouldnt it make just as much sense to let the user specify the workspace-to-update, the input gVCFs, and specify an alternate output path where the merged data is written? To us, the key feature is incremental sample append, not update-in-place. Is the user wanted to update the original copy, after successful completion of GenomicsDB they could certainly delete the original and move the new copy into that location? Not to mention, in theory one could have some job trying to read the original workspace, which might get hosed if some other job is trying to edit that workspace in place. Thanks for any thoughts or comments. -Ben",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6558:185,update,update-workspace-path,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6558,5,['update'],"['update', 'update-in-place', 'update-workspace-path']"
Deployability,"Hello,. when running the cnn I have this error : ; File ""<stdin>"", line 1, in <module>; AttributeError: 'module' object has no attribute 'get_metric_dict'. As I know you are working on another version, I am not totally sure if it is appropriate to report this issue for the current version. You can ignore it I can wait for the other version release. . Thanks a lot",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4591:342,release,release,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4591,1,['release'],['release']
Deployability,"Hello,; Any update to the timeline here? It looks like there is only some lasts tests to be run? I am eagerly awaiting multi-interval support for a project I am working on. Thank you for all of your hard work!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3269#issuecomment-398891375:12,update,update,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3269#issuecomment-398891375,1,['update'],['update']
Deployability,"Hello,; I am missing the SparkGenomeReadCounts tool in the new release which was included in the beta. Will it be included again soon? What was the reason for removing it? Is there an alternative tool in the new release?. Best; ST",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4185:63,release,release,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4185,2,['release'],['release']
Deployability,"Hello,; I have the same issue reported on the GATK forum last week ; https://gatkforums.broadinstitute.org/gatk/discussion/13171/variant-not-being-called-by-hc-gatk-v3-7-0-gcfedb67. Though the above issue is with GATK 3.7, I have also run the same pipeline with GATK4 and the variant is still not called. is there a solution for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-427743185:248,pipeline,pipeline,248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-427743185,1,['pipeline'],['pipeline']
Deployability,"Hello,; Nothing urgent, but do you have any update about this issue ?; Best regards,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7032#issuecomment-781364322:44,update,update,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032#issuecomment-781364322,1,['update'],['update']
Deployability,"Hello.; I am not sure if this is a bug or simply a tool version problem but when running the tests with `./gradlew test` I get 18 failures with the `org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest` class. I wanted to make sure GATK was working right when compiled it from source to have a working base a I intend to try out some experimental modifications to the code. ## Bug Report. ### Affected tool(s) or class(es); `org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest`. ### Affected version(s); - [ ] Latest public release version [version?]; - [x] Latest master branch as of [11.12.18]. ### Description; The following commands were used to build and test GATK; ```; git pull; ./gradlew clean; ./gradlew bundle; ./gradlew test; ```; The tests resulted in 18 failed as can be seen in the attached file. ; [Test results - Class org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest.html.zip](https://github.com/broadinstitute/gatk/files/2667609/Test.results.-.Class.org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest.html.zip). If this is normal (expected) when building from the last commit on master you can close this issue. For experimental development should I use the most recent release or can I work from the most recent commit on master ?. #### Steps to reproduce; see commands above description. The problem could be from a library or java version maybe. I run a Ubuntu 16.04 LTS desktop.; ```; uname -a; Linux A13PC04 4.4.0-140-generic #166-Ubuntu SMP Wed Nov 14 20:09:47 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux. javac -version; javac 1.8.0_102. java -version; java version ""1.8.0_102""; Java(TM) SE Runtime Environment (build 1.8.0_102-b14); Java HotSpot(TM) 64-Bit Server VM (build 25.102-b14, mixed mode); ```. #### Expected behavior; I was expecting the tests to pass. #### Actual behavior; 18 tests failed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5511:599,release,release,599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511,2,['release'],['release']
Deployability,Here are the changes needed to get the full pipeline running on WGS BAMs. This contains commits from other PRs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3106:44,pipeline,pipeline,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3106,1,['pipeline'],['pipeline']
Deployability,Here are the current Oncotator related docs:. - https://gatkforums.broadinstitute.org/gatk/discussion/comment/43617#Comment_43617; - https://gatkforums.broadinstitute.org/gatk/discussion/4154/howto-install-and-run-oncotator-for-the-first-time,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3774#issuecomment-341251810:198,install,install-and-run-oncotator-for-the-first-time,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3774#issuecomment-341251810,1,['install'],['install-and-run-oncotator-for-the-first-time']
Deployability,"Here are the documents we should also update to reflect these updates:; - https://gatkforums.broadinstitute.org/gatk/discussion/1255/using-jexl-to-apply-hard-filters-or-select-variants-based-on-annotation-values; - https://software.broadinstitute.org/gatk/documentation/article?id=11080. Also, here is a list of documents with the `jexl` tag:; https://gatkforums.broadinstitute.org/gatk/discussions/tagged/jexl. I have put in a word of caution in https://gatkforums.broadinstitute.org/gatk/discussion/12350/how-to-filter-on-genotype-using-variantfiltration/p1?new=1.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5422#issuecomment-439972461:38,update,update,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5422#issuecomment-439972461,2,['update'],"['update', 'updates']"
Deployability,"Here how to reproduce the last issue. First of all, you have to download the mini input.bam file from this dropbox link: https://www.dropbox.com/sh/2xni9oh362ovc71/AAAIm7MZ1tLL6xuUUp7tk2g_a?dl=0. Then the following code will reproduce the issue:; ```; wget https://github.com/broadinstitute/picard/releases/download/2.19.0/picard.jar. wget https://github.com/broadinstitute/gatk/releases/download/4.0.12.0/gatk-4.0.12.0.zip; unzip gatk-4.0.12.0.zip. wget -O- ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | \; gzip -d > GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. java -jar picard.jar \; CreateSequenceDictionary \; R=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict. (echo ""##fileformat=VCFv4.2""; \; echo ""##contig=<ID=chr12,length=133275309>""; \; echo -e ""#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO""; \; echo -e ""chr12\t60339493\t.\tA\tG\t.\t.\t.""; \; echo -e ""chr12\t60339499\t.\tA\tG\t.\t.\t.""; \; echo -e ""chr12\t60339510\t.\tC\tT\t.\t.\t."") | bgzip > input.vcf.gz && \; tabix -f input.vcf.gz. for score in 17 18; do; gatk-4.0.12.0/gatk Mutect2 \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; --tumor SM \; -O output.$score.vcf.gz \; --genotyping-mode GENOTYPE_GIVEN_ALLELES \; --alleles input.vcf.gz \; -L chr12:60339493-60339510 \; --min-base-quality-score $score \; --bam-output output.$score.bam && \; bcftools query \; -f ""[%CHROM\t%POS\t%REF\t%ALT\t%GT\t%AD\n]"" \; output.$score.vcf.gz \; -r chr12:60339493-60339510; done; ```. With the two outputs being:; ```; chr12	60339493	A	G	0/1	0,9; chr12	60339499	A	G	0/1	0,8; chr12	60339510	C	T	0/1	0,10; ```; and:; ```; chr12	60339493	A	G	0/1	6,0; chr12	60339499	A	G	0/1	2,5; chr12	60339510	C	T	0/1	0,9; ```. And these are the two BAMs with the reconstructed haplotypes I obt",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6045#issuecomment-527601079:298,release,releases,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6045#issuecomment-527601079,2,['release'],['releases']
Deployability,"Here is a recap of what we discussed today during the CNV meeting:. For the first round of evaluations we decided to run Germline CNV pipeline on TCGA exomes using a range of key hyperparameters (namely psi-t-scale and p-alt) and establish the base level performance metrics using output of GenomeSTRiP on matched WGS samples as ground truth. . @mbabadi could you come up with a good range of hyperparameter values that you think should be cross-validated?. In particular we need to:. - Dockerize tools we will be evaluating against (XHMM, CODEX2, CLAMMS, GenomeSTRiP); - Write a WDL that runs Germline CNV that scatters across range of key hyperparameters and outputs array of VCFs; - Write VCF processors for output of CLAMMS and CODEX2 ; - Write WDLs for running XHMM, CODEX2, CLAMMS and GenomeSTRiP that output VCFs; - Write WDL that takes results of the above and uses @mbabadi 's gCNV evaluation python modules(located here /dsde/working/mehrtash/gCNV_theano_eval) to output performance metrics; - Decide on an automatic evaluation framework. For the next round of evaluations we need to:. - Decide on appropriate metrics for evaluating performance on trios and write scripts that implement them; - Expand the range of hyperparameters in search space (possibly include different bin sizes, GC vs no GC correction, and fragment mid point coverage collection vs largest fragment overlap coverage collection); - Use gnomAD subset of matched WES/WGS pairs for validation",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-362075071:134,pipeline,pipeline,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-362075071,1,['pipeline'],['pipeline']
Deployability,"Here is a script I ran to run the import on 3500 unblocked gvcfs. The script imports one chromosome per workspace.  As the chromosomes get larger --more and more memory is needed.  chr4 through 22 ran fine. The chr3 (see log below) ends without an error BUT with the callset.json NOT being written out.   I could split the chr1-3 at the centromere to try it again. Any other suggestions? Would increasing -Xmx150g to 240g help? . For chromosome 1, which is still running, top indicates is using about  240g (after importing the 65 batches).; ```; PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM  TIME+ COMMAND; 21698 farrell   20   0      443.7g 240.3g   1416 S  86.7 95.5   7398:14 java; ```. ```; #!/bin/bash -l; #$ -l mem_total=251; #$ -P casa; #$ -pe omp 32; #$ -l h_rt=240:00:00; module load miniconda/4.9.2; module load gatk/[4.2.6.1](http://4.2.6.1/); conda activate /share/pkg.7/gatk/[4.2.6.1/install/gatk-4.2.6.1](http://4.2.6.1/install/gatk-4.2.6.1). CHR=$1; DB=""genomicsDB.rb.chr$CHR""; rm -rf $DB; # mkdir -p $DB; # mkdir tmp; echo ""Processing chr$CHR""; echo ""NSLOTS: $NSLOTS""; # head sample_map.chr$CHR.reblock.list; head sample_map.chr$CHR; wc   sample_map.chr$CHR; gatk --java-options ""-Xmx150g -Xms16g"" \;        GenomicsDBImport \;        --sample-name-map sample_map.chr$CHR \;        --genomicsdb-workspace-path $DB \;        --genomicsdb-shared-posixfs-optimizations True\;        --tmp-dir tmp \;        --L chr$CHR\;        --batch-size 50 \;        --bypass-feature-reader\;        --reader-threads 5\;        --merge-input-intervals \;        --overwrite-existing-genomicsdb-workspace\;        --consolidate. ```; End of log on chr3. ```; 07:19:44.855 INFO  GenomicsDBImport - Done importing batch 38/65; 08:05:11.651 INFO  GenomicsDBImport - Done importing batch 39/65; 08:49:12.112 INFO  GenomicsDBImport - Done importing batch 40/65; 09:32:39.526 INFO  GenomicsDBImport - Done importing batch 41/65; 10:23:36.849 INFO  GenomicsDBImport - Done importing batch 42/65; 1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1246785232:909,install,install,909,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1246785232,2,['install'],['install']
Deployability,"Here is an issue ticket for adding the diagnosetarget feature to DepthofCoverage. This request was created from a contribution made by Benoit Dewitte on February 09, 2022 13:15 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4418326549531-Whats-the-equivalent-of-gatk3-depthofcoverage-and-diagnosetarget-](https://gatk.broadinstitute.org/hc/en-us/community/posts/4418326549531-Whats-the-equivalent-of-gatk3-depthofcoverage-and-diagnosetarget-). \--. Hi! ; ; I'm currentlly refactoring ours pipeline which use depthofcoverage and diagnosetarget from GATK 3.8. Despite  google researchs I can not found the equivalent of diagnosetarget for gatk 4 and the depthofcoverage tool that i found is still in beta. I found this [github post](https://github.com/broadinstitute/gatk/pull/5913) which talk about pushing the diagnosetarget feature in depthofcoverage but I was not able to find any more informations. Should I stay on the gatk 3.8 version or upgrade our pipe to gatk 4?. I appreciate very much if someone could enlighten me.<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/270769'>Zendesk ticket #270769</a>)<br> gz#270769</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7702:511,pipeline,pipeline,511,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7702,2,"['pipeline', 'upgrade']","['pipeline', 'upgrade']"
Deployability,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/347:803,integrat,integration,803,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347,1,['integrat'],['integration']
Deployability,"Here the log:. 11:08:24.240 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/results/SOD1/.snakemake/conda/93139e1d/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Aug 19, 2020 11:08:25 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:08:25.663 INFO SplitNCigarReads - ------------------------------------------------------------ ; ; 11:08:25.663 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.1.8.1 ; ; 11:08:25.663 INFO SplitNCigarReads - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 11:08:25.664 INFO SplitNCigarReads - Executing as giulia@### on Linux v2.6.32-754.31.1.el6.x86\_64 amd64 ; ; 11:08:25.664 INFO SplitNCigarReads - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_152-release-1056-b12 ; ; 11:08:25.664 INFO SplitNCigarReads - Start Date/Time: August 19, 2020 11:08:24 AM CEST ; ; 11:08:25.664 INFO SplitNCigarReads - ------------------------------------------------------------ ; ; 11:08:25.664 INFO SplitNCigarReads - ------------------------------------------------------------ ; ; 11:08:25.668 INFO SplitNCigarReads - HTSJDK Version: 2.23.0 ; ; 11:08:25.668 INFO SplitNCigarReads - Picard Version: 2.22.8 ; ; 11:08:25.668 INFO SplitNCigarReads - HTSJDK Defaults.COMPRESSION\_LEVEL : 2 ; ; 11:08:25.668 INFO SplitNCigarReads - HTSJDK Defaults.USE\_ASYNC\_IO\_READ\_FOR\_SAMTOOLS : false ; ; 11:08:25.668 INFO SplitNCigarReads - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true ; ; 11:08:25.668 INFO SplitNCigarReads - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false ; ; 11:08:25.668 INFO SplitNCigarReads - Deflater: IntelDeflater ; ; 11:08:25.669 INFO SplitNCigarReads - Inflater: IntelInflater ; ; 11:08:25.669 INFO SplitNCigarReads - GCS max retries/re",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6776:2172,release,release-,2172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776,1,['release'],['release-']
Deployability,"Here's an example run on a quickstart: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/4b83a498-5bd8-4f42-b312-1d0efcf55cfc - The ancestry file really should be installed in the quickstart storage if it is not there already, and the sites-only-vcf I generated using the hail code (a while ago).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8170#issuecomment-1402751037:198,install,installed,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8170#issuecomment-1402751037,1,['install'],['installed']
Deployability,Here's another one with our exact problem (solved largely by putting the config onto HDFS). http://progexc.blogspot.com/2014/12/spark-configuration-mess-solved.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322554798:134,configurat,configuration-mess-solved,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322554798,1,['configurat'],['configuration-mess-solved']
Deployability,"Hey @bhanugandham @rcmajovski, what is the status of this documentation update? It would be great to be able to point users to this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5383#issuecomment-459134349:72,update,update,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5383#issuecomment-459134349,1,['update'],['update']
Deployability,"Hey @mbabadi, I've answered this user question but I think my answer needs your review. Also, DR mentioned perhaps this option could be set automatically for users? Thanks. ---; Thanks @shlee for the update,; I used the latest jar from the gatk4 repo as recommended. And managed to derive the read count input file and sex genotype table. I just wanted to confirm whether Nd4j also needed to be installed if not using Spark. #script run; ./gatk-launch GermlineCNVCaller --contigAnnotationsTable ../gatk4_Hellbender/grch37_contig_annotations.tsv --copyNumberTransitionPriorTable ../gatk4_Hellbender/grch37_germline_CN_priors.tsv --jobType LEARN_AND_CALL --outputPath ./TS1 --input ../gatk4_Hellbender/target_cov.tsv --targets ../gatk4_Hellbender/targets.txt --disableSpark true --sexGenotypeTable ../gatk4_Hellbender/TS1_genotype --rddCheckpointing false --biasCovariateSolverType LOCAL. #I am getting the following error which seems to be linked with Nd4j:. Using GATK jar ~/localwork/playground/programs/gatk-protected/build/libs/gatk-protected-package-b4390fb-SNAPSHOT-local.jar; 102-b14; Version: 4.alpha.2-1136-gc18e780-SNAPSHOT; 16:55:21.931 INFO GermlineCNVCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:55:21.932 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:55:21.932 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:55:21.932 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:21.932 INFO GermlineCNVCaller - Deflater: IntelDeflater; 16:55:21.932 INFO GermlineCNVCaller - Inflater: IntelInflater; 16:55:21.932 INFO GermlineCNVCaller - Initializing engine; 16:55:21.932 INFO GermlineCNVCaller - Done initializing engine; 16:55:21.933 INFO GermlineCNVCaller - Spark disabled. sparkMaster option (local[*]) ignored.; 16:55:23.448 INFO GermlineCNVCaller - Parsing the read counts table...; 16:55:24.876 INFO GermlineCNVCaller - Parsing the sample sex genotypes table...; 16:55:24.896",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3098:200,update,update,200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3098,2,"['install', 'update']","['installed', 'update']"
Deployability,"Hey @nalinigans - disabling consolidation made GenotypeGVCFs run for too long, so I didn't wait for the completion and cancelled it. My solution was to go the way it's done in the WARP pipeline: bundle the db workspace into a tarball, then extract it locally on the instance that runs GenotypeGVCFs. This approach might also be cheer as it could save on cloud logging spent on small regional requests (I had the same issue with passing VCFs and BAMs as gs:// URLs directly to GATK. Turns out, localising the entire files makes the overall cost cheeper).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7653#issuecomment-1033741157:185,pipeline,pipeline,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7653#issuecomment-1033741157,1,['pipeline'],['pipeline']
Deployability,"Hey David. This will be a tool again in the next release? Users have been asking about generating VCF index, and I have pointed them to IGV or tabix or samtools. I think this has been disabled in the latest point release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4349#issuecomment-364556039:49,release,release,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4349#issuecomment-364556039,2,['release'],['release']
Deployability,"Hey all, any chance of a bugfix release with this fix in it?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6197#issuecomment-547508681:32,release,release,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6197#issuecomment-547508681,1,['release'],['release']
Deployability,Hey developers working on GATK4 doc updates (tagging tech leads here) @cwhelan @samuelklee @ldgauthier @vruano @yfarjoun @LeeTL1220. Just a reminder (from @vdauwera and @droazen) that we want to get rid of many of the short form arguments and only keep the long form for the more obscure arguments. Meaning we keep both forms for commonly used and understood arguments.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-352315064:36,update,updates,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-352315064,1,['update'],['updates']
Deployability,"Hey folks,. I have a test dataset that interestingly core-dumps or JVM errors with `--smith-waterman FASTEST_AVAILABLE` but not with `--smith-waterman JAVA`. The only thing I can think of is somehow Intel's HMM has a length limitation, as I am using `--assembly-region-padding 1000` to GATK to call 100-1000bp indels (and it works!). I cannot share the test BAM unfortunately. What can I do to help debug further?. I'm using `gatk4-4.1.8.1-0` from `conda create -n debug-gatk4 -c defaults -c conda-forge -c bioconda gatk4`. ```; $gatk ... -version; The Genome Analysis Toolkit (GATK) v4.1.8.1; HTSJDK Version: 2.23.0; Picard Version: 2.22.8; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. First error motif:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010efa9dc2, pid=23946, tid=0x000000000000a503; #; # JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); # Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x3a9dc2] PhaseIdealLoop::set_ctrl(Node*, Node*)+0x10; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; #; # Compiler replay data is saved as:; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; ```. Second error motif:; ```; java(24057,0x7000035bd000) malloc: Incorrect checksum for freed object 0x7fd8a8193600: probably modified after being freed.; Corrupt value: 0x2e4630002e47e; java(24057,0x7000035bd000) malloc: *** set a breakpoint in malloc_error_break to debug; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6733:686,release,release,686,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733,3,['release'],"['release', 'release-']"
Deployability,"Hey there, . is there any news on this? I would also like to update gencode db for funcotator. Thanks; Best; Zhan",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7385#issuecomment-1532710650:61,update,update,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7385#issuecomment-1532710650,1,['update'],['update']
Deployability,"Hey, . in the light of recent papers describing mtDNA as a great natural barcode to do lineage tracing in single human cells from scATAC-seq data, I think this is of relevance and I'd be very interested if there is an update on the pipeline as well. . Thanks!!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-488785797:218,update,update,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-488785797,2,"['pipeline', 'update']","['pipeline', 'update']"
Deployability,"Hey, just wondering if there has been any updates for my problem.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-551335338:42,update,updates,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-551335338,1,['update'],['updates']
Deployability,"Hi - @kaixinxiaonvwa-hub . I have a couple of questions:. - Can you post your full stack trace with the errors?; - Did you attempt to enable `gnomAD` data sources or is it doing this without any changes to the data sources directory? Did you do any other configuration steps after downloading the datasources and before running funcotator?. If you enable `gnomAD`, the datasources are hosted on google cloud. If you don't have an internet connection or google cloud is blocked, Funcotator will not be able to connect to read the gnomAD data and will show the error in your `1` case above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1494703773:255,configurat,configuration,255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1494703773,1,['configurat'],['configuration']
Deployability,Hi - as the originator of this request I am wondering if there is any update that has potentially fixed the function of `FastaAlternateReferenceMaker` when working with the spanning deletions?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7341#issuecomment-1595011811:70,update,update,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7341#issuecomment-1595011811,1,['update'],['update']
Deployability,"Hi - what is the code that fixes this issue? One user tried the latest version of GATK and found the bug is still in there, but the previous issue was closed. What is the patch?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5945#issuecomment-493074930:171,patch,patch,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5945#issuecomment-493074930,1,['patch'],['patch']
Deployability,Hi ; We have a forum post asking help for getting GATK 4.1.0.0 conda environment installed using the yml file. ; [https://gatk.broadinstitute.org/hc/en-us/community/posts/18332470602523-Install-GATK-version-4-1-0-0-using-Conda-](url). Looks like restructuring of the default repository under conda took out some of these packages and they are no longer directly accessible. They can be accessed from the forge repo with certain flags. This issue seems to deprecate some of the older but still usable versions of GATK (due to various reasons). Directing people to use the docker version or upgrading to the latest GATK version seems to be the only solution left for now. Any other ideas of how we should pursue this issue? @lbergelson @droazen ?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8504:81,install,installed,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8504,2,"['Install', 'install']","['Install-GATK-version-', 'installed']"
Deployability,"Hi @LiviaMoura ,. The dropped allele is expected behavior. One of the ways reblocking speeds up joint genotyping is by dropping information associated with alleles that are not in the most likely genotype. The subsequent alleles are not left aligned because the position doesn't change. Instead they are trimmed so that they use the minimal representation. Historically the FORMAT DP doesn't change when alleles are dropped (as in subsetting more than 5 alternate alleles in the previous pipeline). Given that this is a GVCF with a <NON_REF> allele, the most correct thing to do would be to move that 1 read associated with the dropped allele to the <NON_REF> AD so that the sum of the AD values are still equal to the FORMAT DP, but the NON-REF AD values will get dropped in the joint genotyping step anyway, so the change would only be reflected in the intermediate GVCF files. The DRAGEN data I had been working with didn't have allele fraction, but we also came across this issue independently. I made a fix and we're testing it now. If it looks good, I'll generalize it to use the header information rather than special casing particular annotations. I can put in some code to subset the posteriors as well. Hopefully I can merge a PR with the fix before the holiday break.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7589#issuecomment-990208958:488,pipeline,pipeline,488,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7589#issuecomment-990208958,1,['pipeline'],['pipeline']
Deployability,"Hi @LiviaMoura . We don't have any haploid calling in the Broad production pipeline, so we never included that feature in Gnarly. (For chrY people typically filter out hets and then treat 0/0 as 0 and 1/1 as 1. chrX on males admittedly requires a little more finesse.) I can probably take a look next week. I'm not sure how much effort a fix would entail, but hopefully the haploid case is just a simpler version of the diploid case right? :-)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7690#issuecomment-1049206545:75,pipeline,pipeline,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7690#issuecomment-1049206545,2,['pipeline'],['pipeline']
Deployability,Hi @Nanderson246 ; This is a known issue that requires us to update the conda environment and its dependencies on our end which all rely on older versions of certain R and python tools. Direct intervention and changing this code breaks certain unit tests which result in failure to build our conda and docker environments. This is a works in progress for our newer conda and docker environment however for the time being you may manually edit your R scripts to solve it or use R from our conda or docker environments to generate images. I hope this helps. Regards.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8992#issuecomment-2391551502:61,update,update,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8992#issuecomment-2391551502,1,['update'],['update']
Deployability,Hi @RWilton i'm sorry to hear that. I suspect its unrelated given how simple this PR is but its quite possible that filter has been broken since evidently nobody was able to use and adjust it for a long time. This is the logic here that the filter uses:; `return read.isPaired() && !read.isUnmapped() && !read.mateIsUnmapped() &&; (Math.abs(read.getStart() - read.getMateStart()) >= mateTooDistantLength || !read.getContig().equals(read.getMateContig()));`. That logic is correct for what the filter is doing. It should be noted that the filter does the opposite of what you expect it to (since its intended for our SV pipeline) in that it filters out all reads that are NOT having distant mates. This means if you try to run HaplotypeCaller with this setting you will be throwing away every read pair EXCEPT the distant ones which results in mostly no reads. We should perhaps rename this filter to be a little less confusing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1103010098:619,pipeline,pipeline,619,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1103010098,2,['pipeline'],['pipeline']
Deployability,"Hi @SZLux,. GATK does not use hbase, so I'm not sure those JARs will help. Can you please try the following command:. CountReadsSpark --input test_sample.bam --output output.readcount.txt --verbosity DEBUG -- --spark-runner SPARK --spark-master spark://xx.xx.xx.xx:7077. Update: To launch a Spark tool on a remote machine, your command must end with the arguments:. -- --spark-runner SPARK --spark-master spark://xx.xx.xx.xx. This will attempt to initialize Spark in cluster mode. Currently there is no way to run a job in local mode on a remote machine using the gatk launcher. To do that, you could ssh into the remote machine and launch it locally i.e. with:. -- --spark-runner LOCAL --spark-master local[*]",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383973549:271,Update,Update,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383973549,1,['Update'],['Update']
Deployability,"Hi @Stikus, thank you yet again for another detailed report. These differences are certainly much more alarming! Luckily, I believe they have a benign explanation. See in the release notes the inclusion of https://github.com/broadinstitute/gatk/pull/8234, which changed the default gCNV parameters. Can you check whether your results differ when running 4.5.0.0 with the 4.4.0.0 parameters?. @droazen perhaps it might be worth highlighting this difference more prominently in the release notes? And I’ll perhaps let @mwalker174 or @asmirnov239 add some more context around the new defaults.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8628#issuecomment-1856321832:175,release,release,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8628#issuecomment-1856321832,2,['release'],['release']
Deployability,"Hi @Tintest,. If you need some guidance in interpreting the WDL pipeline script that @samuelklee linked, please let me know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053#issuecomment-407771160:64,pipeline,pipeline,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053#issuecomment-407771160,2,['pipeline'],['pipeline']
Deployability,"Hi @Tintest,. Thanks for checking out GermlineCNVCaller! That is indeed a large cohort. The theano computational graph that represents the probabilistic model will be quite large and may require more memory than you have to successfully compile. We typically select a training cohort (perhaps 100-200 samples) to train the denoising model; ideally, all of your samples are from the same batch, but if not, you may want to train separate cohorts for each batch. These trained models can then be used to call subsequent samples in case mode using the appropriate model for each batch. Another strategy we use is to scatter gCNV runs across the exome/genome. I'd recommend including at least 10,000 intervals in each scatter shard, but you may be able to get away with more. I'd recommend studying the WDL at https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/germline to see how we typically run the pipeline. @sooheelee is also working on a tutorial that will hopefully provide a useful hands-on example of running the workflow in this manner.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053#issuecomment-407736504:914,pipeline,pipeline,914,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053#issuecomment-407736504,1,['pipeline'],['pipeline']
Deployability,"Hi @Vzzarr ,. Thank you for reporting this. I've never heard of this happening before, but I suspect the difference is that you are using maven and we've only ever used gradle. @magicDGS @LeeTL1220 You both build downstream projects, have you ever seen this?. From what I can tell `com.github.fommil.netlib.all` is a POM only dependency, but it's not annotated as such in our generated POM. Gradle resolves it correctly, and then resolves it's transitive dependencies correctly, but maven seems to resolve it differently. . I've reproduced the issue locally, and it seems like it can be fixed by changing this line in our build file:. https://github.com/broadinstitute/gatk/blob/62e339fb9150db19f80d4b48aed8d47608461690/build.gradle#L220. to specify the exact dependencies we want instead of using the all artifact. I'll open a pull request with that. There's an additional catch though, you're using the latest release to maven central, which is actually a very old version. We haven't been able to release newer versions to central because they depend on a snapshot of a fork of a google library that isn't released to central. We publish these to our artifactory server which can be resolved like any other maven repository. Would you be able to work with an artifactory dependency? If you can you can A) use the newer and better gatk, B) I won't have to backport this change on top of beta.2 . We're going to fix the problem of not being in central eventually ( certainly before 4.0 release... ) but until then resolving from our artifactory is probably the best bet. If you can't / don't want to use the artifactory releases, let me know and I can release a patch version to maven that fixes this problem.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339056907:912,release,release,912,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339056907,7,"['patch', 'release']","['patch', 'release', 'released', 'releases']"
Deployability,Hi @Wangchangsh ; Yes there is an update for this issue. We were able to recreate this problem in our hands and looks like there is a memory management issue somewhere in the GenomicsDB related code inside GenotypeGVCFs. . Our temporary solution until we make an updated release would be to convert imported genomicsDB instances to GVCF using . `gatk SelectVariants -V gendb://instancename -O GVCF_export.g.vcf.gz -R ref.fa -L whateverintervalusedinGDBimport`. and later using this GVCF file as input for the GenotypeGVCFs tool. This ensures that memory usage won't go above unreasonable levels and won't cause any appearant leaks. . I hope this helps. Regards.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2430337332:34,update,update,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2430337332,3,"['release', 'update']","['release', 'update', 'updated']"
Deployability,"Hi @Yyx2626, I'm Geraldine, you may remember me from the Beijing training. It was great visiting your team! I'm sorry it took me so long to follow up on this discussion, and I want to thank you again for reaching out to us about integrating the tool that you developed into GATK. We are certainly very interested in providing this enhancement to the research community, and we are now ready to talk about the next steps. . After examining your paper and the source code in Github, we think that the most efficient way to integrate the functionality you developed would be to adapt the filtering parts of your tool to run on the output of Mutect2. So this would be a standalone tool that you would run after Mutect2, much like the current FilterMutectCalls tool. . If the results are comparable to your current tool, then we would take that into the official distribution of GATK. If somehow that integration does not yield satisfactory results, then we would look at integrating the entire tool, though we're hoping it won't be necessary, so we can avoid maintaining duplicate functionality for some of the boilerplate data transformations. . David @davidbenjamin can provide some advice on how to implement this in GATK4; in brief you would need to write some code that applies the filters you developed to a variant context. Let us know if this is an option you'd like to explore; we'd be happy to help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-403101973:229,integrat,integrating,229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-403101973,4,['integrat'],"['integrate', 'integrating', 'integration']"
Deployability,"Hi @aderzelle. Thanks for your interest in NeuralNetInference. The tool currently has pre-beta`Experimental` status, so for now it should be used for evaluation purposes only. We expect to release another version of GATK, probably within the next week, that will include an updated version of the tool that will include a default architecture file, along with some additional tools for things like training. The tools will still be `Experimental`, but should be a bit easier to use. In the meantime, there is a bit more information about how to access the existing hd5 file [here](https://github.com/broadinstitute/gatk/issues/4511). Note that in the next release, the name of the tool will have changed to CNNScoreVariants. @lucidtronix anything else to add here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4559#issuecomment-375647411:189,release,release,189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4559#issuecomment-375647411,3,"['release', 'update']","['release', 'updated']"
Deployability,"Hi @bbimber, our next release is imminent -- we're just waiting on 1-2 final PRs to be merged. I can safely say it will go out this week.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7322#issuecomment-865082820:22,release,release,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7322#issuecomment-865082820,1,['release'],['release']
Deployability,Hi @brisk022 . There is an update for this issue. We were able to recreate this problem in our hands and looks like there is a memory management issue somewhere in the GenomicsDB related code inside GenotypeGVCFs. . Our temporary solution until we make an updated release would be to convert imported genomicsDB instances to GVCF using . `gatk SelectVariants -V gendb://instancename -O GVCF_export.g.vcf.gz -R ref.fa -L whateverintervalusedinGDBimport`. and later using this GVCF file as input for the GenotypeGVCFs tool. This ensures that memory usage won't go above unreasonable levels and won't cause any appearant leaks. . I hope this helps. Regards.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8989#issuecomment-2430338663:27,update,update,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8989#issuecomment-2430338663,3,"['release', 'update']","['release', 'update', 'updated']"
Deployability,"Hi @cccnrc, glad you found this discussion interesting and apologies for the very late reply. Unfortunately, there hasn't been much movement on this front, as I think we decided that the current model sufficed. I think we are moving in a direction so that we can obviate the need for a separate step to fit global (e.g., depth) and per-contig (e.g., contig ploidy) parameters for each sample. Recall that this is only necessary because each gCNV genomic shard needs these quantities to perform inference, but cannot infer them from the data they are responsible for fitting (which typically covers less than a contig). We are looking to reimplement gCNV in a more modern inference framework that could allow us to do away with such sharding entirely. We could thus fit global/per-contig quantities of interest jointly with the rest of the gCNV model. The timeframe for this work may be relatively long (~year), but I think it'll be worth it. That said, I think a key takeaway from this work is that genotype priors can be more powerful for breaking degeneracies than contig-ploidy priors, so we will probably try to incorporate that insight in future work. To answer your questions:; 1) There are no additional results much further beyond what is shown above.; 2) You can see snippets/comparisons of the genotype and contig-ploidy prior file above. If you're just looking for information about the contig-ploidy prior table used in the current pipeline, see an example at https://gatk.broadinstitute.org/hc/en-us/articles/360051304711-DetermineGermlineContigPloidy and feel free to modify it to be more/less strict as desired.; 3) Unfortunately I believe the samples discussed above are not publicly available. If you are having difficulties with the current model, it would probably be useful to hear about them!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-894432129:1444,pipeline,pipeline,1444,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-894432129,1,['pipeline'],['pipeline']
Deployability,"Hi @cwhelan , I've expanded this PR to do more than what it originally was trying to fix, and separated the patches by commits as usual:. * the originally proposed fix, which brings back the annotation that are available to simple variants but go missing due to a careless bug, is now done in commit 50f1b640a31ddb528dc763b83b26a9d98dce8556; this commit also accordingly refactors the giant class `CpxVariantDetector` into three new classes; * in the 2nd commit 734516383fb665a79796de76535560fc03cb754b, I did more refactoring on how we group the descriptions for the annotation keys, and updated the test VCF files accordingly.; * because of the refactoring, the review comments were gone, so I added them back in the 3rd commit b7619c45a949dfba21d65a5ed876bc72e832aa77, which contains the comments and my replies. They come in as TODO's but are going to be removed ultimately; * in the following commits, I added tests for the CPX code path, selecting three representative cases (there's no limit how complex the scenario can go). One particular commit 224c97c7b736e94ed6b4d8b067ec830a9f8f2403 is large but most of it is for adding a flat file that contains the chromosome names in hg38 and their lengths for building a bare bone sequence dictionary used in building test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525:108,patch,patches,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525,4,"['patch', 'update']","['patches', 'updated']"
Deployability,Hi @danieljrichard. I suspect the error message you're seeing is a not the underlying problem. Sometimes when the tool crashes there are errors during standard shutdown cleanup that hide the real problem. There's a [recent patch](https://github.com/broadinstitute/gatk/commit/f7dea3c08b126c56b851c4d381cfdb5513e0584f) which makes it so that should happen much less but it's not in any currently released version. Are you able to build the current master branch of gatk and repeat your test with that version? I suspect it will clarify what's going on.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452177739:223,patch,patch,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452177739,2,"['patch', 'release']","['patch', 'released']"
Deployability,Hi @dantefff. We're planning on officially moving GATK to use java 11 by default in the relatively near future. I don't have an exact timeline. It's definitely annoying to not have it work out of the box on most linux systems and it's something we want to do soon. I have had very limited bandwidth lately and updating to 11 has been a casualty of that. Now that the world is rebooting things should start to tick along faster and I hope to have it updated soon.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7333#issuecomment-871615858:449,update,updated,449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7333#issuecomment-871615858,1,['update'],['updated']
Deployability,"Hi @droazen , thanks for your quick response! Depending on what you mean for ""multiple tools,"" I'd say just Mutect2. I say this because we are running this as part of a cwl workflow, so Mutect2 is running on its own instance (virtual machine) with that specified docker image. All of the surrounding tools have produced the expected outputs when queried except for Mutect2. That's a good point about the release version, I think we happen to be considering upgrading, but have to be picky as to when given the size and scope of our operation :) Also, your suggestion of using the official GATK might help, as I am not sure I can rule out subtle `apt update` changes even within the same version of ubuntu over time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7269#issuecomment-847248241:404,release,release,404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7269#issuecomment-847248241,2,"['release', 'update']","['release', 'update']"
Deployability,"Hi @droazen ,; I am sorry for the late response. I used the docker container from dockerhub broadinstitute/gatk:4.4.0.0 .; The which python command produces the correct path. I re-loaded the container and tried it again without modification. Again the pipeline crashed with BaseRecalibrator and the above mentioned error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8402#issuecomment-1691458235:252,pipeline,pipeline,252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8402#issuecomment-1691458235,1,['pipeline'],['pipeline']
Deployability,"Hi @droazen ,; I was just wondering if there was any update on this.; Thanks,; Sam",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3979#issuecomment-360667067:53,update,update,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3979#issuecomment-360667067,1,['update'],['update']
Deployability,"Hi @droazen, ; Any updates on the timeframe for this new release? We're eagerly waiting for the next version so we can start updating everything on our side!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2304596770:19,update,updates,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2304596770,2,"['release', 'update']","['release', 'updates']"
Deployability,"Hi @fpbarthel,. You have a few options, but I think they would all require a bit of manual processing on your part. For example, you could use CollectReadCounts with your initial list of bins, but then you'd have to do the averaging step manually. Hopefully, it should not be too trouble to put together your own script to do this; however, since it is somewhat of a custom operation, it's unlikely we'll support it as a feature. In any case, note that the rest of the downstream tools in both our germline and somatic pipelines are only set up to work with integer counts. I don't know your reasons for wanting to average counts over multiple bins, but since 1) averages contain less information than the full resolution bins, 2) the BAM I/O to perform count collection is expensive (so we don't want to discard information during the CollectReadCounts step that we might need later), and 3) we want to build generative models of the counts, our philosophy is to always retain the integer counts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5432#issuecomment-439892644:519,pipeline,pipelines,519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5432#issuecomment-439892644,1,['pipeline'],['pipelines']
Deployability,"Hi @huangk3. This is a known bug. The spark pipeline uses a 2bit reference but bwa needs a fasta reference. There's a branch in pr #1981 that adds a `bwa_reference` parameter as a work around. The test are failing but to the best of my knowledge it's the tests that are wrong and not the code. I need to update the tests in that branch and get it merged in, but if you want to play around it with it it's a good place to start. (use with caution for now though).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2171#issuecomment-247705047:44,pipeline,pipeline,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2171#issuecomment-247705047,2,"['pipeline', 'update']","['pipeline', 'update']"
Deployability,"Hi @jaideepjoshi ,; I was able to get it work with maprfs but using its hdfs path (maprfs is compatible with it). The weird things is: for a path `maprfs:///username/file`, it will be `hdfs://spark01:7222/user/username/file`.; For example:; ```./gatkRun.sh CountVariantsSpark -V hdfs://spark01:7222/user/axverdier/data/phalstedii/PLHAL710.710-20180213-1113.vcf```. gatkRun.sh is just a script to run gatk on spark with some parameters. As I didn't run a job recently (yes, I'm lazy ^^), it's possible it's not compatible with the current gatk version (for example, ` --spark-submit-command` was not).; ```; #! /bin/bash. # Run a gatk spark tool on the lipm's spark.; # The command is: ./gatkRun.sh <gatk spark tool name> <tool arguments>. # === gatk-launcheri and spark infos ===; launcher=""/usr/local/bioinfo/bin/gatk""; sparkNumExecutors=250; sparkMemExecutors=""5g"". # At least, the tool must be defined; if [[ $# -eq 0 ]]; then; echo ""ERROR: you must specify the gatk tool""; exit 1;; fi. # === Get args ===; # Get the tool, then remove it from arguments (with shift) so $@ only contains its parameters; tool=$1 # Get the tool name; name=""GATK_$tool""; shift; toolParams=$@. # === Running ===; sparkParams=""--name $name --num-executors $sparkNumExecutors --executor-memory $sparkMemExecutors --deploy-mode cluster"". gatkSparkParams=""--program-name $name --spark-runner SPARK --spark-master yarn"" # gatkspark parameters related to spark. cmd=""$launcher $tool $toolParams $gatkSparkParams -- $sparkParams""; echo -e ""\n$cmd\n""; $cmd; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-375218548:1294,deploy,deploy-mode,1294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-375218548,1,['deploy'],['deploy-mode']
Deployability,"Hi @jamesemery Thanks for your email.; Actually, I was successful with calculation of ""DepthOfCoverage"" with following procedure:; 1. I found the exact reference fasta file which is used for mapping procedures in my pipeline + .dict and .fa.fai; 2. I made a bed file out of the reference fasta file, using the following command:; faidx -i bed genome.fa > out.bed; 3. Finally I did this for performing the ""DepthOfCoverage"" tool:; gatk DepthOfCoverage -R reference.fa -O result -I s269825.haplotagged.bam -L out.bed. So everything works fine but there is another problem: the size of output file is very huge (GBs)! Should it be like that?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7453#issuecomment-971402891:216,pipeline,pipeline,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7453#issuecomment-971402891,1,['pipeline'],['pipeline']
Deployability,"Hi @jimhavrilla, glad you found the forum post helpful! These updates were indeed made in a recent PR (#5026), but they haven’t been officially released yet.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643553507:62,update,updates,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643553507,2,"['release', 'update']","['released', 'updates']"
Deployability,"Hi @jjfarrell . We took a look through our code and libraries we're depending on and the only place we could find any logging message that would produce those lines in any related repo we could find is in the `TestBAM` example tool from the Hadoop-BAM library. Is there any chance you ran that tool on one of your files (one with 76bp reads), perhaps after installing Hadoop-BAM and following the examples README, and that's what filled up the log?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373795692:357,install,installing,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373795692,1,['install'],['installing']
Deployability,"Hi @lbergelson I added **--disableAllReadFilters**, the log still says ""null"". Using GATK wrapper script /home/kh3/Softwares/gatk/build/install/gatk/bin/gatk; Running:; /home/kh3/Softwares/gatk/build/install/gatk/bin/gatk BwaSpark -I /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.bam -R /home/kh3/Resources/genome_b37/genome.fa --disableAllReadFilters --disableSequenceDictionaryValidation true -t 16 -O /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.aligned.bam; 12:08:44.856 INFO IntelGKLUtils - Trying to load Intel GKL library from:; jar:file:/home/kh3/Softwares/gatk/build/install/gatk/lib/gkl-0.1.2.jar!/com/intel/gkl/native/libIntelGKL.so; 12:08:44.905 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [September 17, 2016 12:08:44 PM EDT] org.broadinstitute.hellbender.tools.spark.bwa.BwaSpark --output /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.aligned.bam --threads 16 --reference /home/kh3/Resources/genome_b37/genome.fa --input /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.bam --disableSequenceDictionaryValidation true --disableAllReadFilters true --fixedChunkSize 100000 --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false; [September 17, 2016 12:08:44 PM EDT] Executing as kh3@rgcaahauva08091.rgc.aws.com on Linux 3.13.0-91-generic amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_101-b13; Version: Version:4.alpha.2-45-ga30af5a-SNAPSHOT; 12:08:44.930 INFO BwaSpark - Defaults.BUFFER_SIZE : 131072; 12:08:44.930 INFO BwaSpark - Defaults.COMPRESSION_LEVEL : 1; 12:08:44.930 INFO BwaSpark - Defaults.CREATE_INDEX : false; 12:08:44.930 INFO BwaSpark - Defaults.CREATE_MD5 : false; 12:08:44.930 INFO BwaSpark - Defaults.CUSTOM_READER_FACTORY : ; 12:08:44.930 INFO BwaSpark - Defaults.EBI_REFERENCE_SERVICE_URL_MAS",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2171#issuecomment-247785408:136,install,install,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2171#issuecomment-247785408,3,['install'],['install']
Deployability,"Hi @lbergelson Thanks for the quick response! I just used the fasta as reference, and it still doesn't work. The log only says ""null"". Using GATK wrapper script /home/kh3/Softwares/gatk/build/install/gatk/bin/gatk; Running:; /home/kh3/Softwares/gatk/build/install/gatk/bin/gatk BwaSpark -I /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.bam -R /home/kh3/Resources/genome_b37/genome.fa --disableSequenceDictionaryValidation true -t 16 -O /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.aligned.bam; 16:55:32.261 INFO IntelGKLUtils - Trying to load Intel GKL library from:; jar:file:/home/kh3/Softwares/gatk/build/install/gatk/lib/gkl-0.1.2.jar!/com/intel/gkl/native/libIntelGKL.so; 16:55:32.310 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [September 16, 2016 4:55:32 PM EDT] org.broadinstitute.hellbender.tools.spark.bwa.BwaSpark --output /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.aligned.bam --threads 16 --reference /home/kh3/Resources/genome_b37/genome.fa --input /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.bam --disableSequenceDictionaryValidation true --fixedChunkSize 100000 --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false --disableAllReadFilters false; [September 16, 2016 4:55:32 PM EDT] Executing as kh3@rgcaahauva08091.rgc.aws.com on Linux 3.13.0-91-generic amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_101-b13; Version: Version:4.alpha.2-45-ga30af5a-SNAPSHOT; 16:55:32.335 INFO BwaSpark - Defaults.BUFFER_SIZE : 131072; 16:55:32.335 INFO BwaSpark - Defaults.COMPRESSION_LEVEL : 1; 16:55:32.335 INFO BwaSpark - Defaults.CREATE_INDEX : false; 16:55:32.335 INFO BwaSpark - Defaults.CREATE_MD5 : false; 16:55:32.335 INFO BwaSpark - Defaults.CUSTOM_READER_FACTORY : ; 16:55:32.335 INFO BwaSpark - Default",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2171#issuecomment-247709200:192,install,install,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2171#issuecomment-247709200,3,['install'],['install']
Deployability,"Hi @lbergelson and @AJDCiarla ,. Thank you for your working!. I am the one who reported this bug and I had given it a try as @lbergelson suggested. I performed tests in two different scenarios:. 1. Using full path without any non-ascii characters as tmp path and it succeeded:; ```; /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx8G -Djava.io.tmpdir=/data/xieduo/gatktest"" BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; Using GATK jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -Djava.io.tmpdir=/data/xieduo/gatktest -jar /data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk_resource/Homo_sapiens_assembly38.fasta -I /data/xieduo/Immun_genomics/data/Łuksza_2022_Nature/bam/PAAD11N.bam --known-sites /data/xieduo/WES_pipe/pipeline/gatk_resource/dbsnp_146.hg38.vcf.gz --known-sites /data/reference/gatk_resource/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/reference/gatk_resource/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -O PAAD11N.recal_data.test.table; 13:35:32.710 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xieduo/WES_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:32.890 INFO BaseRecalibrator - ------------------------------------------------------------; 13",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081:305,pipeline,pipeline,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005#issuecomment-1254561081,3,['pipeline'],['pipeline']
Deployability,"Hi @lbergelson and thanks for considering my issue,. I'm sorry but I'm not familiar to artifactory dependency, if necessary I'll deepen about it; so I just inserted this dependency in the project's pom.xml; ```; <dependency>; <groupId>org.broadinstitute</groupId>; <artifactId>gatk</artifactId>; <version>4.beta.6-18-g2ee7724-20171025.162137-1</version>; </dependency>; ```; as reported in the [artifact repository](https://broadinstitute.jfrog.io/broadinstitute/webapp/#/artifacts/browse/tree/General/libs-snapshot-local/org/broadinstitute/gatk/4.beta.6-18-g2ee7724-SNAPSHOT/gatk-4.beta.6-18-g2ee7724-20171025.162137-1.jar), but when I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact org.broadinstitute:gatk:jar:4.beta.6-18-g2ee7724-20171025.162137-1 -> [Help 1]; ```. Am I making any mistake?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339624024:656,install,install,656,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339624024,2,['install'],['install']
Deployability,Hi @lbergelson! I've just pushed an update to this branch that appears to resolve the test failures on my side.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356109355:36,update,update,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356109355,1,['update'],['update']
Deployability,"Hi @lbergelson, just wondering if there were any updates on this issue as we encountered the same issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6379#issuecomment-980477099:49,update,updates,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6379#issuecomment-980477099,1,['update'],['updates']
Deployability,"Hi @ldgauthier,; I'm sorry for my delay with this topic. I was preparing myself to defend my Ph.D. (successfully done) and I wasn't looking GitHub these days... ; Anyway... we were using public human samples as input... There are 22 of them available on the web, we have the gvcfs on our servers generated by Dragen (these were generated by Dragen 3.6.3), but if you need them, I'll have to ask permission for sharing (let me know if it'd be easier for you, I must share them by email). Some of them ; ```; NA02718; NA07891; NA08618; NA09834; NA11661; NA12217; NA12878; NA14234; NA14626; NA14734; NA17819; NA18668; NA18949; NA20381; ```; Regarding chrY, in samples with XX karyotype, the DRAGEN pipeline makes a diploid variant call, but applies a ""PloidyConflict"" hard filter (and apparently all calls are either 0/0 or ./.), whereas the DRAGEN pipeline makes a haploid variant call for XY karyotype samples as expected.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7690#issuecomment-1106778777:695,pipeline,pipeline,695,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7690#issuecomment-1106778777,2,['pipeline'],['pipeline']
Deployability,"Hi @magicDGS, thanks for tackling this. I would also like to be able to use IndelRealigner with GATK4. Where are you at with the porting so far? The last update to the PR is sooheelee providing you with some test data in March.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-401850707:154,update,update,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-401850707,1,['update'],['update']
Deployability,"Hi @pieterlukasse. This is a great question and somewhat timely. Funcotator hasn't gotten the attention it needs lately because the engineer who's most involved has been extremely busy with other very high priority projects. We intend to support it going forward but it's unclear if that means bug fixes and reactive support or if we're able to make major upgrades. We're currently in the middle of somewhat of a resource crunch, and we are actively planning how to prioritize our attention in the future. . I think if you're basically happy with features now, you should feel safe investing the time into an output parser. If there are major improvements you need I would wait a week or two and ask again then because we'll have more clarity about what we can do. . If you're interested I would consider contributing back your code the GATK core. There's some existing utility code that could probably help you, but there's a long standing gap in our tooling for users to make sense of the funcotations and we'd welcome improvements or new tools. @jonn-smith @droazen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8154#issuecomment-1378997296:356,upgrade,upgrades,356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8154#issuecomment-1378997296,1,['upgrade'],['upgrades']
Deployability,"Hi @ruslan-abasov,. I believe your GermlineCNVCaller results should have inherited the correct dictionary from the count files. The issue is you created some GermlineCNVCaller shards (e.g., shard 4) with inappropriately ordered intervals (since these were instead ordered w.r.t. to the idiosyncratic dictionary you attached). However, I think if you just reshard and rerun GermlineCNVCaller for any such shards, you may be able to reuse most of your results. For example, you could take your shard 4 interval list, which contains intervals from chr18, chr19, and chr1, and reshard these intervals into two shards: 4a containing chr18-19 intervals, and 4b containing chr1 intervals. After rerunning 4a and 4b through GermlineCNVCaller, you should be able to use PostprocessGermlineCNVCalls to stitch together shards 4b, 1, 2, 3, and 4a, since these will be ordered w.r.t. the correct dictionary from the count files (i.e, they will contain intervals in the order chr1, chr10-19). Of course, you will want not want to perform this exact procedure; you'll want to generalize it to whatever will yield the correct order for all 10 of your shards across all contigs. Again, this may be error prone and I can't guarantee that it will be successful, since I haven't tried it myself. I would personally just rerun the pipeline. You might be able to cut down on runtime by using smaller shards (I believe we typically shard the entire genome into far more than 10 shards, which we usually run in parallel) and making sure you set parameters appropriately for WGS. @mwalker174 has the most experience running on WGS and should be able to provide you the latest recommendations, or you might be able to find them by searching GitHub or the GATK Forums. Your point is well taken about failing earlier, and I think I've outlined the best strategy above. It is impossible to catch all possible errors early, but for some we can certainly fail before the GermlineCNVCaller step.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-720091802:1310,pipeline,pipeline,1310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-720091802,1,['pipeline'],['pipeline']
Deployability,"Hi @samuelklee ! I just wanted to give you an update on this. I'm still happy to help make these changes, but I do want to let you know that it may be a while before I can put in the work to do so. I'm currently tied up in a couple of other projects, so I'm happy to hand this off to you or whoever has the time and wants to help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6545#issuecomment-621235977:46,update,update,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6545#issuecomment-621235977,1,['update'],['update']
Deployability,"Hi @samuelklee ; I updated my conda environment and it worked now. ; Sorry again for posting the error in github and not in the gatk forum, hopefully next time it will work. Thanks again; Stefan",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4679#issuecomment-382736818:19,update,updated,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4679#issuecomment-382736818,1,['update'],['updated']
Deployability,"Hi @samuelklee,. Any updates on this PR? Will this be able to get merged in the foreseeable future?. Thanks; M",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1938236585:21,update,updates,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1938236585,1,['update'],['updates']
Deployability,"Hi @shengqh, tools such as you describe are still under development. We are also still working to tune hyperparameters in the main gCNV pipeline, so thanks for trying it out! Please let us know if you encounter any issues.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5373#issuecomment-434275953:136,pipeline,pipeline,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5373#issuecomment-434275953,1,['pipeline'],['pipeline']
Deployability,"Hi @sujianed ; Can you try running the tool without the /bin/bash entry at the beginning of the command? That entry disables the proper initiation of the conda environment with the proper python objects therefore you get this error message. You can run the tool directly from the commandline like . `docker run --rm -it broadinstitute/gatk-dev:NVSCOREVARIANTS-PREVIEW-SNAPSHOT gatk NVScoreVariants ....`. Here is what happens when you have the entry. ```; $ docker run --rm -it broadinstitute/gatk-dev:NVSCOREVARIANTS-PREVIEW-SNAPSHOT /bin/bash; root@5d30f9f10f97:/gatk# python -c ""import scorevariants""; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; ModuleNotFoundError: No module named 'scorevariants'; root@5d30f9f10f97:/gatk# . ```. Without the entry here is the result; ```; $ docker run --rm -it broadinstitute/gatk-dev:NVSCOREVARIANTS-PREVIEW-SNAPSHOT ; This docker image is specially built as a pre-release preview image for running the new GATK tool NVScoreVariants, and comes with a Python environment specific to that tool. Other Python-based GATK tools cannot be run using this image: use the official GATK release images instead.; (nvscorevariants) root@0a9dcd961783:/gatk# python -c ""import scorevariants""; (nvscorevariants) root@0a9dcd961783:/gatk#; ```. See that the bottom entry has the proper conda environment nvscorevariants initialized.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8501#issuecomment-1697386717:935,release,release,935,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8501#issuecomment-1697386717,2,['release'],['release']
Deployability,"Hi @tedsharpe, . A quick follow-up question on this – how does the function currently handle the Q-scores from overlapping portions of paired-end reads? @BenjaminWehnert1008 noticed that read pre-merging and dual Q-score integration can help improve our performance for 1nt variants. Best wishes,; Max",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8995#issuecomment-2416095456:221,integrat,integration,221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8995#issuecomment-2416095456,1,['integrat'],['integration']
Deployability,"Hi @tomwhite! The serializer registrations in ADAM shouldn't effect any GATK serialization, unless you're serializing classes from ADAM (such as `org.bdgenomics.format.avro.AlignmentRecord`); additionally, we haven't seen any performance issues with serialization in ADAM 0.23.0 outside of the GATK. We actually made a number of patches to eliminate logging in 0.23.0 (relative to 0.22.0), so I'd doubt that is the culprit. The one exception to this is logging when writing Parquet out to disk, which greatly increased sometime between ADAM 0.21.0 and 0.23.0, due to a change in Parquet versions upstream in Spark. However, this would only impact you if you were writing Parquet, and additionally this issue was resolved with the release of Spark 2.2.0, so you should see the logging go away with #4314. If I had to hypothesize anything, I'd suggest that the 2bit file change is the one thing that could be biting you. That said, we've been running with this 2bit file code quite frequently on AWS and Azure for at least the last 6 months using GATK HC on WES and WGS data and haven't seen any performance issues. I show that the changes in the 2bit file code between ADAM 0.20.0 and 0.23.0 are API compatible, so if you check out ADAM 0.23.0 and then `git checkout adam-parent-spark2_2.11-0.20.0 adam-core/src/main/scala/org/bdgenomics/adam/util/TwoBitFile.scala` and build the ADAM JAR (and then package that jar into GATK), you should be able to test that hypothesis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897:329,patch,patches,329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897,2,"['patch', 'release']","['patches', 'release']"
Deployability,"Hi @zaneChou1,. Thanks for filing the issue---I'm actually working on this at the moment. The gCNV python code requires some updating, since the APIs for inference changed after the pymc3 version we use (which is the primary reason we stuck with it). Because the changes required go beyond those in the PR you opened, I'll go ahead and close it, but thanks for making the effort to help us keep things updated! We certainly appreciate it. I would be surprised if updating numpy led to drastic performance improvements (1.17.5 was only released in 1/2020), but it's possible there have been improvements in the pymc3 python code. However, we are planning to move much of the python inference code over to pyro, for which the numpy upgrade is also necessary.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6978#issuecomment-733001543:402,update,updated,402,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6978#issuecomment-733001543,3,"['release', 'update', 'upgrade']","['released', 'updated', 'upgrade']"
Deployability,"Hi Adam,. Maybe I'm thinking naively here - and I don't have access to a complete and proper Spark cluster for rigorous testing - but just as a simple test of loading a VCF via Spark, I took [PrintReadsSpark.java](https://github.com/broadinstitute/gatk/blob/030858bc08328200b9df287db2571b907189ec66/src/main/java/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSpark.java) and performed following updates:; - Copied `./src/test/resources/org/broadinstitute/hellbender/utils/SequenceDictionaryUtils/test.vcf` into the local directory.; - Renamed the copy of `PrintReadsSpark.java` as `PrintVCFSpark.java`; - Added `import org.broadinstitute.hellbender.utils.variant.Variant;`; - Added `import org.broadinstitute.hellbender.engine.spark.datasources.VariantsSparkSource;`; - As a test, I changed to the `runTool` method with the following to print the information in the first element in the RDD:. ``` Java; JavaRDD<Variant> rddParallelVariants =; variantsSparkSource.getParallelVariants(output);. System.out.println( rddParallelVariants.first().toString() );; ```. And after re-compiling GATK and running `PrintVCFSpark`, I got the following to print the first element of the RDD:. ``` Bash; $ ./gatk-launch PrintVCFSpark --input test.vcf --output test.vcf. Running:; /home/pgrosu/me/hellbender_broad_institute/gatk/build/install/gatk/bin/gatk PrintVCFSpark --input test.vcf --output test.vcf; [February 14, 2016 7:04:16 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVCFSpark --output test.vcf --input test.vcf --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false; [February 14, 2016 7:04:16 PM EST] Executing as pgrosu on Linux 2.6.32-358.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_05-b13; Version: Version:4.alpha-86-g154d0a8-SNAPSHOT JdkD",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1486#issuecomment-184011857:355,pipeline,pipelines,355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1486#issuecomment-184011857,2,"['pipeline', 'update']","['pipelines', 'updates']"
Deployability,"Hi Chris -. I am not sure what this question is asking. A few users are writing in about this bug, so it is happening in the latest release. . How would someone get the fixed version of the code?. Sorry, I am not usually covering the GATK forum, I am unfamiliar with how to get a fix from the github to the user. I have linked to the forum post about this in the issue ticket. That person may be a good person to ask about what they have tried already to work around the bug. Thanks,. Adelaide. > On May 16, 2019, at 8:17 AM, Chris Norman <notifications@github.com> wrote:; > ; > The latest released gatk doesn't have this fix in it yet, and although I see that one forum user was going to try to reproduce on the latest branch, I don't see the results from that yet. Has someone reproduced this using code that includes the fix to #5893 <https://github.com/broadinstitute/gatk/issues/5893> ?; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub <https://github.com/broadinstitute/gatk/issues/5945?email_source=notifications&email_token=AKX4GYQBYESFFKARDIJ7ZBDPVVGG5A5CNFSM4HNH4LP2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVRT5OA#issuecomment-493043384>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AKX4GYTJN5YX3JP5GSLQ34DPVVGG5ANCNFSM4HNH4LPQ>.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5945#issuecomment-493083173:132,release,release,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5945#issuecomment-493083173,2,['release'],"['release', 'released']"
Deployability,"Hi Chris,. We have a user enquiring about an update on this issue. Do we have a timeline for this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4387#issuecomment-453320358:45,update,update,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4387#issuecomment-453320358,1,['update'],['update']
Deployability,"Hi David,. 1. Here, we must distinguish between the WES minimal example (default parameters, command lines in my original bug report) and our ""production pipeline"". In the minimal example, we do not use PON. In the production pipeline, we use the exome PON file from: gs://gatk-best-practices/somatic-hg38/1000g_pon.hg38.vcf.gz as recommended here: https://gatk.broadinstitute.org/hc/en-us/articles/360035890631-Panel-of-Normals-PON-; In the production pipeline, we also use gnomAD 3.1.2, filtered for AF>0 and FILTER=PASS as ""germline resource"". Some more data from the production pipeline, just in case it could help. ; Since the PON is exome-only, we were not sure whether including the PON would improve the performance of our WGS workflow in the ""production pipeline"" with gatk version 4.1.7.0, so we ran experiments:; - calling without germline resource and without PON; - calling with germline resource only, without PON; - calling with both germline resource and PON. The results:. ![WGS_FD_tumor-normal_reference_workflow_v04_WGS_FD_tumor-normal_reference_workflow_v04_gnomAD_only_WGS_FD_tumor-normal_reference_workflow_v04_no_gnomAD_no_PON](https://user-images.githubusercontent.com/15612230/182359001-a173e711-748b-49ec-b03f-71e5a8293c51.png). We also conducted experiments with a subset of the WES FD sample (FD_1, 1/3 of the full ~100x FD dataset):. - calling without germline resource and without PON; - calling with PON only, without germline resource; - calling with germline resource only, without PON; - calling with both germline resource and PON. The results (please note that the labeling conventions are now different compared to WGS experiments, apologies for the inconvenience):. ![FD_1_T_tumor-normal_WES_muTect2_FD_1_tumor-normal_muTect2_PON_FD_1_tumor-normal_muTect2_gnomAD_FD_1_tumor-normal_muTect2_PON_gnomAD](https://user-images.githubusercontent.com/15612230/182358963-97f04d12-94c6-4f77-acef-c3ebcd78a98f.png). 2. The reference is GRCh38.primary_assembly.genome.fa; The",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1202344705:154,pipeline,pipeline,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1202344705,5,['pipeline'],['pipeline']
Deployability,"Hi David,. Thanks for your response and effort developing the best practices pipeline and GATK. I'm not certain, but I would suspect that a significant percentage of your users may also not use the best practices pipeline for one reason or another. In my particular case, I intersect calls from multiple variant callers and prefer to run this pipeline without the added abstraction of Terra (or WDL) for the sake of simplicity. This was easy to fix on my end, thanks again. Andrew. @davidbenjamin. > On Sep 3, 2019, at 4:16 PM, David Benjamin <notifications@github.com> wrote:; > ; > @lbergelson The stats file is not optional, but the argument is optional because by default FilterMutectCalls looks for the stats file produced automatically by Mutect2 in the same directory as the output vcf.; > ; > @andrewrech The official best practices pipeline -- that is, mutect2.wdl in this repo and hosted on Terra (formerly Firecloud) -- handles this automatically. We generally discourage users from writing their own pipelines because it takes very long and can easily yield inferior results. Is the official pipeline missing a feature that you need?; > ; > As for backwards compatibility, while we can guarantee that Mutect2 and FilterMutectCalls from the same GATK release will always work together we do not make any promises about the interoperability of different releases.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6124#issuecomment-527643415:77,pipeline,pipeline,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6124#issuecomment-527643415,16,"['pipeline', 'release']","['pipeline', 'pipelines', 'release', 'releases']"
Deployability,"Hi GATK team!; I would like a minimum fragment length filter during calling CNVs (the CountReads step) if possible. @LeeTL1220 helped me to find an option to set a maximum fragment length with `--read_filter FragmentLength --maxFragmentLength <value>` ([link to the GATK forum page](https://gatkforums.broadinstitute.org/gatk/discussion/2338/how-can-i-invoke-read-filters-and-their-arguments)). However, it appears there is no minimum fragment length filter implemented. Would it be possible to include the min fragment filter option in the future release or as a pre-release version?. The reason of asking this filter is:. there are shorter fragments in a FFPE tumor PCR-free WGS (top) compared to the PCR-plus WGS (bottom) from the same individual:; ![image](https://user-images.githubusercontent.com/5141643/56065278-611c9a80-5d42-11e9-8b60-b82ea1d69e87.png); and I observed higher MAD values in the PCR-free samples. I would like to see whether the results improve after discarding the shorter fragments in the FFPE PCR-free WGS.; ![image](https://user-images.githubusercontent.com/5141643/56065600-50b8ef80-5d43-11e9-9160-fb0beb5c11de.png)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5884:548,release,release,548,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5884,2,['release'],['release']
Deployability,"Hi GATK team,. I tried running your PathSeq pipeline (broadinstitute/gatk:4.1.8.0) on my cohort and almost half of the samples failed the scoring step with this error message:. `20/07/17 09:38:35 INFO NewHadoopRDD: Input split: file:/cromwell_root/fc-6e61d4b2-bdc8-4abd-bb94-18d8fa11d9b6/7c1b0faa-e956-4289-9e2d-4fb8b9eff6ff/PathSeqPipeline/0ca5578f-70d3-498e-b7cc-23590f0ab31f/call-PathSeqAlign/MMRF_2072_2_BM.microbe_aligned.paired.bam:33554432+33554432; 20/07/17 09:38:46 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 5); java.util.NoSuchElementException: next on empty iterator; 	at scala.collection.Iterator$$anon$2.next(Iterator.scala:39); 	at scala.collection.Iterator$$anon$2.next(Iterator.scala:37); 	at scala.collection.Iterator$$anon$13.next(Iterator.scala:469); 	at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$PeekingImpl.next(Iterators.java:1155); 	at org.broadinstitute.hellbender.utils.spark.SparkUtils.lambda$putReadsWithTheSameNameInTheSamePartition$7bd206b0$1(SparkUtils.java:190); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.execu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6319#issuecomment-660292360:44,pipeline,pipeline,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6319#issuecomment-660292360,1,['pipeline'],['pipeline']
Deployability,"Hi GATK team,. I tried running your PathSeq pipeline (broadinstitute/gatk:4.1.8.0) on my cohort and almost half of the samples failed the scoring step with this error message:; `20/07/17 09:38:35 INFO NewHadoopRDD: Input split: file:/cromwell_root/fc-6e61d4b2-bdc8-4abd-bb94-18d8fa11d9b6/7c1b0faa-e956-4289-9e2d-4fb8b9eff6ff/PathSeqPipeline/0ca5578f-70d3-498e-b7cc-23590f0ab31f/call-PathSeqAlign/MMRF_2072_2_BM.microbe_aligned.paired.bam:33554432+33554432 20/07/17 09:38:46 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 5) java.util.NoSuchElementException: next on empty iterator at scala.collection.Iterator$$anon$2.next(Iterator.scala:39) at scala.collection.Iterator$$anon$2.next(Iterator.scala:37) at scala.collection.Iterator$$anon$13.next(Iterator.scala:469) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$PeekingImpl.next(Iterators.java:1155) at org.broadinstitute.hellbender.utils.spark.SparkUtils.lambda$putReadsWithTheSameNameInTheSamePartition$7bd206b0$1(SparkUtils.java:190) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6709:44,pipeline,pipeline,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6709,1,['pipeline'],['pipeline']
Deployability,"Hi Karthik @kvn95ss ,. This isn't going to do what you want it to do if we implement it as you suggest. The latest GVCF formats try to preserve more annotation data so we can get better statistical power by using all mapping quality values (for example) rather than taking the median across all samples. As such, genomicsDB is going to return a value that isn't usable by VariantRecalibrator without going through GenotypeGVCFs to take the final mean and square root of the stored sum of the squared MQ values. GenomicsDB also won't calculate the FS or SOR values; it will only return the strand bias table. Finally, GenotypeGVCFs will apply a QUAL threshold to remove the lowest evidence variants so your final callset isn't riddled with false positives. GATK4 joint calling pipelines should always include GenotypeGVCFs, whether using CombineGVCFs or GenomicsDBImport to combine single-sample GVCF data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7169#issuecomment-811123495:776,pipeline,pipelines,776,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7169#issuecomment-811123495,2,['pipeline'],['pipelines']
Deployability,"Hi Megan,; I'd like to get some more suggestion for pre-processing the bam for mitochondria calls. Are remove-duplicate and base-quality-recalibration recommended before mutect2 call?. For 1st step of base quality recalibration, what reference file to use for --known-sites? My reads are mapped to hg38. gatk BaseRecalibrator \; -I my_reads.bam \; -R reference.fasta \; --known-sites sites_of_variation.vcf \; -O recal_data.table. So the whole pipeline would be:; BAM -> remove dup -> BQ recalibrate -> Mutect2 call -> FilterMutectCalls . Am I missing anything?. Thanks a lot!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-431849500:444,pipeline,pipeline,444,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-431849500,1,['pipeline'],['pipeline']
Deployability,"Hi Sam,. updating ReCapSegCaller with the new version and updating the tutorial data; is assigned to me as a task. But as far as I understand those tasks will; not need to be ready by the release. Could you confirm it?. Happy holidays,; Marton. On Wed, Nov 29, 2017 at 4:08 PM, samuelklee <notifications@github.com>; wrote:. > Assigned #3826 <https://github.com/broadinstitute/gatk/issues/3826> to; > @MartonKN <https://github.com/martonkn>.; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3826#event-1364415987>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AGPkHrgsag4Wro95TToAuawWDdtzSxp4ks5s7cfKgaJpZM4Qcfhw>; > .; >. -- ; Marton Kanasz-Nagy; Physics Department, Harvard University; 17 Oxford Street, Cambridge, MA 02138; kanasz@physics.harvard.edu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3826#issuecomment-353680464:188,release,release,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826#issuecomment-353680464,1,['release'],['release']
Deployability,"Hi Stefan,. If there is no obvious error (e.g., is `/media/Berechnungen/GATKTest/CN_transition_matrix_autosomal.tsvx` the correct filename, rather than `/media/Berechnungen/GATKTest/CN_transition_matrix_autosomal.tsv`? Does the file exist and is it correctly formatted?), then I would guess that this is likely an error with your nd4j configuration. Just to let you know, we have significantly revamped the both somatic and germline CNV pipelines for the release in January. If you would like a preview of the germline tool, you may want to look at this branch: https://github.com/broadinstitute/gatk/tree/sl_gcnv_ploidy_cli However, be aware that it is still under development.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3996#issuecomment-352760467:335,configurat,configuration,335,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3996#issuecomment-352760467,3,"['configurat', 'pipeline', 'release']","['configuration', 'pipelines', 'release']"
Deployability,"Hi [ShirelyI](https://github.com/ShirelyI),. Could you try running with the latest GATK release (4.4), and see if the issue persists? There have been a lot of fixes to GenomicsDB (which is where the error is coming from) between 4.2 and 4.4. @nalinigans / @mlathara, have either of you seen this error before when reading from GenomicsDB? What does it indicate?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8415#issuecomment-1648478289:88,release,release,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8415#issuecomment-1648478289,1,['release'],['release']
Deployability,"Hi again, some updates! I've updated our PED with inferred rather than stated sex, which has resolved a number of these issues. As stated before, the samples which had incorrectly assigned sexes were not the named samples appearing the error logs, which made troubleshooting a challenge. . We're now running into issues with true sex aneuploidy, which the tool doesn't work for, as stated in [your docs page](https://gatk.broadinstitute.org/hc/en-us/articles/9570468120987-JointGermlineCNVSegmentation-BETA). Do you have a way to cleanly handle these sex aneuploidies so that we can retain calls for the rest of the genome, rather than excluding the sample(s) entirely? This might be a process question, so I'm going to raise separately on the GATK-SV repo. FYI @cassimons",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8834#issuecomment-2123742806:15,update,updates,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8834#issuecomment-2123742806,2,['update'],"['updated', 'updates']"
Deployability,"Hi again,; I tried installing java8 and switching to this version prior to running gatk. It runs and looks to be running the right Java, but spits out roughly the same error:. Thoughts?. /cold/drichard/gatk/./gatk --java-options ""-Xmx25g"" SplitNCigarReads \; -R /cold/drichard/VARIANTS/Homo_sapiens.GRCh38.dna.primary_assembly.fa -I subset_TINY_rehead.bam \; --tmp-dir /thing -O thing.bam; Using GATK jar /cold/drichard/gatk/build/libs/gatk-package-4.3.0.0-44-g227bbca-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx25g -jar /cold/drichard/gatk/build/libs/gatk-package-4.3.0.0-44-g227bbca-SNAPSHOT-local.jar SplitNCigarReads -R /cold/drichard/VARIANTS/Homo_sapiens.GRCh38.dna.primary_assembly.fa -I subset_TINY_rehead.bam --tmp-dir /thing -O thing.bam; 15:34:59.974 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cold/drichard/gatk/build/libs/gatk-package-4.3.0.0-44-g227bbca-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_compression.so; 15:35:00.220 INFO SplitNCigarReads - ------------------------------------------------------------; 15:35:00.226 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.3.0.0-44-g227bbca-SNAPSHOT; 15:35:00.226 INFO SplitNCigarReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:35:00.226 INFO SplitNCigarReads - Executing as drichard@illuvatar on Linux v5.19.0-32-generic amd64; 15:35:00.226 INFO SplitNCigarReads - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_362-8u362-ga-0ubuntu1~22.04-b09; 15:35:00.226 INFO SplitNCigarReads - Start Date/Time: March 2, 2023 3:34:59 PM EST; 15:35:00.226 INFO SplitNCigarReads - ------------------------------------------------------------; 15:35:00.226 INFO SplitNCigarReads - ------------------------------------------------------------; 15:35:00.227 INFO SplitNCigarReads - HTSJDK Version: 3.0.1; 15:35:00.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452525485:19,install,installing,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452525485,1,['install'],['installing']
Deployability,"Hi all, thanks again for working to integrate this code!. Saw some confusion in the comments above and just wanted to clarify: if you take a look at the VQSR-lite PR https://github.com/broadinstitute/gatk/pull/7954/commits that the current branch is rebased upon, you'll see that it contains a version of the Joint Genotyping WDL (which was put together by Megan for Ultima) along with Java code for the tools (which was written by me). Both the WDL and the code have been updated in subsequent PRs. The WDL was rewritten by me in #8074; the main difference is that we no longer run SNPs and indels filtering in ""series"", but instead run them in a single step. However, this requires that you use the same annotations for both SNPs and indels; GVS might not be ready for that just yet, since the default WARP implementation uses different annotations. (But see also the comment here: https://github.com/broadinstitute/gatk/pull/8074#issue-1423991277. The gist is we can easily reimplement Megan's/WARP's ""serial"" SNP-then-indel workflow using the simpler single-step workflow.) (EDIT: I was originally confused here, Megan’s WDL simply runs SNPs and indels separately—thanks to George for correcting me here!). Note also that test infrastructure was moved from Travis to Github Actions between these PRs, so the Travis references above have already been cleaned up. There have also been a few additional minor PRs merged in the interim, with a couple more incoming. These PRs do not fundamentally change the interfaces of the tools/WDL, however, so I think you can update to them when you're ready. Punchline: this branch should suffice for a first cut of a VQSR/VQSR-lite bakeoff, and although it is already slightly out of date, it shouldn't be too much work to get things updated after the first cut is done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8157#issuecomment-1412640649:36,integrat,integrate,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8157#issuecomment-1412640649,8,"['integrat', 'update']","['integrate', 'update', 'updated']"
Deployability,"Hi all,. Any chance this will make it into a release soon? I was hoping this got merged with the recent docker image overhaul. Thanks; Matthias",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2199886702:45,release,release,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2199886702,1,['release'],['release']
Deployability,"Hi all,. Below error occurs trying to access Funcotator data source directory installed on lustre file system. We have a non-lustre mounted fs for cases like this, but I thought it was worth bringing up. ```; org.broadinstitute.hellbender.exceptions.GATKException: Unable to query the database for geneName: null; 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.cosmic.CosmicFuncotationFactory.createFuncotations(CosmicFuncotationFactory.java:244); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:404); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:316); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4413:78,install,installed,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4413,1,['install'],['installed']
Deployability,"Hi all.; This looks like an issue presented by a forum post . [Haplotypecaller FORMAT:DP is affected by the interval in WGS](https://gatk.broadinstitute.org/hc/en-us/community/posts/27992393649051-Haplotypecaller-FORMAT-DP-is-affected-by-the-interval-in-WGS). User uploaded a toy data for us to test and I was able to recreate this issue under GATK 4.6.0.0. I have not tested it with any other versions. When whole contig is given as interval all variant sites in the multisample VCF is reported with DP value much less than what it is supposed to be in samples where no variation occur. Samples with variants are shown as expected DP. Setting ploidy 2 for this analysis restores the expected DP value for samples with HOMREF sites no matter what interval is used. Numbers can be seen in the figure as well as those variant contexts. . This is what user and I got with the whole contig given as interval. ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	DA10_DA10	TDY1754_TDY1754; CP022325.1	69348	.	T	A	2920.63	.	AC=1;AF=0.500;AN=2;DP=85;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;QD=29.56;SOR=0.824	GT:AD:DP:GQ:PL	0:4,0:4:99:0,119	1:0,79:79:99:2931,0; ```; This is what comes when -L is set to `CP022325.1:69347-69349`. This is the same DP reported when ploidy is set to 2 no matter what interval is used. This is also the expected DP value. . ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	DA10_DA10	TDY1754_TDY1754; CP022325.1	69348	.	T	A	2920.63	.	AC=1;AF=0.500;AN=2;DP=98;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;QD=25.36;SOR=0.824	GT:AD:DP:GQ:PL	0:17,0:17:99:0,685	1:0,79:79:99:2931,0; ```. ![image](https://github.com/user-attachments/assets/269169f8-7de2-415c-ba60-8356937da561). User data is in the incoming folder with name `cmateusiak_20240805.tar.gz`. The reference genome is a fungal one from the below link. [Fungi reference C.NeoformansKN99](https://fungidb.org/common/downloads/release-68/CneoformansKN99/fasta/data/FungiDB-68_CneoformansKN99_Genome.fasta)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8943:1893,release,release-,1893,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8943,1,['release'],['release-']
Deployability,"Hi all;; When validation runs on the GATK 4.0.0 release (congrats!) we're running into segfault issues on some `GenomicsDBImport` runs which look to be due to the length of the database path:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f99a7642c5b, pid=7446, tid=0x00007f99fbfa0700; #; # JRE version: OpenJDK Runtime Environment (8.0_121-b15) (build 1.8.0_121-b15); # Java VM: OpenJDK 64-Bit Server VM (25.121-b15 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libtiledbgenomicsdb8843204539247232071.so+0x4fdc5b] std::string::compare(char const*) const+0x1b; ```; Here is a self-contained test case that reproduces the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_genomicsdb_length.tar.gz. A standard small name and longer name of 105 characters work fine:; ```; gatk-launch --java-options '-Xms1g -Xmx2g' GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path short_genomicsdb -L chr22:15069-15500 --variant Test1.vcf.gz --variant Test2.vcf.gz; gatk-launch --java-options '-Xms1g -Xmx2g' GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path long_aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa_genomicsdb/works_aaaaaaaaaaaaaaaaaaaaaaaaaa -L chr22:15069-15500 --variant Test1.vcf.gz --variant Test2.vcf.gz; ```; But when you add an additional character, you trigger the segfault:; ```; gatk-launch --java-options '-Xms1g -Xmx2g' GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path long_aaaaaa; aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa_genomicsdb/fails_aaaaaaaaaaaaaaaaaaaaaaaaaaa -L chr22:15069-15500 -; -variant Test1.vcf.gz --variant Test2.vcf.gz; ```; Thank you for looking at this and please let me know if I can provide any other information to help debug.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4160:48,release,release,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4160,1,['release'],['release']
Deployability,"Hi everyone,. I am going to use GATK4 to carry out population-based snp-calling for around 500 samples with the ploidy level from 2 to 6.; The sequence depth varied from 2x to 80x. Since there are many samples with low sequence depth (<5x), I was advised to use the population-based snp-calling pipeline. ; Recently, I met some problems in the flowchart of this analysis. Firstly, I found the pipelines that detailedly explained the flowchart of BQSR and variant calling for single-sample snp-calling. But I have no idea about the pipeline of the BQSR in population-based snp-calling. Should I apply the BQSR sample by sample following the flowchart menthioned above (the command line below), and then used these corrected bam files to identify the variants based on population-based method? Or there is another correct pipeline for this analysis. **Command lines:**. ```; for i in sample1.bam sample2.bam sample3.bam; do; java -jar picard.jar MarkDuplicates I=$i O=$i_bam CREATE_INDEX=true M=$i_metrics; gatk HaplotypeCaller -R $reference -I $i.sorted.dedup.bam -O ""$i"".g.vcf.gz --tmp-dir ./tmp -ERC GVCF; #SNP; gatk GenotypeGVCFs -R $reference -V ""$i"".g.vcf.gz -O ""$i"".vcf.gz; gatk SelectVariants -R $reference -V ""$i"".vcf.gz -select-type SNP -O ""$i"".snp.vcf.gz; gatk VariantFiltration -R $reference -V $path_BQSR/bqsr1.snp.vcf.gz -filter ""QD < 2.0"" --filter-name ""QD2"" -filter ""FS > 60.0"" --filter-name ""FS60"" -filter ""MQ < 40.0"" --filter-name ""MQ40"" -filter ""MQRankSum < -12.5"" --filter-name ""MQRankSum-12.5"" -filter ""ReadPosRankSum < -8.0"" --filter-name ""ReadPosRankSum-8.0"" -O $""i"".filtered.snp.vcf.gz; gatk SelectVariants -R $reference -V $""i"".filtered.snp.vcf.gz --exclude-filtered -O ""$i"".select.filtered.snp.vcf.gz; #INDEL; gatk SelectVariants -R $reference -V ""$i"".vcf.gz -select-type INDEL -O ""$i"".indel.vcf.gz; gatk VariantFiltration -R $reference -V ""$i"".indel.vcf.gz -filter ""QD < 2.0"" --filter-name ""QD2"" -filter ""FS > 200.0"" --filter-name ""FS200"" -filter ""ReadPosRankSum < -20.0"" --fi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8414:295,pipeline,pipeline,295,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8414,4,['pipeline'],"['pipeline', 'pipelines']"
Deployability,"Hi folks, is there any update on resolving this issue? I still have encountered this in gatk-4.0.6.0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066#issuecomment-407103385:23,update,update,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066#issuecomment-407103385,1,['update'],['update']
Deployability,"Hi folks. @chandrans and I have laid out some plans towards updating GATK4 docs for the January 9 release. Our approach is to prioritize documentation around stable Best Practice Workflows. On the docket currently is the single stable workflow--germline SNP and indel calling from DNA data. We will of course update tool docs (excluding Spark and BWA tools) and supporting tutorials. Even for tools we are unfamiliar with, we aim to have at the least a basic description and an example command. Thanks for the documentation you have already done and the help you give us in updating these. If you are certain your workflow will be ready for the release, then please let us know immediately so we can plan accordingly. If your workflow will be ready later, then can you still give us an estimate for your release so we can plan ahead? Thanks. - @davidbenjamin, did I hear you correctly that you think somatic SNV and indel calling will be ready for the Jan 9 release?; - @samuelklee, I know major changes are currently afoot for somatic CNV. Will you make the Jan 9 release for the targeted exomes use-case? What about WGS?; - @mbabadi, is March, 2018 still the plan?; - @jonn-smith, what is the status on the Tool-That-Must-Not-Be-Named?; - @cwhelan @tedsharpe @SHuang-Broad, is SV on for next year or thereafter?. It would be most helpful to users if we also have validation of our workflows as applied to real data. Are there plans to make benchmarking stats available for each of your workflows?. Sheila and I have 30-man days we can give between us towards updating documentation by December 14. Besides Geraldine, we will rely on some of you to review further refinements to documentation from now to December 14. Thanks again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3769:98,release,release,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769,6,"['release', 'update']","['release', 'update']"
Deployability,"Hi gatk team,. I'm working with generating CNV for somatic with wdl, using this command:. `java -Xmx75G -Dconfig.file=gatk.conf -jar cromwell-46.1.jar run cnv_somatic_panel_workflow.wdl -i parameters.json `. But I got this error in which I don't know the exact reason for it:. ```; [2019-10-01 02:52:52,49] [info] Running with database db.url = jdbc:hsqldb:mem:e98d186c-96db-46ae-92e5-c326e7aa05d9;shutdown=false;hsqldb.tx=mvcc; [2019-10-01 02:53:01,19] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2019-10-01 02:53:01,20] [info] [RenameWorkflowOptionsInMetadata] 100%; [2019-10-01 02:53:01,31] [info] Running with database db.url = jdbc:hsqldb:mem:c4b3296a-4b73-4053-b6bf-d4eeb71c8956;shutdown=false;hsqldb.tx=mvcc; [2019-10-01 02:53:01,85] [info] Slf4jLogger started; [2019-10-01 02:53:02,22] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-876ccf5"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2019-10-01 02:53:02,28] [info] Metadata summary refreshing every 1 second.; [2019-10-01 02:53:02,31] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-10-01 02:53:02,31] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-10-01 02:53:02,32] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2019-10-01 02:53:02,32] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2019-10-01 02:53:02,40] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2019-10-01 02:53:02,43] [info] SingleWorkflowRunnerActor: Version 46.1; [2019-10-01 02:53:02,44] [info] SingleWorkflowRunnerActor: Submitting workflow; [2019-10-01 02:53:02,49] [info] ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6189:901,configurat,configuration,901,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6189,1,['configurat'],['configuration']
Deployability,Hi guys I am very interested in this discussion. It would be great to know:. 1. what were the results?; 2. is this contig-prior-probablity file you created available somehow?; 3. are the data for the samples you tested the pipeline on available?. Thank you so much in advance!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-649726755:223,pipeline,pipeline,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-649726755,1,['pipeline'],['pipeline']
Deployability,"Hi there,. is there any update on this?; Thanks. Best; Zhan",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8276#issuecomment-1672738609:24,update,update,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8276#issuecomment-1672738609,1,['update'],['update']
Deployability,Hi this is SkyWarrior from GATK forum.; Are there any updates on this issue? (I wish to drop using locus based callers to overcome this problem),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-379710308:54,update,updates,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-379710308,1,['update'],['updates']
Deployability,Hi! I know this issue is closed and a solution has been found but I am facing this same issue right now and wanted to follow up and see if it's been patched in the current 4.4.0.0 version of gatk? Or is the new release expected to be published soon?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1799479778:149,patch,patched,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1799479778,2,"['patch', 'release']","['patched', 'release']"
Deployability,"Hi! This issue is a duplicate of #7054 - under the hood a few changes need to be made to support arbitrary `FeatureTag`s. ; As gencode is updated they seem to be adding more `FeatureTag`s, which Funcotator doesn't expect. The fix is relatively straight-forward, but requires several other changes as well. Unfortunately there isn't a good workaround right now. As a side-note, the `getGencode.sh` script you referenced (and all scripts in that same folder: `scripts/funcotator/data_sources`) are not supported and are designed to be for internal use (I have a file in that folder to indicate this, but I'll admit it's not 100% clear). That said, `getGencode.sh` should work properly - the issue is in the GATK itself (specifically in `org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfTranscriptFeature` and associated classes). This is on the short list of things to update next, so I'll try to get to it soon (though I'm not exactly sure when that will be). Given two people have experienced this issue, I'll prioritize it somewhat higher.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7134#issuecomment-799569339:138,update,updated,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7134#issuecomment-799569339,4,['update'],"['update', 'updated']"
Deployability,"Hi!. I am using the gatk tool AnalyzeSaturationMutagenesis to analyze some data produced with the MITE-seq technology. It works perfectly for my purpose, so I decided to include it as a step in my pipeline written in Nextflow. ; Strangely enough, when I try to run the SAME EXACT command line inside a Nextflow module, it gives a generic error for most of the samples (sometimes all of them, sometimes some of them). ; It looks like a random issue, because if I run the same code outside of Nextflow, it works perfectly on every sample. . I would really appreciate if someone may give me some hints on why this is occurring and, eventually, how to fix it. ## Bug Report. ### Affected tool(s) or class(es); AnalyzeSaturationMutagenesis . ### Affected version(s); gatk4-4.3.0.0. ### Description ; Here it follows the output from Nextflow that appears on screen:. ```; Error executing process > 'gatk_count (gatk)'. Caused by:; Process `gatk_count (gatk)` terminated with an error exit status (247). Command executed:. gatk AnalyzeSaturationMutagenesis -I MITE6_P1_out.sam -R /home/tigem/f.panariello/Scratch/Cacchiarelli/MITE/QC_1804//i ndex/genome.fa --orf 1-5610 -O ./MITE6_P1. Command exit status:; 247. Command output:; (empty). Command error:; WARNING: Not mounting requested bind point (already mounted in container): /home/tigem/f.panariello; Using GATK jar /usr/local/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=f alse -Dsamjdk.compression_level=2 -jar /usr/local/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar AnalyzeSaturationMutagenesis -I MITE6_P1_out.sam -R /home/tigem/f.panariello/Scratch/Cacchiarelli/MITE/QC_1804//index/genome.fa --orf 1-5610 -O ./MIT E6_P1; 09:36:03.173 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/local/share/gatk4-4.3.0.0-0/gatk-package -4.3.0.0-local.jar!/com/intel/gkl/native/libgk",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8357:197,pipeline,pipeline,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8357,1,['pipeline'],['pipeline']
Deployability,"Hi!. Thank you for making this fix. . This is a blocking error for our [DepMap release](https://depmap.org/portal/) starting in 1 week. Would you have an ETA for when a dockerized version of gatk will be available with the fix?. Best,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1059127728:79,release,release,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1059127728,1,['release'],['release']
Deployability,"Hi, . I am testing the GATK beta 4.6 at the moment. It's a great improvement in time used to analyse data. Similarly I am interested in calling germline CNV events. I tried out the workflow with only two samples, just to find the right tools and see how it behaves. ; First I used `gatk-launch CalculateTargetCoverage` and `gatk-launch TargetCoverageSexGenotyper` and used the resulting files as input for `gatk-launch GermlineCNVCaller`. Unfortunatelly I got the following error when calling GermlineCNVCaller:. `A USER ERROR has occurred: Couldn't read file /media/Berechnungen/GATKTest/CN_transition_matrix_autosomal.tsvx. Error was: Could not read NDArray tsv file`. I found out that this error has something to do with Numpy. I have installed Numpy 1.13.1. ; Have you seen some error like this before?. Thanks in advance; Stefan",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3996:738,install,installed,738,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3996,1,['install'],['installed']
Deployability,"Hi, ; I am experimenting with submitting a PrintReadsSpark job to a yarn spark cluster in AWS. I run the job with the following command. ```; spark-submit --deploy-mode cluster --class org.broadinstitute.hellbender.Main --deploy-mode cluster --master yarn gatk-package-4.alpha.2-248-gcd449bf-SNAPSHOT-spark.jar PrintReadsSpark -I hdfs://chr1.bam -O hdfs://output.bam; ```. I can see from the output files that the job finished successfully, however the cluster tells me that it failed. It shows the following error message:. ```; 17/05/05 06:03:53 INFO ApplicationMaster: Final app status: FAILED, exitCode: 16, (reason: Shutdown hook called before final status was reported.); ```. I believe this may be due to the `System.exit(0)` statement at line 144 in hellbender.Main, though I am not sure. . Here is a more complete snippet from the stderr log. . ```; 17/05/05 06:03:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1; 17/05/05 06:03:52 WARN DFSClient: Caught exception ; java.lang.InterruptedException; 	at java.lang.Object.wait(Native Method); 	at java.lang.Thread.join(Thread.java:1249); 	at java.lang.Thread.join(Thread.java:1323); 	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609); 	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370); 	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546); 17/05/05 06:03:52 INFO FileOutputCommitter: Saved output of task 'attempt_20170505060336_0011_r_000001_0' to hdfs://ip-172-30-0-86.ec2.internal:8020/output.bam.parts/_temporary/0/task_20170505060336_0011_r_000001; 17/05/05 06:03:52 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 1921 bytes result sent to driver; 17/05/05 06:03:52 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 10260 ms on localhost (executor driver) (1/4); 17/05/05 06:03:53 INFO FileOutputCommitter: Saved output of task 'attempt_20170505060336_0011_r_000000_0' to ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2666:157,deploy,deploy-mode,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2666,2,['deploy'],['deploy-mode']
Deployability,"Hi, ; I have a suggestion that the updated verisons of Mutect2 method [pdfs](https://github.com/broadinstitute/gatk/blob/master/docs/mutect/mutect.pdf) should be kept. ; Of course we can look up from the git history log for what have changed in each edition, but it will be much more straightforward to obtain information from pdf file. Such as, [this picture](https://us.v-cdn.net/5019796/uploads/editor/8d/1rt7qtu6ohp2.png) ; in (this post)[https://gatkforums.broadinstitute.org/gatk/discussion/comment/56644#Comment_56644].; I know it comes from the Mutect2 method old version, but it was no longer here. Xiucz.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6001:35,update,updated,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6001,1,['update'],['updated']
Deployability,"Hi, ; This is the command I used:; `gatk GenomicsDBImport \; $tmp \; --genomicsdb-workspace-path /scratch/user/wild_gwas/$genomicsdb/${chr}_$pos \; --intervals $contig \; --batch-size 100`. $tmp is a list of 150 gvcfs. $contig is 100kb window in the genome. ; The OS version is:. > LSB; Version: n/a; Distributor ID: CentOS; Description: CentOS Linux release 7.4.1708 (Core); Release: 7.4.1708; Codename: Core. I'll try to do the tests kgururaj suggests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357001828:351,release,release,351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357001828,2,"['Release', 'release']","['Release', 'release']"
Deployability,"Hi, ; This is what i got when i run the command gatk --help ; (base) ameni@ameni-Aspire-A315-55G:~/Documents/pharmacogenomics$ gatk --help. Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster ; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after -- ; GCS: run using Google cloud dataproc; commands after the -- will be passed to dataproc; --cluster <your-cluster> must be specified after the --; spark properties and some common spark-submit parameters will be translated ; to dataproc equivalents. --dry-run may be specified to output the generated command line without running it; --java-options 'OPTION1[ OPTION2=Y ... ]' optional - pass the given string of options to the ; java JVM at runtime. ; Java options MUST be passed inside a single string with space-separated values. --debug-port <number> sets up a Java VM debug agent to listen to debugger connections on a; particular port number. This in turn will add the necessary java VM arguments; so that you don't need to explicitly indicate these using --java-options.; --debug-suspend sets the Java VM debug agent up so that the run get immediatelly suspended; waiting for a debugger to connect. By default the port number is 5005 but; can be customized using --debug-port.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8280:506,Configurat,Configuration,506,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8280,1,['Configurat'],['Configuration']
Deployability,"Hi, ; for those looking to run containers within a multi-user HPC environment, running a container with default root privileges presents a potential data security risk. Adding something like :. RUN useradd -ms /bin/bash gatk; WORKDIR /home/gatk; USER gatk. to the Docker file would greatly reduce the risk and bring the current containers in line with general best practice, e.g https://medium.com/@mccode/processes-in-containers-should-not-run-as-root-2feae3f0df3b. There should be no downsides to running in this manner. Singularity could help but the current configuration will be picked up and prevented from running by any site using a container security scanner, e.g. Aqua.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3644#issuecomment-494457377:562,configurat,configuration,562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3644#issuecomment-494457377,1,['configurat'],['configuration']
Deployability,"Hi, ; when i test gatk4 MarkDuplicatesSpark command on yarn cluster, i encountered an issue ""non zero exit code 13"". How can i fix it ? . Here is my command and what i received from the terminal :; ****; gatk MarkDuplicatesSpark -I hdfs://192.168.0.104:9000/user/jacky/NA12878.mapped.illumina.mosaik.CEU.exome.20110411.bam -O hdfs://192.168.0.104:9000/user/jacky/marked_dup.bam -M hdfs://192.168.0.104:9000/user/jacky/marked_dup_metrics.txt -- --spark-runner SPARK --deploy-mode cluster --spark-master yarn; Using GATK jar /home/jacky/Exec/gatk/build/libs/gatk-spark.jar; Running:; /home/jacky/spark/bin/spark-submit --master yarn --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.executor.memoryOverhead=600 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --deploy-mode cluster /home/jacky/Exec/gatk/build/libs/gatk-spark.jar MarkDuplicatesSpark -I hdfs://192.168.0.104:9000/user/jacky/NA12878.mapped.illumina.mosaik.CEU.exome.20110411.bam -O hdfs://192.168.0.104:9000/user/jacky/marked_dup.bam -M hdfs://192.168.0.104:9000/user/jacky/marked_dup_metrics.txt --spark-master yarn; 20/10/22 12:02:26 INFO client.RMProxy: Connecting to ResourceManager at /192.168.0.104:8032; 20/10/22 12:02:26 INFO yarn.Client: Requesting a new application from cluster with 2 NodeManagers; 20/10/22 12:02:26 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (1536 MB per container); 20/10/22 12:02:26 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6906:467,deploy,deploy-mode,467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906,1,['deploy'],['deploy-mode']
Deployability,"Hi, @jamesemery .I downloaded the `GTF` file for `basic gene annotation` in the CHR regions from gencode. The version I obtained was `Release 43 (GRCh38.p13)`. After making some modifications as follow, I managed to run SVAnnotate without encountering any errors. ; ```; sed 's/; tag ""Ensembl_canonical""//g' gencode.v43.basic.annotation.gtf|sed 's/; tag ""overlaps_pseudogene""//g'|sed 's/; tag ""readthrough_gene""//g'|sed 's/; tag ""artifactual_duplication""//g' > gencode.v43.basic.modified_annotation.gtf; ```; However, the tool still fails to provide meaningful annotation information. The output file remains unchanged compared to the original file. Based on the SVAnnotate output as follow, I suspect that the issue might be caused by 'Current Locus unmapped.' ; ```; 16:11:10.044 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/Division/1user/2_Exome/Tools/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 16:11:10.072 INFO SVAnnotate - ------------------------------------------------------------; 16:11:10.074 INFO SVAnnotate - The Genome Analysis Toolkit (GATK) v4.4.0.0; 16:11:10.074 INFO SVAnnotate - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:11:10.074 INFO SVAnnotate - Executing as user@localhost.localdomain on Linux v3.10.0-1160.90.1.el7.x86_64 amd64; 16:11:10.074 INFO SVAnnotate - Java runtime: Java HotSpot(TM) 64-Bit Server VM v17.0.7+8-LTS-224; 16:11:10.075 INFO SVAnnotate - Start Date/Time: 2023年7月5日 CST 下午4:11:10; 16:11:10.075 INFO SVAnnotate - ------------------------------------------------------------; 16:11:10.075 INFO SVAnnotate - ------------------------------------------------------------; 16:11:10.075 INFO SVAnnotate - HTSJDK Version: 3.0.5; 16:11:10.075 INFO SVAnnotate - Picard Version: 3.0.0; 16:11:10.076 INFO SVAnnotate - Built for Spark Version: 3.3.1; 16:11:10.076 INFO SVAnnotate - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:11:10.076 INFO SVAnnotate - ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8394#issuecomment-1621377138:134,Release,Release,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8394#issuecomment-1621377138,1,['Release'],['Release']
Deployability,"Hi, GATK team! I'm working on GATK WGS somatic CNV calling pipeline. . When I tried gatk --java-options ""-Xmx2800g"" ModelSegments --denoised-copy-ratios ${tumor}.denoisedCR.tsv --allelic-counts ${tumor}.allelicCounts.tsv --normal-allelic-counts ${normal}.allelicCounts.tsv --output-prefix ${tumor} -O ${outdir}, I got this type of error:. 10:00:18.408 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/lustre/home/acct-medliuyb/medliuyb-user1/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 10, 2022 10:00:18 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:00:18.544 INFO ModelSegments - ------------------------------------------------------------; 10:00:18.544 INFO ModelSegments - The Genome Analysis Toolkit (GATK) v4.2.0.0; 10:00:18.544 INFO ModelSegments - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:00:18.544 INFO ModelSegments - Executing as medliuyb-user1@huge2.pi.sjtu.edu.cn on Linux v3.10.0-1062.el7.x86_64 amd64; 10:00:18.545 INFO ModelSegments - Java runtime: OpenJDK 64-Bit Server VM v10.0.2+13; 10:00:18.545 INFO ModelSegments - Start Date/Time: January 10, 2022 at 10:00:18 AM CST; 10:00:18.545 INFO ModelSegments - ------------------------------------------------------------; 10:00:18.545 INFO ModelSegments - ------------------------------------------------------------; 10:00:18.545 INFO ModelSegments - HTSJDK Version: 2.24.0; 10:00:18.545 INFO ModelSegments - Picard Version: 2.25.0; 10:00:18.545 INFO ModelSegments - Built for Spark Version: 2.4.5; 10:00:18.545 INFO ModelSegments - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:00:18.546 INFO ModelSegments - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:00:18.546 INFO ModelSegments - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:00:18.546 INFO ModelSegments - HTSJDK Defaults",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7633:59,pipeline,pipeline,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7633,1,['pipeline'],['pipeline']
Deployability,"Hi, I also meet this issue. . The Specificity in `HaplotypeCallerSpark` was a bitter less than local mode in my test. Do you known which configuration can improve the Specificity in `HaplotypeCallerSpark` ? @Atahualkpa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5323#issuecomment-433815315:137,configurat,configuration,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5323#issuecomment-433815315,1,['configurat'],['configuration']
Deployability,"Hi, I think this can be closed now. . I just found that this issue might due to the inconsistency between gCNV version and PostProcessGermlineCNVCalls version. ; I updated my python configuration from 4.1.8.0 to 4.2.2.0 and the issue is gone. . Sorry for the troubles here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-908550017:164,update,updated,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-908550017,2,"['configurat', 'update']","['configuration', 'updated']"
Deployability,"Hi, I think this issue was driven by our use case. We have a GenomicsDBImport/GenotypeGVCFs pipeline that for efficient parallelisation purposes we would like to run on adjacent 10kb intervals. The problem is that we are interested in correctly calling spanning deletions that span across the interval boundaries. Here is an example of the first two variants of an interval starting at Pf3D7_07_v3:1400001; ; ```; Pf3D7_07_v3 1400001 . AG A,GG,CG 952.47 . AC=2,2,1; Pf3D7_07_v3 1400002 . GCCGAA *,ACCGAA,TCCGAA 236625 . AC=306,21,155; ```; ; And here are the same two variants, but this time from an interval starting before Pf3D7_07_v3:1400001:; ; ```; Pf3D7_07_v3 1400001 . AG *,A,GG,CG 952.47 . AC=304,1,2,1; Pf3D7_07_v3 1400002 . GCCGAA *,ACCGAA,TCCGAA 236625 . AC=306,21,155; ```; ; As you'll see, the first version is missing the spanning deletion at Pf3D7_07_v3:1400001. You'll also notice that the allele counts for the A allele are different between the two versions (2 vs 1). So for the interval Pf3D7_07_v3:1400001-1410000, we want the output to look like the second example above, not the first.; ; We are only interested in having calls for positions that lie within the interval, so in the above case we don't want to see any calls for position Pf3D7_07_v3:1400000 or earlier.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6335#issuecomment-567487326:92,pipeline,pipeline,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6335#issuecomment-567487326,1,['pipeline'],['pipeline']
Deployability,"Hi, I'm a GATK4 user and I apologize in advance if these questions can be answered in documentation: I could not find answers to these myself. Are releases not made alongside master branch changes? Is the master branch not a stable branch? I am every excited to try GATK with Java 17, however I'm unsure if it's time to test since there is not a release for this pull request. ; I also say this because I'm struggling to get `gradle` to build this on my machine for reasons unrelated to `GATK`, and I'm much more comfortable running an already-built `.jar`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1457147115:147,release,releases,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1457147115,2,['release'],"['release', 'releases']"
Deployability,"Hi, a small question (and maybe issue here). Does BwaSpark require the input bam to be queryname sorted ?. I have a pipeline doing `.fastq -> FastqToSam -> .bam -> BwaSpark -> Some other stuffs` and FastqToSam take time (40min) relative to the entire pipeline (2h).; I tried to speed-up it by creating a unsorted bam using -SO unsorted. It's faster but BwaSpark crashes. There is no indication in BwaSpark documentation and help it requires a name sorted bam. The only information about it is in the help message of `BwaAndMarkDuplicatesPipelineSpark`: ; > Takes name-sorted file and runs BWA and MarkDuplicates.; > Version:4.0.1.2. Is it a missing information ?. Additional question : could it be possible to do the conversion on Spark (FastqToSamSpark) ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4612:116,pipeline,pipeline,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4612,2,['pipeline'],['pipeline']
Deployability,"Hi, any news on this? will it be 4.1.4.1 or just a hotfix to 4.1.4.0? (just to be paying attention to a new version). Cheers and thanks for the amazing job!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6197#issuecomment-548801212:51,hotfix,hotfix,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6197#issuecomment-548801212,1,['hotfix'],['hotfix']
Deployability,"Hi, are there any available updates on this bug ? ; I have run into it many times with gatk-4.1.0.0.; Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-463926822:28,update,updates,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-463926822,1,['update'],['updates']
Deployability,"Hi, getting the same error trying to run this new mutect2 pipeline on CCLE. We will not annotate mutect2 with funcotator in the meantime but would also be very useful to us if this problem is solved! (it impacts ~15% of our samples). Thank you @jonn-smith !",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-943666506:58,pipeline,pipeline,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-943666506,1,['pipeline'],['pipeline']
Deployability,"Hi, i can't install gatk via conda/mamba. couldyou pls help; pls see steps that i took. ```; $conda config --add channels conda-forge; $conda config --add channels bioconda; $conda config --add channels defaults; $conda config --set channel_priority strict; ```. install command; ```; bash:iscxf001:/data1/greenbab/users/ahunos/apps/gatk-4.5.0.0 1023 $ conda env create -n gatk -f gatkcondaenv.yml; ```. ```; Channels:; - conda-forge; - defaults; - bioconda; Platform: linux-64; Collecting package metadata (repodata.json): done; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::typing_extensions==4.1.1; - conda-forge::theano==1.0.4; - pkgs/main::tensorflow==1.15.0; - conda-forge::scipy==1.0.0; - conda-forge::scikit-learn==0.23.1; - conda-forge::python==3.6.10; - bioconda::pysam==0.15.3; - conda-forge::pymc3==3.1; - conda-forge::pip==21.3.1; - conda-forge::pandas==1.0.3; - conda-forge::numpy==1.17.5; - conda-forge::mkl-service==2.3.0; - conda-forge::mkl==2019.5; - conda-forge::matplotlib==3.2.1; - conda-forge::keras==2.2.4; - conda-forge::joblib==1.1.1; - pkgs/main::intel-openmp==2019.4; - conda-forge::h5py==2.10.0; - conda-forge::dill==0.3.4. Current channels:. - https://conda.anaconda.org/conda-forge/linux-64; - https://repo.anaconda.com/pkgs/main/linux-64; - https://repo.anaconda.com/pkgs/r/linux-64; - https://conda.anaconda.org/bioconda/linux-64; - https://conda.anaconda.org/bioconda; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https:/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8838:12,install,install,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8838,2,['install'],['install']
Deployability,"Hi, it seems to work updating the environment and the software to the 4.2.2.0 release. I was using both the environment and the software from 4.2.0.0. Thank you and I apologize for bothering.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-946656357:78,release,release,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-946656357,1,['release'],['release']
Deployability,"Hi, since there is DOS (Denial of Service) threat for log4j 2.16.0(https://logging.apache.org/log4j/2.x/security.html),; is that possible to update GATK with log4j_2.17.0? Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7603#issuecomment-998102555:141,update,update,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7603#issuecomment-998102555,1,['update'],['update']
Deployability,"Hi, there:. I realize that GATK team released plenty of wonderful tutorials, best practice guidances, WDL scripts, etc. However, for users like me, I still prefer some simple and straight-forward BASH scripts that I could easily embed into existing pipelines and fire up. . Below is what I got from Chat-GPT. I tested it and it actually worked magically, processing my fasta.gz files into VCF. Can someone please kindly take a look at this, and let me know if there is some issue with this script?. Thank you very much & best regards,; Jie. ![image](https://github.com/broadinstitute/gatk/assets/26947455/12e2c577-2633-4189-a02c-ec45c677aa50)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8905:37,release,released,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8905,2,"['pipeline', 'release']","['pipelines', 'released']"
Deployability,"Hi,. Any updates on this? I'm running into the same error with v4.0.1.2. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4312#issuecomment-365632438:9,update,updates,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4312#issuecomment-365632438,1,['update'],['updates']
Deployability,"Hi,. I am on GATK v4.3.0.0 (CentOS) and would like to implement GermlineCNVCaller in my work. In an attempt to set up the conda environment (gcnvkernel) from zip using the command `conda env create -f gatkcondaenv.yml`, I got an error like this: `Found conflicts! Looking for incompatible packages.` . I also tried installing with tar, but I couldn't find gatkPythonPackageArchive.zip as required in the yml. Any help on this issue is much appreciated!. Java version: 1.8.0_201",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8091:315,install,installing,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8091,1,['install'],['installing']
Deployability,"Hi,. I am trying to call common and rare germline copy number variants with GATK 4, for more than 100 human samples based on human genome reference: hg19. For this project, I have 500 GB for memory, 10 TB for storage and 300 cpu cores. The program version is as below:. GATK Version: 4.1.2.0; Openjdk Version: 1.8.0_232; Python Version: 3.6.8. I didn't use the WDL way. I just follow the document of Notebook#11684 and build a local pipeline. I split the my project based on Chromosome, including (chr1, chr2, chr3, chr4, chr5, chr6, chr7, chr8, chr9, chr10, chr11, chr12, chr13, chr14, chr15, chr16, chr17, chr18, chr19, chr20, chr21, chr22, chrX, chrY, chrMT). After finish the pipeline, I am testing it with 6 samples. When I separately submit my script for each chromosome, every sub-project goes well: through my Input BAM Files, I can get the corresponding VCF Files (10 cores and 10 GB for each single project). That is to say, the environment of our GATK and Python for germline copy number variants calling should be OK. However, When I submit all the 25 sub-projects (12 cores and 12 GB for each single project) at the same time, I' m **randomly** suffering the two following PythonScriptExecutorException for some of the **random** sub-projects: . .............................................................(BUG 001).......................................................... Traceback (most recent call last):; File ""/tmp/cohort_determine_ploidy_and_depth.3351404099122294482.py"", line 8, in <module>; import gcnvkernel; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/__init__.py"", line 5, in <module>; from .distributions import *; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/pymc3/distributions/__init__.py"", line 1, in <module>; from . import times",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235:433,pipeline,pipeline,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235,2,['pipeline'],['pipeline']
Deployability,"Hi,. I am trying to test the pathseq tutorial following the tutorial on [this]( https://gatkforums.broadinstitute.org/gatk/discussion/10913/how-to-run-the-pathseq-pipeline ""this"") link. I ran the following commands. bioinfo@bioinfo$ conda activate gatk; (gatk) bioinfo@bioinfo$ gatk PathSeqPipelineSpark \; > --input test_sample.bam \; > --filter-bwa-image hg19mini.fasta.img \; > --kmer-file hg19mini.hss \; > --min-clipped-read-length 70 \; > --microbe-fasta e_coli_k12.fasta \; > --microbe-bwa-image e_coli_k12.fasta.img \; > --taxonomy-file e_coli_k12.db \; > --output output.pathseq.bam \; > --scores-output output.pathseq.txt. And encountered below error:. Using GATK jar /home/bioinfo/Installers/gatk4/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/bioinfo/Installers/gatk4/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar PathSeqPipelineSpark --input test_sample.bam --filter-bwa-image hg19mini.fasta.img --kmer-file hg19mini.hss --min-clipped-read-length 70 --microbe-fasta e_coli_k12.fasta --microbe-bwa-image e_coli_k12.fasta.img --taxonomy-file e_coli_k12.db --output output.pathseq.bam --scores-output output.pathseq.txt; 18:57:39.629 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 18:57:39.729 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/bioinfo/Installers/gatk4/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 18:57:41.594 INFO PathSeqPipelineSpark - ------------------------------------------------------------; 18:57:41.594 INFO PathSeqPipelineSpark - The Genome Analysis Toolkit (GATK) v4.1.0.0; 18:57:41.594 INFO PathSeqPipelineSpark - For support and documentation go to https://software.broadi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5802:163,pipeline,pipeline,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5802,3,"['Install', 'pipeline']","['Installers', 'pipeline']"
Deployability,"Hi,. I am using GATK `version gatk4-4.0.6.0-0` as part of the bcbio-nextgen pipeline for RNA-seq variant calling. There is one step in the pipeline i.e. `gatk GenomicsDBImport` that's been failing consistently no matter how less or many resources in terms of memory and cores I provide. I have tried to run the command as part of the pipeline and in stand-alone mode (like below) and both produce the same error:. ```; [rathik@reslnrefo01 log]$ gatk --java-options '-Xms454m -Xmx3181m -XX:+UseSerialGC' GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path CDL-164-04P-1_0_249250621_genomicsdb -L 1:1-249250621 --variant /mnt/isilon/cbmi/variome/rathik/mendelian_rnaseq/gatk_output/CDL-164-04P/variation/rnaseq/gatk-haplotype/Sample_1__CDL-164-04P-gatk-haplotype-annotated-rnaedit-annotated-gemini.vcf.gz; Using GATK jar /mnt/isilon/cbmi/variome/bin/bcbio-nextgen/bcbio/anaconda/share/gatk4-4.0.6.0-0/gatk-package-4.0.6.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms454m -Xmx3181m -XX:+UseSerialGC -jar /mnt/isilon/cbmi/variome/bin/bcbio-nextgen/bcbio/anaconda/share/gatk4-4.0.6.0-0/gatk-package-4.0.6.0-local.jar GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path CDL-164-04P-1_0_249250621_genomicsdb -L 1:1-249250621 --variant /mnt/isilon/cbmi/variome/rathik/mendelian_rnaseq/gatk_output/CDL-164-04P/variation/rnaseq/gatk-haplotype/Sample_1__CDL-164-04P-gatk-haplotype-annotated-rnaedit-annotated-gemini.vcf.gz; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/mnt/isilon/cbmi/variome/tmp/rathik; 11:49:24.784 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/mnt/isilon/cbmi/variome/bin/bcbio-nextgen/bcbio/anaconda/share/gatk4-4.0.6.0-0/gatk-package-4.0.6.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 11:49:25.130 INFO GenomicsDBImport - ------------------------------------------------------------; 11:49",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5045:76,pipeline,pipeline,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5045,3,['pipeline'],['pipeline']
Deployability,"Hi,. I report a bug here https://gatkforums.broadinstitute.org/gatk/discussion/23236/has-anyone-reported-the-new-release-4-0-12-0-calculatecontaminations-bug/p1?new=1.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5536:113,release,release-,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5536,1,['release'],['release-']
Deployability,"Hi,. I tried to use your new released GATK4 package to do CNV analysis. I know it's a beta tool... I followed the tools documentation and did ""CollectFragmentCounts"" first to get hdf5 files. After that I tried to run ""DetermineGermlineContigPloidy"" in cohort mode with these files. I created a ploidy_priors.tsv file like described in the documentation and used 8 hdf5-files. A few seconds after starting the tool I get the following error:. ```; [11. Januar 2018 16:42:24 MEZ]; org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=2294808576; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException:; python exited with 1; Command Line: python /tmp/die9s/cohort_determine_ploidy_and_depth.9149389425697869853.py --sample_coverage_metadata=/tmp/die9s/samples-by-coverage-per-contig814612566493224652.tsv --output_calls_path=/media/Berechnungen/CNV_analysis/GATK4/normal_cohort-calls --mapping_error_rate=1.000000e-02 --psi_s_scale=1.000000e-04 --mean_bias_sd=1.000000e-02 --psi_j_scale=1.000000e-03 --learning_rate=5.000000e-02 --adamax_beta1=9.000000e-01 --adamax_beta2=9.990000e-01 --log_emission_samples_per_round=2000 --log_emission_sampling_rounds=100 --log_emission_sampling_median_rel_error=5.000000e-04 --max_advi_iter_first_epoch=1000 --max_advi_iter_subsequent_epochs=1000 --min_training_epochs=20 --max_training_epochs=100 --initial_temperature=2.000000e+00 --num_thermal_epochs=20 --convergence_snr_averaging_window=5000 --convergence_snr_trigger_threshold=1.000000e-01 --convergence_snr_countdown_window=10 --max_calling_iters=1 --caller_update_convergence_threshold=1.000000e-03 --caller_admixing_rate=7.500000e-01 --disable_caller=false --disable_sampler=false --disable_annealing=false --interval_list=/tmp/die9s/intervals671187352630642175.tsv --contig_ploidy_prior_table=/media/Berechnungen/CNV_analysis/GATK4/ploidy_priors.tsv --output_model_path=/media/Berechnungen/CNV_analysis/GATK",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125:29,release,released,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125,1,['release'],['released']
Deployability,"Hi,. I'm working on the GATK pipeline with aim to find the best pipeline before start my project.; I never do VQSR before. I need your suggestion according to my result.; I using the NA12878 Exome data from SureSelect7 version with 4 difference main pipelines. All pipeline had follow the best practice option.; 1. BWA7.15-GATK3.7; 2. BWA7.15-GATK4.4; 3. DRAMAP1.2.1-GATK4.4; 4. DRAMAP1.2.1-GATK4.4-dragen. I have questions about the number of variant output and VQSR plot from each pipeline; BWA-GATK3.7 pipeline gave me 100694 variants; BWA-GATK4.4 pipeline gave me 45861 variants; DRAMAP-GATK4.4 gave me 44835 variants; DRAMAP-GATK4.4-dragen gave me 42969 variants. For the VQSR tranchs plot; 1. BWA-GATK3.7; ![image](https://github.com/broadinstitute/gatk/assets/15682256/7d158c0b-d0af-4e5e-a605-993fad38cc0b). 2. BWA-GATK4.4; ![image](https://github.com/broadinstitute/gatk/assets/15682256/1898f5f0-cfa4-476c-8637-9a4ea3333f49). 3. DRAMAP-GATK4.4; ![image](https://github.com/broadinstitute/gatk/assets/15682256/52f6e56c-7dc5-4047-9086-2a9fb37f478f). 4. DRAMAP-GATK4.4-dragen; ![image](https://github.com/broadinstitute/gatk/assets/15682256/20bfc543-ad76-4e3d-a2ba-693cbed46a92). From what I see it far from Ti/Tv ratio that suitable for whole exome sequencing as ~ 2.8. Please give me some suggestion. ; Which pipeline I should selected as the best pipeline for my project. Thanks,; GM",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8435:29,pipeline,pipeline,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8435,9,['pipeline'],"['pipeline', 'pipelines']"
Deployability,"Hi,. I've encountered an issue with the R script generated by `VariantRecalibrator` during my analysis. The generated R script uses color functions (`scale_fill_gradient`) where the RGB color space is still being employed to calculate the gradient. However, in newer versions of R, the ggplot2 and scales libraries have deprecated the RGB color space, and the library now requires the ""Lab"" color space to calculate the gradient. This issue causes the R script to fail unless it is later modified by the user to use `scale_fill_gradient(..., space = ""Lab"")`. Updating the script generation in `VariantRecalibrator` would prevent this problem and make the R script compatible with newer versions of R, and ggplot2. an scales libraries. Here is the suggested change:. update : scale_fill_gradient(..., space = ""rgb""); to : scale_fill_gradient(..., space = ""Lab""). Versions:. The Genome Analysis Toolkit (GATK) v4.6.0.0; HTSJDK Version: 4.1.1; Picard Version: 3.2.0. RStudio 2024.04.2+764 ""Chocolate Cosmos"" Release (e4392fc9ddc21961fd1d0efd47484b43f07a4177, 2024-06-05) for Ubuntu Jammy; Library scales 1.3.0; library ggplot2 3.51",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8992:766,update,update,766,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8992,2,"['Release', 'update']","['Release', 'update']"
Deployability,"Hi,. When I try to run Funcotator, using the below command:. gatk Funcotator \; --variant /rsrch5/home/tdccct/ppshah/shared/CAS_MOSAIC/mutect/mrn_2507919/WES/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC_filtered.vcf.gz \; --reference /rsrch5/home/tdccct/ppshah/shared/gencode/Homo_sapiens/GATK/GRCh38/Sequence/WholeGenomeFasta/Homo_sapiens_assembly38.fasta \; --ref-version hg38 \; --data-sources-path /rsrch5/home/tdccct/ppshah/shared/pipelines/mutect/funcotator_dataSources.v1.7.20200521s \; --output /rsrch5/home/tdccct/ppshah/shared/CAS_MOSAIC/mutect/mrn_2507919/WES/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC_funcotated.vcf \; --output-file-format VCF; ; I get the following error:; ; Using GATK jar /gatk/gatk-package-4.4.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.4.0.0-local.jar Funcotator --variant /home/ppshah/shared/CAS_MOSAIC/mutect/mrn_2507919/WES/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC_filtered.vcf.gz --reference /home/ppshah/shared/gencode/Homo_sapiens/GATK/GRCh38/Sequence/WholeGenomeFasta/Homo_sapiens_assembly38.fasta --ref-version hg38 --data-sources-path /home/ppshah/shared/pipelines/mutect/funcotator_dataSources.v1.7.20200521s --output /home/ppshah/shared/CAS_MOSAIC/mutect/mrn_2507919/WES/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC_funcotated.vcf --output-file-format VCF; 16:36:22.352 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.4.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 16:36:22.392 INFO Funcotator - ------------------------------------------------------------; 16:36:22.396 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8647:499,pipeline,pipelines,499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8647,1,['pipeline'],['pipelines']
Deployability,"Hi,; Copying and running the `spark-submit` command run by gatk-launch, I found out the parameter `spark.driver.userClassPathFirst` is set to true, and if I set to false it runs well (well, my job has an error but because of my data ^^) when running in cluster mode.; Here, my command which works:; > spark-submit --master yarn \; > --conf 'spark.driver.userClassPathFirst=false' --conf 'spark.io.compression.codec=lzf' --conf 'spark.driver.maxResultSize=0' --conf 'spark.executor.extraJavaOptions=""-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1""' \; > --conf 'spark.driver.extraJavaOptions=""-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1""' \; > --conf 'spark.kryoserializer.buffer.max=512m' --conf 'spark.yarn.executor.memoryOverhead=600' \; > --conf 'spark.submit.deployMode=cluster' \; > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-package-4.beta.6-spark.jar BwaSpark --programName gatk4-bwa-test --input hdfs://spark01:7222/user/axverdier/data/phalstedii/PLHAL710.710.unmappedReads.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_BWA_BwaSpark.bam --reference hdfs://spark01:7222/user/axverdier/data/phalstedii/Plhal710r1.1.fa. I didn't find out how to override `spark.driver.userClassPathFirst` to false in the gatk-launch command, it seems to be ignored or replaced by true.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350717821:1066,deploy,deployMode,1066,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350717821,1,['deploy'],['deployMode']
Deployability,"Hi,; Currently, using spark tools, we can set the runner and master using --sparkRunner and sparkMaster.; However, there is not similar parameter to set the deploy-mode so we have to manually set it using --conf.; For example , the following parameters are currently used in the command-line to run on a yarn+cluster spark environment : ; `--sparkRunner SPARK --sparkMaster yarn --conf 'spark.submit.deployMode=cluster'`; It's not very user-friendly, a sparkDeployMode parameter could be usefull :; `--sparkRunner SPARK --sparkMaster yarn --sparkDeployMode cluster`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933:157,deploy,deploy-mode,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933,2,['deploy'],"['deploy-mode', 'deployMode']"
Deployability,"Hi,; I am trying to build from gatk-4 master sources. I received this error code `2` admitedly when I had no git-lfs installed. Now it is installed and in my PATH, but the error still occurs. Can't you capture the real error message?. ```; 22:05:55.883 [QUIET] [system.out] Executing: git lfs pull --include src/main/resources/large; 22:05:55.943 [DEBUG] [org.gradle.configuration.project.BuildScriptProcessor] Timing: Running the build script took 12.879 secs; 22:05:55.952 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.954 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] FAILURE: Build failed with an exception.; 22:05:55.955 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.956 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Where:; 22:05:55.956 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Build file '/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle' line: 102; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * What went wrong:; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] A problem occurred evaluating root project 'gatk'.; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:117,install,installed,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,3,"['configurat', 'install']","['configuration', 'installed']"
Deployability,"Hi,; I am trying to generate vcf using GATK pipeline from bam file, but everytime, I am getting the following exception:; 01:13:15.801 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data1/ngs/programs/gatk-4.0.0.0/gatk-package-4.0.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 01:13:16.075 INFO HaplotypeCaller - ------------------------------------------------------------; 01:13:16.075 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.0.0.0; 01:13:16.075 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 01:13:16.076 INFO HaplotypeCaller - Executing as shashank@grande on Linux v3.13.0-79-generic amd64; 01:13:16.076 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_72-internal-b15; 01:13:16.076 INFO HaplotypeCaller - Start Date/Time: January 18, 2020 1:13:15 AM IST; 01:13:16.076 INFO HaplotypeCaller - ------------------------------------------------------------; 01:13:16.076 INFO HaplotypeCaller - ------------------------------------------------------------; 01:13:16.077 INFO HaplotypeCaller - HTSJDK Version: 2.13.2; 01:13:16.077 INFO HaplotypeCaller - Picard Version: 2.17.2; 01:13:16.077 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 01:13:16.078 INFO HaplotypeCaller - Deflater: IntelDeflater; 01:13:16.078 INFO HaplotypeCaller - Inflater: IntelInflater; 01:13:16.078 INFO HaplotypeCaller - GCS max retries/reopens: 20; 01:13:16.078 INFO HaplotypeCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 01:13:16.078 INFO HaplotypeCaller - Initializing engine; 01:13:17.087 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6384:44,pipeline,pipeline,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6384,1,['pipeline'],['pipeline']
Deployability,"Hi,; I am trying to generate vcf using GATK pipeline from bam file, but everytime, I am getting the following exception:; 01:13:15.801 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data1/ngs/programs/gatk-4.0.0.0/gatk-package-4.0.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 01:13:16.075 INFO HaplotypeCaller - ------------------------------------------------------------; 01:13:16.075 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.0.0.0; 01:13:16.075 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 01:13:16.076 INFO HaplotypeCaller - Executing as shashank@grande on Linux v3.13.0-79-generic amd64; 01:13:16.076 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_72-internal-b15; 01:13:16.076 INFO HaplotypeCaller - Start Date/Time: January 18, 2020 1:13:15 AM IST; 01:13:16.076 INFO HaplotypeCaller - ------------------------------------------------------------; 01:13:16.076 INFO HaplotypeCaller - ------------------------------------------------------------; 01:13:16.077 INFO HaplotypeCaller - HTSJDK Version: 2.13.2; 01:13:16.077 INFO HaplotypeCaller - Picard Version: 2.17.2; 01:13:16.077 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 01:13:16.078 INFO HaplotypeCaller - Deflater: IntelDeflater; 01:13:16.078 INFO HaplotypeCaller - Inflater: IntelInflater; 01:13:16.078 INFO HaplotypeCaller - GCS max retries/reopens: 20; 01:13:16.078 INFO HaplotypeCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 01:13:16.078 INFO HaplotypeCaller - Initializing engine; 01:13:17.087 INF",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-575601220:44,pipeline,pipeline,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-575601220,1,['pipeline'],['pipeline']
Deployability,"Hi,; I recently started getting error messages when running a Nextflow pipeline for WGS analysis. I am using GATK 4.0.1.2 and was wondering whether:. /bin/env python - too many levels of symbolic links. may have to do with a broken conda environment (which GATK seems to use)? This happens for tools such as GenomicsDBImport. If I run the job in question outside of Nextflow, it seems to start just fine. But as far as I know Nextflow does not use python, so doesn't look like the obvious culprit.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4459:71,pipeline,pipeline,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4459,1,['pipeline'],['pipeline']
Deployability,"Hi,; I recently used GATK4 Spark local version for somatic variant call. The machine has 40 cores and 160g mem. I tried 20 and 10 cores for each tumor/normal pair in the BQSR step (BaseRecalibratorSpark) and the two samples are processed at the same time. However, the pipeline frequently failes (errors like outofmemory, cannot allocate a page) unless I use 4 cores for each sample. I think the problem should be solved by tuning Spark and JAVA parameters. I considered options like `--conf spark.driver.memory=10g`, `-XX:ParallelGCThreads=10` but had no luck. Can someone suggest the parameter options that I should look at? . Thanks,. -Han",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3465:269,pipeline,pipeline,269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3465,1,['pipeline'],['pipeline']
Deployability,"Hi,; I tried your commands (and many adaptions / changements) but I always get the same problem:; If the command line includes `--`, I get the JNI linkage error as if the spark related parameters were not parsed.; I tried many things, as:; > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input hdfs://spark01:7222/user/axverdier/data/710-PE-G1.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_CountReadsSpark --javaOptions -Dmapr.library.flatclass -- --sparkRunner SPARK --sparkMaster yarn --deploy-mode cluster; > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input hdfs://spark01:7222/user/axverdier/data/710-PE-G1.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_CountReadsSpark --javaOptions -Dmapr.library.flatclass --sparkRunner SPARK --sparkMaster yarn -- --master yarn --deploy-mode cluster. > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input hdfs://spark01:7222/user/axverdier/data/710-PE-G1.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_CountReadsSpark --javaOptions -Dmapr.library.flatclass --sparkRunner SPARK --sparkMaster yarn -- --master yarn --deploy-mode cluster --conf spark.driver.extraJavaOptions='-Dmapr.library.flatclass' --conf spark.executor.extraJavaOptions='-Dmapr.library.flatclass'. > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input hdfs://spark01:7222/user/axverdier/data/710-PE-G1.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_CountReadsSpark --javaOptions -Dmapr.library.flatclass --sparkRunner SPARK --sparkMaster yarn -- --master yarn --deploy-mode cluster --driver-java-options '-Dmapr.library.flatclass'. It's a non-exhaustive list, I tried a lot of configurations similar to these ones.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350227061:557,deploy,deploy-mode,557,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350227061,5,"['configurat', 'deploy']","['configurations', 'deploy-mode']"
Deployability,"Hi,; I update GATK today.; After 158 minutes variant calling on the same bam files, I have another issue :. ```; [3 décembre 2019 13:57:42 CET] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 158.34 minutes.; Runtime.totalMemory()=28647096320; Exception in thread ""main"" java.lang.OutOfMemoryError: GC overhead limit exceeded; 	at java.util.LinkedHashMap$LinkedKeySet.iterator(LinkedHashMap.java:543); 	at java.util.HashSet.iterator(HashSet.java:173); 	at java.util.AbstractCollection.toArray(AbstractCollection.java:137); 	at java.util.LinkedList.addAll(LinkedList.java:408); 	at java.util.LinkedList.addAll(LinkedList.java:387); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.graphs.BaseGraph$BaseGraphIterator.next(BaseGraph.java:774); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.graphs.BaseGraph$BaseGraphIterator.next(BaseGraph.java:723); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.graphs.BaseGraph.removePathsNotConnectedToRef(BaseGraph.java:505); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.getAssemblyResult(ReadThreadingAssembler.java:514); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.createGraph(ReadThreadingAssembler.java:492); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.assemble(ReadThreadingAssembler.java:401); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.runLocalAssembly(ReadThreadingAssembler.java:148); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:290); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:224); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:320); 	at org.broadinstitute.hellben",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-561188674:7,update,update,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-561188674,1,['update'],['update']
Deployability,"Hi,; I use your software with docker swarm where is deploy spark and hadoop the configuration for docker image is this:; ```; FROM bde2020/spark-master:2.2.0-hadoop2.8-hive-java8. MAINTAINER Jhonattan Loza <toro.ryan.jcl@gmail.com>. COPY picard.jar /; COPY GenomeAnalysisTK_v3.8-0-ge9d806836.jar /. RUN curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash; RUN apt-get install -y git-lfs; RUN git lfs install; RUN apt-get install unzip; RUN apt-get install wget; RUN apt-get install git. RUN mkdir /gatk; RUN apt-get update && apt-get install -y python git mlocate htop && export JAVA_TOOL_OPTIONS=-Dfile.encoding=UTF8 && \; wget https://github.com/broadinstitute/gatk/releases/download/4.0.4.0/gatk-4.0.4.0.zip && unzip gatk-4.0.4.0.zip -d tmp && mv tmp/gatk-4.0.4.0/* /gatk && cp /spark/conf/spark-defaults.conf.template /spark/conf/spark-defaults.conf && \; echo ""spark.eventLog.enabled true"" >> /spark/conf/spark-defaults.conf && \; echo ""spark.eventLog.dir file:///spark/logs/"" >> /spark/conf/spark-defaults.conf. ENV PATH=""$PATH:/spark/bin""; ```; I have this configurations for docker-compose:; - Spark. ```; version: '3'; services:; spark-master:; image: atahualpa/spark-master:GATK4.0.4; networks:; - workbench; deploy:; replicas: 1; mode: replicated; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8080; env_file:; - ./hadoop.env; ports:; - 8333:8080; - 4040:4040; - 6066:6066; - 7077:7077; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/fastq/:/fastq/; - /data0/NGS-SparkGATK/NGS-SparkGATK/:/NGS-SparkGATK/; - /data/ngs/:/ngs/; - /data0/output/:/output/; spark-worker:; image: bde2020/spark-worker:2.2.0-hadoop2.8-hive-java8; networks:; - workbench; environment:; - SPARK_MASTER=spark://spark-master:7077; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8081. env_file:; - ./hadoop.env; volumes:; - referen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:52,deploy,deploy,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,11,"['configurat', 'deploy', 'install', 'release', 'update']","['configuration', 'deploy', 'install', 'releases', 'update']"
Deployability,"Hi,; May I ask when this mitochondria pipeline will be available? ; In the meanwhile, if I use Mutect2 for calling human MT variants (including indel), which is the best choice of parameters?; I have MT bam file to start with and read coverage is in thousand scale for MT.; Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-427039803:38,pipeline,pipeline,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-427039803,1,['pipeline'],['pipeline']
Deployability,"Hi,; Our spark installation use a mapr filesystem ( hdfs compatible ).; GATK spark tools does not seems to recognize it.; When running the following command:; > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input maprfs://spark-ics/user/axverdier/data/710-PE-G1.bam --output maprfs://spark-ics/user/axverdier/testOutGATK_CountReadsSpark --sparkRunner SPARK --sparkMaster yarn --javaOptions -Dmapr.library.flatclass; I got the following error!. > Driver stacktrace:; > 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1436); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1424); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); > 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); > 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); > 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1423); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); > 	at scala.Option.foreach(Option.scala:257); > 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1651); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1606); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1595); > 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); > 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); > 	at org.apache.spark.SparkCo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936:15,install,installation,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936,1,['install'],['installation']
Deployability,"Hi,; The HaplotypeCaller_GATK4_VCF task in the gatk4-exome-analysis-pipeline doesn't seem to add any interval padding. Shouldn't there be interval padding?. Unless the configured Broad intervals already have padding added, but it is not clear why that would be, since that same file is used for calculating HsMetrics, which should not have padding. The question is, for my own implementation of this pipeline, should I add on interval padding to the interval list file? And if so, what size padding? Or should I add the interval padding option to the HaplotypeCaller itself in the wdl script. Thanks for any advice on this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6071:68,pipeline,pipeline,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6071,2,['pipeline'],['pipeline']
Deployability,"Hi,; during compilation of 3.8 sources I get. ```; [INFO] --- exec-maven-plugin:1.2.1:exec (delete-mavens-links) @ gatk-aggregator ---; rm: missing operand; Try 'rm --help' for more information.; rm: missing operand; Try 'rm --help' for more information.; [INFO] ; [INFO] --- maven-failsafe-plugin:2.16:integration-test (integration-tests) @ gatk-aggregator ---; ```. I have no idea whether it breaks something downstream but provided building fails for me later with. ```; [INFO] Reactor Summary:; [INFO] ; [INFO] GATK Root .......................................... SUCCESS [ 16.744 s]; [INFO] GATK Aggregator .................................... SUCCESS [ 4.647 s]; [INFO] GATK GSALib ........................................ SUCCESS [ 6.040 s]; [INFO] GATK Utils ......................................... SUCCESS [ 39.733 s]; [INFO] GATK Engine ........................................ SUCCESS [ 7.557 s]; [INFO] GATK Tools Public .................................. SUCCESS [ 7.689 s]; [INFO] External Example ................................... FAILURE [ 0.051 s]; [INFO] GATK Queue ......................................... SKIPPED; [INFO] GATK Queue Extensions Generator .................... SKIPPED; [INFO] GATK Queue Extensions Public ....................... SKIPPED; [INFO] GATK Aggregator Public ............................. SKIPPED; [INFO] GATK Tools Protected ............................... SKIPPED; [INFO] GATK Package Distribution .......................... SKIPPED; [INFO] GATK Queue Extensions Distribution ................. SKIPPED; [INFO] GATK Queue Package Distribution .................... SKIPPED; [INFO] GATK Aggregator Protected .......................... SKIPPED; [INFO] GATK Tools Private ................................. SKIPPED; [INFO] GATK Package Internal .............................. SKIPPED; [INFO] NA12878 KB Utilities ............................... SKIPPED; [INFO] GATK Queue Private ................................. SKIPPED; [INFO] GATK Queue Extensions Inter",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4686:303,integrat,integration-test,303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4686,2,['integrat'],"['integration-test', 'integration-tests']"
Deployability,"Hi,; first of all, I find it very awkward that after 3.8 release there is 3.8-1. Why the dash instead of a dot, as usual? It only complicates automated package downloads which in general work with numbers separated by dots. You just mix together two schemes. Is that really necessary?. Anyway, the pom.xml is broken:. ```; >>> Preparing source in /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1 ...; Equivalent maven command; mvn -Dmaven.repo.local=/scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/.m2/repository verify '-Ddisable.shadepackage'; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @ ; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR] ; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR] ; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR] ; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelPar",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4685:57,release,release,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4685,1,['release'],['release']
Deployability,"Hi,; in the last months for my Master thesis project I've studied your tool, with this pipeline:. ![ngs_pipeline_gatk](https://user-images.githubusercontent.com/10074137/47147968-ae5a0b00-d2cf-11e8-9fd6-15cd23fbcdcf.png); in spark version, yes, I know is still in beta but I’ve found these problems when I compared the outputs from Haplotypecaller in spark and in not Spark versions. For comparing these results I've used this tool [https://drive.google.com/file/d/1r2WHyiz5WqOIyY_EZ1VZt92wGlL19SE4/view?usp=sharing](url) and I've obtained these plots for sensitivity and specificity( The sensitivity is defined as the number of sites inwhich both sequencing and microarrays detected a deviation from the reference sequencedivided by the number of sites where a variant was detected by using the microarrays). **Spark**; Sensitivity; ![spark_sensitivity_hg19](https://user-images.githubusercontent.com/10074137/47148261-86b77280-d2d0-11e8-8b5a-9ecfef16d889.png); Specificity; ![sparkspecificityhg19](https://user-images.githubusercontent.com/10074137/47148277-933bcb00-d2d0-11e8-97eb-1adceb4e5ee2.png). **Local non Spark tool with GATK 2.7**; ![hg19local](https://user-images.githubusercontent.com/10074137/47148427-fcbbd980-d2d0-11e8-87d8-04ec20c1005d.png); furthermore I've executed the pipeline until BQSR in Spark version and after, I am focused just on Haplotypecaller because I've used this ""backwards"" approach and I've discovered that the pipeline is deterministic from the phase Variant Discovery, but don't in the phase of Preprocessing because when I've executed this phase more times, I've obtained results completely, this is the test with one single sample:; ![comparisons_pfc32](https://user-images.githubusercontent.com/10074137/47148552-49071980-d2d1-11e8-8b1c-aec468285699.png); furthermore when I've used the output from BQSR (executed in Spark) for execute of Haplotypecaller in local(not in Spark) and adapting this output for Haplotypecaller, I had to use the tool Samtools for s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5323:87,pipeline,pipeline,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5323,1,['pipeline'],['pipeline']
Deployability,"Hi. I failed to build GATK4. . I am a very beginner of bioinformatics and data science. ; I am using google VM ubuntu. ; I downloaded gatk-4.4.0.0. Step by step, I tried to build GATK4. (https://github.com/broadinstitute/gatk/blob/master/README.md#building). I made a gitclone using ; wget https://github.com/broadinstitute/gatk. and entered gatk folder. ; there was a gradlew.; and I entered ; ./gradlew bundle ; or; ./gradlew. but it failed to build GATK4 with following errors. . ====================================; OpenJDK 64-Bit Server VM warning: Insufficient space for shared memory file:; 30934; Try using the -Djava.io.tmpdir= option to select an alternate temp location. FAILURE: Build failed with an exception. * What went wrong:; Gradle could not start your build.; > Cannot create service of type DependencyLockingHandler using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyLockingHandler() as there is a problem with parameter #2 of type ConfigurationContainerInternal.; > Cannot create service of type ConfigurationContainerInternal using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createConfigurationContainer() as there is a problem with parameter #13 of type DefaultConfigurationFactory.; > Cannot create service of type DefaultConfigurationFactory using DefaultConfigurationFactory constructor as there is a problem with parameter #2 of type ConfigurationResolver.; > Cannot create service of type ConfigurationResolver using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyResolver() as there is a problem with parameter #1 of type ArtifactDependencyResolver.; > Cannot create service of type ArtifactDependencyResolver using method DependencyManagementBuildScopeServices.createArtifactDependencyResolver() as there is a problem with parameter #4 of type List<ResolverProviderFactory>.; > Could not create service of type VersionControlRepositoryConnect",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8346:1001,Configurat,ConfigurationContainerInternal,1001,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8346,1,['Configurat'],['ConfigurationContainerInternal']
Deployability,HlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdBc3NlbWJsZXIuamF2YQ==) | `52.479% <100%> (-13.636%)` | `29 <0> (-20)` | |; | [...hellbender/engine/spark/IntervalWalkerContext.java](https://codecov.io/gh/broadinstitute/gatk/pull/6047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvSW50ZXJ2YWxXYWxrZXJDb250ZXh0LmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...ls/walkers/mutect/filtering/BaseQualityFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/6047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9maWx0ZXJpbmcvQmFzZVF1YWxpdHlGaWx0ZXIuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...nder/tools/readersplitters/SampleNameSplitter.java](https://codecov.io/gh/broadinstitute/gatk/pull/6047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9yZWFkZXJzcGxpdHRlcnMvU2FtcGxlTmFtZVNwbGl0dGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-2%)` | |; | [...nder/tools/spark/pipelines/CountVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/6047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...broadinstitute/hellbender/utils/svd/SimpleSVD.java](https://codecov.io/gh/broadinstitute/gatk/pull/6047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zdmQvU2ltcGxlU1ZELmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...lbender/tools/walkers/mutect/clustering/Datum.java](https://codecov.io/gh/broadinstitute/gatk/pull/6047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9jbHVzdGVyaW5nL0RhdHVtLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-7%)` | |; | ... and [1845 more](https://codecov.io/gh/broadinstitute/gatk/pull/6047/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6047#issuecomment-513288952:3141,pipeline,pipelines,3141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6047#issuecomment-513288952,1,['pipeline'],['pipelines']
Deployability,"Hm. Just yesterday we updated from TF 1.4 to 1.9. Although this makes it more compelling to switch the default to Intel-optimized, we may still have an issue for the reasons outlined in the previous PR (academic users, not all GCS zones guaranty AVX hardware, and its still unclear to me if Travis, which uses both GCS and EC2, makes such a guaranty). It [sounds like](https://github.com/tensorflow/tensorflow/issues/18689) the failure mode is to crash. For running inference at least (training may be a different story), we may need something better. Another option is that it sounds like its possible to build our own distribution without AVX dependencies to use as a fallback.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429316465:22,update,updated,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429316465,1,['update'],['updated']
Deployability,"Hmm ok @droazen, I bow to your preference (if not entirely to your logic). Nice update overall by the way 👍",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310784825:80,update,update,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310784825,1,['update'],['update']
Deployability,"Hmm, I also realize that I did not update the base Docker image at that time---although I commented in the PR that we should...and I don't think we updated it before release. So I *think* the latest base and the current 4.0.0.0 release Docker contain the getopt dependency, although it was removed from the installation script.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359984275:35,update,update,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359984275,5,"['install', 'release', 'update']","['installation', 'release', 'update', 'updated']"
Deployability,"Hmm, I am also getting intermittent build errors like the following much more often:. ```; Could not determine the dependencies of task ':sparkJar'.; > Could not resolve all files for configuration ':sparkConfiguration'.; > Could not download gson.jar (com.google.code.gson:gson:2.2.2); > Could not get resource 'https://repo.maven.apache.org/maven2/com/google/code/gson/gson/2.2.2/gson-2.2.2.jar'.; > Could not GET 'https://repo.maven.apache.org/maven2/com/google/code/gson/gson/2.2.2/gson-2.2.2.jar'. Received status code 403 from server: Forbidden; > Could not download core.jar (com.github.fommil.netlib:core:1.1); > Could not get resource 'https://repo.maven.apache.org/maven2/com/github/fommil/netlib/core/1.1/core-1.1.jar'.; > Could not GET 'https://repo.maven.apache.org/maven2/com/github/fommil/netlib/core/1.1/core-1.1.jar'. Received status code 403 from server: Forbidden; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601832142:184,configurat,configuration,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601832142,1,['configurat'],['configuration']
Deployability,"Hmm, actually, let me take a second look at this. I think I got a bit confused looking back at the original forum post by the fact that two different users were posting about slightly different scenarios. I'll do some more testing of edge cases just to make sure I'm not missing anything. Apologies, but it's been a while since I opened this, so I need to refresh my memory!. EDIT: OK, I think I understand things now and edited the previous comment to remove confusing/misleading remarks. I'm OK with merging this for this release if you are, and we can look at the NaN issue later---doesn't seem to have caused any serious issues thus far...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-705868335:524,release,release,524,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-705868335,1,['release'],['release']
Deployability,"Hmm, looks like we lose events 1 and 3 with CollectReadCounts at 250bp using analogous ModelSegments parameters. However, I experimented with tweaking the segmentation to work on the copy ratios (rather than the log2 copy ratios), which seems to recover them. Although one of the goals of having evaluations backed by SV truth sets is to tune such parameters/methods, I'm beginning to think that SV integration might benefit from using the CNV tools in a more customized pipeline---especially if maximizing sensitivity at resolutions of ~100bp jointly with breakpoint evidence is the goal. For example, you might imagine a tool that directly uses CNV backend code to collect coverage over regions specified by `-L`, builds a PoN, denoises, and segments on the fly. Or we can put together a custom WDL optimized for sensitivity. Let's discuss in person?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222:399,integrat,integration,399,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222,2,"['integrat', 'pipeline']","['integration', 'pipeline---especially']"
Deployability,"Hmm, perhaps we should consider an additional PR to either set the default value to give the old behavior (i.e., equal to the ‘psi_j_scale’ default) or change all defaults for all parameters to whatever we are using now. Either way, we should mention in the release notes that models may need to be refit @mwalker174.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6285#issuecomment-558588547:258,release,release,258,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6285#issuecomment-558588547,1,['release'],['release']
Deployability,Hook arguments from SelectVariants/GenotypeGVCFs/GnarlyGenotyper to GenomicsDB Export Configuration,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6456:86,Configurat,Configuration,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6456,1,['Configurat'],['Configuration']
Deployability,Hopefully @droazen or @jamesemery would be willing to work on a patch in Valentin's absence?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7060#issuecomment-769358711:64,patch,patch,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7060#issuecomment-769358711,1,['patch'],['patch']
Deployability,Hopefully one final integration run going here https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/99e98043-4606-4a6e-89e8-4a6eb2994bdb,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8505#issuecomment-1701586906:20,integrat,integration,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8505#issuecomment-1701586906,1,['integrat'],['integration']
Deployability,How did you install the GATK Conda environment? Looks like a problem with the conda environment configuration. One possible reason could be that conda environment is not the version 4.3.0.0 is requesting.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8952#issuecomment-2287925550:12,install,install,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8952#issuecomment-2287925550,2,"['configurat', 'install']","['configuration', 'install']"
Deployability,How does GATK4 Accept Sharded Data and SNP&Indels calling Pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3141:58,Pipeline,Pipeline,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3141,1,['Pipeline'],['Pipeline']
Deployability,"How much does count collection cost at the desired bin size? How does this compare to bincov? Perhaps we could eliminate one of these steps if redundant. Note that the read counts are read once and stored in memory, so unless this takes a significant amount of time, then indexing is probably not the highest priority here (although I agree it would be nice to have in general). One related issue, as you mention, is file localization---since each shard only operates on a portion of the counts in each sample, it is a bit wasteful to localize the whole file. But how much does file localization cost? I can't imagine that it is the lowest hanging fruit. One of the more important issues, which you also mention, is optimizing parameters for inference. This includes not only the minimum number of epochs for training, but also things like the learning rate, annealing schedule, iterations per epoch, conditions for epoch convergence, etc. I'll be talking about how to tune these inference parameters---as well as other things in the pipeline---at the next BSV meeting. Let's brainstorm more things to try and prioritize them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5288#issuecomment-427562932:1034,pipeline,pipeline---at,1034,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5288#issuecomment-427562932,2,['pipeline'],['pipeline---at']
Deployability,"How much memory are you giving java (-Xmx parameter) and how much total; memory does the VM have? I've seen odd behavior when the VM doesn't have; enough headroom (~1-1.5gb) and processes start to die once Java consumes; everything it can right before it OOMs. Might be why you're seeing hanging; on OOM errors?. -------------------------------; Kristian Cibulskis; Engineering Director, Data Sciences & Data Engineering; Broad Institute of MIT and Harvard; kcibul@broadinstitute.org. On Wed, May 3, 2017 at 8:59 AM, Thib <notifications@github.com> wrote:. > I updated the doc with some more info.; > TLDR: with 100 samples there is a visible difference between different; > buffer size in terms of memory usage. However the tool seems to not exit; > properly when it runs out of memory, leaving the VM hanging.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/2640#issuecomment-298903456>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABW4g2eDXRdEgkD0zMDRl44RjDvg-4cbks5r2HoxgaJpZM4NNEOf>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2640#issuecomment-298912532:561,update,updated,561,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2640#issuecomment-298912532,1,['update'],['updated']
Deployability,How to run the entire pipeline (using even Spark tools) from Java?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3878:22,pipeline,pipeline,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3878,1,['pipeline'],['pipeline']
Deployability,How to use pipeline to call SNP and INDEL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6592:11,pipeline,pipeline,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6592,1,['pipeline'],['pipeline']
Deployability,HtsgetReader integration tests are failing,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6803:13,integrat,integration,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6803,1,['integrat'],['integration']
Deployability,Htsjdk and the Disq snapshot have been updated and now the previously failing tests are passing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5138#issuecomment-422341161:39,update,updated,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5138#issuecomment-422341161,1,['update'],['updated']
Deployability,"Huh, I wonder why gradle doesn't like a lustre system. I didn't now that was an issue. Git-lfs is an annoyance to install if you don't have access to a package manager. I *think* it can be installed without sudo but I get why that's a pain. I've spent a non-zero amount of time fighting with git-lfs installation before. Thank you for elaborating!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042057009:114,install,install,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042057009,3,['install'],"['install', 'installation', 'installed']"
Deployability,Huh. Our tests should be catching this. Looks like we have a failure in our test pipeline somewhere.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7338#issuecomment-876531256:81,pipeline,pipeline,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7338#issuecomment-876531256,1,['pipeline'],['pipeline']
Deployability,"I _believe_ that the user error text didn't get updated when the `--sequence-dictionary` argument got added. It would be great to mention that argument in GATKTool::initializeIntervals(), which currently says `""We require a sequence dictionary from a reference, a source of reads, or a source of variants to process intervals. "" +; ""Since reference and reads files generally contain sequence dictionaries, this error most commonly occurs "" +; ""for VariantWalkers that do not require a reference or reads. You can fix the problem by passing a reference file with a sequence dictionary "" +; ""via the -R argument or you can run the tool UpdateVCFSequenceDictionary on your vcf.""`. I would change the last sentence to:; `You can fix the problem by passing a reference file with a sequence dictionary via the -R argument, a *.dict dictionary file via the --sequence-dictionary argument, or you can run the tool UpdateVCFSequenceDictionary on your vcf.""`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4507:48,update,updated,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4507,3,"['Update', 'update']","['UpdateVCFSequenceDictionary', 'updated']"
Deployability,"I added a simple patch to fix this undocumented behaviour (#1757). Nevertheless, I'm working in an abstraction to include multi-sample support instead of include all the reads without differentiation in the pileup.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1752#issuecomment-213277514:17,patch,patch,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1752#issuecomment-213277514,1,['patch'],['patch']
Deployability,I added an integration test that tries the same thing with a bucket (it works fine). Merging as soon as green (do it for me if I miss it).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2643#issuecomment-299040179:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2643#issuecomment-299040179,1,['integrat'],['integration']
Deployability,"I added commits that fix this now and more tests. I think that it will probably break the integrations tests...so we need to be sure that we like this change before we make the effort to update all of them... One thing I'm not sure about is continuing to use the STANDARD_CONFIDENCE_FOR_CALLING as the threshold...as I think it will have the opposite effect: as the threshold is lowered, you expect to get more variants, but fewer alleles will pass the `passesThreshold` test...so perhaps another argument is needed...I just hate adding arguments...I leave it to more experienced folks to decide.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6363#issuecomment-575130541:90,integrat,integrations,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6363#issuecomment-575130541,2,"['integrat', 'update']","['integrations', 'update']"
Deployability,I added integration tests for Gnarly and GGVCFs with data from #7483. Back to you @droazen,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-947863211:8,integrat,integration,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-947863211,1,['integrat'],['integration']
Deployability,"I added integration tests for simple output and including features or verbose. While doing it, I realized that GATK 3.5 included some filters that wasn't included here, and that indels weren't tracked, so I changed also the code to fit the previous implementation. Back to you @akiezun.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1836#issuecomment-221651158:8,integrat,integration,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1836#issuecomment-221651158,1,['integrat'],['integration']
Deployability,"I addressed some of your comments, @droazen. If you would like to have a properties file for the configuration, I will need some help on setting it up (although I will try by my own too). Although I still set up some of the environment in `Main`, now the `CommandLineProgram` class have the same instance passed by `Main`. Looking forward for your comments on the updates.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2322#issuecomment-271845715:97,configurat,configuration,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2322#issuecomment-271845715,2,"['configurat', 'update']","['configuration', 'updates']"
Deployability,"I addressed your comments, @cmnbroad. In addition, to make more consistent the errors for malformed `GATKRead`, I updated `ReadMissingReadGroup` and removed `MalformedRead` in two separated commits. Like that, every offending read is passing by `MalformedBAM` for consisten error messages. Back to you and many thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-268452263:114,update,updated,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-268452263,1,['update'],['updated']
Deployability,"I agree with the common functionality, but the PR aims to set the less constraints as possible for the custom implementations. Let me know here or in https://github.com/broadinstitute/barclay/issues/127 the functionality to be common in the base class, and I can work on an updated PR for it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4660#issuecomment-382002792:274,update,updated,274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4660#issuecomment-382002792,1,['update'],['updated']
Deployability,"I also forgot to mention that this change needs an update for Hadoop-BAM due to a change in the way filesystems classes are loaded by Spark submit. @cmnbroad, would you be able to take a look at https://github.com/HadoopGenomics/Hadoop-BAM/pull/120, so I can merge it and do a new release?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-257583089:51,update,update,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-257583089,2,"['release', 'update']","['release', 'update']"
Deployability,"I also just got this ConcurrentModificationException in HaplotypeCallerSparkIntegrationTest locally when running tests on one of my branches (this time in `testNonStrictVCFModeIsConsistentWithPastResults`, but the rest of the stack looks the same). I also vaguely recall seeing once before on travis on a branch where all I did was try to update miniconda to a newer version. My local branch doesn't have any dependency changes, so I suspect this is an existing issue that is just showing up intermittently.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-602804665:339,update,update,339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-602804665,1,['update'],['update']
Deployability,"I also just noticed that tests are failing on the branch because they still reference the old constants in a number of places:. ```; symbol: variable READ_NAME_LONG_NAME; location: class ReadNameReadFilter; /gatk/src/test/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptorTest.java:117: error: cannot find symbol; { PlatformReadFilter.class.getSimpleName(), ""--"" + PlatformReadFilter.PL_FILTER_NAME_LONG_NAME, ""fakePlatform"" }, ; ```. You'll need to update these references in order to get tests passing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360806542:484,update,update,484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360806542,1,['update'],['update']
Deployability,I also need to add documentation still. - document places where --ignore-above-gq-threshold is used and why / what it means; - if we went back to GQ60 what would need to get updated?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7584:174,update,updated,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7584,1,['update'],['updated']
Deployability,I also need to add notes for the BQ permissions--since John cant even see the BQ project we need him to be able to. (update: a note has instead been added to the workspace creation permissions doc),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8649#issuecomment-1894299074:117,update,update,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8649#issuecomment-1894299074,1,['update'],['update']
Deployability,"I also tried the following approach which did not generate an error:. 1. imported the 10 not-reblocked gvcfs from chr16 into genomicsdb ; 2. GenotypeGVCFs with the same command line as number 3 above. . So the error appears to be related to the reblocking of the gvcfs. ```; gendb:///restricted/projectnb/kageproj/gatk/genomicsdb/genomicsDB.chr16; Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx60g -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar GenotypeGVCFs -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -G StandardAnnotation -G AS_StandardAnnotation -V gendb:///restricted/projectnb/kageproj/gatk/genomicsdb/genomicsDB.chr16 -L chr16:105582-211160 --use-new-qual-calculator --only-output-calls-starting-in-intervals TRUE --genomicsdb-shared-posixfs-optimizations TRUE --tmp-dir tmp -O chr16-105582-211160.vcf.gz; 07:46:18.893 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 07:46:18.944 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 25, 2021 7:46:19 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 07:46:19.128 INFO GenotypeGVCFs - ------------------------------------------------------------; 07:46:19.128 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.2.0.0; 07:46:19.128 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 07:46:19.129 INFO GenotypeGVCFs - Executing as farre",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437#issuecomment-905431278:389,install,install,389,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437#issuecomment-905431278,2,['install'],['install']
Deployability,I also updated the gatkbase Docker image to 1.2.2. See comments in #4209.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4246:7,update,updated,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4246,1,['update'],['updated']
Deployability,"I am OK with removing it, since our pipeline seems to have been stabilized without it for almost 6 months now. What do you think @cwhelan @tedsharpe ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3612#issuecomment-332053448:36,pipeline,pipeline,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3612#issuecomment-332053448,1,['pipeline'],['pipeline']
Deployability,"I am also seeing this warning 3x with 4.0.11.0 on a cluster but outside of docker (centos 6). . ```; 18:05:08.861 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.11.0/install/bin/gatk-package-4.0.11.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 24, 2018 6:05:09 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.NoRouteToHostException: No route to host (Host unreachable); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredential",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417:210,install,install,210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417,1,['install'],['install']
Deployability,I am getting this error with HaplotypeCaller 4.0.0.0. Was this bug fix released in that version? Otherwise there is more work to do. . I recently reported the error in the GATK Forum....; https://gatkforums.broadinstitute.org/gatk/discussion/11207/gatk-4-0-0-0-haplotypecaller-error-with-l-chrm#latest,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3845#issuecomment-358443805:71,release,released,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845#issuecomment-358443805,1,['release'],['released']
Deployability,"I am having an issue with the same bug, where these `MPOS=-2147483648` fields are causing an error in downstream analysis. If anyone has any update or a workaround I'd appreciate it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6342#issuecomment-584699134:141,update,update,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6342#issuecomment-584699134,1,['update'],['update']
Deployability,"I am looking at using GATK and first checked at the docker image using **_docker pull broadinstitute/gatk_**. this container image has 1460 vulnerabilities and a lot of them are critical. ; <img width=""1737"" alt=""Screenshot 2023-02-21 212830"" src=""https://user-images.githubusercontent.com/4427764/220508376-aeead13b-999b-4cfd-a7d6-295241df532a.png"">. Then I decided not to use this image and instead create my own image and just deploy the released version 4.2.6.1 from here (https://github.com/broadinstitute/gatk/releases/download/4.2.6.1/gatk-4.2.6.1.zip). Even this has many vulnerabilities include things stemming from log4j 1.2.17. These have been fixed by log4j team years back in version 2.17.1 onwards. I am really stunned that a popular library like gatk is not keeping up with basic security fixes. <img width=""854"" alt=""Screenshot 2023-02-21 212751"" src=""https://user-images.githubusercontent.com/4427764/220508300-7bfe331d-8286-4950-a6dc-e1f5f97c65d0.png"">. the latest version of docker desktop has integrated image scanning and can very easily highlight the issues listed above. Can we start addressing these issues sooner than later.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215:430,deploy,deploy,430,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215,4,"['deploy', 'integrat', 'release']","['deploy', 'integrated', 'released', 'releases']"
Deployability,"I am looking forward to the new datasource release. Meanwhile, if anyone wants to get newer version of some databases, I have created a repo which updates some of them. Checkout [here](https://github.com/zhanyinx/variantalker/tree/main/update_db)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8296#issuecomment-1667874725:43,release,release,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8296#issuecomment-1667874725,2,"['release', 'update']","['release', 'updates']"
Deployability,I am looking to call single nucleotide polymorphism (SNP) and INDEL from my genome mapping results generated from HISAT pipeline. Please suggest process and command for that.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6592:120,pipeline,pipeline,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6592,1,['pipeline'],['pipeline']
Deployability,I am not sure what you’re asking for. Can you be more specific? I feel exhausted fighting the brittle unit and integration tests. I think this is ready for merge.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-445858864:111,integrat,integration,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-445858864,1,['integrat'],['integration']
Deployability,"I am pretty sure GATK3 HC did not call this. But, I am checking now. I put this in GATK4 because I know it will not be fixed in GATK3. I can let the user know this is not high priority for now? We will get to bugs after the main release?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3528#issuecomment-332942323:229,release,release,229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3528#issuecomment-332942323,1,['release'],['release']
Deployability,"I am running `gatk GenotypeGVCFs` and want to get output for all genomic sites. I was expecting the output to include parameters like QUAL and mapping quality (MQ) for invariant sites. This is based on a previous study that used an earlier release of GATK, v2.8-1 ([reference](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4617969/)) that used QUAL and MQ values from that sites (although I am aware that these values are computed differently as for variant sites). However, the version I am using, v4.2.1.0, seems to not produce this output, and I cannot find a relevant option to include it. Am I missing something? is there anyway to get this information?. GATK is run as:. gatk HaplotypeCaller -I sample1.bam -O sample1.vcf -R reference.fa -ploidy 1 -ERC BP_RESOLUTION -stand-call-conf 10.0; ...; gatk CombineGVCFs -R reference.fa -O all_samples.g.vcf --variant sample1.vcf --variant sample2.vcf ...; gatk GenotypeGVCFs -R reference.fa -V all_samples.g.vcf -O all_samples.vcf -ploidy 1 -all-sites. Thank you",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7459:240,release,release,240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7459,1,['release'],['release']
Deployability,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724:380,install,install,380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724,2,['install'],['install']
Deployability,"I am trying to understand the calculation of the [`StrandOddsRatio`](https://software.broadinstitute.org/gatk/documentation/tooldocs/4.1.0.0/org_broadinstitute_hellbender_tools_walkers_annotator_StrandOddsRatio.php). The online documentation and javadoc for the [`StrandOddsRatio` class](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java#L40) shows it as:; ```latex; $$ refRatio = \frac{max(X[0][0], X[0][1])}{min(X[0][0], X[0][1} $$; ```. Nonetheless, my reading of [the code](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java#L102) shows it as; ```latex; $$ refRatio = \frac{min(X[0][0], X[0][1])}{max(X[0][0], X[0][1} $$; ```; The code is:; ```java; final double refRatio = min(t00, t01)/ max(t00, t01);; ```. The docs say its max/min while the code does min/max. The same is true for the docs and implementation of `altRatio`. It looks like either a bug, or the docs need to be updated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5700:1062,update,updated,1062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5700,1,['update'],['updated']
Deployability,"I am using GATK 4.4.0.0 via the official docker release to reheader output from SVABA with an appropriate sequence dictionary. I am using `UpdateVCFSequenceDictionary` for this purpose with the following command: . ```; singularity exec -B ""$PWD"" broadinstitute-gatk-4.4.0.0.img gatk UpdateVCFSequenceDictionary --source-dictionary Mus_musculus.GRCm39.dna.primary_assembly.dict -V svaba.somatic.indel.vcf --replace true -O svaba.somatic.indel.vcf.reheaded.vcf; ```. I have encountered a curious behavior, where by the tool is not simply adjusting the sequence dictionary, but is also modifying a FORMAT field. . Original VCF header: . ```; ##FORMAT=<ID=GQ,Number=1,Type=String,Description=""Genotype quality (currently not supported. Always 0)"">; ```. Updated VCF header: . ```; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ```. From what I can see, the updated text is used frequently in your GATK VCF files, but I can't dig out the specific code where it is being set via `UpdateVCFSequenceDictionary`. I am wondering if there is a collision where `UpdateVCFSequenceDictionary` detects GQ and prints a stock header field to match expectation, rather than leaving it alone. I would expect the tool to simply replace the dictionary portion of the VCF without modifying the FORMAT/INFO fields. This is causing issues with downstream analysis because SVABA QC values are float/string not integer.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8629:48,release,release,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8629,7,"['Update', 'release', 'update']","['UpdateVCFSequenceDictionary', 'Updated', 'release', 'updated']"
Deployability,"I am working on a fix. Meanwhile, here are the commands to work around the issue -; `On Ubuntu:; sudo apt-get update && sudo apt-get install libcurl4`; `On Centos:; sudo yum install libcurl`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6122#issuecomment-525154518:110,update,update,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6122#issuecomment-525154518,3,"['install', 'update']","['install', 'update']"
Deployability,I ask that because for htsjdk defaults they must be system properties and they're final and set statically on load so mucking about resetting system properties after the JVM started already is going to be a bit of a fiddly ordering nightmare. . [Stack overflow](http://stackoverflow.com/questions/6736235/set-java-system-properties-with-a-configuration-file) doesn't seem to think that it's possible to initialize them from a file.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2316#issuecomment-267126704:339,configurat,configuration-file,339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2316#issuecomment-267126704,1,['configurat'],['configuration-file']
Deployability,"I asked about a status update on the travis image space issue in the travis ticket, and based on feedback I tried moving to the new image. It seems to work now. Fixes https://github.com/broadinstitute/gatk/issues/3559.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3622:23,update,update,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3622,1,['update'],['update']
Deployability,"I believe that the problem is that HaplotypeCallerGenotypingEngine doesn't use the version of StandardCallerArgumentCollection.getSampleContamination() with the sampleID, so the sampleContamination variable is never initialized and we get a NPE. The -contamination argument is standard in our production GATK pipeline... and we're about to start telling everyone to use it! This is an important one to fix. Here's a stacktrace:. java.lang.NullPointerException; 	at java.util.Collections$UnmodifiableMap.<init>(Collections.java:1446); 	at java.util.Collections.unmodifiableMap(Collections.java:1433); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.StandardCallerArgumentCollection.getSampleContamination(StandardCallerArgumentCollection.java:89); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:141); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:566); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:218); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:295)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4312:309,pipeline,pipeline,309,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4312,1,['pipeline'],['pipeline']
Deployability,I believe this release also fixes #6158 and #6275 (thanks @mlathara).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6305#issuecomment-563246616:15,release,release,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6305#issuecomment-563246616,1,['release'],['release']
Deployability,"I brew installed openssl, and now there is a different unresolved dependency:. java.lang.UnsatisfiedLinkError: /private/var/folders/cr/16ghvyfj5lvfwxx01rt1k4tdl04sy3/T/libtiledbgenomicsdb6507285380909029818.dylib: dlopen(/private/var/folders/cr/16ghvyfj5lvfwxx01rt1k4tdl04sy3/T/libtiledbgenomicsdb6507285380909029818.dylib, 1): Library not loaded: **/usr/local/opt/libcsv/lib/libcsv.3.dylib**; Referenced from: /private/var/folders/cr/16ghvyfj5lvfwxx01rt1k4tdl04sy3/T/libtiledbgenomicsdb6507285380909029818.dylib; Reason: image not found",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294232254:7,install,installed,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294232254,1,['install'],['installed']
Deployability,I broke external forks pull requests when the dataflow tests were turned on. They need to be updated so that tests that don't require keys will run without them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/810:93,update,updated,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/810,1,['update'],['updated']
Deployability,"I bumped into an error in a PR of mine due to a recent update in master. While I should make the code of the PR more robust I think that the approach take to compose approximate likehoods in ```VariantAnnotator.makeLikelihoods``` can and should be improved. Currently uses -Infility as ""unlikely"" lk (I would say rather ""impossible"" lk) and 0 as ""likely"" based on whether the read pileup does not match the allele or it does match the allele. . IMO the ""unlikely"" lk should never be less than the mapping quality of the read. And it can be further reduced by the base quality in case of an snp or the indel error probrability; by default is 45 Phred yet as part of the integration with Illumina/DRAGEN Dragstr, at least in germline, we can come out with indel penalties that are tailred to the reference, read context.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7312:55,update,update,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7312,2,"['integrat', 'update']","['integration', 'update']"
Deployability,"I came across some notes I made 20170901, while developing the Helsinki Mutect2 tutorial, to report a particular bug, that I am just now getting around to. Here is the command I ended up using to solve the problem:; ```; gatk-launch PrintReads -I hcc1143_N_clean.bam -O hcc1143_N_chr17.bam -L chr17 -L chr11:915890-1133890 -L chr6:29941013-29946495 -L chr11_KI270927v1_alt -L HLA-A*24:03:01:1+; ```. Notice the protection tag `:1+` that I add to the last interval. If I do not add this, I get the following error:; ```; ***********************************************************************. A USER ERROR has occurred: Badly formed genome unclippedLoc: Contig 'HLA-A*24:03' does not match any contig in the GATK sequence dictionary derived from the reference; are you sure you are using the correct reference fasta file?. ***********************************************************************; ```; This error persists even if I provide a dictionary/ref to the command. . The solution comes from the pipelines team, in their [PESS workflow that I documented](https://gatkforums.broadinstitute.org/gatk/discussion/7899/reference-implementation-pairedendsinglesamplewf-pipeline), so credit goes to them. Perhaps our code can do this internally for HLA contigs. Sorry for the late notice. I've been extremely busy. I will assign @droazen since we touched upon this briefly last week.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3807:1002,pipeline,pipelines,1002,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3807,2,['pipeline'],"['pipeline', 'pipelines']"
Deployability,"I can actually replicate this with an interval list with two intervals: ; ```; chr1	11719	18516	+	.; chr2	38664	202755	+	.; ```; throws; ```; org.broadinstitute.hellbender.exceptions.GATKException: Cannot call query with different interval, expected:chr1:11719-18516 queried with: chr2:38664-202755; 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport$InitializedQueryWrapper.query(GenomicsDBImport.java:816); 	at com.intel.genomicsdb.importer.GenomicsDBImporter.<init>(GenomicsDBImporter.java:136); 	at com.intel.genomicsdb.importer.GenomicsDBImporter.lambda$null$2(GenomicsDBImporter.java:563); 	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); ```. We typically run with `--reader-threads 5` in the pipeline, but if I change it to 1 I can get it to run. That's not a longterm solution, but hopefully it's a good hint and it's a good enough workaround for me for the moment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5300#issuecomment-438818966:970,pipeline,pipeline,970,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5300#issuecomment-438818966,1,['pipeline'],['pipeline']
Deployability,"I can confirm that, GATK 4.1.3.0 with CollectRawWgsMetrics; ```; Exception in thread ""main"" java.lang.IllegalArgumentException: The requested position is not covered by this StartEdgingRecordAndOffset object.; ```. **Cmdline:**; ```; picard -Xms4000m \; CollectRawWgsMetrics \; INPUT=example.bam; VALIDATION_STRINGENCY=SILENT \; REFERENCE_SEQUENCE=Homo_sapiens_assembly38.fasta \; INCLUDE_BQ_HISTOGRAM=true \; INTERVALS=wgs_coverage_regions.hg38.interval_list \; OUTPUT=example.raw_wgs_metrics \; USE_FAST_ALGORITHM=true \; READ_LENGTH=250; ```. **Output:**; ```; 18:48:46.330 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/local/share/picard-2.20.7-0/picard.jar!/com/intel/gkl/native/libgkl_compression.so; [Fri Sep 20 18:48:46 GMT 2019] CollectRawWgsMetrics INPUT=example.bam; [Fri Sep 20 18:48:46 GMT 2019] Executing as root@98e13b9f4ef1 on Linux 4.19.44+ amd64; OpenJDK 64-Bit Server VM 1.8.0_152-release-1056-b12; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.20.7-SNAPSHOT; [Fri Sep 20 18:49:00 GMT 2019] picard.analysis.CollectRawWgsMetrics done. Elapsed time: 0.24 minutes.; Runtime.totalMemory()=4054515712; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; Exception in thread ""main"" java.lang.IllegalArgumentException: The requested position is not covered by this StartEdgingRecordAndOffset object.; at htsjdk.samtools.util.AbstractRecordAndOffset.validateOffset(AbstractRecordAndOffset.java:146); at htsjdk.samtools.util.EdgingRecordAndOffset$StartEdgingRecordAndOffset.getBaseQuality(EdgingRecordAndOffset.java:112); at picard.analysis.FastWgsMetricsCollector.excludeByQuality(FastWgsMetricsCollector.java:189); at picard.analysis.FastWgsMetricsCollector.processRecord(FastWgsMetricsCollector.java:144); at picard.analysis.FastWgsMetricsCollector.addInfo(FastWgsMetricsCollector.java:105); at picard.analysis.WgsMetricsProcessorImpl.processFile(WgsMetricsProcessorImpl.java:93); at picard.an",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6163#issuecomment-533770047:930,release,release-,930,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6163#issuecomment-533770047,1,['release'],['release-']
Deployability,"I can't reproduce this yet. I tried downloading the jar, unzipping it, and running the example command you gave, but I can't reproduce what you're seeing. I modified it for my local files:; ```; java -jar gatk-package-4.2.5.0-local.jar \; GenotypeGVCFs \; -R /Users/louisb/Workspace/gatk/src/test/resources/large/Homo_sapiens_assembly19.fasta.gz \; --variant gendb:///Users/louisb/Workspace/gatk/output \; -O out.vcf \; --annotate-with-num-discovered-alleles \; -stand-call-conf 30 \; --max-alternate-alleles 6 \; --force-output-intervals 20 \; -L 20 \; --only-output-calls-starting-in-intervals \; --genomicsdb-shared-posixfs-optimizations; ```; It runs to completion on my machine. ; My md5sum matches yours so that's not the problem. It's not clear to me what's going on here. Are the previous releases working on your cluster still?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042010522:797,release,releases,797,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042010522,2,['release'],['releases']
Deployability,"I can, this only happens on 10 of our 2000 samples (only in WES) none of our 600 WGS seems to have the same issue. It is always on some small contig (you can see here range is 544, but all cases are small ranges like this one). Everything is the default mutect2 pipeline and params (e.g. [gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta](https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0?prefix=Homo_sapiens_assembly38.fasta&authuser=jkalfon%40broadinstitute.org)) : except the interval file: [gs://ccleparams/region_file_wgs.list](https://console.cloud.google.com/storage/browser/ccleparams?prefix=region_file_wgs.list&authuser=jkalfon%40broadinstitute.org); GATK 4.2.6.1. . Here is the VCF file to annotate `gs://ccleparams/test/CDS-2jucw0.hg38-filtered.vcf.gz`. Here is the stacktrace:. ```; ....; 10:53:39.044 INFO VcfFuncotationFactory - ClinVar_VCF 20180429_hg38 cache hits/total: 0/2145; 10:53:39.249 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/1069225; 10:53:39.520 INFO Funcotator - Shutting down engine; [July 12, 2022 10:53:39 AM GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 115.46 minutes.; Runtime.totalMemory()=2050490368; java.lang.StringIndexOutOfBoundsException: String index out of range: 544; at java.lang.String.substring(String.java:1963); at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.initializeForInsertion(ProteinChangeInfo.java:293); at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.<init>(ProteinChangeInfo.java:101); at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.create(ProteinChangeInfo.java:399); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSequenceComparison(GencodeFuncotationFactory.java:2054); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createCodingRegionFunc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653:262,pipeline,pipeline,262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653,1,['pipeline'],['pipeline']
Deployability,"I cannot seem to be able to run the pipeline with the following way of running it:. ```bash; ./manage_sv_pipeline.sh \; /Users/shuang/GATK \; broad-dsde-methods \; gs://broad-dsde-methods/sv/samples/G94797_CHM_MIX/WGS1/G94794.CHMI_CHMI3_WGS1.cram.bam \; gs://broad-dsde-methods/sv/reference/GRCh38/Homo_sapiens_assembly38.fasta \; gs://broad-dsde-methods/shuang/tmp/gatk-jars/default_init.sh; ```. And if I run with the following way (only adding a user name). ```bash; ./manage_sv_pipeline.sh \; /Users/shuang/GATK \; broad-dsde-methods \; gs://broad-dsde-methods/sv/samples/G94797_CHM_MIX/WGS1/G94794.CHMI_CHMI3_WGS1.cram.bam \; gs://broad-dsde-methods/sv/reference/GRCh38/Homo_sapiens_assembly38.fasta \; gs://broad-dsde-methods/shuang/tmp/gatk-jars/default_init.sh \; shuang; ```; The script runs as expected. I believe line 47 is the culprit:; ```bash; SV_ARGS=${*:-${SV_ARGS:-""""}} && SV_ARGS=${SV_ARGS:+"" ${SV_ARGS}""}; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318919090:36,pipeline,pipeline,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318919090,1,['pipeline'],['pipeline']
Deployability,"I cloned GATK4 into /humgen/gsa-scr1/gauthier/workspaces/gatk/ (from gsa5), then tried `./gatk-launch --list`, which didn't work because I hadn't built yet. gatk-launch told me to run `/humgen/gsa-scr1/gauthier/workspaces/gatk/gradlew installDist`, which I did and it threw the following error (sorry for the huge stacktrace, but I didn't want to leave out anything important):. [...]; Download https://repo1.maven.org/maven2/xpp3/xpp3_min/1.1.4c/xpp3_min-1.1.4c.jar; Download https://repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.8.0/commons-beanutils-1.8.0.jar. FAILURE: Build failed with an exception.; - What went wrong:; A problem occurred configuring root project 'gatk'.; ; > Could not resolve all dependencies for configuration ':classpath'.; > Could not download commons-beanutils.jar (commons-beanutils:commons-beanutils:1.8.0); > Could not get resource 'https://repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.8.0/commons-beanutils-1.8.0.jar'.; > > Failed to move file '/tmp/gradle_download3865353896539966562bin' into filestore at '/home/unix/gauthier/.gradle/caches/modules-2/files-2.1/commons-beanutils/commons-beanutils/1.8.0/c651d5103c649c12b20d53731643e5fffceb536/commons-beanutils-1.8.0.jar'; - Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 22.394 secs; Could not stop org.gradle.cache.internal.DefaultMultiProcessSafePersistentIndexedCache@1fc775a3.; org.gradle.api.UncheckedIOException: org.gradle.api.UncheckedIOException: java.io.IOException: Disk quota exceeded; at org.gradle.cache.internal.btree.BTreePersistentIndexedCache.close(BTreePersistentIndexedCache.java:197); at org.gradle.cache.internal.DefaultMultiProcessSafePersistentIndexedCache$4.run(DefaultMultiProcessSafePersistentIndexedCache.java:78); at org.gradle.cache.internal.DefaultFileLockManager$DefaultFileLock.doWriteAction(DefaultFileLockManager.java:173); at org.gradle.cache.internal.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:235,install,installDist,235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,2,"['configurat', 'install']","['configuration', 'installDist']"
Deployability,"I created a minimal branch to clean up the way we were passing around credentials. We create a GCSOptions class instead of a DataflowPipelineOptions when we create the pipeline and pass in secrets in at the point instead at the ReadSources level. ReadSources now takes a pipeline instead of the secrets file location. This isn't a long term solution. We should switch the code to get rid of the GenomicsSecret and instead use the more general secret. I think much of the secets factory junk can go away now (they dated from a time when the Dataflow API wasn't built out much. All tests passed locally. Oddly, I now am sometimes getting a dialog about DSDE needing access to basic information about my Google account, not sure source of the issue (maybe the secret I grabbed?), if it's repeatable, or blocking. I recommend the reviewer patch my branch and test locally.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/513:168,pipeline,pipeline,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/513,3,"['patch', 'pipeline']","['patch', 'pipeline']"
Deployability,"I definitely like the idea of moving in this direction, and it will become more compelling as we extend the GATKSparkTool hierarchy, which is currently pretty flat and doesn't mirror the GATKTool hierarchy. I think we should also consider using some of the concepts from the metrics refactoring, which introduces a layer that separates the implementation of the processing logic from the containing tool/driver, and allows a single implementation (i.e. metrics collector, but could be FlagStats, CountReads, SelectVariants, whatever) to be independent of the source and/or destination of the data. It adds more moving parts, but has the advantage of allowing a single implementation to be used from any of Spark tool, standalone tool, Spark pipeline, standalone pipeline, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2217#issuecomment-254216118:741,pipeline,pipeline,741,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2217#issuecomment-254216118,2,['pipeline'],['pipeline']
Deployability,"I deleted ~/.m2/repository/ folder and his content, used this [pom.xml](https://pastebin.com/mV1qGTzv); ```; <project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""; xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">; <modelVersion>4.0.0</modelVersion>; <groupId>uk.ac.ncl</groupId>; <artifactId>GATKpipe</artifactId>; <version>0.0.1-SNAPSHOT</version>; <repositories>; <repository>; <id>central</id>; <name>Maven Repository Switchboard</name>; <layout>default</layout>; <url>http://repo1.maven.org/maven2</url>; <snapshots>; <enabled>false</enabled>; </snapshots>; </repository>; <repository>; <id>snapshots</id>; <snapshots>; <enabled>true</enabled>; </snapshots>; <name>libs-snapshot</name>; <url>https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot</url>; </repository>; </repositories>; <dependencies>; <dependency>; <groupId>org.broadinstitute</groupId>; <artifactId>gatk</artifactId>; <version>4.beta.6-18-g2ee7724-20171025.162137-1</version>; </dependency>; </dependencies>; </project>; ```; executed `mvn clean install -U` and finally obtained the `BUILD SUCCESS`; Thanks everybody for your support",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-340844337:1126,install,install,1126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-340844337,1,['install'],['install']
Deployability,"I did a really rough benchmarking of the new mode on my local machine. There were ~80,000 samples and ~40,000 variants. Master finished in 139.6 minutes and the new branch finished in 44.74. Significant speedup! At a glance the variants and INFO field attributes look like they match, but I'm running a more thorough comparison now. There's something weird about the logging though. Master output a progress update every 1000 variants, but the new branch only had an update at 1000 and then the total stats when it finished:; ```; 16:19:16.342 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; Chromosome chr20 position 1279618 (TileDB column 2714308521) has too many alleles in the combined VCF record : 61 : current limit : 50. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location.; 17:03:54.604 INFO ProgressMeter - chr20:1269692 44.6 1000 22.4; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.36128615400000264,Cpu time(s),0.3515559999999785; 17:03:56.445 INFO ProgressMeter - chr20:1308850 44.7 40156 899.0; 17:03:56.445 INFO ProgressMeter - Traversal complete. Processed 40156 total variants in 44.7 minutes.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3688#issuecomment-376883431:408,update,update,408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3688#issuecomment-376883431,2,['update'],['update']
Deployability,"I did a simple experiment and changed the version of Java used in the non-Docker (""17"", although again I'm not sure what this actually resolves to) to that used in the Docker (17.0.1+12). This causes both non-Docker and Docker tests to now fail, rather than just the Docker tests; see https://github.com/broadinstitute/gatk/pull/8174#issuecomment-1402974502. Moreover, the test failures produce exactly the same discrepant numerical results. I think we can probably conclude that the expected test results were generated with ""17"" and that changing to 17.0.1+12 generates different results. This is not too unreasonable; see the Slack thread linked in https://github.com/broadinstitute/gatk/pull/8111#issuecomment-1331407680, for example, which shows that we might be getting into pretty hairy territory and that even changes to things like how HotSpot Intrinsics are implemented in each JVM can cause the numerical differences we see here. So perhaps we can either 1) change the Docker version to the version corresponding to ""17"" or 2) change the non-Docker version to 17.0.1+12 and update the expected results?. Not sure about the failing WDL test yet, but hopefully this is enough to get us started!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1403016955:1085,update,update,1085,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1403016955,2,['update'],['update']
Deployability,"I did not install the GATK conda environment. Instead, I created a singularity container using the GATK v4.3.0.0 docker image. Also, the GATK version I have outside container is v4.6.0.0, so the fact that GATK v4.3.0.0 got called means it was using the GATK came with the image.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8952#issuecomment-2287946499:10,install,install,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8952#issuecomment-2287946499,1,['install'],['install']
Deployability,"I did one thing I expect may be controversial, I implemented getAttributeAsLongList() in RMSMappingQuality. It's unlikely that ints would overflow in that particular case, so it might be possible to go without doing that. The cleaner alternative would be to update VariantContext and CommonInfo, but they were in htsjdk, so I wasn't sure how to proceed there.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5435#issuecomment-440032835:258,update,update,258,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5435#issuecomment-440032835,1,['update'],['update']
Deployability,"I did some more work on the broadcast approach to see how feasible it would be, and found that Spark Dataflow made two unnecessary copies of the data (now fixed: https://github.com/cloudera/spark-dataflow/pull/60), which caused OOM errors when trying to broadcast the 3GB reference data. With this fixed, I ran a [pipeline called JoinReferencesDataflow](https://github.com/tomwhite/hellbender/blob/hadoop-references/src/main/java/org/broadinstitute/hellbender/tools/dataflow/pipelines/JoinReferencesDataflow.java) on a small cluster that broadcasts the reference as a dataflow view. The code is a modified version of CountReadsDataflow that simply sends the view, and then doesn't use it, so we can see the cost of doing a broadcast (See the rest of the code in this branch: https://github.com/tomwhite/hellbender/tree/hadoop-references). JoinReferencesDataflow took 2 min 25s to run, of which 18s were for reading the reference from the local filesystem in the driver. For comparison, CountReadsDataflow took 17s on the same cluster. So broadcasting the reference takes less than 2 minutes. Note that this was just for one task, but Spark has [an efficient protocol for sending broadcast variables](http://www.cs.berkeley.edu/~agearh/cs267.sp10/files/mosharaf-spark-bc-report-spring10.pdf), which scales well with the number of nodes, so the approach looks feasible. Having said all that, we might still want to use the sharding approach, in order to share more code between the Google and Spark dataflow implementations. One way this could work would be to generalize `RefAPISource` and `RefAPIMetadata` to support reading reference data from a [ReferenceHadoopSource](https://github.com/tomwhite/hellbender/blob/hadoop-references/src/main/java/org/broadinstitute/hellbender/engine/dataflow/datasources/ReferenceHadoopSource.java), which is in line with @droazen's last comment. Am I right in thinking that the read pipeline work is being completed in https://github.com/broadinstitute/hellbender/tr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/567#issuecomment-120001353:314,pipeline,pipeline,314,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/567#issuecomment-120001353,2,['pipeline'],"['pipeline', 'pipelines']"
Deployability,"I didn't expect for this particular clarification to launch a tutorial. I think the tool docs (i.e. javadoc) should be updated and a new note about pairs in the workflow docs (https://software.broadinstitute.org/gatk/documentation/article?id=11074), in the intro and probably at the section at the end about ""family priors"". Incidentally I'm seeing that the LaTeX at the end of that doc isn't coming out right, so that would be a nice fix too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-453599368:119,update,updated,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-453599368,1,['update'],['updated']
Deployability,I didn't realize we hadn't been updating the changelog /releasing when we added new features anymore. . A few other things that happened recently (not sure if they were before or after last release); - high_CALIBRATION_SENSITIVITY_SNP and high_CALIBRATION_SENSITIVITY_INDEL were moved from the ##FILTER entry in the header to a ##COMMENT. No change to behavior or vcf content outside of header.; - Reduced the number of sharded vcfs coming out of beta workflow for smaller callsets. Documentation on details coming soon.; - Bug fix to correctly handle samples with chromosomes with differing ploidy for DRAGEN 3.7.8 data.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8883#issuecomment-2183251069:190,release,release,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8883#issuecomment-2183251069,1,['release'],['release']
Deployability,"I didnt see an example, but I could have easily missed it: I am writing an integration test for a walker where the user supplies an output prefix, and the tool created three output files based on that prefix. I want to write an integration test, ideally using IntegrationTestSpec in an intended form. Are there any existing integration tests of tools that use this style argument, and/or is there an intended way to make that work using IntegrationTestSpec? . Most examples I see require the test to supply ""-O %s"", and the test creates a temp file for the output. It then expects to compare that path to the expected file you supply. I see how to work around it (dont use %s and manually check outputs), but I thought I'd check to see if there was an official solution. Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5446:75,integrat,integration,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5446,5,"['Integrat', 'integrat']","['IntegrationTestSpec', 'integration']"
Deployability,"I discovered some strange behavior in our test suite. This test in `PrintReadsSparkIntegrationTest` passes:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. ArgumentsBuilder args = new ArgumentsBuilder();; args.add(""--"" + StandardArgumentDefinitions.INPUT_LONG_NAME);; args.add(samWithOneMalformedRead.getCanonicalPath());; args.add(""--"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME);; args.add(outBam.getCanonicalPath());. runCommandLine(args.getArgsArray());; SamAssertionUtils.assertSamsEqual(outBam, new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam""));; }; ```. But if you re-write it to use `IntegrationTestSpec` with the same input, output, and expected file, it fails with `Sort order differs. File 1: nullFile 2: coordinate`:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + outBam.getCanonicalPath(),; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );. spec.executeTest(""PrintReadsSpark_testReadFiltering"", this);; }; ```. Possibly this is indicative of a bug in `IntegrationTestSpec`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1164:822,Integrat,IntegrationTestSpec,822,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164,4,['Integrat'],['IntegrationTestSpec']
Deployability,"I discovered that one of the 345 input gvcfs failed VCF validation. When I removed that file and reran with no other changes, I did not get the ""terminate called without an active exception"" error. However, ImportGvcfs still fails; the failure seems to occur immediately after GenomicsDBImport logs success in importing all batches, in each shard. From all the Cromwell logs it looks like everything is working, but the top level workflow execution fails. I've been trying various configurations of memory, scatter count, and #nodes, so I don't have those log files around still. I can rerun with -DGATK_STACKTRACE_ON_USER_EXCEPTION=true and see if I get anything useful.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1295310651:481,configurat,configurations,481,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1295310651,1,['configurat'],['configurations']
Deployability,"I do not think you should have two versions. Here is a task example from; another workflow:. ```; output {; File cnv_acs_conversion_skew = ""${output_skew_filename}""; Float cnv_acs_conversion_skew_float =; read_float(output_skew_filename); String cnv_acs_conversion_skew_string =; read_string(output_skew_filename); }; ```. While this adds some clutter, at least the task (and workflow) produces a; file, float, or string. Then you can decide which you actually want to; attach to the data model via the method configuration output. Clutter vs. fork? I say ""clutter"". Also, you may only need one alternate; type. On Tue, Jul 2, 2019 at 9:52 AM ldgauthier <notifications@github.com> wrote:. > *@ldgauthier* requested changes on this pull request.; > ------------------------------; >; > In scripts/cnv_wdl/germline/cnv_germline_case_workflow.wdl; > <https://github.com/broadinstitute/gatk/pull/6017#discussion_r299492696>:; >; > > @@ -242,6 +250,7 @@ workflow CNVGermlineCaseWorkflow {; > Array[File] gcnv_tracking_tars = GermlineCNVCallerCaseMode.gcnv_tracking_tar; > Array[File] genotyped_intervals_vcf = PostprocessGermlineCNVCalls.genotyped_intervals_vcf; > Array[File] genotyped_segments_vcf = PostprocessGermlineCNVCalls.genotyped_segments_vcf; > + Array[File] qc_status_files = CollectSampleQualityMetrics.qc_status_files; >; > Ideally I'd want to be able to flag failing samples in an obvious way in; > the workspace, like having new fields in the data model called; > ""sample_quality"" and ""model_quality"" with the QC status reported there. Are; > we violently opposed to having a Cromwell version and a Firecloud version; > of this WDL? (@LeeTL1220 <https://github.com/LeeTL1220>); > ------------------------------; >; > In scripts/cnv_wdl/cnv_common_tasks.wdl; > <https://github.com/broadinstitute/gatk/pull/6017#discussion_r299493991>:; >; > > @@ -453,3 +453,98 @@ task PostprocessGermlineCNVCalls {; > File genotyped_segments_vcf = genotyped_segments_vcf_filename; > }; > }; > +; > +task Col",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-507695717:510,configurat,configuration,510,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-507695717,1,['configurat'],['configuration']
Deployability,"I don't know how to accomplish that with gradle. Is just keeping the test jvm going all we need? Or does the ui shutdown after each test? We could add an infinitely running ""test"" in a special test group to If we want to be keep the test jvm open. Alternatively if we really need to be able to run tests and then view the UI afterwards we could put together something using https://github.com/hammerlab/spree. It's a minor pain to set up, I had weird ruby packaging problems getting meteor installed, but it solves the problem of ""how do we collect spark logs in a usable way"".",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1193#issuecomment-159679676:490,install,installed,490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1193#issuecomment-159679676,1,['install'],['installed']
Deployability,"I don't think rushing a merge is needed. This is a dead simple utility tool that really only needs to be run once or twice (if I understand the needs for the SV pipeline---possible I'm missing something). Why not just create the desired bins, either by using this dev branch or an external script, and provide that as a resource to the SV pipeline for the time being?. As for using streams for coverage collection, do you mean NIO?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-466100631:161,pipeline,pipeline---possible,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-466100631,4,['pipeline'],"['pipeline', 'pipeline---possible']"
Deployability,"I don't think this PR is going to work. I believe the changes I have made will make the tests pass, but in my own testing I'm experiencing the HC dropping variants when running with phasing on in non-ERC mode. I'll update the linked issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470688534:215,update,update,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470688534,1,['update'],['update']
Deployability,"I don't think this is true anymore. We've been using it successfully with gatk4's `HaplotypeCaller`. I'd love some confirmation, and then the docs could be updated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5943:156,update,updated,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5943,1,['update'],['updated']
Deployability,"I don’t feel that there’s any great time pressure, but I do think I’ll need it at some point. And these things do have a way of withering with time...; Maybe not essential for this release. > On Aug 5, 2019, at 4:22 PM, droazen <notifications@github.com> wrote:; > ; > @tedsharpe @cmnbroad Should we try to get this merged for the upcoming release?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5985#issuecomment-518387165:181,release,release,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5985#issuecomment-518387165,2,['release'],['release']
Deployability,"I doubt much CRAM testing has been done with HaplotypeCaller, and I don't see any integration tests for it using CRAM. FWIW, since we have a CRAM version of the BAM we use for those tests, I did just try running them on the CRAM and they passed. As SooHee mentioned though, you'll have issues if the reference you use is in a GCS bucket, or if you specify intervals and the CRAM (and it's index) are in a bucket.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334831157:82,integrat,integration,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334831157,1,['integrat'],['integration']
Deployability,I download 4.1.8.1 release tar.gz file but can't unzip.; ```; 63800K .......... .......... .......... .......... .......... 49.2K; 63850K 533G=21m48s. 2020-07-22 09:06:30 (48.8 KB/s) - ‘4.1.8.1.tar.gz’ saved [65382686]; ```; Here is Error:; ```; $tar -zxf 4.1.8.1.tar.gz . gzip: stdin: unexpected end of file; tar: Unexpected EOF in archive; tar: Unexpected EOF in archive; tar: Error is not recoverable: exiting now; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6719:19,release,release,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6719,1,['release'],['release']
Deployability,"I evaluated an extremely naive prototype of this -- it just forced every read to begin threading at the read start -- on Mutect2 and it improves sensitivity and harms precision by small amounts. I'm pretty sure we can get the precision back by instead starting threading a before at the first unique kmer but then threading *backwards* to the beginning of the read. If we start threading forward at a non-unique kmer we're liable to start at the wrong end of the assembly region, and this modification would fix that. I think I'll try to do this in time for the 4.1 release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4942#issuecomment-447038527:566,release,release,566,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4942#issuecomment-447038527,1,['release'],['release']
Deployability,"I feel like this is going to be problematic in a different way than what @magicDGS is mentioning. We expect many versions of gatk to be compatible with the same python environment. Also for performance reasons we want to start avoid rebuilding the conda environment on every push and bake it into the base docker instead. This change means we definitely have to build it every time. . It feels like we need something more sophisticated. Instead of stamping the conda environment with the gatk version that matches it, maybe we should be stamping the gatk jar and the conda environment with some version based on the conda.env? Maybe we can do something like taking the md5 of the conda.yml and pushing that into both the jar manifest and the conda environment in some way? I'm guessing this scheme has an issue with the actual python code in the gatk since I think that's installed with conda as well? I'd really like to be able to preinstall the various dependencies though and then only update the code that's part of the gatk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5081#issuecomment-411214721:872,install,installed,872,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5081#issuecomment-411214721,2,"['install', 'update']","['installed', 'update']"
Deployability,"I finished the implementation for the draft `SlidingWindowWalker` (I should implement an example and an integration test, but I would like to wait till some issues are solved). made a ""TODO"" about the way in which the intervals are constructed, because I will need a that `ReadShard` have a way to construct a shard without `ReadSource` (either null or empty source), just in case that the implemented `SlidingWindowWalker` does not require reads. @droazen, could you review and give me some feedback about this, because this class is important for other parts of GATK?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-215710163:104,integrat,integration,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-215710163,1,['integrat'],['integration']
Deployability,I fixed these by update the dataproc image from 1.0 -> 1.1. . @davidbernick Is there a way to make that into a variable that's settable in one place and shared between every jenkins spark job?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2289#issuecomment-264497363:17,update,update,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2289#issuecomment-264497363,1,['update'],['update']
Deployability,"I forgot to update the docs about the no need for index files... will do that before merging, anything else that needs to be changed?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3474#issuecomment-325029200:12,update,update,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3474#issuecomment-325029200,1,['update'],['update']
Deployability,"I forked GATK pipelines, and they use docker GATK 4.0.10.1. I will try adding newqual and report, but I assume it will fix it :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6896#issuecomment-710179751:14,pipeline,pipelines,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6896#issuecomment-710179751,1,['pipeline'],['pipelines']
Deployability,I found a pretty nasty funcotator bug as part of looking into this test failure. I think we will need to patch that as a separate pr.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-533669193:105,patch,patch,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-533669193,1,['patch'],['patch']
Deployability,"I found some edge cases when implemented a new walker based on GATKTool that should be considered in the base class to avoid some mistakes by developers. They should either being correctly handled or documented as not-applicable for some walkers:. - [ ] If a tool/walker overrides getPluginDescriptors to remove the `GATKReadFilterPluginDescriptor`, the method `makeReadFilter` will not return a filter with the `getDefaultReadFilters`. This is important for implementing tools where the user shouldn't be able to override the filters. I suggest to either handle the case where the plugin cannot be detected and return a filter with only defaults, or to specify in the documentation that `makeReadFilter` should be overriden in that case. - [ ] Transformer methods for reads (`makePreReadFilterTransformer`and `makePostReadFilterTransformer`) only have effect in `ReadWalker`(and extensions). I think that the `ReadsContext` should have a method to set pre/post transformers, and call this methods to integrate with every extension of `GATKTool`. Otherwise, it should be documented that it has no effect in most of the cases. @droazen - could you give me some way to proceed here? I think that the best way is to implement the proper behavior, but maybe the engine team has a different opinion...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4651:1001,integrat,integrate,1001,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4651,1,['integrat'],['integrate']
Deployability,"I get : `500032 tests completed, 20 failed, 1 skipped`. The 2 extra failed tests are spark related (I don't have a spark setup so I assume this is normal); `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerNonStrict`; `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerStrict`; The skipped test is `testLikelihoodsFromHaplotypes[2](null, false)` in the `VectorPairHMMUnitTest`. I did install git-lfs and downloaded all the required files per the instructions, the files are up to date.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121:445,install,install,445,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121,1,['install'],['install']
Deployability,"I get the same error when I try to run CountReads on dataproc. I get this even if using an older version of our code (all the way back to 2016-6-30, then I get a different error). Dataproc released a [new version on 2016-8-8](https://cloud.google.com/dataproc/docs/concepts/dataproc-versions), bumping up the Spark version - that's probably the cause of the error. It's possible to [request the older 1.0 version](https://cloud.google.com/dataproc/docs/concepts/versioning) and this fixes the problem for me. Of course, eventually we'll probably want to upgrade to the newer version of Spark ourselves as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2183#issuecomment-249261960:189,release,released,189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2183#issuecomment-249261960,2,"['release', 'upgrade']","['released', 'upgrade']"
Deployability,"I got 348 samples to analyse their variants. I have read several turorials about how to use gatk to get a population vcf. At the beginning , I tried to use CombineGVCFs to get the Gvcf and use SelectVariants to pick the snps out. . CombineGVCFs truns to a error ""Exception in thread ""main"" java.lang.OutOfMemoryError"" .; then I chose to use GenomicsDBImport to do this job. It still doesn't work. First error is ""read_one_line_fully && ""Buffer did not have space to hold a line fully - increase buffer size""; I add ""--genomicsdb-vcf-buffer-size 16384000"" , it causes different error ""Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space"". This is my command and work log.; My java version is ; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12). GATK is very helpful in my research, and I really need some help to get it work. gatk --java-options ""-Xmx48g -Xms48G"" GenomicsDBImport -V C1_sentieon_gvcf.gz .......... -V SCAU-106.gvcf.gz -V SCAU-107.gvcf.gz -V SCAU-108.gvcf.gz -V SCAU-128.gvcf.gz --genomicsdb-workspace-path my_database.chr01 -R IRGSP-1.0_genome.fasta --genomicsdb-vcf-buffer-size 16384000 --intervals chr01. 11:48:08.245 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/ayu/anaconda3/share/gatk4-4.0.5.1-0/gatk-package-4.0.5.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 11:48:09.327 INFO GenomicsDBImport - ------------------------------------------------------------; 11:48:09.327 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.0.5.1; 11:48:09.327 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:48:09.327 INFO GenomicsDBImport - Executing as ayu@ayu on Linux v5.15.90.1-microsoft-standard-WSL2 amd64; 11:48:09.327 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 11:48:09.327 INFO GenomicsDBImport - Start Date/Time: November 26, 2023 11:48:08 AM CST; 11:48:0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8593:739,release,release,739,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8593,2,['release'],"['release', 'release-']"
Deployability,I guess not. singularity will be agnostic regarding the anaconda//python install,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6396#issuecomment-577234171:73,install,install,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6396#issuecomment-577234171,1,['install'],['install']
Deployability,I guess that should be fixed as well. Do you have the command and data to reproduce... I can add the integration test for that.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5434#issuecomment-447125138:101,integrat,integration,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5434#issuecomment-447125138,1,['integrat'],['integration']
Deployability,I guess we can disable running it in parallel if that fix it for now. Slower but it might not make much of a difference in practice as running the whole pipeline in the cloud takes a while anyway.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7060#issuecomment-770964912:153,pipeline,pipeline,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7060#issuecomment-770964912,1,['pipeline'],['pipeline']
Deployability,"I had a look to the other branch, @droazen, and I think that it is more functional than this one:; - Check if the input already have a sequence dictionary, and only updates if `--replace` is provided. The version in this PR just overrides the dictionary.; - Check if all the variants agree with the new sequence dictionary, throwing an error if the contig is not present or the variant falls outside the chromosome range. This version does not account at all for that.; - It is a `VariantWalker`, and thus the code is simplest. But the pitfall of this is that if #2223 is implemented, that class will require a dictionary for the input as a `GATKTool`. I'm not sure how that is going to be done, but I guess that it will introduce problems in the class implemented by @cmnbroad. I think that the other version is more complete and I like it more because it is more concern about putative problems.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2232#issuecomment-257143389:165,update,updates,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2232#issuecomment-257143389,2,['update'],['updates']
Deployability,"I have Java 8 installed, but it's not my _default_ Java version, so `gradle check` gives me this error message:. ```; :compileJava FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':compileJava'.; > invalid source release: 1.8; ```. `JAVA_HOME=$JAVA8_HOME gradle check` succeeded. . I would prefer an error message like ""Hellbender requires JAVA_HOME to point to a valid Java 8 installation"" to make it immediately obvious what needs to be done.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/489:14,install,installed,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489,3,"['install', 'release']","['installation', 'installed', 'release']"
Deployability,I have a new build of the GKL that I need to test and then integrate into a new gatk. It's not available yet though.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-814269292:59,integrat,integrate,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-814269292,1,['integrat'],['integrate']
Deployability,"I have a project that depends on `4.alpha.2-183-ge1e71d7-SNAPSHOT` (I am planning to update it, that's why I look at it), and I discovered that the jfrog repository the folder is empty: https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/broadinstitute/gatk/4.alpha.2-183-ge1e71d7-SNAPSHOT/. When looking at the jfrog repository, it looks like no SNAPSHOT jar file is present. As an example, one after-release SNAPSHOT: https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/broadinstitute/gatk/4.0.0.0-1-g9423d25-SNAPSHOT/. Is this in purpose or should it be present? It looks like the current commit https://github.com/broadinstitute/gatk/commit/8463525cc9b523cd00daf2810bcf1c13b69ce0a1 does contain a proper artifact, but I am wondering how long the snapshots are going to be maintained. Thank you!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4565:85,update,update,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4565,2,"['release', 'update']","['release', 'update']"
Deployability,"I have a run going now. On Jan 4, 2018 15:32, ""samuelklee"" <notifications@github.com> wrote:. > Placeholders for now. We can tweak the actual values once @LeeTL1220; > <https://github.com/leetl1220> checks effect on validation.; >; > Closes #4032 <https://github.com/broadinstitute/gatk/issues/4032>.; > ------------------------------; > You can view, comment on, or merge this pull request online at:; >; > https://github.com/broadinstitute/gatk/pull/4046; > Commit Summary; >; > - Changed default values for ModelSegments segmentation parameters.; >; > File Changes; >; > - *M* src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > ModelSegments.java; > <https://github.com/broadinstitute/gatk/pull/4046/files#diff-0> (6); >; > Patch Links:; >; > - https://github.com/broadinstitute/gatk/pull/4046.patch; > - https://github.com/broadinstitute/gatk/pull/4046.diff; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/4046>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk8coObtbYN125S1_BMBx1VnnmbF4ks5tHTVzgaJpZM4RTh_B>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355405908:741,Patch,Patch,741,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355405908,2,"['Patch', 'patch']","['Patch', 'patch']"
Deployability,"I have a version of this working in the branch `cw_phase_star_allele`, but am holding off on making a PR until https://github.com/broadinstitute/gatk/pull/6859 can be merged to avoid conflicting changes to integration test files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5651#issuecomment-712158375:206,integrat,integration,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5651#issuecomment-712158375,1,['integrat'],['integration']
Deployability,I have also stumbled over this. I am adding a detailed error log.; I think that the incompatibility of accelerated PairHMM with a tmp directory mounted noexec should be mentioned in ; the installation requirements. I found it well-documented in [the troubleshooting section](https://gatk.broadinstitute.org/hc/en-us/articles/18965297287067-How-to-setup-and-use-temporary-folder-for-GATK-local-execution). But everyone with this setup will experience falling back to the slow implementation for no other reason. . ```; INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/; miniconda2/envs/polyploidPhasing/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; WARN NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils9418239050694741169.so: /tmp/libgkl_utils9; 418239050694741169.so: failed to map segment from shared object: Operation not permitted); WARN IntelPairHmm - Intel GKL Utils not loaded; PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8453#issuecomment-1905717389:188,install,installation,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8453#issuecomment-1905717389,1,['install'],['installation']
Deployability,I have asked the user for test data and will update this issue when they get back to me.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6776#issuecomment-683959259:45,update,update,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776#issuecomment-683959259,1,['update'],['update']
Deployability,"I have been able to get the connector working on GCP VMs where I have manually authenticated locally with my own account. I have not successfully gotten it working on a cromwell VM or ortherwise using manually supplied keyfiles. Anecdotal evidence, but its worth mentioning that both: `fs.gs.impl`; `fs.AbstractFileSystem.gs.impl`; seem to be optional for getting a run to work. It seems to have defaulted to the right things in the trials I've tested (though thats not to say the default will always work). I have put in a question on the issue tracker asking about available authentication inside a pipelines API VM.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5996#issuecomment-500846568:601,pipeline,pipelines,601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5996#issuecomment-500846568,1,['pipeline'],['pipelines']
Deployability,"I have been running into an issue with Funcotator where some mutations are causing Funcotator to crash because it attempts to query a segment that extends beyond the boundary of the transcript ( see https://github.com/broadinstitute/gatk/issues/6345 ). This pull request addresses the issue by adding a check for transcript length before executing the query. I looked at the code, and Funcotator currently handles problematic sequence queries in `getFivePrimeUtrSequenceFromTranscriptFasta()` by returning an empty string. I modified `getFivePrimeUtrSequenceFromTranscriptFasta()` to also return an empty string when the segment it is trying to retrieve extends beyond the boundary of the transcript. . I have a small VCF that can be used to reproduce the problem using the current code on `master` and the hg38 data source, and I have verified that this pull request allows Funcotator to process the problematic variant without crashing. I did not add the VCF to the tree, but can provide it if that is preferred. Is there any guidance for how to implement integration tests with funcotator? The Funcotator data source I am using is ~12gb, but I would think the problem could be reproduced with 1 transcript and 1 variant. This is my first pull request to GATK, so please let me know if there is anything you would like me to adjust, I'm happy to address any comments.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6546:1058,integrat,integration,1058,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6546,1,['integrat'],['integration']
Deployability,"I have been too quick on this bug diagnosis, sorry. Actually, the VCF given to FilterMutectCalls was the results of a `bcftools concat` operation. And I found out that `bcftools` is actually the culprit for setting this dot value. The value in the original Mutect2 VCF was `MPOS=-2147483648`. All such values were converted by `bcftools` into a `.`. I have replaced `bcftools` with `picard` to merge Vcfs, relaunched and I now wait for the results. I'll keep this post updated. Nonetheless, what a value of `-2147483648` is supposed to mean in `MPOS` tag ?. ```; chr1 885346 . T A . . DP=90;ECNT=8;MBQ=30,29;MFRL=309,433;MMQ=60,27;MPOS=-2147483648;NALOD=-1.307e+00;NLOD=7.24;POPAF=1.37;SAAF=0.081,0.00,0.078;SAPP=5.496e-03,0.055,0.940;TLOD=10.89; GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS 0|1:47,4:0.094:51:26,2:21,2:0|1:885342_GCT_G:885342 0|0:38,1:0.049:39:15,1:23,0:0|1:885342_GCT_G:885342; chr1 888222 . T C . . DP=78;ECNT=2;MBQ=31,31;MFRL=310,293;MMQ=60,30;MPOS=-2147483648;NALOD=-1.352e+00;NLOD=6.64;PON;POPAF=2.23;SAAF=0.051,0.00,0.049;SAPP=6.659e-03,0.023,0.970;TLOD=4.46; GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS 0|1:39,2:0.070:41:20,0:19,2:0|1:888199_TTTTCTTCACATTATA_T:888199 0|0:36,1:0.051:37:20,1:16,0:0|1:888199_TTTTCTTCACATTATA_T:888199; chr1 1401646 . TC T . . DP=75;ECNT=3;MBQ=29,30;MFRL=305,143;MMQ=60,60;MPOS=-2147483648;NALOD=1.10;NLOD=6.92;POPAF=5.40;SAAF=0.030,0.030,0.038;SAPP=8.222e-03,9.890e-03,0.982;TLOD=4.44 GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS 0|1:50,2:0.056:52:27,1:23,1:0|1:1401637_GCTGCTGA_G:1401637 0|0:23,0:0.040:23:12,0:11,0:0|1:1401637_GCTGCTGA_G:1401637; chr1 3870695 . A ACCCT . . DP=59;ECNT=2;MBQ=31,29;MFRL=303,282;MMQ=60,60;MPOS=-2147483648;NALOD=1.54;NLOD=10.23;POPAF=5.40;SAAF=0.081,0.00,0.080;SAPP=9.489e-03,0.029,0.962;TLOD=5.11 GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS 0|1:23,2:0.111:25:12,2:11,0:0|1:3870691_CCG_C:3870691 0|0:34,0:0.028:34:17,0:17,0:0|1:3870691_CCG_C:3870691; chr1 4136053 . GGTTAGTCATCATGGGAGTGA G . . DP=87;ECNT=1;MBQ=30,30;MFRL=314,306;MMQ=60,60;MPOS=-2147483648;",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5684#issuecomment-464516807:469,update,updated,469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5684#issuecomment-464516807,1,['update'],['updated']
Deployability,I have been trying to run the tutorial ( https://gatkforums.broadinstitute.org/gatk/discussion/10913/how-to-run-the-pathseq-pipeline ). When running without the --spark-master the turoail runs smoothly. Bu twhen I try my spark master I get an error. I downloaded SPARK 2.2.0 with hadoop 2.7.3; Java is 1.8.0_131; I set the java classpath (I think correctly); I am aware of this thread: https://github.com/broadinstitute/gatk/issues/3050. But noentheless I cannot get the error to solve. I tried to copy the jar files:; hbase-client-1.4.3.jar; hbase-common-1.4.3.jar; hbase-hadoop2-compat-1.4.3.jar; hbase-protocol-1.4.3.jar; hbase-server-1.4.3.jar; To my spark jar folder. Shall I do smething else? I am also a SPARK newbie. Thank you very much!. ***************** Here is the error log:. ../../../gatk PathSeqPipelineSpark --spark-master spark://xx.xx.xx.xx:7077 --input test_sample.bam --filter-bwa-image hg19mini.fasta.img --kmer-file hg19mini.hss --min-clipped-read-length 70 --microbe-fasta e_coli_k12.fasta --microbe-bwa-image e_coli_k12.fasta.img --conf [jars=~/bin/spark-2.2.0-bin-hadoop2.7/jars/hbase-client-1.4.3.jar] --taxonomy-file e_coli_k12.db --output output.pathseq.bam --verbosity DEBUG --scores-output output.pathseq.txt; Using GATK jar /scratch/home/int/eva/zorzan/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /scratch/home/int/eva/zorzan/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar PathSeqPipelineSpark --spark-master spark://xx.xx.xx.xx:7077 --input test_sample.bam --filter-bwa-image hg19mini.fasta.img --kmer-file hg19mini.hss --min-clipped-read-length 70 --microbe-fasta e_coli_k12.fasta --microbe-bwa-image e_coli_k12.fasta.img --conf [jars=~/bin/spark-2.2.0-bin-hadoop2.7/jars/hbase-client-1.4.3.jar] --taxonomy-file e_coli_k12.db --output output.pathseq.bam --verbosity DEBUG --scores-output,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:124,pipeline,pipeline,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['pipeline'],['pipeline']
Deployability,"I have gcc installed and have also tried the suggestion that @scalavision has suggested and still I get the warning ""Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!"". I am not sure that I used the correct path. I found the path to gcc 7.4.0 path by running ; `gcc -print-prog-name=cc1` -v",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6012#issuecomment-1364652887:11,install,installed,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6012#issuecomment-1364652887,1,['install'],['installed']
Deployability,"I have incorporated your changes, made default to not use FASTEST_AVAILABLE for smithwaterman and also updated the pull request to use latest GKL 0.8.1 which has the AVX512 support for smithwaterman as well. ; Thanks,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3701#issuecomment-341722707:103,update,updated,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3701#issuecomment-341722707,1,['update'],['updated']
Deployability,"I have just experienced the same problem of stack overflow with my first attempt to use gatk HaplotypeCallerSpark with the option --spark-master local[*]. My GATK version is 4.1.2.0,that was installed via bioconda. ; Should I wait for the corrected version or is there a way to circumvent the problem with extra install or by using options like --java-options '-XssOptimalValue'?; When is the corrected version expected? Is Q2 (end of June?) still an option? Will it be readily on bioconda then?; Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-499414227:191,install,installed,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-499414227,2,['install'],"['install', 'installed']"
Deployability,"I have just realized that this is indeed a regression from GATK 4.0 to GATK 4.1:; ```; wget https://github.com/broadinstitute/gatk/releases/download/4.0.12.0/gatk-4.0.12.0.zip; unzip gatk-4.0.12.0.zip; ```. Running this:; ```; gatk-4.0.12.0/gatk \; Mutect2 \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; -O output.vcf.gz \; -L chr1:233443225-233443225 \; --tumor SM; ```. Generates a VCF file with one variant:; ```; GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP; 0/1:3,15:0.799:18:3,7:0,8:0.818,0.818,0.833:0.028,0.025,0.948; ```; So that the AD counts make sense with the previous version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-521801586:131,release,releases,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-521801586,1,['release'],['releases']
Deployability,"I have managed to generate a minimal bam file that reproduces the issue. First of all, you have to download the mini input.bam file from this dropbox link: https://www.dropbox.com/sh/xae79hanumpireu/AABKo1l4Y-z5G5YLBqSpylRva?dl=0. Then the following code will reproduce the issue:; ```; wget https://github.com/broadinstitute/picard/releases/download/2.19.0/picard.jar. wget https://github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0.zip; unzip gatk-4.1.2.0.zip. wget -O- ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | \; gzip -d > GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. java -jar picard.jar \; CreateSequenceDictionary \; R=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict. (echo ""##fileformat=VCFv4.2""; \; echo ""##contig=<ID=chrX,length=156040895>""; \; echo -e ""#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO""; \; echo -e ""chr1\t97329945\t.\tT\tA\t.\t.\t.""; \; echo -e ""chr1\t97329967\t.\tC\tT\t.\t.\t."") | bgzip > input.vcf.gz && \; tabix -f input.vcf.gz. for score in 11 12; do; gatk-4.1.2.0/gatk HaplotypeCaller \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; -O output.$score.vcf.gz \; --genotyping-mode GENOTYPE_GIVEN_ALLELES \; --alleles input.vcf.gz \; -L chr1:97329945-97329967 \; --min-base-quality-score $score && \; bcftools query \; -f ""[%CHROM\t%POS\t%REF\t%ALT\t%GT\t%AD\n]"" \; output.$score.vcf.gz \; -r chr1:97329945-97329967; done; ```. When the parameter `--min-base-quality-score 11` is used, the GT/AD output is this:; ```; chr1	97329945	T	A	1/1	0,35; chr1	97329967	C	T	1/1	0,33; ```; When the parameter `--min-base-quality-score 12` is used, the GT/AD output is this:; ```; chr1	97329945	T	A	0/1	9,10; chr1	97329967	C	T	0/1	6,11; ```; The first output is the output that makes sense. W",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6045:333,release,releases,333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6045,2,['release'],['releases']
Deployability,"I have no objection to this PR. However, it might be simpler to modify the SV pipeline to optionally produce this data on the fly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2607#issuecomment-297147327:78,pipeline,pipeline,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2607#issuecomment-297147327,2,['pipeline'],['pipeline']
Deployability,"I have no problems whatsoever with the code, but I do have some concerns about the design:. In the SV group's pipeline, we distribute this multi-gig file from its home in the cloud once at cluster-creation time, and then reuse it for multiple client executions. There are no superfluous copies lying about anywhere, and no redundant copying operations. We can give it any name we wish, and put it anywhere we desire (except that the path must be the same on every worker). This code, if I'm reading it correctly, will redistribute the file from a non-permanent home on the master's local file system or on the HDFS (to which it must be copied redundantly at least once per cluster instantiation), and then it will further be redundantly copied to a temporary location on each worker's local file system with every client execution. I don't know if that's overhead that we can live with, or whether that might prevent us from writing clients with brief execution times. I'm just opening the issue for discussion. We also lose a little flexibility in that the image must live in the same directory as the reference, though I don't think that's a serious drawback -- it's a perfectly logical place for it. However, since we're just appending a fixed extension ("".img"") to the reference name we can only have one image file per reference, which may be a problem because different images need to be created for different versions of bwa and for various options such as the list of alt contigs. We can handle the first problem by insisting that all clients on a particular cluster stick to one version of bwa, which is probably a good idea, anyway, but I think we're stuck if clients need to specify various alt contig lists. It might be better to provide a default path of ""ref-name""+"".img"", but allow that default to be overridden. Also, just to twist the knife a bit, it's too bad we never reviewed my PR for gatk-bwamem-jni, which version-stamped the images for safety. It's now languished since July, a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3643#issuecomment-333598350:110,pipeline,pipeline,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3643#issuecomment-333598350,1,['pipeline'],['pipeline']
Deployability,"I have noticed that running print reads with a stringent filter which I expect to only return a handful of reads results in the progress meter never printing any progress. This makes it look like the gatk has hung despite the fact it is chugging away and filtering every read it passes over. This should be updated to include an indication of how many reads have been filtered. Additionally, it should be improved to use a second thread to make periodic updates based on execution time in case the tool really has hung in order to make it clearer to the user what is going on.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4641:307,update,updated,307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4641,2,['update'],"['updated', 'updates']"
Deployability,"I have pull requests in flight for both (1) and (2). They are 1469; <https://github.com/GoogleCloudPlatform/google-cloud-java/pull/1469> and; 1470 <https://github.com/GoogleCloudPlatform/google-cloud-java/pull/1470>. Cheers,; JP. On Tue, Dec 6, 2016 at 3:54 AM, Tom White <notifications@github.com> wrote:. > Yes, Hadoop-BAM uses the NIO API to do file merging, whereas in GATK we; > were using the Hadoop APIs (and therefore the GCS<->HDFS adapter) to do it.; >; > It looks like there are a couple of things needed in GCS-NIO to use the; > NIO API for this.; >; > 1. GoogleCloudPlatform/google-cloud-java#1450; > <https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1450>; > so that we don't have to special-case gs URIs to remove everything; > except the scheme and host when looking up the filesystem (see; > https://github.com/HadoopGenomics/Hadoop-BAM/; > blob/master/src/main/java/org/seqdoop/hadoop_bam/util/; > NIOFileUtil.java#L40; > <https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L40>; > ); > 2. GoogleCloudPlatform/google-cloud-java#813; > <https://github.com/GoogleCloudPlatform/google-cloud-java/issues/813>; > to support path matching (https://github.com/HadoopGenomics/Hadoop-BAM/; > blob/master/src/main/java/org/seqdoop/hadoop_bam/util/; > NIOFileUtil.java#L90; > <https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L90>; > ); >; > There may be more, as I stopped there. The best way forward is probably to; > go back to the old code in GATK while the deficiencies in GCS-NIO are fixed; > and then released.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-266151447:1662,release,released,1662,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-266151447,1,['release'],['released']
Deployability,"I have resolved the conflicts, and updated new code that's been added since my original submission of this code that tries to use PipelineOptions. This is a bit of a race. The longer this PR is sitting, the more people have to write code that deals with PipelineOptions that I then have to go back and remove.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2565#issuecomment-300920235:35,update,updated,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2565#issuecomment-300920235,3,"['Pipeline', 'update']","['PipelineOptions', 'updated']"
Deployability,"I have three main reasons to propose to move the arguments in CLP to an argument collection that is configurable by downstream tools/projects:. 1. Support hiding some arguments for downstream projects. For example, I do not want to support a config file by the user, but rather decide the settings for the framework and expose only some configuration.; 1. Set custom defaults for some downstream tools (including GATK). For example, a concrete tool might want to force the temp directory to be specified to avoid failures due to no space (and specify that in the documentation).; 1. Support old-style arguments (not kebab-case) for downstream projects that rely on the current argument definitions. I am specially affected by this one, because updating GATK to the 4.0.0 release of January will be a breaking change that will cause some nightmares for my users - and I don't want to do a major version bump yet (I have to re-work a bit my own framework before it). Thus, the first commit of this PR holds the proposal for the new argument collection. As I know that the team is also trying to normalize arguments and documentation, I included two more commits to help with the task (they can be removed if you think that it is better after the argument collection):; * Use `java.nio.Path` for temp directories (to support temp directories in HDFS, for example); * Change arguments moved to the collection to kebab-case (to help with #3853)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998:337,configurat,configuration,337,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998,2,"['configurat', 'release']","['configuration', 'release']"
Deployability,"I have to deal with this component recently and I found the design rather awkward.... In general between GATK and htsjdk we don't seem to have a proper support for managing and querying Supplementary alignment information from read alignment records:. 1. Querying: implemented in htsjdk consists in forging artificial SAMRecords that contain only the alignment info in the SA tag element... It seems to me that it makes more sense to create class to hold this information alone (e.g. ReadAlignmentInfo or ReadAlignment); SATagBuilder already has defined a private inner class with that in mind ""SARead"" so why not flesh it out and make it public. 2. Writing: currently SATagBuilder gets attached to a read, parsing its current SA attribute content into SARead instances. It provides the possibility adding additional SAM record one by one or clearing the list. ... then it actually updates the SA attribute on the original read when a method (setTag) is explicitly called.; I don't see the need to attach the SATag Builder to a read... it could perfectly be free standing; the same builder could be re-apply to several reads for that matter and I don't see any gain in hiding the read SA tag setting process,... even if typically this builder output would go to the ""SA"" tag, perhaps at some point we would like to also write SA coordinate list somewhere else, some other tag name or perhaps an error message... why impose this single purpose limitation?; I suggest to drop the notion of a builder for a more general custom ReadAlignmentInfo (or whatever name) list. Such list could be making reference to a dictionary to validate its elements, prevent duplicates, keep the primary SA in the first position... etc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3324:882,update,updates,882,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3324,1,['update'],['updates']
Deployability,"I haven't been able to reproduce this locally by running `ReadsPipelineSparkIntegrationTest` repeatedly. In fact, it looks like another test is interacting with this one, since the stack trace references HDFS paths, but this test doesn't use HDFS at all. Another oddity: `TribbleIndexedFeatureReader` implies it's reading a vcf.idx file, but `HaplotypeCallerSpark`, where the exception occurs, is not reading any VCF files (although BQSR does earlier in the pipeline for known sites). Also, we shouldn't be serializing `FeatureDataSource` objects with remote resources any more, since we use Spark `--files` to copy them to the worker nodes (see https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/engine/spark/GATKSparkTool.java#L699). So we shouldn't be seeing `FeatureDataSource` trying to serializing with an HDFS path. Has anyone seen this running locally on their machine, or only on Travis?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-469224499:458,pipeline,pipeline,458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-469224499,1,['pipeline'],['pipeline']
Deployability,I haven't updated the tests since I want confirmation on approach and the answers to our previous questions. Updating the test files is something I only want to do once.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-436771688:10,update,updated,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-436771688,1,['update'],['updated']
Deployability,I just built the base image locally and it installs samtools v1.7:; ```; (base) markw@WMC9F-819:~/IdeaProjects/gatk/scripts/docker/gatkbase$ docker run 53df03aff4c5 samtools; Program: samtools (Tools for alignments in the SAM format); Version: 1.7 (using htslib 1.7-2); ```; I'm not sure why then the latest gatk images are still on 0.1.19?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6148#issuecomment-650268591:43,install,installs,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6148#issuecomment-650268591,1,['install'],['installs']
Deployability,"I just checked our GATK best practices hg19 panel of normals: gs://gatk-best-practices/somatic-b37/Mutect2-exome-panel.vcf and this false positive is in there. Using our best practices pipeline will eliminate this and probably many other false positives. Except in very rare circumstances it is a bad idea to use a custom-made panel. Looking at your shell script it seems that this custom panel was made from only 27 samples, which is far too few. I can not stress enough how serious this issue is. If possible you should re-run all of your results using the best-practices panel of normals. If computational cost is an issue you can remove everything overlapping with the panel, using GATK SelectVariants or something like that, as a post-processing step without having to re-run Mutect2. PS: I just noticed that these are in clinical reports, which makes it much more serious. Please **throw out all previous results immediately and filter with our best-practices panel of normals**.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8340#issuecomment-1613996173:185,pipeline,pipeline,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8340#issuecomment-1613996173,1,['pipeline'],['pipeline']
Deployability,"I just created a Maven Project with Eclipse and modified the pom.xml as reported [here](https://pastebin.com/kwi7gSRk) and then I executed `mvn clean install -U` inside the folder of the project; ```; <project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""; xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">; <modelVersion>4.0.0</modelVersion>; <groupId>uk.ac.ncl</groupId>; <artifactId>GATKpipe</artifactId>; <version>0.0.1-SNAPSHOT</version>; <repositories>; <repository>; <snapshots />; <id>snapshots</id>; <name>libs-snapshot</name>; <url>https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot</url>; </repository>; </repositories>; <dependencies>; <dependency>; <groupId>org.broadinstitute</groupId>; <artifactId>gatk</artifactId>; <version>4.beta.6-18-g2ee7724-20171025.162137-1</version>; </dependency>; </dependencies>; </project>; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339930421:150,install,install,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339930421,1,['install'],['install']
Deployability,"I just heard that production is moving to GatherVCFs, which is getting some update that might be pertinent. I know that the workflows say that they are using MergeVCFs because of other issues:. ```; # using MergeVcfs instead of GatherVcfs so we can create indices; # WARNING 2015-10-28 15:01:48 GatherVcfs Index creation not currently supported when gathering block compressed VCFs.; ```. ---. This concern is germane to any WGS analyses and perhaps not concerning for WES analyses. So perhaps our current WDL workflows that use SplitIntervals could expressly state that they are not safe for WGS variant calling analyses.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-306888339:76,update,update,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-306888339,1,['update'],['update']
Deployability,I just noticed this but wanted to pass along the tidbit that with the SV tools we moved to Dataproc 1.3 (and Spark 2.3.0) because we started hitting errors like this:. `java.io.IOException: Failed to create local dir in /hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1535480872324_0648/blockmgr-1193ec43-c523-423b-bd88-e40ee0102cca/24`. In large jobs running on with the Dataproc 1.2 image after Google released Dataproc 1.3. I also hit the error trying to run Hail the other day and filed an issue with Google here:. https://issuetracker.google.com/issues/113360059,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5125#issuecomment-417345290:418,release,released,418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5125#issuecomment-417345290,1,['release'],['released']
Deployability,"I just pulled to the latest version and was surprised to see `gradlew clean` not work!; ```; $ ./gradlew clean; (...); Could not find org.broadinstitute:barclay:1.0.0-24-g87c3fa2-SNAPSHOT; ```. Reverting to 1.0.0-17-g30db73c-SNAPSHOT didn't work (same error).; Reverting to 1.0.0 made it fail somewhere else, with:; Could not resolve org.broadinstitute:gatk-bwamem-jni:1.0.0-rc1-SNAPSHOT. What's going on? Is there something wrong with my configuration?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2579:439,configurat,configuration,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2579,1,['configurat'],['configuration']
Deployability,"I just pushed a branch:; https://github.com/broadinstitute/picard/tree/yf_documentation_update we; can use that for initial testing. On Tue, Dec 5, 2017 at 1:56 PM, sooheelee <notifications@github.com> wrote:. > @samuelklee <https://github.com/samuelklee>, thanks for the update and; > suggestion. I moved CollectAllelicCounts to the Coverage Analysis; > category. CollectFragmentCounts isn't on the list currently so I added it; > to the same. I hope I'm not missing a bunch of other new tools given I; > missed this one.; >; > @yfarjoun <https://github.com/yfarjoun>; >; > - You are now in charge of deciding whether we should include; > authorship in code. What the Comms team wants is for authorship to NOT show; > up in the gatkDoc/javaDoc. If you want to keep them, author lines should be; > at the bottom and formatted so they do not show up in the documentation.; > Geraldine is fine with completely removing them if you prefer that. There; > is a format trick that has javaDoc skip the author line and I can get that; > to you if you decide to keep some of these and @vdauwera; > <https://github.com/vdauwera> would know this or I can get you what I; > see in other docs. Let either of us know.; > - I can help you test your changes. I think the categories are good to; > go now so I will need to put these into both Picard and GATK; > HelpConstants.java, with the latter being a placeholder until the new; > Picard release is incorporated into the next GATK release, with variables; > that then must be included in each tool doc. I will find an example in a; > bit. Which tool do you want to test? @cmnbroad; > <https://github.com/cmnbroad> can explain the engineering details in; > engineering lingo if you need more information.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349404645>,; > or mute the thread; > <https://github.com/notifications/unsubscr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349407253:272,update,update,272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349407253,1,['update'],['update']
Deployability,"I just ran our pipeline with `--conf spark.driver.userClassPathFirst=false`. It failed near the end with an error that I think is unrelated to the parameter (looks like a regression bug in our logic introduced recently), so I'm inclined to believe changing this setting is fine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3946#issuecomment-357348189:15,pipeline,pipeline,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3946#issuecomment-357348189,1,['pipeline'],['pipeline']
Deployability,I just ran the pipeline from master on the WGS1 BAM file with the following parameters:. ```; /Users/cwhelan/Documents/code/gatk/gatk StructuralVariationDiscoveryPipelineSpark -I hdfs://cw-test-m:8020/data/G94794.CHMI_CHMI3_WGS1.cram.bam -O hdfs://cw-test-m:8020/output/variants/inv_del_ins.vcf -R hdfs://cw-test-m:8020/reference/Homo_sapiens_assembly38.2bit --aligner-index-image /mnt/1/reference/Homo_sapiens_assembly38.fasta.img --exclusion-intervals hdfs://cw-test-m:8020/reference/Homo_sapiens_assembly38.kill.intervals --kmers-to-ignore hdfs://cw-test-m:8020/reference/Homo_sapiens_assembly38.kill.kmers --cross-contigs-to-ignore hdfs://cw-test-m:8020/reference/Homo_sapiens_assembly38.kill.alts --breakpoint-intervals hdfs://cw-test-m:8020/output/intervals --fastq-dir hdfs://cw-test-m:8020/output/fastq --contig-sam-file hdfs://cw-test-m:8020/output/assemblies.sam --target-link-file hdfs://cw-test-m:8020/output/target_links.bedpe --exp-variants-out-dir hdfs://cw-test-m:8020/output/experimentalVariantInterpretations -- --spark-runner GCS --cluster cw-test --num-executors 20 --driver-memory 30G --executor-memory 30G --conf spark.yarn.executor.memoryOverhead=5000 --conf spark.network.timeout=600 --conf spark.executor.heartbeatInterval=120 --conf spark.driver.userClassPathFirst=false; ```. It failed near the end of the pipeline. Here is the tail of the log:. ```; 20:38:14.368 INFO StructuralVariationDiscoveryPipelineSpark - Used 3549 evidence target links to annotate assembled breakpoints; 20:38:14.462 INFO StructuralVariationDiscoveryPipelineSpark - Called 662 imprecise deletion variants; 20:38:14.492 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 7234 variants.; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - INV: 184; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4486; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1170; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1394; 18/01/12 20:,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:15,pipeline,pipeline,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['pipeline'],['pipeline']
Deployability,"I just tried with gatk 4.1.7.0 and 4.1.8.0 released zips and cannot reproduce the issue. I can only see buffer resize logging messages when I use a debug version of libtiledbgenomicsdb.so in my private builds. . That said, `gatk 4.1.7.0` picks up `libtiledbgenomicsdb.so` from the LD_LIBRARY_PATH, otherwise it extracts from the genomicsdb.jar. @ldgauthier, do you have an older version of the native `libtiledbgenomicsdb.so` in your LD_LIBRARY_PATH env? That could be one cause. Otherwise, if you move to using `gatk 4.1.8.1` as @droazen recommends, it will only pick up the native library packed with the genomicsdb 1.3.0 jar. To override the packed genomicsdb library, in versions 1.3.0+, one has to explicitly the path specify via java options -Dgenomicsdb.library.path=<path_to_libtiledbgenomicsdb.so>.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663238869:43,release,released,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663238869,1,['release'],['released']
Deployability,I kicked off an integration test run this morning. I don't expect the results to change (since the integration tests all set the `drop_state` themselves). But I've been burned before!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8550#issuecomment-1758135199:16,integrat,integration,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8550#issuecomment-1758135199,2,['integrat'],['integration']
Deployability,"I made no changes to the copied files. @kcibul @ahaessly let me know if I'm missing anything. I left some of the demo bash scripts thinking that we didn't necessarily need to keep them now that we have WDLs, but let me know if you want me to move anything else. . The readme update here assumes that #6881 will get merged. I also turned off the tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6902:275,update,update,275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6902,1,['update'],['update']
Deployability,I might be able to take a look on Friday. You can help me by confirming that there are integration tests where the output GT is `1|0` and that should jive with the existing PGT.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-436752851:87,integrat,integration,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-436752851,1,['integrat'],['integration']
Deployability,"I might have a working MacOS conda environment, but I haven't run all the python tools. Resolving packages got a lot harder (maybe impossible) after Sam integrated the R dependencies, so my environment branches off the old one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6813#issuecomment-730426065:153,integrat,integrated,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6813#issuecomment-730426065,1,['integrat'],['integrated']
Deployability,"I moved the WDL for importing the array manifest from the variantstore repo and added a test. The test here only checks that the WDL succeeded, it doesn't look a the results (yet). It's ingesting the manifest to a dataset with a 7 day TTL, so the tables eventually get cleaned up. That might be too long for this case, since it adds a table each time the test is run (so on push and PR). . I plan to add more of the ""end-to-end"" pipeline with more testing in the future using a similar scheme, so welcome feedback on the structure.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6860:429,pipeline,pipeline,429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6860,1,['pipeline'],['pipeline']
Deployability,I moved the tool ParallelCopyGCSDirectoryIntoHDFSSpark to the `other` category since it's just a data movement utility that's not really tied to any pipeline. Hope that's OK.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349066298:149,pipeline,pipeline,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349066298,1,['pipeline'],['pipeline']
Deployability,"I noticed a huge amount of ""Jumbo genotype annotations requested but fragment likelihoods or haplotype likelihoods were not given"" logging in some of our pipeline jobs. This patch fixes two things:. 1) I propose GATK only log this message once, the first time it hits this. 2) I think the logic here is wrong. It lacked parenthesis. This logic was:. ```; if (!jumboGenotypeAnnotations.isEmpty() && !fragmentLikelihoods.isPresent() || !haplotypeLikelihoods.isPresent()) {; ```. In java: ""false && false || true"" gives true, which is not what you want. For example, if jumboGenotypeAnnotations was empty, this would still log if either fragmentLikelihoods or haplotypeLikelihoods tests true. That doesnt seem like what you want. In contrast, false && (false || true) still tests false. Adding the parentheses fixes the logic.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7612:154,pipeline,pipeline,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7612,2,"['patch', 'pipeline']","['patch', 'pipeline']"
Deployability,"I obtain this reproducible issue with gatk 4.1.2.0:. Using the following code:; ```; wget https://github.com/broadinstitute/picard/releases/download/2.19.0/picard.jar. wget https://github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0.zip; unzip gatk-4.1.2.0.zip. wget -O- ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | \; gzip -d > GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. java -jar picard.jar \; CreateSequenceDictionary \; R=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict. (echo ""##fileformat=VCFv4.2""; \; echo ""##contig=<ID=chrX,length=156040895>""; \; echo -e ""#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO""; \; echo -e ""chrX\t1052617\t.\tC\tCAAAGGCTGCAATGTGAATGAATTTTTGGAAATAGCCCTAATGCTCATCTATGAAGGAGTGATAAACACAGCATCCTTTATCCATGCAATGGAATATTATGCAGTCTAGAAAAGGAATAAGGCTCTGACAAAAGACTGCAATATGTATGAATTTTGGAAACAGCCCTACTGCCCATCTATAAAGGAATGGATAAACACAGCATAGTTCATCTATACAATGCAATATTATAATGGAATATTATGCAGCCTGGAACAGGAACAAGGCTCTGAG\t.\t.\t."") | \; bgzip > input.vcf.gz; \; tabix -f input.vcf.gz. (echo -e ""@HD\tVN:1.6\tGO:none\tSO:coordinate""; \; echo -e ""@SQ\tSN:chrX\tLN:156040895""; \; echo -e ""@RG\tID:ID\tPL:ILLUMINA\tPU:ID\tLB:LIBRARY\tSM:SAMPLE"") | \; samtools view -Sb -o input.bam; \; samtools index input.bam. gatk-4.1.2.0/gatk HaplotypeCaller \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; -O output.vcf.gz \; --genotyping-mode GENOTYPE_GIVEN_ALLELES \; --alleles input.vcf.gz; ```. I get the following error:. ```; java.lang.IllegalArgumentException: Cigar cannot be null; 	at org.broadinstitute.hellbender.utils.read.AlignmentUtils.consolidateCigar(AlignmentUtils.java:716); 	at org.broadinstitute.hellbender.utils.haplotype.Haplotype.setCigar(Haplotype.java:193); 	at org.broadinstitute.hellbender.tools.walker",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6037:131,release,releases,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6037,2,['release'],['releases']
Deployability,"I obtain this reproducible issue with gatk 4.1.3.0:. First of all, you have to download the mini input.bam file from this dropbox link: https://www.dropbox.com/sh/78rz5wrhu9zkfzh/AACW9ZPhl4WnD-wmAkKcdHT3a?dl=0. Then setup a GATK working environment:; ```; wget https://github.com/broadinstitute/picard/releases/download/2.19.0/picard.jar. wget https://github.com/broadinstitute/gatk/releases/download/4.1.3.0/gatk-4.1.3.0.zip; unzip gatk-4.1.3.0.zip. wget -O- ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405\; .15_GRCh38_no_alt_analysis_set.fna.gz | \; gzip -d > GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. java -jar picard.jar \; CreateSequenceDictionary \; R=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict; ```. Now if I run Mutect2:; ```; gatk-4.1.3.0/gatk \; Mutect2 \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; -O output.vcf.gz \; -L chr1:233443225-233443225; ```. This will generate a VCF file with one variant:; ```; GT:AD:AF:DP:F1R2:F2R1:SB; 0/1:6,21:0.778:27:4,8:0,11:2,4,12,9; ```; With an allelic depth of six supporting the reference. However, there are only four fragments supporting the reference. If I remove those for fragments from the BAM file:; ```; samtools view -h input.bam | \; grep -v "":6112\|:10233\|:18618\|:20229"" | \; samtools view -Sb -o input2.bam && \; samtools index input2.bam; ```. And I run Mutect2 again:; ```; gatk-4.1.3.0/gatk \; Mutect2 \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input2.bam \; -O output.vcf.gz \; -L chr1:233443225-233443225; ```. It will generate a VCF with the same variant:; ```; GT:AD:AF:DP:F1R2:F2R1:SB; 0/1:0,20:0.954:20:0,7:0,11:0,0,11,9; ```; With an allelic depth of zero supporting the reference. The same problem exists with the HaplotypeCaller. I believe this was not the intended ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6096:302,release,releases,302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6096,2,['release'],['releases']
Deployability,I patched this in joptSimple in https://github.com/pholser/jopt-simple/pull/89. This can be enabled by upgrading to the 5.0.1-beta build or waiting for a stable release. Unclear on the time lines for stable release. I suspect if we really need it we can ask for a 4.10 release and the maintainer would likely be willing to create one.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1347#issuecomment-178650249:2,patch,patched,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1347#issuecomment-178650249,4,"['patch', 'release']","['patched', 'release']"
Deployability,"I prefer to host the docs in the forum for the following reasons:; - We want people to use the GATK website and forum as a one-stop shop for all GATK needs, not have to go to Github for some things, both for convenience and as a matter of branding;; - Many end-users don't know/understand Github;; - In the forum we can easily host multiple documents in a way that's intuitive to navigate;; - We can easily render the docs as webpages within the GATK website, which many end-users prefer;; - Forum docs are easy for my team to update or tweak at a moment's notice;; - Users can comment directly on the documents, or create new discussion threads, and it's easier for us to answer them if all is in the same place. ; - If we need to open a github issue ticket (for bug report, feature request etc) we can do it directly from the forum discussion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151707594:527,update,update,527,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151707594,1,['update'],['update']
Deployability,"I propose to still hide from the command line and docs the example walkers. They are meant only for developers, to show how to use some kind of walkers and have a running tool for integration tests. Having then in the command line will generate software users to run them instead of use them for developmental purposes... In addition, I think that this is a good moment to also generate a sub-module structure (as I suggested in #3838) to separate artifact for different pipelines/framework bits (e.g., engine, Spark-engine, experimental, example-code, CNV pipeline, general-tools, etc.). For the aim of this issue, this will be useful for setting documentation guidelines in each of the sub-modules: e.g., example-code should be documented for developers, but not for the final user; experimental module should have the `@Experimental` barclay annotation in every `@DocumentedFeature`; etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346291829:180,integrat,integration,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346291829,6,"['integrat', 'pipeline']","['integration', 'pipeline', 'pipelines']"
Deployability,I put this into a different branch because I upgraded GDB to fix the weird error. I don't want this feature to go into the 4.0.9.0 release so I'll do a PR of the new branch after.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4969#issuecomment-422509124:45,upgrade,upgraded,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4969#issuecomment-422509124,2,"['release', 'upgrade']","['release', 'upgraded']"
Deployability,"I rebased this, and responded to code review comments:. - updated comments; - reverted GenotypeGVCFs change; - reverted changing the default lookahead for VariantWalker side inputs. I think changing the default lookahead for VariantWalker side inputs to the new, smaller value will hurt performance for tools like VQSR. I did some crude timing tests using the FeatureDataSource default (1000 bases) proposed in this branch, and the current default (100,000 bases). The following are total times as reported by Gradle for serial runs of the VQSR integration tests:. With 1000 base lookahead:; 1m40s; 1m29s; 1m29s; 1m25s. With 100,000 base lookahead:; 1m29s; 1m17s; 1m16s; 1m18s. Back to 1000 base lookahead again:; 1m36s; 1m26s; 1m26s; 1m29s. It seems pretty consistently slower with the smaller lookahead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3480#issuecomment-417360848:58,update,updated,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480#issuecomment-417360848,2,"['integrat', 'update']","['integration', 'updated']"
Deployability,"I recently noticed a series of what were evidently memory failures when running HaplotypeCaller on some standard test WGS data when using the exact task used in the warp pipeline here: https://github.com/broadinstitute/warp/blob/develop/pipelines/broad/dna_seq/germline/variant_calling/VariantCalling.wdl. I found that running that wdl with otherwise default inputs except for `haplotype_scatter_count` being set to 10 (so each node doing approximately 5x as much work as when the default, 50, is set) I would get repeated HaplotypeCaller job failures after a few hours that had the pattern of memory failures. The errors tend to involve HaplotypeCaller abruptly ending without any sort of error message or exception at all (which could indicate the vm is dying):; ```; 03:22:15.993 INFO ProgressMeter - chr13:18173014 378.6 1419490 3749.0; 03:22:26.338 INFO ProgressMeter - chr13:18177988 378.8 1419530 3747.4; 03:22:36.801 INFO ProgressMeter - chr13:18203610 379.0 1419700 3746.1; (END); ```; Or alternatively it seems to end without the end-of-run messages being output:; ```; 23:05:30.662 INFO ProgressMeter - chr2:47207099 428.8 1372310 3200.4; 23:05:40.859 INFO ProgressMeter - chr2:47323745 429.0 1372960 3200.7; 23:05:50.896 INFO ProgressMeter - chr2:47476709 429.1 1373720 3201.2; Using GATK jar /gatk/gatk-package-4.2.2.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx6933m -Xms6933m -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -jar /gatk/gatk-package-4.2.2.0-local.jar HaplotypeCaller [INPUTS]; 2022/02/10 23:06:52 Starting delocalization.; 2022/02/10 23:06:53 Delocalization script execution started...; ```. These failures appear to be reproducible and happen at about the same point in every run. The fact that increasing the memory or decreasing the interval per shard seems to remove the issue it makes me suspect there might be an issue where Hapl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7693:170,pipeline,pipeline,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7693,2,['pipeline'],"['pipeline', 'pipelines']"
Deployability,I released a new version of Hadoop-BAM (7.8.0) and updated this PR to use it. All tests are passing now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2350#issuecomment-282037559:2,release,released,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2350#issuecomment-282037559,2,"['release', 'update']","['released', 'updated']"
Deployability,I released a snapshot. A signed artifact will follow (1.0.0). Feel free to send me feedbacks BEFORE.; https://oss.sonatype.org/content/repositories/snapshots/com/github/jsr203hadoop/jsr203hadoop/0.0.1-SNAPSHOT/. Final artifact will follow these names:. ``` xml; <groupId>com.github.jsr203hadoop</groupId>; <artifactId>jsr203hadoop</artifactId>; <version>0.0.1-SNAPSHOT</version>; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1326#issuecomment-166677912:2,release,released,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1326#issuecomment-166677912,1,['release'],['released']
Deployability,"I remember now why this was a draft for the longest time, and also probably why Travis failed - this was waiting for a release of htsjdk after https://github.com/samtools/htsjdk/pull/1544, but I see that GATK master is using 3.0.1, which does include that htsjdk PR. It's probably still a good idea to run Travis",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7193#issuecomment-1428511639:119,release,release,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7193#issuecomment-1428511639,1,['release'],['release']
Deployability,"I reran this with retry enabled. It says it finished successfully. There was an error in the middle but it continued anyways (this isn't shown in the final output, but there was a second bar).; I'm not sure about the output, though. Where is this command supposed to leave `output.bam`? It's not on my desktop. ```; [Stage 1:=====================================> (375 + 2) / 553]17/03/30 18:18:46 WARN org.apache.hadoop.hdfs.DFSClient: DFSOutputStream ResponseProcessor exception for block BP-369249695-10.240.0.8-1490738675068:blk_1073745922_5098; java.io.EOFException: Premature EOF: no length prefix available; 	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2282); 	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:244); 	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:733); 17/03/30 18:18:46 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block BP-369249695-10.240.0.8-1490738675068:blk_1073745922_5098 in pipeline DatanodeInfoWithStorage[10.240.0.4:50010,DS-5596b1b5-b89c-4c39-bbd8-7423614eae0e,DISK], DatanodeInfoWithStorage[10.240.0.3:50010,DS-a0c20806-0af3-4679-b8cd-9cae6ca25071,DISK]: bad datanode DatanodeInfoWithStorage[10.240.0.4:50010,DS-5596b1b5-b89c-4c39-bbd8-7423614eae0e,DISK]; 17/03/30 20:00:21 INFO org.spark_project.jetty.server.ServerConnector: Stopped ServerConnector@61cda923{HTTP/1.1}{0.0.0.0:4040}; 20:00:21.366 INFO MarkDuplicatesSpark - Shutting down engine; [March 30, 2017 8:00:21 PM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 165.11 minutes.; Runtime.totalMemory()=1222115328; Job [ac3f4131-f19f-47db-8cc3-82b243ad4b72] finished successfully.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2517#issuecomment-290541369:745,Pipeline,PipelineAck,745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2517#issuecomment-290541369,3,"['Pipeline', 'pipeline']","['PipelineAck', 'pipeline']"
Deployability,I run `build/install/hellbender/bin/hellbender BaseRecalibrator`; and I get this scary message (notice the three colons (`:`) on that line and lots of UPPERCASE). ```; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument RECAL_TABLE_FILE was missing: Argument 'RECAL_TABLE_FILE' is required. ***********************************************************************; ```. I think it should say something like this:. ```; ***********************************************************************. Invalid command line for BaseRecalibrator: Required argument RECAL_TABLE_FILE was missing. Run BaseRecalibrator -h to see all arguments. ***********************************************************************; ```. @vdauwera please weigh in on what's most useful,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/418:13,install,install,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/418,1,['install'],['install']
Deployability,"I run locally the gradle gatkDoc task and I fixed some HTML formatting (and a missing summary line in `MetricsReadFilter`. Can you have a look to the last commit to be sure, @vdauwera?. I will add fixes if I find problems in my own documentation code when I update the gatk dependency. Thanks for reviewing and accepting these changes!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3128#issuecomment-319623957:258,update,update,258,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3128#issuecomment-319623957,1,['update'],['update']
Deployability,"I saw this message recently when running gcloud:. ```; WARNING: `gcloud auth login` no longer writes application default credentials.; If you need to use ADC, see:; gcloud auth application-default --help; ```. It looks like we may have to update our travis script / our instructions for running on cloud files at some point in the near future.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2660:239,update,update,239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2660,1,['update'],['update']
Deployability,"I second the request for this, and I opened up the same request under the Picard GitHub project: https://github.com/broadinstitute/picard/issues/1647. Notably, this request was implemented in the recently-released Picard 2.24.0 for IntervalListTools specifically: https://github.com/broadinstitute/picard/pull/1608",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4439#issuecomment-785244420:205,release,released,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4439#issuecomment-785244420,1,['release'],['released']
Deployability,I see now that we have a changelog (didn't look at the code change before commenting). I do think any change that's included in the release should be in the changelog.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8883#issuecomment-2182869269:132,release,release,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8883#issuecomment-2182869269,1,['release'],['release']
Deployability,"I see the VCF is large, but if you are able to share it we would be happy to take a look. My first guess is it is some kind of unicode encoding mix up. While the CNN tool is written to be Python2/3 agnostic, we are moving towards a pure Python3 implementation. So you may want to try with Python3, for example, by installing the gatk conda env with:; `conda env create -n gatk -f ./scripts/gatkcondaenv.yml`; and then; `source activate gatk`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4727#issuecomment-385945590:314,install,installing,314,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4727#issuecomment-385945590,1,['install'],['installing']
Deployability,"I see whats going on now - I had been assuming that the extra lines were variant records, but they're just extra filter metadata lines resulting from the bogus tranches. So, the actual fix for this was https://github.com/broadinstitute/gatk/pull/2275. I'm closing this ticket out and will add a separate PR with an integration test that uses multiple tranches so we don't regress.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2276#issuecomment-263878175:315,integrat,integration,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2276#issuecomment-263878175,1,['integrat'],['integration']
Deployability,"I see, then it seems safe to use the protobuf java format. We intend to release the 0.6.0 version asap, preferably today.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2634#issuecomment-298024935:72,release,release,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2634#issuecomment-298024935,1,['release'],['release']
Deployability,I see. Thank you both. Just fixed it and hope it can go in the next release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4673#issuecomment-384447522:68,release,release,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4673#issuecomment-384447522,1,['release'],['release']
Deployability,"I see... The problem is that with minBQ 12 the assembler does not reconstruct the haplotype that contains both variants but two haplotypes that contain one of the variants at a time. As a result reads that would overlap both snp have a 1-bp edition distance agains the reference haplotype and any of the two alternatives. In that case they may seem to support the reference although the Lk difference should be small. . @jamesemery is working in a new version of the assembler that should address some of these issue. I could and se whether the is a quick patch fix for it but if lowering the minBQ does the trick without adding much ""crap"" as a result you could do that for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6045#issuecomment-517396201:556,patch,patch,556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6045#issuecomment-517396201,1,['patch'],['patch']
Deployability,"I separated out the code review updates from the annotation updates for the code review round. So the last 3 commits represent the code review changes, the corresponding annotation changes, and the Barclay snapshot upgrade, respectively).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-271610099:32,update,updates,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-271610099,3,"['update', 'upgrade']","['updates', 'upgrade']"
Deployability,I spent a long time struggling to install the environment as it hasn't been updated to the new tensorflow and keras versions which changed syntax in the newer versions which cause a lot of the errors you see here. I managed to get it all working by fixing the versions in the yaml but conda takes a loooooong time to solve the environment so I would highly recommend using mamba or micromamba!; I'm attaching the yaml I used to get CNNScoreVariants to work here (renamed as .txt as it won't attach as a yml). [gatkcondaenv_fixed.yml.txt](https://github.com/broadinstitute/gatk/files/12557096/gatkcondaenv_fixed.yml.txt),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1711257642:34,install,install,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1711257642,2,"['install', 'update']","['install', 'updated']"
Deployability,I still got the problem using cromwell + singularity and a component complained with the following error:; GATK_LOCAL_JAR was set to: /root/gatk.jar but this file doesn't exist. Please fix your environment.; The pipeline I used is . cromwell-executions/GATKSVPipelineSingleSample/87d715e3-7dd9-4079-9109-adf536d99400/call-GatherSampleEvidence/GatherSampleEvidence/181ae713-8db5-4a5c-b709-ad5b73a544b8/call-CollectCounts/attempt-2/execution/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6525#issuecomment-955922376:212,pipeline,pipeline,212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6525#issuecomment-955922376,1,['pipeline'],['pipeline']
Deployability,"I still need to finish up the tool-level Javadocs for the TrainVariantAnnotationsModel tool. But since I'll be off on vacation until the end of the week, I wanted to go ahead and open this up for review. There's a lot here, but not too much of it is production code (<2k LOC). I've split things up into commits that should hopefully make it more easy to review. The first commit contains the WDL added in #7932 and has already been reviewed by me, although it may benefit from a second pass. The second commit updates that WDL to account for some changes I added after review. There are TODOs scattered throughout the code, but some of them are intentionally left as an exercise for future developers. See the meta issue linked above to get an idea of what might be appropriate to leave to future work. Also note that tools are marked BETA, so there’s certainly room for improvement or changes!. There are also stubs throughout for the BGMM implementation, which will be added in a separate PR. Hopefully we can get some ML club reviewers then. @meganshand @droazen @davidbenjamin mind taking a look or suggesting other reviewers? I would hope that we can get this in by the next release after the other flow-based methods are released, since the IsolationForest filtering method added here is also used in that pipeline. It would also be nice to get this merged by the next release to keep us on track on the malaria side.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7954#issuecomment-1198182182:510,update,updates,510,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7954#issuecomment-1198182182,5,"['pipeline', 'release', 'update']","['pipeline', 'release', 'released', 'updates']"
Deployability,"I suggest we start with just the toggle, since we have an immediate need for that. Finer-grained control can be addressed as part of the more general customization/delegation mechanism we've started in other PRs, and so clearly need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358475214:33,toggle,toggle,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358475214,2,['toggle'],['toggle']
Deployability,I suspect this is related to the jar configuration (3 separate uber- jars) that is unique to the docker CI tests. I'll debug and resolve this after #6351 is merged.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1251462525:37,configurat,configuration,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1251462525,1,['configurat'],['configuration']
Deployability,"I take it you're using GenomicsDBImport to combine the GVCFs? GenomicsDB doesn't support the allele-specific annotations just yet, but look for an update very soon: #3707 In the meantime, you can use CombineGVCFs in place of GenomicsDBImport if you need those allele-specific annotations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4162#issuecomment-357991567:147,update,update,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4162#issuecomment-357991567,1,['update'],['update']
Deployability,"I tested this by:; - running the `GvsAssignIds` workflow; - manually updated the `sample_ids` to span from 1 to 15535; - manually created the `vet_002`, `vet_003`, `vet_004`, `ref_ranges_002`, `ref_ranges_003`, `ref_ranged_004` tables; - running the `GvsImportGenomes` workflow; - running the `GvsPopulateAltAllele` workflow with `max_alt_allele_shards` to 3 so that it would divide the vet tables into (at most) 3 files; see https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/b1b319bc-a2aa-44cb-ad9a-079b7c1c33de for `GvsPopulateAltAllele` run",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7998:69,update,updated,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7998,1,['update'],['updated']
Deployability,"I tested this on a collection of 32 tandem duplications (~10kbp-50kbp events, 5kbp padding, 100bp bins) from an HGSV proband case. Using the latest release docker it nailed almost all of them (hooray!) but it hardly called any dups when I tried to do the calling/postprocessing locally using this branch (log reports successful convergence). This could just be an error on my end but we should check before merging.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4720#issuecomment-386454276:148,release,release,148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4720#issuecomment-386454276,1,['release'],['release']
Deployability,I think I'm inclined towards just the simple toggle.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058383:45,toggle,toggle,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058383,2,['toggle'],['toggle']
Deployability,"I think changes in 4.2.4.1 are exposing an issue, but I think @eriqande is right that the issue isn't with GenomicsDB. The change was that previously GATK wasn't correctly passing the `--max-alternate-allele` argument to GenomicsDB, but now that it is doing so it makes it more likely that some sites don't contain fields like PL (dependent on number of possible genotypes). It looks like the AF calculation used to ignore sites if they didn't have likelihoods, but has now been updated slightly to also allow sites with GQ or sites where any alleles are called+nonref+not symbolic. https://github.com/broadinstitute/gatk/blob/caa48f98c8207b688db6ee35fead3eafb7219e38/src/main/java/org/broadinstitute/hellbender/utils/GenotypeUtils.java#L139-L141. Possibly that condition needs to be tweaked? @ldgauthier might be the best person to ask. As for this working with previous versions, that is only because the `--max-alternate-alleles` wasn't being passed to GenomicsDB correctly. if you want to revert to that behavior you can set `--max-alternate-alleles` to `50` (which is what GenomicsDB defaults to).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1015961941:479,update,updated,479,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1015961941,1,['update'],['updated']
Deployability,"I think hdfview might be broken for e.g. some Ubuntu distributions. Just need to change some tool docs, but might also want to update tutorials. See context in #6924.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6927:127,update,update,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6927,1,['update'],['update']
Deployability,"I think maybe ReadsPipelineSpark runs this entire pipeline as a single tool. There has been some recent work to go from an unaligned BAM through all these steps, but I think maybe that's not yet merged. I think the current tool goes from an aligned BAM. More authoritative info will have to come from the engine team, I'm afraid.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3878#issuecomment-347303037:50,pipeline,pipeline,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3878#issuecomment-347303037,1,['pipeline'],['pipeline']
Deployability,I think tests are failing only because I changed a header line. I will update the expected VCFs.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7996#issuecomment-1263856833:71,update,update,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7996#issuecomment-1263856833,1,['update'],['update']
Deployability,"I think that a proper example would be the one in the tutorial from @sooheelee (https://software.broadinstitute.org/gatk/blog?id=7847, see also https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000). I divided the PRs for the `IndelRealignment` into 4 different sections for better review (2 components of indel-realignment, `RealignerTargetCreator`and `IndelRealignment`). This strategy is because I dissected the pipeline into the easy `RealignerTargetCreator` to found regions worth to look at (this could be marked as experimental/beta before the indel-realignment is in) and the more complicated and component-based `IndelRealigner` (the same as with other tools, this can be marked as experimental/beta until a really good coverage is achieved - in the meantime, I have some test with the current data in the repository and the GATK3 counterpart). There are two parts that are usable outside `IndelRealigner` that are worthy to separate into two commits, and might be useful for other tools/downstream projects: `ConstrainedMateFixingManager` and `NWaySAMFileWriter`. That's the reason of making the port in split PRs. One option can be to have the PRs open, and reviewed independently without acceptance until every component is ready. Otherwise, I think that an experimental tag would be good until we find a good set of tests for edge cases. Does this approach make sense for you, @cmnbroad?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366187605:435,pipeline,pipeline,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366187605,2,['pipeline'],['pipeline']
Deployability,"I think that each tool should either emit proper error messages, or deal with the data it's given. currently BQSR emits a cryptic error message so I think that this PR is an improvement regardless of whether the pipeline is sanitized. . That said, I think that it might be a good idea to make ValidateSamFile break on non-ACGTN bases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-642719900:212,pipeline,pipeline,212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-642719900,1,['pipeline'],['pipeline']
Deployability,"I think that the full version of the binned read-count collection that @asmirnov239 is working on could be easily modified to give you what you want. Let's keep this tool as simple as possible for now. However, something that would be much easier to change in this code (and might have a bigger effect) would be adding counts to all bins that overlap each fragment. It would be interesting to see how this changes the statistics of the counts. If we have some bandwidth, we can try experimenting with this before release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3775#issuecomment-341838868:513,release,release,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3775#issuecomment-341838868,2,['release'],['release']
Deployability,"I think that this is a nice feature (at least for me) and not a bug. For example, if in GATK someone runs a tool with `-RF read_filters.args`, then the pipeline cannot be reproduced in a different dataset unless the file is accessible. I can understand that it could be also nice to preserve the `-RF read_filters.args` to be able to modify the file an re-run the tool with different parameters, but for me the purpose of storing the command line in the header or other places is keep track of the exact params that I used: if a file is modified, then it is impossible to trace the params. For input files, this is expected (if the input has changed, it is expected that the result change), but for arguments it shouldn't be the case (independently of the file changing, the tool was running with exactly that parameters). I vote for solve this in Barclay in a configurable way, to allow users to decide which kind of verbosity of the command line they want (I definitely prefer to expand as currently).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3797#issuecomment-342798092:152,pipeline,pipeline,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3797#issuecomment-342798092,1,['pipeline'],['pipeline']
Deployability,"I think that this is because in Picard tools the version is populated from the manifest `Version` attribute, and thus it prints the GATK version. @droazen and @cmnbroad - this shows that https://github.com/broadinstitute/gatk/issues/4101 in combination with a common CLP barclay class is really needed to set versions properly to combine toolkits in one (GATK/Picard, integrate common tools into a downstream project, etc.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4733#issuecomment-386994409:368,integrat,integrate,368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4733#issuecomment-386994409,1,['integrat'],['integrate']
Deployability,"I think the code and tests are fine (except for the conflicts). I was just trying to empathize about updating expected GVCFs. I want to talk to the engine team about the release schedule, but we won't merge anything else in the HC->GGVCFs pipeline before this, so the tests won't need updating.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-445876386:170,release,release,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-445876386,2,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"I think the issue might be that you need a ` -- ` between the gatk options on the left, and the spark specific options on the right. This is a confusing artifact of how our arg parsing works and the fact that the gatk-launch script needs a way of finding the spark options but doesn't have access to our java parser. (we're planning on fixing that in the near future, but no good time line) . Could you try:; ```; /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input hdfs://spark01:7222/user/axverdier/data/710-PE-G1.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_CountReadsSpark --javaOptions -Dmapr.library.flatclass -- --sparkRunner SPARK --sparkMaster yarn --deploy-mode cluster; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350064538:729,deploy,deploy-mode,729,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350064538,1,['deploy'],['deploy-mode']
Deployability,"I think the message isn't coming from BaseTest, its coming from a static block in SparkContextFactory:. 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getGcsHadoopAdapterTestProperties(SparkContextFactory.java:68); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.<clinit>(SparkContextFactory.java:59); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineArgumentCollection.<init>(SparkCommandLineArgumentCollection.java:20); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.<init>(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.<init>(GATKSparkTool.java:64); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.<init>(PrintReadsSpark.java:19); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at java.lang.Class.newInstance(Class.java:442); 	at org.broadinstitute.hellbender.Main.extractCommandLineProgram(Main.java:285); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:150); 	at org.broadinstitute.hellbender.Main.main(Main.java:233)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330894140:725,pipeline,pipelines,725,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330894140,1,['pipeline'],['pipelines']
Deployability,"I think the real challenge will be doing something worthwhile within the constraints of our Travis environment. Perhaps this sort of thing is best left to CARROT, even though it might not rise to the ""pipeline"" level.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4375#issuecomment-900618432:201,pipeline,pipeline,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4375#issuecomment-900618432,1,['pipeline'],['pipeline']
Deployability,"I think the upgrade to samtools was a consequence of changing the base image from Ubuntu 16.04 -> 18.04 in #5026, since samtools is simply installed using apt-get. If we want to be more specific about which versions of samtools, bedtools, tabix, etc. are included in the Docker images, we may want to build these accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6148#issuecomment-650290760:12,upgrade,upgrade,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6148#issuecomment-650290760,4,"['install', 'upgrade']","['installed', 'upgrade']"
Deployability,"I think there's some sort of permissions issue here. I tried building while not connected to our internal network and ran into a similar issue. I don't exactly understand how our artifactory serves as a mirror of central, but it seems like it may not be mirroring correctly to people outside of our network. . @davidbernick it seems like external people can resolve the artifacts we host in libs-snapshot-local, but possibly not things in libs-snapshot and libs-release. Does that make any sense to you?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-340051148:462,release,release,462,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-340051148,1,['release'],['release']
Deployability,"I think this is happening because were trying to serialize the class loader sun.misc.Launcher$AppClassLoader), which appears to be reached through the graph by way of via https://github.com/damiencarol/jsr203-hadoop/blob/master/src/main/java/hdfs/jsr203/HadoopFileSystem.java#L82. We probably need to short circuit that with a custom serializer for one of these:. Serialization trace:; classes (sun.misc.Launcher$AppClassLoader); classLoader (org.apache.hadoop.conf.Configuration); conf (org.apache.hadoop.hdfs.DistributedFileSystem); fs (hdfs.jsr203.HadoopFileSystem); hdfs (hdfs.jsr203.HadoopPath); path (htsjdk.samtools.seekablestream.SeekablePathStream); seekableStream (htsjdk.tribble.TribbleIndexedFeatureReader); featureReader (org.broadinstitute.hellbender.engine.FeatureDataSource); featureSources (org.broadinstitute.hellbender.engine.FeatureManager). See, for instance, https://github.com/dbpedia/distributed-extraction-framework/issues/9.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-668654169:466,Configurat,Configuration,466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-668654169,1,['Configurat'],['Configuration']
Deployability,"I think this makes sense, but is low priority and can definitely wait until after release.; Add tests for theano HMM + example use case for Hybrid ADVI.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4043:82,release,release,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4043,1,['release'],['release']
Deployability,"I think this might be an unintended consequence of @tomwhite 's changes in https://github.com/broadinstitute/gatk/pull/2350, merged yesterday. In that PR, `ReadSparkSource.getParallelReads()` was patched to call `getHeader()` before doing anything else. @tomwhite Can you have a look at this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2449#issuecomment-285426730:196,patch,patched,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2449#issuecomment-285426730,1,['patch'],['patched']
Deployability,"I think we are also waiting for FC to update, so that NIO can be call cached. Not sure what the status is on that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5015#issuecomment-461938277:38,update,update,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5015#issuecomment-461938277,1,['update'],['update']
Deployability,"I think we can generally enable this by pushing the option up to VariantWalker / GATKTool and integrating it with the createVCFWriter method. . It can optionally return a writer wrapped in a decorator that only outputs sites within the given intervals. We might want to rename the option in that case to something like ""only-output-variants-starting-in-intervals"" so it's clear that it only effects variant outputs. Or make it work with generated bamWriters too...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6339#issuecomment-568100260:94,integrat,integrating,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6339#issuecomment-568100260,2,['integrat'],['integrating']
Deployability,"I think we could probably change away from 3.25, I have 3.4.3 installed on my machine and tests run fine. We just chose one arbitrarily that worked and set it at that so that it wouldn't change out from under us.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359074433:62,install,installed,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359074433,1,['install'],['installed']
Deployability,"I think we have a good idea of what side inputs are for and when we would need them now. . My understanding is that side inputs are appropriate to use when you have a fixed object or set of objects which must be provided as a whole to a task or tasks in a pipeline. If these things can be known at pipeline creation and are inexpensive to generate, it's possible to simply pass the objects as parameters in the pipeline creation. However, if the object is generated as part of the pipeline, then it must be passed as a side input instead. . @wbrockman Is my understanding correct?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/282#issuecomment-94354043:256,pipeline,pipeline,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/282#issuecomment-94354043,4,['pipeline'],['pipeline']
Deployability,"I think we just don't have any borderline cases in our integration tests. We have a lot of cases where VQSR passes and one with artificial data where it's obviously going to fail. I couldn't reproduce the particular failure they saw in production, so I didn't want to add that to Travis if it's persnickety.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6534#issuecomment-617341642:55,integrat,integration,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6534#issuecomment-617341642,1,['integrat'],['integration']
Deployability,I think we need to exclude the htsjdk module from ADAM/bdgenomics as well. Without that exclude (in gatk) I still get htsjdk 2.5 pulled in to gatk-protected when I build it with a locally-installed gatk.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292607193:188,install,installed,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292607193,1,['install'],['installed']
Deployability,I think we should make an effort to keep the project at 0 warnings. We could do this during the bugfixing freeze every release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/118:119,release,release,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/118,1,['release'],['release']
Deployability,"I think we're planning on cutting a release early next week to use in a Warp update. I don't plan on adding anything else, so you could probably rebase now. I don't want to merge before the release though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-948857566:36,release,release,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-948857566,3,"['release', 'update']","['release', 'update']"
Deployability,I think we've seen similar issues before. Libgomp needs to be installed and findable. I think it typically is installed when you install gcc. See https://github.com/broadinstitute/gatk/issues/6012 for more discussion.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8194#issuecomment-1424600684:62,install,installed,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8194#issuecomment-1424600684,3,['install'],"['install', 'installed']"
Deployability,"I thought after the last comment of @vdauwera in the [blog post about the removal](http://gatkforums.broadinstitute.org/gatk/discussion/7131/is-indel-realignment-removed-from-gatk4) that it will be possible to port it here as a contribution (without too much effort from your dev team). If the final solution is that this is not going to be maintained in GATK4, I would port this code to my own software if you give me the permission; but it is definitely something that the community is interested. For example, I'm working with Pool-Seq data with hundreds of individuals together, so `HaplotypeCaller` is not a possibility in our case. I'm actually evaluating other approaches for realignment, such as [ABRA](https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btu376) or [SRMA](https://genomebiology.biomedcentral.com/articles/10.1186/gb-2010-11-10-r99). I'm even thinking on implementing a new realigner based on the GATK's assembler engine and its PairHMM; but this requires more time for evaluation, and it will be nice to be able to compare with the current indel realignment pipeline. Anyway, I can close the issues and PRs in the gatk repo, and port them to my toolkit ([ReadTools](https://github.com/magicDGS/ReadTools)), to maintain the code for the community.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308460892:1113,pipeline,pipeline,1113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308460892,1,['pipeline'],['pipeline']
Deployability,I thought this was one of the things we enforced in gatk despite knowing it's not in the spec? We might need to update a bunch of stuff if we allow for no readgroups. Things like bqsr covariates might start getting weird nulls.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6501#issuecomment-602642246:112,update,update,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6501#issuecomment-602642246,1,['update'],['update']
Deployability,I totally missed the Barclay update that added these... over a year ago. LGTM!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6438#issuecomment-582050900:29,update,update,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6438#issuecomment-582050900,1,['update'],['update']
Deployability,"I tried `CountReadsSpark` and that also worked fine:. ```; $ ./gatk-launch CountReadsSpark -I gs://$BUCKET/hellbender-test-inputs/CEUTrio.HiSeq.WGS.b37.ch20.1m-2m.NA12878.bam -O gs://$BUCKET/test-output/readcount_2 -- --sparkRunner GCS --cluster jps-test-cluster; [November 20, 2017 7:04:27 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=653787136; Job [d9b686ed-3971-4494-b98b-336f751a449d] finished successfully.; (...); $ gsutil cat gs://$BUCKET/test-output/readcount_2; 836574; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-345795866:341,pipeline,pipelines,341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-345795866,1,['pipeline'],['pipelines']
Deployability,"I tried a quick upgrade of our guava dependency from 18 -> 22, but it ends in test failures. It looks like at least one of our hadoop dependencies requires guava <= 18. I'm not totally clear if it's an issue for hadoop-core or only in hadoop-minicluster which is a library we use for running tests. If you're not using hdfs I think you won't have any problems including 22, but I'm afraid we can't upgrade our default version without some work. . Hopefully hadoop 3.x will solve the problem in general by shading their internal version of guava. ; https://issues.apache.org/jira/browse/HADOOP-14284, https://issues.apache.org/jira/browse/HADOOP-10101. It sounds like you have a reasonable workaround, let us know if you have further issues with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516:16,upgrade,upgrade,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516,4,['upgrade'],['upgrade']
Deployability,"I tried clearing my caches and rebuilding, but I resolve everything. I noticed that our artifactory website looks much different today than it did yesterday. I wonder if it was down temporarily for an update. Maybe try again now? Unless they put it behind the firewall which would be a disaster... can you access https://artifactory.broadinstitute.org/?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2579#issuecomment-292587641:201,update,update,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2579#issuecomment-292587641,2,['update'],['update']
Deployability,"I tried running MarkDuplicatesSpark with multiple inputs like it is run in production and got this user error. ```; A USER ERROR has occurred: Sorry, we only support a single reads input for spark tools for now.; ```. For this to go into production it would need to have the ability to take in multiple inputs (I'm currently trying to make a ""fast"" version of the production germline pipeline and it would be great to have this tool included in that pipeline). @jamesemery",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5398:384,pipeline,pipeline,384,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5398,2,['pipeline'],['pipeline']
Deployability,"I tried running gatk version 4.0.7.0 with the environment variable: 'TILEDB_DISABLE_FILE_LOCKING=YES' to see if that would fix the issue, but I still get the same error. I am not sure that the patch that enable that was actually in the 4.0.7.0 release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5024#issuecomment-409070215:193,patch,patch,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5024#issuecomment-409070215,2,"['patch', 'release']","['patch', 'release']"
Deployability,I tried the latest GATK release and also reported errors.; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx50G -Djava.io.tmpdir=./tmp -jar /public/home/gaoshibin/software/GATK/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenotypeGVCFs -R /public/home/gaoshibin/B73_REF/Zea_mays.AGPv4.dna.toplevel.fa -V gendb://./CHR7_gvcf_database -G StandardAnnotation --genomicsdb-shared-posixfs-optimizations true -O new_ALL_MATERIALS_chr7.g.vcf.gz; 17:49:50.404 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 17:49:50.653 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/public/home/gaoshibin/software/GATK/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 17:49:51.271 INFO GenotypeGVCFs - ------------------------------------------------------------; 17:49:51.273 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.2.6.1; 17:49:51.273 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:49:51.273 INFO GenotypeGVCFs - Executing as gaoshibin@comput6 on Linux v3.10.0-693.el7.x86_64 amd64; 17:49:51.274 INFO GenotypeGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_211-b12; 17:49:51.274 INFO GenotypeGVCFs - Start Date/Time: 2022年5月22日 下午05时49分50秒; 17:49:51.274 INFO GenotypeGVCFs - ------------------------------------------------------------; 17:49:51.275 INFO GenotypeGVCFs - ------------------------------------------------------------; 17:49:51.276 INFO GenotypeGVCFs - HTSJDK Version: 2.24.1; 17:49:51.276 INFO GenotypeGVCFs - Picard Version: 2.27.1; 17:49:51.276 INFO GenotypeGVCFs - Built for Spark Version: 2.4.5; 17:49:51.277 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:49:51.277 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_S,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1135301848:24,release,release,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1135301848,1,['release'],['release']
Deployability,"I tried to process data with BQSRPipelineSpark( the latest released gatk4 beta version), but the job always failed at middle of processing.; I use ERR000589, the bam file size is 1.3G.; knownSites uses dbsnp_138.hg19.vcf, and the data size is 10G.; reference is ucsc.hg19.2bit, data size is 0.8G .; it was running on spark2.0, and there are 4 worker in total. Each node has 16 physical cores and 64G data memory.; Below is my command.; ./gatk-launch BQSRPipelineSpark -I hdfs:///user/xxx/ERR000589.bwa.mark.bam -O hdfs:///user/xxx/ERR000589.bwa.marked.bqsr.bam -R hdfs:///user/liucheng/refs/ucsc.hg19.2bit --knownSites hdfs:///user/liucheng/dbsnp/dbsnp_138.hg19.vcf -- --sparkRunner SPARK --sparkMaster spark://cu11:7077 --total-executor-cores 48 --executor-cores 6 --executor-memory 25G --driver-memory 30G. The log is attached as follow:; [July 19, 2017 2:39:55 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BQSRPipelineSpark done. Elapsed time: 3.24 minutes.; Runtime.totalMemory()=23515365376; com.esotericsoftware.kryo.KryoException: java.lang.NegativeArraySizeException; Serialization trace:; vs (org.broadinstitute.hellbender.utils.collections.IntervalsSkipListOneContig); intervals (org.broadinstitute.hellbender.utils.collections.IntervalsSkipList); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:101); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518); 	at com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:606); 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:109); 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3303:59,release,released,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3303,2,"['pipeline', 'release']","['pipelines', 'released']"
Deployability,"I tried to run VariantRecalibrator using the args echoed from an integration test and found that the resource files weren't listed properly. The command in the test was ` "" --resource known,known=true,prior=10.0:"" + getLargeVQSRTestDataDir() + ""dbsnp_132_b37.leftAligned.20.1M-10M.vcf""` and what came out of the engine was `--resource known:/Users/gauthier/workspaces/gatk/src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf`, so it lost the known=true and the prior which makes the command line unrunnable. Probably affects #2269 too. This behavior can be replicated by running any of the VariantRecalibration integration tests and checking the console output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3247:65,integrat,integration,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3247,2,['integrat'],['integration']
Deployability,"I tried to run the whole test suite with `./gradlew clean test`, and several tests are failing with `org.broadinstitute.hellbender.exceptions.UserException$HardwareFeatureException: Machine does not support AVX PairHMM`:. * `HaplotypeCallerIntegrationTest`; * `HaplotypeCallerSparkIntegrationTest`; * `ReadsPipelineSparkIntegrationTest`. Because there are already several tests skipped if the support is not present (e.g., `VectorPairHMMUnitTest`), I expect that the tests do not fail and are skipped instead. I understand that maybe it is important to keep them failing with the GKL implementation for integration, but maybe a setting a flag to force them to do not be skipped would be enough in the travis build to check that nothing is broken, and still do not be scare if lots of tests fail after an unrelated change in a non-AVX machine...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3732:603,integrat,integration,603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3732,1,['integrat'],['integration']
Deployability,"I try to make a pipeline for GenotypeGVCFs and bcftools. ```; gatk --java-options ""-Xmx2048m -XX:ParallelGCThreads=1 -Dsamjdk.compression_level=0"" \; GenotypeGVCFs \; -R ./myreference.fa \; -V gendb://mydatabase/ \; -O /dev/stdout | \; bcftools +setGT -Oz -o resutl.vcf.gz - -- -t q -n . -i 'FORMAT/DP=0 | SMPL_MAX(FORMAT/PL)=0'. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1657606504:16,pipeline,pipeline,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1657606504,1,['pipeline'],['pipeline']
Deployability,"I updated from 4.0.4.0 to 4.0.6.0 and noticed either a memory bug or spike in GenotypeGVCF. . Based on https://github.com/EvanTheB/gatk4-germline-snps-indels/blob/master/joint-discovery-gatk4.simple.wdl:. ```; ""/share/ClusterShare/software/contrib/evaben/gatk/prebuilt/4.0.4.0/bin/gatk"" --java-options ""-Xmx8g -Xms8g"" \; GenomicsDBImport \; --genomicsdb-workspace-path ""$genomicsdb"" \; --batch-size ""50"" \; -L ""chr18:1-80373285"" \; --sample-name-map ""/share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/e64f393e-2ac6-43e6-9b20-cbfa905e7c33/call-GenotypeGVCFs/shard-17/inputs/-321562876/sample_map"" \; --reader-threads 5 \; -ip 500. tmp_vcf=""$TMPDIR""/tmp.vcf.gz. ""/share/ClusterShare/software/contrib/evaben/gatk/prebuilt/4.0.4.0/bin/gatk"" --java-options ""-Xmx8g -Xms8g"" \; GenotypeGVCFs \; -R ""/share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/e64f393e-2ac6-43e6-9b20-cbfa905e7c33/call-GenotypeGVCFs/shard-17/inputs/1017648146/Homo_sapiens_assembly38.fasta"" \; -O ""$tmp_vcf"" \; -D ""/share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/e64f393e-2ac6-43e6-9b20-cbfa905e7c33/call-GenotypeGVCFs/shard-17/inputs/1017648146/Homo_sapiens_assembly38.dbsnp138.vcf"" \; -G StandardAnnotation \; --only-output-calls-starting-in-intervals \; --use-new-qual-calculator \; -V gendb://""$genomicsdb"" \; -L ""chr18:1-80373285"". ""/share/ClusterShare/software/contrib/evaben/gatk/prebuilt/4.0.4.0/bin/gatk"" --java-options ""-Xmx8g -Xms8g"" \; VariantFiltration \; --filter-expression ""ExcessHet > 54.69"" \; --filter-name ExcessHet \; -O ""output.vcf.gz"" \; -V ""$tmp_vcf""; ```. And a SGE hard memory limit of 40G (GenotypeGVCFs has -Xmx8g).; On gatk 4.0.4.0 I see peak memory usage of 15.7G, while with gatk 4.0.6.0 I get:. ```; ...; 19:06:23.757 INFO GenotypeGVCFs - Initializing engine; 19:06:24.785 INFO FeatureManager - Using codec VCFCodec to read file file:///share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/e9bf8c5e-3e70-476a-9",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5024:2,update,updated,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5024,1,['update'],['updated']
Deployability,"I updated the branch with the new changes in the framework, and addressing the comments. Back to you, @droazen.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-245989318:2,update,updated,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-245989318,1,['update'],['updated']
Deployability,"I updated the doc with some more info. ; TLDR: with 100 samples there is a visible difference between different buffer size in terms of memory usage. However the tool seems to not always exit properly when it runs out of memory, leaving the VM hanging.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2640#issuecomment-298903456:2,update,updated,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2640#issuecomment-298903456,1,['update'],['updated']
Deployability,I updated the documentation for the beta document and added it to this PR as well,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8010#issuecomment-1238566665:2,update,updated,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8010#issuecomment-1238566665,1,['update'],['updated']
Deployability,I updated the javadoc with your comments @cmnbroad. Should I only rebase or also squash my previous commits? Waiting for your answer to continue working on this...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-289363211:2,update,updated,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-289363211,1,['update'],['updated']
Deployability,I updated the test to check that the bases that remain in the reads are indeed the correct length and bases. I use random bases since createArtificialRead returns 'A' bases and so we will not know if it was the first or the last bases that were removed.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6139#issuecomment-529004212:2,update,updated,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6139#issuecomment-529004212,1,['update'],['updated']
Deployability,I updated the test to check the output genotype here and I'm now in the process of running the WARP tests and on a dragen callset with 60 haploid/diploid mix samples.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8862#issuecomment-2168083426:2,update,updated,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8862#issuecomment-2168083426,1,['update'],['updated']
Deployability,"I upgraded both the File and the Path tests for `createCommonSAMWriter`, checking that the written file contents match the source file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332080826:2,upgrade,upgraded,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332080826,1,['upgrade'],['upgraded']
Deployability,"I used the updated scripts in this PR to successfully push the 4.4.0.0 release image, so these are confirmed to be working correctly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8247#issuecomment-1474428661:11,update,updated,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8247#issuecomment-1474428661,2,"['release', 'update']","['release', 'updated']"
Deployability,I used the very last version of the WDL using the last master commit for the docker and the name of the output files seem to be a random permutation of the actual sample names. The name inside the file (i.e. the one listed in the #CHROM line) seems to be correct. A previous run using a earlier version of the WDL (probably the one just before the last update) and the latest official gatk docker didn't have this issue.; .,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5217:353,update,update,353,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5217,1,['update'],['update']
Deployability,"I used to have it in there, but once I got copy performance up I assumed it was just clutter. I need to make a minor update to the scripts anyway (option to run the debug program instead of the full pipeline) so I can put back the option to not copy fastq files as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4332#issuecomment-362655529:117,update,update,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4332#issuecomment-362655529,2,"['pipeline', 'update']","['pipeline', 'update']"
Deployability,I want this argument as a fallback for now in case production runs into more trouble with the upcoming callset. Merging in so @lbergelson can incorporate this change in his upcoming patch to `GatherVcfs`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2755#issuecomment-306588957:182,patch,patch,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2755#issuecomment-306588957,1,['patch'],['patch']
Deployability,"I want to update my dependencies, but the last commits are not in the new artifactory. Which one is the latest?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3068#issuecomment-307822412:10,update,update,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3068#issuecomment-307822412,1,['update'],['update']
Deployability,"I was looking into this myself as part of other argument renaming tasks. I don't see that you have changed any of the recalibration table arguments checked into the repo, namely in the test resources /tools/BQSR. (eg. `src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.lowMaxCycle.table`) You should probably take a look at this and other .table files and maybe update them to have more up to date summary statistics, as it could indicate that the gatk is writing its output with the old argument styles as these are used in integration tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4029#issuecomment-355064406:386,update,update,386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4029#issuecomment-355064406,2,"['integrat', 'update']","['integration', 'update']"
Deployability,"I was outputting to .vcf.gz. . I reran the command to output to just. vcf and it runs without error:; ```; /gatk-launch FilterByOrientationBias --artifactModes 'G/T' -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P ~/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk FilterByOrientationBias --artifactModes G/T -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; 01:16:16.916 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.4.3.jar!/com/intel/gkl/native/libgkl_compression.dylib; [June 6, 2017 1:16:16 AM EDT] FilterByOrientationBias --output test_filterbyorientationbias.vcf --preAdapterDetailFile /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics --artifactModes G/T --variant /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891:485,install,install,485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891,4,['install'],['install']
Deployability,I was testing the latest beta.6 release and ran into an issue that HaplotypeCallerSpark no longer outputs bgzipped VCF outputs. Specifying `--output outfile.vcf.gz` produces a plain unzipped VCF. This worked in the beta.5 release so appears to be due to recent changes. Here is a small self-contained test case that reproduces the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_spark_output.tar.gz. Please let me know if I can provide anything else that would help. Thanks as always for all the improvements and work on GATK.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3725:32,release,release,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3725,2,['release'],['release']
Deployability,"I was thinking that if we relied on PyPI for distribution, it would only be for released builds, not a release for every repo merge commit. But, I'm increasingly inclined to think that in the short term we should just include the python archive/zip file right in the gatk distribution zip, and modify the env .yml to install from that. Then every configuration (docker image, git clone user, and end user) could use exactly the same method to establish the environment. That seems like the simplest solution for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3964#issuecomment-352279343:80,release,released,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3964#issuecomment-352279343,8,"['configurat', 'install', 'release']","['configuration', 'install', 'release', 'released']"
Deployability,I will approve after you take a look at the integration test I linked above.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1062986841:44,integrat,integration,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1062986841,1,['integrat'],['integration']
Deployability,"I will send along some notes for the release. By the way, I don't think I've enough permissions to merge the PR or rerun Travis tests....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5970#issuecomment-519972528:37,release,release,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5970#issuecomment-519972528,1,['release'],['release']
Deployability,I will try to test it next time I have a chance. I don't have the pipeline and data up anymore on Terra. But the default Terra pipeline for Mutect2 FilterAlignmentArtifacts with the default Terra cpu platform should reproduce the issue on GATK 4.1.9.0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-782779694:66,pipeline,pipeline,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-782779694,2,['pipeline'],['pipeline']
Deployability,I would also find this feature helpful in terms of streamlining a pipeline I am working on. Any updates on this feature request?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5527#issuecomment-876514964:66,pipeline,pipeline,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5527#issuecomment-876514964,2,"['pipeline', 'update']","['pipeline', 'updates']"
Deployability,"I would also like to have the missing annotations (they are only in the header in 4.1.8.0 VCF outputs). The problem seems to be related to the changes in commit 3021e69 (mitochondrial pipeline, #6399) as running FilterMutectCalls on the previous commit c918f85 emits the annotations CONTQ, GEMRQ, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6721#issuecomment-669894780:184,pipeline,pipeline,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6721#issuecomment-669894780,1,['pipeline'],['pipeline']
Deployability,"I would like to eventually port the indel realignment pipeline, but I don't know if I will have time. @sooheelee, maybe you can tell me if people is interested on it? I think that it is still important for Pool-Seq data, where haplotype-based calling is not usually performed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307734736:54,pipeline,pipeline,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307734736,1,['pipeline'],['pipeline']
Deployability,"I would like to keep in some of my tools the read group arguments in sync with the `AddOrReplaceReadGroup` in picard, but currently there is no way of access them. This is a very simple and trivial patch to extract the short/long names to a static String variable to be able to use them. In addition, I refactored the variable names to the camel-case java convention.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2260:198,patch,patch,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2260,1,['patch'],['patch']
Deployability,"I would like to reiterate that the one code path in ADAM that is. 1. changed between 0.20.0 and 0.23.0 and; 2. that is used in both the GATK BQSR and HC engines. is the two bit file parsing and extraction engine. The main commit that changed in that code path was https://github.com/bigdatagenomics/adam/commit/1eed8e8e464f8f92a6e87afc1d334e751423e810, which reverts cleanly on ADAM trunk. There are also some changes in the `ReferenceRegion` class, they appear to be mostly cosmetic, but this necessitated changing one parameter from `null` to `Strand.INDEPENDENT` in https://github.com/broadinstitute/gatk/commit/8a366c7ba570c61338f7109b86c3284b80d5cf47. The GATK does one lookup into the TwoBitFile (which creates one ReferenceRegion along the way) per read during BQSR and two per assembly region during HC, so this code is inside your inner loop. Again, all it should take to test this hypothesis is:. ```; git clone git@github.com:bigdatagenomics/adam.git; cd adam; git checkout adam-parent-spark2_2.10-0.23.0; git revert 1eed8e8e464f8f92a6e87afc1d334e751423e810; mvn install -DskipTests; ```. You'd then need to build the GATK with the JAR this generates. If this makes the perf regression go away, then we can easily revert this change in ADAM 0.24.0, which will release two weeks from now. Let me know if there's any way I can be of help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367122365:1074,install,install,1074,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367122365,2,"['install', 'release']","['install', 'release']"
Deployability,"I would like to start a new project to extend the engine of GATK (mostly walker types, e.g. https://github.com/broadinstitute/gatk/issues/1198 and common utilities), and thus I require to have an idea of how the versioning scheme is related to the public API if at all. This will allow me to say that the extensions works with GATK between 4.0.0.0 and 4.1.0.0, for example, and to know when some work is required to move to the next released version. Thank you!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4603:433,release,released,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4603,1,['release'],['released']
Deployability,I would support pre-installing the R libraries into the base image. Installing R libraries is slow and tend to fail at random because CRAN isn't as reliable as our other dependencies. We just need keep the docker file for the base image around so we can rebuild it with new libraries if we need to.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2699#issuecomment-300576630:20,install,installing,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2699#issuecomment-300576630,2,"['Install', 'install']","['Installing', 'installing']"
Deployability,I wrote a very minimal guide that says the same thing here: https://github.com/broadinstitute/gatk/wiki/How-to-update-the-gatk-base-docker,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5496#issuecomment-446270446:111,update,update-the-gatk-base-docker,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5496#issuecomment-446270446,2,['update'],['update-the-gatk-base-docker']
Deployability,"I'd like to test this out. @tedsharpe could you add your ""contigNameToMoleculeName"" file to the /broad-dsde-methods/sv/reference/GRCh38 bucket, perhaps along with a little README note on how you created it? It'd also be nice if you could update the scripts in scripts/sv in github (I think you'd have to change svDiscover.sh and scanBam.sh) to correctly pass this along.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2527#issuecomment-289044888:238,update,update,238,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2527#issuecomment-289044888,1,['update'],['update']
Deployability,"I'd rather not change the default HC behavior, but this is pretty exciting because we can lay the argument about porting ReadBackedPhasing to rest. It would be good to do a comparison with RBP -- can you take a look at the RBP integration tests from GATK3 to see if there was a MNP test there?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-380816090:227,integrat,integration,227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-380816090,1,['integrat'],['integration']
Deployability,I'd suggest doing a bug fix release @lbergelson once this fix goes in.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-404577493:28,release,release,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-404577493,1,['release'],['release']
Deployability,"I'll open a ticket for ref conf performance optimization, but I'm keen to get a ""draft"" of the MT joint calling pipeline into 4.1.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-451466938:112,pipeline,pipeline,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-451466938,1,['pipeline'],['pipeline']
Deployability,I'll try to roll out a new release on maven central asap after latest merges.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4638#issuecomment-460611755:27,release,release,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4638#issuecomment-460611755,1,['release'],['release']
Deployability,"I'll try to see if I can create a test to verify index creation. It will probably involve manually integrating an hg38 header with a clone of one of the existing tests, though, since I need something that matches a real recal file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2821#issuecomment-306814748:99,integrat,integrating,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2821#issuecomment-306814748,1,['integrat'],['integrating']
Deployability,"I'm able to install Conda, run the yml and activate it locally. I don't know what's up with the Docker either.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-392194430:12,install,install,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-392194430,1,['install'],['install']
Deployability,"I'm also seeing this more often during the Docker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:143,install,installAll,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['install'],['installAll']
Deployability,"I'm assuming that the recent GKL update addresses this, so am closing based on the girl scout principle (find it broken? fix it), but feel free to reopen. https://github.com/broadinstitute/gatk/pull/3865",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-349721014:33,update,update,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-349721014,1,['update'],['update']
Deployability,"I'm assuming you will have the subset of samples before creating a GenomicsDBFeatureReader object (and before creating the corresponding Protobuf export configuration object). More precisely, you are NOT requesting a line by line filter similar to:; At pos 100, compute INFO fields etc including only the samples whose QUAL > 5; At pos 102, compute INFO fields etc including only the samples whose QUAL > 5; ....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469502322:153,configurat,configuration,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469502322,1,['configurat'],['configuration']
Deployability,I'm closing this because I believe it's a duplicate of #3466. Track that issue for updates.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3813#issuecomment-355650321:83,update,updates,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3813#issuecomment-355650321,1,['update'],['updates']
Deployability,I'm continuously sad that my shell can't autocomplete GATK commands. It would be great if we could generate completion files for bash and zsh automatically. This could piggyback on the upcoming documentation generation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1454:4,continuous,continuously,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1454,1,['continuous'],['continuously']
Deployability,I'm encountering the same bug. Linux OS. Brand new GATK install from github (17 Dec 2019).; Did you manage to figure anything out?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566789383:56,install,install,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566789383,1,['install'],['install']
Deployability,"I'm fine with it.; If the skipped tests are the primary irritant let's just delete them. > On Sep 25, 2017, at 8:47 PM, Steve Huang <notifications@github.com> wrote:; > ; > I am OK with removing it, since our pipeline seems to have been stabilized without it for almost 6 months now. What do you think @cwhelan @tedsharpe ?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3612#issuecomment-332170554:209,pipeline,pipeline,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3612#issuecomment-332170554,1,['pipeline'],['pipeline']
Deployability,I'm going to close this since we've update to 5.6. Feel free to reopen if you continue to have issues with it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6097#issuecomment-524554257:36,update,update,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6097#issuecomment-524554257,1,['update'],['update']
Deployability,I'm going to rebase and patch this branch now -- it conflicts with another arg-renaming branch that I just merged.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4029#issuecomment-356019357:24,patch,patch,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4029#issuecomment-356019357,1,['patch'],['patch']
Deployability,"I'm merging this as is. Once we have some real installable python packages in place, the dummy python package and corresponding test can be reverted, but we need to retain it in the interim or the packaging step would fail.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3964#issuecomment-355132066:47,install,installable,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3964#issuecomment-355132066,1,['install'],['installable']
Deployability,"I'm missing the possibility of tuning the logging to produce TRACE level log messages. As it is stands the users only can choose down to DEBUG. . It seems that this is due to the integration of several logging systems from old GATK, htjsdk and picard where DEBUG the lowest common level. . It would be great to have the ability to produce TRACE level log messages allowing the user to have control on whether these are output or not. . In this case DEBUG log messages that are going to be produced in big numbers should be TRACE whereas unfrequent (one very 5 second or more) would stay as DEBUG.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6378:179,integrat,integration,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6378,1,['integrat'],['integration']
Deployability,"I'm not crazy about the idea of specifying this in the example commands in general. It will depend a lot on what data and use case a user is going through at any given time. I would much prefer leaving specific recommendations to our pipeline scripts, where we can use whatever the prod pipeline uses, and say ""given this use case and example data, this is what works, ymmv"". So I would actually advocate for removing all -Xmx values in the tool docs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319124674:234,pipeline,pipeline,234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319124674,2,['pipeline'],['pipeline']
Deployability,"I'm not sure what proportion of users leverage the incremental import functionality...it wasn't available when GenomicsDBImport was first made available, but has been around for ~3 years now. As for workspaces with whole chromosomes -- there is no requirement or performance benefits to using whole chromosomes. As you say, subsetting a chromosome to smaller regions will work and make the import and query parallelizable. (if you remember where the advice about whole chromosomes came from, let us know. That might be something that needs to be updated/clarified). Many small contigs does add overhead to import though and, till recently, multiple contigs couldn't be imported together (i.e., each contig would have it's own folder under the GenomicsDB workspace - which gets inefficient with many small contigs). For WGS, probably the best way to create the GenomicsDBImport interval list is to split based on where there are consecutive N's in the reference genome (maybe using [Picard](https://broadinstitute.github.io/picard/command-line-overview.html#ScatterIntervalsByNs)) and/or regions that you are blacklisting. I think you suggested that some of the blacklisted regions were especially gnarly - maybe ploidy or high alternate allele count? - depending on the frequency of those, we may save a bit on space/memory requirements. That may address your concern about overlap between variants and import intervals. In general, any variant that starts in a specified import interval will show up in a query to that workspace. I'm not sure if the blacklist regions contain any variants that start within but extend beyond the blacklist -- those may not show up if the regions are split up in this way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1212486548:546,update,updated,546,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1212486548,1,['update'],['updated']
Deployability,"I'm not sure why the `gs` provider doesn't get installed (I think JP was seeing this before), but in any case there's a workaround in GATK for it: https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java#L380-L390. However, since the Hadoop-BAM code is doing the path lookups, it can't call that code directly (the dependency is the wrong way round). It would be best if we could fix the underlying problem of course, so that it gets picked up properly - I wonder if this can be done by fixing the service provider so it survives relocation (see http://maven.apache.org/plugins/maven-shade-plugin/examples/resource-transformers.html#ServicesResourceTransformer). BTW I'm afraid I'm travelling this week, so I won't have time to look at it until next week either :(",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-263997131:47,install,installed,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-263997131,1,['install'],['installed']
Deployability,I'm not totally clear from your response but I think you've resolved the problem? . If you're encountering a bug merging bai files could you open an issue describing that with your stack trace and any relevant information about the configuration you're running?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6233#issuecomment-547956623:232,configurat,configuration,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6233#issuecomment-547956623,2,['configurat'],['configuration']
Deployability,I'm pretty sure that we don't exclude any regions in the hg38 pipeline right now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2591#issuecomment-297588284:62,pipeline,pipeline,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2591#issuecomment-297588284,1,['pipeline'],['pipeline']
Deployability,"I'm pretty sure this was for the old Spark GATK-SV pipeline, which is obsolete. I'm going to close this, but if @vruano or someone else thinks it's still useful we can reopen.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2721#issuecomment-736796696:51,pipeline,pipeline,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2721#issuecomment-736796696,1,['pipeline'],['pipeline']
Deployability,"I'm pretty sure we've done this in the exome production pipeline forever, though not with SplitIntervals. HaplotypeCaller (and presumably MuTect) will only output calls in the specified region, no matter how much territory goes into the active region. If a small interval gets split, it will likely have the same active region for both calls.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-350093043:56,pipeline,pipeline,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-350093043,1,['pipeline'],['pipeline']
Deployability,"I'm reopening this as I'm still having this same problem when using the latest release (4.1.1.0). The variant shown above is not emitted by `GenotypeGVCFs` when using `-stand-call-conf 100` but is when using a lower threshold, e.g. `-stand-call-conf 50`. It would be really nice to be able to use `-stand-call-conf` and have that _just_ filter out records that would result in records in the output VCF with QUAL < threshold.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5793#issuecomment-479261344:79,release,release,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5793#issuecomment-479261344,1,['release'],['release']
Deployability,"I'm stepping into the 7 remaining test failures in the debugger, and I think they may just be fixed by overwriting the actual output of `GenotypeGVCFsIntegrationTest.testEntireVariant` onto the expected output for all the forced output test cases. However, this exercise has revealed some other changes:. `GenotypeGVCFsEngine.callRegion` contains the line `final VariantContext mergedVC = merger.merge(variantsToProcess, loc, ref.getBase(), !outputNonVariants, false)`. Since we want to remove the non-ref allele regardless, we should replace `!outputNonVariants` with `true`. It is important to do this here, because only then does `regenotypeVC` correctly restrict the `AD` to the emitted alleles. Also, doing this strips the variant QUAL from the output if it's monomorphic, which is desired (the `RGQ` field is in the output, so there remains a sense of the quality of the call). Once you do that, could you check whether `removeNonRefAndUnusedAltAlleles` is still necessary? In the integration tests, at least, I didn't see any alt alleles output except those called in a genotype.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582242487:987,integrat,integration,987,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582242487,1,['integrat'],['integration']
Deployability,"I'm surprised none of the variant calling integration tests change. @cmnbroad Would you expect this to change the behavior in any common use cases or is this more of a safety check?. It's admittedly also possible that the MT calling in the Mutect2 integration test does change slightly, but that's a very lenient concordance check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212:42,integrat,integration,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212,2,['integrat'],['integration']
Deployability,"I'm thinking about lists such as filters packages (in the filter plugin): I can imagine a list with long package names separated by commas, which might be complicated to read due to the repetition of the same organization name. I think that it might be also more organize if the configuration file is an YML with sections for the different configurations: this will make the file more readable and easier to modify. Something like the codecov configuration will be interesting, separating configurations for spark, plugins, feature codecs, etc. For example, if I want to use a custom codec for BED files while including the HTSJDK codec packages, I would find a problem. Doing it in a granular level may be interesting for having something like:. ```yml; - codecs:; - packages:; - htsjdk.variant; - htsjdk.tribble; - exclude: bed.BEDCodec; - org.broadinstitute.hellbender.utils.codecs; - org.magicdgs.htsjdk.codecs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675:279,configurat,configuration,279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675,4,['configurat'],"['configuration', 'configurations']"
Deployability,"I'm told there will be a new gcloud release any day now (https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2110) with @jean-philippe-martin 's NIO retry fixes. We should update as soon as it's out, and confirm that it resolves https://github.com/broadinstitute/gatk/issues/2749, https://github.com/broadinstitute/gatk/issues/2685, and (possibly) https://github.com/broadinstitute/gatk/issues/2686",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2822:36,release,release,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2822,2,"['release', 'update']","['release', 'update']"
Deployability,"I'm trying to figure out the best way to replicate GATK3 behavior in GATK4. The GATK4 VariantWalker iterates all variants from VCF(s), calling apply() once per variant. If the input VCFs has duplicates at a given location, apply() is called multiple times for the same locus. In GATK3, VariantEval iterates each locus, and generates a list of variants at that site. I'm trying to figure out the most efficient way to do this in GATK4. One solution is to override traverse(), and add some kind of groupingBy step, for example:. StreamSupport.stream(getSpliteratorForDrivingVariants(), false); .filter(variantfilter); .collect(Collectors.groupingBy(x -> new SimpleInterval(x))); .values(); .forEach(variantList -> {; final SimpleInterval variantInterval = new SimpleInterval(variantList.get(0));; apply(variantList,; new ReadsContext(reads, variantInterval, readFilter),; new ReferenceContext(reference, variantInterval),; new FeatureContext(features, variantInterval));. progressMeter.update(variantInterval);; });. This will get me the right end result (like of variants per site); however, it's not clear to me if this is the most efficient route, and I'm not sure if it's aware of the sorted input. Because the input data are sorted, I could iterate, track the previous location and maintain a list of track variants per site. Each time we hit a new location I call apply() with that list. Are the places in GATK4 that already do this type of per-locus grouping?. Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4456:984,update,update,984,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4456,1,['update'],['update']
Deployability,"I'm trying to genotype 2388 whole genome samples of a wild species. This species has a large genome and lots of diversity. I've created my genomicsDB for my combined set and genotypeGVCF gets stuck when trying to make the VCF. ; I've been giving it 120G of ram, 32 cores and 30 minutes and it only prints out the first variable 12 sites (corresponding to about 800bp of the genome) to the VCF . I understand that is certainly going to be slow, and I'm prepared to heavily parallelize it, but this is currently unusable to me. Is there any way to speed it up?. Here's my command:. ```; /gatk/gatk-launch --java-options ""-Xmx120G"" GenotypeGVCFs \; -R /home/user/bin/ref/reference.fa \; --intervals $contig \; -V gendb://${chr}_$pos \; -O /scratch/wild_gwas/$genomicsdb/${chr}_$pos.tmp.vcf.gz \; --seconds-between-progress-updates 5 --verbosity DEBUG; ```; Here's standard out:. > 21:13:04.092 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/build/install/gatk/lib/gkl-0.8.2.jar!/com/intel/gkl/native/libgkl_compression.so; > 21:13:04.108 DEBUG NativeLibraryLoader - Extracting libgkl_compression.so to /tmp/gowens/libgkl_compression3380966567685792416.so; > 21:13:04.218 INFO GenotypeGVCFs - ------------------------------------------------------------; > 21:13:04.219 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.0.0.0; > 21:13:04.219 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; > 21:13:04.219 INFO GenotypeGVCFs - Executing as user@cdr806.int.cedar.computecanada.ca on Linux v3.10.0-693.5.2.el7.x86_64 amd64; > 21:13:04.219 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_131-8u131-b11-2ubuntu1.16.04.3-b11; > 21:13:04.219 INFO GenotypeGVCFs - Start Date/Time: January 15, 2018 9:13:04 PM UTC; > 21:13:04.219 INFO GenotypeGVCFs - ------------------------------------------------------------; > 21:13:04.220 INFO GenotypeGVCFs - -------------------------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4161:820,update,updates,820,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4161,2,"['install', 'update']","['install', 'updates']"
Deployability,"I'm using GATK 4.1.8.1. And I found a similar error when trying to use GenotypeGVCFs to consolidate genotyping variants on chrX. It does not give any error message. It silently fails. BTW, I'm dealing with WES data. This is the code I used:; # For GenomicDBImport, I randomly select 50 samples from our history samples(using the same probe set) along with the current batch.; time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport \; --tmp-dir /paedyl01/disk1/yangyxt/test_tmp \; --genomicsdb-update-workspace-path ${vcf_dir}/genomicdbimport_chr${1} \; -R ${ref_gen}/ucsc.hg19.fasta \; --batch-size 0 \; --sample-name-map ${gvcf}/batch_cohort.sample_map \; --reader-threads 5; check_return_code. # For GenotypeGVCFs; time ${gatk} --java-options ""-Xmx8g -Xms2g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" GenotypeGVCFs \; -R ${ref_gen}/ucsc.hg19.fasta \; -V gendb://${vcf_dir}/genomicdbimport_chr${1} \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -L chr${1} \; -O ${bgvcf}/all_${seq_type}_samples_plus_${sample_batch}.chr${1}.HC.vcf. # These are log records:; 02:07:51.286 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 02:07:51.321 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl; Nov 06, 2020 2:07:56 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 02:07:56.529 INFO GenotypeGVCFs - ------------------------------------------------------------; 02:07:56.529 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 02:07:56.530 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 02:08:01.543 INFO GenotypeGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 02:08:01.543 INFO Ge",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059:499,update,update-workspace-path,499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059,1,['update'],['update-workspace-path']
Deployability,"I'm using GATK4 as a framework to implement my own tools, and it will be nice to have a way of perform integration tests using `IntegrationTestSpec`. Nevertheless, it requires the extension of the `CommandLineProgramTest` to run the command, and thus it is extending `BaseTest`. The issues that this infrastructure generates when trying to use this test classes are the following:; - `BaseTest` loading of `GenomeLocParser` is annotated with `@BeforeClass`, which throws an error because the reference genome (hg19MiniReference) is not present in the repository.; - `CommandLineProgramTest` is using `org.broadinstitute.hellbender.Main` for running the commands, but for custom tools the instanceMain with a different list of packages. Although this could be solved by extending the class by another abstract class. I propose (and I can implemented if you agree) the following:; - `CommandLineProgramTest` not implementing `BaseTest`.; - `CommandLineProgramTest` as a real abstract class without implementations of `getTestDataDir()` or `runCommandLine()`; - Abstract `GATKCommandLineProgramTest` extending both `CommandLineProgramTest` and `BaseTest`, sited in `org.broadinstitute.hellbender.utils.test` and used in all integrations tests in this repository and the protected repository.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2033:103,integrat,integration,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2033,3,"['Integrat', 'integrat']","['IntegrationTestSpec', 'integration', 'integrations']"
Deployability,"I'm using spark 2.1.0. I can confirm it works with the command ; ```; spark-submit \; --deploy-mode client \; --class org.broadinstitute.hellbender.Main \; --master yarn \; /home/hadoop/gatk-package-4.alpha.2-269-gdce8abc-SNAPSHOT-spark.jar BwaSpark \; --bwamemIndexImage /var/tmp/hs38DH-V.fasta.img \; -I hdfs:///unaligned.bam \; -O hdfs:///aligned.bam \; -R hdfs:///hg38/hs38DH-V.fasta \; --disableSequenceDictionaryValidation true \; --sparkMaster yarn; ```; so I guess it's really a minor issue. I can see it confusing other spark users though, who might expect spark configuration arguments to go through `spark-submit` rather than the application args, especially since the --sparkMaster app arg is optional. Just my two cents.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2718#issuecomment-301945697:88,deploy,deploy-mode,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2718#issuecomment-301945697,2,"['configurat', 'deploy']","['configuration', 'deploy-mode']"
Deployability,"I'm using the `ReadLikelihoods` in a test and I'm setting the likelihoods to negative values. Nevertheless, when I'm trying to get the best alleles for each read using the `bestAlleles()` method, it turns out to return the allele where I haven't set any likelihood (by default, 0). I think that the bug is in the private method [`searchBestAllele`](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/utils/genotyper/ReadLikelihoods.java#L438), were if the candidate likelihood is __bigger than__ the best likelihood, the best allele is updated. I apologize in advance if this is not a bug, but I would like to know if I should use negative likelihoods as in the removed `PerReadAlleleLikelihoodMap`, or positive ones, as suggest the current implementation for getting the best alleles. Thank you in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2311:580,update,updated,580,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2311,1,['update'],['updated']
Deployability,"I'm working on an imputation pipeline right now, and the contigs in the returned VCF header don't contain lengths. This fix to UpdateVCFSequenceDictionary allows me to force an update to the VCF's sequence dictionary so I have a valid VCF I can use with the rest of our tools when both --replace and --disable-sequence-dictionary-validation are set to true.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6140:29,pipeline,pipeline,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6140,3,"['Update', 'pipeline', 'update']","['UpdateVCFSequenceDictionary', 'pipeline', 'update']"
Deployability,I'm working on some Plasmodium falciparum callsets in GATK and I have come across a curious error:. ```; Using GATK wrapper script /juffowup/gatk/build/install/gatk/bin/gatk; Running:; /juffowup/gatk/build/install/gatk/bin/gatk HaplotypeCaller -R /juffowup2/malaria/references/PlasmoDB-61_Pfalciparum3D7_Genome.fasta -I /juffowup2/malaria/haplotypecaller_arg_testing/fixed_bam/PG0004-CW.aligned.merged.markDuplicates.sorted.BQSR.bam -O /juffowup2/malaria/haplotypecaller_arg_testing/PG0004-CW.haplotype_caller.fixed_bam_file.with_pileup.g.vcf.gz --bam-output /juffowup2/malaria/haplotypecaller_arg_testing/PG0004-CW.haplotype_caller.fixed_bam_file.with_pileup.bamout.bam -contamination 0 --sample-ploidy 2 --linked-de-bruijn-graph --pileup-detection true --pileup-detection-enable-indel-pileup-calling true --max-reads-per-alignment-start 20 --annotate-with-num-discovered-alleles -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -G StandardAnnotation -G StandardHCAnnotation -ERC GVCF --verbosity INFO; 14:14:15.323 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 14:14:15.328 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 14:14:15.388 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/juffowup/gatk/build/install/gatk/lib/gkl-0.8.11.jar!/com/intel/gkl/native/libgkl_compression.so; 14:14:15.435 INFO HaplotypeCaller - ------------------------------------------------------------; 14:14:15.439 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.4.0.0-44-g1529aa1-SNAPSHOT; 14:14:15.439 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:14:15.439 INFO HaplotypeCaller - Executing as jonn@dsde-methods-jonn-juffowup on Linux v5.4.0-1104-gcp amd64; 14:14:15.439 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8440:152,install,install,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8440,2,['install'],['install']
Deployability,"I'm worried about relaxing the errors to warnings. We previously had a similar round of issues where installation was failing and producing a warning but no error and we ended up with corrupt docker images. So we added code to convert warnings to errors. What we need is to not throw a warning when a remote is unavailable if the other remotes are available, which seems like the behavior I would expect from specifying multiple remotes...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5602#issuecomment-457246918:101,install,installation,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5602#issuecomment-457246918,1,['install'],['installation']
Deployability,"I've actually been lobbying to get rid of IntegrationTestSpec completely. Although it probably once added value, it has some [problems](https://github.com/broadinstitute/gatk/issues/1562) that limit its usefulness, and the remaining functionality (like expected exception checking) is available directly in the test framework. We have quite a few tests that don't use it at all, and it would be nice to only support one style, so I'd be inclined to discourage rather than encourage it, and focus on resolving the BaseTest issues.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-243120257:42,Integrat,IntegrationTestSpec,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-243120257,1,['Integrat'],['IntegrationTestSpec']
Deployability,"I've added a bunch of additional unit tests for the `StandardCallerArgumentCollection`, and beefed up the `HaplotypeCaller` integration tests as well (we now check for concordance against the GATK3 contamination-corrected calls, in addition to just asserting that the calls in GATK4 improve with contamination correction on).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4455#issuecomment-369983458:124,integrat,integration,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4455#issuecomment-369983458,1,['integrat'],['integration']
Deployability,"I've added a new end-to-end test for SelectVariants that writes to GCS. Sadly, the IntegrationTestSpec class uses Files throughout, so it wasn't possible to do this simply without first completely refactoring IntegrationTestSpec (which should probably be its own pull request). . Doing this refactoring would have the advantage that changing existing end-to-end tests from local to GCS would be trivial. For now instead I went with an ad-hoc approach. It works, and the test passes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455686612:83,Integrat,IntegrationTestSpec,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455686612,2,['Integrat'],['IntegrationTestSpec']
Deployability,"I've added the CRAM tests. Remain to add an integration test that writes to GCS. @cmnbroad can you explain what you mean by ""Also note that you won't be able to use iterator comparison when comparing an Iterator with Iterator."" ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332368738:44,integrat,integration,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332368738,1,['integrat'],['integration']
Deployability,"I've also encountered same problem, any update or quick workaround? Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7625#issuecomment-1524477521:40,update,update,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7625#issuecomment-1524477521,1,['update'],['update']
Deployability,"I've been looking at 2bit performance today, comparing ADAM release version 0.20.0 to release version 0.23.0 and to git HEAD (0.24.0-SNAPSHOT), in various use cases, and do not see any performance differences. @tomwhite `loadReferenceFile` in ADAM only supports local 2bit files, what happens in between the file in `gs://` cloud storage to when you load it via ADAM APIs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367159861:60,release,release,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367159861,2,['release'],['release']
Deployability,I've been taking a look this morning but am so far unable to reproduce the problem. I tried adding lines to the integration test file to mimic having a SNP at the last base of a spanning deletion as in the bug report:. ```; 20 10001300 . GGG G . . .; 20 10001302 . G C . . .; ```. But I'm not hitting this error. . @gmagoon any chance you could provide any more information that would help us reproduce this? The exact command line you're using might help. Do you still get the error if you run with an alleles file consisting _only_ of one of the pairs of given allele lines listed above?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5336#issuecomment-431865967:112,integrat,integration,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5336#issuecomment-431865967,1,['integrat'],['integration']
Deployability,"I've been thinking about this literal edge case. We now have metagenomic pipelines that are meant to align data to presumably extremely small references (bacteria, infectious agents, e.g. viri). These organisms have a different expectation for mutation/variant rates that my synthetic data could represent. I am unfamiliar with the details of the metagenomics pipelines except that it aligns reads to a giant conglomerate of different organisms. I forget whether the pipeline actually produces an alignment BAM or just a list of organisms--perhaps @mwalker174 could inform us. On the forum, we've had a few cases where we encourage folks to use our tools even when they work in other nonmammalian organisms such as bacteria. However, knowing how our assembler handles data at the edges of contigs, and how variants that are close together trigger alternate assumptions, e.g. the presence of an indel as I learned from @droazen, then I'd like to know how I should actually be informing our nonmammalian researchers. Whether they should or should not consider assembly-based calling, whether there are certain parameters they could employ to ensure calling some variant (even if wrong) rather than no variant within the confines of a small genome, or whether I should point them to a pileup caller, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4073#issuecomment-360515238:73,pipeline,pipelines,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4073#issuecomment-360515238,6,['pipeline'],"['pipeline', 'pipelines']"
Deployability,I've been told that this is solvable by bumping the dataproc version from 1.1 -> 1.2. We need to update this on jenkins assuming it works fine with spark 2.2.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4186#issuecomment-358361262:97,update,update,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4186#issuecomment-358361262,1,['update'],['update']
Deployability,"I've completely rewritten the documentation portion to be more helpful to users (and to reflect the new M2 rather than gatk3's M2), and I have updated the example commands. ---; ### Questions for @davidbenjamin ; - `--af_of_alleles_not_in_resource`: is this allele frequency used only in certain contexts, e.g. with matched normal analyses, or towards tumor sample variant alleles, etc.? I need to add to the doc details how this argument factors into calculations.; - I need a sentence or two describing the new algorithmic improvement on the new Mutect2 integration over uncertainty. ; - The WDLs do not include use of a contamination.table and so I did not include it in the commands. Is this something we want to nudge users to use, i.e. should I put in a sentence in the documentation section about the new tool CalculateContamination?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2816:143,update,updated,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2816,2,"['integrat', 'update']","['integration', 'updated']"
Deployability,"I've created a branch for testing here: https://github.com/broadinstitute/gatk/tree/tw_spark2. Note that we can't upgrade until the CDH cluster is upgraded to Spark 2. Also, ADAM format support is disabled until ADAM works with Spark 2 (slated for ADAM 0.20.0: https://github.com/bigdatagenomics/adam/issues/1021)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2073#issuecomment-241432101:114,upgrade,upgrade,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2073#issuecomment-241432101,2,['upgrade'],"['upgrade', 'upgraded']"
Deployability,"I've created a fix in #2450, but have not been able to run the pipeline that failed. @lbergelson, could you take a look?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2449#issuecomment-285653510:63,pipeline,pipeline,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2449#issuecomment-285653510,1,['pipeline'],['pipeline']
Deployability,"I've had several Travis test failures (on my picard removal branch) that appear to be failures during kryo serialization of a mocked ReferenceMultiSource object (based on the failing class name, (org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource$$EnhancerByMockitoWithCGLIB$$b0dc631f, which looks like the CGLIB names mentioned [here](https://github.com/mockito/mockito/issues/319)). We're on an ancient version of mockito anyway, and newer versions no longer use cglib, so it seemed like a good time to upgrade. To do so I also had to replace usage of the method getArgumentAt, which has been [deprecated](https://github.com/mockito/mockito/pull/373) in favor of getArgument.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3581:524,upgrade,upgrade,524,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3581,1,['upgrade'],['upgrade']
Deployability,"I've had this issue on MacOS X and was able to install the environment successfully by removing the open-mp and mkl lines from the yaml:; ```; - intel-openmp=2018.0.0; - mkl=2018.0.1; - mkl-service=1.1.2; ``` ; Then you may need to remove the partially installed environment with:; ```; conda remove --name gatk --all; ```; Then you can run:; ```; conda create -n gatk -f ./scripts/gatkcondaenv.yml; ```; Hopefully, the tools will run without openmp and mkl, but I'm sure we are taking a performance hit so we should figure out what is the right channel to point to for these packages. @erniebrau have you ever had these isssues?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4822#issuecomment-393235457:47,install,install,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4822#issuecomment-393235457,2,['install'],"['install', 'installed']"
Deployability,"I've now improved the naming of the parameter tot specify the Spark submit command (now it's `--sparkSubmitCommand`), to address @lbergelson's feedback. I updated to the latest shaded google-cloud-nio artifact, and it works with Spark 2 on a cluster. However, the `GcsNioIntegrationTest` fails due to the `javax` package (and subpackages) being shaded (these packages should not be shaded since Java provides these classes). So I'm afraid we'll need another release to fix this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-257582314:155,update,updated,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-257582314,4,"['release', 'update']","['release', 'updated']"
Deployability,I've performed a release of 4.0.9.0 using the poms generated with https://github.com/broadinstitute/gatk/pull/5224 and a bit of manual work.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5212#issuecomment-424502910:17,release,release,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5212#issuecomment-424502910,1,['release'],['release']
Deployability,"I've pulled the problem VCF and a couple of successful ones locally and I can confirm that when running with 4 VCFs:. - VCFs that succeeded through JointGermlineCNVSegmentation in our pipeline succeeded for me locally; - The VCF that was flagged in the error message `Exception thrown at chrX:6383391 [VC SAMPLE_ID.segments.vcf.gz ...` completes just fine with other successful partners; - The VCF that was not identified in the error message, but was inferred to be a sex chromosome aneuploidy causes a failure with any combination of other VCFs; - If there are more than 2 VCFs run together, including the failing VCF/aneuploid sample, the error message indicates the problem originates in a non-aneuploid VCF, which misleading and makes this hard to treat. This behaviour was consistent in `4.5.0.0`. Command used in my toy dataset:. ```; gatk --java-options ""-Xms4000M -Xmx6000M"" JointGermlineCNVSegmentation -R /data/Homo_sapiens_assembly38_masked.fasta -O /data/out.vcf.gz -V /data/SAM1.segments.vcf.gz -V /data/SAM2.segments.vcf.gz -V /data/SAM3.segments.vcf.gz -V /data/SAM4.segments.vcf.gz --model-call-intervals /data/preprocessed.interval_list -ped /data/inferred_sex_pedigree.ped; ```. - In this configuration, `SAM4` is aneuploid, and `SAM1` is always the flagged VCF; - If I remove `SAM1` and re-run with 3 VCFs, `SAM3` is mentioned in the error message. It's not derived from alphabetical order, first argument specified with `-V`, or first in the PED file",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8834#issuecomment-2123897736:184,pipeline,pipeline,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8834#issuecomment-2123897736,2,"['configurat', 'pipeline']","['configuration', 'pipeline']"
Deployability,I've pushed up an initial patch to this branch to fix the issues I found. I'll push up tests later tonight after I grab some dinner :),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2393#issuecomment-277404479:26,patch,patch,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2393#issuecomment-277404479,1,['patch'],['patch']
Deployability,"I've rebased this branch and updated it to the latest `GnarlyGenotyper`. It looks like with the new version of google-cloud-java our dependency conflict with BigQuery has been resolved, so we can work towards getting this merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6011#issuecomment-531386196:29,update,updated,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6011#issuecomment-531386196,1,['update'],['updated']
Deployability,"I've rebased this branch, and added a few minor updates. This can be merged after test pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4003#issuecomment-356144033:48,update,updates,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4003#issuecomment-356144033,1,['update'],['updates']
Deployability,"I've run into an error using a certain BAM file I created for testing. Possibly relevant: I also tried running it through PrintReads - all reads were filtered out by the WellFormedReadFilter because they do not have read groups or base qualities. [test_pathseq_unmapped.bam.zip](https://github.com/broadinstitute/gatk/files/537153/test_pathseq_unmapped.bam.zip). > > ./gatk-launch PrintReadsSpark -I ~/Work/gatk/tests/test_pathseq_unmapped.bam -O ~/Work/gatk/tests/test_pathseq_unmapped.output.bam; > > Using GATK wrapper script /Users/markw/IdeaProjects/gatk/build/install/gatk/bin/gatk; > > Running:; > > /Users/markw/IdeaProjects/gatk/build/install/gatk/bin/gatk PrintReadsSpark -I /Users/markw/Work/gatk/tests/test_pathseq_unmapped.bam -O /Users/markw/Work/gatk/tests/test_pathseq_unmapped.output.bam; > > 15:10:22.765 INFO IntelGKLUtils - Trying to load Intel GKL library from:; > > jar:file:/Users/markw/IdeaProjects/gatk/build/install/gatk/lib/gkl-0.1.2.jar!/com/intel/gkl/native/libIntelGKL.dylib; > > 15:10:22.790 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; > > [October 18, 2016 3:10:22 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark --output /Users/markw/Work/gatk/tests/test_pathseq_unmapped.output.bam --input /Users/markw/Work/gatk/tests/test_pathseq_unmapped.bam --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false --disableAllReadFilters false; > > [October 18, 2016 3:10:22 PM EDT] Executing as markw@WMC9F-819 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_91-b14; Version: Version:4.alpha.1-318-gcdc484c-SNAPSHOT; > > 15:10:22.793 INFO PrintReadsSpark - Defaults.BUFFER_SIZE : 131072; > > 15:10:22.793 INFO PrintReadsSpark - Defaults.COMPRESS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2219:566,install,install,566,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2219,3,['install'],['install']
Deployability,I've started to take a look at this. Thank you for running the Carrot Tests! I guess you might be right about the score jitter not mattering but man there are enough differences in the HC integration test that i'm a little worried....,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1581501197:188,integrat,integration,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1581501197,1,['integrat'],['integration']
Deployability,"I've tentatively categorized the tools and they are listed in speadsheet format at:; ### https://docs.google.com/a/broadinstitute.org/spreadsheets/d/19SvP6DHyXewm8Cd47WsM3NUku_czP2rkh4L_6fd-Nac/edit?usp=sharing. - [1] GATK4 and Picard tool categories are up for discussion. They are meant to be functional and will be used at <https://software.broadinstitute.org/gatk/documentation/tooldocs/current/>. First pass by Soo Hee. If you have a better idea, please write to this issue ticket.; - [2] We can do better than minimum. At minimum, each tool has a summary description and example command. ; - Authorship should not be picked up by gatkDocs (but can remain in javaDoc portion of code so long as masked). If `* @author Valentin Ruano-Rubio &lt;valentin@broadinstitute.org&gt;` is placed at top of doc, causes javaDoc to not show. Such lines should be at the end of the javaDoc portion. @vdauwera prefers all author annotations be removed.; - Tool commands should use `gatk` to invoke the launch script, not `gatk-launch`. Engine team tells me this change will be effective end of this month.; - A number of tools need `-Xmx` to be defined and this should be reflected in the example command(s). Hopefully, if your tool needs it, you already know it. Otherwise, see <https://github.com/broadinstitute/gatk/issues/3137>.; - [3] `**AMENDED**` Documentation of Picard tools in the Best Practices are a priority as is categorization of Picard tools. In the forum tool list, Picard tools will be mixed with GATK tools alphabetically, with the PICARD label coming after the tool name. To view docs, build with `./gradlew clean gatkDoc`, then view local index in browser.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-345867598:113,a/b,a/broadinstitute,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-345867598,1,['a/b'],['a/broadinstitute']
Deployability,I've updated https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2453 with this result -- we'll see what they say.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331281442:5,update,updated,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331281442,1,['update'],['updated']
Deployability,I've updated the commands that now use kebab:. [4] tumorA: GATK4 HC NOT seeing the G allele at 121 (but sees the C).; ```; gatk HaplotypeCaller \; 	-I tumorA.bam \; 	-R ref200.fasta \; 	-O gatk4_hc_tumorA.vcf.gz \; 	--max-assembly-region-size 40 \; 	--assembly-region-padding 10 \; 	--min-assembly-region-size 10 \; 	--debug; ```. [5] normal: GATK4 HC completely blind to the GG at 121; ```; gatk HaplotypeCaller \; 	-I normal.bam \; 	-R ref200.fasta \; 	-O gatk4_hc_normal.vcf.gz \; 	--max-assembly-region-size 40 \; 	--assembly-region-padding 10 \; 	--min-assembly-region-size 10 \; 	--debug; ```. [6] tumorB: GATK4 HC has no problem seeing the C allele at 121; ```; gatk HaplotypeCaller \; 	-I tumorB.bam \; 	-R ref200.fasta \; 	-O gatk4_hc_tumorB.vcf.gz \; 	--max-assembly-region-size 40 \; 	--assembly-region-padding 10 \; 	--min-assembly-region-size 10 \; 	--debug; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4073#issuecomment-356088297:5,update,updated,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4073#issuecomment-356088297,1,['update'],['updated']
Deployability,I've updated the image and it seems to be working locally. Now for the true test...,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8228:5,update,updated,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8228,1,['update'],['updated']
Deployability,IIRC it's just an intervals file. It's a debugging option so not a priority for the beta release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2796#issuecomment-305675387:89,release,release,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2796#issuecomment-305675387,1,['release'],['release']
Deployability,"IIRC, this use of this feature was discouraged in GATK3 . Right @vdauwera? Making a new release of HTSJDK and incorporating it should fix the underlying problem.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2755#issuecomment-304333636:88,release,release,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2755#issuecomment-304333636,1,['release'],['release']
Deployability,"INFO ProgressMeter - chrUn_KI270743v1:125398 9.9 6674000 675662.2; 13:55:00.673 INFO ProgressMeter - chr20_KI270869v1_alt:62679 10.0 6792000 676161.8; 13:55:10.679 INFO ProgressMeter - chr19_GL949752v1_alt:485077 10.2 6910000 676673.7; 13:55:26.149 INFO ProgressMeter - HLA-DRB1*11:01:02:3272 10.5 6938356 662718.7; 13:55:26.149 INFO ProgressMeter - Traversal complete. Processed 6938356 total records in 10.5 minutes.; 13:55:26.149 INFO ComposeSTRTableFile - Shutting down engine; [April 4, 2021 1:55:26 PM EDT] org.broadinstitute.hellbender.tools.dragstr.ComposeSTRTableFile done. Elapsed time: 10.52 minutes.; Runtime.totalMemory()=1128792064; Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16G -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar CalibrateDragstrModel -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --str-table-path gvcf.STR/ADNI_002_S_0413.hg38.realign.bqsr/ADNI_002_S_0413.hg38.realign.bqsr.STR.table -O gvcf.STR/ADNI_002_S_0413.hg38.realign.bqsr/ADNI_002_S_0413.hg38.realign.bqsr.Dragstr.model -I /restricted/projectnb/casa/wgs.hg38/adni/cram/ADNI_002_S_0413.hg38.realign.bqsr.cram; 13:55:30.890 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Apr 04, 2021 1:55:31 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:55:31.182 INFO CalibrateDragstrModel - ------------------------------------------------------------; 13:55:31.183 INFO CalibrateDragstrModel - The Genome Analysis Toolkit (GATK) v4.2.0.0; 13:55:31.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182:11512,install,install,11512,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182,1,['install'],['install']
Deployability,Ideally using a standard mechanism like Apache `Configuration`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2368:48,Configurat,Configuration,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2368,1,['Configurat'],['Configuration']
Deployability,Identify inputs and outputs for each tool in the data pre-processing pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/457:69,pipeline,pipeline,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/457,1,['pipeline'],['pipeline']
Deployability,Identify inputs and outputs for tools in the read pre-processing pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/458:65,pipeline,pipeline,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/458,1,['pipeline'],['pipeline']
Deployability,"If AVX is now required in the mainline tensorflow release as well, then I agree with @lucidtronix that we don't need to maintain a fallback environment -- provided that we're talking about **AVX1** here, and not AVX2/AVX512. We don't currently have the ability to request nodes on travis or Google cloud with AVX2/AVX512. I'd like to see this PR modified, however, to throw a `UserException` from the tool rather than in `customCommandLineValidation()`. The `UserException` should include a message with a pointer to versions of Tensorflow that work on non-AVX hardware.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429956467:50,release,release,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429956467,1,['release'],['release']
Deployability,"If I can suggest something here: . - instead of trying to move GATK from Java 8 to Java 11, probably better off to move to Java 17 or Java 18; - On Java 17/18, choose Amazon corretto - https://aws.amazon.com/corretto/ ; - Why Corretto - Corretto is a distribution of Open JDK with patches included by Amazon **_that are not yet integrated in the corresponding OpenJDK update projects_**. ; -- Quarterly updates/patches; - Github page: https://github.com/corretto; - easily ""dockerizable"": https://github.com/corretto/corretto-docker . **_Disclaimer_**: I am **_not_** from Amazon/AWS",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7842#issuecomment-1123002102:281,patch,patches,281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7842#issuecomment-1123002102,5,"['integrat', 'patch', 'update']","['integrated', 'patches', 'update', 'updates']"
Deployability,"If a `VariantWalker` driving variant is indexed with tribble but does not have an sequence dictionary in the header, the dictionary is loaded from the index. Nevertheless, this is a truncated dictionary because the end coordinate for each chromosome is the last variant in that contig. Thus, even if a proper interval for the genome is provided (regarding the reference sequence), the program throw an user error exception. This could be reproduced with the following test in `ExampleVariantWalkerIntegrationTest`:. ``` java; @Test; public void testExampleVariantWalkerInvalidDictionary() throws IOException {; final IntegrationTestSpec testSpec = new IntegrationTestSpec(; "" -L 1:200-1125"" +; "" -R "" + hg19MiniReference +; "" -I "" + TEST_DATA_DIRECTORY + ""reads_data_source_test1.bam"" +; "" -V "" + TEST_DATA_DIRECTORY + ""example_variants.vcf"" +; "" -auxiliaryVariants "" + TEST_DATA_DIRECTORY + ""feature_data_source_test.vcf"" +; "" -O %s"", Arrays.asList(TEST_OUTPUT_DIRECTORY + ""expected_ExampleVariantWalkerIntegrationTest_output.txt""));; testSpec.executeTest(""testExampleVariantWalker_UndefinedContigLengthsInDictionary"", this);; }; ```. The thrown exceptions is the following:. ``` java; java.lang.RuntimeException: org.broadinstitute.hellbender.exceptions.UserException$MalformedGenomeLoc: A USER ERROR has occurred: Badly formed genome loc: Failed to parse Genome Location string: 1:200-1125; ```. This comes from the overrided method `VariantWalker.getBestAvailableSequenceDictionary()`, which prefers the one from the driving variant (in this case, the one which comes from the index), not using the one from the reference/reads if available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2081:617,Integrat,IntegrationTestSpec,617,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2081,2,['Integrat'],['IntegrationTestSpec']
Deployability,"If docker is needed to run M2 wdl, I wish it can run without docker.; I need to run M2 wdl using grid engine backend and an old version needed some modifications to run without docker installed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358877500:184,install,installed,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358877500,1,['install'],['installed']
Deployability,"If the pattern is common, we could certainly explore adding some kind of ""argset"" support to Barclay. It would have the advantage of getting it integrated into the help and doc, though that could get complicated. Another possibility is a hybrid approach, where Barclay supports declarative argset definitions, but uses them for help interrogation only, with a command line argument that takes an argset name and generates output or an executable command line with recommended defaults for that argset:. `gatk GermlineCNVCaller --argsetfor WGS`. would generate:. `gatk GermlineCNVCaller --std-log-mean-bias 1.0 --interval-psi-scale 0.0001 ...`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385681493:144,integrat,integrated,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385681493,1,['integrat'],['integrated']
Deployability,If the requested key is missing in an Avro record:. - Avro 1.11 [throws](https://github.com/apache/avro/blob/release-1.11.0/lang/java/avro/src/main/java/org/apache/avro/generic/GenericData.java#L267-L269); - Avro 1.8 [returns null](https://github.com/apache/avro/blob/release-1.8.0/lang/java/avro/src/main/java/org/apache/avro/generic/GenericData.java#L208). Most of the code here was written for Avro 1.8 behavior; these changes adapt for Avro 1.11.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8266:109,release,release-,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8266,2,['release'],['release-']
Deployability,"If there are overlapping (e.g. a long SNV overlapping an INDEL) or multi-allelic germline variants, Mutect2 will check only the AF of the first variant/allele when searching for germline sites to exclude during active region detection. This PR updates the logic to iterate through all germline alleles.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7468:244,update,updates,244,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7468,1,['update'],['updates']
Deployability,"If we like this -- we also need to . - [x] build a jar; - [x] update the WDL to use this tool (and the Jar); - [ ] Put the BED files someplace public/widely accessible (likely just the 1kb version); - [x] Run an E2E on QuickStart, merge the VCFs and compare (and see no differences); - [x] If we want to validate evenness we need to run with a lot of shards and enough data that they are interesting. Maybe Stroke 10k; - [x] In parallel if we could turn some of the above script into integration tests that would be awesome",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7643#issuecomment-1017113500:62,update,update,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7643#issuecomment-1017113500,2,"['integrat', 'update']","['integration', 'update']"
Deployability,If we will get rid of those anyway can't we just provide a yml file with an unsupported yet minimal conda environment just to run old CNN tools (Neither we make it mandatory on the docker image nor we force people to install it). We should keep in mind that some of those libraries are pulled from the default channel which still raises questionable ethics for some.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8907#issuecomment-2220712963:217,install,install,217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8907#issuecomment-2220712963,1,['install'],['install']
Deployability,"If you haven't ""built"" the wrapper script, it complains. Strictly speaking, if you're only ever going to use Spark, you don't need the wrapper. The check should only happen if you choose the local walker impl. ```; [ec2-user@ip-10-1-1-71 gatk-4.alpha.rc1]$ ./gatk-launch -h; Missing GATK wrapper script: /home/ec2-user/gatk-4.alpha.rc1/build/install/gatk/bin/gatk; To generate the wrapper run:. /home/ec2-user/gatk-4.alpha.rc1/gradlew installDist; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1331:342,install,install,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1331,2,['install'],"['install', 'installDist']"
Deployability,"If you'd prefer i post this kind of question elsewhere, please let me know. My lab creates a large dataset of macaque variant data. We regularly add new samples to a dataset that currently has ~2300 WGS/WXS datasets. We largely follow the GATK short variant calling pipeline. Our gVCF data are aggregated into a GenomicsDb workspace, followed by GenotypeGVCFs. As is, whenever we get new samples, we append them to this growing GenomicsDb workspace, and then re-call all of the genotypes. These steps are getting slower and slower (even when scatter/gathered on a cluster), and I'm concerned it's going to become untenable. Plus it's just really inefficient to constantly re-call 1000s of datasets at 40m genome-wide sites. My question is: do you have any experience with analogous datasets, where you have a large base of ""static"" datasets with regular additions of new data? It would be quite nice to avoid constantly re-genotyping the existing datasets. We could in theory just run GenotypeGVCFs on the incoming data and do a simple merge with the existing data. Are you aware of anyone running a process that looks more like this?. There are some caveats to this: 1) for the incoming batches of data, we could run GenotypeGVCF where we force it to call genotypes from every site that exists in the current dataset. This would promote consistent calling across a common set of sites, 2) after we genotype the incoming batch, we could compare the sites present in that against the sites in the current data. It's likely there would be a handful of novel sites. We could re-run GenotypeGVCFs on the existing data specifically on those new sites (presumably the existing animals are largely WT at those positions), and merge those new sites with the existing data, 3) we then merge the incoming data with the updated core data, which should each have genotypes called at the identical set of sites. Are there any discussions happening about managing/updating large variant datasets like this? Thanks f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7526:266,pipeline,pipeline,266,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7526,1,['pipeline'],['pipeline']
Deployability,"If you're interested in BWASpark tool I might wait a bit. There are a lot of issues with it as it currently stands, it's one of the least tested tools we have. We have someone working on a different more efficient implementation of the bwa bindings that may eventually be integrated into mainline gatk, so we've sort of stopped most development on BWASparkEngine until we're clear on the direction that the new work is going to take.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-267119998:272,integrat,integrated,272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-267119998,2,['integrat'],['integrated']
Deployability,"If you're talking about the need for `dollar`, I'm not sure---looks like there are other instances of this hack in other WDLs, some of which have purportedly been updated to 1.0. I don't think we would need this hack (in the gCNV WDLs, at least) if it weren't for the bash-related shenanigans in that task, which are required due to the wonky output style of IntervalListTools, though...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6502#issuecomment-599609821:163,update,updated,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6502#issuecomment-599609821,1,['update'],['updated']
Deployability,"Implemented CombineRawData() and GenerateRawData() methods from GATK3 in all Allele Specific annotations and added tests designed to mimic the existing CombineGVCFs integration tests in GATK3 by asserting the combined output matches that of GATK3. This could still use more substantial tests for finalizeRawAnnotations and AnnotateRawData. Additionally, I would like to ask for advice as to how I should go about further implementing tests for the annotation classes. . Fixes #1893; Fixes #3535",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3527:165,integrat,integration,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527,1,['integrat'],['integration']
Deployability,Implemented VCF ID for VCF data sources. - Now VCF data sources create an ID field for the ID of the variant; used for the annotation. - Updated the regression test suite with a VCF data source to increase; test coverage. Fixes #5186,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5327:137,Update,Updated,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5327,1,['Update'],['Updated']
Deployability,"Implements #1552 . When the StrandAlleleCountsBySample (SAC) annotation is present in VCFs, allele subsetting by SelectVariants will now update this field in the final VCF. **Summary of changes**; - `SelectVariants.subsetRecord()` uses the updated `GATKVariantContextUtils.updatePLsSACsAD()`, which contains the machinery to subset SAC by the used alleles.; - Added unit and integration tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1852:137,update,update,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1852,4,"['integrat', 'update']","['integration', 'update', 'updatePLsSACsAD', 'updated']"
Deployability,"Implements a Bwa Spark tool for the PathSeq pipeline. . Tool input:; 1) BAM of paired reads; 2) BAM of unpaired reads; 3) Bwa index image file. Output:; 1) BAM of paired alignments; 2) BAM of unpaired alignments. Notes:; - The tool does not generate secondary/supplementary alignments. ; - Alternate alignments are written to the SA tag. ; - Only the sequences for which there was at least 1 alignment are written to the BAM headers (instead of writing all sequences in the reference, which is 10,000's for the pathogen database and substantially increases the run time of the subsequent scoring tool).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3113:44,pipeline,pipeline,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3113,1,['pipeline'],['pipeline']
Deployability,"Implements https://github.com/broadinstitute/gatk/issues/1382.; Remove diploid assumptions during allele subsetting. **Summary**; - Changed `GenotypeLikelihoods.GenotypeLikelihoodsAllelePair GenotypeLikelihoods.getAllelePair(int PLindex)` to `ArrayList<Integer> GenotypeLikelihoods.getAlleles(int PLindex, int ploidy)` in GATKVariantContextUtils. ; - Added integration and unit tests.tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1845:357,integrat,integration,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1845,1,['integrat'],['integration']
Deployability,"Implements tool for clustering SVs, built on top of the clustering engine code refined recently in #7243. In addition to a few bug fixes, updates also include:. - `PloidyTable` class, which ingests and serves as a simple data class for a tsv of per-sample contig ploidies. This was necessary for inferring genotypes when input vcfs contain non-matching sample and variant records.; - Modified `SVClusterEngine` to render sorted output.; - Improved code for SV record collapsing (see the `CanonicalSVCollapser`), particularly for CNVs. Genotype collapsing now infers allele phasing in certain unambiguous cases, in particular for DUPs and multi-allelic CNVs. Testing for this has been cleaned up and augmented with further cases to validate this functionality.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7541:138,update,updates,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7541,1,['update'],['updates']
Deployability,"Implements two new tools and updates some methods for a revamp of the `CombineBatches` cross-batch integration module in [gatk-sv](https://github.com/broadinstitute/gatk-sv). - `SVStratify` - tool for splitting out a VCF by variant class. Users pass in a configuration table (see tool documentation for an example) specifying one or more stratification groups classified by SVTYPE, SVLEN range, and reference context(s). The latter are specified as a set of interval lists using `--context-name` and `--context-intervals` arguments. All variants are matched with their respective group which is annotated in the `STRAT` INFO field. Optionally, the output can be split into multiple VCFs by group, which is a very useful functionality that currently can't be done efficiently with common commands/toolkits.; - `GroupedSVCluster` - a hybrid tool combining functionality from `SVStratify` with `SVCluster` to perform intra-stratum clustering. This tool is critical for fine-tuned clustering of specific variants types within certain reference contexts. For example, small variants in simple repeats tend to have lower breakpoint accuracy and are typically ""reclustered"" during call set refinement with looser clustering criteria.; - `SVStratificationEngine` - new class for performing stratification.; - Updates to breakpoint refinement in `CanonicalSVCollapser` that should improve breakpoint accuracy, particularly in larger call sets. Raw evidence support and variant quality are now considered when choosing a representative breakpoint for a group of clustered SVs.; - Added `FlagFieldLogic` type for customizing how `BOTHSIDE_PASS` and `HIGH_SR_BACKGROUND` INFO flags are collapsed during clustering.; - `RD_CN` is now used as a backup if `CN` is not available when determining carrier status for sample overlap.; - Removed no-sort option in favor of spooled sorting.; - Bug fix: support for empty EVIDENCE info fields; - Bug fix: in one of the JointGermlineCnvDefragmenter tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8990:29,update,updates,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8990,4,"['Update', 'configurat', 'integrat', 'update']","['Updates', 'configuration', 'integration', 'updates']"
Deployability,Improve ChimericAlignment in SV pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3746:32,pipeline,pipeline,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3746,1,['pipeline'],['pipeline']
Deployability,"In #2858 I give each `LocatableCollection` a method to create an `OverlapDetector` when necessary, which does the trick. The new pipeline has no dependence on either `ReadCountCollection` or `TargetCollection`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2859#issuecomment-335622099:129,pipeline,pipeline,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2859#issuecomment-335622099,1,['pipeline'],['pipeline']
Deployability,"In GATK Office hours we found a change that contributed to this error message. The issue may be a bug or an issue with the data that is showing up with the more strict filters in the latest version. This request was created from a contribution made by Igor Islanov on July 06, 2020 12:11 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360071204731-FilterVariantTranches-brakes-on-new-version-of-Gatk](https://gatk.broadinstitute.org/hc/en-us/community/posts/360071204731-FilterVariantTranches-brakes-on-new-version-of-Gatk). \--. Good day,. While updating gatk from 4.1.4.0 to 4.1.8.0 and after running pipeline it brakes on FilterVariantTranches step with error:. htsjdk.tribble.TribbleException: The provided reference alleles do not appear to represent the same position, C\* vs. T\*. The command line  is  ; ; gatk FilterVariantTranches -I ${R1%%\_\*}-recal.bam -V ${R1%%\_\*}-annotated.vcf -R /mnt/d/GenLab/WES/reference/hg19.fasta --create-output-variant-index true --resource /mnt/d/GenLab/WES/db/00-All.vcf.gz --resource /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz --resource /mnt/d/GenLab/WES/reference/1000G\_phase1.indels.hg19.sites.vcf --resource /mnt/d/GenLab/WES/reference/Mills\_and\_1000G\_gold\_standard.indels.hg19.sites.vcf --snp-tranche 99.9 --snp-tranche 99.95 --indel-tranche 99.0 --indel-tranche 99.4 -O ${R1%%\_\*}-filtered.vcf --tmp-dir /mnt/d/GenLab/WES/output/tmp --java-options ""-Xmx24G"". On 4.1.4.0 no problems whatsoever, on 4.1.8.0 not working at all. Double-confirmed by 2 seperate conda envs. The reference file is unchanged during whole running processes, obviously. Full error log: ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx24G -jar /mnt/d/GenLab/WES/software/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar FilterVariantTranches -I D1394-recal.bam -V D1394-annotated.vcf -R /mnt/d/GenLab/WES/refe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6701:625,pipeline,pipeline,625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701,1,['pipeline'],['pipeline']
Deployability,"In GATK3, when merging variants, the IDs of all the source VCFs were retained. This code path seems like it intended that, since the variantSources set is generated, but it doesnt get used for anything. This PR will use that set to set the source of the resulting merged VC. Note: i dont think I can kick off the test suite. It is possible this change would result in tests breaking, and those would need updates.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8750:405,update,updates,405,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8750,1,['update'],['updates']
Deployability,"In PathSeqPipelineSpark, the reads are repartitioned to ~5k per partition (by default) just prior to the pathogen BWA alignment step (to ensure an even distribution of work). Currently, some samples with a lot of non-host reads cause 10,000's of sharded BAMs to be written at the end of the pipeline. This PR reduces the number of partitions in the read RDD just before writing to disk in the PathSeqPipelineSpark tool. It exposes a command-line option for the number of reads per partition, with a default value that results in a much more reasonable number of sharded BAMs in even the worst cases.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3545:291,pipeline,pipeline,291,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3545,1,['pipeline'],['pipeline']
Deployability,"In addition to migrating the remaining tool input and output args, there are few miscellaneous packages, tools and utilities that need additional work:; - [x] Rename `GATKPathSpecifier` to `GATKPath`; - [ ] Add `GATKPath` methods for isDirectory, isReadOnly, resolve sibling, resolve child; - [ ] Fix GenomicsDB URL handling/utils (move isGenomicsDB to GATKPathSpecifier); - [ ] GATKSparkTool still uses `String` in many method signatures; - [ ] Update remaining IOUtils methods; - [ ] Update remaining BucketUtils methods (i.e., remove remaining BucketUtils.isHadoopURL overloads(File, Path, String), etc.); - [ ] Update RevertSAMSpark String/File assumptions and intervconversions; - [ ] Add ReferenceFileSource(`GATKPath`) constructor, remove remaining CachingIndexedFastaSequenceFile/overloads; - [ ] Update tools in the pathseq package (PathSeqBwaSpark, PathSeqScoreSpark) that do directory manipulation. [Edit] Somewhat tangentially, PathSeqBwaSpark currently rejects read inputs specified through `--inputs` and uses separate args to allow the user to identify inputs as paired or unpaired. Once this is using `GATKPathSpecifier` this could be changed to use ""--inputs"" annotated with tags instead. Might be a problem for WDL gen though (which doesn't support tags).; - [ ] Test utilities (createTempFile/Dir, etc. that return GATKPath); - [ ] Add a `toHadoopPath` method to `GATKPath` that returns a `org.apache.hadoop.fs.Path`.; - [ ] Change tools that generate multiple output files using a stem (SplitReads, etc) to use the `resolve` methods listed above once they're available.; - [ ] All usages of `PrintStream` should be replaced with `OutputStreamWriter` (code that requires printf-style formatting can use `write` with `String.format` instead of the `printf` methods). `PrintStream` doesn't propagate IOExceptions and instead requires calls to `checkError`, but almost all usages of `PrintStream` don't call it.; - [ ] Update `org.broadinstitute.hellbender.utils.report` (`GATKReport` ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6610:446,Update,Update,446,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6610,4,['Update'],['Update']
Deployability,"In an effort to make the Reblocking pipeline more user friendly we'd like to always have the option to remove the PRI annotation (which is incorrectly added by certain versions of dragen) from the GVCF turned on, even when PRI is not present in the input. There was an edge case that threw an exception when there were no FORMAT annotations, so this PR fixes that issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8870:36,pipeline,pipeline,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8870,1,['pipeline'],['pipeline']
Deployability,"In defense of the QC check, this is something that's in the Talkowski lab pipeline and it can also help prevent ridiculous runtimes and file sizes when combining segments files in the joint pipeline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7150#issuecomment-811117509:74,pipeline,pipeline,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7150#issuecomment-811117509,2,['pipeline'],['pipeline']
Deployability,"In doing some performance evaluation work for some other HaplotypeCaller work I have noticed that there is apparently a performance regression on the order of perhaps 10-20% of runtime. Running locally I find that running over the same section of a WGS chromosome 15 on the current master 78a9ecd3123fdb77acf3dd7a73b0c12bf4602a1c vs the release 4.1.5.0 i get the following results: . Master: ; real	12m19.765s; user	13m49.276s; sys	0m8.571s; 4.1.5.0: ; real	9m50.558s; user	11m11.924s; sys	0m10.193s. Doing some very cursory digging it would appear that the culprit is in the HMM adjacent code being slowed down. (Note the relative runtime of HMM vs SW) ; Master: ; <img width=""822"" alt=""Screen Shot 2020-04-23 at 1 28 52 PM"" src=""https://user-images.githubusercontent.com/16102845/80130392-80115780-8566-11ea-8f2b-a6978ac71d39.png"">. 4.1.5.0: ; <img width=""850"" alt=""Screen Shot 2020-04-23 at 1 28 33 PM"" src=""https://user-images.githubusercontent.com/16102845/80130396-80115780-8566-11ea-9a1e-1e923bef47a5.png"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6567:337,release,release,337,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6567,1,['release'],['release']
Deployability,"In fact, setting the deploy-mode works with manual jobs as we get logs in our Hadoop monitor ( the tool to monitor the jobs on the spark cluster ) and directly on our console if deploy-mode is not set / set to client. Both `--deploy-mode` and `--conf 'spark.submit.deployMode=cluster'`. But with GATK, logs appear directly on my console and not in the Hadoop monitor even if we set with `--conf 'spark.submit.deployMode=cluster`. The other methods `--deploy-mode` and `-- --deploy-mode` having the said problems.; About the `-- --deploy-mode` and the JNI linkage error, I'm currently checking this.; All our Spark nodes have access to the mapr libraries from `/opt/mapr/...`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350676916:21,deploy,deploy-mode,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350676916,8,['deploy'],"['deploy-mode', 'deployMode']"
Deployability,"In good news, the spark mailing list announced that spark master builds and runs all tests on 11 now. So it looks like support for java 11 coming in spark 3.0. When that is is going to be release isn't clear though. We should start moving to support java 11 in advance of that so we're ready when it releases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6053#issuecomment-525337068:188,release,release,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6053#issuecomment-525337068,4,['release'],"['release', 'releases']"
Deployability,"In helping @bhanugandham figure out why a particular site was failing it became apparent that merging dangling head code was failing to recover deletions in the dangling head. Furthermore there is some code in the dangling end recovery code that asserts a certain high standard of matching (usually 1 but sometimes dangling branch length/kmersize) `getMaxMismatches(final int lengthOfDanglingBranch)`. Both of these facts seem likely to cause dangling heads to be dropped despite their being still potentially informative, particularly the indel code. . I have added the ability for the index recovery code to account for the cigar string when merging dangling ends. Addtionally rather than counting mismatches to reject the branch it simply requires a minimum matching end (which can be changed, I suspect this is where the lionshare of the differences come from). Unfortunately changing the tests is non-trivial (as this happened to change the integration test results for HaplotypeCaller at a few sites) so I wanted to get this branch up to solicit advice a to whether it is worth pursuing this fix. @davidbenjamin @ldgauthier @droazen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6113:946,integrat,integration,946,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6113,1,['integrat'],['integration']
Deployability,"In light of the discovery of the (relatively minor) numerical differences caused by changes to non-CNV code outlined in #7649, and because we are still awaiting coverage from pipeline-level/CARROT testing, I decided to go ahead and add these exact-match tests. This essentially freezes current ModelSegments behavior, which has been exactly stable since https://github.com/broadinstitute/gatk/pull/5814; that is, from sometime between 4.1.0.0/4.1.1.0 almost 3 years ago up to 4.2.4.1 today. Note that the original test files were generated from the test BAMs (e.g., src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam), since these BAMs have been used in the past to consistently generate test files for other tools in the ModelSegments and GermlineCNVCaller pipelines. However, these original test files contained insufficient data to activate the changes found in #7649, even had exact-match tests been present. I thus took some old HCC1143T 100% WES data that I had and snippeted it to chr20. I've confirmed that the added tests with these files would've picked up the regression of log10factorial seen in #7649 for all relevant modes (i.e., all those that take in the allele counts as input, since that regression only affected allele-fraction MCMC sampling). Tests take maybe an additional minute to run and there was about ~12MB of additional large resources checked in, but I didn't try too hard to bring either down. I also added some early-fail parameter validation to check that the minimum total allele count in the case sample is zero in matched-normal mode. There are actually some open questions in my mind as to what the best behavior should be here, but given some of the discussion in #6499 and possible plans for using joint segmentation to do filtering of germline events, I think it's best to enforce that all het sites coming out of the genotyping step are the same across all samples. Recall that we added this parameter in #55",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7652:175,pipeline,pipeline-level,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7652,2,['pipeline'],"['pipeline-level', 'pipelines']"
Deployability,"In light of the newly updated MarkDuplicatesSpark which is finally reaching the point where we trust it, we have evaluated that the work of maintaining both this tool and MarkDuplicatesSpark was too great considering how little code they could directly reuse relative to eachother. . Resolves #4896 #3705",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5166:22,update,updated,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5166,1,['update'],['updated']
Deployability,In light of the recent #7357 and #7358 it has become clear that we are blind changes that cause the logging outputs for GATK to become unusable because we are spitting endless warnings to stdout. I think we should change our integration tests to capture the log output for each of our tests and assert that none of them balloon beyond some reasonable threshold that would capture these problems (perhaps a megabyte but it would take a little bit of sleuthing to be sure). . I would think the best place would be to add a capture into `CommandLineProgramTest.runCommandLine()` that instead of using the current behavior `injectDefaultVerbosity()` we instead leave the logging output as the default and capture it somewhere explicit where we can make assertions about the size of the outputs. Possibly we could create a dummy logging level that just saves and counts the outputs so we can make assertions about the logs. Ideally this should apply to every tool simultaneously since it would be too patchwork to simply add logging output tests for enough of the tools to protect us manually.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7368:225,integrat,integration,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7368,2,"['integrat', 'patch']","['integration', 'patchwork']"
Deployability,"In looking at his further, the container header contains a stream offset, and each slice header also contains a global record counter. Both of these need to be updated. Its not clear if its possible to repair these without re-encoding the entire container stream, but if so that should probably be done in a method exposed by htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2201#issuecomment-324756574:160,update,updated,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2201#issuecomment-324756574,2,['update'],['updated']
Deployability,"In my pipeline, when I called somatic variants using Mutect2, I would mark variants using FilterMutectCalls immediately. I think that FilterMutectCalls should be merged into Mutect2. What's more, I ran Mutect2 by chromosome parallelly by myself, and finally I would merge variants on different chrs into one VCF file-That means that saving .stat file of final result is impossible!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6102#issuecomment-525348017:6,pipeline,pipeline,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6102#issuecomment-525348017,1,['pipeline'],['pipeline']
Deployability,"In order for the variant calling pipeline to be able to scale to process the 68K genomes in the next version of gnomAD and beyond, we need to limit the amount of genotype data we localize. For the filtering portion of the pipeline we could greatly improve performance using a ""sites-only"" query from GenomicsDB. The result could be in BCF format (as I believe it is now) and should include the first 8 fields of the VCF line (CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO) but should not return format-level/genotype data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3688:33,pipeline,pipeline,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3688,2,['pipeline'],['pipeline']
Deployability,"In order of priority:. 1) The ability to query and/or stream intervals for locatable collections might reduce the overhead of file localization in the germline workflows---even though we only run GermlineCNVCaller on a subset of intervals in any particular shard, we localize the entire read-count file. This could be enabled in the parent class to benefit all locatable files, but since it will probably require indexing, we should use only when necessary.; 2) Memory requirements for some tools could be reduced by avoiding intermediate creation of an internally held list, streaming it directly instead.; 3) NIO streaming of entire files to/from buckets could be easily added to the relevant CSV/HDF5 read/write classes. Apart from the first issue, I don't think this really adds much, since the largest files are only ~1GB (and most seg files are much smaller) and are typically cheap to localize for single samples. See also #3976, #4004, #4717, and #5715 for context. I think we should first demonstrate if the first issue is really the dominating cost in the germline pipeline. If not, we should first focus on optimizing inference. The other issues are much lower priority.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5716:1075,pipeline,pipeline,1075,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716,1,['pipeline'],['pipeline']
Deployability,"In order to get it running though you will need to install the following things on each machine using apt-get: gawk, sysstat, and perf-tools-unstable. Additionally as root, you will have to set the /proc/sys/kernel/perf_event_paranoid variable from 1 to 0. For these tasks it might be possible to automate these steps by updating the system image that is used to setup dataproc clusters. In order to actually run and install PAT, you will need to download it from [here](https://github.com/intel-hadoop/PAT/tree/master/PAT) and add all the machines and ssh ports (including the master) in your cluster to the ""ALL_NODES"" setting in the config.template -> config file. You will also have to setup an SSH key to root on the cluster, which can be done with the command `gcloud compute ssh` and set the ""SSH_KEY"" variable in the config file to point to the google_compute_engine file in roots .ssh directory (public keys should have automatically been distributed to the other nodes). . At this point you need simply input the command line command you wish to run into the ""CMD_PATH"" variable and run ./pat run. I recommend running a spark-submit job using yarn-client as master. NOTE: the output will be a directory containing an excel spreadsheet and a bunch of data for each cluster. You will need to open the spreadsheet on a windows copy of excel and use ""control+q"" to run the macros that load the data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1986#issuecomment-234947495:51,install,install,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1986#issuecomment-234947495,2,['install'],['install']
Deployability,"In our Mutect2 workflow, we run a pair of Normal/Tumor through `CalculateContamination` step, the output of which is used in `FilterMutectCalls`. Since upgrading to `4.1.0.0`, `CalculateContamination` is breaking in cases where there're mismatched of N/T samples. . For e.g., `4.0.11.0` generates the following output:; ```; level contamination error; whole_bam 0.5013841326835697 0.0055644124674135865; ```; And `4.1.0.0` gives the following:; ```; sample contamination error; Run06_Pair07_Tumor 1.0 0.03452380752462225; ```. As a result of the above output files, the next step in our pipeline `FilterMutectCall` is failing (issue related to https://github.com/broadinstitute/gatk/issues/5821)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5880:587,pipeline,pipeline,587,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5880,1,['pipeline'],['pipeline']
Deployability,"In particular add output GATKTool.getDefaultToolVCFHeaderLines to the VCF header, and rewrite the integration test for GenerateVCFFromPosteriors so that it validates the equivalence of variant context records, instead of file equivalency",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4267:98,integrat,integration,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4267,1,['integrat'],['integration']
Deployability,"In particular, we are a little lax on sequence-dictionary validation in the CNV pipelines. However, it might be that this is a necessary evil---it seems sequence dictionaries are somewhat inconsistent even in datasets such as TCGA.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3864:80,pipeline,pipelines,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3864,1,['pipeline'],['pipelines']
Deployability,In releasing bulk ingest I noticed a few places we could add some clarification to the workspace description. This has already been updated in the workspace and can go out in github in the next release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8509:132,update,updated,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8509,2,"['release', 'update']","['release', 'updated']"
Deployability,"In running and re-running GvsPrepareCallset.wdl, one past run did not use compressed references, so that is always used with call caching is turned on (which it is by default), even though the dataset has reingested compressed references since then. This is the exact scenario that GetBQTableLastModifiedDatetime was created for — database-based tasks that we want to be able to call cache accurately. Integration run here: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/ea2ecb01-f35f-441a-ba08-1e7938da2ebe (single failure is for ExtractFilterTask.GvsCreateFilterSet.BigQuery Query Scanned ""The relative difference between these is 0.0507051, which is greater than the allowed tolerance (0.05)"")",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8667:402,Integrat,Integration,402,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8667,1,['Integrat'],['Integration']
Deployability,"In the ""Related Annotations"" section of the annotations tool docs, the links were broken redirecting to the GATK homepage. We decided to remove these links since there is not a good way to link to the mentioned tool without the link becoming outdated with new releases.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7307:260,release,releases,260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7307,1,['release'],['releases']
Deployability,In the (proposed) pipeline it was run separately with VariantAnnotator. It could probably be rolled into CalculateGenotypePosteriors. Admittedly even four years later we still don't use it in production.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4987#issuecomment-403562512:18,pipeline,pipeline,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4987#issuecomment-403562512,1,['pipeline'],['pipeline']
Deployability,"In the GATK4 website, it says:; ""Running a Spark tool on a cluster requires Spark to have been installed from http://spark.apache.org/, since gatk-launch invokes the spark-submit tool behind-the-scenes."". when I use spark-submit ,it may invoke the spark version 1.6.0, so I usually use spark2-submit to invoke the spark 2.2.0, and with the GATK4 command， how can I invoke the spark2.2.0 ？. @tomwhite",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336330485:95,install,installed,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336330485,1,['install'],['installed']
Deployability,"In the SV pipeline, for ~100 samples in case mode the cost breakdown was:. memory: $1.04; disk: $1.50; cpu: $4.59. It seems that we are over-provisioning for disk: amount of disk size used was < 5 GB (only ~$0.14 worth of disk) but the default is 150 gb. Therefore it doesn't seem that we would save much by streaming, but we should lower the default disk size in the WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-551235864:10,pipeline,pipeline,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-551235864,1,['pipeline'],['pipeline']
Deployability,"In the WGS SV pipeline, for deletions and duplications that the pipeline believes to be biallelic we do the following:. - ALT: `<DEL>` or `<DUP>`; - SVTYPE: `DEL` or `DUP`; - GT: `0/0` or `0/1` or `1/1`. We currently report depth based copy number and quality for these variants in custom format fields `RD_CN` and `RD_GQ` if they are available; we could possibly move those values to the standard `CN` and `CNQ`, but there is some complexity in how to handle events detected by paired end and split reads without good read depth support; ie those under 1kb or so depending on our depth binning size and the coverage. Our depth genotyping module makes estimates of copy number for these sites but sometimes these can be very inaccurate so at the moment we prefer not to report total copy number in those fields. Probably what we _should_ do is fill in CN with 0, 1, or 2 based on the genotype we emitted and set CNQ to the value we computed for GQ. For multiallelic CNVs (i.e. sites where our model is not sure that the variant is bi-allelic) we write:. - ALT: `<CNV>`; - SVTYPE: `CNV`; - GT and GQ: `.`; - CN and CNQ: estimate of total (diploid/unphased) copy number and quality of the depth evidence. I think there are some tradeoffs in completely characterizing the evidence for and quality of each call and enabling easy searching across the whole VCF without having to parse and understand the entire record. Older versions of our pipeline used to put the diploid copy number of the event into the GT field, I think similarly to what's being described above. This is incorrect VCF -- GT values should be indices into the allele list for the variant, and should be a list of length equal to the ploidy. . My view is that if you can confidently infer the alleles present at the site in the sample set you should use a GT value of the form `0/1`, and if you don't know or aren't interested in trying to infer them you should use CN for total copy number and CNQ for the quality. CNF is also availabl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6167#issuecomment-622053171:14,pipeline,pipeline,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6167#issuecomment-622053171,2,['pipeline'],['pipeline']
Deployability,"In the news file of a structural variant software I use, I read. >Added FIX_SA and FIX_MISSING_HARD_CLIP; >FIX_SA: rewrites split read SA tags; >corrects GATK indel realignment SA tag data inconsistency; >FIX_MISSING_HARD_CLIP: infers missing hard clipping if split read records have different lengths; >corrects for GATK indel realignment stripping hard clipping when realigning. Could such issues perhaps be resolved in an update to GATK?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6459:425,update,update,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6459,1,['update'],['update']
Deployability,"In the process of unifying CalculateTargetCoverage / SparkGenomeReadCounts for the rewrite of the CNV pipeline, we decided to experiment with switching over to fragment-based counts due to a request from CGA. For each fragment, CollectFragmentCounts adds a count to *the bin that overlaps with the fragment center*. We filter to properly-paired, first-of-pair reads in order to have well formed fragments and avoid double counting. We also filter out duplicates. In contrast, CalculateTargetCoverage added a count to *all bins that overlapped with a read* and SparkGenomeReadCounts added a count to *the bin that contained the read start*. These tools kept duplicates. However, none of these collection strategies have been rigorously evaluated. Using a small set of WGS SV tandem-duplication calls from @mwalker174 as a truth set, I did some experimenting with changing the count-collection strategy. (We initially thought we were missing some of these simply due to over-denoising/filtering by the PoN, but as we'll see below, the count-collection strategy plays a non-trivial role.). Subsetting to chr3, I built a small PoN of 12 normals (including the case normal) at 100bp and denoised using bin medians only (i.e., `--number-of-eigensamples 0`) to avoid denoising away common events. In chr3, the case sample had three events:. ````; chr3	8559423		8560126; chr3	64547471	64549936; chr3	90414457	90415989; ````. I tried the following, running `ModelSegments` using fairly sensitive parameters (`--number-of-changepoints-penalty-factor 0.1 --maximum-number-of-segments-per-chromosome 10000 --window-size 16 --window-size 32 --maximum-number-of-smoothing-iterations 0` in copy-ratio-only mode:. 1) CollectFragmentCounts. This only recovered event 2.; 2) CollectReadCounts - same as CollectFragmentCounts, but removing the properly-paired and first-of-pair filters and adding a count for each read to the bin containing its start. This recovered all 3 events.; 3) CollectFragmentOverlaps - same filt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4519:102,pipeline,pipeline,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519,1,['pipeline'],['pipeline']
Deployability,"In this branch are a number of improvements and changes that form the baseline for the current ongoing evaluation of the DRAGEN/GATK pipeline. This represents the joint work of both msyelf and @vruano. The major improvements in this branch are as follows:; - `EstimateDragstrModelParameters` tool for estimating the per-sample/per-STRType errors for use in the HMM gap open/gap close penalties as well as the necessary changes to the PairHMM loading code in order to adjust the model appropriately.; - Support for using the DragstrParams and flat SNP priors to compute genotype posteriors and the support for using them in the selection of genotypes as well as for computing the QUAL score. ; - Base Quality Dropout (BQD) model which penalizes variants with low average base quality scores among genotyped reads and reads that were otherwise excluded from the genotyper. A number of additional arguments to expose internal behaviors in the readThreadingAssembler and HaplotypeCaller have been made in order to support threading more lowBQ reads through to the genotyper. ; - Foreign Read Detection (FRD) model which uses an adjusted mapping quality score as well as read strandedness information to penalize reads that are likely to have originated from somewhere else on the genome. A number of additional arguments and behaviors have been exposed in order to preserve lower mapping quality reads in the HaplotypeCaller in service.; - Dynamic Read Disqualification, allows for longer/lower base quality reads to be less likely to be rejected by eliminating the hard cap on quality scores and further adjusting the limit based on the average base quality for bases in the read. . Design decisions that I would direct the reviewers attention to as they correspond to potentially dangerous/controversial changes:; - Because FRD/BQD require low quality ends to be included in the models for genotyping, I have added the option to softclipLowQualityEnds (as opposed to their current treatment which involv",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6634:133,pipeline,pipeline,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6634,1,['pipeline'],['pipeline']
Deployability,"In this case, the FDR threshold is not honored. The explanation of this is complex, but essentially has to do with the Benjamini-Hochberg procedure not playing well with suppression factor when extended to more than one artifact mode. The definition of ``FilterByOrientationBias`` will have to be changes from ""guaranteeing less than 1% FDR over all mutations"" to ""guaranteeing less than 1% FDR in each specified artifact mode"". This could make the filter more aggressive, so we may have to adjust the FDR threshold. - [x] code fix; - [x] doc updates",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3344:543,update,updates,543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3344,1,['update'],['updates']
Deployability,"InbreedingCoeff.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9JbmJyZWVkaW5nQ29lZmYuamF2YQ==) | `82.759% <100%> (ø)` | `11 <1> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/utils/GenotypeCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vdHlwZUNvdW50cy5qYXZh) | `100% <100%> (ø)` | `4 <1> (ø)` | :arrow_down: |; | [.../hellbender/tools/walkers/annotator/ExcessHet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9FeGNlc3NIZXQuamF2YQ==) | `98.592% <100%> (ø)` | `22 <2> (ø)` | :arrow_down: |; | [...broadinstitute/hellbender/utils/GenotypeUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vdHlwZVV0aWxzLmphdmE=) | `94.872% <100%> (+2.767%)` | `12 <0> (+3)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=footer). Last update [c8ede6e...c63c08b](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2546#issuecomment-290509295:2769,update,update,2769,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2546#issuecomment-290509295,2,['update'],['update']
Deployability,"Include codec registry, versioning/upgrade chain framework.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5338:35,upgrade,upgrade,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5338,1,['upgrade'],['upgrade']
Deployability,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660:157,release,release,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660,8,"['Update', 'release', 'update']","['Update', 'Updated', 'release', 'updates']"
Deployability,"Includes:. * Configuration for packages to search read filters; * Configuration for packages to search annotations. In addition, it changes the behavior of `VariantAnnotatorEngine` to use the annotation packages from the configuration, and mimic what the plugin is doing. This closes https://github.com/broadinstitute/gatk/issues/2155",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4611:13,Configurat,Configuration,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4611,3,"['Configurat', 'configurat']","['Configuration', 'configuration']"
Deployability,IndexFeatureFile needs integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/235:23,integrat,integration,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/235,1,['integrat'],['integration']
Deployability,Initial GKL integration,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1935:12,integrat,integration,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1935,1,['integrat'],['integration']
Deployability,Initial implementation of Insertion/Deletion caller in SV pipeline.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2320:58,pipeline,pipeline,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2320,1,['pipeline'],['pipeline']
Deployability,"Initial port of native PairHMM AVX code from GATK3. (@akiezun #1492). Includes gradle code to build the shared library and package it in the GATK jar file. . Added a new unit test VectorPairHMMUnitTest, which can be integrated into PairHMMUnitTest later.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1504:216,integrat,integrated,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1504,1,['integrat'],['integrated']
Deployability,Initial updates to bulk ingest docs with 25k run,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8475:8,update,updates,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8475,1,['update'],['updates']
Deployability,Install GATK Python packages.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3964:0,Install,Install,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3964,1,['Install'],['Install']
Deployability,Install python-is-python3 during the GATK docker build,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8497:0,Install,Install,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8497,1,['Install'],['Install']
Deployability,Install the python-is-python3 package in our docker build,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8499:0,Install,Install,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8499,1,['Install'],['Install']
Deployability,"Install, run, and evaluate other SV methods",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1102:0,Install,Install,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1102,1,['Install'],['Install']
Deployability,"Installed cyvcf2, read output vcf and truth vcf, parsed output vcf variants into a list of filters using set(variant.FILTER.split("";"")). . @davidbenjamin I noticed that while parsing the truth vcf and extracting variant.FILTER it returns `None` in each line, on looking into the [cyvcf2 documentation](https://brentp.github.io/cyvcf2/docstrings.html) it mentions that `a value of PASS or ‘.’ in the VCF will give None for this function`. However in our email discussion you mentioned that in the output vcf (from Mutect2 pipeline) if the variant is unfiltered then its value is None. ; Does the None value in output & truth vcf mean the same in both cases?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7669#issuecomment-1039538814:0,Install,Installed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7669#issuecomment-1039538814,2,"['Install', 'pipeline']","['Installed', 'pipeline']"
Deployability,Integrate BetaFeature annotation with help/doc.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2791:0,Integrat,Integrate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2791,1,['Integrat'],['Integrate']
Deployability,Integrate CountingVariantFilter.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4954:0,Integrat,Integrate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4954,1,['Integrat'],['Integrate']
Deployability,Integrate GenomicsDB VariantContextWriter interface,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2088:0,Integrat,Integrate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2088,1,['Integrat'],['Integrate']
Deployability,Integrate GenomicsDB load VCFs java interface,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2087:0,Integrat,Integrate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2087,1,['Integrat'],['Integrate']
Deployability,Integrate Picard and GATK report formats,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/251:0,Integrat,Integrate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/251,1,['Integrat'],['Integrate']
Deployability,Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/a795190c-dcc2-40a7-bfcc-84fa6a4ea0dc); Two failed on ValidateVDS (or rather something upstream). I *don't* think this is an effect of this PR.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8807:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8807,1,['Integrat'],['Integration']
Deployability,"Integration WDL [VS-618] (#8042); - Rework Hail script generation [VS-616] (#8034); - Alpine based Variant Store Docker image [VS-648] (#8044); - update warp version (#7906); - Fail Avro extract and callset stats on bad filter name [VS-655] (#8046); - Vs 629 failure to retrieve job information during ingest (#8047); - Restore accidentally removed bcftools [VS-661] (#8051); - Allowing our pipeline to function with a sample size of one (#8055); - Vs 665 re create vcf for cd 68 po 52339 with ad padding fixed (#8057); - VS-665 and VS-620 updating code to use latest docker images containing Rori's AD calculation changes in extract (#8061); - updating the beta workflow to use the latest jar, representing the version of GATK George tested against the workflow (#8062); - VS-637 Address a couple of issues in SampleLoadStatus handling in GVSImportGenomes. (#8052); - Revert Alpinizing of apt dependent task [VS-688] (#8065); - Fix missing vat schema JSONs [VS-699] (#8072); - Fix integration expectations for fixed AD [VS-689] (#8066); - VS-698 Remove unnecessary columns from Call set statistics (#8073); - Fix Dockerfile nits that break 20.10.21 (#8078); - Nirvana 3.18.1 Docker images support [VS-661] (#8082); - Add option to not prepare __REF_DATA or __SAMPLES tables to Prepare [VS-697] (#8079); - ""build-base"" Docker image for faster variantstore image builds [VS-712] (#8085); - GVS / Hail VDS integration test [VS-639] (#8086); - Remove AI/AN from VDS docs [VS-726] (#8096); - Add flag for cost_observability table writing to support sub-cohort use case [VS-521] (#8093); - Document STS delivery process for VDS [VS-727] (#8101); - delete obsolete callset_QC directory and its contents [VS-318] (#8108); - doc link typo and add check for control samples in AVRO export (#8110); - Add defaults for scatter_count in GvsExtractCohortFromSampleNames [VS-496] (#8109); - Escape table names properly in ValidateVat WDL (#8116); - Vs 741 fix indefinite freeze in split intervals task when using ex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:29975,integrat,integration,29975,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['integrat'],['integration']
Deployability,Integration run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/1b430f2b-4517-4d00-b8da-a8399da124b0),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8847#issuecomment-2140875298:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8847#issuecomment-2140875298,1,['Integrat'],['Integration']
Deployability,"Integration run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/8eadce08-04fa-447f-bbbc-934f52e79030), still working on testing this by hand",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8923:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8923,1,['Integrat'],['Integration']
Deployability,Integration run [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/5bcd1072-f9c4-4885-805b-a29091e27791).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8066:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8066,1,['Integrat'],['Integration']
Deployability,Integration run [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/76c46310-3c0d-43a8-9fce-072ef7750651). As written the task requires `apt-get`. Converting this to Alpine would be non-trivial and not really worthwhile as it might even take longer to build all the extra things into the `alpine` image that we simply download with the `slim` image.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8065:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8065,1,['Integrat'],['Integration']
Deployability,"Integration run [in progress](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/544fb86b-ffb7-447c-b380-fdefce10be99). Does away with the `STARTED` and `FINISHED` sample load statuses to more explicitly record what work has actually been done for a sample: `REFERENCES_LOADED`, `VARIANTS_LOADED` or `HEADERS_LOADED`. Legacy `FINISHED` and `STARTED` states are recognized and handled appropriately (short circuiting data load and being ignored, respectively).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8674:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8674,1,['Integrat'],['Integration']
Deployability,Integration run going [here](https://app.terra.bio/#workspaces/gvs-dev/mlc%20GVS%20Quickstart%20v3/job_history/4adcc972-86be-411e-bc95-a27c8a14de3b),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8303:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8303,1,['Integrat'],['Integration']
Deployability,Integration run here (failed because of known issue cost/output checks): https://job-manager.dsde-prod.broadinstitute.org/jobs/e904302b-e338-4bc7-bf7d-3ef1bfcd3fd9,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8022:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8022,1,['Integrat'],['Integration']
Deployability,"Integration run here: https://app.terra.bio/#workspaces/gvs-dev/mlc%20GVS%20Quickstart%203%20samples/job_history/acb5b878-af45-443d-8139-0f0044cbcb38. The basic problem: https://news.ycombinator.com/item?id=9255830. Repro:. ```; % # make a file shaped like what was failing in ingest; % for i in $(seq 50000); do ; echo foo,${i} >> file.csv; done; % # repro the pipeline that was failing; % set -o pipefail; % cat file.csv | cut -d, -f2 | sort -r -n | head -1; 50000; % echo $?; 141; % # repeat with temp file construct; % head -1 <(cat file.csv | cut -d, -f2 | sort -r -n) ; 50000; % echo $?; 0; %; ```; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8441:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8441,2,"['Integrat', 'pipeline']","['Integration', 'pipeline']"
Deployability,Integration run in progress https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/474c06f0-1c6a-41d0-bc1f-7a22054153fe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8474:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8474,1,['Integrat'],['Integration']
Deployability,Integration run in progress with `GvsUnified` removed [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/52748da4-46e6-4ae4-97a4-f91ca6517e34),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1636213505:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1636213505,1,['Integrat'],['Integration']
Deployability,"Integration run in progress: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/b0ba98ae-a81f-4be2-bd72-c374359b644c. I actually don't expect this to pass due to VS-1141, but hopefully once this lands VS-1141 will be the *only* thing preventing integration from passing. Stowaway bug fixes:. - Hail version defaulted properly; - VDS tie out now waits for VDS creation to finish",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8586:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8586,2,"['Integrat', 'integrat']","['Integration', 'integration']"
Deployability,Integration run kicked off [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/e706347d-cae4-4138-a5a3-34692b39ae89). Previous versions completed successfully but failed cost comparison because the name of the WDL step changed and was unrecognized by the branches of the comparison code that cut slack.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8262:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8262,1,['Integrat'],['Integration']
Deployability,Integration run with [all the tests here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/d6892c6d-0d1e-415b-819b-24a30ed08f0f),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8687:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8687,1,['Integrat'],['Integration']
Deployability,"Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/4de33a53-be6f-43b2-96db-7e8a0fb398f8); Example run of GvsExtractAvroFilesForHail using an Exome data set that has PGT, PID, and PS defined is [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Exome%20Beta%20Test%20ggrant/job_history/43a87886-60be-4f60-a2d3-3f4a97ceea5b).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8536:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8536,1,['Integrat'],['Integration']
Deployability,Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/80b6ed98-3b79-40f3-b55b-524b6f63f1e1). Failed one of the four (in Hail VDS tieout) - with a weird python3 error. 99.9994% sure not related to this PR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8393#issuecomment-1613622838:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8393#issuecomment-1613622838,1,['Integrat'],['Integration']
Deployability,Integration test for CollectTargetedPcrMetrics,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/872:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/872,1,['Integrat'],['Integration']
Deployability,Integration test successful https://app.terra.bio/#workspaces/broad-firecloud-dsde/VS-415%20GVS%20Quickstart%20Default%20Extract%20Scatter/job_history/73ac71db-0488-46be-a8e8-7f00e795edec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7888:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7888,1,['Integrat'],['Integration']
Deployability,Integration testing tables are not forever [VS-1049],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8563:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8563,1,['Integrat'],['Integration']
Deployability,"Integration tests are not passing as the gold files have not been updated. Understanding what ""correct"" looks like for spanning deletions beyond just unit tests is very complex, and fraught with bad data (ie multiple overlapping reference blocks, etc). . Putting this work on the shelf until the value is worth the effort",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7945:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7945,2,"['Integrat', 'update']","['Integration', 'updated']"
Deployability,Integration tests have a million different VC/Genotype setup methods,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5709:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5709,1,['Integrat'],['Integration']
Deployability,Integration tests look okay (there's a Python one that says to skip if it's in docker):; - org.broadinstitute.hellbender.utils.python.StreamingPythonExecutorIntegrationTest#testRequirePythonEnvironment; Unit tests:; - org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest#testLikelihoodsFromHaplotypes; - org.broadinstitute.hellbender.utils.io.IOUtilsUnitTest#testUnsuccessfulCanReadFileCheck (intended to be skipped); - fixed ; No variant calling tests ignored; No python tests ignored; No R tests ignored. The PairHMM one returns:; ```; 03:44:48.410 WARN NativeLibraryLoader - Unable to load libgkl_pairhmm_fpga.so from native/libgkl_pairhmm_fpga.so (/tmp/libgkl_pairhmm_fpga7585161099923450811.so: libgkl_pairhmm_shacc.so: cannot open shared object file: No such file or directory); ```; I don't know if that's expected or not -- maybe yes because it's looking for an FPGA?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5339#issuecomment-592086345:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5339#issuecomment-592086345,1,['Integrat'],['Integration']
Deployability,Integration tests: add a way for intelligent comparison of files of different formats,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/190:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/190,1,['Integrat'],['Integration']
Deployability,IntegrationTestSpec doesn't handle CRAM output,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1562:0,Integrat,IntegrationTestSpec,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1562,1,['Integrat'],['IntegrationTestSpec']
Deployability,IntegrationTestSpec is hardwired to text files and bam files but compares them byte-by-byte. We need more digested way of comparing files to remove the brittleness of md5 while retaining the ability to notice failures.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/190:0,Integrat,IntegrationTestSpec,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/190,1,['Integrat'],['IntegrationTestSpec']
Deployability,IntegrationTestSpec should not ignore leading/trailing whitespace by default,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7560:0,Integrat,IntegrationTestSpec,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7560,1,['Integrat'],['IntegrationTestSpec']
Deployability,IntegrationTests for a walker that creates multiple outputs based on a user-supplied prefix?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5446:0,Integrat,IntegrationTests,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5446,1,['Integrat'],['IntegrationTests']
Deployability,Intel Conda environment needs a continuous integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5255:32,continuous,continuous,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5255,2,"['continuous', 'integrat']","['continuous', 'integration']"
Deployability,"Interesting! Thanks for generating these. I am already convinced by #4519 we should at least switch over to a ‘CollectReadCounts’ strategy for initial evaluations. A few comments:. -I’m guessing that the equal insert size and uniform sampling is enhancing many of these artifacts to a level that we probably don’t see in the real world. Can we take a look at some real-world examples?. -Same goes for the fact that homs will be unlikely. -Not sure about the dropouts. Might be worth running without SNPs as a confounding factor. -How flexible is SVGen? Might be worth putting together a more realistic simulated data set. Any chance @MartonKN might be able to use it to cook up some realistic tumor data?. -I don’t recall having a `CollectBaseCallCoverage` type tool in beta—which tool are you thinking of? On a related note, it seems there is some demand to port `DepthOfCoverage` from GATK3. However, I’d prefer that we roll a CNV-specific version of the tool even if it does get ported. In any case, I think along with findings from the other issue, we should issue a quick PR for `CollectReadCounts` and go ahead to change the `CollectCounts` WDL task to call it—it’s for this very reason that the task is named generically! @sooheelee note that we may have to update the tutorials, etc. at some point, but perhaps the right time will be until all evaluations are more complete. Speaking of which, this PR should not delay getting the first round of automated evaluations up and running. Again, the whole point of those is to have a reproducible baseline metric against which we can easily experiment with and adopt these sorts of changes. Although these sorts of theoretical/simulated/thought experiments are clearly useful to us, unfortunately, they may not be as compelling to some of our users as demonstrable improvement seems on real data!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375122976:1265,update,update,1265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375122976,2,['update'],['update']
Deployability,"Interesting, this is the first time that I have seen a CentOS-7 install without zlib and uuid - even the minimal installations include it. Your options are:; - Install zlib and uuid (yum -y install zlib libuuid); - Ask your admins whether these packages are installed in some other location. For example, if the zlib library is at /opt/my_install/lib64/libz.so, then you can set your environment variable LD_LIBRARY_PATH; ```; export LD_LIBRARY_PATH=/opt/my_install/lib64:/opt/my_install/lib:$LD_LIBRARY_PATH; ```; - Wait for the next GenomicsDB binary jar to show up",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357067214:64,install,install,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357067214,5,"['Install', 'install']","['Install', 'install', 'installations', 'installed']"
Deployability,"Interesting. Sorry this is causing so much trouble. From one of your above comments I wasn't clear if the solution using `--conf 'spark.submit.deployMode=cluster'` work correctly or not. . Is it possible that it's correct behavior for it to fail with the linkage error? According to the [mapr doc](https://maprdocs.mapr.com/52/DevelopmentGuide/c-loading-mapr-native-library.html) that command causes it to expect the application to load the library itself, but GATK by default doesn't have a copy of MAPR and won't load it on it's own. Have you included the mapr library somehow into the gatk jar? Or is it provided to spark some other way? I don't really know how maprfs works and how it interacts with hadoop paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350315653:143,deploy,deployMode,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350315653,2,['deploy'],['deployMode']
Deployability,"Interesting. The CRAI file itself (when you gunzip it) appears normal although I don't have an md5 from GP for the CRAI (just for the CRAM). I suppose I can't rule out a bitflip somewhere. I don't know which software GP uses to produce CRAI files and since they lack a header, I'm not sure I'll be able to find out. Having reindexed it with `samtools index` (v1.7, htslib 1.7-2), and then diffing my gunzipped crai vs the original crai, I think I see the offending line:. ```; # Original .crai:; -1	0	-2147483647	710543306	480	278484. # samtools-1.7 .crai:; -1	0	1	710543306	480	278484; ```. I'll ping our Broad GP contact to see if they can identify an issue in their pipeline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1088788251:669,pipeline,pipeline,669,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1088788251,1,['pipeline'],['pipeline']
Deployability,"Interestingly, just adding the constant to gcloud allows gatk to proceed. Well it crashed for me a bit later:. [Stage 0:==========================================> (431 + 2) / 553]17/03/30 00:30:53 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 431.0 in stage 0.0 (TID 431, jp-test-cluster-w-0.c.genomics-pipelines.internal): com.google.cloud.storage.StorageException: 503 Service Unavailable; Service Unavailable; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:186); ...; 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:571); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.Files.isRegularFile(Files.java:2229); 	at htsjdk.samtools.SamFiles.lookForIndex(SamFiles.java:72). That's the same 503 we've been protecting against in reads, now rearing its head on a readAttributes call.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2517#issuecomment-290465707:316,pipeline,pipelines,316,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2517#issuecomment-290465707,1,['pipeline'],['pipelines']
Deployability,"Intermittent ""Connection reset by peer"" during pip install on Travis.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194:51,install,install,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194,1,['install'],['install']
Deployability,"Intermittent failure at https://travis-ci.com/github/broadinstitute/gatk/jobs/297047618. ```; [TileDB::FileSystem] Error: hdfs: Cannot list contents of dir gs://hellbender-test-logs/staging/703469fc-52fe-441d-b6e0-8092a114fe2c//chr20$17960187$17981445/genomicsdb_meta_dir; hdfsBuilderConnect(forceNewInstance=0, nn=gs://hellbender-test-logs, port=0, kerbTicketCachePath=(NULL), userName=(NULL)) error:; java.io.IOException: Must supply a value for configuration setting: fs.gs.project.id; 	at com.google.cloud.hadoop.util.ConfigurationUtil.getMandatoryConfig(ConfigurationUtil.java:39); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createOptionsBuilderFromConfig(GoogleHadoopFileSystemBase.java:2185); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1832); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1013); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:976); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2812); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:100); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2849); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2831); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:389); 	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:171); 	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:168); 	at java.base/java.security.AccessController.doPrivileged(Native Method); 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1836); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:168); 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6522:448,configurat,configuration,448,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6522,3,"['Configurat', 'configurat']","['ConfigurationUtil', 'configuration']"
Deployability,"Intriguing. Thanks for the good example. To get around this it looks like we need to update NIO to allow it to be in a special ""broken"" state where the CloudStorageFileSystemProvider allows itself to be constructed even without credentials, failing later when we ask it to do anything. I think this is possible, but the change would have to be in gcloud-java-nio itself. The additional state is a bit counter-intuitive (usually allocation-is-initialization) but it seems worthwhile in this case. I'll get the ball rolling over at gcloud-java-nio.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2110#issuecomment-241813191:85,update,update,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2110#issuecomment-241813191,4,"['rolling', 'update']","['rolling', 'update']"
Deployability,"Introducing the IntervalLocusIterator which will traverse every locus in intervals, regardless of coverage. Minor changes. Removed imports. AlignmentContextLocusIterator first cut. Still needs unit tests. Putting in the walker. Still needs unit tests. Adding tests (and fixes) so that we can get AlignmentContexts. Adding tests (and fixes) so that we can get AlignmentContexts. Working tests. Beginning migration to a LocusWalker change rather than a separate walker. Merging the emit empty loci into locus walker. Still need warnings and validation of parameters. Next step is the LocusWalker testing. Simple test of the new LocusWalker when it emit empty loci. Addressing PR requests and added ShardedIntervalIterator to save RAM on big intervals. Addressing the rest of the PR comments. Rolling back to int from long. Addressing second round of PR comments. Wrapped LIBS in a factory so that we can encapsulate the retrieval of the best alignment context iterator. Spark empty loci traversal being supported. Rebasing based off of the other emit loci branch.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2731:790,Rolling,Rolling,790,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2731,1,['Rolling'],['Rolling']
Deployability,Investigate normalization in denoising method in the ModelSegments pipeline.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4150:67,pipeline,pipeline,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4150,1,['pipeline'],['pipeline']
Deployability,Is it guaranteed that one of the configurations won't include any of the MQ0 regions? Why is that?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-364663550:33,configurat,configurations,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-364663550,1,['configurat'],['configurations']
Deployability,"Is it possible to add an integration test to this? Since the change did not fail any test, it seems that the integrationtest is missing",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8442#issuecomment-1803448694:25,integrat,integration,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8442#issuecomment-1803448694,2,['integrat'],"['integration', 'integrationtest']"
Deployability,Is it possible you have only a jre installed instead of a full jdk?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-592727818:35,install,installed,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-592727818,1,['install'],['installed']
Deployability,Is there a successful integration run?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8915#issuecomment-2245307770:22,integrat,integration,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8915#issuecomment-2245307770,1,['integrat'],['integration']
Deployability,Is there a way you can use/update the [GvsQuickstartIntegration.AssertCostIsTrackedAndExpected](https://github.com/broadinstitute/gatk/blob/ah_var_store/scripts/variantstore/wdl/GvsQuickstartIntegration.wdl#L196) task to check for these additional tracked costs?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7919#issuecomment-1170602208:27,update,update,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7919#issuecomment-1170602208,1,['update'],['update']
Deployability,Is there an update on this? Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-909219829:12,update,update,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-909219829,1,['update'],['update']
Deployability,Is there any planned release date for this functionality?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2092#issuecomment-377937119:21,release,release,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2092#issuecomment-377937119,1,['release'],['release']
Deployability,Is there any update for this issue? I'm asking as AWS moved to NIO v2 late 2018 and htslib supports direct S3 access.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3708#issuecomment-628392999:13,update,update,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3708#issuecomment-628392999,1,['update'],['update']
Deployability,Is there any update of this ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5075#issuecomment-424103872:13,update,update,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5075#issuecomment-424103872,1,['update'],['update']
Deployability,Is there any update on that? Got the same issue on 4.4.0.0,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-1529112746:13,update,update,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-1529112746,1,['update'],['update']
Deployability,"Is there any update on this? From what I understand, most non-GATK variant callers (such as bcftools or platypus) could still benefit from this. Additionally, the [documentation](http://www.htslib.org/workflow/#mapping_to_variant) for htslib still references GATK's IndelRealigner. If there's no replacement forthcoming, I will open an issue of htslib to have this updated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-464410020:13,update,update,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-464410020,2,['update'],"['update', 'updated']"
Deployability,Is there still anything missing? It is not merged since quite some time. The funcotator data sources in version 1.7 are already lacking at least 2 years behind the current databases. I would like to see a possibility to create own and updated bundles merged.; Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1135553632:235,update,updated,235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1135553632,1,['update'],['updated']
Deployability,Is this waiting on a barclay proper release or should we merge with the snapshot?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-278974881:36,release,release,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-278974881,1,['release'],['release']
Deployability,Issue 2457 docker updates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2709:18,update,updates,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2709,1,['update'],['updates']
Deployability,"Issue: Integer overflow error caused Mutect2 v4.1.4.0 to generate a stats file with a negative number. Solution is to change the int data type to long. User report:. Hello, I've just adapted my pipeline to the new filtering strategies, while looking at the files I noticed that for a WGS run I obtained a stats file with a negative number:; [egrassi@occam biodiversa]>cat mutect/CRC1307LMO.vcf.gz.stats; statistic value; callable -1.538687311E9. Looking around about the meaning of the number I found https://gatkforums.broadinstitute.org/gatk/discussion/24496/regenerating-mutect2-stats-file, so I'm wondering if I should be worried by having a negative number of callable sites :/; What's more puzzling is that FilterMutectCalls after ran without any error. Before running mutect I used the usual best practices pipeline, then:; ; gatk Mutect2 -tumor CRC1307LMO -R /archive/home/egrassi/bit/task/annotations/dataset/gnomad/GRCh38.d1.vd1.fa -I align/realigned_CRC1307LMO.bam -O mutect/CRC1307LMO.vcf.gz --germline-resource /archive/home/egrassi/bit/task/annotations/dataset/gnomad/af-only-gnomad.hg38.vcf.gz --f1r2-tar-gz mutect/CRC1307LMO_f1r2.tar.gz --independent-mates 2> mutect/CRC1307LMO.vcf.gz.log; ; gatk CalculateContamination -I mutect/CRC1307LMO.pileup.table -O mutect/CRC1307LMO.contamination.table --tumor-segmentation mutect/CRC1307LMO.tum.seg 2> mutect/CRC1307LMO.contamination.table.log; ; gatk LearnReadOrientationModel -I mutect/CRC1307LMO_f1r2.tar.gz -O mutect/CRC1307LMO_read-orientation-model.tar.gz 2> mutect/CRC1307LMO_read-orientation-model.tar.gz.log; ; gatk FilterMutectCalls -V mutect/CRC1307LMO.vcf.gz -O mutect/CRC1307LMO.filtered.vcf.gz -R /archive/home/egrassi/bit/task/annotations/dataset/gnomad/GRCh38.d1.vd1.fa --stats mutect/CRC1307LMO.vcf.gz.stats --contamination-table mutect/CRC1307LMO.contamination.table --tumor-segmentation=mutect/CRC1307LMO.tum.seg --filtering-stats mutect/CRC1307LMO_filtering_stats.tsv --ob-priors mutect/CRC1307LMO_read-orientation-model.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6302:194,pipeline,pipeline,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6302,2,['pipeline'],['pipeline']
Deployability,"It *looks like* it doesn't. I ran a job and looked at the ""environment"" tab in the Spark page for the job and didn't see ""spark.local.dir"" mentioned in the list of properties or the command line. Based on [the documentation](http://spark.apache.org/docs/latest/configuration.html), the setting must thus still be at its default value of ""/tmp"". . /tmp is on the HDD, the SSD one would have to be on /mnt/1/.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2426#issuecomment-283210934:261,configurat,configuration,261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2426#issuecomment-283210934,1,['configurat'],['configuration']
Deployability,"It also fails in Mac OS X 10.11.6 x86_64. I'm trying to update my project to the latest version of GATK and this dependency throws the following error with some of my gradle tests and while running an uber-jar (using `--use_jdk_deflater false`):. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011d925644, pid=7088, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression8215566221555962564.dylib+0x1644] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid7088.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Find attached the log: [hs_err_pid7088.log.txt](https://github.com/broadinstitute/gatk/files/652421/hs_err_pid7088.log.txt). Should I open a different issue for this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2302#issuecomment-267103689:56,update,update,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2302#issuecomment-267103689,1,['update'],['update']
Deployability,It appears that the webUI has been updated to no longer show the scanned images first due to complaints. This seems to have resolved itself. Closing the ticket,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4454#issuecomment-370515447:35,update,updated,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4454#issuecomment-370515447,1,['update'],['updated']
Deployability,It didn't work because python failed to install correctly.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550380447:40,install,install,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550380447,1,['install'],['install']
Deployability,"It does look like there are some references to similar issues(see comments in https://stackoverflow.com/questions/35245401/combining-conda-environment-yml-with-pip-requirements-txt) in some stack overflow threads, and some conda tickets that may be related. Given this issue, and the unrelated but evolving requirement that we have more than a single conda yml (we need a separate one with the intel tensorflow version that supports acceleration on intel hardware), I'm going to make the following changes:. Add a single conda template and a gradle task that generates the two (nearly but not quite identical) yml files as part of the build. These will be stored in the build directory with the python package archive, so the yml file no longer has to specify a path to the zip (which we previously had to strip when we included the file in the zip/tar distribution). The zip and yml files will be copied into the tar/zip distributions as was previously done.; Add a gradle target that creates/updates the local conda dev. This is for local use by devs during iterative development. The yml files will still exist in the build directory, and can be used manually like they previously were, but from the build directory instead of in the root.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4741#issuecomment-387439532:994,update,updates,994,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4741#issuecomment-387439532,1,['update'],['updates']
Deployability,"It doesn't seem related to the version of java. I updated my version of java to; ```; javac -version; javac 1.8.0_191. java -version; java version ""1.8.0_191""; Java(TM) SE Runtime Environment (build 1.8.0_191-b12); Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode); ```. The issue remains the same, I pulled the latest commit on master and ran; ```; ./gradlew clean; ./gradlew bundle; ./gradlew test; ...; Results: FAILURE (500075 tests, 500072 successes, 2 failures, 1 skipped). 500075 tests completed, 2 failed, 1 skipped; ```; The behavior is the same, the exact two same tests fail.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451930915:50,update,updated,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451930915,1,['update'],['updated']
Deployability,"It happened again, on Friday. This was running updated code that [checks the position before calling](https://github.com/broadinstitute/gatk/blob/jp_retry_more_2/src/main/java/org/broadinstitute/hellbender/utils/nio/SeekableByteChannelPrefetcher.java#L119) - so we know that we set the position to a non-negative value before doing the read. The error says that the position was -218103808 -- this is 0xD000000 in hex, a suspiciously round number. The previous times we've seen this, we got:. value seen in error | hex | on 40MB boundary?; ------------ | ------------- | ---; -218103808 | -0xD000000 | no; -285212672 | -0x11000000 | no; -1577058304 | -0x5E000000 | no; -385875968 | -0x17000000 | no. Our prefetch buffer size is 40 MB (0x2800000) so we might think that explains the many leading zeroes (are we just on a negative number of buffer boundaries?) but the error number is not a multiple of this constant, so that's not it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2516#issuecomment-289573036:47,update,updated,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2516#issuecomment-289573036,1,['update'],['updated']
Deployability,"It has been decided to merge this branch in after the release so it can be more substantially tested. Since it is being pushed off, we should take a look at the precision issue for annotations. Would it be possible to limit the precision of the output annotations to 3 decimal points? It seems to be outputting a lot of annotations that end up being excessively long.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-356037149:54,release,release,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-356037149,1,['release'],['release']
Deployability,It is now site-by-site independent (unlike GATK3). All integration tests were ported as is (after ditching the MD5s). The algorithm was changed so that it works on a site-by-site independent basis. Some changes to the engine classes were required to allow queries over intervals in feature data sources. Fixes https://github.com/broadinstitute/hellbender/issues/38,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/614:55,integrat,integration,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/614,1,['integrat'],['integration']
Deployability,"It is what I will do if this change is not accepted, @droazen. It was just a request to keep the arguments in my toolkit equals to Picard/GATK to easier integration of pipelines with my custom tools and yours. Anyway, thanks for taking in account my proposals. I added a new commit removing the change for the short arguments. Back to you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2384#issuecomment-278591310:153,integrat,integration,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2384#issuecomment-278591310,2,"['integrat', 'pipeline']","['integration', 'pipelines']"
Deployability,"It just moved to 1.30, update once it's on maven central.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/329:23,update,update,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/329,1,['update'],['update']
Deployability,"It just occured to me that you probably meant you were running with `--sparkMaster local[4]` not, on a local cluster (vs a cluster in the cloud). In that case disregard my previous advice. Running a single process spark isn't going to scale well to 40 cores whatever you do, you'd be better off installing spark locally on your machine and running it as a single node cluster than running in the local mode. . If you want to run with master local, the biggest thing is probably to set -Xmx high enough, I'd set it as all of your memory - some overhead for the OS. Maybe try something like:; `-Xmx 140G -XX:ParallelGCThreads=6 --sparkMasterLocal[40]",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3465#issuecomment-324066954:295,install,installing,295,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3465#issuecomment-324066954,1,['install'],['installing']
Deployability,"It looks like all of our builds are failing since we cleared the cache because of R dependency issues. ```; ... Setting up r-base-core (3.1.3-1trusty) ...; Installing new version of config file /etc/bash_completion.d/R ...; Installing new version of config file /etc/R/Renviron.site ...; Installing new version of config file /etc/R/Makeconf ...; Installing new version of config file /etc/R/repositories ...; Installing new version of config file /etc/R/Rprofile.site ...; Installing new version of config file /etc/R/ldpaths ...; Replacing config file /etc/R/Renviron with new version; W: --force-yes is deprecated, use one of the options starting with --allow instead.; Installing packages into ‘/home/travis/site-library’; (as ‘lib’ is unspecified); Error: (converted from warning) dependencies ‘rlang’, ‘vctrs’ are not available; Execution halted; ```. Both libraries now require R >= 3.2.; We could either try again to nail down the R versions exactly, which is almost certainly possible but not something we've ever figured out a good way to do, or we could just upgrade R and hope for the best, kicking the can down the road again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6072:156,Install,Installing,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6072,8,"['Install', 'upgrade']","['Installing', 'upgrade']"
Deployability,"It looks like at one point GATK 3.8 was available via the [homebrew science tap](https://github.com/ilovezfs/homebrew-science/blob/master/gatk.rb). I've tried adding their formula to my homebrew formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:214,install,installing,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586,2,['install'],"['install', 'installing']"
Deployability,"It looks like hadoop is on version 2.5.0, and it doesn't look like either of the upcoming hadoop version, 2.8 or 3.0.0 is going to change it. https://github.com/apache/hadoop/blob/release-2.8.0-RC1/hadoop-project/pom.xml",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2437#issuecomment-284515190:180,release,release-,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2437#issuecomment-284515190,1,['release'],['release-']
Deployability,"It looks like in each of the cases that are failing, the filter expression references an attribute that isn't present in the variant, which the tool treats as ""PASS"" by default (this can be toggled using `--missing-values-evaluate-as-failing true`, in which case variants with missing values will be filtered). The parentheses are confounding but not relevant - the failing case above that uses no parens references `MQRandSum` (sic); the succeeding case references `MQRankSum`. Separating the expression components into separate filter expression arguments **does** change the results because each expression is evaluated individually and serially, so a reference to a missing value in one expression results in a `PASS`, but the subsequent expression results in the filter being applied if it meets the criteria. We should certainly update the doc to reinforce these subtleties. Another option would be to have a stricter ""throw on missing"" option as the default, but that could lead to lead to warning fatigue. Any other suggestions ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5362#issuecomment-436026665:190,toggle,toggled,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5362#issuecomment-436026665,2,"['toggle', 'update']","['toggled', 'update']"
Deployability,It looks like the HTSJDK update branch changed a few engine constants and that wasn't pulled into the combineGVCFs branch before merging.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3869:25,update,update,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3869,1,['update'],['update']
Deployability,"It looks like the conda env recently started resolving h5py to v3.1.0, which in turn appears to be incompatible with the keras version we're using, causing the CNNScoreVariants integration tests to fail when keras tries to load the model file (see https://github.com/tensorflow/tensorflow/issues/44467). This PR pins the version to the version used by the last build I could find that succeeded, which is 2.10.0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6955:177,integrat,integration,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6955,1,['integrat'],['integration']
Deployability,"It looks like the tests are running very slowly because of a performance regression due to the changes in `IntegrationTestSpec.assertEqualTextFiles`. You can see this on tests that should be unaffected by the core changes in this PR, like the VQSR integration tests, which have no cloud/bucket dependency and usually take about [1 minute](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_24775.2/tests/test/classes/org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibratorIntegrationTest.html), but took [25 minutes](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_24563.2/tests/test/classes/org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibratorIntegrationTest.html) with this branch. The same thing happens when the VQSR tests are run locally with this branch; all the time is spent in `assertEqualTextFiles`. @jean-philippe-martin I don't want to push to this branch without your ok, but reverting the first few lines of `assertEqualTextFiles` seems to fix the problem locally. (Separately, I will do some profiling to figure out for posterity sake why that change had such a dramatic affect ).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-462772143:107,Integrat,IntegrationTestSpec,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-462772143,2,"['Integrat', 'integrat']","['IntegrationTestSpec', 'integration']"
Deployability,"It looks like there have been some changes since I last looked at this, including one new tool, so I can make another pass on the java code. But I'd feel a lot better about taking this if there were at least one integration test for each of the tools (right now there are a couple of tests for the inference tool, and none for the other 3 tools). @lucidtronix is that possible to do that in the next day or so ? . As for type hinting,I'd love to see it in all of our Python code. I think it made the gcnv code much more readable (BTW, does anyone have mypy stubs for numpy, theano, tensorflow) ? We might want to run a type/checker linter as part of the build.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367435050:212,integrat,integration,212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367435050,1,['integrat'],['integration']
Deployability,"It looks like we copy and execute install_R_packages.R from the repo when building the base Docker image, and then on travis, we use the current repo version for the travis image. We also copy the current version to the final Docker image during the build, but we don't execute it there (at least as far as I can tell). This means the travis tests that use the Docker image run with a different R environment (the one established for the base image) than the non-Docker tests. Also, the Docker image winds up having the updated copy of the script, but its not the one reflected in the actual environment. @jamesemery It looks like you might have added the second copy - can you take a look and verify that we should fix this, or see if there is someting I'm missing.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4251:520,update,updated,520,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4251,1,['update'],['updated']
Deployability,It looks like we need to update mockito. ; https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27538.13/tests/test/index.html. ```. java.lang.IllegalArgumentException: Unknown Java version: 11; 	at net.bytebuddy.ClassFileVersion.ofJavaVersion(ClassFileVersion.java:135); 	at net.bytebuddy.ClassFileVersion$VersionLocator$ForJava9CapableVm.locate(ClassFileVersion.java:357); 	at net.bytebuddy.ClassFileVersion.ofThisVm(ClassFileVersion.java:147); 	at net.bytebuddy.dynamic.loading.ClassInjector$UsingReflection$Dispatcher$CreationAction.run(ClassInjector.java:301); 	at net.bytebuddy.dynamic.loading.ClassInjector$UsingReflection$Dispatcher$CreationAction.run(ClassInjector.java:290); 	at java.base/java.security.AccessController.doPrivileged(Native Method); 	at net.bytebuddy.dynamic.loading.ClassInjector$UsingReflection.<clinit>(ClassInjector.java:70); 	at net.bytebuddy.dynamic.loading.ClassLoadingStrategy$Default$InjectionDispatcher.load(ClassLoadingStrategy.java:184); 	at net.bytebuddy.dynamic.TypeResolutionStrategy$Passive.initialize(TypeResolutionStrategy.java:79); 	at net.bytebuddy.dynamic.DynamicType$Default$Unloaded.load(DynamicType.java:4456); 	at org.mockito.internal.creation.bytebuddy.SubclassBytecodeGenerator.mockClass(SubclassBytecodeGenerator.java:115); 	at org.mockito.internal.creation.bytebuddy.TypeCachingBytecodeGenerator$1.call(TypeCachingBytecodeGenerator.java:37); 	at org.mockito.internal.creation.bytebuddy.TypeCachingBytecodeGenerator$1.call(TypeCachingBytecodeGenerator.java:34); 	at net.bytebuddy.TypeCache.findOrInsert(TypeCache.java:138); 	at net.bytebuddy.TypeCache$WithInlineExpunction.findOrInsert(TypeCache.java:346); 	at net.bytebuddy.TypeCache.findOrInsert(TypeCache.java:161); 	at net.bytebuddy.TypeCache$WithInlineExpunction.findOrInsert(TypeCache.java:355); 	at org.mockito.internal.creation.bytebuddy.TypeCachingBytecodeGenerator.mockClass(TypeCachingBytecodeGenerator.java:32); 	at org.mockito.internal.creation.bytebuddy.SubclassB,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-532377836:25,update,update,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-532377836,1,['update'],['update']
Deployability,It might be prudent to hold off on this until after #5532 so the test update is less painful.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5676#issuecomment-463643786:70,update,update,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5676#issuecomment-463643786,1,['update'],['update']
Deployability,It might still be worth silencing this for people who are running spark 2.0.0 which is what we are doing on jenkins. (and what we officially support in our build.gradle). Ultimately we need to upgrade to spark 2.2.x #2555,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4186#issuecomment-358372207:193,upgrade,upgrade,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4186#issuecomment-358372207,1,['upgrade'],['upgrade']
Deployability,"It needs to be integrated with CRAMIndexer, and tests should be added for both BAM and CRAM.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1135:15,integrat,integrated,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1135,1,['integrat'],['integrated']
Deployability,It seems fairly rare that the PL array is truly uninformative and consequently would be removed based on the fact that none of the integration tests seem to have failed as a result of this.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7148:131,integrat,integration,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7148,1,['integrat'],['integration']
Deployability,It seems like another R dependency has moved. ; `http://cran.r-project.org/src/contrib/data.table_1.10.4-2.tar.gz` -> `https://cran.r-project.org/src/contrib/Archive/data.table/data.table_1.10.4-2.tar.gz`. We'll need to update our `installRscripts`. We should seriously consider just hosting these files ourselves somewhere.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3772:220,update,update,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3772,2,"['install', 'update']","['installRscripts', 'update']"
Deployability,"It seems like the patch in 4.1.6 didn't go far enough and that exception needs to be replaced with a `continue` in all cases. This seems to be occurring for haplotypes with long indels inside their assembly padding that don't have enough spanning sequence to resolve. Since the variation is inside the padding, it seems safe to ignore. Increasing padding resolves the issue, alhtough this is at the cost of runtime and should not be necessary. For example, suppose we have a ref haplotype ABCDD, where A, B, and C represent sequences of, say, 100 bases and D is a sequence of 50 bases. Suppose further that A and DD are the padding. Then the cigar of an alt haplotype ABCD gets aligned as a 350 base match that doesn't span the full padded reference region, leading to the error. I still need to figure out why this didn't happen in 4.1.4 (my guess is that elsewhere the code effectively skipped these haplotypes before the exception).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-607059533:18,patch,patch,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-607059533,1,['patch'],['patch']
Deployability,"It seems plausible to me, though, that the Google auth library may have been patched to perform checks that it wasn't performing previously. Maybe our project permissions have always been mis-configured :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940762:77,patch,patched,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940762,1,['patch'],['patched']
Deployability,It seems that the error goes away when I installed 2.0.2 ..... I had the 2.1.0 that is the only 2.x.x available thru homebrew on Mac. So it might all be due to a version difference.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290556381:41,install,installed,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290556381,1,['install'],['installed']
Deployability,"It seems that you can find out what FileSystem corresponds to what URI/URL by using the return of FileSystemProviders.installedProviders. Instead BucketUtils has hard-wired scheme names and has many conditional (isCould... isHadoop) for operations that can be done by using the appropriate FileSystem implementation that in turn can be resolved looking at that list. I guess that there are extant utility classes that process that list once for subsequent queries (e.g. scheme-name -> FS), but I have not confirmed that. Otherwise it is easy to write one. Is there is a reason what we need to do our own thing in BucketUtils?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3569:118,install,installedProviders,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3569,1,['install'],['installedProviders']
Deployability,"It seems to imply that ggplot isn't installed in the docker, which is confusing because it should be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406016353:36,install,installed,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406016353,1,['install'],['installed']
Deployability,It should also be noted that the current behavior of the HaplotypeCaller on low base quality reads could be better. Specifically in the PairHMM there is code that explicitly caps the base qualities for every base in every read to be at most the reads Mapping Quality. Empirically this doesn't seem to sufficiently penalize low MQ reads in the HMM scores which is part of the reason for the hard cuttoff. In the upcoming DRAGEN-GATK release code we disable this particular behavior and instead apply a secondary genotyping algorithm in the genotyper that attempts to partition the evidence by mapping quality and adjust the score if there is a significant difference in MQ between reads supporting the various alleles. No doubt there could be other approaches for capping MQ (possibly a reads HMM likelihoods contribution can be capped based on its MQ as well which is also a part of the DRAGEN-GATK).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7034#issuecomment-758861915:432,release,release,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7034#issuecomment-758861915,1,['release'],['release']
Deployability,"It sounds like they're planning a release at the end of december, and would be able to do a point release for us if we needed it. My vote is we put up a snapshot for now and ask them to do a november point release if they're able. . https://github.com/bigdatagenomics/adam/issues/1248",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2247#issuecomment-258994862:34,release,release,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2247#issuecomment-258994862,3,['release'],['release']
Deployability,"It turns out I was mistaken that setting the environment variables fixes the problem (stupid error on my part). It's possible the BaseTest message is unrelated. I haven't tested this branch out yet, but building from the commit immediately before the update works. I am going to try the next version to see if it helps. Edit: #3594 does not fix the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330896419:251,update,update,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330896419,1,['update'],['update']
Deployability,It was fixed in 4.1.5.0.; You can find the notes in:; https://github.com/broadinstitute/gatk/releases,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6446#issuecomment-680108598:93,release,releases,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6446#issuecomment-680108598,1,['release'],['releases']
Deployability,It was noticed while doing #8351 that the `GencodeFunctotation.equals()` method has the following line in it; ``` ; if (geneTranscriptType != that.geneTranscriptType) return false; ; ```. Unfortunately the geneTranscriptType is stored as a Sting and thus this should NOT be expected to succeed in almost any case. As it stands fixing this innocuous oversight seems to break several of the combinatorial funcotator tests and an integration test. Somebody should fix this behavior (easy) and validate that the test changes are within tolerable levels (hard).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8385:427,integrat,integration,427,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8385,1,['integrat'],['integration']
Deployability,It was released last week.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1478742242:7,release,released,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1478742242,1,['release'],['released']
Deployability,It will be useful if this is added to the configuration system (#2368 and #3081).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2155#issuecomment-316078724:42,configurat,configuration,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2155#issuecomment-316078724,1,['configurat'],['configuration']
Deployability,"It won't be able to run any faster than BWA mem does with a similar number of cores, since it is essentially just running bwamem. It's potentially faster as part of a spark pipeline so you can load and process data once instead of saving the data to disk and reloading it repeatedly. . The complete list of spark configuration parameters is available on the [spark docs](https://spark.apache.org/docs/3.5.0/configuration.html). Many of them are not relevant in local mode. From what I understand the local mode is going to execute as a single executor with the number of cores specified in the `local[#]` block ( or the total number of system threads if it's set to `*`) It will use the available memory that java is configured with. I'm pretty sure it's ignoring the memory and configuration parameters you've set. Those will be relevant if you configure a stand alone spark cluster (potentially one running exclusively on your local machine). . Our spark tools are not being actively developed for the most part. We've moved away from them to use single threaded tools widely sharded and managed by cromwell. The additional complexity of the spark environment made it hard to see much benefit when most of the tools are embarassingly parallel and easily shardable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8897#issuecomment-2214866066:173,pipeline,pipeline,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8897#issuecomment-2214866066,4,"['configurat', 'pipeline']","['configuration', 'pipeline']"
Deployability,It would be good if we kept updated on the newest BWA mem. We'd need Heng to update the Apache2 branch with his newest changes.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2711#issuecomment-301186181:28,update,updated,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2711#issuecomment-301186181,2,['update'],"['update', 'updated']"
Deployability,It would be great if mac users could install GATK easily with homebrew. We should put together a brew formula for it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4164:37,install,install,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164,1,['install'],['install']
Deployability,It would be great to also update the doc for https://github.com/broadinstitute/gatk/issues/5939 at the same time.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5964#issuecomment-495771225:26,update,update,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5964#issuecomment-495771225,1,['update'],['update']
Deployability,"It's a little confusing that we use downsampled tumor BAMs for the gCNV WDL tests, for example. Can wait until after release.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4007:117,release,release,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4007,1,['release'],['release']
Deployability,"It's a type of quality metrics they designed - quotes below -(https://support.illumina.com/content/dam/illumina-support/documents/documentation/software_documentation/dragen-bio-it/Illumina-DRAGEN-Bio-IT-Platform-User-Guide-1000000141465-00.pdf). . About the chrM, thank you. . Anyway, I don't think the ""VCFAdapterException"" error is related with the chrM, because the JoinGenotype pipeline worked fine with Reblock(snap) + GATK 4.2.5, and they were there (of course we know it was generating wrong data, but we had results to open and check in HAIL). ```; You can use somatic quality (SQ) as the primary metric to describe the confidence with which the caller; made a somatic call. SQ is reported as a format field for the tumor sample. Variants with SQ score; below the SQ filter threshold are filtered out using the weak_evidence tag. To trade off sensitivity; against specificity, adjust the SQ filter threshold. Lower thresholds produce a more sensitive caller and; higher thresholds produce a more conservative caller.; ```. ```; QUAL is not output in the somatic variant records. Instead, the confidence score is FORMAT/SQ.; ##FORMAT=<ID=SQ,Number=1,Type=Float,Description=""Somatic quality"">; The field is specific to the sample. For the tumor samples, it quantifies the evidence that a somatic; variant is present at a given locus.; If a normal sample is also available, the corresponding FORMAT/SQ value quantifies the evidence that; the normal sample is a homozygous reference at a given locus.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7797#issuecomment-1113714714:383,pipeline,pipeline,383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7797#issuecomment-1113714714,1,['pipeline'],['pipeline']
Deployability,It's not necessary to update `DepthPerAlleleBySample`. This is verified by `DepthPerAlleleBySampleUnitTest.testUsingReads ` for the refDepth=altDepth=0 case.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2529#issuecomment-289564636:22,update,update,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2529#issuecomment-289564636,1,['update'],['update']
Deployability,"It's pretty clear at this point that there is a bug in tribble with iteration over block-compressed inputs that lack an index. This is a completely different codepath (and even a different `FeatureReader`) than you get if an index is present. To buy us some time to nail this down, we are going to patch GATK to always require an index for block-compressed tribble files, even if `-L` is not specified. This change will go out in the bug fix release this Friday.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359855307:298,patch,patch,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359855307,4,"['patch', 'release']","['patch', 'release']"
Deployability,It's weird that it worked before though if roles aren't set up right. It seems like security issues shouldn't be solved by asking people to upgrade their client software so that it can deny them permission.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940018:140,upgrade,upgrade,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940018,1,['upgrade'],['upgrade']
Deployability,"It's weird, usually java should output an error message if it runs out of memory. The exception would be when java is assigned so much memory that the SYSTEM kills it instead of java killing itself. ; You could try adding `dmesg | tail -100` to your wdl after m2 runs to see if there are any messages from the OOMkiller. . What's your total available memory on the machine and your -Xmx setting? You typically need to leave some memory room for the OS and other native sofware. (although by default our pipelines SHOULD have that configured correctly.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7494#issuecomment-939070414:503,pipeline,pipelines,503,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7494#issuecomment-939070414,1,['pipeline'],['pipelines']
Deployability,Iterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); ```. I ran the same command again from my computer (not in the cloud) still using the NIO paths and it ran successfully. I've also seen it run successfully when running the same pipeline in the cloud. The only thing I think I've changed is the disk size I'm asking for. I'm in the process of validating the input bam right now.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316:7353,pipeline,pipeline,7353,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316,1,['pipeline'],['pipeline']
Deployability,"Its possible to specify CNN inference size argument values that cause the Python process run out of memory, and the failure mode appears to be the java process hangs. Its not clear whether its always possible to recover from this using the global exception handler we currently install on the Python side - we need to explore a bit to see if the handler is being invoked on OOM; whether catching the OOM exception explicitly would help, or if we need an alternative reporting strategy for low-memory conditions. Attached is a log provided by @bhanugandham from a run in a Terra notebook that failed and that exhibited a hang that we assume was due to OOM, and that was resolved by reducing the inference batch size. [gatkStreamingProcessJournal-772629669.txt](https://github.com/broadinstitute/gatk/files/2988819/gatkStreamingProcessJournal-772629669.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5820:278,install,install,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5820,1,['install'],['install']
Deployability,Its use in `ValidateBasicSomaticShortMutations` seems limited to the integration test. Can I rewrite the test to do without `AnnotatedInterval` and call it a day?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3884#issuecomment-526876913:69,integrat,integration,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3884#issuecomment-526876913,1,['integrat'],['integration']
Deployability,"I’ll take a look at the somatic tests. They should be OK, probably just something related to kebab case changes. EDIT: Or hmm, maybe they weren't passing before. Something to do with annotated-interval validation, I think. I think the WDL tests should be using the Docker, which has g++. Travis machines might be slower?. Integration tests will need to be in the python test group. Take a look at the python tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-350160424:322,Integrat,Integration,322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-350160424,1,['Integrat'],['Integration']
Deployability,Jar on Maven central updated - please clear any cached jars,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-295584988:21,update,updated,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-295584988,2,['update'],['updated']
Deployability,"Java 8 is now old enough that it's not the default on new machines, (java 12 seems to be what comes on a new macbook.) Installing java 8 has become more of a hassle because oracle now requires you to login in order to get it. We should update the readme with information about how to get java 8, probably pointing people to https://adoptopenjdk.net/. I think comms probably needs to update/add some documentation about this as well because it's definitely a friction point. We might also want to advise using jenv for people with multiple java installations to manage them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6024:119,Install,Installing,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6024,4,"['Install', 'install', 'update']","['Installing', 'installations', 'update']"
Deployability,"Java implementation of segmentation is now in the sl_wgs_segmentation dev branch, with a few simple unit tests. I'll expand on these and add tests for denoising in the future, but for now we have a working revised pipeline up through segmentation. The CLI is simply named ModelSegments (since my thinking is that it could eventually replace ACNV). I ran it on some old denoised exomes. Runtime is <10s, comparable to CBS. Here's a particularly noisy exome:. CBS found 1398 segments:; ![cbs](https://user-images.githubusercontent.com/11076296/30165095-cdf6251a-93ac-11e7-91fb-dcc8f48fe07f.png). Kernel segmentation with a penalty given by a = 1, b = 0 found 1018 segments:; ![kern](https://user-images.githubusercontent.com/11076296/30165106-dbbe0b40-93ac-11e7-99ec-5d58d8417d8b.png). Kernel segmentation with a penalty given by a = b = 1 (which is probably a reasonable default penalty, at least based on asymptotic theoretical arguments) reduced this to 270 segments :; ![kern-smooth](https://user-images.githubusercontent.com/11076296/30165113-e2b545a8-93ac-11e7-97a9-a692e43ebbdf.png). The number of segments can similarly be controlled in WGS. WGS runtime is ~7min for 250bp bins, ~30s of which is TSV reading, and there is one more spot in my implementation that could stand a bit of optimization, which might bring the runtime down. In contrast, I kicked off CBS 45 minutes ago, and it's still running... @LeeTL1220 this is probably ready to hand off to you for some WDL writing and preliminary evaluation. ; Although I can't guarantee that there aren't bugs, I ran about ~80 exomes with no problem. We can talk later today.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-327797936:214,pipeline,pipeline,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-327797936,2,['pipeline'],['pipeline']
Deployability,Java\jdk1.8.0_121\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\rt.jar;C:\project\push\target\classes;E:\repository\org\springframework\boot\spring-boot-starter-jdbc\2.3.0.RELEASE\spring-boot-starter-jdbc-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter\2.3.0.RELEASE\spring-boot-starter-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot\2.3.0.RELEASE\spring-boot-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-autoconfigure\2.3.0.RELEASE\spring-boot-autoconfigure-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-logging\2.3.0.RELEASE\spring-boot-starter-logging-2.3.0.RELEASE.jar;E:\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\repository\org\apache\logging\log4j\log4j-to-slf4j\2.13.2\log4j-to-slf4j-2.13.2.jar;E:\repository\org\apache\logging\log4j\log4j-api\2.13.2\log4j-api-2.13.2.jar;E:\repository\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;E:\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;E:\repository\org\yaml\snakeyaml\1.26\snakeyaml-1.26.jar;E:\repository\com\zaxxer\HikariCP\3.4.5\HikariCP-3.4.5.jar;E:\repository\org\springframework\spring-jdbc\5.2.6.RELEASE\spring-jdbc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-beans\5.2.6.RELEASE\spring-beans-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-tx\5.2.6.RELEASE\spring-tx-5.2.6.RELEASE.jar;E:\rep,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:2256,RELEASE,RELEASE,2256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['RELEASE'],['RELEASE']
Deployability,Javadoc update: minor error in the documentation regarding --genotyping-mode,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5657:8,update,update,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5657,1,['update'],['update']
Deployability,JlYWRXYWxrZXIuamF2YQ==) | `83.784% <83.784%> (ø)` | `14 <14> (?)` | |; | [...ute/hellbender/engine/SlidingWindowReadWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/4682/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvU2xpZGluZ1dpbmRvd1JlYWRXYWxrZXIuamF2YQ==) | `85.294% <85.294%> (ø)` | `10 <10> (?)` | |; | [...e/hellbender/utils/iterators/ShardingIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4682/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pdGVyYXRvcnMvU2hhcmRpbmdJdGVyYXRvci5qYXZh) | `92.683% <92.683%> (ø)` | `18 <18> (?)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4682/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4682/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4682/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4682/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `73.973% <0%> (-26.027%)` | `11% <0%> (+4%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/ga,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-384608003:2806,pipeline,pipelines,2806,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-384608003,1,['pipeline'],['pipelines']
Deployability,Jonn and Louis;; Thanks so much to the pointer to the other PRs and for the work. A `--javaOptions` flag for `gatk-launch` would work perfect for me. Once this gets merged I'll update the conda package to include it. Much appreciated.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2778#issuecomment-305674477:177,update,update,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2778#issuecomment-305674477,1,['update'],['update']
Deployability,"Jupollet,. This is a known issue and should be resolved by the most recent release; gatk4-4.1.4.1. This was released last week, so you may need to just update. If that doesn’t work, you may need to disable supplementary reads. Thanks,. Mark. On Mon, Dec 2, 2019 at 10:52 AM jupollet <notifications@github.com> wrote:. > I verify with sacct SLURM command and the job have no problem with RAM; > memory, he run through the end but no produce .stat file and output only; > .vcf and .vcf.idx; >; > —; > You are receiving this because you were assigned.; >; >; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6271?email_source=notifications&email_token=ACRX2DIR7ZYRDCNPZNOLET3QWU4L3A5CNFSM4JPWZLUKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEFUEKKA#issuecomment-560481576>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ACRX2DJECNGRYUGBY62LLN3QWU4L3ANCNFSM4JPWZLUA>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-560493809:75,release,release,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-560493809,3,"['release', 'update']","['release', 'released', 'update']"
Deployability,Just FYI to @ldgauthier that I think this issue can be closed now that #5318 is merged and released.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5314#issuecomment-468854875:91,release,released,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5314#issuecomment-468854875,1,['release'],['released']
Deployability,"Just a note to self: now that sl_wgs_acnv is in, I did some rebasing. My local sl_wgs_acnv_headers is rebased on master, but I haven't pushed it; will push after @asmirnov239 completes his review.; Both local and remote sl_delete_cnv_legacy are rebased on local sl_wgs_acnv_headers.; Both local and remote sl_wgs_acnv_headers_docs are rebased on top of that.; At some point sl_gcnv_ploidy_cli should be rebased as well, but currently it's rebased on pre-review sl_wgs_acnv -> sl_wgs_acnv_headers.; The forthcoming branch for adding old padding behavior to PreprocessIntervals will need to be rebased on top of sl_gcnv_ploidy_cli. @LeeTL1220 @davidbenjamin Hopefully all the branches under review will get merged in soon, but ideally any C30/FC updates to the WDL will happen after sl_wgs_acnv_headers_docs (which I'm still working on) gets merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3914#issuecomment-351826950:744,update,updates,744,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3914#issuecomment-351826950,1,['update'],['updates']
Deployability,"Just a patch to make the change suggested in the review of broadinstitute/gatk-protected#1001. @asmirnov239 your comment was correct, not sure what I was thinking back then!. Closes #3372.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3378:7,patch,patch,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3378,1,['patch'],['patch']
Deployability,"Just a quick test of `--splitMultiallelics` looks good:; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; 17:52:19.004 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:52:19 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:52:19.130 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:52:19.131 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:52:19.131 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:52:19.131 INFO LeftAlignAndTrimVariants ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:403,install,install,403,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971,3,['install'],['install']
Deployability,"Just a reminder tech leads @droazen @cwhelan @samuelklee @ldgauthier @vruano @yfarjoun @LeeTL1220 @cmnbroad , that the tool doc updates need to be done, reviewed and merged as soon as possible. Please assign your people tools to update if you haven't already and let us know the status of the changes in the STATUS column of [the spreadsheet](https://docs.google.com/a/broadinstitute.org/spreadsheets/d/19SvP6DHyXewm8Cd47WsM3NUku_czP2rkh4L_6fd-Nac/edit?usp=sharing). Please prioritize tools that are featured in any Best Practice workflow. The forum docs revolve mostly around Best Practice workflows. **@chandrans and I have to then take your new kebab parameters and _edit the entirety of the forum documents_ to represent the new syntax and WE HAVE LESS THAN 9 WORKING DAYS TO DO SO as of today 12/4.** @chandrans is leaving for the holidays starting December 15 and will not be back until near the release on January 9. Once she goes on holiday, I take over her forum duties, which is a full-time job. We really need to have these changes now so we can start working on updating forum docs as the updates are merged to master. Thank you for your work towards these improvements. Again, although I cannot help in changing code, and do not understand the intricacies, I have brought in homemade cheesecake towards fueling your work towards these updates.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349040010:128,update,updates,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349040010,6,"['a/b', 'release', 'update']","['a/broadinstitute', 'release', 'update', 'updates']"
Deployability,"Just an idea: it will be nice to propagate the configuration from `Main` to the tools, and obtain from it the packages/classes to include in the command line tools (this is one of the things that I implemented in #2322).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309680944:47,configurat,configuration,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309680944,1,['configurat'],['configuration']
Deployability,Just checks that the input and output bams are equal (which is still the; case for a bam with no duplicates). Once BQSR is hooked up we'll have; to update the expected output for this test. This is intended as a starting point for the more meaningful tests we; eventually want to have.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/772:148,update,update,148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/772,1,['update'],['update']
Deployability,"Just finished switching over all of the CNV tools to fail early if directories are not writeable---or do not exist and cannot be created---only to realize that this behavior is inconsistent with that of Picard IntervalListTools (which is used in the gCNV pipeline). That tool fails early if the output directory is not writeable or does not exist, and although there is a code path later that suggests that output directories should be created, it is not reached due to this early fail. It might be that this inconsistency was introduced in https://github.com/broadinstitute/picard/pull/1208 and I did not catch it in my PR review. @yfarjoun any opinions what the intended behavior should be? Are there any conventions for Picard tools in general?. Perhaps we could enforce this at the engine level (maybe checks that are triggered by annotations such as suggested in https://github.com/broadinstitute/gatk/issues/141, if possible)? But this would only work for GATK tools and would still rely on the diligence of developers. In any case, I'll decide on and document a convention for the CNV tools, but I think it might be a quixotic dream to enforce consistent behavior---especially without breaking things downstream which may rely on existing, inconsistent behavior...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-469067676:255,pipeline,pipeline,255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-469067676,1,['pipeline'],['pipeline']
Deployability,"Just follow the recommendations from our readme file ; ```. First, make sure [Miniconda or Conda](https://conda.io/docs/index.html) is installed (Miniconda is sufficient). To ""create"" the conda environment:; If running from a zip or tar distribution, run the command conda env create -f gatkcondaenv.yml to create the gatk environment. Execute the shell command source activate gatk to activate the gatk environment.; See the [Conda](https://conda.io/docs/user-guide/tasks/manage-environments.html) documentation for additional information about using and managing Conda environments.; ```; And yes you don't have to call SNPs and INDELs separately.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-2213817998:135,install,installed,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-2213817998,2,['install'],['installed']
Deployability,"Just for future reference, note that comments in `testVariantRecalibratorSNPMaxAttempts` are also incorrect or out of date. The test passes even if you limit it to one attempt. ```; // For this test, we deliberately *DON'T* sample a single random int as above; this causes; // the tool to require 4 attempts to acquire enough negative training data to succeed; ```. So again, the tests were already ""broken."" But still, rather than attempt to fix them, I think it's best to follow the principle of not changing both production and test code to the extent that it is possible in this scenario. We've already updated enough exact-match expected results to make me a bit uncomfortable!. Someone else may want to tackle fixing the tests in a separate push, but I think it makes sense for me to focus on avoiding these sorts of issues when writing tests for the new tools. EDIT: For the record, I confirmed that the undesired behavior in this test that the RNG hack was trying to avoid was fixed (and hence, the test was ""broken"") in #6425. Probably wasn't noticed because this is the only non-exact-match test and the test isn't strict enough to check that attempts 1-3 fail, it only checks that we succeed by attempt 4. Again, someone else may feel free to examine the actual coverage of this test and whether it's safe to remove it and/or clean up all the duct tape---but at some point, it becomes difficult to tell which pieces of duct tape are load bearing!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1064236628:607,update,updated,607,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1064236628,1,['update'],['updated']
Deployability,"Just for information, when do you think a new release with this corrected bug will be available (possibly also in bioconda) ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-466662922:46,release,release,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-466662922,1,['release'],['release']
Deployability,"Just for the record, the old somatic + germline pipelines comprise ~70k lines of Java code (including tests and utility classes). The new pipelines clock in at around ~22k lines of Java + python.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3903#issuecomment-348516041:48,pipeline,pipelines,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3903#issuecomment-348516041,2,['pipeline'],['pipelines']
Deployability,"Just got an update by email from the GP team indicating that their perspective is that these are valid index files. It seems that this issue lives in a liminal space where Mutect2 is crashing due to reasons that are not a GATK bug, but also not due to any formal problem in the GP pipeline either. Still, I'm running Broad-built software on recently sequenced Broad-provided genetic data, so it seems a little odd that these aren't playing well together. Trying to think of a solution so that other people in this situation aren't left confused by the error message, is this error specific enough that an additional statement could be added to the error message, e.g., ""This error may be triggered by CRAM indexes produced by older implementations of `htsjdk`, in which case reindexing with an updated `htsjdk` may resolve this problem.""? Or is this error more general, making such a suggestion inappropriate?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1099607060:12,update,update,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1099607060,3,"['pipeline', 'update']","['pipeline', 'update', 'updated']"
Deployability,"Just needs a new release of htsjdk, I think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6754#issuecomment-705742236:17,release,release,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6754#issuecomment-705742236,1,['release'],['release']
Deployability,"Just noticed an updated version of the kernel segmentation paper: https://hal.inria.fr/hal-01413230v2/document The original version referenced in this issue can be found at: https://hal.inria.fr/hal-01413230v1/document. A couple of noteworthy changes include the form of the penalty function and the fact that they use an estimate of the variance to normalize the data and set the kernel variance to unity (they also symmetrize the BAF, which I guess is required for the latter). I don't think either change will make a huge difference to the final segmentation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-355392629:16,update,updated,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-355392629,1,['update'],['updated']
Deployability,"Just realized CNV WDLs are not using NIO in FireCloud. This is as simple as changing `File` to `String` for supported files. Not sure if these need to live in our repo (I see we have a M2 NIO WDL), I'd be fine with them just living in FireCloud. @bshifaw would you be OK making the changes in FireCloud for the next release? If not, I can add an NIO version to the repo. @LeeTL1220 perhaps something to add to the style guide (if it's not already there)?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4806:316,release,release,316,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4806,1,['release'],['release']
Deployability,"Just to be clear folks, we are using `gatk` directly, not `./gatk` in the example commands. And if you can, for those of you yet to make your updates, please use compressed file examples. Those of you who've already put in changes, thank you and Comms can tidy those bits later.; ```; <h3>Usage examples</h3>; <pre>; gatk --javaOptions ""-Xmx4g"" GenotypeGVCFs \; 	-R Homo_sapiens_assembly38.fasta; 	-V combined.g.vcf.gz; 	-O cohort.vcf.gz; </pre>. <pre>; gatk GenotypeGVCFs \; 	-R reference.fa; 	-V combined.g.vcf.gz; 	-O cohort.vcf.gz; </pre>; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-350095894:142,update,updates,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-350095894,2,['update'],['updates']
Deployability,"Just to provide additional context, all of the machinery in the AbstractRecordCollection classes for reading/writing CNV input/output TSVs was meant to make passing metadata (dictionaries, sample names, etc.) from tool to tool as automatic and consistent as possible. This avoids having to re-provide sample names, dictionaries, etc. at each tool/step---which often led to dictionary inconsistencies, contig/sample ordering bugs, etc. in older versions of the pipelines---at the cost of 1) redundantly carrying along this metadata in input/output TSVs, and 2) requiring consistent dictionaries in all initial BAM inputs. I think these are small costs to pay.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6957#issuecomment-726973610:460,pipeline,pipelines---at,460,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6957#issuecomment-726973610,1,['pipeline'],['pipelines---at']
Deployability,"Just updated the forum post with a solution. Basically, when running GenomicsDBImport on an uncompressed/unindexed vcf, the following exception was thrown - . ```; org.broadinstitute.hellbender.exceptions.UserException: Failed to create reader from file:///Users/nalini/gatk_test/ex001.mutect2-output.vcf; 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.getReaderFromPath(GenomicsDBImport.java:988); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.getHeaderFromPath(GenomicsDBImport.java:563); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.initializeHeaderAndSampleMappings(GenomicsDBImport.java:502); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.onStartup(GenomicsDBImport.java:439); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: htsjdk.tribble.TribbleException: An index is required, but none found., for input source: file:///Users/nalini/gatk_test/ex001.mutect2-output.vcf; 	at htsjdk.tribble.TribbleIndexedFeatureReader.<init>(TribbleIndexedFeatureReader.java:135); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:121); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.getReaderFromPath(GenomicsDBImport.java:941); 	... 9 more; ```. After compressing/indexing [the test file](https://drive.google.com/file/d/1VtV81cvmDMVov-vzEobagsO1DOwvIiB9/view?usp=sharing) provided in the forum post, was able to successfully run GenomicsDBImport as well as SelectVariants.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7362#issuecomment-886943056:5,update,updated,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7362#issuecomment-886943056,1,['update'],['updated']
Deployability,"Just wanted to add - I just tried installing the GATK docker as described here: https://gatk.broadinstitute.org/hc/en-us/articles/360035889991--How-to-Run-GATK-in-a-Docker-container. As I'd think that all software dependencies and whatnot should be fine. However, I still get the same error message:. /gatk/./gatk --java-options ""-Xmx25g"" SplitNCigarReads \; > -R Homo_sapiens.GRCh38.dna.primary_assembly.fa -I subset_TINY_rehead.bam \; > --tmp-dir /gatk/my_data/temp -O thing.bam; Using GATK jar /gatk/gatk-package-4.1.3.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx25g -jar /gatk/gatk-package-4.1.3.0-local.jar SplitNCigarReads -R Homo_sapiens.GRCh38.dna.primary_assembly.fa -I subset_TINY_rehead.bam --tmp-dir /gatk/my_data/temp -O thing.bam. 21:12:14.158 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.3.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Mar 02, 2023 9:12:16 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 21:12:16.383 INFO SplitNCigarReads - ------------------------------------------------------------; 21:12:16.384 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.1.3.0; 21:12:16.384 INFO SplitNCigarReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 21:12:16.384 INFO SplitNCigarReads - Executing as root@9d399eec0e24 on Linux v5.19.0-32-generic amd64; 21:12:16.384 INFO SplitNCigarReads - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; 21:12:16.384 INFO SplitNCigarReads - Start Date/Time: March 2, 2023 9:12:14 PM UTC; 21:12:16.385 INFO SplitNCigarReads - ------------------------------------------------------------; 21:12:16.385 INFO SplitNCigarReads - ----------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452564826:34,install,installing,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452564826,1,['install'],['installing']
Deployability,"Justin Rhoades of the blood biopsy team noticed a bug in the Mutect2 pipeline: if the number of scatters was sufficiently high, the last chunk of intervals did not contain any autosomal contigs, and therefore `GetPileupSummaries` was run on an empty interval for that scatter, throwing an error. For the pipeline there is no reason not to allow this empty interval and consequent empty output because it gets merged with other output later in the pipeline. It also seems that this is a generic feature of scattered jobs -- empty intersection of intervals need not imply a user error. Therefore, I added an argument to `IntervalArgumentCollection` to allow empty intervals. Since the change to the Mutect2 pipeline is tiny the primary need in code review is to judge whether the changes to `IntervalArgumentCollection` are acceptable. @lbergelson could you look at this PR?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6209:69,pipeline,pipeline,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6209,4,['pipeline'],['pipeline']
Deployability,"K/NGS-SparkGATK/:/NGS-SparkGATK/; - /data/ngs/:/ngs/; - /data0/output/:/output/; spark-worker:; image: bde2020/spark-worker:2.2.0-hadoop2.8-hive-java8; networks:; - workbench; environment:; - SPARK_MASTER=spark://spark-master:7077; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8081. env_file:; - ./hadoop.env; volumes:; - reference-image:/reference_image. reference:; image: vzzarr/reference:hg19_img; networks:; - workbench; deploy:; mode: global; restart_policy:; condition: on-failure; tty: true #keeps the container alive; volumes:; - reference-image:/reference_image. volumes:; reference-image:. networks:; workbench:; external: true; ```; - Hadoop:; ```; version: '3'; services:; namenode:; image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - namenode:/hadoop/dfs/name; environment:; - CLUSTER_NAME=test; env_file:; - ./hadoop.env; deploy:; mode: replicated; replicas: 1; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50070; ports:; - 8334:50070; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/output/:/output/; - /data/ngs/:/ngs/; datanode:; image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - datanode:/hadoop/dfs/data; environment:; SERVICE_PRECONDITION: ""namenode:50070""; # depends_on:; # - namenode; env_file:; - ./hadoop.env; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50075. volumes:; datanode:; namenode:. networks:; workbench:; external: true; ```; the datanodes and namenode and spark master and workers are all working.; My hardware resources are:; 16 core and 1Tb memory ssd and 56Gb ram for 3 machines. I have this problem when I launch the version(GATK) v4.0.4.0 but not with this version v4.0.2.0-4-gb59d863-SNAPSHOT:. >java.lang.IllegalStateException: Duplicate key -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:2550,deploy,deploy,2550,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['deploy'],['deploy']
Deployability,Kd BGE Doc Updates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8926:11,Update,Updates,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8926,1,['Update'],['Updates']
Deployability,Kd GVS GP self service doc updates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8886:27,update,updates,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8886,1,['update'],['updates']
Deployability,"Keep me updated. I think a multi-sample version of ModelSegments would be pretty easy to implement and would hopefully share a similar command-line scheme for specifying allelic-count and denoised-copy-ratio files for the normal/tumors. Something to think about is that the modeling step probably can be done on a per-sample basis after multi-sample segmentation, and it would be nice to scatter per sample for WGS. There are probably a few ways we can implement this, but let me know if you're planning something similar for M2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4887#issuecomment-396687918:8,update,updated,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4887#issuecomment-396687918,1,['update'],['updated']
Deployability,Kristen requested some small changes for the mitochondria pipeline. This renames the output vcf with the name of the sample and puts a default value for autosomal_median_coverage (meaning you'll now get the NuMT filter even if you don't provide the actual autosomal coverage). Happy to discuss if that's the right thing to do or if we really want to force people to put a value for autosomal coverage.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6160:58,pipeline,pipeline,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6160,1,['pipeline'],['pipeline']
Deployability,"K}/lib/python3.6/site-packages/theano/__init__.py"", line 110, in <module>; from theano.compile import (; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/__init__.py"", line 12, in <module>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 140, in <module>; preargs=args); File ${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2396, in compile_str; (status, compile_stderr.replace('\n', '. '))); Exception: Compilation failed (return status=1): /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_deregisterTMCloneTable. /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_registerTMCloneTable. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x1a): error: unsupported reloc 42. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x6b): error: unsupported reloc 42. collect2: error: ld returned 1 exit status. ```. Then I have installed theano with python 3.6.6 which is compiled with gcc 5.4.0, and it was giving me no errors. ```sh. $ theano-nose . ----------------------------------------------------------------------; Ran 0 tests in 0.012s. OK; ```. The Theano toolchain issue might be caused by theano not being actively developed anymore. Probably they never tested it with newer toolchains.; See this message that is also on the Theano github page.; https://groups.google.com/d/msg/theano-users/7Poq8BZutbY/rNCIfvAEAwAJ. #### Steps to reproduce; see description. #### Expected behavior; see descrip",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:3119,INSTALL,INSTALLDIRGCC,3119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['INSTALL'],['INSTALLDIRGCC']
Deployability,Label names are standard from https://docs.google.com/document/d/1eyPrpCSCMyf1CaBkc-aDi39xV7Bq9hthh07ludpgPNw. branch adds labels to:; - `bg query` calls in WDL command blocks; - queries run within python scripts called by WDLs; - datasets created with Utils.BuildGATKJarAndCreateDataset. Quickstart integration run here: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/15442e08-92af-48bc-ab96-2bdd4f39a801,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7902:300,integrat,integration,300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7902,1,['integrat'],['integration']
Deployability,"Last week, spark 2.0.0 is formally released. However, when I tested gatk4 on spark2.0.0, I found they were incompatible. It seems that the interface isn't match. The error log looks like below. Exception in thread ""main"" java.lang.NoSuchMethodError: scala.collection.Seq.aggregate(Ljava/lang/Object;Lscala/Function2;Lscala/Function2;)Ljava/lang/Object;; at org.bdgenomics.adam.models.NonoverlappingRegions.mergeRegions(NonoverlappingRegions.scala:75); at org.bdgenomics.adam.models.NonoverlappingRegions.<init>(NonoverlappingRegions.scala:55); at org.bdgenomics.adam.models.NonoverlappingRegions$.apply(NonoverlappingRegions.scala:169); at org.bdgenomics.adam.util.TwoBitRecord$.apply(TwoBitFile.scala:193); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.bdgenomics.adam.util.TwoBitFile.<init>(TwoBitFile.scala:70); at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:43); at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:41); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:320); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2073:35,release,released,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2073,1,['release'],['released']
Deployability,Latest greatest integration success https://job-manager.dsde-prod.broadinstitute.org/jobs/4ccc1f23-fcf4-4549-8046-a52364ec80c3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8533#issuecomment-1740967533:16,integrat,integration,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8533#issuecomment-1740967533,1,['integrat'],['integration']
Deployability,"Laura if you don't mind - is `@RG` really necessary for HaplotypeCaller's work? I understand that it is defined in the specs but is it critical for the functioning, if we assume that each sample is one library? ; In my case, I was following a pipeline involving `STAR` mapping -> `MarkDuplicates` -> `SplitNCigarReads` -> `HaplotypeCaller`. As I understand, normally I should have added `@RG`s at the mapping step. Neither `MarkDuplicates` nor `SplitNCigarReads` gave any warning about it, so I only figured the problem at the final step. I have then added totally fake `@RG`s to my files just after SplitNCigarReads step, and it worked - then why HaplotypeCaller can't do something similar in case when RGs are not present?; Thanks! . > ; > ; > Got it. Then I guess I'm arguing against @aushev's expected behavior that; > ; > > HaplotypeCaller should just treat them normally without any error",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6501#issuecomment-599721878:243,pipeline,pipeline,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6501#issuecomment-599721878,1,['pipeline'],['pipeline']
Deployability,Lb nio updates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1691:7,update,updates,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1691,1,['update'],['updates']
Deployability,"LearnReadOrientationModel json file does not exist within gatkdoc release subfolder in v.4.1.8.1. We are now utilizing these files to automatically create Galaxy tool wrappers, so it would be awesome to get this in for the next release. Thanks much!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6720:66,release,release,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6720,2,['release'],['release']
Deployability,"Lee is looking for someone else to evaluate it @davidbenjamin. In the meanwhile, because we have the BETA/Experimental label on this tool, it should be ok to release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3031#issuecomment-306563045:158,release,release,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3031#issuecomment-306563045,1,['release'],['release']
Deployability,"Lee, just letting you know I've tagged you in a forum question. ---; The oncotated maf output includes many rejected mutations (using the configuration from the public spaces). This is bad practice. The unfiltered VCF (or preferably a tsv) should have these sites but we should not be annotating them or putting them in final outputs. . This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/11440/m2-gatk4-oncotated-maf-output-includes-rejected-mutations/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4421:138,configurat,configuration,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4421,1,['configurat'],['configuration']
Deployability,"Legacy pipeline (note, the following should only be done after final ModelSegments PR is in):; - [x] Delete prototype tools. (#3887) (SL, PR issued by 12/1); - ~~Add deprecated/legacy tag to legacy pipeline tools. (SL, PR issued by 12/1 EDIT: need further input from @vdauwera )~~; - ~~Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PR issued by 12/15)~~; - ~~(Reach) Collect all legacy code in a new package.~~; - [x] Delete old pipelines. (SL, #3935 awaiting review). ModelSegments pipeline:; - [x] Review and merge denoising PR (#3820).; - [x] Add WDL changes from @LeeTL1220, @meganshand, and @jsotobroad to dev branch. (Note that we exposed PreprocessIntervals.bin_length in these WDLs; I'm assuming that https://github.com/broadinstitute/cromwell/issues/2912 will allow this to be specified via the json, so I reverted this change.); - [x] Make simple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3826:7,pipeline,pipeline,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826,5,"['Update', 'pipeline']","['Update', 'pipeline', 'pipelines']"
Deployability,Lessons learned in VDS creation during Echo Scale Testing. Successful integration run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/9e6aa362-e25b-49d0-83cd-d64e926c6386).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8602:70,integrat,integration,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8602,1,['integrat'],['integration']
Deployability,Let's be honest -- this is never going to happen. The goal is to move towards non-exact-match integration tests anyway.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3407#issuecomment-580901710:94,integrat,integration,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3407#issuecomment-580901710,1,['integrat'],['integration']
Deployability,"Let's create a mock up of a possible future configuration setup using the Owner library (https://github.com/lviggiano/owner). For the mock up, I recommend we have two configuration files, one containing system properties and the other containing a few general engine settings. . We can select a few system properties from `gatk-launch` for inclusion in the system properties config file (eg., `samjdk.compression_level`, `samjdk.use_async_io_read_samtools`, etc.). . For the engine settings file, I recommend including `codecPackages` (a `List<String>` currently hardcoded in `FeatureManager.CODEC_PACKAGES`), `cloudPrefetchBuffer`/`cloudIndexPrefetchBuffer` (int values) from `GATKTool`, and `createOutputBamIndex` (boolean), also from `GATKTool`. As part of this, we'll have to prove that we can inject the system properties sufficiently early on that libraries such as htsjdk will pick them up.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3126:44,configurat,configuration,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3126,2,['configurat'],['configuration']
Deployability,"Let's discuss further before you get too far along. The design of the Collections code was intended to ensure that very strict file formats are adhered to within the CNV pipeline. Making it more flexible to accommodate TSVs with arbitrary column headers, relax requirements for sequence dictionaries, etc. undermines that goal. There are also two other issues to consider:. 1) It looks like @jonn-smith has also been putting considerable effort into building a TSV framework for Funcotator. Perhaps CombineSegmentBreakpoints should consider using that framework instead, if it is more appropriate. We can also discuss bringing the CNV pipeline over into that framework, but this should definitely wait until after release. The end goal is for CNV team to spend as little time as possible writing or maintaining any code related to TSV parsing. 2) @mbabadi has put together some python evaluation code for the new gCNV, which makes use of the IntervalTree python package and PyVCF to accomplish some things that are very similar to what CombineSegmentBreakpoints is doing. Perhaps we could implement a similar approach purely in Java by making use of the IntervalTree implementation in htsjdk. I think for now we should treat CombineSegmentBreakpoints as a one-off tool to be used for internal validations. After release, we should design a more generic evaluation tool. This tool could take as input multiple collections of annotated locatables, with a few rigidly defined formats allowed (e.g., VCF, CNV Collection TSVs, perhaps some TSVs from other tools, etc.), with one designated as ground truth. The regions for evaluation could also be specified via -L (since it is possible this might not completely specified by the ground-truth collection). The appropriate intersections and lookups could then be performed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3995#issuecomment-352860616:170,pipeline,pipeline,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3995#issuecomment-352860616,4,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"Let's discuss. In the new pipeline, I currently have median absolute deviation after standardization and denoising output as text files during the plotting step, as before. But I think it actually makes more sense to output them after DenoiseReadCounts. We also can't output the number of segments until after the ModelSegments step. However, I would rather not bake this sort of thing into the jar if a simple `wc -l` would suffice.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3583#issuecomment-335602331:26,pipeline,pipeline,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3583#issuecomment-335602331,2,['pipeline'],['pipeline']
Deployability,"Let's do it. There are a lot of weirdly represented complex events in the; gnomAD browser that have come up and I expect this should fix 99% of them. On Sat, Mar 30, 2019 at 11:28 PM David Benjamin <notifications@github.com>; wrote:. > Update: there's another example on that thread now. If no one objects I'm; > going to do this.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5564#issuecomment-478308694>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdEXlYsOHiNeV5drfdrjIuDbiY6fpks5vcCtLgaJpZM4Zyez7>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-478586914:236,Update,Update,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-478586914,1,['Update'],['Update']
Deployability,Like #5485 but for tabix. (Build will fail until new Disq release is made.),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5574:58,release,release,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5574,1,['release'],['release']
Deployability,Limit the number of parts we run the VAT pipeline on as a test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8780:41,pipeline,pipeline,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8780,1,['pipeline'],['pipeline']
Deployability,Loading the known sites file (e.g. dbsnp_138.hg18.vcf) takes around 6 minutes in the Spark pipeline using `KnownSitesCache`. This ticket is to see if we can improve this.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5103:91,pipeline,pipeline,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5103,1,['pipeline'],['pipeline']
Deployability,"Looking at the htsjdk code responsible for the original throw (as far as I can see in the stack enclosed in the description) there is a few ""smells"" in the way synchronized is used or not use ReferenceSource.java. It is likely to be the reason behind the error considering that is failing in multi-thread. . Probably adding synchronized to getReferenceBasesByRegion would fix that. Is a htsjdk issue and not a GATK one. Do you want to add a workaround in GATK or press for a fix and update of the htsjdk dependency. @droazen?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8139#issuecomment-1376298392:483,update,update,483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8139#issuecomment-1376298392,1,['update'],['update']
Deployability,Looking forward to this being merged. Need to take stock after all the doc/kebab updates towards finalization. Happy holidays @lbergelson @droazen.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3961#issuecomment-353497923:81,update,updates,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3961#issuecomment-353497923,1,['update'],['updates']
Deployability,Looking into broadcasting reference to all workers for native Spark Reads pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/855:74,pipeline,pipeline,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/855,1,['pipeline'],['pipeline']
Deployability,"Looks like Xbyak might have been successfully squashed by the update to tensorflow 1.15.0, but it's hard to say given its intermittent nature. Not sure what to do about the Java 11 funkiness.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-602140879:62,update,update,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-602140879,1,['update'],['update']
Deployability,Looks like a missing set of parentheses caused the logging output for HaplotypeCaller to become unusably flooded with garbage. @droazen we should really get this in before release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7358:172,release,release,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7358,1,['release'],['release']
Deployability,"Looks like all packages *except* ggplot2 were successfully installed. The following lines in the R script are responsible for installing 3 of the packages:. ```; dependencies = c(""ggplot2"",""gplots"",""gsalib""); repos <- c(""http://cran.cnr.Berkeley.edu"",; ""https://cran.mtu.edu"",; ""http://lib.stat.cmu.edu/R/CRAN/""); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- 1; while(length(missing)!=0 & try <= length(repos)) {; install.packages(dependencies[missing], repos = repos[try], clean = TRUE); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- try + 1; }; ```. I guess this is supposed to ensure that the installs don't fail due to intermittent connection errors, etc., but each repo is only hit once and it's possible for the loop to exit with dependencies still missing. Could this have happened when the current base image was built and pushed? @jamesemery did you push this image?. Also, I learned that *reshape2* (as opposed to reshape) is actually a dependency of ggplot2 that is automatically installed along with ggplot2. So the original removal of reshape from the `install.packages` list was fine. However, the import statement that is removed in this PR fails whether or not ggplot2 successfully installs, and is extraneous in any case. This is all consistent with the fact that the users from the forum post only get an error message about reshape and not ggplot2. Note that they are using broadinstitute/gatk:4.0.4.0, in which ggplot2 is successfully installed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406028261:59,install,installed,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406028261,20,['install'],"['install', 'installed', 'installing', 'installs']"
Deployability,Looks like the integration tests failed with an unrelated error -- I'll try re-running them.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7393#issuecomment-953190949:15,integrat,integration,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7393#issuecomment-953190949,1,['integrat'],['integration']
Deployability,Looks like there was an R error in Carrot. Fortunately the actual meat of the Carrot test ran to completion (for the CHM) I have also checked that this matches for the exome and the NIST sample. I would say that these samples are exactly matching in terms of their VCFeval output and thus we can be confident that this branch did not break the standard pipeline path and we can call this 👍. ```; Type | Precision | Recall | F1_Score | TP_Eval | TP_Base | FP | FN | Stratifier | IGV_Session | UNK | Name | Truth_Set | Summary_Type | Comparison_Engine; -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --; SNP | 0.9706 | 0.9863 | 0.9784 | 3473278 | 3489284 | 105213 | 48308 | NA | gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/7012fa81-18fd-4c9c-8722-22c9d7fa642d/call-CHMSampleHeadToHead/BenchmarkComparison/ae3dcac7-7105-4847-ac07-f9f64a43c4c8/call-BenchmarkVCFControlSample/Benchmark/67f50e9a-e7a3-4b31-9d14-d700b46ddfa5/call-VcfEvalWriteXMLfile/shard-0/CONTROLSNAPSHOT2018HG002_CHM_GRCh38_SYNDIPv20180222_vcfeval.xml | 539662 | CONTROLSNAPSHOT2018HG002 | CHM_GRCh38_SYNDIPv20180222 | summary | VcfEval; INDEL | 0.8814 | 0.8636 | 0.8724 | 485076 | 465627 | 65264 | 73548 | NA | gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/7012fa81-18fd-4c9c-8722-22c9d7fa642d/call-CHMSampleHeadToHead/BenchmarkComparison/ae3dcac7-7105-4847-ac07-f9f64a43c4c8/call-BenchmarkVCFControlSample/Benchmark/67f50e9a-e7a3-4b31-9d14-d700b46ddfa5/call-VcfEvalWriteXMLfile/shard-0/CONTROLSNAPSHOT2018HG002_CHM_GRCh38_SYNDIPv20180222_vcfeval.xml | 429205 | CONTROLSNAPSHOT2018HG002 | CHM_GRCh38_SYNDIPv20180222 | summary | VcfEval; Type | Precision | Recall | F1_Score | TP_Eval | TP_Base | FP | FN | Stratifier | IGV_Session | UNK | Name | Truth_Set | Summary_Type | Comparison_Engine; SNP | 0.9743 | 0.99 | 0.9821 | 3384890 | 3391796 | 89358 | 34303 | HCR | gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/7012fa81-18fd-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1850884297:353,pipeline,pipeline,353,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1850884297,1,['pipeline'],['pipeline']
Deployability,"Looks like this failed on travis. I think given that given the lateness of the hour (release wise), we might want to take the original change that removes the libgcc-ng dependency, since that passed on travis, and rely on the simple workarounds for osx, which we'll have to convey out-of-band. Anything that requires changing the docker image seems risky at this point, not to mention that the image is already at 5.2 gig, which is way over our desired target. @samuelklee Any thoughts on this ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356131086:85,release,release,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356131086,2,['release'],['release']
Deployability,"Looks like this java.lang.NullPointerException is from an environment set up issue. . This request was created from a contribution made by Jordi Maggi on April 25, 2022 09:25 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/5574426055963-CNNScoreVariants-crashes-with-java-lang-NullPointerException](https://gatk.broadinstitute.org/hc/en-us/community/posts/5574426055963-CNNScoreVariants-crashes-with-java-lang-NullPointerException). \--. Hi,. I created a conda environment and installed gatk4 through `conda install -c bioconda gatk4`. I have been using this environment to run all steps of the single sample germline variant calling best practices workflow (both gatk and picard). However, I have never been able to run CNNScoreVariants with this setup, as it always results in a java.lang.NullPointerException error. The only way I am able to run this step is by running it through the docker image you provide. That, however, is not ideal for our setup. Any idea as to what I may try to be able to run it directly?. GATK version:. Using GATK jar /home/analyst/anaconda3/envs/snakemake\_env/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar ; ; Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /home/analyst/anaconda3/envs/snakemake\_env/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar --version ; ; The Genome Analysis Toolkit (GATK) v4.2.5.0 ; ; HTSJDK Version: 2.24.1 ; ; Picard Version: 2.25.4. Exact command:. gatk CNNScoreVariants -I 73318\_WES\_hg19\_recalibrated.sorted.bam -V 73318\_80\_IDTv1.vcf.gz -R /media/analyst/Data/Reference\_data/hg19.fa -O /media/analyst/Data/73318\_CNNScore\_test.vcf.gz -tensor-type read\_tensor > /media/analyst/Data/CNNScoreVariants.log. Entire console output:. Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7811:498,install,installed,498,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7811,2,['install'],"['install', 'installed']"
Deployability,Looks like we need to update our Rscripts... thanks for the report!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-1934930813:22,update,update,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-1934930813,1,['update'],['update']
Deployability,Lots of updates to the Mutect2 wdl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4201:8,update,updates,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4201,1,['update'],['updates']
Deployability,M2 NIO wdl -- updated for Firecloud pet service accounts,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4710:14,update,updated,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4710,1,['update'],['updated']
Deployability,M2 pon wdl works in Firecloud; M2 wdl works in JES; updated oncotator docker in M2 template,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4048:52,update,updated,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4048,1,['update'],['updated']
Deployability,"MASSIVE bug fixes and test updates. (Rebased 61 commits). - Fixed a bug when variants overlap the end of transcripts. - Updated logging in FuncotatorUtils::getAlignedRefAllele. - Fixed a bug in identifying splice sites for intronic regions. - Fixed a bug in FuncotatorUtils::isIndelBetweenCodons that caused issues; on reverse stranded variants. - Added in regression test data input files and expected files.; - Updated regression test sets to include only unique variants.; - Added in a 5' flank and a Start Codon insertion to regression test set. - Fixed a bug in FuncotatorUtils::isIndelBetweenCodons. - Finally fixed a bug with indels and start codons:; Now indels in start codons will not have protein renderings, nor will; they have codon change strings. This brings Funcotator closer to; Oncotator functionality (in Oncotator, start codon insertions/deletions; do not have protein change strings or codon change strings). - Fixed a bug in ordering transcripts by appris ranking. - Fixed a minor bug in how other transcripts are generated:.; With RNA/LINCRNA transcripts, the protein change would be null and was; append ed to the end of each `other transcript`. Now the null is no; longer appended. - Fixed a bug in insertions on the - strand:; All insertions on - strand had incorrectly rendered genome changes,; coding sequence changes, and protein changes.; This is due to how these fields are generated from the reference; sequence. - Fixed a bug (insertions on - strand):; Insertions on the - strand would have incorrect reference; sequences/alleles.; Now they are handled as a special case when computing the aligned; reference allele. - Fixed a bug in transcript selection for GencodeFuncotationFactory:; The LocusLevel / Curation Level was being incorrectly pulled from the; GENE features, rather than the TRANSCRIPT features that contain each; variant. As a result, the order in which representative transcripts; were chosen was wrong. The TRANSCRIPT feature is now being used to; det",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5302:27,update,updates,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5302,3,"['Update', 'update']","['Updated', 'updates']"
Deployability,"MPRESSION_LEVEL : 2; 14:40:45.791 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:40:45.791 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:40:45.792 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:40:45.792 INFO HaplotypeCaller - Deflater: IntelDeflater; 14:40:45.792 INFO HaplotypeCaller - Inflater: IntelInflater; 14:40:45.792 INFO HaplotypeCaller - GCS max retries/reopens: 20; 14:40:45.792 INFO HaplotypeCaller - Requester pays: disabled; 14:40:45.792 INFO HaplotypeCaller - Initializing engine; 14:40:47.694 INFO IntervalArgumentCollection - Processing 50818468 bp from intervals; 14:40:47.714 INFO HaplotypeCaller - Done initializing engine; 14:40:47.826 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 14:40:47.864 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 14:40:47.868 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 14:40:47.921 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 14:40:47.922 INFO IntelPairHmm - Available threads: 1; 14:40:47.922 INFO IntelPairHmm - Requested threads: 4; 14:40:47.922 WARN IntelPairHmm - Using 1 available threads, but 4 were requested; 14:40:47.922 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 14:40:48.005 INFO ProgressMeter - Starting traversal; 14:40:48.006 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 14:40:51.792 WARN InbreedingCoeff - InbreedingCoeff will not be calculated; at least 10 samples must have called genotypes; 14:40:58.312 INFO ProgressMeter - chr22:10659064 0.2 35790 208384.3; 14:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7076:8264,install,install,8264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7076,1,['install'],['install']
Deployability,"MQ=56.9;MQRankSum=-0.962;QD=2.57;ReadPosRankSum=0.193;SOR=0.712; `. ```; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chr6:26914009 [VC chr6.raw.excessHet.vcf.gz @ chr6:26914009 Q276902.75 of type=INDEL alleles=[G*, GTGTA, GTGTATA, GTGTGTA] attr={AC=[4269, 29, 5], AF=[0.620, 4.209e-03, ; #### Steps to reproduce; /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk --java-options -Xms5g ApplyVQSR -O indel.recalibrated.vcf.gz -V chr6.raw.excessHet.vcf.gz -AS --recal-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.recal --use-allele-specific-annotations --tranches-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.tranches --truth-sensitivity-filter-level 99.0 --create-output-variant-index true -mode INDEL; ```. #### Expected behavior; Create recalibrated vcf file. #### Actual behavior; ```; Caused by:; Process `ApplyRecalibrationIndels` terminated with an error exit status (3). Command executed:. #!/bin/bash; /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk --java-options -Xms5g ApplyVQSR -O indel.recalibrated.vcf.gz -V chr6.raw.excessHet.vcf.gz -AS --recal-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.recal --use-allele-specific-annotations --tranches-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.tranches --truth-sensitivity-filter-level 99.0 --create-output-variant-index true -mode INDEL. Command exit status:; 3. Command output:; (empty). Command error:; 23:21:52.354 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 23:22:02.735 INFO ProgressMeter - chr6:1162012 0.2 25000 144494.8; 23:22:12.789 INFO ProgressMeter - chr6:2449556 0.3 53000 155623.0; 23:22:23.019 INFO ProgressMeter - chr6:3663394 0.5 82000 160448.7; 23:22:33.257 INFO ProgressMeter - chr6:4991347 0.7 112000 164291.1; 23:22:43.683 INFO ProgressMeter - chr6:6325045 0.9 141000 164832.0; 23:22:53.824 INFO ProgressMeter - chr6:7646289 1.0 171000 166913.4; 23:23:03.973 INFO ProgressMeter - chr6:902992",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8054:1737,install,install,1737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8054,1,['install'],['install']
Deployability,"MT; 22:19:48.307 INFO FixMisencodedBaseQualityReads - ------------------------------------------------------------; 22:19:48.307 INFO FixMisencodedBaseQualityReads - ------------------------------------------------------------; 22:19:48.309 INFO FixMisencodedBaseQualityReads - HTSJDK Version: 2.13.2; 22:19:48.309 INFO FixMisencodedBaseQualityReads - Picard Version: 2.17.2; 22:19:48.310 INFO FixMisencodedBaseQualityReads - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 22:19:48.314 INFO FixMisencodedBaseQualityReads - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 22:19:48.318 INFO FixMisencodedBaseQualityReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 22:19:48.319 INFO FixMisencodedBaseQualityReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 22:19:48.325 INFO FixMisencodedBaseQualityReads - Deflater: IntelDeflater; 22:19:48.326 INFO FixMisencodedBaseQualityReads - Inflater: IntelInflater; 22:19:48.330 INFO FixMisencodedBaseQualityReads - GCS max retries/reopens: 20; 22:19:48.330 INFO FixMisencodedBaseQualityReads - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 22:19:48.331 INFO FixMisencodedBaseQualityReads - Initializing engine; 22:19:48.861 INFO FixMisencodedBaseQualityReads - Done initializing engine; 22:19:48.917 INFO ProgressMeter - Starting traversal; 22:19:48.917 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 22:19:49.026 INFO FixMisencodedBaseQualityReads - 196 read(s) filtered by: WellformedReadFilter. 22:19:49.029 INFO ProgressMeter - unmapped 0.0 918 505321.1; 22:19:49.030 INFO ProgressMeter - Traversal complete. Processed 918 total reads in 0.0 minutes.; 22:19:49.079 INFO FixMisencodedBaseQualityReads - Shutting down engine; [January 23, 2018 10:19:49 PM GMT] org.broadinstitute.hellbender.tools.FixMisencodedBaseQualityReads done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=580386816; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4241:2263,patch,patch,2263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4241,1,['patch'],['patch']
Deployability,"M_READER_FACTORY :; 08:48:45.921 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 08:48:45.921 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 08:48:45.921 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 08:48:45.921 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.REFERENCE_FASTA : null; 08:48:45.921 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 08:48:45.921 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 08:48:45.921 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 08:48:45.922 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 08:48:45.922 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 08:48:45.922 DEBUG ConfigFactory - Configuration file values:; 08:48:45.927 DEBUG ConfigFactory - gcsMaxRetries = 20; 08:48:45.927 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 08:48:45.927 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 08:48:45.927 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 08:48:45.927 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 08:48:45.927 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 08:48:45.927 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 08:48:45.927 DEBUG ConfigFactory - samjdk.compression_level = 2; 08:48:45.927 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 08:48:45.927 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 08:48:45.927 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 08:48:45.927 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 08:48:45.927 DEBUG ConfigFactory - spark.executor.memoryOverhead ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6217:4030,Configurat,Configuration,4030,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6217,1,['Configurat'],['Configuration']
Deployability,Made runtime attrs to args in MT pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8417:33,pipeline,pipeline,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8417,1,['pipeline'],['pipeline']
Deployability,"MainPostParseArgs(CommandLineProgram.java:169); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:218); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: GCS FileSystem URIs mustn't have: port, userinfo, path, query, or fragment: gs://broad-gatk-test-jenkins/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam; 	at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:192); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:83); 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:336); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:40); 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:140); 	at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:121); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); 	at org",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337:4251,deploy,deploy,4251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337,1,['deploy'],['deploy']
Deployability,MainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.NegativeArraySizeException; 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.resize(IdentityObjectIntMap.java:447); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.putStash(IdentityObjectIntMap.java:245); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:239); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:135); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.putStash(IdentityObjectIntMap.java:246); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:239); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:135); 	at com.esotericsoftware.kryo.util.MapReferenceResolver.addWrittenObject(MapReferenceResolver.java:41); 	at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:658); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:623); 	at c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3303:4716,deploy,deploy,4716,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3303,1,['deploy'],['deploy']
Deployability,MainPostParseArgs(CommandLineProgram.java:171); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:220); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.NoSuchFileException: jonn-test-bucket/foo.bam.parts; 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:575); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219); 	at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276); 	at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322); 	at java.nio.file.FileTreeIterator.<init>(FileTreeIterator.java:72); 	at java.nio.file.Files.walk(Files.java:3574); 	at java.nio.file.Files.walk(Files.java:3625); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.getFilesMatching(NIOFileUtil.java:91); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:61); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); 	at org.broadinstitute.hellbender.engine.spark.dat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2793:2373,deploy,deploy,2373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2793,1,['deploy'],['deploy']
Deployability,MainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleCl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591:3544,deploy,deploy,3544,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591,1,['deploy'],['deploy']
Deployability,MainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:152); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:175); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:161); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleCl,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994:9110,deploy,deploy,9110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994,1,['deploy'],['deploy']
Deployability,MainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadinstitute.hellbender.Main.main(Main.java:275); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.ContigAlignmentsModifier.removeOverlap(ContigAlignmentsModifier.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.AssemblyContigAlignmentSignatureClassifier.lambda$processContigsWithTwoAlignments$e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$13.hasNext(Ite,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:12785,deploy,deploy,12785,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['deploy'],['deploy']
Deployability,Make building and pushing user docs to the website a step in the release process,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4425:65,release,release,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4425,1,['release'],['release']
Deployability,Make each release in the repo citable with Digital Object Identifiers (doi),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3085:10,release,release,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3085,1,['release'],['release']
Deployability,Make it easier for test authors to make their tests toggle-able between different dataflow backends,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/561:52,toggle,toggle-able,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/561,1,['toggle'],['toggle-able']
Deployability,"Make the logging frequency used by the ProgressLogger available as an input. If not used, sets the default value. Variants team is using a branch of gatk and have made this change there, so pulling this change into master to simplify future merges / branch updates.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8662:257,update,updates,257,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8662,1,['update'],['updates']
Deployability,"MannWhitneyU was re-written from scratch in 2016 in GATK3,; but these changes never got ported to GATK4. This new version; produces significantly different results from the version; currently in GATK4, resulting in VERY different values for the; RankSumTest annotations in HaplotypeCaller output. @meganshand informs me that the updated GATK3 version has been; validated in R, and has much better tests than the old version. This is a straightforward port of that version with minimal changes:. -Merged ""MWUnitTest"" and ""RankSumUnitTest"" from GATK3 into a single; test class MannWhitneyUUnitTest; -Ported MathUtils.binomialCoefficient() and wrote new test for it; -Updated RankSumTest class and tests as appropriate. I've confirmed that with this change, the RankSum annotations produced; by the GATK4 HaplotypeCaller closely match those produced by the GATK3; HaplotypeCaller. Resolves #2604",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2605:329,update,updated,329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2605,2,"['Update', 'update']","['Updated', 'updated']"
Deployability,"Many of the pull requests are not using [`CommandLineProgramTest.runCommandLine()`](https://github.com/broadinstitute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/69:511,patch,patch,511,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69,2,"['patch', 'update']","['patch', 'update']"
Deployability,"Many users do not want mutations filtered in the VCF to show up in the MAF file. Two things:. - Update the default M2 WDL to use `broadinstitute/oncotator:1.9.7.0` docker image. - Add an optional flag to prune filtered mutations to the Oncotator task. If this is set to True, add the following to the oncotator command: `--collapse-filter-cols --prune-filter-cols`. This is unnecessary for the CNV WDL.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4422:96,Update,Update,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4422,1,['Update'],['Update']
Deployability,"Mappings = new AssemblyContigWithFineTunedAlignments(contig, tigWithInsMappings.insertionMappings);; > +; > + this.basicInfo = new BasicInfo(contig);; > +; > + annotate(refSequenceDictionary);; > + }; > +; > + private static List<AlignmentInterval> deOverlapAlignments(final List<AlignmentInterval> originalAlignments,; > + final SAMSequenceDictionary refSequenceDictionary) {; > + final List<AlignmentInterval> result = new ArrayList<>(originalAlignments.size());; > + final Iterator<AlignmentInterval> iterator = originalAlignments.iterator();; > + AlignmentInterval one = iterator.next();; > + while (iterator.hasNext()) {; > + final AlignmentInterval two = iterator.next();; > + // TODO: 11/5/17 an edge case is possible where the best configuration contains two alignments,; > + // one of which contains a large gap, and since the gap split happens after the configuration scoring,; > I agree it is backwards. But...; > ; > The reason was that the (naive) alignment configuration scoring module rightnow uses MQ and AS (aligner score) for picking the ""best"" configuration (i.e. sub-list of the alignments given by aligner), which would be technically wrong if we were to split the gap and to simply grab the originating alignment's values.; > ; > This is especially true for AS, whose recomputing takes more time, and code, and forces us to know how AS are computed in the aligner so that there's no bias in computing the scores of naive alignments vs gap-split alignments (may not matter in practice, but still takes more code to compute).; > ; > Lots of the code in the discovery stage was devoted actually to alignment related acrobatics and edge cases so that the breakpoints we could resolve are as accurate as possible.; > I've kept in mind your wisdom that different aligners may be experimented with, but it seems unlikely in the near future (their own quirkiness, lack of API for JNI, etc); it seems more and more likely to me that eventually it's inevitable to have a custom alignment m",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-350618009:1740,configurat,configuration,1740,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-350618009,4,['configurat'],['configuration']
Deployability,Master is broken. [E.g.](https://travis-ci.com/broadinstitute/gatk/jobs/227807624). ```; Fetched 217 kB in 1s (163 kB/s); Reading package lists...; W: http://ppa.launchpad.net/couchdb/stable/ubuntu/dists/trusty/Release.gpg: Signature by key 15866BAFD9BCC4F3C1E0DFC7D69548E1C17EAB57 uses weak digest algorithm (SHA1); W: GPG error: https://packagecloud.io/github/git-lfs/ubuntu trusty InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 6B05F25D762E3157; W: The repository 'https://packagecloud.io/github/git-lfs/ubuntu trusty InRelease' is not signed.; W: There is no public key available for the following key IDs:; 6B05F25D762E3157 . ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6116:211,Release,Release,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6116,1,['Release'],['Release']
Deployability,Matched gCNV pipeline arguments,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8234:13,pipeline,pipeline,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8234,1,['pipeline'],['pipeline']
Deployability,Matplotlib throws RuntimeError when Python is not installed as a framework,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4743:50,install,installed,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4743,1,['install'],['installed']
Deployability,May I pass on this? I would like to devote my non-M2 extracurricular time to fixing assembly issues in HC before the 4.1 release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5532#issuecomment-447985785:121,release,release,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5532#issuecomment-447985785,1,['release'],['release']
Deployability,Maybe @vruano is a good person to review so we spread some knowledge of the joint calling pipeline.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6757#issuecomment-705176631:90,pipeline,pipeline,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6757#issuecomment-705176631,1,['pipeline'],['pipeline']
Deployability,Maybe combineReports should be renamed to updateCountsForPair? Would that be better?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5883#issuecomment-484644408:42,update,updateCountsForPair,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5883#issuecomment-484644408,1,['update'],['updateCountsForPair']
Deployability,"Maybe it would be better to pair this with the upcoming Java 17 upgrade, so that we don't have to explicitly check the Java version? What do you think @cmnbroad ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8111#issuecomment-1331261667:64,upgrade,upgrade,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8111#issuecomment-1331261667,1,['upgrade'],['upgrade']
Deployability,MeanQualityByCycleSpark integration test fails on ADAM files with setHeaderStrict,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1540:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1540,1,['integrat'],['integration']
Deployability,"Mention in README that ""clean"" should be run before ""installSpark""/""sparkJar"", since gatk-launch cannot currently handle multiple spark jars in build/libs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1317:53,install,installSpark,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1317,1,['install'],['installSpark']
Deployability,Merge changes from master onto our version of gatk Dockerfile. Running integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/35dd363a-b140-47c7-ad69-7e5297a6ff10),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8801:71,integrat,integration,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8801,1,['integrat'],['integration']
Deployability,Merge changes from the EchoCallset branch back into our main branch ('ah_var_store'). Most of these changes are VDS creation related. Passing Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f5cb7a2d-b224-4b8e-8daf-2d22939a1d96),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8993:142,Integrat,Integration,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8993,1,['Integrat'],['Integration']
Deployability,"MergeBamAlignment is run on each readgroup seperately, currently MarkDuplicates is used to aggregate all the readgroups. I tried finding a nice graph type thing showing the dependencies of the workflow but couldn't find anything :(. But here is where MBA is run on each readgroup (the output of BWA gets streamed into MBA) - https://github.com/gatk-workflows/five-dollar-genome-analysis-pipeline/blob/master/tasks_pipelines/unmapped_bam_to_aligned_bam.wdl#L113. and here is markduplicates taking in each aligned MBA'd readgroup bam as input ( this is outside the per readgroup scatter) - https://github.com/gatk-workflows/five-dollar-genome-analysis-pipeline/blob/master/tasks_pipelines/unmapped_bam_to_aligned_bam.wdl#L157",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5398#issuecomment-438050467:387,pipeline,pipeline,387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5398#issuecomment-438050467,2,['pipeline'],['pipeline']
Deployability,Merging now. I added an issue to track adding in more integration tests: #7523,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7513#issuecomment-951250845:54,integrat,integration,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7513#issuecomment-951250845,1,['integrat'],['integration']
Deployability,"Merging this now despite the ADAM situation, as we need to update to htsjdk 2.8.0 for a critical NIO bug fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2247#issuecomment-265773849:59,update,update,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2247#issuecomment-265773849,1,['update'],['update']
Deployability,"Merging this now to have usable VCF NIO support in master -- continuous tests to prove that the wrapper is applied will be added in a separate PR, but my ad-hoc tests on the latest version of this branch suggest it's working fine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2393#issuecomment-277697090:61,continuous,continuous,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2393#issuecomment-277697090,2,['continuous'],['continuous']
Deployability,"Methods team has updated how we structure our own buckets. `${prefix}/${user}` to `${prefix}-${user}`. Updating scripts to reflect that, and to avoid zombie buckets.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6114:17,update,updated,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6114,1,['update'],['updated']
Deployability,"Might be a dupe of https://github.com/broadinstitute/gatk/issues/4375 (note the date...). Continuing our discussion on Slack, we could add some tests on the simulated data that are suitably insensitive to numerical instability, but still check for whatever events may happen to be in the simulated data. I'm not sure if there's a record of the latter, as I would guess the data was generated with an external python script, but I suppose you could always just take what is currently output by the test as the expected result. There is some cost associated with adding, running, and maintaining such tests, and I'll leave it up to you and @mwalker174 to decide whether it's worth it. For the record, I think our intention was always that correctness would be covered at the pipeline level on suitably large data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6893#issuecomment-709572384:773,pipeline,pipeline,773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6893#issuecomment-709572384,1,['pipeline'],['pipeline']
Deployability,Migrate FuncotateSegments to use Owner for its configuration files,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5963:47,configurat,configuration,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5963,1,['configurat'],['configuration']
Deployability,Migrate GATK engine to new configuration mechanism,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3081:27,configurat,configuration,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3081,1,['configurat'],['configuration']
Deployability,"Minimal GATK port of nvscorevariants from https://github.com/NVIDIA-Genomics-Research/nvscorevariants. The tool runs successfully in both 1D and 2D modes, and a strict integration test passes for the 1D model. However, this PR has a number of outstanding issues that need to be resolved before it can be merged and replace the legacy CNNScoreVariants tool:. - The conda environment in scripts/nvscorevariants_environment.yml needs to be incorporated into the main GATK conda environment. - The integration test for the 2D model does not currently pass, despite using a much higher epsilon than the 1D test. Some of the scores differ by significant amounts vs. the CNNScoreVariants 2D output. We need to investigate why this is. - There is currently no training tool to train a new model, like there is for the legacy CNN tool. @samuelklee and @mwalker174 , could you please comment on what it would take to incorporate the `scripts/nvscorevariants_environment.yml` conda environment into the main GATK conda environment, assuming we are free to remove/retire the CNN tool?. @lbergelson and @zamirai, please do a general code review when you get a chance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004:168,integrat,integration,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004,2,['integrat'],['integration']
Deployability,Minor AoU Documentation Update,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7999:24,Update,Update,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7999,1,['Update'],['Update']
Deployability,Minor Funcotator WDL updates.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6326:21,update,updates,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6326,1,['update'],['updates']
Deployability,Minor changes for updated VAT reference testing [VS-1054],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8670:18,update,updated,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8670,1,['update'],['updated']
Deployability,Minor update to AoU Documentation; Update to include link to Firecloud support script which can be used to upload sample sets without using the UI.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7994:6,update,update,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7994,2,"['Update', 'update']","['Update', 'update']"
Deployability,Minor updates to picard.sam package to reflect latest version.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/332:6,update,updates,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/332,1,['update'],['updates']
Deployability,Mitochondria Pipeline Tools,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5310:13,Pipeline,Pipeline,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5310,1,['Pipeline'],['Pipeline']
Deployability,Mock up an example configuration setup using Owner,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3126:19,configurat,configuration,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3126,1,['configurat'],['configuration']
Deployability,ModelSegments can currently deal with single sample segmentation. This branch contains the backend class (and the corresponding unit tests) that is able to segment based on multiple data samples. The updated version of the front-end class ModelSegments will be addressed in a different branch.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5524:200,update,updated,200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5524,1,['update'],['updated']
Deployability,ModelSegments integration test failures on newer Java 11 releases,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8107:14,integrat,integration,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8107,2,"['integrat', 'release']","['integration', 'releases']"
Deployability,"Modify CreateVariantIngestFiles to write missing ref intervals with the ZERO state, unless we are dropping that (ZERO) state and none other. Successful Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/0509cd35-50bc-431b-88c2-590e15cd3cc9)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8560:152,Integrat,Integration,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8560,1,['Integrat'],['Integration']
Deployability,"Modify GvsCreateVATFromVDS to take as an optional input the `sites_only_vcf` - if provided, the code bypasses the logic to create it from VDS.; This PR also modifies IndexVcf and SelectVariants to use localization_optional for their inputs. Updated Passing Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/760a8910-77a3-446e-b539-196663bbd90b); Rerun of GvsCreateVATFromVDS using a passed in sites_only VCF [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/9ca7d011-82f3-43a9-9161-1df0f7174fa9).; Rerun of GvsCreateVATFromVDS NOT using a passed in sites_only VCF [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/de8fae29-a904-40d1-849b-15ba84fa0a8f).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8851:241,Update,Updated,241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8851,2,"['Integrat', 'Update']","['Integration', 'Updated']"
Deployability,Modify GvsExtractCallset so that you can change the value of 'output_gcs_dir' as an input and it won't cause the extract to be re-run (won't invalidate call caching). Passing run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/a5fd0daf-8816-42e4-ad15-3aa432e2ed80).; Passing Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/3c874e74-4fdd-4cbb-af75-a44bb7e17ea1).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8960:319,Integrat,Integration,319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8960,1,['Integrat'],['Integration']
Deployability,"Modifying what I wrote earlier, got confused with another issue. I am not familiar with Lustre and Lustre configuration. Did the excessive file locking from Lustre(FUTEX_WAIT_PRIVATE?) go away with `--genomicsdb-shared-posixfs-optimizations`? . Is there anyway to configure Lustre buffer sizes for writing? If not, can you try setting environment variable TILEDB_UPLOAD_BUFFER_SIZE to something like 5242880(5M) and try `GenomicsDBImport`? Does it help with performance? Is the amount of file locking lower than before?. If the performance is still not acceptable... What version of gatk are you using? Can you use the latest gatk and try using the `--bypass-feature-reader` option with `GenomicsDBImport`? Does this help with performance?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7646#issuecomment-1039746554:106,configurat,configuration,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7646#issuecomment-1039746554,1,['configurat'],['configuration']
Deployability,More prep work for separating GVS code: remove references to GVS code from non-GVS code. Integration test currently running [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/2af93966-3c84-4aec-bc1e-82cb88478852).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8229:89,Integrat,Integration,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8229,1,['Integrat'],['Integration']
Deployability,More refactoring of Mark duplicates and pipeline hookup,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/770:40,pipeline,pipeline,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/770,1,['pipeline'],['pipeline']
Deployability,"Most are straightforward docker image swaps, with two exceptions. 1. GVSAsssignIDs was able to move to a much smaller docker image due to it not actually using GATK.; 2. GVSImportGenomes couldn't use an alpine docker image due to the -d option in split, so I got rid of the -d option. Turns out, it runs fine without it so I could update it to an alpine image.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8061#issuecomment-1282756152:331,update,update,331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8061#issuecomment-1282756152,1,['update'],['update']
Deployability,"Most of our integration tests use the non-UCSC convention. I would be shocked if that were the issue. If anyone reading this has the issue, feel free to re-open or post on the GATK forum.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4939#issuecomment-583804417:12,integrat,integration,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4939#issuecomment-583804417,1,['integrat'],['integration']
Deployability,"Most of the CRAM tests were added before we could write CRAM on Spark, so this fills out the CRAM write tests for the remaining Spark tools/pipelines (ApplyBQSRSpark, BQSRPipelineSpark and ReadsPipelineSpark). Also includes one totally opportunistic deletion of an unused zero-length fasta file.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1667:140,pipeline,pipelines,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1667,1,['pipeline'],['pipelines']
Deployability,"Most of the arguments in RecalibrationArgumentCollection are in the form ""mismatches_context_size"". This probably needs to be updated but it will have the consequence of invalidating existing BaseRecalibrator report tables and require the arguments get changed in all of the report tables checked in as test files.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3974:126,update,updated,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3974,1,['update'],['updated']
Deployability,"Most of these changes are to support automated evaluation of GATK CNV. - Updates SimpleAnnotatedGenomicRegion to use the collection framework used in other GATK CNV CLIs. CLIs (both experimental quality): ; - `TagGermlineEvents` is a simple tool that attempts to identify events in a tumor seg file that correspond to a germline events. ; - This is done purely with concordance on the breakpoints of the events (within some padding). ; - Input germline segments must have calls. ; - If a germline call is broken into multiple segments, this tool will handle that appropriately (ditto if there are multiple tumor segments overlapping the germline call); . - `MergeAnnotatedRegions` will merge all overlapping regions and resolve annotation value conflicts.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4205:73,Update,Updates,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4205,1,['Update'],['Updates']
Deployability,"Most of these changes are to support automated evaluation of GATK CNV. - Updates `AnnotatedIntervals` (formerly `SimpleAnnotatedGenomicRegion`) to use the tribble framework for reading. Writing is done in a way that should be concordant with a future tribble writing framework, as per discussion with @droazen.; - Changes to `XsvLocatableTableCodec` to support usage of arbitrary config files. This cannot be done when using tribble features in the CLI. Already reviewed with @jonn-smith . Support for SAM File headers and comments is included.; - *Note:* The reading of `AnnotatedIntervals` cannot be done automatically on the command line, unless the config file is a sibling. The tools below do not even attempt this, since the use cases involved will never have a sibling config file.; - Created a default config file in the jar file resources to read tsvs with locatable fields from the CNV collection files. This is much less strict than the framework used by the CNV tools. The reader will accept any columns (or subset of the columns). CLIs (both experimental quality): ; - `TagGermlineEvents` is a simple tool that attempts to identify events in a tumor seg file that correspond to a germline events. ; - This is done purely with concordance on the breakpoints of the events (within some padding). ; - Input germline segments must have calls. ; - If a germline call is broken into multiple segments, this tool will handle that appropriately (ditto if there are multiple tumor segments overlapping the germline call). - `MergeAnnotatedRegions` will merge all overlapping regions and resolve annotation value conflicts. Closes #3995",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4276:73,Update,Updates,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4276,1,['Update'],['Updates']
Deployability,"Most tools that write vcf outputs call `GATKTool.createVCFWriter(final File outFile)` because they use `File` arguments. Once https://github.com/broadinstitute/gatk/pull/5378 is merged, these calls should be replaced with calls to `GATKTool.createVCFWriter(final Path outFile)`, and then the `File` method can be removed. It would be nice if during the same pass we:. - Change the type of the `File` arguments with use the new `GATKUri` class.; - Integrated the use of `getDefaultToolVCFHeaderLines` use of for all the writers (see https://github.com/broadinstitute/gatk/issues/5493); - Tag each of these outputs as ""gcs-enabled"".",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5512:447,Integrat,Integrated,447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5512,1,['Integrat'],['Integrated']
Deployability,Mostly changing `use_classic_VQSR` to `use_VQSR_lite` with a couple of minor bugfixes thrown in. Successful integration run [here](https://app.terra.bio/#workspaces/gvs-dev/mlc%20GVS%20Quickstart%20v3/job_history/3e60bf43-5cc3-4e5b-97ad-1732b4c543be).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8360:108,integrat,integration,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8360,1,['integrat'],['integration']
Deployability,Move Funcotator integration test expected outputs out of large,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5379:16,integrat,integration,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5379,1,['integrat'],['integration']
Deployability,"Move NativeUtils.loadLibraryFromClasspath() to gatk-native-bindings, publish a new release, and make gatk-bwamem-jni and gatk-fermilite-jni implement NativeLibrary and call load() internally",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2408:83,release,release,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2408,1,['release'],['release']
Deployability,Move ReadFilter plugin integration up to GATKTool.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2218:23,integrat,integration,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2218,1,['integrat'],['integration']
Deployability,Move to using [GenomicsDB Release 1.5.0](https://github.com/GenomicsDB/GenomicsDB/releases/v1.5.0). ; Highlights in the release relevant to gatk are; - [readthedocs](https://genomicsdb.readthedocs.io/en/latest/) for GenomicsDB design/usage/functionality - GenomicsDB/GenomicsDB#265.; - GenomicsDB/GenomicsDB#284; - GenomicsDB/GenomicsDB#271; - Exclude spark from genomicsdb core jar GenomicsDB/GenomicsDB#281; - General improved performance/logging.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8358:26,Release,Release,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8358,3,"['Release', 'release']","['Release', 'release', 'releases']"
Deployability,Move to version [GenomicsDB 1.5.4](https://github.com/GenomicsDB/GenomicsDB/releases/tag/v1.5.4) for fix to PR #8415.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8987:76,release,releases,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8987,1,['release'],['releases']
Deployability,"Moved R dependencies to conda environment, cleaned up R/python dependencies, and updated base Docker/Travis configuration.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026:81,update,updated,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026,2,"['configurat', 'update']","['configuration', 'updated']"
Deployability,Moving classes that tests depend on from the test folders into the src folders in the utils.test package. This way they will be available to projects that depend on hellbender. Fixes #525 . Updating to the newest testng release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/527:220,release,release,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/527,1,['release'],['release']
Deployability,"Moving to [GenomicsDB 1.4.1 ](https://github.com/GenomicsDB/GenomicsDB/releases/tag/v1.4.1)release will allow for the direct use of the native GCS C++ client instead of the GCS Cloud Connector via HDFS. The GCS Cloud Connector can still be used with GenomicsDB via the `--genomicsdb-use-gcs-hdfs-connector` option. Using the native client with gcs allows for GenomicsDB to use the standard paradigms to help with authentication, retries with exponential backoff, configuring credentials, etc. The defaults are all hardcoded to match what is in gatk at present. It also helps with performance issues with gcs, see #7070. This version also contains fixes for #7089, although it will require additional support from gatk(will be part of a separate PR).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7224:71,release,releases,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7224,2,['release'],"['release', 'releases']"
Deployability,Moving us off of of the weird beta protobuf version to the newest 3.x release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6736:70,release,release,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6736,1,['release'],['release']
Deployability,Multipair WDL for somatic CNV pipeline.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2969:30,pipeline,pipeline,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2969,1,['pipeline'],['pipeline']
Deployability,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:1118,configurat,configuration,1118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716,1,['configurat'],['configuration']
Deployability,Must update `DataSourceUtils::assertPathFilePropertiesField` to allow for absolute paths / URI paths for the data sources supporting files.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5348#issuecomment-434452495:5,update,update,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5348#issuecomment-434452495,1,['update'],['update']
Deployability,"Mutect adopted natural logarithms in #5858. In the update, it looks like one base 10 log was missed. This PR updates the missed log.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6884:51,update,update,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6884,2,['update'],"['update', 'updates']"
Deployability,"Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_222-8u222-b10-1ubuntu1~18.04.1-b10; 16:46:49.699 INFO Mutect2 - Start Date/Time: November 6, 2019 4:46:49 PM CST; 16:46:49.699 INFO Mutect2 - ------------------------------------------------------------; 16:46:49.699 INFO Mutect2 - ------------------------------------------------------------; 16:46:49.699 INFO Mutect2 - HTSJDK Version: 2.15.1; 16:46:49.699 INFO Mutect2 - Picard Version: 2.18.2; 16:46:49.699 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:46:49.699 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:46:49.700 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:46:49.700 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:46:49.700 INFO Mutect2 - Deflater: IntelDeflater; 16:46:49.700 INFO Mutect2 - Inflater: IntelInflater; 16:46:49.700 INFO Mutect2 - GCS max retries/reopens: 20; 16:46:49.700 INFO Mutect2 - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 16:46:49.700 INFO Mutect2 - Initializing engine; 16:46:49.995 INFO FeatureManager - Using codec VCFCodec to read file file:///home/vip/data/Mutect2/af-only-gnomad.raw.sites.hg19.vcf.gz; 16:46:50.064 INFO Mutect2 - Shutting down engine; [November 6, 2019 4:46:50 PM CST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2394947584; org.broadinstitute.hellbender.exceptions.GATKException: Error initializing feature reader for path /home/vip/data/Mutect2/af-only-gnomad.raw.sites.hg19.vcf.gz; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:357); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:308); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:255); 	at org.broadinstitute",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6248:2499,patch,patch,2499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6248,1,['patch'],['patch']
Deployability,Mutect2 error when running inside a pipeline in parallel with intervals,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7059:36,pipeline,pipeline,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7059,1,['pipeline'],['pipeline']
Deployability,Mutect2 method updated versions should be reserved,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6001:15,update,updated,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6001,1,['update'],['updated']
Deployability,Mutect2: Update allele matching during active region detection,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7468:9,Update,Update,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7468,1,['Update'],['Update']
Deployability,"My first idea was to port it to ReadTools (that's why I asked to change it to the public code when GATK3 was divided into the non-free version and the plan was not to port indel-realignment). Nevertheless, someone showed interest into this and that's why I did this PRs; in addition, it is much better than the original authors (if still at Broad) can contribute to see if the port is correct. Anyway, I don't have any strong feeling about this, and I can always port the pipeline to ReadTools and maintain it there (actually, I had some ideas for other realignment methods and it will be interesting to compare with this). @cmnbroad - this was a long time ago, when even some of the standards (documentation and kebab-case arguments) were not even implemented. Regarding the tests, the last commit includes one using a BAM file in the repository, and the output was generated with GATK3 (if I remember correctly, although I can't remember the version). I think that the best way to go is to re-open a PR to have a cleaner history and proper standards. The idea will be:. 1. Copy of the GATK3 files (from the latest release); 2. Reformat (license and coding-style); 3. Port to the new framework.; 4. Convert documentation and arguments to the GATK4 format; 5. Add tests by running the latest GATK3 release on data in the repository and checking concordance. If a different dataset should be used for the tests, it will be nice if you can provide some. Otherwise, I will use data in the repository (b37_reference_20_21 and NA12878_20_21_WGS_bam)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363745763:472,pipeline,pipeline,472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363745763,3,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"My main issue now is that I need both a fix (or workaround) for https://github.com/broadinstitute/gatk/issues/6045 and an annotation engine that counts fragments rather than reads. What I am afraid of is that even if vruano finds a fix for the other bug, I would still need to have it backported to GATK 4.0.12.0 which is the latest release currently capable of counting fragments. I would be okay with just dropping evidence if necessary. Is there a way to drop one of two pair ended reads (regardless of whether they overlap or not) on the fly?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-527703598:333,release,release,333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-527703598,1,['release'],['release']
Deployability,"My test run has successfully finished. Awesome, @TedBrookings !. Two suggestions that you could decide when to address them:; 1. This script requires a lot of user interaction (gcloud update, whether to create a cluster, whether to copy results, whether to delete cluster), I could imagine this being inconvenient for some, so we could have some upfront arguments specifying answers to these questions when the script is launched.; 2. The bucket to which the results are copied is not overridable by caller of script. A user might want to copy the results to a specific location.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318925727:184,update,update,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318925727,1,['update'],['update']
Deployability,"N See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 09:14:26.202 INFO PrintReadsSpark - Shutting down engine; [June 8, 2017 9:14:26 AM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=494927872; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /user/yaron/output.bam because writing failed with exception /user/yaron/output.bam.parts/_SUCCESS: Unable to find _SUCCESS file. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file /user/yaron/output.bam because writing failed with exception /user/yaron/output.bam.parts/_SUCCESS: Unable to find _SUCCESS file; at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:255); at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.runTool(PrintReadsSpark.java:37); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:4956,pipeline,pipelines,4956,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['pipeline'],['pipelines']
Deployability,N0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrLmphdmE=) | `90.909% <ø> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...ellbender/tools/spark/pipelines/FlagStatSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvRmxhZ1N0YXRTcGFyay5qYXZh) | `90% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountBasesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRCYXNlc1NwYXJrLmphdmE=) | `90% <ø> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/CountVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRWYXJpYW50c1NwYXJrLmphdmE=) | `90.909% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...lbender/tools/spark/pipelines/PrintReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRSZWFkc1NwYXJrLmphdmE=) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/5991/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.971% <0%> (+0.245%)` | `159% <0%> (ø)` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5991#issuecomment-500387504:2145,pipeline,pipelines,2145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5991#issuecomment-500387504,2,['pipeline'],['pipelines']
Deployability,NFO BwaAndMarkDuplicatesPipelineSpark - ------------------------------------------------------------; 11:01:49.336 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Version: 2.14.3; 11:01:49.336 INFO BwaAndMarkDuplicatesPipelineSpark - Picard Version: 2.18.2; 11:01:49.336 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:01:49.336 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:01:49.336 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 11:01:49.336 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:01:49.337 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 11:01:49.337 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 11:01:49.337 INFO BwaAndMarkDuplicatesPipelineSpark - GCS max retries/reopens: 20; 11:01:49.337 INFO BwaAndMarkDuplicatesPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 11:01:49.337 WARN BwaAndMarkDuplicatesPipelineSpark - ; ```; - (GATK) v4.0.4.0-23-g6e1cc8c-SNAPSHOT; ```; Using GATK jar /gatk/build/libs/gatk-spark.jar; Running:; /spark//bin/spark-submit --master spark://973f3a3a3407:7077 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.exec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:16807,patch,patch,16807,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['patch'],['patch']
Deployability,NFO BwaAndMarkDuplicatesPipelineSpark - ------------------------------------------------------------; 16:33:45.590 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Version: 2.14.3; 16:33:45.590 INFO BwaAndMarkDuplicatesPipelineSpark - Picard Version: 2.17.2; 16:33:45.590 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:33:45.590 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:33:45.590 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 16:33:45.590 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:33:45.590 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:33:45.591 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:33:45.591 INFO BwaAndMarkDuplicatesPipelineSpark - GCS max retries/reopens: 20; 16:33:45.591 INFO BwaAndMarkDuplicatesPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 16:33:45.591 WARN BwaAndMarkDuplicatesPipelineSpark - ; ```; - (GATK) v4.0.4.0. ```; Using GATK jar /gatk/gatk-package-4.0.4.0-spark.jar; Running:; /spark//bin/spark-submit --master spark://926a0516ccf6:7077 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverh,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:13081,patch,patch,13081,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['patch'],['patch']
Deployability,NFO GenomicsDBImport - HTSJDK Defaults.CREATE_MD5 : false; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.CUSTOM_READER_FACTORY :; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.REFERENCE_FASTA : null; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793:4316,Configurat,Configuration,4316,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793,1,['Configurat'],['Configuration']
Deployability,NFO GenomicsDBImport - Start Date/Time: 17 July 2018 17:01:47 BST; 17:01:47.523 INFO GenomicsDBImport - ------------------------------------------------------------; 17:01:47.523 INFO GenomicsDBImport - ------------------------------------------------------------; 17:01:47.523 INFO GenomicsDBImport - HTSJDK Version: 2.14.3; 17:01:47.523 INFO GenomicsDBImport - Picard Version: 2.18.2; 17:01:47.523 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:01:47.523 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:01:47.523 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:01:47.523 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:01:47.523 INFO GenomicsDBImport - Deflater: IntelDeflater; 17:01:47.523 INFO GenomicsDBImport - Inflater: IntelInflater; 17:01:47.523 INFO GenomicsDBImport - GCS max retries/reopens: 20; 17:01:47.523 INFO GenomicsDBImport - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:01:47.524 INFO GenomicsDBImport - Initializing engine; 17:01:47.959 INFO IntervalArgumentCollection - Processing 3362775 bp from intervals; 17:01:47.984 INFO GenomicsDBImport - Done initializing engine; Created workspace /mnt/chla/outputsb.workspace; 17:01:48.120 INFO GenomicsDBImport - Vid Map JSON file will be written to outputsb.workspace/vidmap.json; 17:01:48.120 INFO GenomicsDBImport - Callset Map JSON file will be written to outputsb.workspace/callset.json; 17:01:48.120 INFO GenomicsDBImport - Complete VCF Header will be written to outputsb.workspace/vcfheader.vcf; 17:01:48.120 INFO GenomicsDBImport - Importing to array - outputsb.workspace/genomicsdb_array; 17:01:48.136 INFO ProgressMeter - Starting traversal; 17:01:48.136 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 17:01:48.250 INFO GenomicsDBImport - Importing batch 1 with ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5064:2625,patch,patch,2625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5064,1,['patch'],['patch']
Deployability,"NIO can now do this, as of [pull request #3869](https://github.com/googleapis/google-cloud-java/pull/3869) (Nov 27, 2018). This is included in gcloud-java versions [v0.73.0](https://github.com/googleapis/google-cloud-java/releases/tag/v0.73.0) onward.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5306#issuecomment-471620009:222,release,releases,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5306#issuecomment-471620009,1,['release'],['releases']
Deployability,"NIO output support for SelectVariants. Tested like so:. ```; $ ./gatk SelectVariants \; --variant dbsnp_138.b37.excluding_sites_after_129.vcf \; --select-random-fraction 0.01 \; --output gs://mybucket/variants.vcf; $ gsutil ls -lh gs://mybucket/*.vcf; 23.38 MiB 2018-10-30T23:58:12Z gs://mybucket/variants.vcf; ```. Includes the required changes under the hood, plus test updates. This change also gives NIO support to **HaplotypeCaller**, so it can write its VCF to cloud storage. Also, fixes #2128.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378:372,update,updates,372,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378,1,['update'],['updates']
Deployability,"NScoreVariants - Start Date/Time: August 13, 2018 11:29:43 AM UTC; 11:29:43.469 INFO CNNScoreVariants - ------------------------------------------------------------; 11:29:43.469 INFO CNNScoreVariants - ------------------------------------------------------------; 11:29:43.469 INFO CNNScoreVariants - HTSJDK Version: 2.16.0; 11:29:43.469 INFO CNNScoreVariants - Picard Version: 2.18.7; 11:29:43.469 INFO CNNScoreVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:29:43.470 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:29:43.470 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 11:29:43.470 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:29:43.470 INFO CNNScoreVariants - Deflater: IntelDeflater; 11:29:43.470 INFO CNNScoreVariants - Inflater: IntelInflater; 11:29:43.470 INFO CNNScoreVariants - GCS max retries/reopens: 20; 11:29:43.470 INFO CNNScoreVariants - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 11:29:43.470 WARN CNNScoreVariants -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CNNScoreVariants is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 11:29:43.470 INFO CNNScoreVariants - Initializing engine; 11:29:44.086 INFO FeatureManager - Using codec VCFCodec to read file file:///restricted/projectnb/casa/wgs.hg38/sv/gatk.cnn/vcf/adsp-5k.hg38.GATK.aws-batch_SNP_INDEL.chr22.4794samples.g.vcf.gz; 11:29:44.281 INFO CNNScoreVariants - Done initializing engine; 11:29:52.451 INFO CNNScoreVariants - Using key:CNN_1D for CNN architecture:/tmp/farrell/1d_cnn_mix_train_full_bn.3573521081782697200.json and weights:/tmp/farrell/1d_cnn_mix_train_full_bn.1075881893743930029.hd5; 11:29:54.959 INFO ProgressMeter - Starting traversal; 11:29:54.960 INFO ProgressMeter - Current Locus Elapsed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5101:2523,patch,patch,2523,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5101,1,['patch'],['patch']
Deployability,NV WDL tests. commit 5466b806e36df16cad2d045be074e7f9afec0957; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 16:38:15 2017 -0500. fixed arg issues in somatic WDL; exposed all missing args to java side; major update to germline WDLs; all optional python args exposed to WDLs as optional args. commit 50cb6fd08de15469a9080cbb27ff30c8b7ee7e21; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:50:45 2017 -0500. missing serialVersionUID. commit 5f0f31eab63b0e6f6105708ded7f86c96c830781; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:35:33 2017 -0500. annotated intervals kebab case; updated germline WDL workflows. commit 29cc6234dbfb8db12559217a650c6ceb170c5797; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:15:28 2017 -0500. cleanup test files. commit 08a35bb4e65eceb735adcd41a91132e9a34d2b66; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 02:50:19 2017 -0500. update WDL scripts. commit 12bcfa192ee6fa6da21239ebf5b513633efe974f; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 02:47:33 2017 -0500. significant updates to GermlineCNVCaller; integration tests for GermlineCNVCaller w/ sim data in both run modes. commit 151416a4af735ca721bd75e4b54a780c17ac9397; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 01:42:05 2017 -0500. hybrid ADVI abstract argument collection w/ flexible default values; hybrid ADVI argument collection for contig ploidy model; hybrid ADVI argument collection for germline denoising and calling model. commit 56e21bf955d3dc0c52aceb384f28cf6173959de0; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 23:18:39 2017 -0500. rewritten python-side coverage metadata table reader using pandas to fix the issues with comment line; change criterion for cohort/case based on whether a contig-ploidy model is provided or not; simulated test files for ploidy determination tool; proper,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:6719,update,update,6719,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['update'],['update']
Deployability,NVCaller - HTSJDK Defaults.CREATE_MD5 : false; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.CUSTOM_READER_FACTORY : ; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.REFERENCE_FASTA : null; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 23:37:00.976 DEBUG ConfigFactory - Configuration file values: ; 23:37:00.982 DEBUG ConfigFactory - gcsMaxRetries = 20; 23:37:00.982 DEBUG ConfigFactory - gcsProjectForRequesterPays = ; 23:37:00.982 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 23:37:00.982 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 23:37:00.982 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 23:37:00.982 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 23:37:00.983 DEBUG ConfigFactory - samjdk.compression_level = 2; 23:37:00.983 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 23:37:00.983 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 23:37:00.983 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 23:37:00.983 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 23:37:00.983 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 23:37:00.983 DEBUG ConfigFactory - spark.driver.extraJavaOptions = ; 23:37:00.983 DEBUG ConfigFactory - spark.execut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:3764,Configurat,Configuration,3764,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,1,['Configurat'],['Configuration']
Deployability,NVCaller - HTSJDK Defaults.CREATE_MD5 : false; 23:43:52.471 INFO GermlineCNVCaller - HTSJDK Defaults.CUSTOM_READER_FACTORY : ; 23:43:52.471 INFO GermlineCNVCaller - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 23:43:52.471 INFO GermlineCNVCaller - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 23:43:52.471 INFO GermlineCNVCaller - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.REFERENCE_FASTA : null; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 23:43:52.472 DEBUG ConfigFactory - Configuration file values: ; 23:43:52.474 DEBUG ConfigFactory - 	gcsMaxRetries = 20; 23:43:52.474 DEBUG ConfigFactory - 	gcsProjectForRequesterPays = ; 23:43:52.474 DEBUG ConfigFactory - 	gatk_stacktrace_on_user_exception = false; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.use_async_io_read_samtools = false; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.use_async_io_write_samtools = true; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.use_async_io_write_tribble = false; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.compression_level = 2; 23:43:52.474 DEBUG ConfigFactory - 	spark.kryoserializer.buffer.max = 512m; 23:43:52.474 DEBUG ConfigFactory - 	spark.driver.maxResultSize = 0; 23:43:52.474 DEBUG ConfigFactory - 	spark.driver.userClassPathFirst = true; 23:43:52.474 DEBUG ConfigFactory - 	spark.io.compression.codec = lzf; 23:43:52.474 DEBUG ConfigFactory - 	spark.executor.memoryOverhead = 600; 23:43:52.475 DEBUG ConfigFactory - 	spark.driver.extraJavaOptions = ; 23:43:52.475 DEBUG ConfigFactory - 	spa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8938:2826,Configurat,Configuration,2826,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8938,1,['Configurat'],['Configuration']
Deployability,Name Dataflow pipelines,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/684:14,pipeline,pipelines,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/684,1,['pipeline'],['pipelines']
Deployability,Namely MultidimensionalKernelSegmenterUnitTest and ModelSegmentsIntegrationTest. Note that the Cromwell tests already essentially serve as integration tests and that the pipeline has already been through several preliminary evaluations without any issues.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3916:139,integrat,integration,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3916,2,"['integrat', 'pipeline']","['integration', 'pipeline']"
Deployability,Need additional VQSR integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2290:21,integrat,integration,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2290,1,['integrat'],['integration']
Deployability,"Need some guidance here. The CompareSAMs tool was not propagating the validation stringency. I have a fix for that, but that alone doesn't fix the compareBAMFiles test in BaseRecalibrationIntegrationTest.java, since that uses SamAssertionUtils.assertSamsEqual, which also doesn't propagate (or accept) a validation stringency. Changing SamAssertionUtils to use either SILENT or LENIENT does fix the integration test, and all the other tests pass, but it seems like a relaxing of the stringency, and I'm not sure it should be necessary to the BQSR test. If relaxing the stringency for BQSR test _IS_ the right path, one possibility is to add a new method to SamAssertionUtils that accepts a validation stringency argument.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/419#issuecomment-109796266:399,integrat,integration,399,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419#issuecomment-109796266,1,['integrat'],['integration']
Deployability,Need to cleanup the documentation in Funcotator prior to the GATK 4.0 release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4021:70,release,release,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4021,1,['release'],['release']
Deployability,Need to look at how to version the releases of data sources and individual data sources. This is exemplified with the dbSNP `common` vs dbSNP `All` problem.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4582:35,release,releases,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4582,1,['release'],['releases']
Deployability,"Needed two commits because I forgot to check the integration test the first go-round and I had changed parameter args. Sorry!; Github is complaining that there are conflicts, but since local git is fine, I'm assuming that just means I need to rebase before any merge and I should ignore that for now?. Back to you @cwhelan @davidbenjamin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-396709375:49,integrat,integration,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-396709375,1,['integrat'],['integration']
Deployability,Never mind -- refseq to the rescue. I'm working on a patch now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023359171:53,patch,patch,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023359171,1,['patch'],['patch']
Deployability,"New tool aiming to call all types of precise variants detectable by long read alignments (not fully functioning yet in the sense that not all types of variants are detected yet&mdash;to be handled by later PRs in this series).; This new tool splits the input long reads by scanning their alignment characteristics (number of alignments, if strand switch is involved, if mapped to the same chromosome, if have equally good alignment configurations based on the scoring tool, etc), and send them down different code path/logic units for variant type inference and VCF output.; This PR would only deal with simple INSDEL, for long reads having exactly 2 alignments (no other equally good alignment configuration) mapped to the same chromosome without strand switch or order switch (translocation or large tandem duplications), because we already have this type of variant covered in master. __UPDATE__; See updated roadmap in #2703. NEEDS TO WAIT UNTIL PART 1 IS IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3456:432,configurat,configurations,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3456,3,"['configurat', 'update']","['configuration', 'configurations', 'updated']"
Deployability,New: GroundTruthScorer; Update: FlowFeatureMapper,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8579:24,Update,Update,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8579,1,['Update'],['Update']
Deployability,"Next I set out to determine whether hellbender is slowing down on the larger interval simply because there is more data / a longer traversal, or because it's slower at processing the `1:1-10000000` interval than the `1:10000000-20000000` interval. And surprisingly, it appears that the latter is the case:. Time to process the `1:1-10000000` interval across two runs:. ```; GATK3: 5m25.983s 5m31.913s; HB: 6m2.156s 5m59.804s; ```. (Recall that HB was ~5% faster than GATK3 at processing the `1:10000000-20000000` interval). Moreover, our newly-installed progress meter shows that the rate at which we process records is unusually low at the start of the `1:1-10000000` interval, but is consistent throughout the processing of the `1:10000000-20000000` interval:. HB processing rate over 1:1-10000000:. ```; 14:22:19.520 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 14:22:29.522 INFO ProgressMeter - 1:769026 0.2 133000 797920.2; 14:22:39.531 INFO ProgressMeter - 1:1066133 0.3 298000 893553.2; 14:22:49.544 INFO ProgressMeter - 1:1389358 0.5 471000 941247.0; 14:22:59.572 INFO ProgressMeter - 1:1695902 0.7 636000 952785.2; 14:23:09.601 INFO ProgressMeter - 1:1961884 0.8 808000 968031.8; 14:23:19.636 INFO ProgressMeter - 1:2264803 1.0 985000 983099.3; 14:23:29.637 INFO ProgressMeter - 1:2583326 1.2 1162000 994352.2; 14:23:39.694 INFO ProgressMeter - 1:2817177 1.3 1297000 970638.9; 14:23:49.705 INFO ProgressMeter - 1:3095124 1.5 1467000 975993.8; 14:23:59.726 INFO ProgressMeter - 1:3372416 1.7 1637000 980190.6; 14:24:09.734 INFO ProgressMeter - 1:3678706 1.8 1810000 985355.8; 14:24:19.777 INFO ProgressMeter - 1:4087198 2.0 1984000 989880.0; 14:24:29.813 INFO ProgressMeter - 1:4341518 2.2 2165000 996983.7; 14:24:39.822 INFO ProgressMeter - 1:4598153 2.3 2350000 1004975.0; 14:24:49.834 INFO ProgressMeter - 1:4859664 2.5 2530000 1009892.7; 14:24:59.838 INFO ProgressMeter - 1:5103960 2.7 2712000 1014982.7; 14:25:09.887 INFO ProgressMeter - 1:5341742 ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1032#issuecomment-150660236:544,install,installed,544,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1032#issuecomment-150660236,1,['install'],['installed']
Deployability,Next minor GATK release?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7322:16,release,release,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7322,1,['release'],['release']
Deployability,"No - you should use GenomicsDB as the input to GenotypeGVCFs. My suggestion to use SelectVariants was only a debugging step to check whether GenomicsDB included the expected input data. Also, I misread your original post -- your GVCFs have literally 109 sites? And the interval list/bed file has 109 sites, not 109 regions? I would strongly recommend using a single interval in that case. Having a subfolder for each site will lead to a lot of unnecessary overhead. Lastly, I would recommend upgrading to a newer GATK. 4.1.8.0 is exactly 2 years old it seems...there's been quite a few changes/updates since then. edit: and to resolve why the number of subfolders in the workspace don't match the lines in the bed file -- my guess is that some of the sites in the bed file are abutting each other. The default behavior in these cases is to merge these into a single interval. Look at [--interval-merging-rule](https://gatk.broadinstitute.org/hc/en-us/articles/5358869876891-GenomicsDBImport#--interval-merging-rule) for more information",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7952#issuecomment-1196224025:594,update,updates,594,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7952#issuecomment-1196224025,1,['update'],['updates']
Deployability,"No additional changes that might affect the `HaplotypeCaller` output are slated to be merged before the 4.1 release tomorrow, so today would be a good time to get this one in @ldgauthier @davidbenjamin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5484#issuecomment-458251853:108,release,release,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5484#issuecomment-458251853,1,['release'],['release']
Deployability,No further comments here. Looking forward to integrating this into PathSeq.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2367#issuecomment-276202293:45,integrat,integrating,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2367#issuecomment-276202293,1,['integrat'],['integrating']
Deployability,"No longer draft, but this PR requires an htsjdk update for the test to pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7066#issuecomment-775180228:48,update,update,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7066#issuecomment-775180228,1,['update'],['update']
Deployability,"No problem @ruqianl, thanks again for bringing it to our attention! The fix will be included in the official Docker image in the next release; however, I'm not sure if that will happen imminently, as the last release occurred just 18 days ago and there have only been 10 additional commits in the meantime. @droazen may have a better timeline for you. I believe there are some nightly Docker builds at https://hub.docker.com/r/broadinstitute/gatk-nightly/, so give it enough time and this fix should show up there (if it hasn't already).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7411#issuecomment-900495188:134,release,release,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7411#issuecomment-900495188,2,['release'],['release']
Deployability,"No problem adding hasEnd()... but can you break down what SV types have it which don't .... . *BUT* I think is important to consider here what ""end"" means in reality.. I think that ""end"" here should be the last position continuously overlapped by the variant from its start position. So for insertions, translocations and bnds, typically it would be set equal to start. . Think about ""start"" itself.... it does not make reference to the first overlapped based but the ones before it. If a BND would not have an ""end"" why should it have an ""start""?. I think start-end is just defined to what is practical for the sake of working with VCFs. What do you think? @SHuang-Broad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325025262:220,continuous,continuously,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325025262,1,['continuous'],['continuously']
Deployability,"No update from the user, sent them a reminder just now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-696424744:3,update,update,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-696424744,1,['update'],['update']
Deployability,"No update, sorry. The PRs are pending of review, and the data is still not available for proper testing...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-361892345:3,update,update,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-361892345,1,['update'],['update']
Deployability,No updates for this issue? ; These warnings are pretty annoying and often useless because they don't give any info about the specific location that causes warning (at least that's the case for `StrandBiasBySample` warning).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3828#issuecomment-598529852:3,update,updates,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3828#issuecomment-598529852,1,['update'],['updates']
Deployability,No waivers! ;) . I updated the wiki with a note about the PHP functionality (anticipating the merge of your PR slightly) and describing the outputs a tad more. . @droazen Are we ok to merge this or holding off on everything until tests run again?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311126776:19,update,updated,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311126776,1,['update'],['updated']
Deployability,"No worries, @rklein2, thanks for the update. I can do the first round of changes, and we may make some more after @mwalker174 reviews. In any case, we'll circle back to you for a final review, which you can do whenever is convenient---no rush on our end to get this in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6545#issuecomment-621243245:37,update,update,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6545#issuecomment-621243245,1,['update'],['update']
Deployability,"Normally one provides passing workflow runs with a PR. For the integration run [that is here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/ab86fb6d-c5d6-48b6-8322-923af691751c). There's also a ""real"" run taking place using this branch [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/db59d5b8-e2ac-4619-9563-aa5631bf053c). However for testing correctness of these changes with respect to the requester pays flag, my pet ""does not have serviceusage.services.use access to the Google Cloud project"". I therefore present instead a [run with my changes](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/9e712055-f466-4929-b6eb-5306f3cde1a0) that fails in exactly the same way as a [run without my changes](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/185506f5-9dc1-4c02-997d-6fe3f5695259).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8552:63,integrat,integration,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8552,1,['integrat'],['integration']
Deployability,Not critical for this week's release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5835#issuecomment-476327874:29,release,release,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5835#issuecomment-476327874,1,['release'],['release']
Deployability,"Not ready for merge as this relies on https://github.com/HadoopGenomics/Hadoop-BAM/pull/136, hence a new Hadoop-BAM release. Addresses https://github.com/broadinstitute/gatk/issues/2572 and https://github.com/broadinstitute/gatk/issues/2571",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3369:116,release,release,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3369,1,['release'],['release']
Deployability,"Not ready for merge yet! Needs tests + some additional fixes for `AnalyzeCovariates`. The basic `BaseRecalibrator` -> `ApplyBQSR` pipeline with a custom covariate seems to be working, however. @takutosato please try this branch out with your new homopolymer covariate and let me know whether it works! Feel free to grab some time on my calendar next week for help working through any issues.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4688#issuecomment-383229944:130,pipeline,pipeline,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4688#issuecomment-383229944,1,['pipeline'],['pipeline']
Deployability,"Not that I know of: https://github.com/samtools/htsjdk/releases. https://github.com/samtools/htsjdk/pull/848 was merged on April 8, 2017 and the last htsjdk release was on February 21, 2017.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2753#issuecomment-304109160:55,release,releases,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2753#issuecomment-304109160,2,['release'],"['release', 'releases']"
Deployability,"Not the newest version of java, the newest version of GATK. Use java 8 and [Gatk 4.1.4.1](https://github.com/broadinstitute/gatk/releases/download/4.1.4.1/gatk-4.1.4.1.zip).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6384#issuecomment-575718095:129,release,releases,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6384#issuecomment-575718095,1,['release'],['releases']
Deployability,"Not yet @ptranvan. @kgururaj and his team have a patch coming soon to add multi-interval support to this tool, so there's a good chance it will make it into a GATK release this month.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3269#issuecomment-371176755:49,patch,patch,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3269#issuecomment-371176755,2,"['patch', 'release']","['patch', 'release']"
Deployability,Not yet. haven't released genomicsdb version 0.6.3-proto-3.0.0-beta-1. Will let you know once its done.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2733#issuecomment-302816420:17,release,released,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2733#issuecomment-302816420,1,['release'],['released']
Deployability,"Note separate method configuration, but uses the same WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362811803:21,configurat,configuration,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362811803,1,['configurat'],['configuration']
Deployability,"Note that before this is merged, we'll need to do a datasource release in which the following property is added to the gencode config files:. ```; # Required field for GENCODE files.; # NCBI build version:; ncbi_build_version = X; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5522#issuecomment-447141409:63,release,release,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5522#issuecomment-447141409,1,['release'],['release']
Deployability,"Note that there is an AnnotateIntervals tool in the CNV pipeline (awaiting review in sl_denoising) that will output a TSV with column headers CONTIG, START, END, and GC_CONTENT. It takes -L, which can do the padding for you. If this doesn't exactly fit the bill for you, then it's probably best if you roll your own implementation rather than modify or refactor that code---should be easy enough.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3859#issuecomment-345807469:56,pipeline,pipeline,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3859#issuecomment-345807469,1,['pipeline'],['pipeline']
Deployability,"Note that we could probably extract some code for reading and subsetting read counts for both DetermineGermlineContigPloidy and GermlineCNVCaller, see related issue #4004. There is also some duplication in the integration-test code, which is probably not worth cleaning up. @ldgauthier would you mind reviewing?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5307#issuecomment-430629093:210,integrat,integration-test,210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5307#issuecomment-430629093,1,['integrat'],['integration-test']
Deployability,"Note to self: once this is reviewed, the GATKPath copy constructor changes made here should be propagated to the` HtsPath` class in htsjdk (hopefully before the next htsjdk release), since those will need to be reflected in GATK PR https://github.com/broadinstitute/gatk/pull/6763 once its rebased on the changes in this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6718#issuecomment-700919440:173,release,release,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6718#issuecomment-700919440,1,['release'],['release']
Deployability,"Note to self: the gcloud API changes a bit with the new release, apply the changes in [jp_gcloud_17_snapshot](https://github.com/broadinstitute/gatk/tree/jp_gcloud_17_snapshot) to adapt.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2822#issuecomment-306241927:56,release,release,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2822#issuecomment-306241927,1,['release'],['release']
Deployability,"Note: This branch is still blocked on several changes in Picard (https://github.com/broadinstitute/picard/pull/1236, and possibly https://github.com/broadinstitute/picard/pull/1245), once those are resolved and released then this branch should hopefully get the stamp of approval from @takutosato. * Added optical/library duplicate marking of reads (note: this does not include library tagging); * Added the ability to remove reads from the output bam based on their duplicate marking status. Resolves #4675 ; Resolves #5377",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5377:211,release,released,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5377,1,['release'],['released']
Deployability,"Notebook documenting the _actual_ creation of this VDS here:; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/analysis/launch/Make%20a%20VDS%20with%20Quickstart.ipynb?mode=edit. This VDS (well I made two, one with VQSR and one with VETS) can then be used for a tie out in the near future with the WDL pipeline for VDS creation. gs://fc-eada2674-7c2b-42a6-8db3-0246872596dc/quickstart-vds-for-wdl-tieout/VQSR-Classic/vds/. gs://fc-eada2674-7c2b-42a6-8db3-0246872596dc/quickstart-vds-for-wdl-tieout/VETS/vds/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8513:313,pipeline,pipeline,313,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8513,1,['pipeline'],['pipeline']
Deployability,"Notes:. - Classes in hellbender/tools/picard/analysis/artifacts are removed and replaced with Picard versions (except Transition, which is not public in Picard).; - GATK version of GatherVcfs is retained, and the Picard version is masked out - is this what we want ?; - The non-Spark GATK metrics tools have been removed and replaced with the Picard versions. The test data is retained (but moved) since its used by the Spark metrics tool tests. Additional changes we'll want to make separately to minimize the complexity of this PR:; - Eliminate the download of picard.jar from the GATK WDL tests and update the WDL to run Picard tools through GATK.; - Unify and merge the Picard and GATK program groups. These are similar, but not identical, and the combined result has artificial/duplicate groups.; - Normalize the confusing mix of Alpha/Beta/Experimental tags and comments.; - Add unified doc and tab-completion tasks that include Picard.; - Remove and replace SamComparison and Transition classes with the Picard versions.; - Fix GATK CompareBaseQualities (its a PicardCommandLineProgram).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3620:602,update,update,602,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3620,1,['update'],['update']
Deployability,Now integration tested successfully [here](https://app.terra.bio/#workspaces/broad-firecloud-dsde/VS-415%20GVS%20Quickstart%20Default%20Extract%20Scatter/job_history/ff9d7466-79f1-4c96-a7b9-dd2354dc1c76).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7878#issuecomment-1147593213:4,integrat,integration,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7878#issuecomment-1147593213,1,['integrat'],['integration']
Deployability,"Now run with `--maxIndelSize 250`.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; 17:24:16.345 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:24:16 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:24:16.502 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.502 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:24:16.502 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:24:16.502 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:24:16.502 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:24:16.503 INFO LeftAlignAndTrimV",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543:342,install,install,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543,3,['install'],['install']
Deployability,Now that ADAM 0.18 has been released. Fixes #957.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1059:28,release,released,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1059,1,['release'],['released']
Deployability,"Now that I look at https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer it will take a bit of work to get up to date (it was tied to a particular version of cromwell-tools and Advisor, which is python2-based, has not been actively maintained---exactly why I wanted to move to a more well supported solution...). . If it's not too much trouble, I'll try to get everything running locally on this older stuff for the first round of optimization, but this problem is probably a perfect candidate for the Neptune-based solution that @dalessioluca recently finished at https://github.com/dalessioluca/cromwell_for_ML.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710153874:81,pipeline,pipeline-optimizer,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710153874,1,['pipeline'],['pipeline-optimizer']
Deployability,"Now that htsjdk has support for indexed block-compressed FASTA, maybe the best approach is to add support also in GATK to allow this test resource to be smaller (and at the same time, check integration with other tools). @droazen - is there any plan to include support for bgzip FASTA in GATK soon? I can take that as a small project if you are interested, but I should plan it somehow to be sure about the rettirements in GATK to support them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5111#issuecomment-413436528:190,integrat,integration,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5111#issuecomment-413436528,1,['integrat'],['integration']
Deployability,"Now that we're using git lfs to manage our large test resources, we need to configure travis to install/init git lfs before running the test suite.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/840:96,install,install,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/840,1,['install'],['install']
Deployability,Now the Mutect2 WDL has all the hooks to run Funcotator (`Funcotator.wdl` was updated as well). The `Funcotate` task in the M2 WDL is identical to that same task in `Funcotator.wdl`. Fixes #5253,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5735:78,update,updated,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5735,1,['update'],['updated']
Deployability,"Now, it seems like calling `contaminationDownsampling` right after `retainEvidence` could cause problems if both methods remove reads. However, one might correctly point out that although the cache invalidation I mentioned is not handled systematically, the method `removeEvidenceByIndex` _does_ have some code to update the evidence by sample and the evidence index map. It's possible that this code is totally fine and that this lead is a dead end. However, the code looks like it could be simpler and it's tough to parse. For example, try to track the `to` variable, which determines the determination of the outer `for` loop:. ```; for (int etrIndex = 1, to = nextIndexToRemove, from = to + 1; to < newEvidenceCount; etrIndex++, from++) {; if (etrIndex < evidencesToRemove.length) {; nextIndexToRemove = evidencesToRemove[etrIndex];; evidenceIndex.remove(evidences.get(nextIndexToRemove));; } else {; nextIndexToRemove = oldEvidenceCount;; }; for (; from < nextIndexToRemove; from++) {; final EVIDENCE evidence = evidences.get(from);; evidences.set(to, evidence);; evidenceIndex.put(evidence, to++);; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6586#issuecomment-625030697:314,update,update,314,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6586#issuecomment-625030697,2,['update'],['update']
Deployability,"O ""$i"".snp.vcf.gz; gatk VariantFiltration -R $reference -V $path_BQSR/bqsr1.snp.vcf.gz -filter ""QD < 2.0"" --filter-name ""QD2"" -filter ""FS > 60.0"" --filter-name ""FS60"" -filter ""MQ < 40.0"" --filter-name ""MQ40"" -filter ""MQRankSum < -12.5"" --filter-name ""MQRankSum-12.5"" -filter ""ReadPosRankSum < -8.0"" --filter-name ""ReadPosRankSum-8.0"" -O $""i"".filtered.snp.vcf.gz; gatk SelectVariants -R $reference -V $""i"".filtered.snp.vcf.gz --exclude-filtered -O ""$i"".select.filtered.snp.vcf.gz; #INDEL; gatk SelectVariants -R $reference -V ""$i"".vcf.gz -select-type INDEL -O ""$i"".indel.vcf.gz; gatk VariantFiltration -R $reference -V ""$i"".indel.vcf.gz -filter ""QD < 2.0"" --filter-name ""QD2"" -filter ""FS > 200.0"" --filter-name ""FS200"" -filter ""ReadPosRankSum < -20.0"" --filter-name ""ReadPosRankSum-20"" -O ""$i"".filtered.indel.vcf.gz; gatk SelectVariants -R $reference -V ""$i"".filtered.indel.vcf.gz --exclude-filtered -O ""$i"".selected.filtered.indel.vcf.gz. gatk BaseRecalibrator -R $reference -I $i_bam -O grp1 --use-original-qualities --known-sites ""$i"".select.filtered.snp.vcf.gz --known-sites ""$i"".selected.filtered.indel.vcf.gz; gatk ApplyBQSR -R $reference -I $i_bam -O ""$i"".sorted.dedup.BQSR1.bam -bqsr grp1 --static-quantized-quals 10 --static-quantized-quals 20 --static-quantized-quals 30 --add-output-sam-program-record --create-output-bam-md5 --use-original-qualities; gatk ValidateSamFile -I ""$i"".sorted.dedup.BQSR.bam -O ""$i""_validateSamFile_of_bqsr_bam_file.out; samtools index ""$i"".sorted.dedup.BQSR.bam; done; gatk --java-options ""-Xmx30G"" HaplotypeCaller -R $reference -I sample1.sorted.dedup.BQSR.bam sample2.sorted.dedup.BQSR.bam sample3.sorted.dedup.BQSR.bam -O sample1_sample2_sample4.g.vcf.gz --tmp-dir tmp -ERC GVCF; ```. Secondly, how do I set the ploidy parameter for different samples in the population-based snp-calling?; Finally, for each taxa, there are some samples with relatively high sequence depth (> 10x). Is there any better choices for the snp-calling pipeline ??. Sincerely.; Jing",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8414:3217,pipeline,pipeline,3217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8414,1,['pipeline'],['pipeline']
Deployability,"O NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/yangyxt/software/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Aug 30, 2021 11:04:20 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:04:20.983 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------ ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.2.2.0 ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - Executing as yangyxt@paedyl02 on Linux v3.10.0-1160.11.1.el7.x86\_64 amd64 ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_152-release-1056-b12 ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - Start Date/Time: August 30, 2021 11:04:20 AM HKT ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------ ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------ ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - HTSJDK Version: 2.24.1 ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - Picard Version: 2.25.4 ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - Built for Spark Version: 2.4.5 ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.COMPRESSION\_LEVEL : 2 ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.USE\_ASYNC\_IO\_READ\_FOR\_SAMTOOLS : false. 11:04:20.984 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true ; ; 11:04:20.984 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false ; ; 11:04:2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444:2278,release,release-,2278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444,1,['release'],['release-']
Deployability,"O PedReader - Reading PED file /cromwell\_root/fc-47de7dae-e8e6-429c-b760-b4ba49136eee/resources/1kgp/1kgp\_trios.ped with missing fields: \[\] 19:35:29.854 INFO PedReader - Phenotype is other? true 19:35:32.686 INFO VariantEval - Creating 1881 combinatorial stratification states 19:35:32.742 INFO ProgressMeter - Starting traversal 19:35:32.742 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute 19:36:01.819 INFO VariantEval - Shutting down engine \[May 27, 2021 7:36:01 PM UTC\] org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval done. Elapsed time: 0.54 minutes. Runtime.totalMemory()=4964483072 java.lang.IndexOutOfBoundsException: Index: 1, Size: 1 at java.util.ArrayList.rangeCheck(ArrayList.java:653) at java.util.ArrayList.get(ArrayList.java:429) at org.broadinstitute.hellbender.utils.samples.MendelianViolation.isViolation(MendelianViolation.java:180) at org.broadinstitute.hellbender.utils.samples.MendelianViolation.updateViolations(MendelianViolation.java:122) at org.broadinstitute.hellbender.utils.samples.MendelianViolation.countFamilyViolations(MendelianViolation.java:148) at org.broadinstitute.hellbender.tools.walkers.varianteval.evaluators.MendelianViolationEvaluator.update1(MendelianViolationEvaluator.java:122) at org.broadinstitute.hellbender.tools.walkers.varianteval.util.EvaluationContext.apply(EvaluationContext.java:74) at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval.processComp(VariantEval.java:596) at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval.doApply(VariantEval.java:562) at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval$PositionAggregator.callDoApply(VariantEval.java:497) at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval$PositionAggregator.addVariant(VariantEval.java:478) at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval$PositionAggregator.access$100(VariantEval.java:469) at org.broadinstitut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7304:4134,update,updateViolations,4134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7304,1,['update'],['updateViolations']
Deployability,OK - I found where it was happening. This will be fixed along with the Funcotator Data Sources update.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6693#issuecomment-658288460:95,update,update,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6693#issuecomment-658288460,1,['update'],['update']
Deployability,"OK @droazen @davidbenjamin I think this is ready for review. Note that:. 1) I did not restore the optimization introduced by @davidbenjamin in #5466. Happy to file an issue to restore it later by adding the appropriate parameter check, if we think it's important.; 2) I only added integration tests for HC and M2, since there is only a minimal test for FilterAlignmentArtifacts at this time. But I would think that these tests are enough to show that the exposure preserves behavior (unless I somehow got extremely unlucky with the test data and parameter values...); 3) Apologies to the reviewer for the somewhat complicated commit history, which resulted from introducing/removing the TSV stuff and was more trouble than it might be worth to reorder/resolve in the final rebase. I think it would be easiest for the reviewer to look at the 4 ""bubbled up..."" commits separately when reviewing the exposure of each parameter set, but then look at the overall commit when reviewing more superficial things or the tests.; 4) I'd appreciate it if the reviewer double checked that I did not switch anything up in parameter names, doc strings, default values, etc. when introducing the 12 explicit args in AssemblyBasedCallerArgumentCollection. Lots of copying and pasting there and would be easy to screw things up, as you might imagine! Pretty sure the tests bear out that this was done correctly, but you never know. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-897081017:281,integrat,integration,281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-897081017,1,['integrat'],['integration']
Deployability,"OK it's up at [#2239](https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2239), please have a look. I've updated the code to retry when reopens are indicated (since the two don't overlap I take back that line about it retrying 40 times). This means that it'll be close to the level of aggressive that you tested with.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315479752:116,update,updated,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315479752,1,['update'],['updated']
Deployability,"OK so just following along; the problem appears related to the Google Cloud Storage Connector and its configuration. When running on Cloud we need to ask for the `https://www.googleapis.com/auth/devstorage.read_write` scope, as described in [the install docs](https://github.com/GoogleCloudPlatform/bigdata-interop/blob/master/gcs/INSTALL.md). But you're right that `https://www.googleapis.com/auth/cloud-platform` should imply that so it should work... The command line argument is `--scopes` (plural) and not `--scope` but that's probably not the issue, the tool would have complained if you actually typed `scope` in there. . Perhaps the code is trying to do the non-cloud setup and that's what's making it not work on cloud?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331047616:102,configurat,configuration,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331047616,3,"['INSTALL', 'configurat', 'install']","['INSTALL', 'configuration', 'install']"
Deployability,OK! There was a transient dependency that bumped the `commons-math3` version. I've just pushed an update that should fix this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356135455:98,update,update,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356135455,1,['update'],['update']
Deployability,"OK, I experimented a bit with removing the R install from the base image and adding the R dependencies to the conda environment in a branch and rebased on that. A few issues that I've run into or that came up in discussion with @jamesemery and @cmnbroad:. -I moved all tests that depend on R into the `python` test group (which should perhaps be renamed to `conda`). Note that some of these also fall into the `spark` test group---not sure if there is any special Spark setup done for that group, but we should make sure that they don't fail if they're not run with the conda environment. -@cmnbroad mentioned that some Picard tools that depend on R may break outside of the conda environment if the user does not have the R dependencies. -When we install R in the base image, we pull in a lot of basic dependencies (e.g., build-essential, various libraries and compilers, etc.) So when the R install is removed, it looks like many tests begin failing or hanging, perhaps because they are falling back on Java implementations (e.g., AVX PairHMM tests). We need to determine the dependencies for these tests and install them separately. Here is the list of packages that get pulled in by the R install: ```autoconf automake autotools-dev binutils bsdmainutils build-essential; bzip2-doc cdbs cpp cpp-5 debhelper dh-strip-nondeterminism dh-translations; dpkg-dev fakeroot g++ g++-5 gcc gcc-5 gettext gettext-base gfortran; gfortran-5 groff-base ifupdown intltool intltool-debian iproute2; isc-dhcp-client isc-dhcp-common libalgorithm-diff-perl; libalgorithm-diff-xs-perl libalgorithm-merge-perl libarchive-zip-perl; libasan2 libasprintf-dev libasprintf0v5 libatm1 libatomic1; libauthen-sasl-perl libblas-common libblas-dev libblas3 libbz2-dev; libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libcroco3 libcurl3; libdns-export162 libdpkg-perl libencode-locale-perl libfakeroot; libfile-basedir-perl libfile-desktopentry-perl libfile-fcntllock-perl; libfile-listing-perl libfile-mimeinfo-perl libfile-stripnon",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954:45,install,install,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954,6,['install'],['install']
Deployability,"OK, I think I figured out what was going on. In 9b194a6 I changed PreprocessIntervals to drop intervals with all Ns (if you remember, this was giving me NaNs in AnnotateIntervals, which gCNV didn't like). But I must not have rebuilt the somatic WGS PoNs and updated the copies in the large test resources. I could've sworn that I tested the somatic pipeline locally, but perhaps I forgot to update the jar at some point. Ideally, we should figure out some way to use the PoNs built by the panel WDL tests in the subsequent tests for the case/pair workflows.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-350179422:258,update,updated,258,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-350179422,3,"['pipeline', 'update']","['pipeline', 'update', 'updated']"
Deployability,"OK, I think things are looking good! Updated a bunch of things, including the following:. - conda 23.1.0 -> 23.10.0; in the base Docker, also disabled conda auto-updating and set the solver to the much faster libmamba (NOTE: before this PR went in, this change was actually made in https://github.com/broadinstitute/gatk/pull/8610); - python 3.6.10 -> 3.10.13; - pymc 3.1 -> 5.10.0; - theano 1.0.4 -> pytensor 2.18.1; - added pytorch 2.1.0; - removed tensorflow 1.15.0 and other CNN dependencies; - added libblas-dev to the base Docker; I think MKL versions of all packages are being used, but we should verify!. These and other packages (numpy, scipy, etc.) are all pretty much at the latest available versions for python 3.10. I've also bumped version numbers for our internal python packages. I also made all of the changes to the gCNV code to accommodate any changes introduced by PyMC/Pytensor. For the most part, these were minor renamings of `theano`/`tt`/etc. to `pytensor`/`pt`/etc. However, there were some more nontrivial changes, including to 1) model priors (since some of the distributions previously used were removed or are now supported differently), 2) the implementation of posterior sampling, 3) some shape/dimshuffle operations, and other things along these lines. Using a single test shard of 20 1kGP WES samples x 1000 intervals, I have verified determinism/reproducibility for DetermineGermlineContigPloidy COHORT/CASE modes, GermlineCNVCaller COHORT/CASE modes, and PostprocessGermlineCNVCalls. Numerical results are also relatively close to those from 4.4.0.0 for all identifiable call and model quantities (albeit far outside any reasonable exact-match thresholds, most likely due to differences in RNG, sampling, and the aforementioned priors). Some remaining TODOs:. - [x] Rebuild and push the base Docker. EDIT: Mostly covered by #8610, but this also includes an addition of `libblas-dev`.; - [x] Update expected results for integration tests, perhaps add any that might ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285:37,Update,Updated,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285,1,['Update'],['Updated']
Deployability,"OK, added an integration test to check that MKL is enabled. If we move the conda install of these packages into the base image, then we might need to perform these checks elsewhere, e.g., in the bash script for building the image. Gotta push the base image and update the main Dockerfile. I'll merge after the weekend unless there are any more comments. Again, @droazen please be sure to highlight that R plotting will now require the conda environment in the release notes!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-622500992:13,integrat,integration,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-622500992,4,"['install', 'integrat', 'release', 'update']","['install', 'integration', 'release', 'update']"
Deployability,"OK, great that you already were aware of it! We can probably resolve it during the upcoming round of python dependency updates.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5776#issuecomment-470998923:119,update,updates,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5776#issuecomment-470998923,1,['update'],['updates']
Deployability,"OK, great to hear! I'll close this issue for now, but thanks for bringing it to our attention. We might try to release some documentation on how memory requirements, runtime, etc. scale with the size of the coverage matrix in each shard.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468676205:111,release,release,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468676205,1,['release'],['release']
Deployability,"OK, great---I'll issue some PRs to delete some of the prototype tools soon and update the spreadsheet accordingly. A non-CNV-specific ""Deprecated"" program group seems reasonable to me if there is enough demand. If this is the only way to delineate the legacy CNV + ACNV pipeline from the new pipeline, I'm OK with it---but we should probably make the situation clear at any workshops, presentations, etc. between now and release that might focus on the legacy pipeline. On a different note, are there any conventions for short names that we should follow?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346191550:79,update,update,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346191550,10,"['pipeline', 'release', 'update']","['pipeline', 'release', 'update']"
Deployability,"OK, looks like you can get around the compiler lock issues by pointing each invocation of GermlineCNVCaller to a different compilation directory. For example, invoke `gatk` by. `THEANORC=PATH/TO/THEANORC_# gatk GermlineCNVCaller ...`. This uses the `THEANORC` environment variable to set the `.theanorc` configuration file to `PATH/TO/THEANORC_#` for this instance of GATK (where you should fill in `#` appropriately). Each `PATH/TO/THEANORC_#` should be a file containing the following:. ````; [global]; base_compiledir = PATH/TO/COMPILEDIR_#; ````. Where again, `#` is filled in appropriately. The goal is to point each GermlineCNVCaller instance to a different compilation directory. @xysj1989 can you let me know if this works for you?. This is a bit of a hack. We could probably avoid this by changing the GATK code to use a specified or temporary directory for the theano directory without too much effort. However, there is an upside to using a non-temporary directory to avoid recompilation of the model upon subsequent runs. In this case, we'd just want to let the user be able to specify the theano directory (rather than dump things in `~/.theano` unexpectedly). We should think about whether this should be opt-in, i.e., should we preserve the original behavior of using `~/.theano` by default?. @mwalker174 opinions? @droazen or engine team, thoughts on what the policy should be for python/R scripts doing this sort of thing? Is it generally true that the GATK leaves no trace, other than producing the expected output?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-548430809:304,configurat,configuration,304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-548430809,1,['configurat'],['configuration']
Deployability,"OK, relaxed the exact match to a delta of 1E-6 (chosen because doubles are formatted in somatic CNV outputs as `""%.6f""`) and tests pass on Travis (modulo an unrelated intermittent timeout failure). Note also that I was also able to reproduce locally by switching between Java 8 and 11. Had to add some quick test code for doing the comparisons; not actually sure if we have other utility methods to do so somewhere in the codebase. Another interesting note: I tried to clean up the offending use of log10factorial in AlleleFractionLikelihoods, but this introduced numerical differences at the ~1E-3 level. I think all of the round tripping between log and log10 actually adds up. Some digging revealed that this was introduced way back in gatk-protected in https://github.com/broadinstitute/gatk-protected/commit/aeec297e104db9f5196cb8f8e6691133302474bc#diff-34bd76cb2a416a212e25cbfb11298207265fb9cced775918aefcdb6b91ebc247. Despite the fact that we could easily replace the use of log10factorial with a private logGamma cache, at this point I think it makes more sense to freeze the current behavior. But if similar numerical changes are introduced to ModelSegments in the future, then it might make sense to clean this up at that point as well. Anyway, changed the title of the PR to reflect this update. Should be ready to go!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7652#issuecomment-1023793014:1299,update,update,1299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7652#issuecomment-1023793014,1,['update'],['update']
Deployability,"OK, thanks @drifty914. Note that the file with num_intervals_per_scatter = 20 is a minimal test case that is run with our continuous integration tests. In real-world use, you want enough intervals in each shard to fit a denoising model---probably 5000 or more is safe. I am wondering if your issue is related to https://github.com/broadinstitute/gatk/issues/4782 and https://askubuntu.com/questions/162229/how-do-i-increase-the-open-files-limit-for-a-non-root-user. It may be that your user ulimit is not high enough for the theano compilation directory?. Let me try to put together a fix for that issue and see if it addresses yours as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467085960:122,continuous,continuous,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467085960,2,"['continuous', 'integrat']","['continuous', 'integration']"
Deployability,"OK, thanks @ldgauthier, I think I've addressed all the comments but one. A little TODO list for my benefit:. - [x] Updated the GATK version in the ExcessHet documentation to 4.2.2.0, but we'll see if I need to revisit that.; - [x] Not quite sure about the `ReducibleAnnotation` business. Let me know how to make these changes, or else happy to punt and file an issue.; - [ ] Also not sure I've parsed the results of the Jenkins tests, at least in terms of comparing how many sites get hard filtered with/out the change. Where should I be looking at to see the baseline result for that step? Also looks like a lot of results for https://gotc-jenkins.dsp-techops.broadinstitute.org/job/warp-workflow-tests/11755/ were call-cached, is that to be expected? Haven't looked at these tests before, so maybe you can walk me through them at some point. But I guess we can be sure that the overall results don't change too much (at least for 50 samples), which is a good start.; - [x] Didn't quite get to making those plots of the change in decision boundary, will do that tomorrow or later this week. EDIT: Nevermind, took like 5 minutes to throw them together (albeit using the slow python implementation and some for loops...), see below.; - [x] Hmm, looks like my own PR #6885 might've introduced a few more exact match test failures...grr. Here are some plots for N = 50, 100, and 500 samples showing (in black) those counts that previously fell under the 3E-6 threshold with the mid-p correction but now pass without it. As you can see, not much to sweat from these ""theoretical"" plots, but good to convolve with the actual allele frequency spectrum and get an idea of how many sites occupy these black squares in practice (as well as start us down the road of reexamining the threshold itself):. ![image](https://user-images.githubusercontent.com/11076296/132413689-37f3dfeb-e3f5-4869-a803-fe27f3cd79bd.png); ![image](https://user-images.githubusercontent.com/11076296/132413649-d716ee7d-6763-4275-82de-e",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-914612907:115,Update,Updated,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-914612907,1,['Update'],['Updated']
Deployability,"OK, verified that numerical results in the gCNV WDL tests match 4.1.6.0. Not sure if @lucidtronix needs to run similar checks for the CNN. Other than needing to push a new base image after review, I think this branch is ready to go. However, as we discussed, we should highlight major changes (e.g., the need to run R plotting tools in the conda environment) in the release notes. @droazen can you assign a final reviewer?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-608460914:366,release,release,366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-608460914,1,['release'],['release']
Deployability,"OK. Our pipelines currently all use gatk like you say. Our upstream code splits an operation (set of processing steps) into intervals and scatter/gathers across our slurm cluster. Other code then merges the output, which is usually a vcf. VariantQC (which is basically a fancy variant eval), cannot currently be split so easily, since it aggregates data across the genome. Another option I've toyed with is making a mode in which one could execute it over a set of intervals, and have each job write some intermediate output with the pre-aggregated data. I would make another step that aggregates these outputs. If there are any facilities that exist in gatk to support this type of scenario I'd appreciate pointers. . I was considering spark in this instance with the idea that it would be local parallelization, not a true spark cluster.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7013#issuecomment-749910672:8,pipeline,pipelines,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7013#issuecomment-749910672,1,['pipeline'],['pipelines']
Deployability,Obviated by ModelSegments pipeline.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2940#issuecomment-356695813:26,pipeline,pipeline,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2940#issuecomment-356695813,1,['pipeline'],['pipeline']
Deployability,"Offhand I don't have any rule of thumb for memory usage, unfortunately. One thing that can help to reduce memory pressure is to use the `--batch-size` parameter. Also, this doesn't help you now, but we're looking to enable a feature to reduce the memory usage by 5x or more. Works for local/posix files right now, but we need a little tinkering to make it work with Google cloud files. Regarding logging for GenomicsDBImport - that is expected. A lot of the heavy lifting is done by the native layer, so we need to do a bit more work to push updates back to the progress meter. It's on our to-do list....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656278175:542,update,updates,542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656278175,1,['update'],['updates']
Deployability,"Oh interesting, thank you. Yes this is a nextflow pipeline. Thanks for the tip! Will report back.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-2078160409:50,pipeline,pipeline,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-2078160409,1,['pipeline'],['pipeline']
Deployability,"Oh yeah, I see. I did upgrade to latests minconda and now I see the same issue. So something changed in conda.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4741#issuecomment-387168692:22,upgrade,upgrade,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4741#issuecomment-387168692,1,['upgrade'],['upgrade']
Deployability,Oh!!; I thought GATK on conda was maintained by GATK. My bad. Just learned from this [blog](https://gatkforums.broadinstitute.org/gatk/discussion/11361/installing-gatk4-via-conda). I will install it separately.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595886955:152,install,installing-,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595886955,4,['install'],"['install', 'installing-']"
Deployability,"Oh, be sure to mention that you updated the base image and included dplyr in the commit message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6039#issuecomment-532818587:32,update,updated,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6039#issuecomment-532818587,1,['update'],['updated']
Deployability,"Oh, that's interesting... I wonder if there is a sane way to detect the version mismatch. It's weird that it breaks with a NEWER version of spark. I would expect 2.1.0 to be compatible with 2.0.2. . Incidentally, it would be a good idea to upgrade to the newest spark version. #2555",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290764935:240,upgrade,upgrade,240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290764935,1,['upgrade'],['upgrade']
Deployability,"Oh, that's right, I'd forgotten about the SGA license issue. Since we're; about to move to fermi-lite (hopefully), let's just hold off on checking in; the initialization script until that's done, keeping it in the known bucket; location. On Wed, Mar 8, 2017 at 11:37 AM, Steve Huang <notifications@github.com>; wrote:. > @cwhelan <https://github.com/cwhelan> I was actually debating with myself; > about whether to include the initialization script here, as it was living; > in the bucket referred to in the creation script.; > So we could do this:; > always store the initialization script locally with the creation script; > instead of referring to a script living remotely, and makes that a required; > argument. The good: this makes it easier to track changes; The bad:; > initialization script must be removed from the bucket to avoid tracking; > possible different versions.; >; > A non-technical issue: we are ""delivering"" SGA in the initialization; > script, if that comes in to this repo, legal might have a problem with it.; > On the other hand, it the initialization script lives in a place only we; > can access, we are ""installing SGA for our own use"", which is not a problem; > with the GPL license.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/2435#issuecomment-285093289>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AArTZZPv4WyEYz-yYaZZIIjH8LBMOhZ4ks5rjtlCgaJpZM4MTqFc>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2435#issuecomment-285105258:1133,install,installing,1133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2435#issuecomment-285105258,1,['install'],['installing']
Deployability,"Ok @jean-philippe-martin, I have an updated patch that seems to resolve the 503 errors! It's here: https://github.com/droazen/google-cloud-java/tree/dr_retry_CloudStorageReadChannel_fetchSize. Will you have time before you leave on vacation to open a PR against google-cloud-java? If not, let me know and we'll try to sort out our CLA issues and PR it ourselves. I didn't have time to write unit tests, unfortunately, though we're running it now with 1000 concurrent jobs each accessing 11,000 files and not seeing any errors.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319:36,update,updated,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319,2,"['patch', 'update']","['patch', 'updated']"
Deployability,"Ok, based on internal discussions, I updated this to not emit the spanning-del only sites, but to include the LowQual sites.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5219#issuecomment-425956735:37,update,updated,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5219#issuecomment-425956735,1,['update'],['updated']
Deployability,"Ok, thanks -- I'll add a note to the release notes retroactively to try to cut down on user surprise.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4390#issuecomment-364990476:37,release,release,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4390#issuecomment-364990476,1,['release'],['release']
Deployability,"Ok, we have a working test! It runs the plumbing NA12878 through the whole pipeline. @ldgauthier or @jsotobroad this is ready for review (the wdl is a direct copy with one change to add more memory to RevertSam because I tested it with PAPI v2 and it needed more memory than was specified). Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5566#issuecomment-454024917:75,pipeline,pipeline,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5566#issuecomment-454024917,1,['pipeline'],['pipeline']
Deployability,"Ok,could we ask for a minor release? I will wait for your decision to continue my work on this PR...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2247#issuecomment-258561771:28,release,release,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2247#issuecomment-258561771,1,['release'],['release']
Deployability,"Ok. I'm sorry, but we're unable to help you then. GATK 3 is no longer maintained or updated. We recommend everyone upgrades to 4. The differences between 3 and 4 are only going to increase over time. . Is there a specific missing feature preventing you from upgrading? Or some issue that manifests in 4 but not 3?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5789#issuecomment-472200516:84,update,updated,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5789#issuecomment-472200516,2,"['update', 'upgrade']","['updated', 'upgrades']"
Deployability,"Okay apparently there is not a version number in the picard.jar file downloaded from https://github.com/broadinstitute/picard/releases and thus if easybuild detects a cache copy, it will use that instead of downloading it which was an older version. They forced it to download and now version is correct. I will re-try and see if the error persists. Thanks for catching that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419783633:126,release,releases,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419783633,1,['release'],['releases']
Deployability,"Okay, I've had time to sit down and go through each tool. Sorry, but I'm WFH today so I've no paper proofs to hand you. For Jan 9 release, we are aiming for:; - Meaningful one-line summaries that convey the tool functionality; - Functional categorization of tools; - Example commands that are representative and of course that work, i.e. uses updated kebab syntax. --- . ## CalcMetadataSpark . 1. Revise one-line summary to something like:; Collects read metrics relevant to structural variant discovery. - Notice the lack of a period at the end above.; - Not statistics but metrics?. 2. Overview and Notes could use finessing but let's leave this for next year. One thing to do now is move this statement up top:; This tool is used in development and should not be of interest to most researchers. 3. I think this tool fits under the DiagnosticsAndQCProgramGroup.java.; 4. The tool takes a SAM/BAM/CRAM and calculates fragment length statistics...; 5. ""This is the first step in the workflow""--> makes it sound like this tool is necessary in the SV workflow but you say otherwise in the debugging sentence. I find this confusing. 6. I'm noticing that the example command does not have spark options despite the tool being a Spark tool. For such cases, it would be helpful to state, e.g. ""This tool can run in both Spark and non-Spark modes, depending on if --sparkMaster is set."" Then include a second example command that shows how to utilize Spark. There is an example from ChrisW in <https://github.com/broadinstitute/gatk/issues/3853>:. ```; 	-- \; --sparkRunner GCS \; --cluster my-dataproc-spark-cluster; ```. ---; ## DiscoverVariantsFromContigAlignmentsSAMSpark. 1. ""Parse"" is vague. How about: ; Parses aligned contig assemblies of genomic breakpoints and calls structural variants. And `6. ` from above. ---; ## ExtractOriginalAlignmentRecordsByNameSpark. 1. Subsets reads by names; 2. I think you mean FilterSamReads (Picard) and not PrintReads. AFAIK, PrintReads cannot subset based on a l",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451:130,release,release,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451,4,"['release', 'update']","['release', 'updated']"
Deployability,"On branch `ll_CollectAllelicCountsSpark`, I have created a CLI called: `CollectAllelicCountsSpark` ... This tool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3823:215,integrat,integration,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823,2,['integrat'],['integration']
Deployability,On it. Not intending to make the kill switch until test coverage is up.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4260#issuecomment-360567998:33,kill switch,kill switch,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260#issuecomment-360567998,1,['kill switch'],['kill switch']
Deployability,"Once #2457 is merged, the gatkbase docker image will be the basis for GATK4 docker images. However, gatkbase depends on no files in the GATK4 repo. However, we *might* want to move the installation of R libraries into gatkbase. Currently the custom R installation script takes a substantial portion of time in the GATK4 docker image build. The question is whether we expect the R libraries to change much. Once we answer this question, we can decide whether this issue should be addressed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2699:185,install,installation,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2699,2,['install'],['installation']
Deployability,"Once again I've managed to convince David R. to let me merge with some tech debt as follows:; - [ ] Add to GnarlyGenotyper an integration test like testRawAndFinalizedAlleleSpecificAnnotationsThoroughly() for GGVCFs; - [ ] Add a direct unit test for makeReducedAnnotationString() if you exposed it as package-accessible; - [ ] ~Break out finalized key definition, promote getKeyNames and getRawKeyNames to default methods in ReducibleAnnotation interface~; - [ ] One last `ann.getRawKeyNames().get(0)` in GnarlyGenotyperEngine",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6203:126,integrat,integration,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6203,1,['integrat'],['integration']
Deployability,"Once https://github.com/broadinstitute/gatk/pull/3620/ is in, we should add/update the gradle tasks for gatkDoc and gatkTabComplete to generate unified (GATK and Picard) doc and tab completion script.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3627:76,update,update,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3627,1,['update'],['update']
Deployability,"Once we choose the library to use for GATK configuration, let's have a design meeting to make sure we come up with something that works for Spark, downstream projects, our users, etc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3079:43,configurat,configuration,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3079,1,['configurat'],['configuration']
Deployability,"Once we do https://github.com/broadinstitute/gatk/issues/2817, we can disable the non-docker unit and integration tests in travis, saving a huge amount of time and resources. (We should keep the instance of the tests that run on the Oracle JDK, however).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3294:102,integrat,integration,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3294,1,['integrat'],['integration']
Deployability,"Oncotator script: `create_uniprot_datasource_preprocess.sh.example`. Since this initializes an oncotator gencode datasrouce, it will not work for generating hg38 data. However, it can be used as a template for writing an updated sciprt for Funcotator. Does a superset of what is needed here, but a side-effect is to generate the initial preferred transcript list.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5914#issuecomment-488780369:221,update,updated,221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5914#issuecomment-488780369,1,['update'],['updated']
Deployability,One additional thing to do is to update the fourth tab of the spreadsheet so folks know which program groups to apply to their tools.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3924#issuecomment-350031080:33,update,update,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3924#issuecomment-350031080,1,['update'],['update']
Deployability,"One concern I have is the maintainability of the test (having been burned by this in other places myself). When we add a new output field, etc we need a very easy way to update/generate these results. At the very least some instructions would be helpful (and imagine someone to follow those as part of a PR)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7192#issuecomment-821234533:170,update,update,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7192#issuecomment-821234533,1,['update'],['update']
Deployability,"One final thing: i'm happy to try to debug this, and was going to write a test case based on the existing GenomicsDB integration tests. However, when I try to run any integration test involving genomicsdb, I get an exception like the following. I am on windows, so perhaps this is the issue?. 09:03:37.460 FATAL GenomicsDBLibLoader - ; java.io.FileNotFoundException: File /tiledbgenomicsdb.dll was not found inside JAR.; 	at org.genomicsdb.GenomicsDBLibLoader.loadLibraryFromJar(GenomicsDBLibLoader.java:118) ~[genomicsdb-1.3.2.jar:?]; 	at org.genomicsdb.GenomicsDBLibLoader.loadLibrary(GenomicsDBLibLoader.java:55) [genomicsdb-1.3.2.jar:?]; 	at org.genomicsdb.GenomicsDBUtilsJni.<clinit>(GenomicsDBUtilsJni.java:30) [genomicsdb-1.3.2.jar:?]; 	at org.genomicsdb.GenomicsDBUtils.createTileDBWorkspace(GenomicsDBUtils.java:46) [genomicsdb-1.3.2.jar:?]; 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.overwriteCreateOrCheckWorkspace(GenomicsDBImport.java:1005) [classes/:?]; 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.onTraversalStart(GenomicsDBImport.java:661) [classes/:?]; 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1056) [classes/:?]",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7005#issuecomment-749138102:117,integrat,integration,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7005#issuecomment-749138102,2,['integrat'],['integration']
Deployability,"One more DepthOfCoverage observation. The GATK4 version let's one control the delimiter in the output, which seems like a useful idea. However:. 1) this isnt that big a deal, but why change the GATK3 default of tab to comma in GATK4?. 2) The enum is named CSV and TABLE. Why not rename 'TABLE' to 'TSV' to make it more clear? A comma-delimited table is still a table. This is a beta tool now, and I assume with the next release changing an argument becomes harder.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6623:420,release,release,420,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6623,1,['release'],['release']
Deployability,"One of our tests (BaseRecalibratorDataflow, on cloud) started failing. It turns out that the culprit is a Dataflow limitation. This is what I got back from the DF team:. _I examined logs of this pipeline on the service and in this case, metadata.items[3] is the pipelineOptions item, whose biggest part is --filesToStage, built from the classpath: it seems you have too many .jar's in classpath, or the jars have too long (absolute) filenames.; It seems that you are using Gradle and all the absolute filenames point deep inside gradle cache directories.; So, as a work-around, you could consider asking Gradle to build a self-contained distribution of your application, put it in a less deep directory, and run that._. We may run into this problem for other tests as well, so it's good to know about the issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/580:195,pipeline,pipeline,195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/580,2,['pipeline'],"['pipeline', 'pipelineOptions']"
Deployability,"One of the example commands in CalculateGenotypePosteriors describes the usage of the `-supporting` argument and the `--num-reference-samples-if-no-call` argument at the same time:; ```; gatk --java-options ""-Xmx4g"" CalculateGenotypePosteriors \; -V input.vcf.gz \; -O output.vcf.gz \; -supporting 1000G.phase3.integrated.sites_only.no_MATCHED_REV.hg38.vcf.gz \; --num-reference-samples-if-no-call 2504; ```; Calculate the posterior genotypes of a callset, and impose that a variant *not seen* in the external panel is tantamount to being AC=0, AN=5008 within that panel. We don't have any tests that use both of these arguments at the same time, but it looks like the behavior in that case is wrong. PosteriorProbabilitiesUtils adds numRefSamplesFromMissingResources regardless of whether there was an overlapping variant in the panel or not, effectively diluting the AF of all the variants used as priors and making the number of reference alleles very inconsistent across variants.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4760:311,integrat,integrated,311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4760,1,['integrat'],['integrated']
Deployability,"One proposal for moving forward would be to have a default properties file with a known name/location that is included in the gatk jar (say, ""gatk.default.properties""), which is always loaded and populates the initial configuration, and then use the classloader getResources method to also load all resources with some other known name (say, ""gatk.properties""). That way any properties files on the classpath with the known name would be automatically discovered and loaded. The apache commons API allows looks like it has good support for handling this using a [composite](http://commons.apache.org/proper/commons-configuration/userguide/howto_compositeconfiguration.html#Composite_Configuration_Details) configuration. We would have to define some rules around override semantics, but it looks like the api provides a lot of control over that as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2322#issuecomment-274654954:218,configurat,configuration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2322#issuecomment-274654954,3,['configurat'],['configuration']
Deployability,"One thing, v4.1.8.0 is backward compatible with all the workspaces generated by versions <4.1.8.0, not the other way around. For example, v4.1.7.0 cannot read a GenomicsDB workspace created by v4.1.8.0, but 4.1.8.0 can read a 4.1.7.0 workspace. So some questions -; 1. Are the failures in the same set of nodes?; 2. Have all the ""nodes"" in the cluster been updated to running gatk v4.1.8.0.; 3. Is it possible to attach a file named `__array_schema.tdb` from one of the arrays causing the segfault?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-716832351:357,update,updated,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-716832351,1,['update'],['updated']
Deployability,"Only performance optimizations were made to the copy-ratio denoising method in the ModelSegments pipeline, which is otherwise identical to that used in GATK CNV. No special care is taken to preserve the normalization of the overall copy-ratio profile during the process. This may become important in downstream tumor-heterogeneity inference; estimates of the ploidy may be otherwise biased. We can investigate using simulated data. This issue could be obviated by #4121 in the near future, but a quick fix might nevertheless be in order.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4150:97,pipeline,pipeline,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4150,1,['pipeline'],['pipeline']
Deployability,"Oof, looks like there are now a bunch of broken integration tests that check ExcessHet for whatever reason. So let's definitely decide on whether we want to make the switch to mid p-values before I go through those. EDIT: Actually, what’s SOP here? Do I have to go through and recalculate ExcessHet for *every single VCF/GenomicsDB in the repo*?. If we stick with the one-sided p-values now calculated here, then I guess one bonus is we’ll no longer have ExcessHet Phred scores of 3.0103 (which result from that short circuit returning a p-value of 0.5) everywhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892755997:48,integrat,integration,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892755997,1,['integrat'],['integration']
Deployability,"Oof, that's a nasty problem. We can definitely do something about it. It feels more like a Microsoft bug than a GATK one though. It seems crazy that each layer pull has to be a separate web request and there's no batch api for it? Multi layer docker builds are pretty standard from what I understand. . It sounds like your suggestions are talking about 2 slightly different issues to me. 1. Too many layers:. We typically have squashed the GATK docker images, but we recently switched to building our release images with google cloud build. Since squash is *STILL* an experimental feature in docker we've had trouble getting it to work there. Since the size reduction was pretty minimal from squashing we figured it would be ok to not prioritize it. It's definitely possible for us to consolidate various layers in the build. Or manually squash the images. We can take a look for our next release. Wide workflows on azure are something we need to support. 2. Docker size reduction:; I've spend a lot of time looking at this in the past. Our docker image is huge, but it's mostly due to the massive size of our python and R dependencies. I've done a bunch of work reducing temporary files in independent layers and using multiple stages to reduce the size. There's not much low hanging fruit left there. Similarly, moving to alpine is tricky an has limited benefit. GATK packages a number of C libraries which do not work out of the box on alpine due to the different C runtime. (At least that was the case the last time I investigated it a few years ago. ) I suspect there's a way to port things so they work on it, but it's not something we can do now. It also wouldn't be much of a help, the base image is completely dwarfed by piles of python and R dependencies which are very difficult to safely trim. Anyway, that's the state of things. We've considered a java only image for a while which would be much smaller than the current one. (although still fat by most docker standards...). We've never ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427:501,release,release,501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427,2,['release'],['release']
Deployability,"Ooh, actually, on second thought hold off on the merge @jamesemery. I think we might want to only run with `-Drelease=true` when publishing a docker image as part of an official GATK release. We might need to tie it to one or more of the arguments to the `build_docker.sh` script.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3719#issuecomment-338024325:183,release,release,183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3719#issuecomment-338024325,1,['release'],['release']
Deployability,Oops -- good point. QUALapprox is not default. I've updated the docs with the appropriate argument to add. Still good @gbrandt6 ?. I will investigate the test failures. I'm 99% sure it's not related to my docs change....,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7231#issuecomment-828646984:52,update,updated,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7231#issuecomment-828646984,1,['update'],['updated']
Deployability,"Oops! Of course! Sorry I didn't include that as well. Glad you were able; to get it off RefSeq. Thanks so much for looking into this for all of us. Much appreciated!. eric. On Thu, Jan 27, 2022 at 10:51 AM ldgauthier ***@***.***>; wrote:. > Never mind -- refseq to the rescue. I'm working on a patch now.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023359171>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AAPQ4JSI4TKOZNLDMPAACQDUYFSYXANCNFSM5L75WXOA>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023469845:294,patch,patch,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023469845,1,['patch'],['patch']
Deployability,"Oops, looks like they just updated the URL last week. Perhaps another reason why we should host these dependencies or have some simple contingencies for testing them other than manually building the base image.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3712:27,update,updated,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3712,1,['update'],['updated']
Deployability,Opened https://github.com/broadinstitute/GATKZendesk/pull/2 to resurrect this old article (source: https://web.archive.org/web/20160415213604/https://www.broadinstitute.org/gatk/guide/article?id=1328). I updated the article text and command lines for the modern era.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8272#issuecomment-1502305330:204,update,updated,204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8272#issuecomment-1502305330,2,['update'],['updated']
Deployability,"Opening a new issue for evaluating the new version of gCNV. @kuanlinhuang We will release Best Practices recommendations for this workflow, including suggested parameter values for various data types typically generated at the Broad, when this new round of evaluations is complete.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2907#issuecomment-356728485:82,release,release,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2907#issuecomment-356728485,1,['release'],['release']
Deployability,"Ops fixed the bad blacklist in broad-references, but this means the old file is no longer there. @ldgauthier or @jsotobroad Can you please do a quick review? @droazen It would be really awesome if this (tiny!) commit could end up in the release.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5612:237,release,release,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5612,1,['release'],['release']
Deployability,"Option 2, for sure. On Tue, May 8, 2018, 02:38 Jonn Smith <notifications@github.com> wrote:. > This is an issue with the Gencode files chosen for the datasources. The; > Fasta file we use currently is a subset of the total genes in Gencode, so; > this is an expected error (though it shouldn't be a user error).; >; > We have 2 options:; >; > 1. changing the code to throw a warning and ignore variants in; > transcripts not in the Fasta.; > 2. Download a larger set of sequences from Gencode and make sure all; > transcripts are represented in the Fasta file.; >; > My choice is 2 because it is a relatively seamless update (though the data; > sources will need to be updated, and this will add about 1.6 GB to the data; > sources).; >; > @LeeTL1220 <https://github.com/LeeTL1220> Thoughts?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4739#issuecomment-387300313>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk_4_-aePFLbkcvBhmHeQhZRgWY0Sks5twT1igaJpZM4T1InN>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4739#issuecomment-387377523:618,update,update,618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4739#issuecomment-387377523,2,['update'],"['update', 'updated']"
Deployability,"Optionally extract VCFs in bgzipped compression format. Integration test - [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/60357098-e6f2-4264-a322-c3088ce36152). [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/2c4dea90-367f-4875-939a-ce0b9ae296e7) is an example extract using bgzip; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/7a8413da-499b-4f93-ba85-554937249bd4) is an example extract not using bgzip (so, just '.gz')",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8809:56,Integrat,Integration,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8809,1,['Integrat'],['Integration']
Deployability,"Originally, we just had the normal be optional. You also had automated tests in the WDL Travis. . In FC, for tumor only, you would probably want a separate method configuration that ran on sample entity type. I'm open to other suggestions, but I can't think of another way. This could in theory be used for germline calling, too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362811723:163,configurat,configuration,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362811723,1,['configurat'],['configuration']
Deployability,"Ouch! Well that definitely explains the hanging :). Now do you think we can possibly convince the maintainers of that project to cut a bug fix release with that patch, once it's merged?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2793#issuecomment-306950250:143,release,release,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2793#issuecomment-306950250,2,"['patch', 'release']","['patch', 'release']"
Deployability,"Our PR has been merged, and a release with the fix is in progress: https://github.com/googleapis/java-storage-nio/pull/864",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716#issuecomment-1069678041:30,release,release,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716#issuecomment-1069678041,1,['release'],['release']
Deployability,"Our R dependency is primarily for producing plots. It could be possible to create plots using javascript instead. Javascript plots have several potential advantages but also several major downsides. The biggest and most obvious drawback is that we don't have any code to produce them yet, and they are likely harder to generate and experiment with than R scripts. . The advantage would be that we could avoid requiring an R installation to run hellbender scripts, we could potentially also include interactive plotting or other neat tricks to make the plots more useful. I see 2 possible routes to replacing Rscripts with javascript. The first would be for tools that require graphs to perform some html generation and produce html reports with embedded javascript. The user could then open these in their browser and view the plots ( much like how our test suite report and jacoco is done). . A different option would be to use javascript plotting libraries directly within the jvm to generate SVG. Java 8 has a new javascript engine which is supposed to be reasonably fast and offers access to java objects from within it. Unfortunately it doesn't offer a full DOM like a browser does, so most existing javascript libraries will fall over. It seems like it would take a lot of hacking to get something like d3 to run directly on the jvm. (someone has done something of the kind here: http://jazdw.net/content/server-side-svg-generation-using-d3js) . Other options would be to use the javafx web panes to display a browser directly, or to plot directly on a canvas. Either of these options seem like they would be painful and awful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/248:424,install,installation,424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/248,1,['install'],['installation']
Deployability,"Our long term solution is a rather large modification to the graph assembly; code: https://github.com/broadinstitute/gatk/issues/5828. That will likely take a couple months, but we fully expect a dramatic; improvement in phasing. Since we're working on that, spending time in a; quick fix is just going to make the long term fix take longer. On Thu, Apr 11, 2019, 4:46 PM Nils Homer <notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> any updates on a solution? We; > have an example for clinically reportable variant that matches #5824; > <https://github.com/broadinstitute/gatk/issues/5824>.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3368#issuecomment-482307485>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdBhIYIXwi9yIHobr45Nil-8yzNgTks5vf58ygaJpZM4Olg1H>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3368#issuecomment-483654829:468,update,updates,468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3368#issuecomment-483654829,1,['update'],['updates']
Deployability,"Our patches to `google-cloud-java` in https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2281 and https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2283 to fix the transient NIO errors have now been merged into master, and will be part of their next release (which will be the release after `0.22.0`). We should update to the next release as soon as it's out, to remove our existing dependency on a SNAPSHOT build of `google-cloud-java`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3500:4,patch,patches,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3500,5,"['patch', 'release', 'update']","['patches', 'release', 'update']"
Deployability,"Our travis gcloud installation scripts relied on piping interactive responses; into the stdin of the installer, which is brittle. This patch changes our script to instead run the installer in non-interactive mode.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6974:18,install,installation,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6974,4,"['install', 'patch']","['installation', 'installer', 'patch']"
Deployability,Our wiki has a bunch of outdated things which should be updated: ex: https://github.com/broadinstitute/gatk/wiki/Why-are-there-multiple-GATK-repositories%3F,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2794:56,update,updated,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2794,1,['update'],['updated']
Deployability,"Overall, this looks fine, just a few minor comments. Two broader questions/issues:; - Does the test data exercise all of the code paths and edge cases?; - In general, putting the majority of testing in integration tests instead of unit tests is bad pattern. It have several bad consequences (1) it becomes less clear which cases are being tested (2) it's slower than just running unit tests and (3) it makes it unhelpful to (perhaps someday) move to a testing framework that only runs tests relevant to the code directly affected (because all integration tests must be run).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1013#issuecomment-149599490:202,integrat,integration,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1013#issuecomment-149599490,2,['integrat'],['integration']
Deployability,"Overview: see [this presentation](https://docs.google.com/presentation/d/1jPKYcaMcpT_e1l8L6D3wn7wBvC-yKt4GVrgeeTRBrss/edit#slide=id.g7f3200a976_0_97). ![image](https://user-images.githubusercontent.com/1423491/136983924-338faca1-30f0-4f1e-92c7-b34f091050ca.png). WDL; * updated WDLs to support parameterized loading of PET and/or RANGES; * enhanced inline schemas in WDL to JSON to allow for declaring required fields. Common; * updated AvroFileReader to use GATKPath instead of String for file, allows us to read from gs:// directly; * changed ""mode"" from EXOMES/GENOMES/ARRAYS (unused) to PET/RANGES; * promoted GQStateEnum to top-level class (it was inside PetTsvCreator but used across the codebase); * added numerical GQ value to GQStateEnum; * max deletion size is 1000bp . Import; * added flags to enable writing of PET and/or VET; * code to create RefRanges with pluggable writer and TSV/Avro implementations; ; Extract; * add parameter to parameterize inferred GQ value; * support to read VET/Ranges data from Avro files (to support testing); * Entire implementation of ranges support; * Note there is a maximum supported DELETION size. Upstream deletions larger than this will not generate downstream spanning indels. Testing; * added new integration test for ranges extract; * added various unit tests; * (IN PROCESS) scientific tieout against 1k; * scale testing up to 90k once we've move to v2 reblocking. How to perform scientific tieout; 1. Run the ""GvsIngest"" pipeline with load_ref_ranges = true, this will load both the PET and REF_RANGES tables; 2. Run Create Alt Allele, Training, etc as normal; 3. Extract a callset twice -- once with mode = 'PET' (the default) and once with mode = 'RANGES'; 4. Compare the resulting VCFs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7498:270,update,updated,270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7498,4,"['integrat', 'pipeline', 'update']","['integration', 'pipeline', 'updated']"
Deployability,PCA results from the R pipeline for the full CMG cohort are in the bucket associated with my workspace: gs://fc-d3bc13de-ef61-4854-a05c-d311219008b3/pca.rda The rownames in pca$x should be the sample names. Also in the bucket are two bed files. the aux_capture_uniques was used for clustering in the R pipeline and the gencode file was used for calling. Other notes:; gCNV_helper.jar is Java 14 and may have some issues reading .vcf.gz on mac; At least a subset of the CMG calls from the R pipeline are in gs://fc-d3bc13de-ef61-4854-a05c-d311219008b3/isaacsCalls.tsv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926865252:23,pipeline,pipeline,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926865252,3,['pipeline'],['pipeline']
Deployability,PGEN + Docker image updates [VS-1254],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8749:20,update,updates,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8749,1,['update'],['updates']
Deployability,PGEN Updates for AoU [VS-1254],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8739:5,Update,Updates,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8739,1,['Update'],['Updates']
Deployability,"PR #5840 created a few pipeline-breaking changes. Since the orientation bias annotation and filter are only standard in Mutect2 we weren't expecting it to cause problems for HaplotypeCaller users. And as far as Mutect2 is concerned the WDL is always in a working state and we hope users are running the pipeline that way. While changing the annotation name was not absolutely necessary we felt it was important because the OxoG artifact is only one example of an artifact with orientation bias. As of 2012 or so it was the best-known such artifact but the name is now misleading. We don't want users to think that we don't handle other artifacts when in fact the new orientation bias model handles every orientation bias artifact. By the way @tfenne, are you using this annotation in order to run the orientation bias filter?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480030577:23,pipeline,pipeline-breaking,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480030577,2,['pipeline'],"['pipeline', 'pipeline-breaking']"
Deployability,PR is #3594 if we want to try moving forward one release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330886791:49,release,release,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330886791,1,['release'],['release']
Deployability,"PR is ready to be merged. The 2 GCS tests in GenomicsDBImportIntegrationTest.java are commented out, but they have been tested with the HELLBENDER test project and GOOGLE_APPLICATION_CREDENTIALS in the nalini_new_genomicsdb_jar branch and will be uncommented as soon as a new GenomicsDB jar is released.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-429598743:294,release,released,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-429598743,1,['release'],['released']
Deployability,PR updated after a rebase from a nearly a year old master. @ldgauthier @kachulis please review first (3rd last commit) . @davidbenjamin please review second (2nd last commit) on AlleleLikelihoods changes... these two commit are a bit entangled and would be a bit of work to split it in two PRs. I found a couple of bugs that does not seem to manifest themselves in practice and have splitted marginalization and evidence filtering in two steps. Filtering can use any given criterion (lambda) not necessarelly interval overlap. The last commit gathers changes in test files for the first (main) commit. Most of the differences in vcf are due to updated DPs annotations and some minor changes in PLs.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-558828882:3,update,updated,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-558828882,2,['update'],['updated']
Deployability,PRs like https://github.com/broadinstitute/gatk/pull/2156 make it clear that we need some master configuration mechanism in the GATK that can be overridden by clients/downstream projects. . One promising option is `commons-configuration` (https://commons.apache.org/proper/commons-configuration/userguide/user_guide.html) using properties files -- we should look into this to see whether it does what we want.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2297:97,configurat,configuration,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2297,3,['configurat'],['configuration']
Deployability,Package bash completion file in GATK release zip,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3499:37,release,release,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3499,1,['release'],['release']
Deployability,Parsing the GATK config file currently overrides any command-line specified config options for system-level parameters. Options explicitly specified on the command-line should override what is in the config file. The `GATKConfig.properties` file is missing from the packaged binary release (as created by`gradle bundle`). Gradle must be updated to include it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4436:282,release,release,282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4436,2,"['release', 'update']","['release', 'updated']"
Deployability,"Part of road map laid out in #4111 . ## Consolidate logic, update variant representation (PR#4663) . ### consolidate logic in the following classes. - [x] `AssemblyContigAlignmentSignatureClassifier` now gone, its inner enum class `RawTypes` is moved to `AssemblyContigWithFineTunedAlignments.AlignmentSignatureBasicTypes` and reduced into fewer cases (`Suspicious`, `Simple` and `Complex`). - [x] static method `BreakpointsInference.inferFromSimpleChimera()` now moved to state query method `ChimericAlignment.inferType()`. - [x] `AssemblyContigWithFineTunedAlignments.hasIncompletePictureFromTwoAlignments()` merged with `ChimericAlignment.hasIncompletePicture()`. ### update how variants are represented. - [x] change `SVLEN` for `CPX` variants to the difference between _[alt haplotype sequence length]_ and _[affected reference region length]_, which is following the technical definition of `SVLEN` in VCF spec. - [x] change `RPL` output to one of these (note that test coverage is expected); - [x] ins/del, when del/ins bases are < 50 and annotate; when type is determined as ins, the POS will be 1 base before the micro-deleted range and END will be end of the micro-deleted range, where the REF allele will be the corresponding reference bases.; - [x] ins and del when both are >= 50, and link by `EVENT`. - [x] change `SVTYPE=DUP` to`SVYTPE=INS` when the duplicated region is shorter than 50 bp (tests). Note that this will lead to `INS` records with `DUP_REPEAT_UNIT_REF_SPAN` and `DUP_SEQ_CIGARS` (when available). In addition, we are currently treating duplication expansion as insertion. ; The VCF spec doesn't force `DUP` records as such.; If we decide to allow `POS` and `END` to designate the beginning and end of the duplicated reference region, we need to make at least the following change:. - [ ] shift the left breakpoint to the right by 1 base compared to the current implementation, and ; - [ ] `downstreamBreakpointRefPos = complication.getDupSeqRepeatUnitRefSpan().getEnd();`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663:59,update,update,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663,2,['update'],['update']
Deployability,Passed integration test here: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/be46efc1-38b9-48a8-953a-42b06581266a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8529#issuecomment-1798828249:7,integrat,integration,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8529#issuecomment-1798828249,1,['integrat'],['integration']
Deployability,"Passing Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/ad05b4d1-7aed-4482-8b5c-ced7b87d2d37).; Verified that GQ0 dropped in 'hail_lite' run and not in 'hail_vcf' run; (queries of count by state from ref ranges table):. **Hail Lite (Hail path, drop state 0):; state count**; 2 2495387; 3 4773472  ; 4 5959290. **Lite VCF (VCF path, drop_state 40):; state count**; 0 2764630; 2 2495387; 3 4773472. Spun up a notebook and ran the vds_validation.py script on the VDS generated by 'hail_lite'. And it passed:. > 2023-10-04 19:08:01.278 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.; > To preserve matrix table column order, first unkey columns with 'key_cols_by()'; > checking that:; > * no reference blocks have GQ=0; > * all ref blocks have END after start; > * all ref blocks are max 1000 bases long; > running densify on 200kb region (0 + 1) / 1]; > took 10.9s to densify 0 rows after interval query; > Hail VDS validation successful======================================(1 + 0) / 1]",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8538:8,Integrat,Integration,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8538,1,['Integrat'],['Integration']
Deployability,Passing Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/70870e97-4e58-4a55-8424-f78b0e26ac28).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8393#issuecomment-1613031872:8,Integrat,Integration,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8393#issuecomment-1613031872,1,['Integrat'],['Integration']
Deployability,Passing Integration test (using built-in dockers) [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/d2063e26-a22e-412e-ad91-aa2b14fbb7ec).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8566:8,Integrat,Integration,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8566,1,['Integrat'],['Integration']
Deployability,Passing Lite Run [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/89e89bba-9647-4451-a6fc-934a7b72ed1e); Passing Classic Run [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/9810bedb-dc9b-4a65-97e2-69497fbba516); Passing Integration Test [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/ea45667c-5c45-48a6-b654-2a7c8da362d7).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8269#issuecomment-1516398664:307,Integrat,Integration,307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8269#issuecomment-1516398664,1,['Integrat'],['Integration']
Deployability,Passing integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/9a1e766a-0735-49c0-86ee-ab55a57787ac),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1509736338:8,integrat,integration,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1509736338,1,['integrat'],['integration']
Deployability,Passing integration test here: https://job-manager.dsde-prod.broadinstitute.org/jobs/2b9f4dc6-d058-4803-a583-5ab76fbd71e8,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7919#issuecomment-1170209017:8,integrat,integration,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7919#issuecomment-1170209017,1,['integrat'],['integration']
Deployability,Passing integration tests (all chrs) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/be35d4ae-7fd5-48ae-b7e1-a7c74eddd4ab); and chr20/x/y [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f3222e37-13a4-43fc-a341-cd7cdafed777),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8948:8,integrat,integration,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8948,1,['integrat'],['integration']
Deployability,"Passing run of GvsCreateVATFromVDS [here](https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20WGS%2010K%20Callset/job_history/7bb1410b-123c-4150-8a6b-f3d36234527a); Passing run of GvsCallsetStatistics [here](https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20WGS%2010K%20Callset/job_history/ecc67d79-ecbf-41c6-bbee-52be83327d64); (both are on the AoU 10K - so need your PMI-OPS account to see). Integration test ran [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/b1f35d64-4406-4fef-a3af-e86703f36148) - had one failure, but it was in the cost tracking, so probably not a concern for this PR",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8519#issuecomment-1721658082:424,Integrat,Integration,424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8519#issuecomment-1721658082,1,['Integrat'],['Integration']
Deployability,Passing run where generated from a VDS [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/12712c01-46c5-4968-b687-0360ac09f8e6); Passing run where used an existing sites-only VCF [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/e01f9bf2-2224-4be3-b09e-bf6289126621); Integration Test run [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/62087a48-696d-4ce9-aff8-243110c3dce0),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8977:351,Integrat,Integration,351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8977,1,['Integrat'],['Integration']
Deployability,Passing workflow here: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Exome%20Data%2049k/job_history/38d22351-33cd-4c2c-abf9-feccda71d40a. Mostly passing integration test here: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/4a7e6628-6c19-442d-90b8-202da267d8bb; (the failure was a bq time out.),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8374:155,integrat,integration,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8374,1,['integrat'],['integration']
Deployability,Patch O(n^2) algorithm in VCFHeader.addMetadataLineLookupEntry(),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3448:0,Patch,Patch,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3448,1,['Patch'],['Patch']
Deployability,Patch build_docker.sh -p option to push to GCR in addition to dockerhub,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3793:0,Patch,Patch,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3793,1,['Patch'],['Patch']
Deployability,Patch gatk-launch to allow it to run with standalone packaged GATK jars,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2090:0,Patch,Patch,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2090,1,['Patch'],['Patch']
Deployability,Patch htsjdk to propagate indices to CRAM readers correctly,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/788:0,Patch,Patch,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/788,1,['Patch'],['Patch']
Deployability,Patch is up at https://github.com/broadinstitute/gatk/pull/4203,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3845#issuecomment-358752939:0,Patch,Patch,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845#issuecomment-358752939,1,['Patch'],['Patch']
Deployability,PathSeq documentation update,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3918:22,update,update,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3918,1,['update'],['update']
Deployability,"PathSeqFilterSpark and PathSeqPipelineSpark clear all the sequences from the input header file, as the Bwa step only accepts unaligned reads. However, the header sequences were being cleared before the reads were loaded, causing WellformedReadFilter to remove any mapped reads (by failing to find the corresponding sequence name in the header). This PR fixes this bug by creating a deep copy of the header. It also refactors this code, which is used in both the Filter and Pipeline tools, into a utility function `checkAndClearHeaderSequences()` in PSUtils. Tests have also been added/updated accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3453:473,Pipeline,Pipeline,473,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3453,2,"['Pipeline', 'update']","['Pipeline', 'updated']"
Deployability,"Per discussions with @fleharty, we are looking to significantly revamp the automated somatic CNV evaluations in preparation for benchmarking the TH prototype. The existing evaluations use a few unsupported/experimental tools and idiosyncratic/redundant classes (e.g., the `src/main/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedinterval` class this issue concerns), the functionality of which we can hopefully move to python-based validation code. . The aforementioned code was purposefully decoupled from supported CNV code, but since then it has been incorporated into `Funcotator` tools and `ValidateBasicSomaticShortMutations`, at least. @jonn-smith @davidbenjamin can we discuss a plan for cleaning this code up? Would it be easy to use an existing TSV/XSV class to handle the functionality needed for these tools?. @jonn-smith perhaps we should also discuss the plan for future `FuncotateSegments` development/integration with @fleharty.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3884#issuecomment-526226506:937,integrat,integration,937,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3884#issuecomment-526226506,1,['integrat'],['integration']
Deployability,Picard integration.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3620:7,integrat,integration,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3620,1,['integrat'],['integration']
Deployability,"Picard style was to have arguments with default collection values be appended to rather than replaced if that argument is also specified on the command line. to remove the defaults you have to specifically pass in `null` and then the new options. this seems like totally bizarre behavior, I thought I had fixed it with my initial patch but it slipped through unchanged. `RevertSam` relies on this functionality, so its interface will need to change slightly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/175:330,patch,patch,330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/175,1,['patch'],['patch']
Deployability,"Picard tries to adhere to the following (but it's up to each tool to figure; out):. 1. Check input and output files for readability/writability as soon as; possible.; 2. Delete incomplete outputs in case of caught exception.; 3. Return non-zero value in case of error. On Sun, Mar 3, 2019 at 4:45 PM samuelklee <notifications@github.com> wrote:. > Just finished switching over all of the CNV tools to fail early if; > directories are not writeable---or do not exist and cannot be; > created---only to realize that this behavior is inconsistent with that of; > Picard IntervalListTools (which is used in the gCNV pipeline).; >; > That tool fails early if the output directory is not writeable or does not; > exist, and although there is a code path later that suggests that output; > directories should be created, it is not reached due to this early fail. It; > might be that this inconsistency was introduced in; > broadinstitute/picard#1208; > <https://github.com/broadinstitute/picard/pull/1208> and I did not catch; > it in my PR. @yfarjoun <https://github.com/yfarjoun> any opinions what; > the intended behavior should be? Are there any conventions for Picard tools; > in general?; >; > Perhaps we could enforce this at the engine level (maybe checks that are; > triggered by annotations such as suggested in #141; > <https://github.com/broadinstitute/gatk/issues/141>, if possible)? But; > this would only work for GATK tools and would still rely on the diligence; > of developers.; >; > In any case, I'll decide on and document a convention for the CNV tools,; > but I think it might be a quixotic dream to enforce consistent; > behavior---especially without breaking things downstream which may rely on; > existing, inconsistent behavior...; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4825#issuecomment-469067676>,; > or mute the thread; > <https://github.com/notifications",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-470113262:612,pipeline,pipeline,612,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-470113262,1,['pipeline'],['pipeline']
Deployability,Pip install and pin numpy version.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6413:4,install,install,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6413,1,['install'],['install']
Deployability,Pipeline with multiple datatypes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/281:0,Pipeline,Pipeline,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/281,1,['Pipeline'],['Pipeline']
Deployability,Placed a call to forceJVMLocaleToUSEnglish in Main.runCommandLineProgram so that integration tests can take advantage of this. Fixes #2557,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3064:81,integrat,integration,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3064,1,['integrat'],['integration']
Deployability,"Please count me also. It is very useful tool. My whole pipeline is with GATK4, so it would be best to have this tool too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4891#issuecomment-420247697:55,pipeline,pipeline,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4891#issuecomment-420247697,1,['pipeline'],['pipeline']
Deployability,"Please find the print_array_schema executable [here](https://github.com/GenomicsDB/GenomicsDB/releases/download/v1.3.1/print_array_schema). You may have to do a `chmod +x print_array_schema` after downloading.; ```; Usage: print_array_schema <genomicsdb-workspace-path>/<genomicsdb_array>; ```; This will print out all the information for the array, it does not know anything about the fragments. Look at the `Types` printed out by the tool. ; ```; e.g.; Types:; 	END: int64[1]; 	REF: char[var]; 	ALT: char[var]; 	ID: char[var]; 	QUAL: float32[1]; ...; Coordinates: int64; ```; Every fragment should have `__book_keeping.tdb.gz` and `__tiledb_fragment.tdb`. In addition, for each fragment, there should be one file for each type plus another file if it is a var type.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-722709713:94,release,releases,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-722709713,1,['release'],['releases']
Deployability,"Please find the standalone consolidation tool [here](https://github.com/GenomicsDB/GenomicsDB/releases/download/v1.3.1/consolidate_genomicsdb_array). The usage is `consolidate_genomicsdb_array <genomicsdb_workspace_path> <array_name>`, for example `./consolidate_genomicsdb_array ~/my_ws/ ""20\$1\$63025520""`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-724446496:94,release,releases,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-724446496,1,['release'],['releases']
Deployability,Please fix the broken 3.8-1 release with wrong pom.xml,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4685:28,release,release,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4685,1,['release'],['release']
Deployability,Please update jbwa with the current github version. A patch for PPC64 is merged with jbwa now. Thanks!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1914:7,update,update,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1914,2,"['patch', 'update']","['patch', 'update']"
Deployability,"Please update the GitHub description to use https://www.broadinstitute.org/gatk/ which saves one redirect, and is more secure with rogue DNS servers.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3211:7,update,update,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3211,1,['update'],['update']
Deployability,Please upgrade NIO to a version that has prefetching baked-in.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4986:7,upgrade,upgrade,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4986,1,['upgrade'],['upgrade']
Deployability,"Please, I would like to update my GATK dependency to the latest master. Nevertheless, the Barclay version included contains a bug that is solved in https://github.com/broadinstitute/barclay/commit/87c3fa228fa96d11b7177f8bfdfca4801c83a068, but a change in the usage method of Barclay before the fix to print hidden arguments broke the GATK command line class. Could it be possible to update to the latest Barclay master, please?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2454:24,update,update,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2454,2,['update'],['update']
Deployability,Plot called segments at end of ModelSegments pipeline.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4244:45,pipeline,pipeline,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4244,1,['pipeline'],['pipeline']
Deployability,"PlotSegmentedCopyRatio for 250bp bins takes ~15 minutes. (However, with #2858, plotting is now the slowest step in the pipeline!)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3554#issuecomment-327793286:119,pipeline,pipeline,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3554#issuecomment-327793286,1,['pipeline'],['pipeline']
Deployability,"Point taken on the squash, though I deliberately separated the copy of GATK3 integration tests using GATK3 data, since this would not get merged. It seems to make sense to keep that separate still?. i'll update examples, etc. i am honestly not that familiar updates to argument conventions for GATK4 - i'll give this a look but if you have more specifics that would help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-433417437:77,integrat,integration,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-433417437,3,"['integrat', 'update']","['integration', 'update', 'updates']"
Deployability,Polish up PathSeq and add pipeline tool,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3271:26,pipeline,pipeline,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3271,1,['pipeline'],['pipeline']
Deployability,Port IndelRealignment pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3104:22,pipeline,pipeline,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104,1,['pipeline'],['pipeline']
Deployability,"Port https://github.com/broadgsa/gatk-protected/pull/24; ```; Without this patch the stream is only closed (thus, flushed) when the; object is garbage collected. This is problematic when subsequent jobs; proceed and expect the output to be available, for example; AnalyzeCovariates. We see failures in approximately 50% of runs due to; this issue and they are confirmed as fixed when applying the patch (on; a busy machine using NFS storage).; ```. The tool `BaseRecalibratorSparkSharded` is affected. The fix will be in `BaseRecalibratorEngineSparkWrapper.saveTextualReport`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3161:75,patch,patch,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3161,2,['patch'],['patch']
Deployability,Port of the GATK3 Version of CombineGVCFs and its associated integration tests. . Fixes #16,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3718:61,integrat,integration,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3718,1,['integrat'],['integration']
Deployability,Ported CallSegments as CallCopyRatioSegments for ModelSegments CNV pipeline.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3731:67,pipeline,pipeline,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3731,1,['pipeline'],['pipeline']
Deployability,Ported Picard tool UpdateVcfSequenceDictionary,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2232:19,Update,UpdateVcfSequenceDictionary,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2232,1,['Update'],['UpdateVcfSequenceDictionary']
Deployability,Possibly you are running into the Spark performance regression described in https://github.com/broadinstitute/gatk/issues/4376. This was patched in the latest release (4.0.2.0) -- could you try running with that release and see if the issue is resolved?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4479#issuecomment-369947491:137,patch,patched,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4479#issuecomment-369947491,3,"['patch', 'release']","['patched', 'release']"
Deployability,"Posting at the suggetion of shlee. There's discussion about what parts of VariantEval will be ported to GATK4 or whether Picard's partially overlapping tool CollectVariantCallingMetrics will take this over. I want to at least make you aware that we've developed a tool we're calling VariantQC, which is built in GATK3 and runs VariantEval internally to generate data stratified in various ways to make HTML QC reports, sorta like FASTQC or MultiQC (https://github.com/bbimber/gatk-protected/releases). An example report is here: https://prime-seq.ohsu.edu/_webdav/Internal/Bimber/Public/%40files/VariantQC_Example.html. Our goal was always to port this to GATK4, polish it up, and then make it more generally available. Much of what this tool does is take the pre-built tables/reports from VariantEval and put them into HTML, but we also wrote some custom stratifications to bin data by filter, etc. Like this thread notes, VariantEval has a lot of features not in picard, and honestly we dont use many of them. However, the extensibility of Stratifier/VariantEvaluator are pretty important for us. . We realize this is prioritized against all the GATK4 features; however, 1) how set are plans about migration of VariantEval/merge w/ picard and 2) if most of VariantEval isnt going to be ported, can we pick it up in our repo? We could also potentially offer some assistance in porting the tool because we have a vested interest; however, unless the task is defined as porting VariantEval as close as possible to as-is (not that this is critical, but it's the simplest thing for the outsider to do), it would need some discussion around exactly what's planned.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-320737252:491,release,releases,491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-320737252,1,['release'],['releases']
Deployability,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6994:789,configurat,configuration,789,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994,2,['configurat'],['configuration']
Deployability,"Preparation for some refactoring related to TileDB integration. Extracted classes are package-protected for now, since they are not intended for direct use outside of the engine package.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1929:51,integrat,integration,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1929,1,['integrat'],['integration']
Deployability,Prevents a bug that occurs when a file path contains characters that are illegal in URIs. Specific example was when using `--tmp-dir file:///tmp/workflow#main` GATK would initially correctly interpret this as `/tmp/workflow#main` but then when setting the Java temp directory in `CommandLineProgram.java` line 164 it would send `/tmp/workflow#main` to `IOUtils.getAbsolutePathWithoutFileProtocol` which would then mangle it by turning it into a URI and then removing `file://` resulting in `/tmp/workflow%23main` which later causes issues when things like the Codecs attempt to write configuration files to the temp directory that doesn't exist. CWLTool often creates path names that contain `#` so workflows made by CWLTool and containing GATK can fail because of this bug.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6769:584,configurat,configuration,584,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6769,1,['configurat'],['configuration']
Deployability,"Previous behavior assumed that the NM tag was the number of substitutions (as would be implied by ""matches or mismatches"" in CIGAR lingo). This patches makes the function correctly account for indels as well.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3876:144,patch,patches,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3876,1,['patch'],['patches']
Deployability,"Previously we were relying on the gcloud package signing key retrieved; during build of the GATK base image. However, the base image is updated; so infrequently that it's possible that the key it uses has expired. To; address this, we now retrieve an updated key at the start of the Docker; build.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7180:136,update,updated,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7180,2,['update'],['updated']
Deployability,"Previously, reads with deletions at the current loci were not being included in; the pileups passed to isActive(), which was a difference vs. the default settings; in GATK3. This patch changes the default to be to include such reads in both; HaplotypeCaller and Mutect2. Resolves #3830",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3831:179,patch,patch,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3831,1,['patch'],['patch']
Deployability,"Previously, the only integration tests involving assembly region traversal were in gatk-protected,; which led to breakage. Resolves #2172",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2179:21,integrat,integration,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2179,1,['integrat'],['integration']
Deployability,Primarily the large integration tests check for the non-locatable; funcotation factories producing data. Regenerated the expected output from large tests. Fixes #5773,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5774:20,integrat,integration,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5774,1,['integrat'],['integration']
Deployability,PrintReads --remove-mates or --update-flags option,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6839:31,update,update-flags,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6839,1,['update'],['update-flags']
Deployability,Probably git. See `core.autocrlf` at https://git-scm.com/book/id/v2/Customizing-Git-Git-Configuration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431474812:88,Configurat,Configuration,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431474812,1,['Configurat'],['Configuration']
Deployability,Problem with gcnvkernel installation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8091:24,install,installation,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8091,1,['install'],['installation']
Deployability,"Profiling using JBuilder remotely on gsa5 (with a large load from other programs) seem to show that close to or over 50% of the CPU effort is dedicated to filter ""bad"" reads. <img width=""1006"" alt=""screen shot 2018-09-27 at 2 37 59 pm"" src=""https://user-images.githubusercontent.com/791104/46167159-09fe1f00-c263-11e8-8ea0-02621146659b.png"">. To reproduce you may run (or better make your copy and run on a different profiling port and folder):; ```; cd /dsde/working/valentin/crc-profiling; sh run.sh; ```; ```; #run.sh contents:; java -agentpath:./bin/linux-x64/libjprofilerti.so=port=5006,nowait -jar ./gatk-local.jar \ ; CollectReadCounts \ ; -I /dsde/working/CHM/33remap/msb2.m38.bam \; -R /seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta \; -O /tmp/test.tsv -L hg38.interval_list -imr OVERLAPPING_ONLY; ```. The sample was chosen kinda at random , is a CHM pseudo diploid sample but you could use an alternative. Please change profiling port and output file. On the profiling machine (presumably your laptop or desktop) you need to install JProfiler (Broad owns a license for that).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5233:1062,install,install,1062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5233,1,['install'],['install']
Deployability,Proposal: update gradle to 4.6,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4659:10,update,update,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4659,1,['update'],['update']
Deployability,Prototype TileDB integration (for CombineGVCFs and GenotypeGVCFs),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1647:17,integrat,integration,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1647,1,['integrat'],['integration']
Deployability,Publish release and nightly GATK jars to the Broad filesystem for internal users,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4208:8,release,release,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4208,1,['release'],['release']
Deployability,"Pushed needed updates to test data here, will merge once tests pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2163#issuecomment-246826685:14,update,updates,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2163#issuecomment-246826685,1,['update'],['updates']
Deployability,Pv sw alignerclass update,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3390:19,update,update,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3390,1,['update'],['update']
Deployability,"PyMC was updated from Theano (think of this as an old alternative to TensorFlow) to Aesara.; > 9. Since then, PyMC 5.9 has been released and the underlying backend has been updated again, from Aesara to PyTensor.; > 10. So if we are going to update the environment to support Python 3.10+, it probably makes sense to go all the way to PyMC 5.9. I've made some strides in this PR; as of [6b08f3a](https://github.com/broadinstitute/gatk/pull/8561/commits/6b08f3af205cb9af1f5c63a0786f9a5a52cd78c1), I've made enough updates to accommodate API changes so that cohort-mode inference for both GermlineCNVCaller and DetermineGermlineContigPloidy runs successfully under Python 3.10 and PyMC 5.9.0---although note that 5.9.1 has been released in the interim!. However, our work has just begun. Results now produced in the numerical tests mentioned above are quite far off from the original expected results. It remains to be seen whether this is due to the randomness of inference, some slight changes to the model prior that were necessitated by the API changes, or some bugs introduced in other code updates. (Also note that I believe Andrey's PR in item 4 already broke these tests, although the numerical differences were much smaller and more reasonable---but perhaps he can confirm. Also noting here that I think determinism is still currently broken as of this commit---there have been some changes to PyTensor/PyMC seeding so that our previous theano/PyMC3 hack no longer applies.). So I think the next step is to just go to scientific-level testing and see what the fallout is. Ideally, we'd still get good performance (or perhaps better! at least on the runtime side, hopefully...) and we can just update the numerical tests. But if performance tanks, then we might need to see whether I've introduced any bugs. @mwalker174 @asmirnov239 perhaps you can comment on what might be the appropriate test suite here----1kGP?. I'll also highlight again that this PR will remove TensorFlow and might require",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561:2422,update,updates,2422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561,1,['update'],['updates']
Deployability,Python script executor updates required for NeuralNetInference branch.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4218:23,update,updates,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4218,1,['update'],['updates']
Deployability,"Questions: I'm not sure how to integrate the count summary and output from these in hellbender. GATK uses a collection of filters, so it can query each filter individually for a count. Hellbender uses a single filter lambda, which represents a sequence of and'd and or'd filters, so the filter itself needs to report all of the counts based on component filter conditions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/613:31,integrat,integrate,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/613,1,['integrat'],['integrate']
Deployability,Quick update - this bug occurs when handling alternate alleles (I believe of size > 1 base) in 5' UTRs. I'm working on a fix now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-388905709:6,update,update,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-388905709,1,['update'],['update']
Deployability,Quick update to docs to include an FAQ section with the first common question populated. Already pushed to forum.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5755:6,update,update,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5755,1,['update'],['update']
Deployability,Quick update: the bug persisted using the most recent GATK v4.1.6.0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6521#issuecomment-604572065:6,update,update,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6521#issuecomment-604572065,1,['update'],['update']
Deployability,Quickstart based integration test [VS-357],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7812:17,integrat,integration,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7812,1,['integrat'],['integration']
Deployability,R1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...ellbender/utils/SparkToggleCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TcGFya1RvZ2dsZUNvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `0% <0%> (-92.308%)` | `0% <0%> (-6%)` | |; | [...roadinstitute/hellbender/utils/svd/SVDFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zdmQvU1ZERmFjdG9yeS5qYXZh) | `0% <0%> (-85.714%)` | `0% <0%> (-3%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.258%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> (ø)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | ... and [186 more](https://codecov.io/gh/broadinstitute/gatk/pull/3970/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3970#issuecomment-352141723:3017,pipeline,pipelines,3017,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3970#issuecomment-352141723,1,['pipeline'],['pipelines']
Deployability,"RAM. ```; The script runs the ComposeSTRTableFile to produce the table that is then read by CalibrateDragstrModel. ; ```; ./test.sh /restricted/projectnb/casa/wgs.hg38/adni/cram/ADNI_002_S_0413.hg38.realign.bqsr.cram; Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16G -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar ComposeSTRTableFile -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -O gvcf.STR/ADNI_002_S_0413.hg38.realign.bqsr/ADNI_002_S_0413.hg38.realign.bqsr.STR.table -I /restricted/projectnb/casa/wgs.hg38/adni/cram/ADNI_002_S_0413.hg38.realign.bqsr.cram; 13:44:55.228 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Apr 04, 2021 1:44:55 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:44:55.456 INFO ComposeSTRTableFile - ------------------------------------------------------------; 13:44:55.458 INFO ComposeSTRTableFile - The Genome Analysis Toolkit (GATK) v4.2.0.0; 13:44:55.458 INFO ComposeSTRTableFile - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:44:55.459 INFO ComposeSTRTableFile - Executing as farrell@scc-hadoop.bu.edu on Linux v3.10.0-1160.15.2.el7.x86_64 amd64; 13:44:55.459 INFO ComposeSTRTableFile - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:44:55.460 INFO ComposeSTRTableFile - Start Date/Time: April 4, 2021 1:44:55 PM EDT; 13:44:55.460 INFO ComposeSTRTableFile - ------------------------------------------------------------; 13:44:55.460 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182:4212,install,install,4212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182,1,['install'],['install']
Deployability,"README should mention new build targets ""gradle installSpark"" and ""gradle installAll"", remove mention of ""gradle sparkJar""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1302:48,install,installSpark,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1302,2,['install'],"['installAll', 'installSpark']"
Deployability,"README.md instructs developers to create the conda environment with the command:; ```; conda env create -n gatk -f scripts/gatkcondaenv.yml; ```; This currently fails with the following message (at least on MacOS):; ```; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/commands/install.py"", line 335, in run; wb.build(autobuilding=True); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/wheel.py"", line 749, in build; self.requirement_set.prepare_files(self.finder); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 809, in unpack_url; unpack_file_url(link, location, download_dir, hashes=hashes); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 715, in unpack_file_url; unpack_file(from_path, location, content_type, link); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 599, in unpack_file; flatten=not filename.endswith('.whl'); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 482, in unzip_file; zipfp = open(filename, 'rb'); FileNotFoundError: [Errno 2] No such file or directory: '/Users/markw/IdeaProjects/gatk/scripts/build/gatkPythonPackageArchive.zip'; ```; Moving gatkcondaenv.yml to the GATK root solves the issue. W",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4741:638,install,install,638,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4741,1,['install'],['install']
Deployability,README: R setup for running tests may need OS X update,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5389:48,update,update,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5389,1,['update'],['update']
Deployability,REATE_MD5 : false; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.CUSTOM_READER_FACTORY :; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.REFERENCE_FASTA : null; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 20:41:37.620 DEBUG ConfigFactory - Configuration file values:; 20:41:37.626 DEBUG ConfigFactory - gcsMaxRetries = 20; 20:41:37.626 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 20:41:37.626 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 20:41:37.626 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 20:41:37.626 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 20:41:37.626 DEBUG ConfigFactory - samjdk.compression_level = 2; 20:41:37.626 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 20:41:37.626 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 20:41:37.626 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 20:41:37.626 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 20:41:37.626 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 20:41:37.626 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 20:41:37.627 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 20:41:37.627 DEBUG ConfigFactory - codec_pack,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:4801,Configurat,Configuration,4801,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['Configurat'],['Configuration']
Deployability,"RITE\_FOR\_SAMTOOLS : true ; ; 00:12:21.143 INFO  BaseRecalibrator - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false ; ; 00:12:21.143 INFO  BaseRecalibrator - Deflater: IntelDeflater ; ; 00:12:21.144 INFO  BaseRecalibrator - Inflater: IntelInflater ; ; 00:12:21.144 INFO  BaseRecalibrator - GCS max retries/reopens: 20 ; ; 00:12:21.144 INFO  BaseRecalibrator - Requester pays: disabled ; ; 00:12:21.144 INFO  BaseRecalibrator - Initializing engine ; ; 00:12:21.485 INFO  FeatureManager - Using codec VCFCodec to read file file:///data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz ; ; 00:12:21.565 INFO  FeatureManager - Using codec VCFCodec to read file file:///data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz ; ; 00:12:21.688 INFO  FeatureManager - Using codec VCFCodec to read file file:///data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz ; ; 00:12:21.797 WARN  IndexUtils - Feature file ""file:///data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file ; ; 00:12:21.895 WARN  IntelInflater - Zero Bytes Written : 0 ; ; 00:12:21.966 INFO  BaseRecalibrator - Done initializing engine ; ; 00:12:21.969 INFO  BaseRecalibrationEngine - The covariates being used here: ; ; 00:12:21.969 INFO  BaseRecalibrationEngine -     ReadGroupCovariate ; ; 00:12:21.969 INFO  BaseRecalibrationEngine -     QualityScoreCovariate ; ; 00:12:21.969 INFO  BaseRecalibrationEngine -     ContextCovariate ; ; 00:12:21.969 INFO  BaseRecalibrationEngine -     CycleCovariate ; ; 00:12:22.016 INFO  ProgressMeter - Starting traversal ; ; 00:12:22.017 INFO  ProgressMeter -        Current Locus  Elapsed Minutes       Reads Processed     Reads/Minute. **How can I assign a temp directory and won't get the bug?**. I set the gatk environment using conda:. /data/xieduo/WES\_pipe/pipeline/bin/Minicond",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:18267,pipeline,pipeline,18267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['pipeline'],['pipeline']
Deployability,"Ran the updated version on 1000 shards with 11k samples, and there were no 503 or SSL errors at all.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3295#issuecomment-316438413:8,update,updated,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3295#issuecomment-316438413,1,['update'],['updated']
Deployability,"Rather than start off the exome genotyping task with a step to merge the query intervals for better GDB performance, make it an option as for Import in #5540 . This is necessary to get the exome joint calling pipeline onto official GATK release dockers.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5741:209,pipeline,pipeline,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5741,2,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"Rationale: certain evaluators use a pedigree. This PR is a minor change that lets VariantEvalArgCollection supply the PedigreeValidationType. It defaults to the current behavior, which is to always use STRICT. It includes an integration test to cover this feature.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7240:225,integrat,integration,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7240,1,['integrat'],['integration']
Deployability,Re-activate async I/O for the samtools package only (not tribble) after next htsjdk release,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1653:84,release,release,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1653,1,['release'],['release']
Deployability,"Re-enable tests for htsget now that the reference server is back to a stable version. * Some tests were disabled due to issues with the htsget reference server, now that it's back to running an older stable version; the tests which work on that version are re-enabled. * Partial fix for #6640 another commit will be needed when the server is upgraded to support fields/tags. The field test had to be disabled because it doesn't seem like the current server version supports the parameter correctly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6668:342,upgrade,upgraded,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6668,1,['upgrade'],['upgraded']
Deployability,"Re-opening this one, since the ""craft test case"" part of this ticket has not yet been done -- we've just moved to an updated snapshot.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3118#issuecomment-316801259:117,update,updated,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3118#issuecomment-316801259,1,['update'],['updated']
Deployability,Re-packaging SV pipeline classes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2698:16,pipeline,pipeline,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2698,1,['pipeline'],['pipeline']
Deployability,Re-runs with PR feedback incorporated:. - [Integration](https://app.terra.bio/#workspaces/gvs-dev/mlc%20GVS%20Quickstart%203%20samples/job_history/e8b6077d-a90a-4cc2-be0d-0a08cb98280a); - [Beta](https://app.terra.bio/#workspaces/gvs-dev/mlc%20GVS%20Quickstart%203%20samples/job_history/52a3c02e-485b-4320-bb21-07931ecbe7dd),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1632980023:43,Integrat,Integration,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1632980023,1,['Integrat'],['Integration']
Deployability,ReCapSeg uses HD5F to store matrix data. This issue is about addressing hdf5 library integration in Hellbender. . Time estimate of 5 man days.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/498:85,integrat,integration,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/498,1,['integrat'],['integration']
Deployability,"Read count logging for PathSeq Filter, Score, and Pipeline tools",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3611:50,Pipeline,Pipeline,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611,1,['Pipeline'],['Pipeline']
Deployability,"Read counts at different stages of the PathSeq pipeline are now logged using `MetricsFile`. The filter metrics contains the number of reads remaining and number of reads filtered at each step (after filtering pre-aligned reads, low quality/complexity reads, host reads, and duplicates). The score metrics give number of pathogen-mapped and unmapped reads. These metrics are now validated in the PathSeq integration tests, which have also been refactored to use DataProviders instead of separate functions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3611:47,pipeline,pipeline,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611,2,"['integrat', 'pipeline']","['integration', 'pipeline']"
Deployability,ReadSparkSource.getHeader is fragile and needs to be updated,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1346:53,update,updated,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1346,1,['update'],['updated']
Deployability,"Reads with multiple indels are skipped?. On Mon, Sep 23, 2019, 6:32 PM Nils Homer <notifications@github.com> wrote:. > ------------------------------; > You can view, comment on, or merge this pull request online at:; >; > https://github.com/broadinstitute/gatk/pull/6177; > Commit Summary; >; > - Update LeftAlignIndels documentation; >; > File Changes; >; > - *M*; > src/main/java/org/broadinstitute/hellbender/tools/LeftAlignIndels.java; > <https://github.com/broadinstitute/gatk/pull/6177/files#diff-0> (4); >; > Patch Links:; >; > - https://github.com/broadinstitute/gatk/pull/6177.patch; > - https://github.com/broadinstitute/gatk/pull/6177.diff; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/6177?email_source=notifications&email_token=ABSGC5G4S2GMEBIMTJZEBBLQLE7YNA5CNFSM4IZUFPPKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HNFD7YQ>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABSGC5CJ26F4N7WB4LYXEDDQLE7YNANCNFSM4IZUFPPA>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6177#issuecomment-535485844:298,Update,Update,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6177#issuecomment-535485844,3,"['Patch', 'Update', 'patch']","['Patch', 'Update', 'patch']"
Deployability,ReadsPipelineSpark needs an integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1162:28,integrat,integration,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1162,1,['integrat'],['integration']
Deployability,"Reads` from Mutect2 (https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java#L326); - separate consideration of overlapping reads when calculating genotype likelihoods, as used in UnifiedGenotyper (https://github.com/broadgsa/gatk-protected/blob/aa8764d6c3de146856b174a8674fa787a6311d7c/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/genotyper/DiploidSNPGenotypeLikelihoods.java#L183). As I see it, #4958, which seems to be more related to read likelihood calculation, is where a more involved solution, with more fundamental changes, might be warranted. From my perspective (not being especially familiar with the pairHMM model), an ideal solution would transition the pairHMM from read likelihood to a ""fragment likelihood"" or ""haplotype likelihood"" when information from read pairs is available, even if they aren't overlapping. The idea would be that a modified pairHMM model could produce a single fragment (or haplotype) likelihood for a given read pair. Such an approach would unify the issues of ""merging"" read pairs and phasing in a read-pair aware manner (and potentially also modeling PCR errors). In principle, a ""fragment likelihood""-type approach could even incorporate info from corresponding PCR duplicates to improve the results when sequencing error rates are high. This sort of approach could also flow into the genotype likelihood calculation by providing a single, merged fragment likelihood to consider rather than a separate read likelihood for each read. UPDATE: On further thought, it probably wasn't a good idea for me to use the terms fragment likelihood or haplotype likelihood to distinguish the proposed approach, since the read likelihood is effectively already calculating those. Probably a better term would be ""read set likelihood"", where the read set would consist of paired reads and potentially also any corresponding PCR duplicate reads.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5436#issuecomment-443558420:2682,UPDATE,UPDATE,2682,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5436#issuecomment-443558420,1,['UPDATE'],['UPDATE']
Deployability,Ready for you! I made it depend on the updated htsjdk (snapshot) and Travis is now happy.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2331#issuecomment-274583358:39,update,updated,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2331#issuecomment-274583358,1,['update'],['updated']
Deployability,"Reasoning:; - task will not recreate/overwrite table if it exists; - task does not take long, so unnecessary runs are not costly in time or $; - when not volatile, Beta users need to run with call-caching off if they re-run the pipeline. run where tables already existed: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/64782949-33dd-41ef-b3f7-5e88cc5a5dcc. integration run: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/9e79ef7f-9e64-46c7-8749-83909a5d423f (it failed the end tests, but the tables were created/populated as expected)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8765:228,pipeline,pipeline,228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8765,2,"['integrat', 'pipeline']","['integration', 'pipeline']"
Deployability,"Rebased and squashed on top of sl_wgs_acnv_headers_docs. Here is the log of squashed commits, for reference:. ````; commit 3eda4b18888f38249be39f99901d8453a4de50d6; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Thu Dec 28 14:56:27 2017 -0500. updated command lines for WDL tests for C29. commit 7ce1369943cce4ae9cfb5e96455d18d3960e9b77; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Thu Dec 28 13:30:21 2017 -0500. use C29 and decrease gcnv_max_training_epochs. commit 68772cba486b44ebc8cf8bfc2b600c1e8a406c61; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Sun Dec 17 19:20:05 2017 +0330. documentation update of GermlineCNVCaller and DetermineGermlineContigPloidy. commit c032281f8c43a80e4ec8cb96eb66397ad2acf9b7; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 15 18:14:35 2017 -0500. Fixed imr kebab case in WDL, moved argument classes, removed GenomeLocParser, fixed up gCNV WDL readme. commit be84a804f6ab6fbb815995db9c116d1db950ab8b; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 13:55:08 2017 -0500. removed extra comma in gCNV Case WDL test JSON. commit cb379b866d425f12f5525ecb28ad0b636a528d44; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 12:58:59 2017 -0500. added missing cpu parameters to gCNV Case WDL tasks. commit eed85f6c70f4a7f15e0765b5f15a1bf8541c151e; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 11:26:31 2017 -0500. disabled some gCNV WDL tests. commit 6d8ca07fef41518b5b157fb9a214d4536c617156; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 10:54:54 2017 -0500. fixed DenoiseReadCountsIntegrationTest files. commit adfbef12f2ab90f93b49a4f786979549648e1f22; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Mon Dec 11 02:22:56 2017 -0500. removed CNV evaluation code from this branch. commit 18c8d31f39a1964474c5d7b12ee8cbfafc4ac9e2; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Sun Dec 10 00:19:58 2017 -0500. GS VCF parser outputs dict for samples ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:248,update,updated,248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,4,['update'],"['update', 'updated']"
Deployability,Rebased and updated -- will merge once tests pass.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3911#issuecomment-356119436:12,update,updated,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3911#issuecomment-356119436,1,['update'],['updated']
Deployability,Rebased to incorporate WDL 1.0 changes from #6502. @fleharty let's get this in for the 4.1.6.1 release?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6482#issuecomment-606764765:95,release,release,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6482#issuecomment-606764765,1,['release'],['release']
Deployability,"Rebasing on the most recent commit to `ah_var_store` with some fixups, successful integration run [here](https://app.terra.bio/#workspaces/gvs-dev/mlc%20GVS%20Quickstart%203%20samples/job_history/1156657f-5c31-446a-92e1-5e39ae012ce2). The Docker CI breakages appear to be affecting all Java 8 based branches, not just this one (I currently have no idea what's wrong there).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8434:82,integrat,integration,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8434,1,['integrat'],['integration']
Deployability,"ReblockGVCF (which we run in production) will revert to PLs, so this behavior is irrelevant in the warp pipelines",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6269#issuecomment-1377805998:104,pipeline,pipelines,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6269#issuecomment-1377805998,1,['pipeline'],['pipelines']
Deployability,Rebuilt the base image so we have the newest ubuntu and library patches.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9005:64,patch,patches,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9005,1,['patch'],['patches']
Deployability,Recent refactoring seems to have introduced a bug in pileup mode that failed to enforce the limit on the number of haplotypes to be considered. With this patch:. - HaplotypeCaller once again respects the limit on haplotypes before genotyping.; - Changed some `HashSet`s to `LinkedHashSets` to preserve determinism.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8489:154,patch,patch,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8489,1,['patch'],['patch']
Deployability,"Recently I was setting up GATK to run in a VM and I had forgotten to install Java8 onto the machine. When I tried to run GATK from the launch script I ran into the following error: ; ```; Using GATK jar /home/emeryj/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/emeryj/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar -help; Traceback (most recent call last):; File ""./gatk"", line 479, in <module>; main(sys.argv[1:]); File ""./gatk"", line 152, in main; runGATK(sparkRunner, sparkSubmitCommand, dryRun, gatkArgs, sparkArgs, javaOptions); File ""./gatk"", line 328, in runGATK; runCommand(cmd, dryrun); File ""./gatk"", line 384, in runCommand; check_call(cmd, env=gatk_env); File ""/usr/lib/python2.7/subprocess.py"", line 181, in check_call; retcode = call(*popenargs, **kwargs); File ""/usr/lib/python2.7/subprocess.py"", line 168, in call; return Popen(*popenargs, **kwargs).wait(); File ""/usr/lib/python2.7/subprocess.py"", line 390, in __init__; errread, errwrite); File ""/usr/lib/python2.7/subprocess.py"", line 1024, in _execute_child; raise child_exception; OSError: [Errno 2] No such file or directory; ```; This should perhaps be made a little bit clearer for users as this isn't particularly helpful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5992:69,install,install,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5992,1,['install'],['install']
Deployability,Reduce the logging a bit.; Probably should make a PR directly into gatk master so that when we next merge gatk master changes we'll get this goodness?. Integration run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f8c38f97-7945-414f-9432-13b2f12138bb) (note failed one of the subtests for a random docker pull error); Example CreateFilterSet run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/b2e7eb86-e494-4891-885b-5a96cb1056b3),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8650:152,Integrat,Integration,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8650,1,['Integrat'],['Integration']
Deployability,Reenable ReferenceTwoBitSourceUnitTest after ADAM 0.18 is released,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/957:58,release,released,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/957,1,['release'],['released']
Deployability,"Refactor Funcotator scripts to take arguments, not internal configurations",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5346:60,configurat,configurations,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5346,1,['configurat'],['configurations']
Deployability,"Refactor python code from extract dir into a scripts directory. Passing Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f85602d0-6dc5-49d6-82d1-eb58e9966021); Passing VAT Creation work [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/ddc7fcf9-5fb7-44e2-8117-721389d4f858), [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/0d705f21-3362-4890-b925-5bed2646fe4d), and [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/15cfe125-e700-44c8-b9d0-c3e98d7db4c0)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9017:72,Integrat,Integration,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9017,1,['Integrat'],['Integration']
Deployability,"Reflect the changes from https://github.com/broadinstitute/picard/pull/1782 in the GATK doc build. Note that this requires a new version of Picard that is not yet released. Also, I suppressed deprecation warnings caused by the use of obsolete Java 8 javadoc classes (FieldDoc) for now, since it causes the Java 11 build to fail. A new metrics category shows up in the doc now, with all of the Picard and GATK metrics:. <img width=""1252"" alt=""Screen Shot 2022-10-18 at 4 42 37 PM"" src=""https://user-images.githubusercontent.com/10062863/196540823-a6108b75-c9e7-44c0-a4ba-1d8f927fe5b6.png"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7749:163,release,released,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7749,1,['release'],['released']
Deployability,"Regarding the non-Docker integration tests failing earlier today, I think this was because the R packages were added to the Travis cache in #3101. @cmnbroad cleared the cache to see if we could reproduce a compiler error introduced in #3934 on Travis (for the record, we could reproduce it on my local Ubuntu machine and gsa5, but not on Travis). This removed the cached getopt dependency, which then caused tests to fail. See #4246.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441:25,integrat,integration,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441,2,['integrat'],['integration']
Deployability,"Regarding writing the SAM file, I now remember why it was created instead of using existing ones: the SV pipeline needs to be able to write to HDFS, hence cannot rely on a `File` interface&mdash;which the `ReadUtils.createCommonSAMWriter(...)` exposes. ; So the current hand rolled version in `SVFileUtils.getSAMFileWriter()` calls into `BucketUtils.createFile(...)` for that HDFS compatibility, and then makes use of the `SAMFileWriterFactory.makeBAMWriter(final SAMFileHeader header, final boolean presorted, final OutputStream stream)`, unlike `ReadUtils.createCommonSAMWriter(...)` which calls into `SAMFileWriterFactory.makeSAMOrBAMWriter(final SAMFileHeader header, final boolean presorted, final Path outputPath)`. So in short: HDFS compatibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3674#issuecomment-339391912:105,pipeline,pipeline,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3674#issuecomment-339391912,1,['pipeline'],['pipeline']
Deployability,"Regression test for #3163. A unit test was added in #3164, but we should add an integration test as well.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3181:80,integrat,integration,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3181,1,['integrat'],['integration']
Deployability,Related to this when would the best practices for this analysis be released:; https://software.broadinstitute.org/gatk/best-practices/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2907#issuecomment-335941911:67,release,released,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2907#issuecomment-335941911,1,['release'],['released']
Deployability,"Related, I have found the documentation for the `-no-overlaps` option to be a bit unclear. Especially with it being a default option now in the WARP [VariantCalling WDL script](https://github.com/broadinstitute/warp/blob/develop/pipelines/broad/dna_seq/germline/variant_calling/VariantCalling.wdl), I would hope that there would be a better description of where the overlaps come from, when we do and don't want to allow them, how downstream results would be affected, and why this is now a default option. If I should make this documentation request a separate issue, let me know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103#issuecomment-1329756065:229,pipeline,pipelines,229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103#issuecomment-1329756065,1,['pipeline'],['pipelines']
Deployability,Release GATK 4.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5636:0,Release,Release,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5636,1,['Release'],['Release']
Deployability,Release doc additions [VS-1376],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8927:0,Release,Release,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8927,1,['Release'],['Release']
Deployability,Release docs fixup [VS-1088],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8548:0,Release,Release,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8548,1,['Release'],['Release']
Deployability,Release new version of GVS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8883:0,Release,Release,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8883,1,['Release'],['Release']
Deployability,"Released `gatkbase-3.3.0` to `broadinstitute/gatk:gatkbase-3.3.0`, but getting `Permission ""artifactregistry.repositories.uploadArtifacts"" denied on resource ""projects/broad-gatk/locations/us/repositories/us.gcr.io""` when trying to push to `us.gcr.io/broad-gatk/gatk:gatkbase-3.3.0`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2201879544:0,Release,Released,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2201879544,1,['Release'],['Released']
Deployability,"Relies on https://github.com/disq-bio/disq/pull/69, which has not yet been merged or released.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5485:85,release,released,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5485,1,['release'],['released']
Deployability,Remove -1 length once a corrected version of the exome interval list is released.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2089:72,release,released,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2089,2,['release'],['released']
Deployability,Remove EXPERIMENTAL_FPGA_LOGLESS_CACHING option from PairHMM after next GKL release,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6673:76,release,release,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6673,1,['release'],['release']
Deployability,Remove NuMTs from MT pipeline and updates wdl to GATK4.1.1.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5847:21,pipeline,pipeline,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5847,2,"['pipeline', 'update']","['pipeline', 'updates']"
Deployability,Remove Unneeded Task and Update Docs [VS-817],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8702:25,Update,Update,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8702,1,['Update'],['Update']
Deployability,Remove download of picard.jar from .travis.yml and update Mutect2 WDL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3625:51,update,update,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3625,1,['update'],['update']
Deployability,"Remove gatk-launch dependency on settings.gradle, update gatkZipDistribution target",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3054:50,update,update,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3054,1,['update'],['update']
Deployability,Remove reference to `PipelineOptions` SV package,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3477:21,Pipeline,PipelineOptions,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3477,1,['Pipeline'],['PipelineOptions']
Deployability,Remove some uses of dataflow.sdk.options.PipelineOptions,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2786:41,Pipeline,PipelineOptions,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2786,1,['Pipeline'],['PipelineOptions']
Deployability,Remove travis R install and only run R tests on the Docker.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6454:16,install,install,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6454,1,['install'],['install']
Deployability,Removed GATK3.5 VCFs from HC integration test files.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7634:29,integrat,integration,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7634,1,['integrat'],['integration']
Deployability,Removed mapping error rate from estimate of denoised copy ratios output by gCNV and updated sklearn.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7261:84,update,updated,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7261,1,['update'],['updated']
Deployability,Removed undocumented mid-p correction to p-values in exact test of Hardy-Weinberg equilibrium and updated corresponding tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394:98,update,updated,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394,2,['update'],['updated']
Deployability,Removing the beta tag in advance of the 4.1 release. . Resolves #4675,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5603:44,release,release,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5603,1,['release'],['release']
Deployability,"Reopening -- @ldgauthier reports that this error still occurs even after the patch in https://github.com/broadinstitute/gatk/pull/5099. With that patch, we are now retrying on `UnknownHostException`, but the retries are all failing: . ```; [August 14, 2018 7:09:18 AM UTC] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 896.64 minutes.; Runtime.totalMemory()=3966238720; java.util.concurrent.CompletionException: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: All 20 reopens failed. Waited a total of 1918000 ms between attempts; at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273); at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280); at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1592); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: All 20 reopens failed. Waited a total of 1918000 ms between attempts; at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.lambda$getFeatureReadersInParallel$614(GenomicsDBImport.java:605); at java.util.LinkedHashMap.forEach(LinkedHashMap.java:684); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.getFeatureReadersInParallel(GenomicsDBImport.java:600); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.createSampleToReaderMap(GenomicsDBImport.java:491); at com.intel.genomicsdb.importer.GenomicsDBImp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412904420:77,patch,patch,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412904420,2,['patch'],['patch']
Deployability,"Reopening this ticket, as it seems not to have been completely resolved by the patch in https://github.com/broadinstitute/gatk/pull/6510",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6473#issuecomment-669238395:79,patch,patch,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6473#issuecomment-669238395,1,['patch'],['patch']
Deployability,Replace MannWhitneyU with updated version from GATK3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2604:26,update,updated,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2604,2,['update'],['updated']
Deployability,Replace literal arguments with variables in several integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4416:52,integrat,integration,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4416,1,['integrat'],['integration']
Deployability,Replaced bash script in gCNV ScatterIntervals task with updated version of IntervalListTools.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5414:56,update,updated,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5414,1,['update'],['updated']
Deployability,Replaced by evaluation of new gCNV pipeline.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3009#issuecomment-356705190:35,pipeline,pipeline,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3009#issuecomment-356705190,1,['pipeline'],['pipeline']
Deployability,"Report; ### Affected tool(s) or class(es); HaplotypeCaller --max-reads-per-alignment-start. ### Affected version(s); - [x] Latest public release version [4.1.2.0]; - [ ] Latest master branch as of [date of test?]. ### Description; We used GATK4 to detect a fairly large duplication (60bp) in a control sample. We did sequenced two replicates for this sample, one having significantly more coverage than the other.With default GATK4 parameter the duplication was only detected in the sample with the lowest coverage. After inspection of GATK4 parameter we found that it was the downsampling throught the --max-reads-per-alignment-start that was in cause.Indeed, all the reads that contains the duplications are softcliped (see IGV capture below) because the insertion/duplication event is too bigged to be correctly aligned by BWA. This causes all reads containing the duplication to have the same start position in the BAM file. Then, the downsampling based on start position must drastically reduce the signal and the variant is skipped. This explains why the variant was missed at high coverage level and not in the replicates with lower signal.We think that the downsampling should take Softclips into account to be more reliable, but maybe you have a better idea.Also we did some performance evaluation and GATK4 runned faster with the downsampling desactivated. Is it normal ?; ![duplication](https://user-images.githubusercontent.com/53903734/62783152-17f41180-babc-11e9-9ddb-bed3c3042d97.png). #### Steps to reproduce; Run GATK4 with default parameters on the BAM containing the duplication (we can provide a toy). Disable --max-reads-per-alignment-start by switching the value to 0 to enable the identification of the duplication. #### Expected behavior; The duplication should have been found because the downsampling on start position does not take into accout the reads softclips. #### Actual behavior; The duplication is missed at high coverage depth",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6088:137,release,release,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6088,1,['release'],['release']
Deployability,Request: fine-grained configuration for codec packages for downstream projects,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4180:22,configurat,configuration,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4180,1,['configurat'],['configuration']
Deployability,Request: update Barclay dependency,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2454:9,update,update,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2454,1,['update'],['update']
Deployability,Requires a new htsjdk release - draft state until then.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6763:22,release,release,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6763,1,['release'],['release']
Deployability,"Requires upgrades to Hadoop-BAM (not yet released) and htsjdk. Fixes https://github.com/broadinstitute/gatk/issues/1346, https://github.com/broadinstitute/gatk/issues/1261, https://github.com/broadinstitute/gatk/issues/1175, https://github.com/broadinstitute/gatk/issues/1326, https://github.com/broadinstitute/gatk/issues/1259, and much of the underlying code for https://github.com/broadinstitute/gatk/issues/1270, which will be enabled in a separate PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1469:9,upgrade,upgrades,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1469,2,"['release', 'upgrade']","['released', 'upgrades']"
Deployability,"Researcher reports error in GenotypeGVCFs that uses a GenomicsDB database using v4.0.5.0. Removing `new qual` param OR using v4.0.4.0 allows the command to run without error. I saw a similar error with v4.0.5.1 when I tried to add `new qual` to a workshop hands-on tutorial GenotypeGVCFs step using a GenomicsDB database. ---; Hi,. I am trying to process locally 260 WES gvcf through joint discovery wdl pipeline. I encountered an error at GenotypeGVCFs below which I am not sure how to proceed. I have used all the default reference libraries and only modified the merge_count in the script to be 8144 so that my server resources won't be maxout fully in the ImportGVCFs step. . [https://github.com/gatk-workflows/gatk4-germline-snps-indels/blob/master/joint-discovery-gatk4-local.wdl](https://github.com/gatk-workflows/gatk4-germline-snps-indels/blob/master/joint-discovery-gatk4-local.wdl ""https://github.com/gatk-workflows/gatk4-germline-snps-indels/blob/master/joint-discovery-gatk4-local.wdl""). ```; 23:17:43.992 WARN InbreedingCoeff - Annotation will not be calculated, must provide at least 10 samples; 23:17:44.064 WARN InbreedingCoeff - Annotation will not be calculated, must provide at least 10 samples; 23:17:46.334 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),30.197597194999727,Cpu time(s),28.791204838999864; [June 25, 2018 11:17:46 PM UTC] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 4.01 minutes.; Runtime.totalMemory()=5354029056; java.lang.IllegalArgumentException: log10LikelihoodsOfAC are bad 2.559797571100845E-21,NaN; 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AFCalculationResult.<init>(AFCalculationResult.java:72); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.getLog10PNonRef(AlleleFrequencyCalculator.java:143); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotype",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4975:404,pipeline,pipeline,404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4975,1,['pipeline'],['pipeline']
Deployability,"Responded to most of the review, but still need to add a proper integration test and fix up the pipeline test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4800#issuecomment-393337753:64,integrat,integration,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4800#issuecomment-393337753,2,"['integrat', 'pipeline']","['integration', 'pipeline']"
Deployability,"Responded to review comments. Since we now have a mix of ""obsolete"", ""approved"", and ""placeholder"" program groups that are easily confused (some obsolete groups look similar to new approved groups, i.e., ReadProgramGroup which is obsolete, and ReadsDataGroup, which is approved, but a placeholder for Picard. So I added a comment to each PG class marking it as obsolete, or as a placeholder. For the new, approved groups, I just added a comment containing the summary text. I also fixed an existing problem where we QCProgramGroup was used for some actual tools, and some tools that were jut for testing. I updated the test tools to point to the TestProgramGroup, and obsoleted QCProgramGroup (like all of the obsolete groups, there are still tools referencing it). The sooner we merge this the better.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3924#issuecomment-350274620:607,update,updated,607,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3924#issuecomment-350274620,1,['update'],['updated']
Deployability,Restore link in VariantFiltration to point to update online JEXL doc.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5525:46,update,update,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5525,1,['update'],['update']
Deployability,"Results are in:. Using the branch for PR #4971 with the value `ALIGNMENT_LOW_READ_UNIQUENESS_THRESHOLD` set to 10 and 19, while keeping the gap split children together (that is, method ; `private static GoodAndBadMappings splitGaps(final GoodAndBadMappings configuration, final boolean keepSplitChildrenTogether)` is called with `false` for its second parameter). Here are the comparisons:; ```; simple variants unique TP unique FP; size-10 filter: 10756 24 101; size-19 filter: 10755 1 0; ```. So I think your suggestion is a better trade off!. What I'll do is make that parameter an (advanced) CLI argument in PR #4971 , and experiment more to settle on a good default value.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-403890890:257,configurat,configuration,257,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-403890890,2,['configurat'],['configuration']
Deployability,"Returning false instead of throwing when data is missing in the `GoogleGenomicsReadToGATKReadAdapter` is misleading -- we don't know the answer to the question the client is asking in such cases, so returning false is not correct behavior. If these fields are actually missing in the underlying reads we really do want to blow up with an exception on access, as it means the read object is not usable by us (and the query that produced these incomplete objects likely needs to be modified). Could you restore the previous versions of these methods (`isSecondaryAlignment()`, `isDuplicate()`, etc.) before I review?. As for the Google read converters, could you open a separate ticket with your description of the inconsistencies so we can decide whether to submit a patch?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/871#issuecomment-136771148:766,patch,patch,766,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/871#issuecomment-136771148,1,['patch'],['patch']
Deployability,"Revamping the existing somatic validation pipeline needs to be done before development of the TH prototype can continue. - [ ] Identify test bed of TCGA samples from various tumor types. We can mix tumor-normal samples (as I've done at the counts/allelic-counts level in preliminary evaluations of the TH prototype) to expand the effective number of samples.; - [ ] Determine minimal version of current CGA ABSOLUTE pipeline (to be used as a baseline for comparison).; - [ ] Generate and manually curate ABSOLUTE results and narrow samples down to those with relatively robust solutions.; - [ ] Construct ModelSegments/M2 -> ABSOLUTE pipeline (will at least require minor development/tuning of ModelSegments output -> ABSOLUTE input conversion script, may also require germline tagging, see related #5804) and evaluate.; - [ ] Construct ModelSegments/M2 -> TH pipeline and evaluate.; - [ ] Remove unsupported code/tools. See https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199 for a summary. We should make sure that any users that would be affected by this are notified and prepare accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699:42,pipeline,pipeline,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699,4,['pipeline'],['pipeline']
Deployability,"Revert ""Bump to ADAM 0.23.0 release. (#4044)""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4428:28,release,release,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4428,1,['release'],['release']
Deployability,"Revert ""Upgrade htsjdk to v3.0.0. (#7867)""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7960:8,Upgrade,Upgrade,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7960,1,['Upgrade'],['Upgrade']
Deployability,"Revert ""Upgrade to htsjdk 2.11.0. Make TargetCodec indexable.""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3441:8,Upgrade,Upgrade,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3441,1,['Upgrade'],['Upgrade']
Deployability,Revert 403 GCS retry patch once Google fixes the underlying service,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3800:21,patch,patch,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3800,1,['patch'],['patch']
Deployability,Revert explicit GAR references in our Docker build scripts for now. Variants team members are not Methods team members and thus do not have the access required to make Variants GAR repos public in the `broad-dsde-methods` project. Note that Variants images are still ending up in GAR thanks to the magic of DevOps redirects. This PR also retains the Docker image ID-based referencing that was introduced at the same time as the explicit GAR references that are now being backed out. Successful (or at least non-instafailing) [integration run here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/2f00b836-0c2d-41e9-84b1-b8c6a2bea8f6).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8789:526,integrat,integration,526,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8789,1,['integrat'],['integration']
Deployability,Revert some phasing changes that were unnecessary for AoU and broke our integration tests. [Integration run](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/ba93baa2-9971-4c90-8ce3-635702a81eb6),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8590:72,integrat,integration,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8590,2,"['Integrat', 'integrat']","['Integration', 'integration']"
Deployability,Revert upgrade to GenomicsDB 1.1.2 to fix a regression,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6204:7,upgrade,upgrade,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6204,1,['upgrade'],['upgrade']
Deployability,"Reverting the update to gkl 0.3.1 for now because we've encountered some downstream errors that are making it impossible to update gatk-protected. This reverts commit 9e3c6e3d7370c503d2a57be0c662fb1016d8b764, reversing; changes made to 767974906e91c90079cefa4512b463138ca09f68.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2319:14,update,update,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2319,2,['update'],['update']
Deployability,"Reworks classes used by `JointGermlineCNVSegmentationIntegration` for SV clustering and defragmentation. The design of `SVClusterEngine` has been overhauled to enable the implementation of `CNVDefragmenter` and `BinnedCNVDefragmenter` subclasses. Logic for producing representative records from a collection of clustered SVs has been separated into an `SVCollapser` class, which provides enhanced functionality for handling genotypes for SVs more generally. A number of bugs, particularly with max-clique clustering, have been fixed, as well as a parameter swap bug in `JointGermlineCNVSegmentationIntegration`. This is the first of a series of PRs for an experimental Java-based implementation of some modules in `gatk-sv` pipeline, including SV vcf merging, clustering, evidence aggregation, and genotyping.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7243:724,pipeline,pipeline,724,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7243,1,['pipeline'],['pipeline']
Deployability,"Right now, in master pipeline we have one `INSERTED_SEQUENCE` AND `INSDERTED_SEQUENCE_MAPPINGS` annotation each, with the 2nd annotation taking possibly multiple values whereas the 1st only 1 value. We need to improve this. ; A possible solution is to have one annotation with paired multiple entries as suggested by @cwhelan . The goal is to make transforming symb alt allele records to BND records easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3647:21,pipeline,pipeline,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3647,1,['pipeline'],['pipeline']
Deployability,"Right, seems to be a recent update, Using the very latest release works. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5627#issuecomment-459716792:28,update,update,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5627#issuecomment-459716792,2,"['release', 'update']","['release', 'update']"
Deployability,"Right, so I'd seen that explainer of interval_list but wasn't sure how to go about generating an interval_list to test what I'm generating. Specifically, I did a small test using some of the test resource gvcfs and generated a genomicsdb workspace - something like this:. ```; ./gatk GenomicsDBImport -V ./src/test/resources/large/gvcfs/HG00096.g.vcf.gz -V ./src/test/resources/large/gvcfs/HG00268.g.vcf.gz -V ./src/test/resources/large/gvcfs/NA19625.g.vcf.gz --genomicsdb-workspace-path test -L chr20; ```; And then generated the interval_list for those, like this:; ```; ./gatk GenomicsDBImport --genomicsdb-update-workspace-path test --output-interval-list-to-file test.interval_list; ```; In this case, `test.interval_list` looks like this:; ```; @HD VN:1.6; @SQ SN:chr20 LN:64444167; @SQ SN:chr21 LN:46709983; chr20 1 64444167 + .; ```; Is that right? I was trying to figure out what tool output/workflow I could compare this to to make sure it was correct. I tried looking at [this link](https://software.broadinstitute.org/gatk/documentation/tooldocs/4.0.0.0/picard_util_IntervalListTools.php) to try and see if there was some way to use that. But doing that didn't really seem to be the same thing....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5970#issuecomment-518817072:610,update,update-workspace-path,610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5970#issuecomment-518817072,1,['update'],['update-workspace-path']
Deployability,"Right, the `try` block needs to catch the `java.lang.UnsatisfiedLinkError` exception. We'll fix that in the next GKL release. As a workaround, you can try defining this environment variable: `export GKL_USE_LIB_PATH=1`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2302#issuecomment-265859639:117,release,release,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2302#issuecomment-265859639,1,['release'],['release']
Deployability,"Right, we're waiting on an HTSJDK release before the next GKL release. After that, we'll add the new GKL to GATK.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2315#issuecomment-278686151:34,release,release,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2315#issuecomment-278686151,2,['release'],['release']
Deployability,"Right. I want to subset by sample name, effectively taking a slice of the; position by sample genotype matrix and computing Info annotations based; only in the kept samples. On Mon, Mar 4, 2019, 8:52 PM Karthik Gururaj <notifications@github.com>; wrote:. > I'm assuming you will have the subset of samples before creating a; > GenomicsDBFeatureReader object (and before creating the corresponding; > Protobuf export configuration object).; >; > More precisely, you are NOT requesting a line by line filter similar to:; > At pos 100, compute INFO fields etc including only the samples whose QUAL; > > 5; > At pos 102, compute INFO fields etc including only the samples whose QUAL; > > 5; > ....; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469502322>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMZjIbDJ2eDZcB69XHiUycnumzHrks5vTc3PgaJpZM4Z7pF2>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469680991:416,configurat,configuration,416,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469680991,1,['configurat'],['configuration']
Deployability,Right. Time for my own Picard facepalm. I'll wait for the normal HTSJDK update process :),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454960119:72,update,update,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454960119,1,['update'],['update']
Deployability,Rlci5qYXZh) | `83.673% <60%> (ø)` | `11 <1> (?)` | |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/4757/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `71.292% <73.333%> (+0.922%)` | `35 <14> (-15)` | :arrow_down: |; | [...er/utils/python/StreamingPythonScriptExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/4757/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9weXRob24vU3RyZWFtaW5nUHl0aG9uU2NyaXB0RXhlY3V0b3IuamF2YQ==) | `85.577% <83.333%> (+1.577%)` | `20 <11> (+5)` | :arrow_up: |; | [...nder/engine/datasources/ReferenceHadoopSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4757/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlSGFkb29wU291cmNlLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4757/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...hellbender/tools/spark/pipelines/SortSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4757/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFNhbVNwYXJrLmphdmE=) | `70.588% <0%> (-29.412%)` | `4% <0%> (-2%)` | |; | [...adinstitute/hellbender/utils/spark/SparkUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4757/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zcGFyay9TcGFya1V0aWxzLmphdmE=) | `72.727% <0%> (-11.797%)` | `12% <0%> (-9%)` | |; | ... and [137 more](https://codecov.io/gh/broadinstitute/gatk/pull/4757/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4757#issuecomment-388043128:3444,pipeline,pipelines,3444,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4757#issuecomment-388043128,1,['pipeline'],['pipelines']
Deployability,"Rlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...6737d16d1f0749554cafe9f8cf869fac1fcede0c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...6737d16d1f0749554cafe9f8cf869fac1fcede0c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `77.6% <0%> (-9.6%)` | `28% <0%> (-8%)` | |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...6737d16d1f0749554cafe9f8cf869fac1fcede0c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `70.946% <0%> (-6.757%)` | `18% <0%> (-4%)` | |; | ... and [4 more](https://codecov.io/gh/broadinstitute/gatk/pull/2433?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2433?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2433?src=pr&el=footer). Last update [92cb860...6737d16](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...6737d16d1f0749554cafe9f8cf869fac1fcede0c?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2433#issuecomment-283613034:5140,update,update,5140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2433#issuecomment-283613034,2,['update'],['update']
Deployability,"Rlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...f539662b2a136507a34ea2da64e0445d6df3469d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...f539662b2a136507a34ea2da64e0445d6df3469d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `77.6% <0%> (-9.6%)` | `28% <0%> (-8%)` | |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...f539662b2a136507a34ea2da64e0445d6df3469d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `70.946% <0%> (-6.757%)` | `18% <0%> (-4%)` | |; | ... and [4 more](https://codecov.io/gh/broadinstitute/gatk/pull/2455?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2455?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2455?src=pr&el=footer). Last update [dfa9cf1...f539662](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...f539662b2a136507a34ea2da64e0445d6df3469d?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2455#issuecomment-285859315:5105,update,update,5105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2455#issuecomment-285859315,2,['update'],['update']
Deployability,"RpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `89.474% <0%> (-0.526%)` | `8% <0%> (+5%)` | |; | [...stitute/hellbender/utils/collections/CountSet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2xsZWN0aW9ucy9Db3VudFNldC5qYXZh) | `31.21% <0%> (-0.403%)` | `22% <0%> (ø)` | |; | [.../hellbender/tools/walkers/annotator/ExcessHet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9FeGNlc3NIZXQuamF2YQ==) | `98.198% <0%> (-0.393%)` | `25% <0%> (+3%)` | |; | [...gine/spark/AddContextDataToReadSparkOptimized.java](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvQWRkQ29udGV4dERhdGFUb1JlYWRTcGFya09wdGltaXplZC5qYXZh) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...ellbender/tools/spark/sv/GATKSVVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9HQVRLU1ZWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | ... and [92 more](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=footer). Last update [e7c90f1...08af964](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2447#issuecomment-285197333:4374,update,update,4374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2447#issuecomment-285197333,2,['update'],['update']
Deployability,"RpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmtFbmdpbmUuamF2YQ==) | `82.857% <59.091%> (-6.234%)` | `6 <3> (+1)` | |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `66.667% <60%> (ø)` | `5 <1> (+1)` | :arrow_up: |; | [...e/hellbender/engine/filters/ReadFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeS5qYXZh) | `94.048% <66.667%> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...der/tools/walkers/annotator/RMSMappingQuality.java](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9STVNNYXBwaW5nUXVhbGl0eS5qYXZh) | `98.413% <0%> (-1.587%)` | `34% <0%> (+20%)` | |; | [...ls/walkers/genotyper/afcalc/ExactAFCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `89.474% <0%> (-0.526%)` | `9% <0%> (+6%)` | |; | ... and [18 more](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=footer). Last update [88c181d...6a33314](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2494#issuecomment-287889612:4362,update,update,4362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2494#issuecomment-287889612,2,['update'],['update']
Deployability,Run MD+BQSR+HC pipeline on full genome,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3106:15,pipeline,pipeline,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3106,1,['pipeline'],['pipeline']
Deployability,"Run validation tests continuously in jenkins: ReadsPipelineSpark, BQSR etc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1401:21,continuous,continuously,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1401,1,['continuous'],['continuously']
Deployability,Running `gatk --version` produces a dump of all the available tools and then a user exception.; ```. ... UpdateVcfSequenceDictionary (Picard) Takes a VCF and a second file that contains a sequence dictionary and updates the VCF with the new sequence dictionary.; VariantAnnotator (BETA Tool) Tool for adding annotations to VCF files; VcfFormatConverter (Picard) Converts VCF to BCF or BCF to VCF.; VcfToIntervalList (Picard) Converts a VCF or BCF file to a Picard Interval List. --------------------------------------------------------------------------------------. ***********************************************************************. A USER ERROR has occurred: '--version' is not a valid command. ***********************************************************************; ```; It should print the version instead.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5533:105,Update,UpdateVcfSequenceDictionary,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5533,2,"['Update', 'update']","['UpdateVcfSequenceDictionary', 'updates']"
Deployability,"Running the reads pipeline on latest master on GCP on an exome shows a major performance regression. At the end of last year this took 40 minutes for the whole job, now using master BQSR is taking 1.4 hours, and HC is taking well over an hour (it hasn't finished yet). #4278 is the likely culprit for the HC slowdown. Not sure about BQSR. cc @lbergelson @droazen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4376:18,pipeline,pipeline,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376,1,['pipeline'],['pipeline']
Deployability,Running with default arguments locally the runtime (for a WGS full chr15) drops from ~8.9 minutes to ~4.7 minutes after this patch. If I had to peg something else to optimize it would be replacing CSVWriter which seems to be somewhat slow but I can be contented that this tool is reasonably fast when nothing pathological is being triggered.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6740:125,patch,patch,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6740,1,['patch'],['patch']
Deployability,Running without an output file causes an NPR. Needs a null check. ```; ./gatk-launch CountReadsSpark -I src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam; ```. ```; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.gcs.BucketUtils.isCloudStorageUrl(BucketUtils.java:44); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.createFile(BucketUtils.java:105); at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:37); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:310); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66); at org.broadinstitute.hellbender.Main.main(Main.java:81); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1523:454,pipeline,pipelines,454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1523,1,['pipeline'],['pipelines']
Deployability,Runs with @danking 's changes to import_gvs.py included:; - creation of Avro files https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/5a16077c-1981-4cc7-85f6-8462c4a9a99a; - creation of VDS using those files: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/dd699836-c9e1-4a4b-a39f-201871686bb4; - quickstart integration test run: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/0691d981-cbf3-4150-8128-58f2ce81895c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8673#issuecomment-1930637107:387,integrat,integration,387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8673#issuecomment-1930637107,1,['integrat'],['integration']
Deployability,"S9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `89.474% <0%> (-0.526%)` | `8% <0%> (+5%)` | |; | [...stitute/hellbender/utils/collections/CountSet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2xsZWN0aW9ucy9Db3VudFNldC5qYXZh) | `31.21% <0%> (-0.403%)` | `22% <0%> (ø)` | |; | [.../hellbender/tools/walkers/annotator/ExcessHet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9FeGNlc3NIZXQuamF2YQ==) | `98.198% <0%> (-0.393%)` | `25% <0%> (+3%)` | |; | [...roadinstitute/hellbender/utils/GenotypeCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vdHlwZUNvdW50cy5qYXZh) | `100% <0%> (ø)` | `7% <0%> (+3%)` | :arrow_up: |; | [...ols/walkers/genotyper/MinimalGenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9NaW5pbWFsR2Vub3R5cGluZ0VuZ2luZS5qYXZh) | `27.273% <0%> (ø)` | `4% <0%> (+1%)` | :arrow_up: |; | ... and [58 more](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=footer). Last update [724fbd0...a163be6](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-288240771:4359,update,update,4359,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-288240771,2,['update'],['update']
Deployability,"S9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQmFzZVF1YWxpdHlDbGlwUmVhZFRyYW5zZm9ybWVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...llbender/tools/walkers/annotator/TandemRepeat.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...6b3c7a9b6d6dfb45fc64613bccf1a74e85a374fe?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9UYW5kZW1SZXBlYXQuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...oadinstitute/hellbender/tools/spark/sv/SvType.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...6b3c7a9b6d6dfb45fc64613bccf1a74e85a374fe?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdlR5cGUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...tute/hellbender/metrics/SAMRecordAndReference.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...6b3c7a9b6d6dfb45fc64613bccf1a74e85a374fe?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9tZXRyaWNzL1NBTVJlY29yZEFuZFJlZmVyZW5jZS5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | ... and [430 more](https://codecov.io/gh/broadinstitute/gatk/pull/2510?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2510?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2510?src=pr&el=footer). Last update [724fbd0...6b3c7a9](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...6b3c7a9b6d6dfb45fc64613bccf1a74e85a374fe?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2510#issuecomment-288256519:5159,update,update,5159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2510#issuecomment-288256519,2,['update'],['update']
Deployability,"S9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyLmphdmE=) | `17% <0%> (-52.5%)` | `9% <0%> (-30%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `58.53% <0%> (-23.18%)` | `33% <0%> (-9%)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `77.08% <0%> (-3.13%)` | `31% <0%> (ø)` | |; | [...adinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `89.39% <0%> (-3.04%)` | `61% <0%> (-2%)` | |; | ... and [25 more](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5291?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5291?src=pr&el=footer). Last update [626c887...a1e13fc](https://codecov.io/gh/broadinstitute/gatk/pull/5291?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437412464:4650,update,update,4650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437412464,2,['update'],['update']
Deployability,"SJDK Defaults.COMPRESSION_LEVEL : 1; 18:11:33.871 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:11:33.871 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 18:11:33.871 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:11:33.871 INFO PrintReadsSpark - Deflater: IntelDeflater; 18:11:33.871 INFO PrintReadsSpark - Inflater: IntelInflater; 18:11:33.871 INFO PrintReadsSpark - GCS max retries/reopens: 20; 18:11:33.871 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 18:11:33.871 INFO PrintReadsSpark - Initializing engine; 18:11:33.871 INFO PrintReadsSpark - Done initializing engine; 17/10/13 18:11:33 INFO spark.SparkContext: Running Spark version 2.2.0.cloudera1; 17/10/13 18:11:34 WARN spark.SparkConf: spark.master yarn-client is deprecated in Spark 2.0+, please instead use ""yarn"" with specified deploy mode.; 17/10/13 18:11:34 INFO spark.SparkContext: Submitted application: PrintReadsSpark; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing view acls groups to: ; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing modify acls groups to: ; 17/10/13 18:11:34 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); groups with view permissions: Set(); users with modify permissions: Set(hdfs); groups with modify permissions: Set(); 17/10/13 18:11:34 INFO util.Utils: Successfully started service 'sparkDriver' on port 45754.; 17/10/13 18:11:34 INFO spark.SparkEnv: Registering MapOutputTracker; 17/10/13 18:11:34 INFO spark.SparkEnv: Registering BlockManagerMaster; 17/10/13 18:11:34 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:3830,deploy,deploy,3830,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['deploy'],['deploy']
Deployability,"SNAPSHOT-spark.jar -- PrintReadsSpark -I gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam -O hs37d5cs.reads.txt --apiKey XXXXXXXXXXXXXXXXXXXXX --verbosity DEBUG --sparkMaster yarn; Copying file:///Users/markw/IdeaProjects/gatk/build/libs/gatk-package-4.alpha.2-157-g7d7c5ec-SNAPSHOT-spark.jar [Content-Type=application/java-archive]...; - [1 files][ 95.3 MiB/ 95.3 MiB] 9.0 MiB/s; Operation completed over 1 objects/95.3 MiB.; Job [5b3d4225-0547-4aa9-8a83-ab26460aa2d2] submitted.; Waiting for job output...; 21:42:45.768 INFO IntelGKLUtils - Trying to load Intel GKL library from:; 	jar:file:/tmp/5b3d4225-0547-4aa9-8a83-ab26460aa2d2/gatk-package-4.alpha.2-157-g7d7c5ec-SNAPSHOT-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 21:42:45.791 DEBUG IntelGKLUtils - Extracted Intel GKL to /tmp/root/libgkl_compression6493251482684327282.so. 21:42:45.792 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [February 6, 2017 9:42:45 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark --output hs37d5cs.reads.txt --input gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam --apiKey XXXXXXXXXXXXXXXX --sparkMaster yarn --verbosity DEBUG --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --QUIET false --use_jdk_deflater false --disableAllReadFilters false; [February 6, 2017 9:42:45 PM UTC] Executing as root@mw-test-m on Linux 3.16.0-4-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_111-8u111-b14-2~bpo8+1-b14; Version: Version:4.alpha.2-157-g7d7c5ec-SNAPSHOT; 21:42:45.795 INFO PrintReadsSpark - Defaults.BUFFER_SIZE : 131072; 21:42:45.795 INFO PrintReadsSpark - Defaults.COMPRESSION_LEVEL : 1; 21:42:45.795 INFO PrintReadsSpark - Defaults.CREATE_INDEX : false; 21:42:45.795 INFO PrintReadsSpark - Defaults.CREATE_MD5 : false; 21:42:45.795 INFO PrintReadsSpark - Defaults.CUSTO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929:2745,pipeline,pipelines,2745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929,1,['pipeline'],['pipelines']
Deployability,SSION_LEVEL : 2; 11:35:40.188 INFO Mutect2 - HTSJDK Defaults.CREATE_INDEX : false; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.CREATE_MD5 : false; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.CUSTOM_READER_FACTORY : ; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.REFERENCE_FASTA : null; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:35:40.190 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 11:35:40.190 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:35:40.190 INFO Mutect2 - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 11:35:40.190 DEBUG ConfigFactory - Configuration file values: ; 11:35:40.196 DEBUG ConfigFactory - 	gcsMaxRetries = 20; 11:35:40.196 DEBUG ConfigFactory - 	gcsProjectForRequesterPays = ; 11:35:40.196 DEBUG ConfigFactory - 	gatk_stacktrace_on_user_exception = false; 11:35:40.196 DEBUG ConfigFactory - 	samjdk.use_async_io_read_samtools = false; 11:35:40.196 DEBUG ConfigFactory - 	samjdk.use_async_io_write_samtools = true; 11:35:40.197 DEBUG ConfigFactory - 	samjdk.use_async_io_write_tribble = false; 11:35:40.197 DEBUG ConfigFactory - 	samjdk.compression_level = 2; 11:35:40.197 DEBUG ConfigFactory - 	spark.kryoserializer.buffer.max = 512m; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.maxResultSize = 0; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.userClassPathFirst = true; 11:35:40.197 DEBUG ConfigFactory - 	spark.io.compression.codec = lzf; 11:35:40.197 DEBUG ConfigFactory - 	spark.executor.memoryOverhead = 600; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.extraJavaOptions = ; 11:35:40.198 DEBUG ConfigFactory - 	spa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:3302,Configurat,Configuration,3302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Configurat'],['Configuration']
Deployability,SV Pipeline Jobs LongRunning : BAFFromGVCFs_ImportGVCFs and GenotypeVCFs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7646:3,Pipeline,Pipeline,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7646,1,['Pipeline'],['Pipeline']
Deployability,SV pipeline clean up,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2621:3,pipeline,pipeline,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2621,1,['pipeline'],['pipeline']
Deployability,"SV pipeline fails in experimental variation interpretation with "" Unexpected CIGAR format with deletion neighboring clipping""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4260:3,pipeline,pipeline,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260,1,['pipeline'],['pipeline']
Deployability,"SV pipeline fails on NA12878 b37 bam with ""observedValue must be non-negative"" in IntHistogram",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:3,pipeline,pipeline,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,1,['pipeline'],['pipeline']
Deployability,"SV pipeline failure on CHM WGS1 with ""two input alignments' overlap on read consumes completely one of them.""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:3,pipeline,pipeline,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['pipeline'],['pipeline']
Deployability,SV pipeline run on NA12878 hg19 has a very slow laggard assembly task,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3607:3,pipeline,pipeline,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3607,1,['pipeline'],['pipeline']
Deployability,SV pipeline tries to create illegal interval,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3874:3,pipeline,pipeline,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874,1,['pipeline'],['pipeline']
Deployability,SV read depth integration,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5161:14,integrat,integration,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5161,1,['integrat'],['integration']
Deployability,SV spark pipeline bash script,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2187:9,pipeline,pipeline,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2187,1,['pipeline'],['pipeline']
Deployability,"Same here, @jhl667 - good to get additional confirmation. May I ask whether you used the same gold-standard call set or another one, and whether yours was WGS or WES? . I’m linking @droazen here as well since he acted as the release manager of the affected releases. I think it would be good to get clarity soon, since probably tens of thousands of clinical samples have been processed with the affected versions in the last two years, and a reduction in precision of 10-20% (absolute) may have been relevant for clinical decisions in at least some of these cases. Also, I know how hard it is to avoid such things in what is essentially research software (and such a great one to boot), so this is not about blaming anyone but about fixing the root cause as soon as possible. If it turns out that the issue only affects this particular reference call set and no patients (for some arcane reason), then all the better in my view.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1171653305:225,release,release,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1171653305,2,['release'],"['release', 'releases']"
Deployability,Same integration test fails with IntegrationTestSpec but passes with manual runCommandLine()/assertSamsEqual() calls,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1164:5,integrat,integration,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164,2,"['Integrat', 'integrat']","['IntegrationTestSpec', 'integration']"
Deployability,Same problem. Any solution or update?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2428771429:30,update,update,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2428771429,1,['update'],['update']
Deployability,Saw it again [here](https://travis-ci.com/broadinstitute/gatk/jobs/180435353) (now restarted). If I'm reading the serialization stack in the right order:. ```; Serialization trace:; classes (sun.misc.Launcher$AppClassLoader); classLoader (org.apache.hadoop.conf.Configuration); conf (org.apache.hadoop.hdfs.DistributedFileSystem); fs (hdfs.jsr203.HadoopFileSystem); hdfs (hdfs.jsr203.HadoopPath); path (htsjdk.samtools.seekablestream.SeekablePathStream); seekableStream (htsjdk.tribble.TribbleIndexedFeatureReader); featureReader (org.broadinstitute.hellbender.engine.FeatureDataSource); featureSources (org.broadinstitute.hellbender.engine.FeatureManager); ```. it looks like we're trying to serialize a ClassLoader. The FieldSerializer does appear to use a ClassLoader to load classes during serialization.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-467462740:262,Configurat,Configuration,262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-467462740,1,['Configurat'],['Configuration']
Deployability,"Say hello to Azure SQL Database from `sqlcmd`, Python and Java (via Ammonite) running in a Cromwell on Azure deployment. Since the Azure Batch VMs spun up by Cromwell on Azure appear to have no identity associated with them the workflow currently takes a database access token as a parameter which it passes to the three tasks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8220:109,deploy,deployment,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8220,1,['deploy'],['deployment']
Deployability,"ScoreVariantAnnotations:. Scores variant calls in a VCF file based on site-level annotations using a previously trained model. TODOs:. - [x] Integration tests. Exact-match tests for (non-exhaustive) configurations given by the Cartesian product of the following options:; * Java Bayesian Gaussian Mixture Model (BGMM) backend vs. python sklearn IsolationForest backend; (BGMM tests to be added once PR for the backend goes in.); * non-allele-specific vs. allele-specific; * SNP-only vs. SNP+INDEL (for both of these options, we use trained models that contain both SNP and INDEL scorers as input) ; - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs.; - [x] Parameter/mode validation.; - [x] Double check or add behavior for handling previously filtered input, clearing present filters, etc. Future work:. - [ ] The `score_samples` method of the sklearn IsolationForest is single-threaded. See (possibly stalled) PR at https://github.com/scikit-learn/scikit-learn/pull/14001 and some workarounds using e.g. `multiprocessing` ibid.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948563:199,configurat,configurations,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948563,3,"['Integrat', 'configurat']","['Integration', 'configurations']"
Deployability,Scripts running the whole sv-pipeline as exists now from birth to termination,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2435:29,pipeline,pipeline,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2435,1,['pipeline'],['pipeline']
Deployability,"See #2488 for context. In short, the internal pathways for authentication changed, breaking some tests. We're pushing forward anyways but need to remember to re-enable the code & tests once we can (should be the next release).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2496:217,release,release,217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2496,1,['release'],['release']
Deployability,See [Issue 5277 - Migrate to org.genomicsdb fork](https://github.com/broadinstitute/gatk/issues/5277). . The first genomicsdb 1.0.0.beta jar consists of only a refactoring of all the packages to org.genomicsdb. Note that this pass should have no performance implications compared to the last [Intel release](https://mvnrepository.com/artifact/com.intel/genomicsdb/0.10.2-proto-3.0.0-beta-1+90dad1af8ce0e4d) as there is no change other than refactoring. Issues [5568-buffer resizing excessive logging](https://github.com/broadinstitute/gatk/issues/5568) and [5342-file synching error](https://github.com/broadinstitute/gatk/issues/5342) will both be addressed in the next release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5587:299,release,release,299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5587,2,['release'],['release']
Deployability,"See below:. 1) Are the failures in the same set of nodes?. This job was split into 200 intervals and would have run across a lot of different nodes. One specific interval set is causing issues. That interval/job has failed 3 times, on different nodes with a similar error. 2) Have all the ""nodes"" in the cluster been updated to running gatk v4.1.8.0. they all use the exact same JAR when they execute, which is 4.1.8.0. . 3) Is it possible to attach a file named __array_schema.tdb from one of the arrays causing the segfault?. I renamed it '.txt' to keep github happy, but here is that file. It is from contig QNVO02001146.1, which is the last contig it logged progress from before the error: ; [__array_schema.tdb.txt](https://github.com/broadinstitute/gatk/files/5441668/__array_schema.tdb.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-716835521:317,update,updated,317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-716835521,1,['update'],['updated']
Deployability,"See e.g. SavvyCNV. Should be relatively easy to rework PreprocessIntervals to make this possible, but we should see if the filtering/denoising/segmentation methods in both pipelines play along nicely.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6131:172,pipeline,pipelines,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6131,1,['pipeline'],['pipelines']
Deployability,"See https://bismap.hoffmanlab.org/. As of March 2020, some updates have been made to the single-read mappability track. These are probably minor, but we should update the version of the track in our resource files and do appropriate sanity checks. Note that a manual merging of overlapping intervals was performed for that version, but should no longer be necessary.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6591:59,update,updates,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6591,2,['update'],"['update', 'updates']"
Deployability,See https://github.com/GenomicsDB/GenomicsDB/releases/tag/v1.5.2 for release notes.; Of relevance to gatk are the following ; ```; Support for MacOS universal builds; Catch JNI importer exceptions and propagate them as java IOExceptions; Turn off HDFS support by default; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8710:45,release,releases,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8710,2,['release'],"['release', 'releases']"
Deployability,"See https://github.com/broadinstitute/dsde-pipelines/blob/develop/genomes_in_the_cloud/joint_genotyping_workflow/JointGenotypingWf.wdl for an example, and also the comments to https://github.com/broadinstitute/gatk/issues/3968",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3967#issuecomment-351739333:43,pipeline,pipelines,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3967#issuecomment-351739333,1,['pipeline'],['pipelines']
Deployability,"See https://github.com/broadinstitute/gatk/issues/4125 (which I suspect is due to the conda env not being established). @mbabadi @samuelklee @vdauwera Unfortunately we didn't add anything to the doc for these tools saying that they require the conda env. Some suggestions:. - Ideally, we could do something along the lines of what @droazen suggested in #4125, where the script executor validates that the environment is established. In a previous discussion though, @vdauwera expressed some concerns around requiring miniconda (as opposed to enumerating the individual requirements and allowing users to install these themselves - which is harder to communicate, and even harder to validate). We should discuss this further.; - Either way, the tools themselves could catch PythonScriptExecutorException and re-throw it with a helpful message saying the conda env is required.; - Update the tool summaries saying that the conda env is required.; - Update the tool javadoc/gatkdoc with more detail.; - Other ? Blog entry/forum post ?. This shouldn't be an issue for Docker users. We did discover a last minute issue that will affect OSX users though, which has a couple of workarounds described in this [PR](https://github.com/broadinstitute/gatk/pull/4087).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4127:604,install,install,604,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4127,3,"['Update', 'install']","['Update', 'install']"
Deployability,"See https://github.com/broadinstitute/gatk/issues/4888, which is an older report for the same issue. As mentioned there, I think we should patch our fork of `google-cloud-java` to do a channel reopen on `UnknownHostException` for now as a quick fix. @jean-philippe-martin is eventually going to add an official configuration mechanism for clients of `google-cloud-java` to customize which errors should trigger a retry/reopen, which should provide a better way to deal with these errors as they crop up without having to modify the NIO library itself.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412134420:139,patch,patch,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412134420,2,"['configurat', 'patch']","['configuration', 'patch']"
Deployability,See model update in #4371 that should obviate this. Should also handle this via -XL anyway.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3008#issuecomment-390741592:10,update,update,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3008#issuecomment-390741592,1,['update'],['update']
Deployability,"Seems like there weren't any exact-match tests to update after the latest release, so this should be ready pending your approval, @ldgauthier!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-969089252:50,update,update,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-969089252,2,"['release', 'update']","['release', 'update']"
Deployability,Seems someone updated it already in conda here https://anaconda.org/bioconda/gatk4. It's working fine now. Thanks,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595896563:14,update,updated,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595896563,1,['update'],['updated']
Deployability,"Seems still failing, what about multiple tries. ```r; dependencies = c(""naturalsort"",""ggplot2"",""gplots"",""reshape"",""gsalib""); repos <- c(""http://cran.cnr.Berkeley.edu"", ; ""https://cran.mtu.edu"", ; ""http://lib.stat.cmu.edu/R/CRAN/""); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- 1; while(length(missing)!=0 & try <= length(repos)) {; install.packages(dependencies[missing], repos = repos[try]); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- try + 1; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809:278,install,installed,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809,3,['install'],"['install', 'installed']"
Deployability,SelectVariants doesn't update GQ when using --removeUnusedAlternates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3404:23,update,update,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3404,1,['update'],['update']
Deployability,"SequenceDictionaryUtils/test.vcf` into the local directory.; - Renamed the copy of `PrintReadsSpark.java` as `PrintVCFSpark.java`; - Added `import org.broadinstitute.hellbender.utils.variant.Variant;`; - Added `import org.broadinstitute.hellbender.engine.spark.datasources.VariantsSparkSource;`; - As a test, I changed to the `runTool` method with the following to print the information in the first element in the RDD:. ``` Java; JavaRDD<Variant> rddParallelVariants =; variantsSparkSource.getParallelVariants(output);. System.out.println( rddParallelVariants.first().toString() );; ```. And after re-compiling GATK and running `PrintVCFSpark`, I got the following to print the first element of the RDD:. ``` Bash; $ ./gatk-launch PrintVCFSpark --input test.vcf --output test.vcf. Running:; /home/pgrosu/me/hellbender_broad_institute/gatk/build/install/gatk/bin/gatk PrintVCFSpark --input test.vcf --output test.vcf; [February 14, 2016 7:04:16 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVCFSpark --output test.vcf --input test.vcf --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false; [February 14, 2016 7:04:16 PM EST] Executing as pgrosu on Linux 2.6.32-358.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_05-b13; Version: Version:4.alpha-86-g154d0a8-SNAPSHOT JdkDeflater; 19:04:16.098 INFO PrintVCFSpark - Initializing engine; 19:04:16.100 INFO PrintVCFSpark - Done initializing engine; 2016-02-14 19:04:17 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 2016-02-14 19:04:19 WARN MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.; MinimalVariant -- interval(1:737406-737411), snp(false), indel(true); 19:04:24.266 INFO Prin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1486#issuecomment-184011857:1483,pipeline,pipelines,1483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1486#issuecomment-184011857,1,['pipeline'],['pipelines']
Deployability,Serialize auth onto pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/868:20,pipeline,pipeline,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/868,1,['pipeline'],['pipeline']
Deployability,"ServletContextHandler@50f4b83d{/jobs/job/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@5d66ae3a{/jobs/job,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@30159886{/jobs/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@33de7f3d{/jobs,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO ui.SparkUI: Stopped Spark web UI at http://10.48.225.55:4041; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/03/07 20:32:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/03/07 20:32:55 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/03/07 20:32:55 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/03/07 20:32:55 INFO memory.MemoryStore: MemoryStore cleared; 18/03/07 20:32:55 INFO storage.BlockManager: BlockManager stopped; 18/03/07 20:32:55 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/03/07 20:32:55 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/07 20:32:55 INFO spark.SparkContext: Successfully stopped SparkContext; 20:32:55.769 INFO FlagStatSpark - Shutting down engine; [March 7, 2018 8:32:55 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.FlagStatSpark done. Elapsed time: 1.60 minutes.; Runtime.totalMemory()=2091384832; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Shutdown hook called; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Deleting directory /tmp/farrell/spark-9e0f0525-00f3-4b37-b1d2-4cf55b4c8cb0. real 1m41.113s; user 0m49.698s; sys 0m4.432s. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:13744,pipeline,pipelines,13744,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,2,['pipeline'],['pipelines']
Deployability,Set up continuous tests for the conda environment on MacOS in Travis,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6813:7,continuous,continuous,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6813,1,['continuous'],['continuous']
Deployability,"Several backwards-incompatible changes in VCF 4.3 (eg., escape sequences) have made it difficult to update without first doing a major refactoring in HTSJDK to better version/isolate our parsers. @cmnbroad can provide further details.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2602#issuecomment-471719969:100,update,update,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2602#issuecomment-471719969,1,['update'],['update']
Deployability,"Several changes:. - Fix https://github.com/broadinstitute/gatk/issues/4741, where newer versions of conda appear to treat relative references in the environment yml as being relative to the yml file instead of relative to the cwd (based on observation).; - Add a second conda yml file (`gatkcondaenv.intel.yml`) for environments that use Intel hardware acceleration and Intel Tensorflow package (based on https://github.com/broadinstitute/gatk/pull/4735).; - Add a gradle task (`condaEnvironmentDefinition`) to generate the conda yml files from a single template to ensure that all the environment definitions remain in sync. This task also generates the Python package archive.; - Add a gradle task (`localDevCondaEnv`) to create or update a local (non-Intel) conda environment. This is a shortcut for use during development when you're iteratively changing/testing Python code and want to update the conda env.; - Opportunistically removed the prefix verb ""create"" from the name of the `createPythonPackageArchive` task, which is now called `pythonPackageArchive`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4749:734,update,update,734,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4749,2,['update'],['update']
Deployability,Several improvements to SV contig alignment configuration picker,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4326:44,configurat,configuration,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326,1,['configurat'],['configuration']
Deployability,"Several temporary placeholder program groups were added in https://github.com/broadinstitute/gatk/pull/3924 so they could be used until we get the real ones from Picard. However, since then, the approved list of program groups have changed (i.e., BAMPreprocessing no longer exists). Once the [final groups](https://github.com/broadinstitute/picard/pull/1043) are merged into Picard, we'll need to upgrade to a that Picard, remove the placeholders and replace any references to the placeholders to references to the real thing.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4034:397,upgrade,upgrade,397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4034,1,['upgrade'],['upgrade']
Deployability,Sf cnn wdl updates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5251:11,update,updates,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5251,1,['update'],['updates']
Deployability,Sh sv cluster image ver upgrade and custom name,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4137:24,upgrade,upgrade,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4137,1,['upgrade'],['upgrade']
Deployability,Share more code between walker and Spark integration tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5723:41,integrat,integration,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5723,1,['integrat'],['integration']
Deployability,Shl Update somatic short variants tool docs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4310:4,Update,Update,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4310,1,['Update'],['Update']
Deployability,Should also include an update to gatk-protected to make the tools there use the new API in a more consistent way.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2175#issuecomment-251445431:23,update,update,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2175#issuecomment-251445431,1,['update'],['update']
Deployability,"Should not be much longer @ajshultz -- https://github.com/broadinstitute/gatk/pull/4645 just needs a final review pass, so it's likely to make the next GATK release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3269#issuecomment-398900147:157,release,release,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3269#issuecomment-398900147,1,['release'],['release']
Deployability,"Should the CreateHadoopBamSplittingIndex tool also work on a cram? I am getting this error below which suggests not. What are the benefits of a SplittingIndex for a spark job? On average-how long should it take a spark job to get the splits for a 30x bam or cram? . ```; gatk CreateHadoopBamSplittingIndex -I adni/cram/ADNI_002_S_0413.hg38.realign.bqsr.cram; Using GATK jar /share/pkg/gatk/4.0.1.1/install/bin/gatk-package-4.0.1.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar /share/pkg/gatk/4.0.1.1/install/bin/gatk-package-4.0.1.1-local.jar CreateHadoopBamSplittingIndex -I adni/cram/ADNI_002_S_0413.hg38.realign.bqsr.cram; 11:47:53.243 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.1.1/install/bin/gatk-package-4.0.1.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 11:47:53.455 INFO CreateHadoopBamSplittingIndex - ------------------------------------------------------------; 11:47:53.455 INFO CreateHadoopBamSplittingIndex - The Genome Analysis Toolkit (GATK) v4.0.1.1; 11:47:53.455 INFO CreateHadoopBamSplittingIndex - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:47:53.455 INFO CreateHadoopBamSplittingIndex - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-696.10.3.el6.x86_64 amd64; 11:47:53.456 INFO CreateHadoopBamSplittingIndex - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_151-b12; 11:47:53.456 INFO CreateHadoopBamSplittingIndex - Start Date/Time: March 7, 2018 11:47:52 AM EST; 11:47:53.456 INFO CreateHadoopBamSplittingIndex - ------------------------------------------------------------; 11:47:53.456 INFO CreateHadoopBamSplittingIndex - ------------------------------------------------------------; 11:47:53.457 INFO CreateHadoopBamSplittingIndex - HTSJDK Version: 2.14.1; 11:47:53.457 INFO CreateHadoopBamSplittingIndex - Picard Ve",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506:398,install,install,398,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506,3,['install'],['install']
Deployability,"Should we add this to the gradle build? Unit test require R and various R libraries to be installed, but this isn't mentioned in the documentation or performed by the build script. . I suggest we ; 1. tag all tests that require R in some way so that they can be disabled a system that doesn't have R; 2. add documentation to the readme explaining you need R and a number of r libraries; 3. either document that you must run install_R_packages.R or have gradle do it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/222:90,install,installed,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/222,1,['install'],['installed']
Deployability,Simple copy/paste bug. Closing the header line creator fixes the hanging issues as seen in [this run](https://job-manager.dsde-prod.broadinstitute.org/jobs/21c1ec08-444e-4acd-8490-cc9640d9ea03) (requires PMI ops). Integration run [in progress](https://job-manager.dsde-prod.broadinstitute.org/jobs/3b5129bb-b7fe-47db-abc4-dda5d7f5006a) (regular auth).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8533:214,Integrat,Integration,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8533,1,['Integrat'],['Integration']
Deployability,Simple patch to allow passing specific tool classes to `Main.instanceMain` instead of whole packages to solve #2140. This will allow clients that want their own command line with their tools to include only `IndexFeatureFile` for their own codecs and/or bundle tools like `CreateSequenceDictionary` to pre-process input files.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2204:7,patch,patch,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2204,1,['patch'],['patch']
Deployability,Simple patch to improve the `Main` usage in the same direction as previous PRs to finer control by API user:. * Added `handleNonUserException(final Exception exception)` to handle custom exceptions.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2261:7,patch,patch,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2261,1,['patch'],['patch']
Deployability,"Simple toggle wins the day, by a vote of 2-1 :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058790:7,toggle,toggle,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058790,1,['toggle'],['toggle']
Deployability,Simple update to use the correct version of Spark in the scripts.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5125:7,update,update,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5125,1,['update'],['update']
Deployability,Simplifying argument in mitochondria pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6904:37,pipeline,pipeline,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6904,1,['pipeline'],['pipeline']
Deployability,"Since M2 only has one full-time developer, I think the history of mutect2 pdfs on github and the GATK release notes will have to suffice.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6001#issuecomment-583451842:102,release,release,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6001#issuecomment-583451842,1,['release'],['release']
Deployability,"Since the Picard changes in #3620, SamAssertionUtils has been failing silently. See e.g. the Standard error tab for https://storage.googleapis.com/hellbender-test-logs/build_reports/13120.7/tests/test/classes/org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSparkIntegrationTest.html:. ```; USAGE: SortSam [arguments]; ...; input is not a recognized option; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3664:251,pipeline,pipelines,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3664,1,['pipeline'],['pipelines']
Deployability,"Since we're using Mutect2 for mitochondrial calling, we want some reference confidence representation for joint calling. I did my best, but further refactoring suggestions appreciated. Tests to follow. @davidbenjamin can you take a look at the LODs in the integration test results? I'm not entirely surprised that at the same depth, the variant LOD is higher than the reference LOD. I'm not sure that the NON_REF LOD at variant sites is coming out right though. Is there an effective negative LOD asymptote?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5312:256,integrat,integration,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5312,1,['integrat'],['integration']
Deployability,"Since we're using Mutect2 for our mitochondrial variant calling pipeline that's in development, and we want to joint call mitochondria, I'm working on ""somatic joint calling"". It won't have a joint likelihood model (yet?) the way that germline SNP and indel joint calling does, but it will be able to give you a ""squared-off"" matrix of calls for each sample at each site that's variant in any sample.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4887#issuecomment-431005889:64,pipeline,pipeline,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4887#issuecomment-431005889,1,['pipeline'],['pipeline']
Deployability,"Since you asked, I have a couple of thoughts:. First, I don't know if allowing the SAMRecord header to be set to null ; something that was intended to be widely used, or whether it was an ; oversight in the API or done to solve some particular corner case. If ; many SAMRecord methods appear to be broken if the header is null, then ; perhaps this isn't something that was intended for wide use. Second, it sounds like the suggestion is that headerless SAMRecords ; would now be widely used, and thus a common thing that people writing ; code against htsjdk need to anticipate.; So if you go this way you should update the SAMRecord documentation to ; clearly indicate that SAMRecords can be in either a headerless or ; non-headerless (headerful?) state; and indicate how each API function is affected by this. If certain ; methods behave differently, then people writing code against SAMRecord ; need to anticipate this; and existing code may need to be updated. In other words, headerless ; SAMRecords should become ""part of the spec"". Third, although I don't know in detail about the different execution ; environments you are trying to support, there is a general strategy that ; I haven't seen discussed in these threads.; Perhaps it's impractical, but I'll mention it anyway. It seems like ; another approach would be to create (internal to the implementation) a ; ""header tag"" that could be efficiently serialized; and passed as part of the SAMRecord when you need to distribute it. The ; header tag could be used by the receiver to reattach the SAMRecord to ; its header (either proactively or on demand), but transparently to ; application code that is running against the SAMRecord API.; This would allow SAM headers to be transmitted out-of-band in a way that ; depends on the execution environment. Depending on the environment, ; this might be done by proactive broadcast, or you could think of the ; header tag as a promise to retrieve the header if/when it is needed. ; The size and com",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518:612,update,update,612,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518,2,['update'],"['update', 'updated']"
Deployability,"Sink.writeReadsSingle(ReadsSparkSink.java:228); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:153); at org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark.runTool(BwaAndMarkDuplicatesPipelineSpark.java:62); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:230); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. I have to look more into BwaAndMarkDuplicatesPipelineSpark. The good news is at least we get BwaSpark working now: `BwaSpark` with `--bamPartitionSize`=4000000 or 64000000, the program finishes in less than 20 minutes without error. (It used to stalled if no `--bamPartitionSize` is specified).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:5166,deploy,deploy,5166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,6,['deploy'],['deploy']
Deployability,Skeleton of the reads preprocessing pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/655:36,pipeline,pipeline,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/655,1,['pipeline'],['pipeline']
Deployability,Sl dr update docker base image,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8614:6,update,update,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8614,1,['update'],['update']
Deployability,Small updates to GVS Integration WDL [VS-618],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8042:6,update,updates,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8042,2,"['Integrat', 'update']","['Integration', 'updates']"
Deployability,"Small updates to GvsExtractCallset from beta callset, new workflow for re-scattered shards",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7493:6,update,updates,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7493,1,['update'],['updates']
Deployability,Small updates to JointVcfFiltering WDL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8027:6,update,updates,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8027,1,['update'],['updates']
Deployability,"So I just updated one of the newer tests, and now all of the tests for HaplotypeCaller seem to be passing locally. The previous commits updating the copy code were preserved when Louis reverted, so there were basically no changes I had to make to get this ""working."" That does leave us with one question now:. When looking into this a little with James and Louis earlier, we realized that the code for setting up the ActiveRegionGenotyper uses a weird partial copy of the standard CLI args method that has existed in the code for whoever knows how long. Conceptually this seems like a bad idea, but changing it now would possibly cause some older tests to fail, if they were based on this faulty method reasoning. Should we try to merge the PR as it is now, with all tests passing, and hopefully consistency with previous behavior, or try to update the logic around this genotyper as well at the same time? It's possible we can try to address the latter point as well at some point in the future when we try to get Louis's refactor code actually working. Maybe there could be some quarter goal around a HaplotypeCaller code revamp sometime inspired by some of these ideas?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1847916216:10,update,updated,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1847916216,2,['update'],"['update', 'updated']"
Deployability,"So a couple of questions:; * Should an external developer always install the R dependencies before running `./gradlew clean test`?; * If the R dependencies are needed for testing and the rest of the code, may be worthy to install them if not present in the gradle script or should be specified that the dependencies are missing... Is there an easy way to do that?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3740#issuecomment-338997058:65,install,install,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3740#issuecomment-338997058,2,['install'],['install']
Deployability,"So if I needed a new combine operation for an allele-specific annotation, how would I specify that the annotation is allele-specific? Do we need a updateINFOFieldLengthDescriptor like updateINFOFieldCombineOperation?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4993#issuecomment-415407026:147,update,updateINFOFieldLengthDescriptor,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4993#issuecomment-415407026,2,['update'],"['updateINFOFieldCombineOperation', 'updateINFOFieldLengthDescriptor']"
Deployability,"So we definitely don't update the QUAL if we drop alternate alleles:https://github.com/broadinstitute/gatk/blob/9fce0b22faf2e8db7a8662884266a1893b6b10c5/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java#L259; Note that the QUAL is based off of the AFResult that had alleles removed if they exceeded the output limit, but not if they had less evidence than the calling confidence threshold. @davidbenjamin I really hate to run the AF calculator again if we drop low quality alleles. Or maybe the new qual isn't as bad as I think? Would it be a decent approximation to add up the per-allele quals for the remaining alleles?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5793#issuecomment-483785934:23,update,update,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5793#issuecomment-483785934,1,['update'],['update']
Deployability,So we typically override the config files on the command line. We'll have to make sure we wire the log4j 1.x logger to respect our command line overrides if it doesn't already. You can check that by testing if you can control the log output with the --verbosity command. If not we'll have to update `LoggingUtils.setLoggingLevel()`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320787794:292,update,update,292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320787794,1,['update'],['update']
Deployability,"Somatic WDLs have them hidden, gCNV WDLs (in sl_gcnv_ploidy_cli) have them exposed. (EDIT: Actually, gCNV WDLs only have them exposed for gCNV-specific tasks. Common tasks such as PreprocessIntervals are also not exposed.). The former makes for cleaner `wdltool inputs` JSONs that contain only the bare minimum inputs, but it is unclear whether FC will allow for task-level parameters to be set. However, this can still be done via JSON, as long as the task is at the main workflow level (although this may change with a C30 hotfix?). The latter makes for messier JSONs and requires more upkeep to make sure everything stays exposed, but should work in FC (unless the workflow is used as a subworkflow?)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3980:525,hotfix,hotfix,525,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3980,1,['hotfix'],['hotfix']
Deployability,"Some (but not all) users get a warning whenever they run a dataflow pipeline that calls `DataflowWorkarounds.registerGenomicsCoders`. Here is an example:. ```; Jul 01, 2015 2:33:36 PM com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds registerGenomicsCoders; INFO: Registering coders for genomics classes; Jul 01, 2015 2:33:36 PM org.reflections.Reflections scan; WARNING: could not create Vfs.Dir from url. ignoring the exception and continuing; org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/Library/KeyAccess/KeyAccess.app/Contents/SharedFrameworks/KeyAccess.framework/KeyAccess]; either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.; at org.reflections.vfs.Vfs.fromURL(Vfs.java:109); at org.reflections.vfs.Vfs.fromURL(Vfs.java:91); at org.reflections.Reflections.scan(Reflections.java:237); at org.reflections.Reflections.scan(Reflections.java:204); at org.reflections.Reflections.<init>(Reflections.java:129); at com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/609:68,pipeline,pipeline,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609,1,['pipeline'],['pipeline']
Deployability,"Some are camel case already, some are python-style underscored arguments, and none are in the new standard format of #2596. Note that this requires carefully changing our wdls!!! @LeeTL1220 and @vdauwera this is easy enough to do, but any considerations on timing relative to releases or other logistical thoughts?. I notice that this inconsistency is shared with HaplotypeCaller. . .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3325:276,release,releases,276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3325,1,['release'],['releases']
Deployability,"Some comments/questions for the review:; - I'll add a separate ticket to rewrite the integration tests, all of which pass and most of which are disabled since they require access to large files on the broad file system. In the meantime I need to add a couple of small tests to get the coverage back up, and would like to get the CR process started.; - I ported a bunch of support files but need feedback on whether they're in the right location.; - Somewhere I saw something that said GATK no longer supports .ped files ? If not, what should the replacement be in the tests require pedigree input?; - Is it a requirement to support Ploidy > 2 ? The current GATK tool, and thus the HB tool, do not; - I did not port the WalkerTestSpec.disableShadowVCF? Is that needed in Hellbender ?; - Are there other headers I should be applying to the output variant file ?. Command Line Arguments:; - I didn't port the GATK command line argument ""-no_cmd_line_in_header"". Should I ? And if not, should the command line args automatically be propagated to the output vcf file ? I didn't see GATK do this anywhere.; - There was one test that used --variant:dbsnp on the command line but I couldn't find the code that processed that in GATK, not sure what the means on the command line.; - I replaced ""-U LENIENT_VCF_PROCESSING"" with ""--lenient"" (testFileWithoutInfoLineInHeaderWithOverride needs this to pass).; - I replaced ""-L"" with --interval since HB seems to use -L for ""lane"" ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/792#issuecomment-128798027:85,integrat,integration,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/792#issuecomment-128798027,1,['integrat'],['integration']
Deployability,Some concerns about the Mutect2 WDL pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3061:36,pipeline,pipeline,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061,1,['pipeline'],['pipeline']
Deployability,Some info on Spark configurations:. https://stackoverflow.com/questions/29441316/specifying-an-external-configuration-file-for-apache-spark,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322552565:19,configurat,configurations,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322552565,2,['configurat'],"['configuration-file-for-apache-spark', 'configurations']"
Deployability,Some issues with the ga4gh htsget reference server have come up while the current htsget integration branch has been in development. A a server update is causing the previously passing tests to begin to fail. We need to re-enable them once the server is back on stable footing.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6640:89,integrat,integration,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6640,2,"['integrat', 'update']","['integration', 'update']"
Deployability,"Some notes on individual commits:. Updated CallCopyRatioSegments and PreprocessIntervals; reorganized copynumber packages.; -For motivation of changes in CallCopyRatioSegments, see #3825.; -I added the ability to turn off binning in PreprocessIntervals by specifying bin_length = 0.; -I removed the separation between coverage and allelic packages to make the package structure a bit simpler.; -@MartonKN should review, since he wrote PreprocessIntervals and is updating the caller. Added segmentation classes and tests for ModelSegments CNV pipeline.; -I added implementations of copy-ratio, allele-fraction, and ""multidimensional"" (joint) segmentation. All implementations are pretty boilerplate; they simply partition by contig and then call out to KernelSegmenter. Note that there is some logic in multidimensional segmentation that only uses the first het in each copy-ratio interval and if any are available, and imputes the alt-allele fraction to 0.5 if not.; -Makes sense for @mbabadi to review this, since he reviewed the KernelSegmenter PR. Added modeling classes and tests for ModelSegments CNV pipeline.; -Most of this code is copied from the old MCMC code. However, I've done some overall code cleanup and refactoring, especially to remove some overextraction of methods in the allele-fraction likelihoods (see #2860). I also added downsampling and scaling of likelihoods to cut down on runtime. Tests have been simplified and rewritten to use simulated data.; -@LeeTL1220 do you think you could take a look?. Added ModelSegments CLI.; -Mostly control flow to handle optional inputs and validation, but there is some ugly and not well documented code that essentially does the GetHetCoverage step. We'll refactor later, I filed #3915.; -@asmirnov239 can review. This is lower priority than the gCNV VCF writing. Deleted gCNV WDL and Cromwell tests.; -Trivial to review. Added WDL and Cromwell tests for ModelSegments CNV pipeline.; -This includes the cost optimizations from @meganshand a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3913:35,Update,Updated,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3913,2,"['Update', 'pipeline']","['Updated', 'pipeline']"
Deployability,"Some of our argument names have grossly inconsistent short vs. long names, like `-writeFullFormat,--never_trim_vcf_format_field`. For the 4.0 release we should do a pass to ensure that all short and long names are consistent with each other.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2597:142,release,release,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2597,1,['release'],['release']
Deployability,"Some of the CNV tools are miscategorized: GetHetCoverage + tools in the ""Intervals Manipulation"" category. The latter should probably be considered CNV-specific because they either use the target-file format (which is only used in the legacy CNV + ACNV pipeline) or perform a task that is specific to the CNV pipeline and probably not of general interest (PreprocessIntervals).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-347530234:253,pipeline,pipeline,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-347530234,2,['pipeline'],['pipeline']
Deployability,"Some of the Docker work from `ah_var_store` needs to be on `EchoCallset` to be able to do the PGEN subsets, particularly the PLINK Docker and GAR changes upon which the PLINK Docker changes depend. I have freshly baked the Variants, PLINK, and Docker images just now for this PR. 👨‍🍳 . Integration run in progress here https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/2585a1b6-c5da-48f0-a196-b5679e7f40a5",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8805:286,Integrat,Integration,286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8805,1,['Integrat'],['Integration']
Deployability,"Some of the categories we are removing are still in the HelpConstants, e.g. DOC_CAT_SPARK*.; --> learned on purpose otherwise code breaks. Will be removed at later time. Here's that spreadsheet again. It's the fourth tab `categories_summaries`: https://docs.google.com/a/broadinstitute.org/spreadsheets/d/19SvP6DHyXewm8Cd47WsM3NUku_czP2rkh4L_6fd-Nac/edit?usp=sharing. I see two place holders for Picard, ReadProgramGroup and VariantProgramGroup. Are these for those categories only in Picard? Because then there is only one such category and it is the `Base Calling` category.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3924#issuecomment-349699185:269,a/b,a/broadinstitute,269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3924#issuecomment-349699185,1,['a/b'],['a/broadinstitute']
Deployability,"Some of the files in the CNV workflows are not yet supported by NIO, so it won’t be as easy as changing File to String everywhere. I think the ref and the BAMs are the most important ones to change, as Lee pointed out. Let’s not worry too much about getting this in the next release or anything like that—-as soon as is convenient is fine. But let’s decide on things like whether we need a copy in this repo and perhaps have a general strategy going forward.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-391765626:275,release,release,275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-391765626,1,['release'],['release']
Deployability,"Some preliminary evaluation of the new ModelSegments pipeline on CRSP samples has revealed some weaknesses of the ReCapSeg caller (which is simply ported from the old pipeline) to me. I think there are a lot of confusing things going on:. 1) For determining copy-neutral segments, all segments with log2 mean below some threshold are used (rather than absolute log2). There is a comment that this is done to ""mimic the python code"" but I have no idea why this would be sensible, since it includes all deletions.; 2) There is some confusion arising from inconsistent use of z-score and T-statistic. Standard deviation, rather than standard error, is used for calling; i.e., a ""called segment"" is one that has a mean log2 copy ratio that has a z-score above some threshold with respect to the standard deviation of the log2 copy ratios of intervals that fall within copy-neutral segments (note also that these intervals have already been filtered by z-score to remove outliers). That is, any segment with a mean that falls sufficiently within the fuzziness of the caterpillar is not called.; 3) However, even calling using standard error is probably not what we want. This would simply be asking the question: given a population of copy-neutral intervals with a mean and standard deviation, does any non-copy-neutral segment contain intervals with a mean significantly different than the population? We've already answered this question during segmentation!. I think what we want to do instead is ask questions about the population of segment-level copy-ratio estimates, weighted by length.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3825:53,pipeline,pipeline,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3825,2,['pipeline'],['pipeline']
Deployability,"Some print messages like this:; ```; Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.smithwaterman.SmithWatermanIntelAlignerUnitTest > testSubstringMatchLong[0](359, 7M, SOFTCLIP) STANDARD_ERROR; 03:09:09.419 WARN NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils7398935100372553580.so: Shared object ""libm.so.6"" not found, required by ""libgkl_utils7398935100372553580.so""); Test: Test method testSubstringMatchLong[0](359, 7M, SOFTCLIP)(org.broadinstitute.hellbender.utils.smithwaterman.SmithWatermanIntelAlignerUnitTest) produced standard out/err: 03:09:09.419 WARN IntelSmithWaterman - Intel GKL Utils not loaded; ```. libgkl_utils.so is installed in /usr/local/lib/libgkl_utils.so, which is under the standard prefix location /usr/local where all packages are installed. OS: FreeBSD 14.1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8939:708,install,installed,708,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8939,2,['install'],['installed']
Deployability,"Some read tags get lost when we convert SAM to fastq. This tool allows us to get those tags back once we are done processing the fastqs (some tools e.g. adapter clippers cannot take SAMs as input so the conversion is unavoidable.) So this tool works like Picard MergeBamAlignment, except that we are putting the tags from the unaligned bam to the aligned bam, rather than adding alignment info to the unaligned bam. We will use this in our new TCap RNA pipeline.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7739:453,pipeline,pipeline,453,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7739,1,['pipeline'],['pipeline']
Deployability,Some refactoring of where the main WDLs live. Passing Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/009b92ea-9b51-4ebe-8ddd-924c53f28a55).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8970:54,Integrat,Integration,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8970,1,['Integrat'],['Integration']
Deployability,"Some tools work with a large list of intervals. In some case these are quite repetitive and they could specify in a single line but due to the need to enumerate each interval explicitly in the interval lists it might result in a uncessary large file, potentially GB in size. ## Repetitive intervals. For example the SV detection pipeline collects read counts at 100bp intervals. In a 3.2Gbp genome that is roughly 30M entries. Easily a text interval_list in its simplest form would need around 30ch for each interval that bump it up to 900MB . However one could express the same list just like:. `* *:100`. where the first asterisk stands for ""any contig"", the second stands for ""whole contig"" and the 100 means into 100bp adjacent intervals. from 7ch to 900M??? A few more example as to how such a language could look like:. ```; chr1 # the entire chr1; chr1 * # same; chr1,chr2 # both chr1 and chr2, in full.; * # all contigs in full.; * * # same.; chr1 100-200 # sigle interval from 100-200 on chr1.; chr1 { 100-200 } # same; chr1 { # same; 100-200; }; * 100-200 # 100-200 at every contig.; chr1,chr2 100-200 # only on chr1 and chr2; chr1 *200 # from 1-200 i.e. start to 200.; chr1 4000* # from 4000 to the end of chr1.; chr1 4000 # only position 4000; chr1 4M # only position 4 million. M=10^6, k/K=10^3 ; chr1 10000-99 # from 10000 to 10099... ; # perhaps is best not to accept this as it might silence user input errors.; # but what about instead?; chr1 100[00-99]; chr1 10000+100 # 100 bps starting at 10000 so 10000-10099; chr1 4k # only poistion 4000.; chr20 1M+32K # from position 1 million extending to the following 32Kbps.; chr20 1M1+32K # from position 1 million and 1 instead. (avoiding all those 0s). chr1 *:200 # consecutive 200bp intervals for the entire chromosome; chr1 *:200(100) # 200bp intervals with 100 gaps; chr1 *:200/20 # 200bp intervals with an overlap of 20bp.; chr1 *:20/200 # 200bp starting every 20 positions (so 180bp overlap); chr1 *:200~20 # 200bp intervals truncat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5702:329,pipeline,pipeline,329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5702,1,['pipeline'],['pipeline']
Deployability,"Some updates per the description:. - Backed out ExcessHet changes from this PR; - ~Removed BigQuery classes temporarily, to return inside a `gvs` package in a later PR.~ Brought these back under a `gvs` package",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8362#issuecomment-1602561256:5,update,updates,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8362#issuecomment-1602561256,1,['update'],['updates']
Deployability,"Somehow Kris managed to generate a VCF with an index that doesn't have a properly sorted sequence dictionary: gs://broad-dsde-methods/kcibul/bug_for_louis I think it was with GATK4 SelectVariants (with a version prior to the commandline being put in the header), but I'm not 100% sure. Generating the index on the fly with GATK3 works fine. I'm not sure if the original tabix index from the GotC pipeline is okay: gs://broad-jg-dev-storage/temp/09C99383.91c5a812-70c5-4526-a3a2-3e99b9cf08fb.g.vcf.gz.tbi. I found this because GATK3 complained about the contig order.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3119:396,pipeline,pipeline,396,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3119,1,['pipeline'],['pipeline']
Deployability,"Someone from my team is going to give this issue a try, we'll post any updates here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7356#issuecomment-888511365:71,update,updates,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7356#issuecomment-888511365,1,['update'],['updates']
Deployability,"Sometimes NON_REF gets a zero and sometimes it's empty. This seems isolated to a much older version of ReblockGVCF, but that was what we were running for production pipeline tests. @droazen I'd like this to go into this week's release",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6442:165,pipeline,pipeline,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6442,2,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/866:412,Integrat,IntegrationTestSpec,412,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866,7,"['Integrat', 'pipeline']","['IntegrationTestSpec', 'pipelines']"
Deployability,"Sorry @ldgauthier, I forgot to test that, I'll do it now. Props for using the word svelte. @droazen-- we have gatk4 installed and updated via bioconda, so I'm not super sure exactly which versions had this problem, just that the current version. If it would help I could roll back `gatk4` to `4.0.12.0` and see if the issue was there as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462474405:116,install,installed,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462474405,2,"['install', 'update']","['installed', 'updated']"
Deployability,"Sorry @magicDGS -- since this is failing tests and needs a rebase/review, and we're extremely pressed for time this morning, this is going to have to wait until the next point release. But don't worry, I think I can safely say that we plan to do point releases frequently -- I'd expect the first one within a couple of weeks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-356314345:176,release,release,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-356314345,2,['release'],"['release', 'releases']"
Deployability,Sorry I missed the test case. I updated the header of the test case so the pull request passes the integration tests. Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324430072:32,update,updated,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324430072,2,"['integrat', 'update']","['integration', 'updated']"
Deployability,Sorry for the bug @cvalenci. That looks like something we've seen before and recently fixed (#4980). Can you try 4.0.6.0: https://github.com/broadinstitute/gatk/releases/tag/4.0.6.0 ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5009#issuecomment-404619628:161,release,releases,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5009#issuecomment-404619628,1,['release'],['releases']
Deployability,"Sorry for the delay @bbimber -- the release is currently being held up by an issue with the Google Cloud requester pays support that is affecting large numbers of GATK users (https://github.com/broadinstitute/gatk/issues/7716). There is an open PR to fix this (https://github.com/broadinstitute/gatk/pull/7730), but tests are not yet passing. . While you wait for the release to come out, you could use the latest nightly docker image (https://hub.docker.com/r/broadinstitute/gatk-nightly/) or build GATK from source to confirm that your NPE is indeed fixed as we believe it to be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7687#issuecomment-1076598767:36,release,release,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7687#issuecomment-1076598767,2,['release'],['release']
Deployability,"Sorry if this is not the right place to ask, but is there any update on GenomicsDBImport being able to run on multiple intervals? I couldn't find an issue for this in the tracker. We have a lot of users for whom it's a deal-breaker.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4496#issuecomment-371366878:62,update,update,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4496#issuecomment-371366878,1,['update'],['update']
Deployability,Sorry to be a pain but is there any update on this?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8097#issuecomment-1380365985:36,update,update,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8097#issuecomment-1380365985,1,['update'],['update']
Deployability,"Sorry to be a pain... I'm still getting this problem with 4.0.2.1, which according to the tag [description](https://github.com/broadinstitute/gatk/releases/tag/4.0.2.1) should have this issue fixed. ```; Using GATK jar /home/db291g/applications/gatk/gatk-4.0.2.1/gatk-package-4.0.2.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar /home/db291g/applications/gatk/gatk-4.0.2.1/gatk-package-4.0.2.1-local.jar FilterMutectCalls --variant gatk4/WW00274.vep.vcf.gz --output test.vcf.gz; 10:00:20.977 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/db291g/applications/gatk/gatk-4.0.2.1/gatk-package-4.0.2.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 10:00:21.082 INFO FilterMutectCalls - ------------------------------------------------------------; 10:00:21.083 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.0.2.1; 10:00:21.083 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:00:21.083 INFO FilterMutectCalls - Executing as db291g@login01 on Linux v2.6.32-431.23.3.el6.x86_64 amd64; 10:00:21.083 INFO FilterMutectCalls - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 10:00:21.083 INFO FilterMutectCalls - Start Date/Time: March 7, 2018 10:00:20 AM GMT; 10:00:21.083 INFO FilterMutectCalls - ------------------------------------------------------------; 10:00:21.083 INFO FilterMutectCalls - ------------------------------------------------------------; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Version: 2.14.3; 10:00:21.084 INFO FilterMutectCalls - Picard Version: 2.17.2; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOL",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787:147,release,releases,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787,1,['release'],['releases']
Deployability,"Sorry, I guess I didn't see your edit pointing out that line of code. I've indeed looked at that test and more---there's a lot of similar duct tape and inconsistent resetting of the RNG throughout the entire test suite. But since I think we can reasonably assume that there's enough duct tape to make things deterministic overall, I don't think it's worth cleaning up the duct tape just to get neater, but equally deterministic behavior. (Or perhaps can you point to instances of persisting non-determinism, e.g. random failures in Travis?). In any case, I think it makes more sense to focus effort on making cleaner tests for the new tools, rather than make an 11th hour effort to revamp these existing tests. Do you agree?. See e.g. https://github.com/broadinstitute/gatk/issues/6112 for some related discussion. Also added a note mentioning that the original GATK3 expected results have been updated, although now looking back at the commit history, I'm not sure if that was already true.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1063002941:895,update,updated,895,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1063002941,1,['update'],['updated']
Deployability,"Sorry, I know this is old, but i'm currently dealing with this exact issue using `gatk-4.beta.5`. It sounds like this has been solved, but the solution isn't clear to me. . EDIT: Perhaps an upgrade to 4.1 will solve this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2944#issuecomment-474483603:190,upgrade,upgrade,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2944#issuecomment-474483603,2,['upgrade'],['upgrade']
Deployability,"Sorry, it's difficult for me to spot git notifications in my email. . > Maybe @bshifaw can chime in? Are the featured workspaces covered by tests elsewhere? What is the current SOP for taking workflows from this repo, turning them into featured workspaces, and populating their configurations?. Example JSONs with input test data are usually introduced in the gatk-workflows git repos and carried over to the featured workspaces. That isn't to say they are not welcomed from the gatk repo. > @bshifaw related to what Sam was saying - we also have a few standard resources needed to run the workflows that we would like to share with users. What is the standard procedure for doing so? Ideally they would be bundled with featured workspaces, but also accessible from outside of Terra. Workflow resources files that are not already in [broad-references](https://console.cloud.google.com/storage/browser/broad-references) would be saved in the [gatk-best-practices](https://console.cloud.google.com/storage/browser/gatk-best-practices) bucket. In the past i've separated the resources files per workflow directory (e.g. pathseq, cnn-hg38) but you can organize them a different way if the resources files would be shared by other workflows (e.g. somatic-hg38, somatic-b37).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-507703719:278,configurat,configurations,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-507703719,1,['configurat'],['configurations']
Deployability,"Sorry, just saw this now. We still don't have a simple solution for training models without pysam. We can probably do something similar to what we do with inference, but I think the current priority is to improve inference throughput so it will probably be a little while before we get to re-writing the training code. If people feel we should re-prioritize please let me know.; I have installed the conda environment on the same OSX version, without seeing this issue.; Which gcc version are you using @mwalker174 ? ; My `gcc -v` output is:; ```; Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1; Apple LLVM version 8.0.0 (clang-800.0.42.1); Target: x86_64-apple-darwin15.6.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-391014193:386,install,installed,386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-391014193,3,"['Install', 'install']","['InstalledDir', 'installed']"
Deployability,"Sorry, only thought of this after giving my 👍🏻 ; do we want to update the documentation somewhere (e.g. https://github.com/broadinstitute/gatk/blob/ah_vs_565_output_intervals_and_sample_list/scripts/variantstore/beta_docs/run-your-own-samples.md) to let users know where to find these outputs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8010#issuecomment-1238335512:63,update,update,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8010#issuecomment-1238335512,1,['update'],['update']
Deployability,"Sounds good - was thinking of doing that at the last moment (i.e. having the PR approved, build a 'ah_varstore_<date>' docker off of this PR and then update the wdls and then merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7965#issuecomment-1201531818:150,update,update,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7965#issuecomment-1201531818,1,['update'],['update']
Deployability,"Sounds good! After I get this current version of the pipeline released,; I'll explore this further. Maybe we could follow-up on slack, or meet up; at Broad at some point if you're on-site. many thanks!. Brian. On Thu, Feb 29, 2024 at 9:32 AM Gökalp Çelik ***@***.***>; wrote:. > For that purpose I would still suggest using Sample Name IDs and Read; > Group IDs along with Mutect2 to call variants therefore contribution of; > each cell to a mutation will be quantified in terms of Allele Fractions.; > Especially if you also disable downsampling it will be quite the data to; > analyze.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971271149>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABZRKX37ASEZBUTV2HCSR4TYV45W5AVCNFSM6AAAAABD4OZKJ6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSNZRGI3TCMJUHE>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >. -- ; --; Brian J. Haas; The Broad Institute; http://broadinstitute.org/~bhaas <http://broad.mit.edu/~bhaas>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971281473:53,pipeline,pipeline,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971281473,2,"['pipeline', 'release']","['pipeline', 'released']"
Deployability,"Sounds great, thanks for your work on this and for the update, @davidbenjamin !",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5436#issuecomment-481740688:55,update,update,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5436#issuecomment-481740688,1,['update'],['update']
Deployability,Spark SV pipeline example shell scripts currently not working,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6068:9,pipeline,pipeline,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6068,1,['pipeline'],['pipeline']
Deployability,Spark SV pipeline might need property `dfs.client.use.datanode.hostname=true`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6064:9,pipeline,pipeline,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6064,1,['pipeline'],['pipeline']
Deployability,Spark Walker base classes need ReadsContext/readFilter integration,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2338:55,integrat,integration,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2338,1,['integrat'],['integration']
Deployability,Spark and deploy-mode,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933:10,deploy,deploy-mode,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933,1,['deploy'],['deploy-mode']
Deployability,"Spark cluster nodes not released, even though spark calculations are complete",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2833:24,release,released,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2833,1,['release'],['released']
Deployability,"Spark local mode. In private Spark tools under development (which travers a WGS BAM and then performing several shuffles) I have seen speedups of up to 40% (~ 46 minutes -> 26 minutes). An initial test of `MarkDuplicatesSpark` using a 30GB bam file gave me a 9% speedup (logs are below). It might be good to investigate making this easier for users (I downloaded Hadoop and built it from source, and then set gatk's java opts to load the native library). Two options might be: 1) distribute native libraries for supported architectures with gatk or 2) make sure gatk docker images include the native libraries and are set to use them. Logs for `MarkDuplicatesSpark` without and with native libraries, running on a Broad login server:. Without:. ```; $ ${GATK_DIR}/gatk MarkDuplicatesSpark -I CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -O CEUTrio.HiSeq.WEx37; .NA12892.readnamesort.dupmarked.bam -- --spark-runner LOCAL --spark-master local[8]; Using GATK wrapper script ${GATK_DIR}/gatk/build/install/gatk/bin/gatk; Running:; ${GATK_DIR}/gatk/build/install/gatk/bin/gatk MarkDuplicatesSpark -I CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -O CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.dupmarked.bam --spark; -master local[8]; 14:40:21.800 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 14:40:21.889 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:${GATK_DIR}/gatk/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.so; 14:40:21.989 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 14:40:21.990 INFO MarkDuplicatesSpark - The Genome Analysis Toolkit (GATK) v4.0.4.0-7-g46a8661-SNAPSHOT; 14:40:21.990 INFO MarkDuplicatesSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:40:21.991 INFO MarkDuplicatesSpark - Executing as cwhelan@",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4746:1109,install,install,1109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4746,2,['install'],['install']
Deployability,"SparkCommandLineArgumentCollection does not support ""="" in the values of spark configuration variables",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3687:79,configurat,configuration,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3687,1,['configurat'],['configuration']
Deployability,SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:182); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:201); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.seek(BlockCompressedInputStream.java:380); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIter,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:19452,deploy,deploy,19452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['deploy'],['deploy']
Deployability,"SparkCommandLineProgram.java:31); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.FileSystemNotFoundException: Provider ""gs"" not installed; 	at java.nio.file.Paths.get(Paths.java:147); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferencePath(ReferenceFileSparkSource.java:53); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferenceBases(ReferenceFileSparkSource.java:60); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceMultiSparkSource.getReferenceBases(ReferenceMultiSparkSource.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.getRefBaseString(BreakEndVariantType.java:89); 	at org.br",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:7662,deploy,deploy,7662,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['deploy'],['deploy']
Deployability,SparkTool.initializeToolInputs(GATKSparkTool.java:370); > 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:360); > 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); > 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); > 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); > 	at org.broadinstitute.hellbender.Main.main(Main.java:239); > 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); > 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); > 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); > 	at java.lang.reflect.Method.invoke(Method.java:498); > 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:733); > 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177); > 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202); > 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116); > 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); > Caused by: java.io.FileNotFoundException: /spark-ics/user/axverdier/data/710-PE-G1.bam; > 	at com.mapr.fs.MapRClientImpl.open(MapRClientImpl.java:243); > 	at com.mapr.fs.MapRFileSystem.open(MapRFileSystem.java:958); > 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:807); > 	at org.seqdoop.hadoop_bam.util.SAMHeaderReader.readSAMHeaderFrom(SAMHeaderReader.java:51); > 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:205),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-350232988:2727,deploy,deploy,2727,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-350232988,6,['deploy'],['deploy']
Deployability,Spawn of VS-1214 which required the ability to run with a wheel. Hopefully we never need to use this but now we would have the ability if we ever need it. Full integration run [in progress](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/6d67fda8-1237-4cd8-bf49-fe582ae7fc13). Runs requiring PMI ops access exercising this new wheel functionality with a Delta-age 0.2.98 wheel:; - [Delta](https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20Echo%20RD/job_history/7215bdc8-f951-4b84-b9bf-3aaa80eae0a1); - [Delcho](https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20Echo%20RD/job_history/a336972e-d9f4-4a74-92fe-6ed94d2b5fff),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8692:160,integrat,integration,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8692,1,['integrat'],['integration']
Deployability,"Speaking of adding such a toggle, here you go: https://github.com/broadinstitute/gatk/pull/5324",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-431059166:26,toggle,toggle,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-431059166,1,['toggle'],['toggle']
Deployability,Split integration tests into two roughly equal targets,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2818:6,integrat,integration,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2818,1,['integrat'],['integration']
Deployability,"Split more travis integration tests into the ""variant calling"" job",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4990:18,integrat,integration,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4990,1,['integrat'],['integration']
Deployability,Split travis integration tests into two jobs to reduce test runtime,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4983:13,integrat,integration,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4983,1,['integrat'],['integration']
Deployability,"SplitNCigarReads is failing due to incompatibilities between htsjdk's version of snappy and Spark's version. Temporary solution is to add system property 'disable.snappy' to force htsjdk to fallback to pure java. Longer term solution likely involves patches to htsjdk and possibly snappy itself. ```; ./gatk-launch SplitNCigarReads -I src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam -O out.bam -R src/test/resources/large/human_g1k_v37.20.21.fasta. Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk SplitNCigarReads -I src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam -O out.bam -R src/test/resources/large/human_g1k_v37.20.21.fasta; 15:31:00.516 INFO IntelGKLUtils - Trying to load Intel GKL library from:; jar:file:/Users/louisb/Workspace/gatk/build/install/gatk/lib/gkl-0.1.2.jar!/com/intel/gkl/native/libIntelGKL.dylib; 15:31:00.552 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [July 20, 2016 3:31:00 PM EDT] org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads --output out.bam --input src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam --reference src/test/resources/large/human_g1k_v37.20.21.fasta --refactor_NDN_cigar_string false --maxReadsInMemory 150000 --maxMismatchesInOverhang 1 --maxBasesInOverhang 40 --doNotFixOverhangs false --disable_all_read_filters false --interval_set_rule UNION --interval_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --addOutputSAMProgramRecord true --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false; [July 20, 2016 3:31:00 PM EDT] Executing as louisb@wm1b0-8ab on Mac OS X 10.10.5 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_91-b14; Version: Version:4.alpha.1-217-g3ff51ed-SNAPSHOT; 15:31:00.557 INFO SplitNCigarReads - Defaults.BUFFER_SIZE : 131072; 15:31:00.557 INFO SplitNCigarReads - ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2026:250,patch,patches,250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2026,3,"['install', 'patch']","['install', 'patches']"
Deployability,SplitNCigarReadsIntegrationTest and SplitNCigarReadsUnitTest are bizzarely similar. something weird is going on. the 'integration test' is not really an intergration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1209:118,integrat,integration,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1209,1,['integrat'],['integration']
Deployability,Still got to test my Rc vs 923 add validation branch on the integration test now that it's fixed!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8592:60,integrat,integration,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8592,1,['integrat'],['integration']
Deployability,"Still not sure why the tests failed randomly! all XHMM-related tests use their own RNG with fixed seeds and there are no RNG calls in any parallel streams. Therefore, the randomly generated test data must be identical and fully deterministic across all runs. However, it did not appear to be the case! some test runs triggered a bug in HMMPostProcessor (see below) and some runs didn't. I removed a few unnecessary RNGs and the issue is not reproducible anymore. In particular, both XHMMModel and XHMMEmissionProbabilityCalculator had their own RNG but then again, if the tests are run in a deterministic order, it shouldn't matter. The good news is the bug in HMMPostProcessor is fixed; the bad news is, I still don't know why the tests were not deterministic. I bet the failing issue is (magically!) fixed as a result of pulling out the RNG from XHMMModel and XHMMEmissionProbabilityCalculator. If it occurs again, I'll investigate more. - fixed a bug in HMMPostProcessor that required all samples to be queried in the given list of genotyping segments every time (origin of the failing tests: sometimes the randomly generated genotyping segments contained fewer samples than all samples available for genotyping); - got rid of the unnecessary RNG in XHMMModel to make it stateless (sampling requires an external RNG); - also made XHMMEmissionProbabilityCalculator stateless (sampling requires an external RNG); - truncated the target list used in XHMM integration tests (cuts down the test time by a factor of 10)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3140:1455,integrat,integration,1455,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3140,1,['integrat'],['integration']
Deployability,"Still valid as of date 2017/07/06, though should be done quickly by @tedsharpe 's upgrade in the new binding.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2123#issuecomment-313503534:82,upgrade,upgrade,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2123#issuecomment-313503534,1,['upgrade'],['upgrade']
Deployability,"Strange. That looks fine. Sorry to keep asking question, but a) what operating system are you using? b) how did you install java? Every java 8 jdk should come with javadoc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-653704795:116,install,install,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-653704795,1,['install'],['install']
Deployability,Stretch goal for the 4.0 release this summer.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2480#issuecomment-287792721:25,release,release,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2480#issuecomment-287792721,1,['release'],['release']
Deployability,Stumbled back on this when looking at #6924. @ldgauthier @mwalker174 was the above comment addressed? Might be good to verify the gCNV tutorial is still consistent or update it at some point.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6167#issuecomment-718769708:167,update,update,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6167#issuecomment-718769708,1,['update'],['update']
Deployability,Successful Integration Test Run [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/9ab365ff-743b-4d97-9c2a-6a09cf8728f4) - But note that the Exome Integration test failed for slight (and expected) difference in table sizes. I have updated the truth in gs://gvs-internal-quickstart/integration/2023-07-25-quicker/exome_weighted/table_sizes_expected.csv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8531#issuecomment-1739742037:11,Integrat,Integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8531#issuecomment-1739742037,4,"['Integrat', 'integrat', 'update']","['Integration', 'integration', 'updated']"
Deployability,Successful Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/d43ca844-632b-4737-962e-56369ac91e53),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8696:11,Integrat,Integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8696,1,['Integrat'],['Integration']
Deployability,Successful Joint Calling workflow (Exome) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Exome%20Beta%20Test%20ggrant/job_history/0ff13881-727f-4fdf-bde7-904559eac58f).; Successful Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/5a35adca-9f75-467c-8441-53f922ab8a7d).; A more recent integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/e0a281c5-c412-4d27-a08d-cbd169f74a1c) (two failures on slight cost differences),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8515#issuecomment-1710547302:189,Integrat,Integration,189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8515#issuecomment-1710547302,2,"['Integrat', 'integrat']","['Integration', 'integration']"
Deployability,Successful Quickstart Integration here: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/a7705dcb-0a9e-4667-ba88-6553ecd9cbd3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8173#issuecomment-1403754046:22,Integrat,Integration,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8173#issuecomment-1403754046,1,['Integrat'],['Integration']
Deployability,"Successful integration run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/ef747737-4d19-4770-83b7-47715eff8237). tl;dr the only commit really worth looking at is 9ac0befbcc39b9c5a7eb0938dd79a7d5cbd5f297, everything else is a simple merge from master. This is just minor tweaks around recent changes in the JointVariantCalling WDL. I'll need to merge and push this locally to preserve history from master as that option is not available within the GATK GitHub repo.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8537:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8537,1,['integrat'],['integration']
Deployability,"Successful integration run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f7f0131f-96b8-424e-b022-9cb08fd4b39e). Only the ~9 newest commits are actually new, the rest comes from GATK master.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8505:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8505,1,['integrat'],['integration']
Deployability,"Successful integration run added to the PR, and the docker images were also updated",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1729641138:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1729641138,2,"['integrat', 'update']","['integration', 'updated']"
Deployability,Successful integration run https://app.terra.bio/#workspaces/gvs-dev/mlc%20GVS%20Quickstart%20v3/job_history/c711a4cf-ac33-4c93-a4b7-b46b2796f090,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8044:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8044,1,['integrat'],['integration']
Deployability,"Successful integration run; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20cremer/job_history/4caeb3e1-6c8f-4547-a334-b3264f2aed95. We initially changed the name of the method (since import_gvs is a bit misleading inside our repo) but because it looks like there are still external changes being made, we decided to keep the name consistent with Tim/Hail's chosen one.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8330:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8330,1,['integrat'],['integration']
Deployability,Successful integration test [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/2065c1e2-c7f3-47b8-8f20-306ba24ad09f),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8345#issuecomment-1568210916:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8345#issuecomment-1568210916,1,['integrat'],['integration']
Deployability,Successful post-update run here: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20hatcher/job_history/b8c599c9-cebf-4e5c-9ea1-1dc19ee15b49,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8023#issuecomment-1251314053:16,update,update,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8023#issuecomment-1251314053,1,['update'],['update']
Deployability,"Summary information about this bug:. This issue affects GATK versions 4.3.0.0 through 4.5.0.0, and is fixed in GATK 4.6.0.0. The PR with the fix is: https://github.com/broadinstitute/gatk/pull/8900. This issue also affects Picard versions 2.27.3 through 3.1.1, and is fixed in Picard 3.2.0. This bug is triggered when writing a CRAM file using one of the affected GATK/Picard versions, and both of the following conditions are met:; ; * At least one read is mapped to the very first base of a reference contig; * The file contains more than one CRAM container (10,000 reads) with reads mapped to that same reference contig. When both of these conditions are met, the resulting CRAM file may have corrupt containers associated with that contig containing reads with an incorrect sequence. . Since many common references such as hg38 have N's at the very beginning of the autosomes and X/Y, many pipelines will not be affected by this bug. However, users of a telomere-to-telomere reference, users doing mitochondrial calling, and users with reads aligned to the alt sequences will want to scan their CRAM files for possible corruption. The other mitigating circumstance is that when a CRAM is affected, the signal will be overwhelmingly obvious, with the mismatch rate typically jumping from sub-1% to 80-90% for the affected regions, making it likely to be caught by standard QC processes. A CRAM scanning tool called `CRAMIssue8768Detector` that can detect whether a particular CRAM file is affected by this bug was added in https://github.com/broadinstitute/gatk/pull/8819, and was released as part of GATK 4.6.0.0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8768#issuecomment-2198315437:894,pipeline,pipelines,894,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8768#issuecomment-2198315437,2,"['pipeline', 'release']","['pipelines', 'released']"
Deployability,"Summary of changes:. - Fixed a minor issue in sampling error estimation that could lead to NaN (as a result of division by zero). - Introduced separate _internal_ and _external_ admixing rates. The _internal_ admixing rate is to be used internally by discrete RV posterior update routines (""callers"") as a safety measure to stabilize self-consistency loops. For example, consider the mean-field treatment of two coupled Markov chains: the mean-field decoupling of the two chains yields two independent Markov chains with effective emission, transition, and prior probabilities, all of which must be self-consistency determined. The internal admixing rate would be used to admix the old and new self-consistent fields across the two chains in order to dampen oscillations and improve convergence properties. Once internal convergence is achieved, the converged posteriors must be saved to a workspace in order to be consumed by the continuous sub-model. The new internally converged posteriors will be admixed with the old internally converged posteriors from the previous epoch with the _external_ admixing rate. - Introduced two-stage inference for cohort denoising and calling. In the first (""warm-up"") stage, discrete variables are marginalized out, yielding an effective continuous-only model. The warm-up stage calculates continuous posteriors based on the marginalized model. Once convergence is achieved, continuous and discrete variables are decoupled for the second (""main"") stage. The second stage starts with a discrete calling step (crucial), using continuous posteriors from the warm-up stage as the starting point. The motivation behind the two-stage inference strategy is to avoid getting trapped in spurious local minima that are potentially introduced by mean-field decoupling of discrete and continuous RVs. Note that mean-field decoupling has a tendency to stabilize local minima, most of which will disappear or turn into saddle points once correlations are taken into account. Whi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4720:273,update,update,273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4720,2,"['continuous', 'update']","['continuous', 'update']"
Deployability,Support fasta input in dataflow read pre-processing pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/460:52,pipeline,pipeline,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/460,1,['pipeline'],['pipeline']
Deployability,"Support for incrementally adding samples to existing genomicsdb workspaces. I've added these comments to the docs, but just wanted to call out again that we recommend making a backup of the existing workspace before trying to update the workspace. Otherwise, if the incremental update fails the workspace may be in a corrupted/inconsistent state. . If the user chooses not to backup (or can't), there is a (somewhat painful, manual) way to restore the workspace on failure IFF the --consolidate option has not been used. The tool will output a backup callset file (suffixed .inc.backup) and a file suffixed .fragmentlist with a list of all the original fragments. In order to roll back to a consistent workspace, the user must; - replace the callset file in the workspace with the one suffixed .inc.backup. That is, something like:; > mv _workspace_/callset.json.inc.backup _workspace_/callset.json; - delete all the directories in the workspace not named genomicsdb_meta_dir or included the file suffixed .fragmentlist",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5970:226,update,update,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5970,2,['update'],['update']
Deployability,Support grouping by key of input data for multi-input tools in the dataflow read pre-processing pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/462:96,pipeline,pipeline,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/462,1,['pipeline'],['pipeline']
Deployability,Support interval input in dataflow read pre-processing pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/461:55,pipeline,pipeline,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/461,1,['pipeline'],['pipeline']
Deployability,"Sure @ldgauthier, I can update the javadoc and [Article#11074](https://software.broadinstitute.org/gatk/documentation/article?id=11074). It might take me some time to figure out the LaTeX part. I remember @vdauwera mentioning this was something we will fix on the forum management side. Any help towards what needs to be fixed would be appreciated @vdauwera or I can contact Vanilla for help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-453604969:24,update,update,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-453604969,1,['update'],['update']
Deployability,Switch from ExcessHet back to HWE for array pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6848:44,pipeline,pipeline,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6848,1,['pipeline'],['pipeline']
Deployability,Switch to the updated type & location inference tool in SV pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4111:14,update,updated,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111,2,"['pipeline', 'update']","['pipeline', 'updated']"
Deployability,Switch travis gcloud installation to use noninteractive mode,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6974:21,install,installation,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6974,1,['install'],['installation']
Deployability,Switched to version in https://github.com/droazen/google-cloud-java/tree/dr_better_nio_retries to test JP's modifications to my original patch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3295#issuecomment-316210736:137,patch,patch,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3295#issuecomment-316210736,1,['patch'],['patch']
Deployability,Synchronize update of shared genotype likelihood tables.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5071:12,update,update,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5071,1,['update'],['update']
Deployability,"THX all!; The problem is that I did not install ""git lfs"" @magicDGS",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4669#issuecomment-382592770:40,install,install,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4669#issuecomment-382592770,1,['install'],['install']
Deployability,TKSparkTool.runPipeline(GATKSparkTool.java:351); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:218); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: No enum constant com.google.cloud.storage.StorageClass.DURABLE_REDUCED_AVAILABILITY; 	at java.lang.Enum.valueOf(Enum.java:238); 	at com.google.cloud.storage.StorageClass.valueOf(StorageClass.java:22); 	at com.google.cloud.storage.BlobInfo.fromPb(BlobInfo.java:940); 	at com.google.cloud.storage.Blob.fromPb(Blob.java:779); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:189); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:197); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:57,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2517:1941,deploy,deploy,1941,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2517,1,['deploy'],['deploy']
Deployability,TKSparkTool.runPipeline(GATKSparkTool.java:353); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:111); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:169); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:120); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:141); 	at org.broadinstitute.hellbender.Main.main(Main.java:196); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:728); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Invalid splitting BAM index: should contain at least 1 offset and the file size; 	at org.seqdoop.hadoop_bam.SplittingBAMIndex.readIndex(SplittingBAMIndex.java:69); 	at org.seqdoop.hadoop_bam.SplittingBAMIndex.<init>(SplittingBAMIndex.java:49); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeSplittingBaiFiles(SAMFileMerger.java:117); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); 	at org.broadinstitute.hellbender.engine.spark.datasources.Read,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2503:1219,deploy,deploy,1219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2503,1,['deploy'],['deploy']
Deployability,"TKSparkTool.runPipeline(GATKSparkTool.java:353); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:111); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:169); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:218); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: GCS FileSystem URIs mustn't have: port, userinfo, path, query, or fragment: gs://broad-gatk-test-jenkins/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam; 	at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:192); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:83); 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:336); 	at org.seqd",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337:3922,deploy,deploy,3922,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337,1,['deploy'],['deploy']
Deployability,TKSparkTool.runPipeline(GATKSparkTool.java:353); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.NegativeArraySizeException; 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.resize(IdentityObjectIntMap.java:447); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.putStash(IdentityObjectIntMap.java:245); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:239); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:135); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.putStash(IdentityObjectIntMap.java:246); 	at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:239); 	at com.esoteri,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3303:4387,deploy,deploy,4387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3303,1,['deploy'],['deploy']
Deployability,TKSparkTool.runPipeline(GATKSparkTool.java:353); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:171); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:190); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:220); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.NoSuchFileException: jonn-test-bucket/foo.bam.parts; 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:575); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219); 	at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276); 	at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322); 	at java.nio.file.FileTreeIterator.<init>(FileTreeIterator.java:72); 	at java.nio.file.Files.walk(Files.java:3574); 	at java.nio.file.Files.walk(Files.java:3625); 	a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2793:2044,deploy,deploy,2044,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2793,1,['deploy'],['deploy']
Deployability,TKSparkTool.runPipeline(GATKSparkTool.java:360); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAda,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591:3215,deploy,deploy,3215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591,1,['deploy'],['deploy']
Deployability,TKSparkTool.runPipeline(GATKSparkTool.java:360); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:152); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:175); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:161); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAda,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994:8781,deploy,deploy,8781,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994,1,['deploy'],['deploy']
Deployability,TKSparkTool.runPipeline(GATKSparkTool.java:362); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.NoSuchFileException: /gatk4/output_3.bam.parts/_SUCCESS: Unable to find _SUCCESS file; 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:53); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:231); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:153); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:259); 	... 18 more; 17/10/13 18:11:54 INFO util.ShutdownHookManager: Shutdown hook called; 17/10/13 18:11:54 INFO util.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:24946,deploy,deploy,24946,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['deploy'],['deploy']
Deployability,TKSparkTool.runPipeline(GATKSparkTool.java:387); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadinstitute.hellbender.Main.main(Main.java:275); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.ContigAlignmentsModifier.removeOverlap(ContigAlignmentsModifier.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.AssemblyContigAlignmentSignatureClassifier.lambda$processContigsWithTwoAlignments$e28aa838$1(Assembly,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:12456,deploy,deploy,12456,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['deploy'],['deploy']
Deployability,TKSparkTool.runPipeline(GATKSparkTool.java:387); at; org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30; ); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.jav; a:179); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at; org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at; org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928); at; org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at; org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: scala.Product$class; at java.lang.ClassLoader.findClass(ClassLoader.java:523); at; org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.java:35); at java.lang.ClassLoader.loadClass(ClassLoader.java:418); at; org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40); at; org.apache.spark.util.ChildFirstURLClassLoader.load,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6644:4851,deploy,deploy,4851,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644,1,['deploy'],['deploy']
Deployability,TKSparkTool.runPipeline(GATKSparkTool.java:458); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:635); Caused by: java.io.FileNotFoundException: File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.ha,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:5162,deploy,deploy,5162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['deploy'],['deploy']
Deployability,TKSparkTool.runPipeline(GATKSparkTool.java:461); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:182); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:201); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtool,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:19333,deploy,deploy,19333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['deploy'],['deploy']
Deployability,TKSparkTool.runPipeline(GATKSparkTool.java:533); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.RuntimeException: Could not serialize lambda; 	at com.twitter.chill.java.ClosureSerializer.write(ClosureSerializer.java:70); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); 	... 44 more; Caused by: java.lang.NoSuchMethodException: htsjdk.samtools.reference.AbstractFastaSequenceFile$$Lambda$94/1029586776.writeReplace(); 	at java.lang.Class.getDeclaredMethod(Class.java:2130); 	at com.twitter.chill.java.ClosureSerializer.write(Clo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6091:3992,deploy,deploy,3992,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6091,1,['deploy'],['deploy']
Deployability,"TKSparkTool.runPipeline(GATKSparkTool.java:534); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.FileSystemNotFoundException: Provider ""gs"" not installed; 	at java.nio.file.Paths.get(Paths.java:147); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferencePath(ReferenceFileSparkSource.java:53); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferenceBases(ReferenceFileSparkSource.java:60); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceMultiSparkSource.getReferenceBases(ReferenceMultiSparkSource.java:89); 	at org.b",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:7543,deploy,deploy,7543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['deploy'],['deploy']
Deployability,Tabix fails in UpdateVCFSequenceDictionary when outputting .vcf.gz file,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5087:15,Update,UpdateVCFSequenceDictionary,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5087,1,['Update'],['UpdateVCFSequenceDictionary']
Deployability,"Tagging @rcmajovski, who will lead on the forum doc updates.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5422#issuecomment-440374899:52,update,updates,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5422#issuecomment-440374899,1,['update'],['updates']
Deployability,Tagging @tedsharpe as I know you have worked on these pipelines.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3878#issuecomment-347299425:54,pipeline,pipelines,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3878#issuecomment-347299425,1,['pipeline'],['pipelines']
Deployability,Takes in a WGS bam or cram and outputs VCF of SNP/Indel calls on the mitochondria. Note this pipeline does not perform any realignment and just uses read-pairs that map to chrM,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7414:93,pipeline,pipeline,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7414,1,['pipeline'],['pipeline']
Deployability,"Talked to @ldgauthier about this, and I'm not sure that this matters anymore for our current joint-calling pipeline. @ldgauthier would you be comfortable closing?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4294#issuecomment-460404012:107,pipeline,pipeline,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4294#issuecomment-460404012,1,['pipeline'],['pipeline']
Deployability,"Technically, the Hadoop upgrade is not required for this, since we're temporarily reverting back to a Java 11 version that doesn't trigger the version parsing issues that surface with older Haddop/Jetty versions, but we may as well keep it, since we'll need it once we fix the ModelSegments tests and switch back to using current Java 11 versions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8102#issuecomment-1330749145:24,upgrade,upgrade,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8102#issuecomment-1330749145,1,['upgrade'],['upgrade']
Deployability,Tell me about it :). Biggest support burden of upping the java version was due to Apple making it hard to seamlessly upgrade the java version. Users themselves didn't care all that much as long as the requirements were clear. . So far we've been lucky that no other major tool seems to dictate which version of java users should have on their machine. Otherwise collisions could happen.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9#issuecomment-66529138:117,upgrade,upgrade,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9#issuecomment-66529138,1,['upgrade'],['upgrade']
Deployability,Temporarily closing and re-open after Beta release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2701#issuecomment-304359494:43,release,release,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2701#issuecomment-304359494,1,['release'],['release']
Deployability,Test run with `load_data_scatter_width` set: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/f10f47ab-8b5b-428a-b418-c9dc9f9c3a58; Test run with `load_data_scatter_width` not set: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/5bf5fe73-10d6-4df2-a5df-3f793c25ebde; integration run: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/84f14232-dc62-4ce5-8031-7840f7f2aedc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8985:348,integrat,integration,348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8985,1,['integrat'],['integration']
Deployability,Test will fail until htsjdk is updated. Fixes https://github.com/broadinstitute/gatk/issues/6475.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7066:31,update,updated,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7066,1,['update'],['updated']
Deployability,"Tested using gatk-4.beta.6-151-g1ec409c-SNAPSHOT locally and with dataproc. Observed bug while testing commands for documentation updates in https://github.com/broadinstitute/gatk/pull/4068. . CollectInsertSizeMetricsSpark requires the `--histogramPlotFile` (`-H`, file to write insert size Histogram chart to) and current example commands add the `.pdf` extension to these files. The tool errors without this being specified but then doesn't write the file. In CollectBaseDistributionByCycleSpark, `--chart` (`-C`, A file (with .pdf extension) to write the chart to) is optional. When specified, the tool appears to ignore this option and does not write the file. . Metrics files defined by `-O` are written.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4085:130,update,updates,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4085,1,['update'],['updates']
Deployability,"Testing branch `ck_3487_port_LeftAlignAndTrimVariants`, which ports LeftAlignAndTrimVariants from GATK3 to GATK4. ### stdout; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; 16:34:35.251 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 4:34:35 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 16:34:35.413 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 16:34:35.414 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:34:35.414 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 16:34:35.414 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 16:34:35.414 IN",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:397,install,install,397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494,3,['install'],['install']
Deployability,"Testing updated branch with improved messaging.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:8,update,updated,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326,4,"['install', 'update']","['install', 'updated']"
Deployability,Tests appear to be passing. Will rebase on master to remove commits from #4280 and merge so we don't delay the release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361345078:111,release,release,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361345078,1,['release'],['release']
Deployability,"Tests are ""failing"" with the ""code is too big"" error on the CNN testTrainingReadModel. I had to update my conda yml template to use a newer Tensorflow @cmnbroad found -- should I add that here too?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6330:96,update,update,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6330,1,['update'],['update']
Deployability,"Tests are not passing because I'm now using NIO in the WDL. I'll need to fix that, but the WDL itself should be ready for review. . The changes:; - Updates the pipeline for the new Mutect2 Filtering scheme and pulls filtering after the liftover and recombining of the VCF. ; - Makes the subsetting of the WGS bam fast by using PrintReads over just chrM instead of traversing the whole bam for NuMT mates.; - Moves polymorphic NuMTs based on autosomal coverage to a filter (it was an annotation before); - Adds option to hard filter by VAF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5847:148,Update,Updates,148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5847,2,"['Update', 'pipeline']","['Updates', 'pipeline']"
Deployability,Tests are passing using a snapshot generated while debugging https://github.com/broadinstitute/picard/pull/1904. Folks can review and give feedback. Perhaps we shouldn't merge though unless referencing a library SNAPSHOT is ok or picard 3.0.1 is released.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1655703824:246,release,released,246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1655703824,2,['release'],['released']
Deployability,Tests now running with the Picard 3.1.0 release,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1656037136:40,release,release,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1656037136,1,['release'],['release']
Deployability,Tests that need to access data in a GCS bucket (but not run an actual pipeline); need a PipelineOptions object containing our API key. This new method makes; it for them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/742:70,pipeline,pipeline,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/742,2,"['Pipeline', 'pipeline']","['PipelineOptions', 'pipeline']"
Deployability,"Thank you @SHuang-Broad. The error was gone after I copied bwaindeximage file to lustre file system, which can be accessed by all worker nodes.; The new problem is: the program started but didn't give any informative message/progress (see log below). It was stopped (Ctl-C) after 16 hours. The sequence data is regular human exome, which could be mapped in 1-2 hours in our traditional pipeline. ```; ../gatk/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; -I hdfs://ln16/user/myname/NA12878/wes/NA12878-NGv3-LAB1360-A.unaligned.bam ; -O hdfs://ln16/user/myname/gatk4test/BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://ln16/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /TEST/hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=720 ; --executor-cores 20 ; --executor-memory 50g ; --conf spark.driver.memory=50g; Using GATK jar /home/myname/gatk4/gatk/build/libs/gatk-package-4.alpha.2-1125-g27b5190-SNAPSHOT-spark.jar; Running:; /opt/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --master spark://ln16:7077 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOption; s=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.di$able=true --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --conf spark.cores.max=720 --executor-cores 20 --executor-memory 50g --conf spark.driver.memory=50g /home/myname/gatk4/gatk$build/libs/gatk",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:386,pipeline,pipeline,386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['pipeline'],['pipeline']
Deployability,"Thank you @ddrichel! That's really helpful and seems to support my suspicion. The most relevant changes to Mutect2 between versions 4.1.8.1 and 4.1.9.0 are #6520, #6696, and #6821, which have in common the property that they are bug fixes restoring sensitivity in edge cases. I don't think that any of these are regressions because the job of Mutect2 is to output any candidate variant. Filtering is the responsibility of FilterMutectCalls. Because our panel of normals is generated by running Mutect2, a panel of normals generated before 4.1.9.0 is blind to artifacts that occur in these edge cases. I suspect that re-generating our panels of normals using a more recent release of Mutect2 will solve the problem. I'm going to need to see how long it will take to gather the samples to re-generate our hg38 panel of normals (it might not take long at all) and triage that against the timetable for Mutect3, which does away with the panel of normals entirely.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1203356531:672,release,release,672,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1203356531,1,['release'],['release']
Deployability,"Thank you @gmagoon. This is in the new draft now and these updates should be reflected in the next release of GATK. . @ldgauthier, the PR containing the updates is at https://github.com/broadinstitute/gatk/pull/5601.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-456975545:59,update,updates,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-456975545,3,"['release', 'update']","['release', 'updates']"
Deployability,"Thank you @kshakir. What I see there is that the code sets the default NIO option, and as part of this is creates a google cloud `StorageOptions` object. Sadly for us, when this object is created it determines which Google credentials to use, and if nothing was specified by the user it will send some network messages to try to figure out whether it's running on a Google Compute Engine machine. When we wrote the default-setting code we didn't realize that setting the number of retries was going to cause a network message to be sent, with the associated potential retries and delays. We can't change the way Google Compute Engine works, or how the Google authentication works either. Ideally we'd want some way to only search for credentials when we know NIO is going to be used. The point of these defaults is that they're used for anything that uses NIO, including third-party library code. We can't fully replicate this behavior in a different way from the outside. So I think the ""correct"" fix would be to go deep inside the Google NIO library and change it so that instead of providing a default configuration (that the user would have to put together, causing the problem you've seen), we can provide a *callback* that sets the configuration when the Google Cloud NIO provider is loaded. This is harder for future developers to wrap their heads around, but at least it would prevent this delay if NIO is not used. I'd like to think about this some more before doing something quite this drastic, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504:1105,configurat,configuration,1105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504,2,['configurat'],['configuration']
Deployability,"Thank you @mwalker174 . The input bamfile is about 7 GB. If no `--bamPartitionSize` is specified, the job would stuck at the first step `collect at ReadsSparkSource.java:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:626,pipeline,pipelines,626,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['pipeline'],['pipelines']
Deployability,"Thank you @mwalker174 for the suggestions. I ended up writing for loops to test which configurations work. Driver memory: 2-50g; executor memory: 2-50g; executor cores: 1-20; bamPartitionSize: 1-64m. Some combinations failed in minutes, some failed in hours, and some finished without errors. Bellow are three of which work for a ~33X WGS data:; ```; ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 4000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=600 ; --executor-cores 20 ; --executor-memory 10g ; --conf spark.driver.memory=50g. ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 4000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=600 ; --executor-cores 5 ; --executor-memory 50g ; --conf spark.driver.memory=50g. ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 64000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.core",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313981314:86,configurat,configurations,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313981314,1,['configurat'],['configurations']
Deployability,Thank you everyone for your contributions towards this documentation effort. ; Instructions from @vdauwera ~~to follow~~ at [this Google doc](https://docs.google.com/a/broadinstitute.org/document/d/1r1AV4yWP4_vNmniUDR5LojihuggMDI2OnEpfRiYyvdk/edit?usp=sharing); Favorite tool doc examples from @vdauwera NOW in her SOP doc.; Spreadsheet from @sooheelee ~~to be~~ posted [here](https://docs.google.com/a/broadinstitute.org/spreadsheets/d/19SvP6DHyXewm8Cd47WsM3NUku_czP2rkh4L_6fd-Nac/edit?usp=sharing),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853:166,a/b,a/broadinstitute,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853,2,['a/b'],['a/broadinstitute']
Deployability,Thank you for the feedback! Will update style.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/511#issuecomment-101807825:33,update,update,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511#issuecomment-101807825,1,['update'],['update']
Deployability,"Thank you for the update to the PGT definition in the GATKVCFHeaderLines. ; If the possible discordance of the GT and PGT in at least 1 genotype in 7% of the phased variants is a feature and not a bug then I am not understanding the PGT field correct. . For example why is GT and PGT concordant for the genotypes of 93% of the phased variants?; Anf if PGT will only ever be heterozygous, then why are there PGT fields with the value 1|1, both concordant and discordant with the GT field?. Thank you for the extra clarification. A link to documentation describing the PGT whould also be very helpful. . PGT 1|1 concordant with the genotype field; ```; Chr_10	7000450		T	G	1703.2	PASS	; AC=10;AF=0.556;AN=18;BaseQRankSum=0.451;ClippingRankSum=-0.792;DP=147;ExcessHet=15.796;FS=58.874;MLEAC=10;MLEAF=0.556;MQ=53.78;MQ0=0;MQRankSum=-3.328;QD=11.75;ReadPosRankSum=0.797;SOR=4.003	; GT:AD:DP:GQ:PGT:PID:PL:PS	0|1:12,5:17:99:0|1:7000450_T_G:216,0,514:7000450	0/1:6,2:8:28:.:.:28,0,207:.	0|1:31,4:35:42:0|1:7000450_T_G:42,0,1288:7000450	0|1:4,3:7:99:0|1:7000441_G_T:114,0,159:7000441	0|1:10,10:20:99:0|1:7000450_T_G:390,0,390:7000450	0|1:13,7:20:99:0|1:7000450_T_G:252,0,546:7000450	0/1:15,5:20:99:.:.:165,0,558:.	1|1:0,4:4:12:1|1:7000450_T_G:180,12,0:7000450	0|1:6,8:14:99:0|1:7000450_T_G:318,0,228:7000450. 1|1:0,4:4:12:1|1:7000450_T_G:180,12,0:7000450. Chr_11	29801226	A	G	627.62	PASS	; AC=2;AF=0.125;AN=16;DP=92;ExcessHet=0.1472;FS=0;MLEAC=2;MLEAF=0.125;MQ=59.22;MQ0=0;QD=31.94;SOR=2.303	; GT:AD:DP:GQ:PGT:PID:PL:PS	0/0:15,0:15:42:.:.:0,42,487:.	0/0:10,0:10:24:.:.:0,24,360:.	1|1:0,14:14:45:1|1:29801226_A_G:649,45,0:29801226	.:0,0:.:.:.:.:.:.	0/0:11,0:11:30:.:.:0,30,375:.	0/0:21,0:21:60:.:.:0,60,735:.	0/0:5,0:5:12:.:.:0,12,163:.	0/0:6,0:6:12:.:.:0,12,173:.	0/0:10,0:10:27:.:.:0,27,405:. 1|1:0,14:14:45:1|1:29801226_A_G:649,45,0:29801226; ```. PGT 1|1 disconcordant with the genotype field (which is 2|2):; ```; Chr_08 694087 . A *,G 172.35 PASS AC=5,2;AF=0.313,0.125;AN=16;DP=52;ExcessHet=0.1809;FS=0;M",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6220#issuecomment-544394703:18,update,update,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6220#issuecomment-544394703,1,['update'],['update']
Deployability,"Thank you for the update, @droazen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-705663517:18,update,update,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-705663517,1,['update'],['update']
Deployability,"Thank you for your review, @vruano ! I addressed each of your comments. In the process, I discovered a bug in an integration test that needed fixing, which is added as another commit.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3537#issuecomment-329907772:113,integrat,integration,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3537#issuecomment-329907772,1,['integrat'],['integration']
Deployability,"Thank you for your suggestion @wir963. This would certainly be a useful feature. If you are waiting for this capability, I think you could probably write a small pipeline to modify the current output:. 1. Merge UMI read tags into the output PathSeq BAM (involves traversing the input BAM); 2. Filter duplicate UMI reads (perhaps retaining the one with the best alignment score); 3. Split BAM into paired and unpaired read BAMs; 4. Feed these back into `PathSeqScoreSpark`. PathSeq currently removes all read tags - I have received requests in the past to fix this. I'm not sure when I'll have a chance to address this, but I will keep the ticket open since it's currently the only feature request.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6655#issuecomment-644299048:162,pipeline,pipeline,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6655#issuecomment-644299048,1,['pipeline'],['pipeline']
Deployability,"Thank you very much @cmnbroad . I really appreciate your help. I tried all the things you suggested, but I still get the error.; The program was installed in a singularity container using docker img. Do you think tha it might be a java issue?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6241#issuecomment-548846823:145,install,installed,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6241#issuecomment-548846823,1,['install'],['installed']
Deployability,"Thank you very much @droazen! This should take care of all the comments, so once the checks are green I'll press ""squash and merge."" Then I'll move on to the next tool to update!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4424#issuecomment-381676296:171,update,update,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4424#issuecomment-381676296,1,['update'],['update']
Deployability,Thank you! I also wonder if you could advise timeline for the new release with this fix.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452016657:66,release,release,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452016657,1,['release'],['release']
Deployability,"Thank you! That was indeed the issue. Hunting down the exact way to install lfs from the command line took a little time, so I'll add the steps here in case, feel free to add them to your readme.; `sudo` was cut out since the docker I'm using doesn't like it and says it's not a valid command (based on debian 9).; ```; curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash; apt install -y git-lfs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6019#issuecomment-507519267:68,install,install,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6019#issuecomment-507519267,3,['install'],['install']
Deployability,"Thank you!. On Mon, Oct 22, 2018 at 10:33 AM meganshand <notifications@github.com>; wrote:. > @SusieX <https://github.com/SusieX>; >; > Marking duplicates: I do recommend removing duplicates (we run; > MarkDuplicates from Picard).; >; > BQSR: The pipeline we're developing is for Whole Genome data, so our bams; > have gone through BQSR in the whole genome pipeline. We're using those; > recalibrated base qualities. I haven't tested running BQSR only on the; > mitochondria so I don't know how well that would work.; >; > If you do need to run BQSR only on the mitochondria I'd start by using the; > phylotree sites as --known-sites, but you'd need to have those sites in; > vcf format. Again, I haven't tested this so I don't know how well it will; > perform.; >; > If you end up using BQSR I think you're pipeline (BAM -> remove dup -> BQ; > recalibrate -> Mutect2 call -> FilterMutectCalls) is correct. Good luck!; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5193#issuecomment-431852996>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AQ4DHh9X94wZ-4488FohFKnkv1SCe6c2ks5undccgaJpZM4WqV76>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-431899805:247,pipeline,pipeline,247,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-431899805,3,['pipeline'],['pipeline']
Deployability,"Thank you!. On Tue, Oct 16, 2018 at 9:29 AM meganshand <notifications@github.com> wrote:. > @SusieX <https://github.com/SusieX> Sorry for the delay, we're just; > trying to finalize some potentially disruptive changes before we merge.; > I'll open an issue so I can ping you there once this PR has been both; > merged and released. Thanks!; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5193#issuecomment-430237566>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AQ4DHqWjVP9RQyGuRbbM-Nds_8l0RDtSks5uld84gaJpZM4WqV76>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-430238072:322,release,released,322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-430238072,1,['release'],['released']
Deployability,"Thank you, now I understand. But then two more questions:; Why does the official broad gatk exome pipeline: it does not have --interval-padding set. Why is that?; ; I have tried adding --interval-padding in the past, but it causes the official broad gatk exome pipeline to crash due to resulting multiply called variants in different scatter intervals. See here for prior issue report: https://gatkforums.broadinstitute.org/gatk/discussion/11937/vcf2tiledbexception-incorrect-cell-order-found. So how can I add interval-padding to the broak gatk exome pipeline?; . So per the above, there still seems to be some issues in the official broad gatk exome pipeline. . From: droazen <notifications@github.com>; Reply-To: broadinstitute/gatk <reply@reply.github.com>; Date: Thursday, August 1, 2019 at 3:04 PM; To: broadinstitute/gatk <gatk@noreply.github.com>; Cc: gevro <g.evrony@gmail.com>, Mention <mention@noreply.github.com>; Subject: Re: [broadinstitute/gatk] Missing interval padding for HaplotypeCaller (#6071). . @gevro If you want to get variant calls in your padded regions, then specify --interval-padding. HaplotypeCaller will internally add additional padding (the --assembly-region-padding) to the intervals during assembly to help assemble events that span off the edge of assembly regions, but it's the -L intervals that determine the bounds of the final callset, and these are transformed by --interval-padding. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6071#issuecomment-517421610:98,pipeline,pipeline,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6071#issuecomment-517421610,4,['pipeline'],['pipeline']
Deployability,"Thank you, sir. In fact , firstly I called SNP from both parents respectively, and then combined both parents vcf files to a integrate vcf file, I want to get maternal different homozygous SNP compare to reference genome and paternal different homozygous SNP compare to reference genome, and combined both parents SNPs to a integrate biSNP.vcf file ,and then filtered heterozygote sites. Finally I submited this integrate biSNP.vcf as a input file of argument ""sites"" of GATK-3.8 ASEReaderCounter, l got normal output file of ASE reads count. But if I used argument ""variants"" of GATK-4.0 to replace ""sites"" argument of GATK-3.8, other files were not changed, it reminded me that ""the SNP site of inupt file is not het"" , so I got null result file in the end,because l filtered integrate vcf file, all SNP sites of different parents are homozygote compare to reference genome. So l want to know what kind of vcf file can be used as input file of ""variants"" argument of GATK-4.0 ASEReadCounter ? both parents g.vcf files ? Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7747#issuecomment-1084770372:125,integrat,integrate,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7747#issuecomment-1084770372,4,['integrat'],['integrate']
Deployability,"Thanks @bbimber, I have the file downloaded, please go ahead and remove it. I have reproduced the seg fault - it is because of one faulty fragment - `WGS_Sept_1117.gdb/QNVO02001147.1$1$28016/__58eb4600-9c95-425e-a585-4bb23b486577140340709598976_1596797671601`. Not sure why, but it seems to be missing a number of files(e.g. `__coords.tdb`) causing the fault. Things work fine if you move the fragment out of the array. . For what its worth, all the samples from the callset.json seem to be represented in the rest of the fragments. So you might be fine with downstream processing with `__58eb4600-9c95-425e-a585-4bb23b486577140340709598976_1596797671601` removed for now. . For our debugging, . 1. Was the GenomicsDBImport run in an update mode at all after an initial import?; 2. Do you have any logs from `gatk GenomicsDBImport` for the `QNVO02001147.1$1$28016` array? ; 3. Was anything reported in the Lustre logs?; 4. I have attached the samples found in the callset.json for the `QNVO02001147.1$1$28016` array, can you confirm these were the expected samples? Are there any missing?. [samples.txt](https://github.com/broadinstitute/gatk/files/5460536/samples.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-718941513:734,update,update,734,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-718941513,1,['update'],['update']
Deployability,Thanks @bshifaw! I asked the user to try the new release. If that fails I will debug ASAP.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-540302477:49,release,release,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-540302477,1,['release'],['release']
Deployability,"Thanks @clsgithubusr, we are well aware that Theano is no longer in development. There are plans to move future model implementations to pyro (https://github.com/pyro-ppl/pyro) and some prototype models have already been developed in that framework. As is stated in the post you linked, things move relatively quickly in the ML world!. Fortunately, Theano is a relatively mature and stable framework. If you use the GATK conda environment you shouldn’t have any issues. If not, I don’t think we can make any guarantees. It was a major decision for us to introduce python ML frameworks into our codebase, but it was necessary to enable methods that can take advantage of all of the developments happening in the field of ML. We understand that deployment may be more difficult as a result, but using conda and Docker should hopefully ease the burden significantly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766#issuecomment-470211072:743,deploy,deployment,743,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766#issuecomment-470211072,1,['deploy'],['deployment']
Deployability,Thanks @cmnbroad. Got swept away in Taiwan workshop updates.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5245#issuecomment-448091892:52,update,updates,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5245#issuecomment-448091892,1,['update'],['updates']
Deployability,"Thanks @davidbenjamin - my thought here was that since it's an available annotation in HaplotypeCaller it would be nice to just add a line to the release notes in case anyone else had started emitting it. To answer your question, we have been emitting it in a clinical pipeline, but haven't actually been using it for downstream filtering yet.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480072316:146,release,release,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480072316,2,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,Thanks @davidbenjamin and @sooheelee ! Please keep me updated.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4555#issuecomment-375988400:54,update,updated,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4555#issuecomment-375988400,1,['update'],['updated']
Deployability,Thanks @davidbenjamin for the updates and apologies for taking a while to get back to this PR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3937#issuecomment-353443578:30,update,updates,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3937#issuecomment-353443578,1,['update'],['updates']
Deployability,"Thanks @davidbenjamin! This looks much cleaner now. Still holding out a tiny bit of hope for merging before the release, if you have a chance to look at the new changes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477741728:112,release,release,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477741728,1,['release'],['release']
Deployability,Thanks @droazen ! . Eagerly waiting for the next release,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1682823503:49,release,release,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1682823503,1,['release'],['release']
Deployability,"Thanks @droazen & @ldgauthier. I can certainly run a bunch more iterations of the same HC run on the same data. I'm not super hopeful it will turn anything up though. I can also try selecting a bunch of the different PairHMM implementations. I can't share too much, but this issue turned up in a very high throughput (1000s of samples a day) clinical pipeline. We're going back and looking for other instances where we see an excess of that `Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null` message, and re-running those samples to see if, on re-run, they generate different outputs. I realize the AVX-specific hardware issue is perhaps a little far-fetched, though given the volume of the pipeline and the fact that it runs in a cloud environment, I think it's entirely reasonable to suspect we'll run into hardware/instance issues occasionally. And there are AVX or at least SIMD specific registers, so if one of those were to see problems that could cause the PairHMM issues, without causing issues in other software that doesn't leverage the SIMD/AVX instructions. My main question really is this: is anyone familiar enough with the Intel PairHMM implementation and interface that they could weigh in on whether or not unexpected hardware errors could result in the return of empty likelihoods from the PairHMM instead of some kind of error, exception or segfault?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6889#issuecomment-709555915:351,pipeline,pipeline,351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6889#issuecomment-709555915,2,['pipeline'],['pipeline']
Deployability,"Thanks @droazen for the patched 4.1.8.1, the effort is appreciated. FYI I ran an experiment by setting; `; private static final int ONE_THIRD_QUAL_CORRECTION = 5;; `; which was introduced in https://github.com/broadinstitute/gatk/commit/a304725a60f5000ec6381040137043a557fc3dc1, to 0, which effectively should revert the commit. In v4.4.0.0. for SNVs, this results in ~2% loss of recall and a striking ~13% gain in precision (from 0.8286 to 0.9609), ~4% improvement over v4.1.8.1. ![FD_TN_4181_FD_TN_4190_FD_TN_4400_FD_TN-4 4 0 0-18-g7518611](https://user-images.githubusercontent.com/15612230/236791152-0618610f-cafd-4c1d-b395-238401b069e1.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1538091453:24,patch,patched,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1538091453,1,['patch'],['patched']
Deployability,"Thanks @droazen,; Additionally the dockstore integration App will need to be added this repo (as mentioned [here](https://docs.dockstore.org/en/develop/getting-started/dockstore-workflows.html#registration-with-github-apps)). . For example: ; ![Screen Shot 2020-10-14 at 11 11 04](https://user-images.githubusercontent.com/14318238/96010590-f6a15a80-0e0f-11eb-80e2-68568c18d8df.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6770#issuecomment-708478858:45,integrat,integration,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6770#issuecomment-708478858,1,['integrat'],['integration']
Deployability,"Thanks @droazen. Because you assigned it to me, I would like to know a couple of details on how this should be implemented in GATK4:. * GATK3 use to have a the `MisencodedBaseQualityReadTransformer` always on, with a switch for checking/fixing the qualities. If we follow this approach in GATK, the only change for this is to include the checking step every n reads and then #2160 will do the rest. Nevertheles, I think that it's quite dangerous to allow an user to disable it with the plugin (because the name suggest that it is only fixing the qualities), so I suggest to integrate in the read data source an iterator for checking every x reads if the qualities are misencoded, independently on the transformer.; * GATK3 throws an UserException for ""putatively misencoded"" qualities, using 60 as maximum base quality for throwing. I think that in the case of GATK4 could be more useful to use a warning if it is over 60 (I do not know what is the reasoning behind this value), and use `SAMUtils.MAX_PHRED_SCORE` for throwing. I'd be happy to implement this if there is a consensus about what to do here, so I'll wait for your ideas...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2082#issuecomment-288760814:574,integrat,integrate,574,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2082#issuecomment-288760814,1,['integrat'],['integrate']
Deployability,"Thanks @eitanbanks, we'll try to get a patch out this week for this one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4312#issuecomment-361992446:39,patch,patch,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4312#issuecomment-361992446,1,['patch'],['patch']
Deployability,Thanks @erniebrau! Looking forward to test the next release of GKL.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330808237:52,release,release,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330808237,1,['release'],['release']
Deployability,Thanks @jamesemery! I've updated the PR to address your comments.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4926#issuecomment-418507292:25,update,updated,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4926#issuecomment-418507292,1,['update'],['updated']
Deployability,Thanks @jamesemery. The compile errors will be fixed once Disq 0.2.0 is released.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5485#issuecomment-454749917:72,release,released,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5485#issuecomment-454749917,1,['release'],['released']
Deployability,"Thanks @jean-philippe-martin -- this worked, though it took me a while to realize that the update from `1.0-rc2` to `1.0-rc3` was also essential (still failed for me with `1.0-rc2`)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314302312:91,update,update,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314302312,1,['update'],['update']
Deployability,"Thanks @jjfarrell -- I've replicated the issue, and am working on a patch now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3845#issuecomment-358714808:68,patch,patch,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845#issuecomment-358714808,1,['patch'],['patch']
Deployability,"Thanks @jonn-smith. Is Funcotator ready for us to document now or in the next month? Meaning, is it usable by users now? Otherwise, we can release an `alpha` tutorial initially to get folks to use it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3769#issuecomment-341184664:139,release,release,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769#issuecomment-341184664,2,['release'],['release']
Deployability,"Thanks @kdatta. The branch builds now, but there are a couple of problems that cause several tests to fail, including some existing tests that used to pass. You can see the results [here](https://travis-ci.org/broadinstitute/gatk/jobs/221534229). - The main issue is that GenomicsDB fails to load. This causes the importer tests to fail, as well as the existing GenomicsDB integration tests. (Note that the importer tests fail with a null pointer exception, but that problem is secondary and only happens when the db fails to load, which is the root problem.) We can fix the NPE in code review, for now the main issue is fix the core problem of why genomics db fails to load. - The changes in OptionalVariantInputArgumentCollection and RequiredVariantInputArgumentCollection are causing argument name collisions in other tools, which is why ExampleIntervalWalkerIntegrationTest tests are failing in this branch. The simplest fix in the short term is to just revert the changes you made to those two classes, and remove the new VariantInputArgumentCollection class. These aren't being used by the importer tool anyway. It should be pretty easy to reproduce load issue, it happens on my laptop and and travis, but let me know if you need help or have questions about any of this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294148791:373,integrat,integration,373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294148791,2,['integrat'],['integration']
Deployability,"Thanks @lbergelson - nice to meet you too. Sorry for the delay here. I had to set up gsutils on my system and am having gdb issues. . Submitting `sudo gdb /nfsdata-tmp/tools/gatk /home/bduser/mepowers/core.114856` I get back . ```; Missing separate debuginfo for the main executable file; Try: yum --enablerepo='*debug*' install /usr/lib/debug/.build-id/6c/../../../jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.el7_2.x86_64/bin/java; Core was generated by `java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samt'.; Program terminated with signal 6, Aborted.; ```; I did try the yum --enablerepo, but it am getting the same error. . Any quick workarounds? Thanks in advance for the help. Will try again on Monday.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-466588771:321,install,install,321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-466588771,1,['install'],['install']
Deployability,"Thanks @lbergelson and @droazen. Could it be possible to add a simple patch to add all the reads to the returned `AlignmentContext`, instead of just add the `ReadPileup` from just one covered sample?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1752#issuecomment-213057081:70,patch,patch,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1752#issuecomment-213057081,1,['patch'],['patch']
Deployability,"Thanks @lbergelson for looking into this. Users can definitely squash the image after pulling, and then push it to their private registries - that's the best workaround here, so this is likely a low-priority issue. Docker images can only be pulled by layers currently; there's no way to pull an image that has multiple layers with one HTTP request. In the [TES runner](https://github.com/microsoft/ga4gh-tes), we are also increasing the docker pull retry count to help. I'll try to update the `dockerfile` and send a PR, thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1935007776:482,update,update,482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1935007776,1,['update'],['update']
Deployability,Thanks @lbergelson for your answer and explanation. **_Suggestion:_** It might be worthwhile to update the necessary pages with above info (about Java 8 and Java 11) so that it will help all. I would suggest updating these pages. - _**Requirements section**_: https://github.com/broadinstitute/gatk#requirements; - https://gatk.broadinstitute.org/hc/en-us/articles/360035532332; - **_QuickStart section and Requirements section_**: https://gatk.broadinstitute.org/hc/en-us/articles/360036194592; - **_Section on Software/Java 8_**: https://gatk.broadinstitute.org/hc/en-us/articles/360035889531-What-are-the-requirements-for-running-GATK-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7842#issuecomment-1122801151:96,update,update,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7842#issuecomment-1122801151,1,['update'],['update']
Deployability,"Thanks @lbergelson! I agree that it might be good to break into more layers—could be worth talking to SV team and seeing what lessons they learned in putting together their hierarchy of images. Also, note that I pushed the install of miniconda into the base, but I did not push down the setup of the GATK conda environment itself (which takes the bulk of the time during the main-image build, as it requires lots of downloading). I think I commented elsewhere that a good strategy might be to set up the conda environment with the non-GATK python dependencies in the base, and then update the environment via a pip install of the GATK python packages in the main image. This would let us make python code changes without having to rebuild the base, but might require a bit of scripting to create a final yml for non-Docker users. I also agree that it would be nice to cut down the Travis time, might be worth taking a look at other strategies to do that—could save everyone a lot of time!. Will try to add the test you suggested sometime tomorrow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-621487662:223,install,install,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-621487662,6,"['install', 'update']","['install', 'update']"
Deployability,"Thanks @lbergelson. I try to not depend on this, but when we're developing tools that rely on a GATK feature not yet in a release (like i'm trying to do here), it's quite useful to have those snapshots.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8138#issuecomment-1370160247:122,release,release,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8138#issuecomment-1370160247,1,['release'],['release']
Deployability,Thanks @lbergelson. Looks like the repo hasn't been updated since March. Recommend pinging Paolo from Intel and asking who the current maintainer is.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5393#issuecomment-437056873:52,update,updated,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5393#issuecomment-437056873,1,['update'],['updated']
Deployability,Thanks @ldgauthier! That canary certainly looks alive to me. Happy to merge whenever you and/or Variants team approve.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1062112049:25,canary,canary,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1062112049,1,['canary'],['canary']
Deployability,"Thanks @mwalker174! That setup_gcnvkernel.py file is just for manual installations (users or devs can rename it to setup.py and install the package using pip, for example---I think there's some documentation on this in the readme in the python folder.). So it's not checked by any build tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6245#issuecomment-551241621:69,install,installations,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6245#issuecomment-551241621,2,['install'],"['install', 'installations']"
Deployability,Thanks @ronlevine ! Switching to an updated HTSJDK snapshot appears to fix this issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2753#issuecomment-304388797:36,update,updated,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2753#issuecomment-304388797,1,['update'],['updated']
Deployability,"Thanks @ruqianl, you may want to read through the comments at https://github.com/broadinstitute/gatk/issues/6235 and the corresponding PR https://github.com/broadinstitute/gatk/pull/6244, which both address this issue. See also the following bit of documentation added in that PR:. > Advanced users may wish to set the THEANO_FLAGS environment variable to override the GATK theano configuration. For example, by running THEANO_FLAGS=""base_compiledir=PATH/TO/BASE_COMPILEDIR"" gatk GermlineCNVCaller ..., users can specify the theano compilation directory (which is set to $HOME/.theano by default). See theano documentation at https://theano-pymc.readthedocs.io/en/latest/library/config.html. So you can specify a unique compilation directory for each of your jobs to avoid the compilelock, e.g., `THEANO_FLAGS=""base_compiledir=PATH/TO/BASE_COMPILEDIR/FOR/JOB/0"" gatk GermlineCNVCaller ...`, `THEANO_FLAGS=""base_compiledir=PATH/TO/BASE_COMPILEDIR/FOR/JOB/1"" gatk GermlineCNVCaller ...`, etc. Alternatively, you can increase `config.compile.timeout` as discussed in those comments.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7411#issuecomment-905070899:381,configurat,configuration,381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7411#issuecomment-905070899,1,['configurat'],['configuration']
Deployability,"Thanks @samuelklee , I will incorporate your conda update into this branch, now that we've dealt with the test failures!. I patched the VETS test code to include the h5diff (and diff) output in the exception messages when one of these commands fails, and switched to the existing `BaseTest` methods for running the process and capturing the output. You can see what the output looks like (when we remove the epsilon tolerance) here:. https://storage.googleapis.com/hellbender-test-logs/build_reports/8610/merge_7165443572.3/tests/testOnPackagedReleaseJar/classes/org.broadinstitute.hellbender.tools.walkers.vqsr.scalable.ScoreVariantAnnotationsIntegrationTest.html. https://storage.googleapis.com/hellbender-test-logs/build_reports/8610/merge_7165443572.3/tests/testOnPackagedReleaseJar/classes/org.broadinstitute.hellbender.tools.walkers.vqsr.scalable.TrainVariantAnnotationsModelIntegrationTest.html. As you suspected/hoped, all the differences were tiny. When you have a chance, could you please review these changes to the VETS tests and let me know if you spot any issues?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8610#issuecomment-1850563977:51,update,update,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8610#issuecomment-1850563977,2,"['patch', 'update']","['patched', 'update']"
Deployability,"Thanks @samuelklee! I don't think 5 is strictly necessary, since we should be able to use VariantFiltration with a hard filter of a VQSLOD threshold right? Or are you saying that ScoreVariantAnnotations is the tool that needs to convert between LL/sensitivity and VQSLOD cutoff? . I'm happy to work on the WDL, do most of the tools on this branch have integration tests? That's where I'll start grabbing commands.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069187834:352,integrat,integration,352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069187834,1,['integrat'],['integration']
Deployability,"Thanks @samuelklee, I was able to get the pipeline to finish last night using the 5000 interval setting as long as I used a single thread to handle the larger memory footprint. I might be able to increase this slightly after some tuning tests. Likely the threads/memory issue is why my earlier attempts to use 5000 intervals with many more samples failed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468672358:42,pipeline,pipeline,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468672358,1,['pipeline'],['pipeline']
Deployability,"Thanks JP. This is really Interesting. Unfortunately I think the vcf slice is the major motivating use case. How; large was that vcf? Do you think there's anything we can do to get some; speedup with NIO for small files when we only have 1 core? I'm not totally; clear on how data transfer over a network interacts with thread waiting.; If we are receiving data over the internet does that need cpu time or is; that handled asynchronously by the network card? I.e. if we're prefetching; in on thread, can that thread be asleep or is it consuming cpu time the; whole time a transfer is in progress?. I suspect that the immediate next question people are going to have is ""4; cores are inefficient, 1 core is slow, how about 2 cores..."". I'm curious about async and vcf. The updated slides show vcf with async on; being ~40% slower than with async off. That's; setting use_async_io_write_tribble on / off? It looks like we should just; disable it if we're on a single core, but by default we have it on.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2424#issuecomment-284076588:773,update,updated,773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2424#issuecomment-284076588,2,['update'],['updated']
Deployability,"Thanks Laura, the next release will incorporate both your suggestions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4963#issuecomment-413701822:23,release,release,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4963#issuecomment-413701822,1,['release'],['release']
Deployability,"Thanks a lot @davidbenjamin ; In the meantime I have compiled the master branch when I saw this issue was resolved and it worked fine. I tried also to create a pon with this fresh compiled version but I got some errors (don't remember exactly what right now). Looks like you are in the middle of changing the pipeline of pon creation by integrating GenomicsDB as an intermediate, right ? Do you think it will also be ready for this next release ? I would like to create the pon with the same GATK version. Problem is I can not fall back on an earlier version because I would definitely get the bug we are talking about in this thread :-). Perhaps we should also change our computing nodes at some point I guess :). Thanks again",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470662216:309,pipeline,pipeline,309,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470662216,3,"['integrat', 'pipeline', 'release']","['integrating', 'pipeline', 'release']"
Deployability,"Thanks a lot for your detailed information. ; I just had a look into the branch you told me, but it looks quite complicated to me at this time. I think I will wait until the official release in January and hope for some kind of best practise guidelines to come up.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3996#issuecomment-352778559:183,release,release,183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3996#issuecomment-352778559,2,['release'],['release']
Deployability,"Thanks a lot, @ddrichel. Given that the current Mutect2 release is still broken on both tumor-normal and tumor-only WES data, and downgrade is not possible on production systems due to the log4j vulnerability: is there any path forward for users that care for both accuracy and security, @davidbenjamin and @droazen ?. I fear waiting for Mutect3 isn't an option since even when it is finished there won't be independent benchmarks available for it for quite a while. Also, I suspect (as any other software product) the new version will have bugs, too, until it has matured in production. Therefore I'd suggest that identifying, understanding and fixing the bug in the current Mutect2 release would be the wisest path forward - do you agree?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1534464682:56,release,release,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1534464682,2,['release'],['release']
Deployability,"Thanks everyone for your contributions to updating the tool docs for yesterday's GATK4.0 release. . In my brief surveys of the status of tooldoc updates, I noticed a number of tools without example commands. I will fill in these missing ones going forward. Thanks again for your efforts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-356657487:89,release,release,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-356657487,2,"['release', 'update']","['release', 'updates']"
Deployability,Thanks for a doing that TwoPass update in here.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2149#issuecomment-245366191:32,update,update,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2149#issuecomment-245366191,1,['update'],['update']
Deployability,"Thanks for adding this! Let me discuss further with @mwalker174 to understand the need and typical use cases (e.g., combining fixed-grid bins) to make sure we don't run into any gotchas downstream. I'll try to review by EOD, but in the meantime, you might want to address a few issues I see at first glance:. 1) Correct the name of the tool (PreprocessIntervals) in the commit message and description.; 2) Add descriptions of the new parameters to the tool Javadoc.; 3) Amend the corresponding WDL task and expose the new parameters in all relevant germline and somatic WDLs.; 4) We should be sure to update the relevant documentation for all germline and somatic WDLs, which emphasizes how PreprocessIntervals should be run differently for WES and WGS, if we plan on changing the default behavior of the tool in the future.; 5) Tests are failing due to a compilation warning about a redundant cast to int.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387:601,update,update,601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387,1,['update'],['update']
Deployability,"Thanks for all the comments! I've made fixes for the minor ones. I'd like to address the secondary and supplemental reads improvement separately (https://github.com/broadinstitute/gatk/issues/2418), so that it doesn't block progress on testing the intervals optimization. I hope this PR can go in once we have a Hadoop-BAM release (which I'll do soon). (Regarding the ""keep paired reads together"" code - as I've explained in a comment, it's pragmatic to have this code in GATK.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2350#issuecomment-281688390:323,release,release,323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2350#issuecomment-281688390,1,['release'],['release']
Deployability,"Thanks for bringing this to our attention, @Tintest. I think that we may be able to address this by setting `base_compiledir` via `os.environ[""THEANO_FLAGS""]` appropriately (see http://deeplearning.net/software/theano/library/config.html). @mbabadi @cmnbroad any thoughts? . In any case, thanks for trying out the GermlineCNVCaller pipeline. You may have to tune some parameters, depending on your data type. You may find the following discussions helpful:. https://gatkforums.broadinstitute.org/gatk/discussion/11711/germlinecnvcaller-interval-merging-rule-error. https://github.com/broadinstitute/gatk/issues/4719. Note that we're still in beta, but our preliminary evaluations have demonstrated improved performance over other callers in both WES and WGS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-390303432:332,pipeline,pipeline,332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-390303432,1,['pipeline'],['pipeline']
Deployability,Thanks for exercising this corner case - looks like TileDB internally used 256 chars for paths. Have increased that to 4096 (max for most filesystems). The next release will fix this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4160#issuecomment-358887152:161,release,release,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4160#issuecomment-358887152,1,['release'],['release']
Deployability,"Thanks for helping with the updates, @MartonKN! Looks like you have some failing integration tests, though. Perhaps go through and fix those up before @sooheelee takes a look? Don't forget you can run integration tests locally for those tools you've updated. It might also be worth rebasing on the most recent version of master and re-pushing your branch to make sure no other argument updates slipped in that might conflict with yours.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3989#issuecomment-352525285:28,update,updates,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3989#issuecomment-352525285,5,"['integrat', 'update']","['integration', 'updated', 'updates']"
Deployability,"Thanks for looking into this @cmnbroad !. * Does this issue only affect tabix indices, or all indices? . * Does it only affect `IndexFeatureFile`, or other GATK4 tools as well? . * Will an htsjdk patch be required?. * You say that the offsets are correct when indexing on the fly -- does this mean that a tabix index produced by `ApplyVQSR` on an hg38 `.vcf.gz` on-the-fly will be correct? Can you comment on https://github.com/broadinstitute/gatk/issues/2821 to confirm?. If this is the case, can you craft an integration test proving that `ApplyVQSR` creates a correct tabix index for an hg38 `.vcf.gz`? We should also probably disable tabix index creation in `IndexFeatureFile` temporarily until we can patch htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2801#issuecomment-306768554:196,patch,patch,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2801#issuecomment-306768554,3,"['integrat', 'patch']","['integration', 'patch']"
Deployability,"Thanks for looking into this @davidbenjamin. I followed the best practices using bwa mem, mark duplicates etc., to create these input bams for HaplotypeCaller. This is Novaseq 2 x 150 data, I ran Fastqc on the reads and everything looks really good, the only thing I can find that might explain the soft-clipping is that there's some Nextera adapter read through on a small percentage of the reads. I haven't been using -Y with bwa (I see it's used in GATK 4 wdls), so it seems like there should be less soft-clipping than normal. I'll admit these are definitely messy regions we're dealing with, but we really need to make the F5 calls for our clinical pipeline. I just tried --dont-use-soft-clipped-bases and I wasn't able to pick the SNP up in the 55-55003_F5_region.bam, but using forceActive/dontTrimActiveRegions does work on this call.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-402690747:654,pipeline,pipeline,654,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-402690747,1,['pipeline'],['pipeline']
Deployability,"Thanks for pointing this out, @cxfustc. We should probably update to more recent versions of Apache Commons Math, where this appears to be fixed. We may want to check for any other performance/runtime improvements. @lbergelson what do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6133#issuecomment-527147418:59,update,update,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6133#issuecomment-527147418,1,['update'],['update']
Deployability,"Thanks for reporting this, @Stikus! That change you highlighted indeed fixes the issue. There was an oblique mention of issues with the previously specified version of pip in the comments of that PR. Note that we now use conda 23.10.0 with the libmamba solver in the GATK Docker image. Please feel free to reopen if you have issues with that specific configuration!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8618#issuecomment-1851818671:351,configurat,configuration,351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8618#issuecomment-1851818671,1,['configurat'],['configuration']
Deployability,"Thanks for running the tests. I was hopeful that that would fix it but it; sounds something else is going on that needs investigation. On Thu, Mar 2, 2023, 3:51 PM danieljrichard ***@***.***>; wrote:. > Hi again,; > I tried installing java8 and switching to this version prior to running; > gatk. It runs and looks to be running the right Java, but spits out roughly; > the same error:; >; > Thoughts?; >; > /cold/drichard/gatk/./gatk --java-options ""-Xmx25g"" SplitNCigarReads; > -R /cold/drichard/VARIANTS/Homo_sapiens.GRCh38.dna.primary_assembly.fa -I; > subset_TINY_rehead.bam; > --tmp-dir /thing -O thing.bam; > Using GATK jar; > /cold/drichard/gatk/build/libs/gatk-package-4.3.0.0-44-g227bbca-SNAPSHOT-local.jar; > Running:; > java -Dsamjdk.use_async_io_read_samtools=false; > -Dsamjdk.use_async_io_write_samtools=true; > -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2; > -Xmx25g -jar; > /cold/drichard/gatk/build/libs/gatk-package-4.3.0.0-44-g227bbca-SNAPSHOT-local.jar; > SplitNCigarReads -R; > /cold/drichard/VARIANTS/Homo_sapiens.GRCh38.dna.primary_assembly.fa -I; > subset_TINY_rehead.bam --tmp-dir /thing -O thing.bam; > 15:34:59.974 INFO NativeLibraryLoader - Loading libgkl_compression.so from; > jar:file:/cold/drichard/gatk/build/libs/gatk-package-4.3.0.0-44-g227bbca-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_compression.so; > 15:35:00.220 INFO SplitNCigarReads -; > ------------------------------------------------------------; > 15:35:00.226 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK); > v4.3.0.0-44-g227bbca-SNAPSHOT; > 15:35:00.226 INFO SplitNCigarReads - For support and documentation go to; > https://software.broadinstitute.org/gatk/; > 15:35:00.226 INFO SplitNCigarReads - Executing as ***@***.*** on; > Linux v5.19.0-32-generic amd64; > 15:35:00.226 INFO SplitNCigarReads - Java runtime: OpenJDK 64-Bit Server; > VM v1.8.0_362-8u362-ga-0ubuntu1~22.04-b09; > 15:35:00.226 INFO SplitNCigarReads - Start Date/Time: March 2, 2023; > 3",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452528344:224,install,installing,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452528344,1,['install'],['installing']
Deployability,"Thanks for the additional info! To clarify, though, was any validation done on the GVCF outputs themselves to check concordance vs. GATK3? If not, can I suggest that we do such a validation? Being able to say that we have 856 validated runs of the GATK4 HC on exome data would greatly bolster the case for including it in the new exome pipeline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-380785661:336,pipeline,pipeline,336,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-380785661,1,['pipeline'],['pipeline']
Deployability,"Thanks for the answer @SHuang-Broad. It would be nice if the bwa-mem C library have the option to pass streams instead of files for the index, allowing passing in-memory and file-based (in whatever file system abstraction) indexes. I will try to look at the code and see if I can submit a patch, but I need to refresh my C++ for that...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312583534:289,patch,patch,289,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312583534,1,['patch'],['patch']
Deployability,"Thanks for the clarification @jean-philippe-martin. . Based on JP's analysis @kcibul, it might help decrease the frequency of these errors to run `GenomicsDBImport` with a smaller `--batchSize` value, since that controls the number of simultaneous open GCS connections. This would come at a cost of greater fragmentation within `GenomicsDB` itself, however, which might force us to run with `--consolidate`. Before resorting to running with a smaller batch size, we should probably evaluate the combined effects of JP's recently merged https://github.com/broadinstitute/gatk/pull/2750 as well as his [jp_aggressive_reopen](https://github.com/jean-philippe-martin/gcloud-java/tree/jp_aggressive_reopen) branch in gcloud. We hope to move to a newer gcloud release or snapshot soon, but in a pinch we could provide you with a custom-built jar built on the unmerged gcloud branch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-304128622:754,release,release,754,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-304128622,1,['release'],['release']
Deployability,"Thanks for the files. We've identified the issue as a bug in htslib - pretty straightforward fix. The mixed ploidy is not a problem in this case. But the confluence of multiploidy, number of samples and number of alternate alleles causes some locations in the combined gvcf to have very large arrays of FORMAT data. That triggers an (unforeseen) overflow in htslib. . With Thanksgiving coming up, we won't be able to get the fix out in a released GenomicsDB this week. Can try for early next week, depending on when you're next doing a GATK release @droazen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-558813259:438,release,released,438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-558813259,2,['release'],"['release', 'released']"
Deployability,"Thanks for the ideas -- I found a few more details out this morning. I was trying to use a service account, rather than my personal account, using `gcloud auth activate-service-account`. This works for gcloud and gsutil commands, but doesn't seem to work with ADC very well evidently. Once I changed and used my personal account via `gcloud auth application-default login` GATK4 no longer gave that error. Then I found out that the file I gave you (which I picked because it's NA12878, but not where I originally found the problem) was not indexed. So I went back to using the original file which has `foo.vcf.gz` as well as `foo.vcf.gz.tbi`. GATK SelectVariants ran successfully. Finally, I spun up a GCE-vm which is running with the service account I want, installed Java and GATK4 and was able to run the command successfully. So it seems like the problem would be ""how do I run using a service account from a non-GCE VM"". If there's an answer to that, that would be great.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281694639:759,install,installed,759,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281694639,1,['install'],['installed']
Deployability,Thanks for the input @bhandsaker and @cwhelan. The calls were made with version `4.0.10.0`. I thought that was the latest - but it looks like we're a couple of minor versions behind. I'll retry making those calls with the latest version and see if it persists. Are the changes you're talking about in the latest release version or just on master?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5523#issuecomment-447374216:312,release,release,312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5523#issuecomment-447374216,1,['release'],['release']
Deployability,"Thanks for the question @droazen. No, these tools are more meant to be an update to VQSR, i.e., they do not assume that the BAM/reads will be available and only use the annotations. I think such tools will remain useful going forward, especially for joint genotyping. We can probably eventually push CNN/etc.-based generation of additional features/annotations from the BAM/reads upstream of filtering, so that they’re generated at the same time as our traditional “handcrafted” annotations, after which we can throw everything through the annotation-based filtering tools here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1074265783:74,update,update,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1074265783,1,['update'],['update']
Deployability,"Thanks for the quick review, @ldgauthier!. I don't think my fix will address any non-determinism in the integration tests. I'm inclined to just do better with the new tools---there does seem to be enough duct tape in the integration tests regarding re/setting the RNG so that the exact-match tests consistently pass. As for learning how to run the WARP tests, I think that would indeed be pretty useful---for anyone that might have to update code for VQSR or the new tools in the future! Can we teach everyone to fish? Isn't this what CARROT is for?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1061830649:104,integrat,integration,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1061830649,6,"['integrat', 'update']","['integration', 'update']"
Deployability,Thanks for the reminder. We can go ahead and merge if you want to approve. I’ll probably revisit this once I get around to the pymc3 update.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6935#issuecomment-733248367:133,update,update,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6935#issuecomment-733248367,1,['update'],['update']
Deployability,"Thanks for the review @davidbenjamin. I just read the release notes for v4.0.1.0 and saw that there is a fix to allow `.list` extensions in addition to `.arg` extensions, so I added this to CreateSomaticPanelOfNormals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4310#issuecomment-361987314:54,release,release,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4310#issuecomment-361987314,1,['release'],['release']
Deployability,Thanks for the review @lbergelson. I've addressed all your comments. (Note the tests will still fail until there's a new Hadoop-BAM release.),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3369#issuecomment-322515672:132,release,release,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3369#issuecomment-322515672,1,['release'],['release']
Deployability,"Thanks for the review and running those tests, @ldgauthier! Will restore the aforementioned GnarlyGenotyperIntegrationTests and update a few other exact matches in the rebase this afternoon. You also asked above if there was a theoretical reason to change the threshold. Since it seems the original was relatively arbitrary (at least from what I've been told, happy to be corrected), I think we can leave it. The new annotation is strictly larger, so we will then be slightly more conservative about keeping sites if we leave the threshold fixed. You can think of this as a slight change in the decision boundary in genotype-count space---perhaps I can add some plots to this thread this afternoon to demonstrate. In practice, what we care about is whether: 1) many sites flicker across the change in boundary after hard filtering, and/or 2) these sites result in discrepancies post-VQSR. I think the tests you ran suggest that we don't need to worry much about the second issue, and I can take a closer look later to check about the first (which will depend simply on the number of samples and the allele frequency spectrum). We can also take a basic look at how things might change with e.g. more samples using the aforementioned plots.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-914471272:128,update,update,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-914471272,2,['update'],['update']
Deployability,"Thanks for the review! @meganshand I adressed your comments. I saw that the patch for ADAM was accepted, @lbergelson, so I don't know if they will release soon a minor version for the bug fix. What should I do, @droazen?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2247#issuecomment-257965130:76,patch,patch,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2247#issuecomment-257965130,2,"['patch', 'release']","['patch', 'release']"
Deployability,"Thanks for the review, @fleharty!. Thanks for highlighting the AVX business, which I didn't consider carefully. This was just copied from the other HC integration tests, and was in turn copied to the M2 tests---but I now realize that the style of the M2 tests is a little different in that an implementation isn't specified. But I think in both cases, we'll try to call an AVX implementation (since the M2 tests will default to `FASTEST_AVAILABLE`) and that Travis should be OK with it, at least?. @droazen can correct me if I'm wrong and let me know if he'd like further review on this branch. Otherwise I'll try to address comments and get this in before I head out on vacation next week.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-906679400:151,integrat,integration,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-906679400,1,['integrat'],['integration']
Deployability,"Thanks for the suggestions! The SV jobs are all running fine with no hanging after increasing the memory. The commandline below completed on 100 30x crams without any issues. . ```; gatk --java-options ""-Djava.io.tmpdir=tmp"" StructuralVariationDiscoveryPipelineSpark \; -R $REF \; --aligner-index-image GRCh38_full_analysis_set_plus_decoy_hla.fa.img \; --kmers-to-ignore GRCh38_ignored_kmers.txt \; --contig-sam-file hdfs:///user/farrell/adni/sv/$SAMPLE.contig-sam-file\; -I $CRAM_DIR/$SAMPLE.cram \; -O hdfs:///user/farrell/$CENTER/sv/$SAMPLE.sv.vcf \; -- \; --spark-runner SPARK --spark-master yarn --deploy-mode cluster \; --executor-memory 60G\; --driver-memory 40g\; --num-executors 12\; --executor-cores 4\; --files $REF.img,GRCh38_ignored_kmers.txt \; --name ""$SAMPLE"" --conf spark.yarn.submit.waitAppCompletion=false\; --conf spark.yarn.executor.memoryOverhead=5000 \; --conf spark.network.timeout=600 \; --conf spark.executor.heartbeatInterval=120. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4635#issuecomment-381441151:603,deploy,deploy-mode,603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4635#issuecomment-381441151,1,['deploy'],['deploy-mode']
Deployability,Thanks for the test data @vladsaveliev ! I already had a fix for this in a branch. We can probably get it merged in time for the up coming release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7483#issuecomment-946045992:139,release,release,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7483#issuecomment-946045992,1,['release'],['release']
Deployability,"Thanks for the thoughts. Singularity is definitely awesome and I'm hoping to support it as an alternative choice to Docker for local HPC clusters where we won't require equivalent root permissions to run. So it helps avoid some of the potential external permission errors by creating a potentially cleaner path to running. Unfortunately it doesn't deal with the underlying issue of needing to map users inside of the containers so that Spark is happy with them. Having something more lightweight than needing user updates in the internal `/etc/passwd` would also help with potential issues on other container enginer (Singularity, rkt).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4626#issuecomment-381642529:514,update,updates,514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4626#issuecomment-381642529,1,['update'],['updates']
Deployability,"Thanks for the update @cwhelan and thanks for prepping the initial documentation. If you are considering any `(How to) tutorials`, then perhaps you might find of interest some factors I've outlined in <https://github.com/broadinstitute/gatk/issues/3774> (for John). @mwalker174, I'm sorry to have overlooked Path-Seq. Geraldine mentioned she is working on some docs for you. Will your workflow be ready by January 9?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3769#issuecomment-341551936:15,update,update,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769#issuecomment-341551936,1,['update'],['update']
Deployability,Thanks for the update @jean-philippe-martin !,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-498378582:15,update,update,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-498378582,1,['update'],['update']
Deployability,Thanks for the update @mlathara. I have not seen a response yet from the second user so it looks like user error.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793#issuecomment-690774661:15,update,update,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793#issuecomment-690774661,1,['update'],['update']
Deployability,"Thanks for the update, @cmnbroad. I think that at least til that is solved, we could add a temporary solution to be able to use a consistent way of dealing with `File` and `java.nio.Path` user exceptions... What if I submit a PR to change all ctors to accept `java.nio.Path` instead of `File` in file-related `UserException`s? The `File.toPath()` will always work, but the `Path.toFile()` doesn't. I found problems with respect to HDFS paths when throwing exceptions, and this will allow to use them with `File` and `Path`...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-300407681:15,update,update,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-300407681,1,['update'],['update']
Deployability,"Thanks for the update, @droazen!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2371#issuecomment-287454577:15,update,update,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2371#issuecomment-287454577,1,['update'],['update']
Deployability,"Thanks for the update, @erniebrau - I would answer every question as soon as I read it. Thank you for doing this!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-329198004:15,update,update,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-329198004,1,['update'],['update']
Deployability,"Thanks for the updates @fdchevalier. I see exactly what the issue is now; the presence of the .tbi file causes the code to go down a different path (through TabixFeatureReader), which in turn manifests the issue because it doesn't handle the spaces in the paths correctly. I'll create a ticket in htsjdk, where the bug is.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-651372730:15,update,updates,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-651372730,1,['update'],['updates']
Deployability,"Thanks for these suggestions, @sooheelee. Note that there's already an issue filed to add `@PG` tags at https://github.com/broadinstitute/gatk/issues/4117. As for the `@RG` tag, I was following the example of the SV team, which I saw introduced a custom RG ID (although this may only be used for tagging intermediate files---not sure?) Although not ideal, I think passing the sequence dictionary and sample name in this way allows us to reuse the relevant SAM header code and also prevents the possibility of users mixing up samples. (Recall that the old pipeline required the sample name to be passed in as a separate input to each tool and that no validation that each input came from the same sample was performed.). As for VCF output, we are also planning to add this to the ModelSegments pipeline (it is already in the gCNV pipeline). See https://github.com/broadinstitute/gatk/issues/4114. However, I think it makes sense for this to wait until the improved caller is in. I'll close this as a dupe for now, but we'll be able to reference your comments here from those issues in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4481#issuecomment-369986160:555,pipeline,pipeline,555,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4481#issuecomment-369986160,3,['pipeline'],['pipeline']
Deployability,Thanks for using our pipeline and reporting the issue @jjfarrell !,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458#issuecomment-370896619:21,pipeline,pipeline,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458#issuecomment-370896619,1,['pipeline'],['pipeline']
Deployability,"Thanks for your answer @davidbenjamin. I still think that a javadoc update may be useful. If GATK is used as a framework and the user does not know that they should fill in all the likelihoods for all the alleles and reads, even without knowing about `PerReadAlleleLikelihoodMap`, this may drive to errors in the code that may be solved with a implementation note in the documentation. Thanks a lot again for the information, it was very useful!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2311#issuecomment-272486775:68,update,update,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2311#issuecomment-272486775,1,['update'],['update']
Deployability,Thanks for your comments! I updated the code.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-333636280:28,update,updated,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-333636280,1,['update'],['updated']
Deployability,"Thanks for your feedback, @cmnbroad. In my case, I think that `IntegrationTestSpec` is a good way of avoid complicated code to test tool results, but it is true that it have some problems (one that I had was the usage for testing programs where the outputs are determined by a prefix in the command line, but with different suffixes). I think, from the API user point of view, that a class like `IntegrationTestSpec` to facilitate program output testing (including user exceptions) will be nice for developing purposes. Nevertheless, this is just a convenience that I asked for here, but I can try to solve the issues with the `BaseTest` instead. By the way, I would love to have this interface in GATK at least for now, because several of my tools rely on the `IntegrationTestSpecs` for development...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-243124889:63,Integrat,IntegrationTestSpec,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-243124889,3,['Integrat'],"['IntegrationTestSpec', 'IntegrationTestSpecs']"
Deployability,"Thanks for your feedback, @droazen. I think that it will be nice to have a better annotator engine for handling what should be on/off in which cases instead of hardcoded them when it is necessary. But I can wait til the release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2534#issuecomment-290677995:220,release,release,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2534#issuecomment-290677995,2,['release'],['release']
Deployability,"Thanks for your question, @xysj1989. You are right that it can be advantageous to use SNP data for CNV calling. In my experience, however, it is not of high importance in practice. Indeed we do use BAF in our structural variation pipeline, but only for the purpose identifying high-quality calls. We typically find that BAF support tends to be weak/noisy for all but the largest CNVs, so requiring SNP evidence would greatly reduce sensitivity. @samuelklee can probably shed some more light on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6407#issuecomment-581659408:230,pipeline,pipeline,230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6407#issuecomment-581659408,1,['pipeline'],['pipeline']
Deployability,Thanks for your suggestion @mwalker174. I'd definitely like to do this soon so I'll implement that suggestion and update this thread with any questions.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6655#issuecomment-644304685:114,update,update,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6655#issuecomment-644304685,1,['update'],['update']
Deployability,"Thanks for your time Chris. ; So, build/doc/gatkDoc had a .css file. Also there was a build/tmp/gatkDoc folder with a javadoc.options file. . I then installed the jdk version 8 (I had version 11) and tried running gradlew again. ; This time it worked !!. I guess it is a version issue? I wish I had a better perspective but I am not a JAVA person.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-594221644:149,install,installed,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-594221644,1,['install'],['installed']
Deployability,"Thanks for your work on this @samuelklee! Testing on both wes and wgs would be ideal. For wgs we can use the gatk-sv reference panel, which is our standard (I can help with this once a docker is ready). For wes, 1kgp would work although it's definitely showing its age. Are the integration test differences large?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1804698174:278,integrat,integration,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1804698174,1,['integrat'],['integration']
Deployability,"Thanks much for this. Unfortunately running as root isn't an option since external CWL runners (like bunny, Toil, cwltool and hopefully Cromwell soon) make the decisions about the username to use and will try to mirror the runner with the external user to match user permissions on the output files. Also people trust it more when you're not trying to run as root (hence, not wanting to mess with `/etc/passwd` in the Docker container for fix Spark as well). This was using the bcbio-vc Docker image (https://github.com/bcbio/bcbio_docker#docker-images) with gatk installed via bioconda, but I don't think is image specific unless you're specifically doing something in your images to work around the problem which is doesn't sound like. Is there any chance to tweak Spark to make it less picky/dependent on the user? I'm not enough of a Spark expert to know if this is work-aroundable in a reasonable way?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4626#issuecomment-378718128:564,install,installed,564,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4626#issuecomment-378718128,1,['install'],['installed']
Deployability,Thanks! ; Do you know when an updated docker image with this fix will become available? ; Is there an easy way to get that?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1064280760:30,update,updated,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1064280760,1,['update'],['updated']
Deployability,"Thanks! Just to be clear, the PR is incomplete. We need to determine the additional dependencies (which were previously installed along with R) required for AVX, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-413599300:120,install,installed,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-413599300,2,['install'],['installed']
Deployability,"Thanks!. GATK has been there fore more than 1 decade, I guess. I really hope that now it is easy to run. Can you please let me know how to install through conda then? . BTW, the current version 4.5.0 does not require users to separate SNP from INDEL when calling variants, correct?. Best regards,; Jie",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-2210256469:139,install,install,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-2210256469,1,['install'],['install']
Deployability,"Thanks, @LeeTL1220! @droazen please include in the next release notes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5976#issuecomment-497827240:56,release,release,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5976#issuecomment-497827240,1,['release'],['release']
Deployability,"Thanks, @LeeTL1220! Made some minor updates, will merge when tests pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3820#issuecomment-347597529:36,update,updates,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820#issuecomment-347597529,1,['update'],['updates']
Deployability,"Thanks, @cmnbroad!. - You're right about gatkbase-2.1.0, that image is coming from #5026, which needs some more work. We can delete it for the time being if you think it'll cause confusion.; - Correct, I think the import statement for `reshape` in BQSR.R was always incorrect/extraneous. `reshape2` is the correct dependency for `ggplot2` (which is itself imported), and `reshape` is not explicitly used in BQSR.R. So to recap: I removed the installation of this unnecessary package, but failed to remove an unnecessary import statement since it was in an untested code path, which was then caught when users tried to run the tool. Investigation of this issue then revealed that `ggplot2` was not installed correctly in the current base image, due to a completely unrelated dependency issue.; - Good call on clearing the Travis cache. Not actually sure how to do that, do I just delete the cache at https://travis-ci.org/broadinstitute/gatk/caches for this particular branch?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-408447924:442,install,installation,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-408447924,4,['install'],"['installation', 'installed']"
Deployability,"Thanks, @droazen! @asmirnov239 has been looking at PyMC3 updates for gCNV, which will help unlock the conda environment. I understand he has a working branch, but needs to do more testing—perhaps he can comment further?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1228848779:57,update,updates,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1228848779,1,['update'],['updates']
Deployability,"Thanks, @gokalpcelik! That's unfortunate that the packages are no longer accessible. However, this old version of the environment was also somewhat problematic in that it included build strings, installed many packages using pip instead of conda, and was otherwise overly restrictive, see e.g. https://gatk.broadinstitute.org/hc/en-us/community/posts/360061666671-Broken-conda-env-create-n-gatk-f-gatkcondaenv-yml. I would suggest, in the following order:. 1) Users upgrade to more recent versions of GATK; 2) Users use the 4.1.0.0 Docker; 3) Users edit the 4.1.0.0 environment to be less restrictive. For example, using Ubuntu 20.04.2 + conda 23.10.0, I was able to build something that is probably sufficiently close to the 4.1.0.0 conda environment by making the following changes:. ``` <- certifi=2016.2.28=py36_0; < - openssl=1.0.2l=0; < - pip=9.0.1=py36_1; < - python=3.6.2=0; < - readline=6.2=2; < - setuptools=36.4.0=py36_1; < - sqlite=3.13.0=0; < - tk=8.5.18=0; < - wheel=0.29.0=py36_0; < - xz=5.2.3=0; < - zlib=1.2.11=0; ---; > - openssl=1.0.2l; > - pip=9.0.1; > - python=3.6.2; > - setuptools=36.5.0; > - wheel=0.29.0; > - xz=5.2.3; > - zlib=1.2.11 ; ```. There is some clobbering that happens with the pip installs, but nothing major. Note that I cannot guarantee that this environment exactly reproduces results generated with the Docker (and it's possible that there might be a more minimal fix), but it's perhaps a starting point for those users that cannot go with the other (highly preferred) options.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8504#issuecomment-1852138745:195,install,installed,195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8504#issuecomment-1852138745,3,"['install', 'upgrade']","['installed', 'installs', 'upgrade']"
Deployability,"Thanks, @lbergelson. I was also thinkinhg that this code is mostly deprecated, but I wanted to ported as is for the first pass review. I just need to support the new mpileup version (unique sample, because if not it is more difficult), because the consensus one is deprecated. I will update the codec and add some tests for it. In addition, ~~I was thinking to create a list of `PileupElement` inside the feature to make easier to compare the internal pileup, but with ""reads"" of one base-pair.~~ Update to this: `PileupElement`is difficult to generate without including `GATKRead` simple implementation, and I think that it is not worthy. On the other hand, I will improve the walker itself. I will tell you when I finished with the changes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-224419331:284,update,update,284,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-224419331,1,['update'],['update']
Deployability,"Thanks, @samuelklee I'd try out the nightly builds. I have got another question about running multiple shards in parallel by submitting multiple slurm jobs each running GermlineCNVCaller with one shard. That seems to trigger this (`INFO (theano.gof.compilelock`). . `; INFO (theano.gof.compilelock): Waiting for existing lock by process '62379' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3632551' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '62379' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.18-el8_4.x86_64-x86_64-with-debian-buster-sid-x86_64-3.6.10-64/lock_dir; INFO (theano.gof.compilelock): Waiting for existing lock by process '3633423' (I am process '61988'); INFO (theano.gof.compilelock): To manually release the lock, delete /mnt/beegfs/mccarthy/scratch/general/rlyu/Projects/Snakemake_projects/yeln_2019_spermtyping/.theano/compiledir_Linux-4.1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7411#issuecomment-905060709:412,release,release,412,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7411#issuecomment-905060709,2,['release'],['release']
Deployability,"Thanks, I come here from this thread. ; It seems like I have to downgrade the pipeline to the older version with CombineGVCFs step, GenomicDBImport just can't do this stuff now :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7667#issuecomment-1260955047:78,pipeline,pipeline,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7667#issuecomment-1260955047,1,['pipeline'],['pipeline']
Deployability,"Thanks, Mark. Yes, intentional. We moved a couple of methods that we more naturally methods on the assembled objects rather than statics in client code at Chris' suggestion. Part of the API upgrade, from my point of view.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4622#issuecomment-378226435:190,upgrade,upgrade,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4622#issuecomment-378226435,1,['upgrade'],['upgrade']
Deployability,"Thanks. To those questions:. 1) Yes, we updated after import. FWIW, when we do this, we always copy the original workspace to a working location and execute the update on this copy. 2) I'm sure we would. Is there something specific we should look for?. 3) We dont generally have this level of detail on it would be pretty difficult to get that unless I'm asking for something fairly specific from the cluster admins. 4) regarding your samples.txt file: this appears to be the number 0-1116? We do expect 1117 total samples. I'm not sure if you were expecting this to have the proper samples names, but the total count is what I expect.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-718976015:40,update,updated,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-718976015,2,['update'],"['update', 'updated']"
Deployability,That PR is in so we're good. I see there were [four alpha releases](https://mvnrepository.com/artifact/com.google.cloud/google-cloud) in February so the code may be soon available officially.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2441#issuecomment-285814522:58,release,releases,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2441#issuecomment-285814522,1,['release'],['releases']
Deployability,"That is a separate matter altogether from both 1) unifying the allele-count collection tools, and 2) standardizing the format of tabular data. The most appropriate place for integration of Mutect2 SNV calls would be as input to the tumor-heterogeneity tool (along with the ModelSegments output) further downstream. This is because it is unlikely that including the SNVs as input to ModelSegments would significantly improve either segmentation or modeling there. If the allele-count collection tools are unified, I think that the only redundant work done across both pipelines would be the calling of hets from the pileups, which is extremely cheap. However, we should certainly also unify the code to do this (which I've spoken to @davidbenjamin about as well).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386734926:174,integrat,integration,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386734926,2,"['integrat', 'pipeline']","['integration', 'pipelines']"
Deployability,"That is correct. N's only (on the main contigs, not including Y and MT). We looked into the slow regions and didn't find anything worth doing. On Wed, Apr 26, 2017 at 9:46 PM, Eric Banks <notifications@github.com>; wrote:. > I'm pretty sure that we don't exclude any regions in the hg38 pipeline; > right now.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/2591#issuecomment-297588284>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0hyn3fdw-iQ2Ea1260I2GrdxjjkEks5rz_NcgaJpZM4M5EDY>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2591#issuecomment-297592544:287,pipeline,pipeline,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2591#issuecomment-297592544,1,['pipeline'],['pipeline']
Deployability,That is true! Should I update the title of the issue to reflect this?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8768#issuecomment-2045034104:23,update,update,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8768#issuecomment-2045034104,1,['update'],['update']
Deployability,"That sounds prudent. The new version of the GermlineCNVCaller workflow will be available at release; I think you'll find the workflow itself to be quite streamlined and hopefully easy to use. However, because the model is relatively sophisticated, there are some parameters and model priors that may need to be set appropriately to generate optimal results. We plan on spending some time shortly after release doing internal evaluations to determine some best-practices guidelines for data generated at the Broad.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3996#issuecomment-352850485:92,release,release,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3996#issuecomment-352850485,4,['release'],['release']
Deployability,"That would be really bad. Are you sure?. On Fri, May 25, 2018, 08:30 sooheelee <notifications@github.com> wrote:. > FYI, next release of Cromwell is supposed to automatically interpret File; > types as Sting when given a gs:// bucket file.; >; > Sent from an iPhone and typed with my thumbs.; >; > > On May 24, 2018, at 3:48 PM, samuelklee <notifications@github.com>; > wrote:; > >; > > @LeeTL1220 Actually, since the coverage collection itself is comparable; > to the time it takes to localize the BAM, this probably also helps even; > when you're not just running on snippets.; > >; > > Building a PoN on chr20-22 took ~2.5 hours without NIO (3/50 BAMs were; > preempted, some more than once), but it only took ~40 minutes with an NIO; > WDL I quickly whipped up (and 1/4 of that was because I was unlucky enough; > to get preempted on one BAM after 10 minutes)!; > >; > > —; > > You are receiving this because you are subscribed to this thread.; > > Reply to this email directly, view it on GitHub, or mute the thread.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4806#issuecomment-392042783>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk5K6EpZQft219BT7K8DoONgZqx2hks5t1_lQgaJpZM4UMBDI>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-392044533:126,release,release,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-392044533,1,['release'],['release']
Deployability,"That's a good point--the documentation should be updated. I think it's safe to do so here before I updated actual workspace itself, although technically it has the potential to create a small window in which the documentation talks about features that are not there. I'll update the ticket in Jira to explicitly mention updating the documentation as well, as it should be among the AC.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8010#issuecomment-1238401881:49,update,updated,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8010#issuecomment-1238401881,3,['update'],"['update', 'updated']"
Deployability,That's great! Thank you so much. Do you know when the next release will be released?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8097#issuecomment-1423164501:59,release,release,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8097#issuecomment-1423164501,2,['release'],"['release', 'released']"
Deployability,"Thats a good idea. I don't know what our release plan is. I think we might; do one more minor release on java 8 for someone internal and then give a; bit of time before a java 17 release to let things shake out a bit. There; are a bunch of things we punted until it was merged that we want to get; done related to the update. I will put out a snapshot tonight or tomorrow; for you to test against. I wouldn't anticipate many major problems; updating although there might be some wrangling module exports which is; awfully confusing. The bulk of our issues had to do with fixing the; documentation generation and dealing with spark both of which hopefully; will just work for you. On Thu, Mar 2, 2023, 3:56 PM bbimber ***@***.***> wrote:. > @lbergelson <https://github.com/lbergelson> or @cmnbroad; > <https://github.com/cmnbroad>: would you mind kicking off a build on; > this, so I can see how DISCVR-seq builds against it? Are you planning a; > GATK release any time soon?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1452531115>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABD3RLCRVXIM5Y3O2RC6IKTW2ECP3ANCNFSM6AAAAAAQV3ZLXM>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1452540395:41,release,release,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1452540395,5,"['release', 'update']","['release', 'update']"
Deployability,"The -contamination argument was not hooked up properly in the HaplotypeCaller.; This patch fixes the tool argument, and adds tests on artificially contaminated; data to demonstrate that the feature works as intended. Resolves #4312",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4455:85,patch,patch,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4455,1,['patch'],['patch']
Deployability,"The 1.7 release of the data sources has a lifted over hg19 version of Gencode. In this version contrary to other releases, the individual elements of each transcript seem to be represented in numerical order, rather than the order in which they appear in the transcript at transcription time. For `+` strand transcripts, this doesn't matter, but for `-` strand transcripts, the ordering of the exons/CDS regions in the gencode gtf file is reversed to what is expected. The result is that the coding sequence, protein prediction, and other annotations are incorrect. One user has already run into this issue: https://gatk.broadinstitute.org/hc/en-us/community/posts/360076207992--Repost-Wrong-annotation-with-Funcotator-1-7. One of two fixes is required:. 1. Update the code to always sort the transcript elements by how they appear in the transcribed sequence; 2. When generating the Gencode data, always sort the transcript elements by their transcribed order. We should do both and later roll back the sorting to optimize for speed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7051:8,release,release,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7051,3,"['Update', 'release']","['Update', 'release', 'releases']"
Deployability,"The BCFCodec in the next release of htsjdk (after 2.19) will reject any BCF input that is greater than BCF 2.1 (see https://github.com/broadinstitute/gatk/issues/5838 and https://github.com/samtools/htsjdk/issues/1323). However, GenomicsDB uses htslib, which generates version 2.2 output, to create BCF streams for GATK (with the BCF IDX fields removed). This will no longer work with post-2.19 htsjdk versions. Since GATK bypasses codec discovery and provides the codec directly for GenomicsDB inputs, the proposed solution is to change to the BCF codec in htsjdk to delegate version checking to an overridable method(!), and then provide a subclassed codec in GATK that has relaxed version checking.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5839:25,release,release,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5839,1,['release'],['release']
Deployability,"The BigQuery library upgrade for extract, broke ingest :/ This fixes that. It also rethrows an exception we were eating that I noticed. The error seen during ingest was. ```; java.lang.IllegalArgumentException: JSONObject does not have a bytes field at root.sample_id.; 	at com.google.cloud.bigquery.storage.v1beta2.JsonToProtoMessage.fillField(JsonToProtoMessage.java:306); 	at com.google.cloud.bigquery.storage.v1beta2.JsonToProtoMessage.convertJsonToProtoMessageImpl(JsonToProtoMessage.java:138); 	at com.google.cloud.bigquery.storage.v1beta2.JsonToProtoMessage.convertJsonToProtoMessage(JsonToProtoMessage.java:86); 	at com.google.cloud.bigquery.storage.v1beta2.JsonStreamWriter.append(JsonStreamWriter.java:110); 	at com.google.cloud.bigquery.storage.v1beta2.JsonStreamWriter.append(JsonStreamWriter.java:90); 	at org.broadinstitute.hellbender.tools.gvs.ingest.CreateVariantIngestFiles.writeLoadStatus(CreateVariantIngestFiles.java:202); 	at org.broadinstitute.hellbender.tools.gvs.ingest.CreateVariantIngestFiles.onTraversalSuccess(CreateVariantIngestFiles.java:369); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1062); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7620:21,upgrade,upgrade,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7620,1,['upgrade'],['upgrade']
Deployability,"The CNV WDLs don't use the standard gatk launcher script, which results in important system properties not being set. Assigning to @samuelklee and @LeeTL1220 to fix in time for the 4.0 release. Note that `gatk-launch` is being renamed to `gatk` in https://github.com/broadinstitute/gatk/pull/3961, so you'll want to wait until that PR is merged (should be merged today).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3968:185,release,release,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3968,1,['release'],['release']
Deployability,"The Docker tests will fail in the dev branch unless the image is updated, which I'd rather do off of master. Since you agree that this is trivial, I'm going to go ahead and merge!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3693#issuecomment-336854819:65,update,updated,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3693#issuecomment-336854819,1,['update'],['updated']
Deployability,The Engine Team discussed this internally and we're going to pull out a subset of all the configuration options into the config file. These options should be those that will change only infrequently (like the data sources directory).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4960#issuecomment-461937685:90,configurat,configuration,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4960#issuecomment-461937685,1,['configurat'],['configuration']
Deployability,The Funcotator WDL needs to be integrated into the WDL for M2 and plugged into the automated testing.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4088:31,integrat,integrated,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4088,1,['integrat'],['integrated']
Deployability,"The GATK VCF header issue causing the underlying problem was fixed in #3351, so a new release of GATK4 should work correctly and avoid losing variants during GenomicsDB import/output for joint calling. I agree with Louis that failing with an error would be better than the current silent failures in case of any future issues. Thank you all again for the help debugging this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-325024708:86,release,release,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-325024708,1,['release'],['release']
Deployability,"The GATK docker image is on samtools 1.7, which is ancient and has several known issues that users have run into (especially with CRAM files). We shoud update to a modern version.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8460:152,update,update,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8460,1,['update'],['update']
Deployability,"The GATK docker image uses samtools version 0.1.19 instead of the current version 1.9 and can therefore not read `gs://` resources. Samtools is installed in the gatkbase image via apt-get, the recent releases are not available there. Instead, it would have to be built manually (see http://www.htslib.org/download/).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6148:144,install,installed,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6148,2,"['install', 'release']","['installed', 'releases']"
Deployability,"The GCS ReadUtils tests are failing intermittently on the Barclay upgrade branch, probably due to filename collision when tests are running in parallel on Travis because the tests don't use unique temporary filenames.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3810:66,upgrade,upgrade,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3810,1,['upgrade'],['upgrade']
Deployability,"The Genome Analysis Toolkit (GATK) v4.5.0.0; ## Description; Hi,; Here is my situation, I'm testing the feasibility of incremental GenomicsDB，I have total 400 samples to joint calling, I have no problem directly using `GenomicsDBImport `and `GenotypeGVCFs `for joint calling of all 400 samples. The configuration used is 4c32g for `GenomicsDBImport `and 2c16g for `GenotypeGVCFs`. But when I first built a GenomicsDB of 200 samples using `GenomicsDBImport `successfully, and then use GenomicsDB `--genomicsdb-update-workspace-path` increment 200 samples into the GenomicsDB , use this incremental imported GenomicsDB to `GenotypeGVCFs`. The error happend and report GENOMICSDB_TIMER,Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; Here are my code; ```; gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenomicsDBImport \; --tmp-dir $PWD \; --genomicsdb-workspace-path ~{workspace_dir_name}~{prefix}.~{index} \; --batch-size 50 \; -L ~{intervals} \; --reader-threads 5 \; --merge-input-intervals \; --consolidate \; -V ~{sep = "" -V "" single_sample_gvcfs}. gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenomicsDBImport \; --tmp-dir $PWD \; --genomicsdb-update-workspace-path ~{workspace_dir_name} \; --batch-size 50 \; --reader-threads 5 \; --merge-input-intervals \; --consolidate \; -V ~{sep = "" -V "" single_sample_gvcfs}. gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenotypeGVCFs \; --tmp-dir $PWD \; -R ~{ref} \; -O ~{workspace_dir_name}.vcf.gz \; -G StandardAnnotation \; --only-output-calls-starting-in-intervals \; -V gendb://~{workspace_dir_name} \; -L ~{intervals} \; --merge-input-intervals \; -all-sites; ```; And I found that before report error the number of threads used by GATK increased, but the memory usage did not exceed the maximum limit of the server.; I also cheched `--max-alternate-alleles` and `--genomicsdb-max-alternate-alleles` to a smaller size but still the same error. I would appreciate some insights in why that is. Thanks,; Yang",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8777:1298,update,update-workspace-path,1298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8777,1,['update'],['update-workspace-path']
Deployability,"The Google Cloud web UI allows you to create ""directories"". When you press that button, it creates a file with a trailing slash, and the web UI interprets it as a directory even though it's a file. This causes no end of trouble because now every other program in the world that accesses cloud storage must be updated to adopt this ""convention"" or they'll see files where the user doesn't expect them. My guess would be that's what's going on here. That said, NIO *should* understand what these things are and ignore them. The [current workaround](https://github.com/googleapis/google-cloud-java/pull/4304) is to consider 0-byte files as potentially being fake directories. @cwhelan I cannot access the file `gs://broad-dsde-methods-shuang/pb/bams/NA12892/` but if you can, could you please check its size for me? I mean the file specifically. If it's nonzero that would explain the problem. If it's zero or nonexistent then we'll need to dig some more to understand what's going on.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-492450635:309,update,updated,309,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-492450635,1,['update'],['updated']
Deployability,"The Intel-optimized version of TensorFlow 1.9 is now the default for Anaconda users. It now supports all processors with AVX - so everything since Sandy Bridge, which was released in 2011. With that in mind, I was thinking we could dispense with two different conda environments and fold everything into the ```gatk``` environment. @samuelklee , I'm the new guy on the Intel team you've been dealing with.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5142:171,release,released,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5142,1,['release'],['released']
Deployability,The Java 17 branch includes an upgrade to gradle 7.5.1.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7984#issuecomment-1251456845:31,upgrade,upgrade,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7984#issuecomment-1251456845,1,['upgrade'],['upgrade']
Deployability,"The M2 WDLs don't use the standard gatk launcher script, which results in important system properties not being set. Assigning to @davidbenjamin and @LeeTL1220 to fix in time for the 4.0 release. Note that `gatk-launch` is being renamed to `gatk` in https://github.com/broadinstitute/gatk/pull/3961, so you'll want to wait until that PR is merged (should be merged today).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3967:187,release,release,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3967,1,['release'],['release']
Deployability,The README suggests that. >You can use test.single when you just want to run a specific test class:; >`./gradlew test -Dtest.single=SomeSpecificTestClass`. But when I run `./gradlew test -Dtest.single=HaplotypeCallerIntegrationTest` or `./gradlew test -Dtest.single=org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerIntegrationTest` gradle runs the entire integration test suite. Running `./gradlew test --tests *HaplotypeCallerIntegrationTest` does produce the desired result of running just `HaplotypeCallerIntegrationTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6853:381,integrat,integration,381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6853,1,['integrat'],['integration']
Deployability,"The SAMRecord class currently allows the header to be set to null (either at construction time or via `setHeader()`), but may blow up or allow itself to enter an inconsistent state when it lacks a header (eg., the reference name and reference index can get out of sync). We should patch this class (and subclasses such as `BAMRecord`) in https://github.com/samtools/htsjdk/ to behave sensibly in all cases when a header is not present (eg., use a special missing value for reference index when the reference index cannot be looked up), and add unit tests to prove that headerless `SAMRecords` function correctly. This is important for dataflow and spark, where we want to serialize `SAMRecords` without paying the cost of serializing a header for each record.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/903:281,patch,patch,281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/903,1,['patch'],['patch']
Deployability,The SV discovery pipeline threw a bunch of errors seemingly related to this:; https://issues.apache.org/jira/browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.conc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:17,pipeline,pipeline,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491,1,['pipeline'],['pipeline']
Deployability,"The SVConcordance tool is currently too inefficient in terms of memory usage, requiring several 100's of GB of heap space on ~100K samples. This PR aims to reduce memory usage in two ways:. 1. Truth VCF records are stripped of all genotype fields except `GT` and `CN`, which are necessary and sufficient for concordance computations.; 2. A new option `--do-not-sort` is introduced to skip output record sorting. A major source of heap usage is the output buffer in the `ClosestSVFinder` class, which ensures records are emitted in coordinate-sorted order. This buffer quickly fills, however, when there is at least one record being actively clustered that spans a large interval because the buffer cannot be flushed until a variant beyond the maximal clusterable coordinate of that large variant is encountered. This option will allow users to substantially reduce max heap usage on larger call sets (a single SVRecord can consume ~100MB with 100K samples). Includes an integration test to cover the `--do-not-sort` functionality.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8623:970,integrat,integration,970,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8623,1,['integrat'],['integration']
Deployability,The SplitReads integration tests will fail once we upgrade htsjdk without this.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1241:15,integrat,integration,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1241,2,"['integrat', 'upgrade']","['integration', 'upgrade']"
Deployability,"The VAT pipeline creates 3 tables, 2 are intermediary tables used to create the third. I was tired of deleting them, so I made them temp tables. <img width=""565"" alt=""Screen Shot 2021-09-16 at 10 44 09 AM"" src=""https://user-images.githubusercontent.com/6863459/133633262-a41466a9-2cae-4b69-8c61-28e81d1a8706.png"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7455:8,pipeline,pipeline,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7455,1,['pipeline'],['pipeline']
Deployability,The WDL needs to be updated in general to be correct and include all the hooks for the latest Funcotator info.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5253#issuecomment-466518667:20,update,updated,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5253#issuecomment-466518667,1,['update'],['updated']
Deployability,"The `./gradlew clean install printVersion` command I mentioned publishes it to the local maven repo. Then you need to reference that version from your own build.gradle. Also beware when doing this iteratively that the local snapshot version # is based on the current head commit hash. In my experience, once gatk is published to local maven under a given version, if you want to make a change, you'll need to make a commit to force the version number to update, and then rerun the command above, and update your VariantQC to the new version. Otherwise the local repo won't be updated since it will appear up to date. Hope that makes sense.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759638068:21,install,install,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759638068,4,"['install', 'update']","['install', 'update', 'updated']"
Deployability,"The `PS` tag should be type `Integer`, not `String` according to the spec, but no error is reported (for me). ```bash; bcftools view https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/HG001_GRCh38_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.gz chr1:4001310-4001310 > test.vcf; ```. Related: https://github.com/genome-in-a-bottle/giab_latest_release/issues/15",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6762:177,release,release,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6762,1,['release'],['release']
Deployability,"The `gatktool` Python code installs a system exception handler to catch unhandled Python exceptions, and sends a negative ack to the `StreamingProcessController` when it sees one. The controller then grabs the stdout/stderr contents; writes it to the log/journal file; and throws a java exception. However, there is a shutdown race condition where occasionally the GATK process will get the negative ack and terminate before the Python exception chain is finished processing, and the exception message never appears in the journal. We've seen this happen when the CNN Python inference code runs out of memory. It would be better to have the exception handler write the exception string directly to the ack FIFO, with a message length included, so the controller can deterministically retrieve the message for inclusion in the java exception without having to rely on std in/out.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5100:27,install,installs,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5100,1,['install'],['installs']
Deployability,The acceptance criteria are to replicate the gatk3 functionality and tests. depends on #293 . there's code for some of it at googlegenomics/genomics-pipeline. @jean-philippe-martin can you describe the status of that code?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/424:149,pipeline,pipeline,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/424,1,['pipeline'],['pipeline']
Deployability,The actual code for the funcotation factories is all set up for this. The required update is that `GencodeFuncotationFactory` needs to be refactored to take in the name of the data source. Right now it's assumed that it can only be `Gencode`.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3956#issuecomment-378314286:83,update,update,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3956#issuecomment-378314286,1,['update'],['update']
Deployability,"The advantage of using SLF4J is that it is a general facade, so it makes simpler to change for one logging system to other if the bound is implemented. For the most common logging systems (log4j, jul, JLC, etc.), there are this implementation and even no-op logging. One of the nice things from slf4j is that it allows to use the logging format set by the software to every library dependency, controlling the verbosity of other libraries too. . After having a look to the gradle dependencies, it seems that ADAM and Spark use slf4j. This will allow better integration with the two libraries: now the `slf4-jdk` is completely removed, and I don't know if this will blow up at some point if some of the ADAM/Spark classes try to load them. In addition, it will make GATK4 more general. Regarding features, I'm not using more that what log4j is providing, but I'm quite familiar with logback and I have a bias to use it if possible, but the GATK framework as it is implemented now ""force"" to use log4j. But anyway, I'm happy also with using log4j and I was only suggesting this for make GATK4 more general (and to come back in my work to logback, but that is just personal taste). @lbergelson, feel free to close the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259211054:557,integrat,integration,557,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259211054,2,['integrat'],['integration']
Deployability,"The best explanation that I've seen comes from @davidbenjamin at [this now-deprecated forum page](https://sites.google.com/a/broadinstitute.org/legacy-gatk-forum-discussions/2019-02-11-2018-08-12/21357-Mutect2):. > > There are differences in the actual variant allele frequency and the VAF provided by GATK.; >; > Do you mean that AF != AD/DP? It’s true that this is not what Mutect2 emits for the AF, which is a probabilisitc estimate that accounts for uncertainty. To see what I mean, suppose there are 100 total reads, 90 of which are ref and 10 of which each have a 60% chance of supporting the alt allele. As far as AD is concerned this is 10 alt reads, but as far as probability is concerned this is an expected 6 alt reads.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8080#issuecomment-1788433729:123,a/b,a/broadinstitute,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8080#issuecomment-1788433729,1,['a/b'],['a/broadinstitute']
Deployability,"The biggest thing for a new data source would be the latest (or dare I say; the ability to choose the version) of GENCODE. On Wed, Apr 5, 2023, 10:06 AM Jonn Smith ***@***.***> wrote:. > @robby81 <https://github.com/robby81> This still has to be merged. I've; > been pulled off onto some other projects for a bit. Some changes to the; > internals of Funcotator are needed for this tool to be most useful, so I; > was waiting until those updates were made to merge this.; >; > I can compile a new release of the data sources, but I haven't heard from; > anyone in the community that it's a priority. Can you create a new issue; > for it? Some questions around a new release: If I were to create one, what; > would the new release include? Would there be any new data sources that; > were not included before? Are any included data sources no longer useful; > and should be removed?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1497550761>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AAJMDRJS4JRSEURXGDDFK5TW7V36RANCNFSM5COZRAWA>; > .; > You are receiving this because you are subscribed to this thread.Message; > ID: ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1497616444:437,update,updates,437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1497616444,4,"['release', 'update']","['release', 'updates']"
Deployability,"The broad artifactory moved to https://broadinstitute.jfrog.io/broadinstitute/. There is a redirect in place which as been working for downloads, but uploads are failing with `401 Unauthorized`. It seems like updating the url fixes the problem. As a second issue, our builds try to upload archives for every integration test build, which worked when we only had 1 integration test build, but now that we have multiples we are uploading duplicates which isn't good. We should fix that, probably by adding either a new environment variable to the travis build, or a final build stage to perform the upload.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3068:308,integrat,integration,308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3068,2,['integrat'],['integration']
Deployability,"The build is failing since 1.21.0-SNAPSHOT is no longer available in any Maven repositories. It looks like 1.21.0 was released last week: https://repo1.maven.org/maven2/com/google/http-client/google-http-client/, and changing the build to use that version seems to fix the problem. Related to #650.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1185:118,release,released,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1185,1,['release'],['released']
Deployability,"The change doesn't affect anything when the BAM has a single sample, and when the BAM has more than one it handles what was previously a failure. So it's not going to break anything other than a pipeline that was somehow relying on the failure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8859#issuecomment-2146402849:195,pipeline,pipeline,195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8859#issuecomment-2146402849,1,['pipeline'],['pipeline']
Deployability,The changes in #5112 introduced several problems that have prevented us from performing a maven release of 4.0.9.0. I believe that the two issues are:. 1. The sources jar is misspelled as `source` jar; 2. The generated pom files are missing project level information. . We should:. - [x] Manually fix the files and peform a release of 4.0.9.0.; - [ ] Patch the build.gradle so that it's correct for future release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5212:96,release,release,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5212,4,"['Patch', 'release']","['Patch', 'release']"
Deployability,The changes to Mutect are included in the 4.0.11.0 release. A rough draft of the WDL is here: https://portal.firecloud.org/#methods/mt/MitochondrialCalling/8. When this is a complete pipeline (beyond the draft stage) there will be more information on the GATK forum.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5310#issuecomment-433067987:51,release,release,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5310#issuecomment-433067987,2,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"The cloud tests are timing out after 10 minutes without emitting any output. It seems like `ApplyBQSRDataflowIntegrationTest.testPR_Cloud` is responsible. It looks like something is crashing in dataflow but the runner is never stopped so it keeps waiting indefinitely (or at least 10 minutes..) See the dataflow log [here](https://console.developers.google.com/project/broad-dsde-dev/dataflow/job/2015-07-24_12_44_26-17415749601435236766). . Executing locally also seems to hang forever, with messages like . ```; Error: (b65a2091061bf0f9): Workflow failed. Causes: (71540087aac21e37): Unable to create VMs. Causes: (71540087aac21994): Error:; Test: Test method testPR_Cloud[0](ApplyBQSR(args=''))(org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSRDataflowIntegrationTest) produced standard out/err: Message: Value for field 'resource.metadata.items[1].value' is too large; ```. Seems like this is possibly a dataflow bug. If the workflow fails in some way the client should be released.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/750:986,release,released,986,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/750,1,['release'],['released']
Deployability,The current SV pipeline is producing invalid VCF files that are missing a header line for these attributes.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3224:15,pipeline,pipeline,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3224,1,['pipeline'],['pipeline']
Deployability,"The current docker build script runs `gradle installAll` in addition to running `localJar`. This causes the `gatk` script in our docker image to prefer running with the unpackaged set of jars, instead of the fully packaged jar. This, in turn, can cause us to run out of file handles in certain tools, since we need to open all of the jars for our dependencies individually at once. We should just run something like `gradle clean localJar sparkJar createPythonPackageArchive` in our `Dockerfile`, and avoid `installAll`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4409:45,install,installAll,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4409,2,['install'],['installAll']
Deployability,"The current documentation states that the type of the intervals parameter in the GenomicsDBImport ; tool is `List[String]` whereas this tool can only take one interval (as explained in the Caveats section) at https://software.broadinstitute.org/gatk/documentation/tooldocs/4.0.0.0/org_broadinstitute_hellbender_tools_genomicsdb_GenomicsDBImport.php#--intervals. The type should be updated to be just a `string` and maybe a note should be included in the actual argument documentation to say that, in opposition to other tools, only one interval can be provided.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4196:381,update,updated,381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4196,1,['update'],['updated']
Deployability,"The current fatJar gradle task does not properly merge resource files, causing an error when you try to run a Spark tool from the resulting jar. This PR replaces the fatJar task by configuring our shadowJar task to properly merge resource files. I've attempted to share configuration with the sparkJar task, which is also of type ShadowJar. Discussed briefly with @lbergelson.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1213:270,configurat,configuration,270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1213,1,['configurat'],['configuration']
Deployability,"The current implementation of VETS borrowed VQSR's logic for classifying variants into SNPs and indels, for which separate models are trained. We retained this logic to make comparisons with VQSR as straightforward as possible. In this logic, which originates from htsjdk, an alternate allele with len(REF) = len(ALT) is counted as a MNP and classified as a SNP. However, we are now applying VETS to long-read genotyping of SVs, where inversions satisfy the same criterion but are then awkwardly classified as SNPs. We should add a toggle to allow classification of MNPs as indels, probably retaining the old behavior as default to not cause any changes for e.g. GVS. Tagging @koncheto-broad and @fabio-cunial for their visibility.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8733:532,toggle,toggle,532,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8733,1,['toggle'],['toggle']
Deployability,"The current initialization action for dataproc workers puts the reference image in different places depending on whether or not an SSD is mounted. Preemptible dataproc workers don't have SSDs, so a mixed cluster will have references mounted on different paths depending on the worker. This change symlinks the SSD mount point onto the HDD so that paths can be consistent. . Also increases several cluster configuration parameters relating to retries, which I saw recommended if using preemptible workers.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4493:405,configurat,configuration,405,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4493,1,['configurat'],['configuration']
Deployability,"The current port of the `HaplotypeCaller` in `dr_runnable_haplotypecaller` has several ""fuzzy"" integration tests, in addition to traditional ""exact match"" integration tests, that test that we're above a certain % of concordance with a known good set (currently, GATK 3 output) using selected parts of the records (eg., alleles, genotypes, start/end positions). We should try to expand this strategy to include fuzzy testing for other parts of the output as well, such as annotations, with the ultimate goal of moving away from exact-match testing for the `HaplotypeCaller`. Will need to be done in consultation with methods people, particularly @ldgauthier",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1732:95,integrat,integration,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1732,2,['integrat'],['integration']
Deployability,"The current test report suggests that if we split off the tests in the `exome` package into a separate target, we would be close to a balanced 2-way split. Possibly the right way to do this is to have two new values for `TEST_TYPE` in `build.gradle`: `cnvIntegration` and `nonCNVIntegration`. Specifying just `integration` would run all the integration tests, as before. Specifying `cnvIntegration` would run everything in the `exome`, `copynumber`, and `coveragemodel` packages. Specifying `nonCNVIntegration` would run everything outside of those packages.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2818:310,integrat,integration,310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2818,2,['integrat'],['integration']
Deployability,"The custom R library installation can be moved into the docker base image (gatkbase), if desired",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2699:21,install,installation,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2699,1,['install'],['installation']
Deployability,"The docs update should be a pretty quick fix, but since we have some; explanation here in this issue it's not super high priority. On Wed, Nov 14, 2018 at 6:11 PM Bhanu Gandham <notifications@github.com>; wrote:. > Hi @ldgauthier <https://github.com/ldgauthier>; > I will look into this. What's the timeline? How soon do we need this?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5409#issuecomment-438854100>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdPBnavPNrzkjHM9tRZo499bECnYcks5uvKM5gaJpZM4YeJPw>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-439052451:9,update,update,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-439052451,1,['update'],['update']
Deployability,The documentation for `LeftAlignAndTrimVariants` indicates that it only works for indels. It should be updated to work for MNPs as well. . This operation would simply remove any common leading bases from all alleles of a `VariantContext` and update the start position by however many bases were removed. It would be implemented in `LeftAlignAndTrimVariants.java:289` replacing the noop for non-indels.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7516:103,update,updated,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7516,2,['update'],"['update', 'updated']"
Deployability,"The dsde-pipelines repo should be updated when the arg changes go in (all the GenomicsDBImport args are long args that have been changed, for example).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3891#issuecomment-348207248:9,pipeline,pipelines,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3891#issuecomment-348207248,2,"['pipeline', 'update']","['pipelines', 'updated']"
Deployability,The earlier GKL release did not have all updates merged. Hence submitting another request to include the latest GKL.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4379:16,release,release,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4379,2,"['release', 'update']","['release', 'updates']"
Deployability,"The empty alts that results from overtrimming in an alt allele UDF correlate strongly with VAT / alt allele mismatches, but from trial runs with and without this patch they don't seem to actually be causing the mismatches. Nonetheless I think this is a desirable change as it keeps VAT VIDs from getting weird. VIDs have the format `<contig>-<position>-<ref>-<alt>`; if the alt is empty the VID just ends in a dash which just seems like an edge case waiting to break something.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8326:162,patch,patch,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8326,1,['patch'],['patch']
Deployability,"The error message about allele sorting is unhelpful -- it's from an integration test check for exact match of output vcf against an expected vcf and the ""sort order"" error really just means there are fewer alleles in the output than expected. Since this change is what we want, the solution is just to overwrite the expected VCF. I checked all the discordant files and found nothing wrong, so this is okay. I also looked at all the output after the change `!outputNonVariants` --> `true` that I suggested, and it is definitely more correct.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582252469:68,integrat,integration,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582252469,1,['integrat'],['integration']
Deployability,"The existing Spark interface for metrics collectors is described [here](https://github.com/broadinstitute/gatk/blob/fc66240a1a382ad803b7f83ead612f65957a644e/src/main/java/org/broadinstitute/hellbender/tools/spark/pipelines/metrics/MetricsCollectorSpark.java). [Here](https://github.com/broadinstitute/gatk/blob/414cedf60d2041636f772658a6d04f470affb0f4/src/main/java/org/broadinstitute/hellbender/tools/spark/pipelines/metrics/QualityYieldMetricsCollectorSpark.java) is one implementation of that interface, which in turn just delegates to the actual ""tool"" logic component that is reused for all variations of the tool (Spark, standalone, CollectMultiple, etc).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2217#issuecomment-254217599:213,pipeline,pipelines,213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2217#issuecomment-254217599,2,['pipeline'],['pipelines']
Deployability,"The existing pipelines and multiple collectors are not consistent in how the user's filter requests are merged and propagated to different stages of the pipeline. The BQSR pipeline for instance first retrieves the initial RDD via getReads, which honor's the user's filter requests, but subsequently manually applies the BQSR-specific filter, which might re-enable a filter that was disabled by the user. We should have a more explicit (and user-transparent) set of rules for propagating/applying filters in the cases where we're composing multiple tools.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2150:13,pipeline,pipelines,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2150,3,['pipeline'],"['pipeline', 'pipelines']"
Deployability,The failing test is not related as this just updates some documentation and scripts.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3790#issuecomment-341686323:45,update,updates,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3790#issuecomment-341686323,1,['update'],['updates']
Deployability,"The failure is: ""ERROR: (gcloud.components.update) The component [bq-nix] failed to download."" This looks like a transient issue related to gcloud components update. FWIW I was able to update my desktop's installation with no issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-288228672:43,update,update,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-288228672,4,"['install', 'update']","['installation', 'update']"
Deployability,"The file size only went from 1.9MB to 3MB -- there's no perceptible; difference in test runtime that I can see. On Wed, Apr 5, 2017 at 2:04 PM, droazen <notifications@github.com> wrote:. > *@droazen* commented on this pull request.; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/spark/; > ParallelCopyGCSDirectoryIntoHDFSSparkIntegrationTest.java; > <https://github.com/broadinstitute/gatk/pull/2540#discussion_r109987028>:; >; > > +; > +; > +public class ParallelCopyGCSDirectoryIntoHDFSSparkIntegrationTest extends CommandLineProgramTest {; > +; > + @Override; > + public String getTestedToolName() {; > + return ParallelCopyGCSDirectoryIntoHDFSSpark.class.getSimpleName();; > + }; > +; > + @Test(groups = {""spark"", ""bucket""}); > + public void testCopyFile() throws Exception {; > + MiniDFSCluster cluster = null;; > + try {; > + final Configuration conf = new Configuration();; > + // set the minicluster to have a very low block size so that we can test transfering a file in chunks without actually needing to move a big file; > + conf.set(""dfs.blocksize"", ""1048576"");; >; > Instead of switching to a larger file, is it possible to just decrease the; > block size further? (thinking about test runtimes here); >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/2540#discussion_r109987028>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AArTZYV_vD1XwS5IPvZiNZKOe6QzDJDVks5rs9e2gaJpZM4MtGXX>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2540#issuecomment-291948506:884,Configurat,Configuration,884,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2540#issuecomment-291948506,2,['Configurat'],['Configuration']
Deployability,"The first commit has the raw GATK3 files, the second has the ported files. In order to minimize the diffs from GATK3 for the initial port, there are only very minimal style changes. Integration tests will follow in a separate PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2094:182,Integrat,Integration,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2094,1,['Integrat'],['Integration']
Deployability,The first step of taking this code from the Hail team is just pasting it into our repo. Successful run:; https://job-manager.dsde-prod.broadinstitute.org/jobs/49d62f48-2dee-417c-aa65-411cbe47be17. GvsQuickstartHailIntegration--we remove the whl from the integration test---sure seems like we wont need one going forward!. Another ticket will be made for these next steps:; Likely this will need to end up in our docker image and the WDL that creates the Avro files can make a version of the input for this scripts instead; Next we will want to remove the Tranches calculations and instead of that value passed in as yet another parameter; Phasing and dropping GQ0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8282:254,integrat,integration,254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8282,1,['integrat'],['integration']
Deployability,"The fix for this issue is merged, but there are a couple of PRs for related issues (https://github.com/broadinstitute/gatk/pull/4680 and https://github.com/broadinstitute/gatk/pull/4681) that should be merged before we do a release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4572#issuecomment-383096422:224,release,release,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4572#issuecomment-383096422,1,['release'],['release']
Deployability,"The following command generates an error. Other spark programs work when specifying hdfs://scc/user/farrell/adsp/bams/SRR990385.bam as the input. It seems to be having a problem with testing for the presence of the SRR990385.bai file which is present. I tried running the command with hdfs://scc:**8020**/user/farrell/adsp/bams/SRR990385.bam and that works. . `/share/pkg/gatk/4.beta.5/install/bin/gatk-launch SparkGenomeReadCounts -I hdfs://scc/user/farrell/adsp/bams/SRR990385.bam -o SRR990385.ReadCounts -R /restricted/projectnb/genpro/bundle/2.8/b37/human_g1k_v37.fasta --verbosity ERROR -- --sparkRunner SPARK --sparkMaster yarn --num-executors 1 --executor-memory 4G --executor-cores 3`. [December 3, 2017 2:56:35 PM EST] org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts done. Elapsed time: 0.57 minutes.; Runtime.totalMemory()=982515712; org.apache.spark.SparkException: Job aborted due to stage failure: Task 12 in stage 0.0 failed 4 times, most recent failure: Lost task 12.3 in stage 0.0 (TID 14, scc-q09.scc.bu.edu, executor 1): java.lang.IllegalArgumentException: **Wrong FS: hdfs://scc:8020/user/farrell/adsp/bams/SRR990385.bai, expected: hdfs://scc**; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:193); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:105); at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302); at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298); at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766); at org.seqdoop.hadoop_bam.util.WrapSeekable.openPath(WrapSeekable.java:60); at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3909:386,install,install,386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3909,1,['install'],['install']
Deployability,"The following idiom occurs about 25 times in this repo, mainly in integration tests:; ```; StreamSupport.stream(new FeatureDataSource<VariantContext>(vcf).spliterator(), false). . .; ```; We should extract a method, perhaps `Utils.streamVcf(final File vcf)`, to replace this unwieldy construct.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5006:66,integrat,integration,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5006,1,['integrat'],['integration']
Deployability,"The following is the reads of chr1: 14633 position in bqsr.bam seen through samtools tview. QUAL values are no longer as continuous as they were before gatk 4.1 version. ![image](https://user-images.githubusercontent.com/11796428/70585983-dbb6f600-1c00-11ea-97ba-b83a3d4ce03d.png). ---; another one： chr1:13279; GVCF; ```; chr1 13274 . T <NON_REF> . . END=13278 GT:DP:GQ:MIN_DP:PL 0/0:21:60:20:0,60,709; chr1 13279 . C <NON_REF> . . END=13279 GT:DP:GQ:MIN_DP:PL 0/0:21:57:21:0,57,855; chr1 13280 . A <NON_REF> . . END=13284 GT:DP:GQ:MIN_DP:PL 0/0:22:60:22:0,60,900; ```; VCF (from GenotypeGVCFs); ```; chr1 13275 . G . 96.81 . DP=20 GT:AD:DP:RGQ 0/0:20,0:20:60; chr1 13276 . A . 96.81 . DP=20 GT:AD:DP:RGQ 0/0:20,0:20:60; chr1 13277 . T . 96.81 . DP=20 GT:AD:DP:RGQ 0/0:20,0:20:60; chr1 13278 . A . 96.81 . DP=20 GT:AD:DP:RGQ 0/0:20,0:20:60; chr1 13279 . C . 0 . DP=21 GT:AD:DP:RGQ 0/0:21,0:21:57; chr1 13280 . A . 96.81 . DP=22 GT:AD:DP:RGQ 0/0:22,0:22:60; chr1 13281 . C . 96.81 . DP=22 GT:AD:DP:RGQ 0/0:22,0:22:60; chr1 13282 . C . 96.81 . DP=22 GT:AD:DP:RGQ 0/0:22,0:22:60; chr1 13283 . C . 96.81 . DP=22 GT:AD:DP:RGQ 0/0:22,0:22:60; ```; reads: (no clipped reads); ![image](https://user-images.githubusercontent.com/11796428/70586910-73b5df00-1c03-11ea-8ba4-843d34bda913.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6309#issuecomment-564355856:121,continuous,continuous,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6309#issuecomment-564355856,1,['continuous'],['continuous']
Deployability,The following tools are updated in this PR:; CountBases; CountBasesSpark; CountReads; CountReadsSpark; CheckPileup; EstimateLibraryComplexityGATK; FlagStat; FlagStatSpark; GetSampleName; SplitReads; AnalyzeCovariates. Could you please review @sooheelee? Thank you!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4003:24,update,updated,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4003,1,['update'],['updated']
Deployability,The generated online doc currently doesn't include the names of the default annotations or annotation groups used by various tools. The values are already propagated from the annotation plugin to the freemarker map by Barclay; it should be easy to update the freemarker template to display these similar to the way we display default read filters.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5577:248,update,update,248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5577,1,['update'],['update']
Deployability,"The ggplot2 R dependency was not installed correctly in the gatkbase-2.0.0 Docker image. It appears that this resulted from a recent ggplot2 update that has broken dependencies (perhaps for the version of R that we use). This missing ggplot2 dependency was the root cause of #5022. I updated the install_R_packages.R script, which should now fail if any package fails to install, and pushed an updated gatkbase-2.0.1 image. The second commit addresses #5022. This should be considered a temporary fix until #5026 is in. Closes #5022.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5040:33,install,installed,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5040,5,"['install', 'update']","['install', 'installed', 'update', 'updated']"
Deployability,The goal of this PR is to adjust the ingest in two ways:; 1. To update the ingest to loop through all samples (not just the first 10k); 2. To update the ingest to be far more efficient in a few ways:; - To remove the files that are downloaded to each vm so that they do not carry around the extra weight; - To check that the samples in the fofns have not been ingested already so that additional work doesn't need to be done toward processing those samples. There is still work to do around making the bulk ingest process significantly more user-friendly,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8197:64,update,update,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8197,2,['update'],['update']
Deployability,"The google-cloud-java maintainers have merged a fix for the longstanding issue; https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2453 that prevented us; from running on a modern version of the library, and forced us to run off of a fork.; This PR updates us to the latest release, which incorporates the fix. Resolves #3591; Resolves #3500; Resolves #4986",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5135:262,update,updates,262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5135,2,"['release', 'update']","['release', 'updates']"
Deployability,"The htsget.ga4gh.org appears to be down (tests get 404s, ping fails). This output is from my PR https://github.com/broadinstitute/gatk/pull/6799 that prints out the target URI:. ```; org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; at org.broadinstitute.hellbender.tools.HtsgetReader.doWork(HtsgetReader.java:266); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:146); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:187); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); at org.broadinstitute.hellbender.testutils.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:111); at org.broadinstitute.hellbender.tools.HtsgetReaderIntegrationTest.testSuccessfulParameters(HtsgetReaderIntegrationTest.java:85); ```; Jermey (GA4GH dev) says:. > I recently updated the server, but my understanding was that the gatk build was spinning up a local server from an older image; > 11:41; > so htsget.ga4gh.org is using a newer image, while the gatk tests should pull an older image, spin it up locally, and then request from http://localhost. But based on the output above, it looks like we actually target `https://htsget.ga4gh.org/read...`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6803:1481,update,updated,1481,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6803,1,['update'],['updated']
Deployability,The htsjdk branch for this is [here](https://github.com/cmnbroad/htsjdk/tree/cn_bcf_codec_version) and the GATK branch is [here](https://github.com/broadinstitute/gatk/tree/cn_bcf_version_override). We'll need this for the next (post 2.19) htsjdk update. Will require the htsjdk branch to be merged and released before we can use the GATK branch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5839#issuecomment-477376375:247,update,update,247,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5839#issuecomment-477376375,2,"['release', 'update']","['released', 'update']"
Deployability,The htsjdk downstream tests were put together before gradle had composite builds and are very hacky. They should be refactored to use composite builds instead of installing a strangely named maven artifact. . We should also split them into unit/ integration tests to reduce wallclock time. This should be easy since we already to it in travis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3235:162,install,installing,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3235,2,"['install', 'integrat']","['installing', 'integration']"
Deployability,"The idea is that this WDL will run all the checks for each release of the VAT table, one call for each validation. The first validation rule (""Validation Check confirms that data is put into the VAT table after completing without an error."") is included as a model for subsequent calls. - workflow should succeed if it's able to try all tests; - workflow output `validation_results` will contain details of each test result in an array of `{""testName"": ""result details""}`:; Example 1 — [fail](https://job-manager.dsde-prod.broadinstitute.org/jobs/2728b55b-5344-492a-951a-48fd416e9d0d); `{ ""EnsureVatTableHasVariants"": ""FAIL: The VAT table spec-ops-aou.rsa_gvs_quickstart.rsa_scratch has no variants in it."" }`; Example 2 — [pass](https://job-manager.dsde-prod.broadinstitute.org/jobs/83e3bd5a-9144-452e-93d9-9f273055177f); `{ ""EnsureVatTableHasVariants"": ""PASS: The VAT table spec-ops-aou.anvil_100_for_testing.aou_shard_223_vat has 294821 variants in it."" },`; Example 3 — [the test wasn't able to run](https://job-manager.dsde-prod.broadinstitute.org/jobs/7179d111-02aa-4bca-a0a0-f55e10e43791); `{ ""EnsureVatTableHasVariants"": ""Something went wrong. The attempt to count the variants returned: Error in query string: Error processing job 'spec-ops- aou:bqjob_r357c4b6fe6b0c6fb_0000017aac301de7_1': Unrecognized name: vid at [1:24]"" }`. Closes https://github.com/broadinstitute/dsp-spec-ops/issues/364",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7352:59,release,release,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7352,1,['release'],['release']
Deployability,"The integration tests I had for the allele-specific annotations admittedly had very small VCFs, but they were very, very gross variants. :) At the very least, the rank sums need test data that have a 0/1 sample and a 0/2 sample.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-325462858:4,integrat,integration,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-325462858,1,['integrat'],['integration']
Deployability,"The intervals we are passing to GenomicsDBImport are sorted by chromosomal numbers for a subset of chromosomal regions: chr 7, 8, 9, 10. ; The next step is CreateSomaticPanelOfNormals or GenotypeGVCFs depending on the pipelines. But the output for both steps all shows the problem that chr 10 is ahead of chr 7 (chr 10, 7, 8, and 9). ; Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8416#issuecomment-1635962226:218,pipeline,pipelines,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8416#issuecomment-1635962226,1,['pipeline'],['pipelines']
Deployability,"The latest GATK release does significantly cut down on the number of critical vulnerabilities (mainly by moving to the latest Ubuntu 18.04 image), but there is definitely more work to be done here, so I'll keep this ticket open",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1496162653:16,release,release,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1496162653,1,['release'],['release']
Deployability,"The latest Picard release introduces a dependency on the Google Cloud NIO library that conflicts with GATK's dependency. We are going to have to blacklist the Picard NIO dependency for now. . Longer term, we might want to consider having both projects depend upon a build of htsjdk that comes with the NIO plugin.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4556:18,release,release,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4556,1,['release'],['release']
Deployability,"The latest code in htsjdk, which includes https://github.com/samtools/htsjdk/pull/1454 (changes the Allele class into an interface, and uses SimpleAllele as the concrete implementation) causes the `VariantAnnotatorEngineUnitTest.testCombineAnnotations` test to fail because the order of the list returned by `ReducibleAnnotationData.getAlleles` is different with that change than it is without it (presumably due to the different hashCode/equals implementations). `AS_RMSMappingQuality.parseRawData` seems to assume that the order of the Alleles in the list returned by ; `ReducibleAnnotationData.getAlleles` exactly matches the order of the raw data in the String returned by `ReducibleAnnotationData.getRawData`, since it uses indexed access to the list, but I don't see anything that states or ensures/enforces this. Changing the Map maintained by `ReducibleAnnotationData` into a LinkedHashMap fixes the issue for this test, but that just changes the order to be input order - the real issue is that the contract around how the order of the list and the order of the raw data is maintained isn't clear. This will need to be addressed before we can upgrade to the next release of htsjdk.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7586:1152,upgrade,upgrade,1152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7586,2,"['release', 'upgrade']","['release', 'upgrade']"
Deployability,"The latest released gatk doesn't have this fix in it yet, and although I see that one forum user was going to try to reproduce on the latest branch, I don't see the results from that yet. Has someone reproduced this using code that includes the fix to #5893 ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5945#issuecomment-493043384:11,release,released,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5945#issuecomment-493043384,1,['release'],['released']
Deployability,"The latest version of the funcotator data sources dates to mid-2020. This is almost three years now without any update of the following sources:; *gencode (v34, now 43); *dbsnp; *COSMIC; *clinvar. Therefore, a new bundle should be provided to stay up-to-date again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8296:112,update,update,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8296,1,['update'],['update']
Deployability,"The main purpose of this PR was to output the new estimated bytes read from the Read API for better monitoring and debugging. However in the course of that I discovered that we were using ancient versions of the google APIs. No massive improvements from the release logs, but a lot of nice features (cleaner logging, automatic retries for certain errors, ). bigQuery 1.131.1 -> 2.3.3 [Release log for bigQuery](https://github.com/googleapis/java-bigquery/blob/main/CHANGELOG.md). bigQueryStorage 1.22.3 -> 2.5.0 [Release log for bigQueryStorage](https://github.com/googleapis/java-bigquerystorage/blob/main/CHANGELOG.md)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7601:258,release,release,258,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7601,3,"['Release', 'release']","['Release', 'release']"
Deployability,The necesssary change went into htsjdk so we can do this now whenever we pick up a new release of htsjdk.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8160#issuecomment-1410619589:87,release,release,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8160#issuecomment-1410619589,1,['release'],['release']
Deployability,"The new images include updated versions of python, docker, git, google-cloud-sdk, amongst others.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3953#issuecomment-351415666:23,update,updated,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3953#issuecomment-351415666,1,['update'],['updated']
Deployability,The new index creation tool `IndexFeatureFile` needs integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/235:53,integrat,integration,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/235,1,['integrat'],['integration']
Deployability,"The new pipeline is in a complete state. Nearly all tools and scripts were rewritten, many from scratch. I've tried to minimize interaction with old `tools/exome` code (notably, `ReadCountCollection` and `SegmentUtils`). There are still some improvements that can be made (especially in segment union and the subsequent modeling), but we should be ready to go for a first validation. Some notes:. WDL:; - I've moved the old pipeline to `somatic_old` folders.; - There is now just a matched-pair workflow and a panel workflow. We can add a single BAM case workflow or expand the matched-pair workflow to handle this, depending on the discussion at https://github.com/broadinstitute/gatk/issues/3657.; - WES/WGS is toggled by providing an optional target-file input.; - For all workflows, we always collect integer read counts; for WGS, these are output as both HDF5 and TSV and the HDF5 is used for subsequent input.; - For the case workflow, we always collect allelic counts at all sites and output as TSV.; - [x] We should output all data files as HDF5 by default and as TSV optionally. EDIT: This is done for `CollectFragmentCounts`.; - [x] We will need to update the workflows when @MartonKN and @asmirnov239 get `PreprocessIntervals` and `CollectReadCounts` merged, respectively. These tools will remove the awkwardness required by `PadTargets` and `CalculateTargetCoverage`/`SparkGenomeReadCounts`. Denoising:; - All parameters are exposed in the PoN creation tool (#3356).; - Without a PoN, standardization and optional GC correction are performed (#3570).; - Other than the minor point about sample mean/median being used inconsistently noted above, the denoising process is essentially exactly the same mathematically as before (""superficial"" differences include the vastly improved memory and I/O optimizations, the ability to adjust number of principal components used, the removal of redundant SVDs, the enforcement of consistent GC-bias correction).; - [ ] That said, I'll carry over this ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:8,pipeline,pipeline,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,6,"['pipeline', 'toggle']","['pipeline', 'toggled']"
Deployability,The newest release of GenomicsDB treats spanning deletions (spanning; from earlier positions) as deletions in the min PL value computation.; This behavior now matches the behavior of CombineGVCFs. A more detailed description of the issue is provided in; https://github.com/broadinstitute/gatk/pull/4963. * Deleted a couple of files which are no longer necessary.; * Fixed the index of newMQcalc.combined.g.vcf; * Fixes #5045 (error out with a helpful error message); * Fixes #5300,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5397:11,release,release,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5397,1,['release'],['release']
Deployability,The newest release of gatk supports multiple intervals in GenomicsDBImport. There's a known issue https://github.com/broadinstitute/gatk/issues/4994 which prevents the use of large interval lists. It should be be fixed in the next release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4013#issuecomment-404332940:11,release,release,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4013#issuecomment-404332940,2,['release'],['release']
Deployability,"The next release is going to be a big 4.1 minor version release, so there are a lot of new features we're trying to finish up. Hopefully it will be by the end of the month, but a nightly will be available with this change by tomorrow: https://hub.docker.com/r/broadinstitute/gatk-nightly",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452020693:9,release,release,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452020693,2,['release'],['release']
Deployability,"The official 4.0 release, not the beta release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307530154:17,release,release,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307530154,2,['release'],['release']
Deployability,The only tool that is update in this PR is UnmarkDuplicates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4019:22,update,update,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4019,1,['update'],['update']
Deployability,"The only way I can think of this happening is if a read is aligned to the start of a contig (ie position 1), and has a left soft clip. Then the unclipped read start will be negative. It looks like reporters are running on hg38, so I suspect that this is occurring on alt contigs that have alignable bases at the very begging of the contig (as opposed to the primary contigs). For some reason we have not seen this in data produced by the Broad's hg38 alignment pipeline yet. I will try to push a quick fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685#issuecomment-480385301:461,pipeline,pipeline,461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685#issuecomment-480385301,1,['pipeline'],['pipeline']
Deployability,"The other issue is that making newQual the default is going to introduce batch effects. @vdauwera Can correct me if I'm wrong, but the party line used to be ""use the same version for all of your samples or we're not responsible"". I do want to do it, I just don't know how we make it as obvious as possible. Would this justify a minor release? Or we could put one of those scary red warnings in the GenotypeGVCFs log for a few releases?. @davidbenjamin is still going to look into one last spanning deletion issue and we'll run a bunch of samples through HaplotypeCaller (since they share the same AlleleFrequencyCalculator) to make sure nothing chokes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-377526021:334,release,release,334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-377526021,2,['release'],"['release', 'releases']"
Deployability,"The other issue we need to resolve is the one @samuelklee mentioned [here](https://github.com/broadinstitute/gatk/pull/3838#issuecomment-348073948), which is how to install/distribute our own Python packages (i.e., gCNV kernel and CNN-vqsr). Assuming the common environment doesn't change frequently, it can probably be baked right into the base docker image, but since we want the Python code to live in the GATK repo, we need to be able to test PRs with modified Python code directly in travis on the image we build for testing. Is there any reason we can't/shouldn't just pip install them on the generated docker right from source, or from a locally built archive ? Its seems like an option, at least for just getting a CPU enabled distribution running. We'll probably still need a separate solution like a conda env for non-docker users, and longer term we'll have to address GPU enabling, but for now a local install seems like an option.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-348543770:165,install,install,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-348543770,3,['install'],['install']
Deployability,"The output file (`-O`/`--output`) is optional, but if not set you get a NPE:. ```; java.lang.NullPointerException; at java.io.File.<init>(File.java:277); at org.broadinstitute.hellbender.tools.spark.pipelines.FlagStatSpark.runTool(FlagStatSpark.java:41); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:257); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66); at org.broadinstitute.hellbender.Main.main(Main.java:81); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); ```. This is the command I ran:. ```; ./gatk-launch FlagStatSpark \; --input hdfs:///user/$USER/bam/CEUTrio.HiSeq.WGS.b37.ch1.1m-65m.NA12878.bam \; -bps 134217728 \; -- \; --sparkRunner SUBMIT --sparkMaster yarn-client \; --driver-memory 3G \; --num-executors 14 \; --executor-cores 1 \; --executor-memory 3G; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1282:199,pipeline,pipelines,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1282,6,"['deploy', 'pipeline']","['deploy', 'pipelines']"
Deployability,"The package org.broadinstitute.hellbender.utils.commandline contains annotation classes called AdvancedOption and HiddenOption that are duplicates of Advanced and Hidden in org.broadinstitute.hellbender.commandline. All usages of these should be updated and this entire package should be removed. Also, it looks like Hidden is not integrated with the command line parser.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2130:246,update,updated,246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2130,2,"['integrat', 'update']","['integrated', 'updated']"
Deployability,"The packages for codecs is a key feature for downstream tools implementing new codecs for other formats or to include overrides of codecs already included. Nevertheless, the current implementation (at version 4.0.0.0) the only way of configuring this is at the package level using the `codec_packages` configuration. I request support for the following fine-grained configuration:. * Add/Remove concrete codec classes; * Exclude single classes from a concrete `codec_package` specified (this can be done by the previous requirement if it uses fully qualified codec names); * Exclude sub-packages from a concrete `codec_package` specified. Representing this in an YML format, I would like to have the ability to configure the codecs as following:. ```yml; - codecs:; - packages:; - htsjdk.variant; - htsjdk.tribble; - exclude_class: bed.BEDCodec; - org.broadinstitute.hellbender.utils.codecs; - exclude_package: gencode; - org.magicdgs.htsjdk.codecs; - classes:; - org.external.htsjdk_codecs.CustomBedCodec; ```. This would be even more useful if HTSJDK is moving to an interface-based library...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4180:302,configurat,configuration,302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4180,2,['configurat'],['configuration']
Deployability,"The packages required by these tests are installed by scripts/docker/gatkbase/install_R_packages.R. Perhaps we should update the readme, which seems to indicate that the R dependencies are only used for plotting.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3740#issuecomment-338992163:41,install,installed,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3740#issuecomment-338992163,2,"['install', 'update']","['installed', 'update']"
Deployability,"The palindrome artifact read filter wasn't checking for an edge case. Now it is. @takutosato Could you review? And if you approve and it's Monday or Tuesday, could you merge before the release?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5241:185,release,release,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5241,1,['release'],['release']
Deployability,"The patch clears up the 503 failures due to `fetchSize()`, but we are STILL seeing 503's with other metadata operations such as `Files.exists()`:. ```; com.google.cloud.storage.StorageException: 503 Service Unavailable; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:586); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.tribble.util.ParsingUtils.resourceExists(ParsingUtils.java:428); at htsjdk.tribble.AbstractFeatureReader.isTabix(AbstractFeatureReader.java:217); at htsjdk.tribble.AbstractFeatureReader$ComponentMethods.isTabix(AbstractFeatureReader.java:223); ```. I'm going to continue modifying the patch until we see all 503s go away, then post here once it's ready.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314813629:4,patch,patch,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314813629,4,['patch'],['patch']
Deployability,"The problem is that the package can't download any files during build due to security reasons. It has to use predefined, repeatable set of dependencies, and can't download random versions of gradle either. It has to use the ```devel/gradle``` port, and once this port has been upgraded to version 5.0 gatk became broken. ```devel/gradle4``` had to be created. Generally, indiscriminate downloads of files lead to security problems like the one that recently happened with a particular bitcoin-related node code, which was using a zillion node dependencies. One of them got infiltrated by a criminal who eventually stole bitcoins because he managed to inject his code into financial applications running on user's sites. To prevent such things from happening, all major packaging systems only use fingerprinted dependencies, and can't ""just download"" some alternative version of something during build, contrary to what devs might be expecting.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444205059:277,upgrade,upgraded,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444205059,1,['upgrade'],['upgraded']
Deployability,The problem seems to be fixed in picard with @cmnbroad's change to the cloud configuration. Thew pom for 2.18.1+ looks like it won't include nio.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4556#issuecomment-375432298:77,configurat,configuration,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4556#issuecomment-375432298,1,['configurat'],['configuration']
Deployability,"The product sheet had old scale numbers and VQSR, updated to VETS and new scale numbers.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8929:50,update,updated,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8929,1,['update'],['updated']
Deployability,"The properties needed are listed here (for testing in this case): https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/engine/spark/SparkContextFactory.java#L83-L86. They are; * `fs.gs.impl`; * `fs.AbstractFileSystem.gs.impl`; * `fs.gs.project.id`; * `google.cloud.auth.service.account.json.keyfile`. Note that to set them as Spark configuration values, they need to be prefixed with `spark.hadoop`. So from the `spark-submit` command line you would write. ```; --conf spark.hadoop.fs.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5996#issuecomment-500745498:374,configurat,configuration,374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5996#issuecomment-500745498,1,['configurat'],['configuration']
Deployability,The proposed fix for this issue is under review in PR https://github.com/broadinstitute/gatk/pull/6652 -- should be part of the next GATK release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6709#issuecomment-664554342:138,release,release,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6709#issuecomment-664554342,1,['release'],['release']
Deployability,"The recent branch #8489 has demonstrated that there are some problematic edge cases in the pileup allele merging code that could cause pathological numbers of haplotypes to be handed to the genotyper. In updating the bug in that branch it was observed that it is very common that there are score ties at the 5th haplotype level for the pileupcaller as illustrated by the noise in the updated tests. This algorithm is not a good heuristic and we should replace it with something better, some ideas from that branch that might fix a few of its shortcomings:. 1) Increase/decouple the kmer size used with the reads from the assembly graph kmer size to prevent the filtering step from being redundant with assembly; 2) Normalize the scores to the haplotype lengths to deal with haplotype size bias.; 3) Change the scores to instead reflect the absolute count of unsupported kmers from the graph to also deal with hapotype size bias. ; 4) Iteratively expand the kmer size used for filtering to pare down the number of haplotypes in a more principled fashion.; 5) Utilize the read kmer occurrence counts to construct the scores in order to reduce the risk of spurious reads being sufficient support for a given haplotype. . We have observed that there can be significant changes to the actual genotyping engine output from the pileup engine from even relatively minor changes to the pileupcalling merging code. We should strive to find a more principled solution for merging haplotypes than the one we have currently.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8494:384,update,updated,384,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8494,1,['update'],['updated']
Deployability,The recently-added sequence dictionary validation in `BaseRecalibratorDataflow` does not work when the reference is stored in a bucket -- we should patch it so that it does.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/683:148,patch,patch,148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/683,1,['patch'],['patch']
Deployability,The relevant WDL is in the dsde-pipelines repo (https://github.com/broadinstitute/dsde-pipelines/pull/968) and gets synced (somewhat manually) with the gatk-workflows repo. Most of the best practices WDLs live in the GATK repo except the classic germline SNPs and indels. C'est la vie.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6423#issuecomment-579456659:32,pipeline,pipelines,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6423#issuecomment-579456659,2,['pipeline'],['pipelines']
Deployability,The rest of the mitochondria joint calling pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5673:43,pipeline,pipeline,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5673,1,['pipeline'],['pipeline']
Deployability,The return value of picard tools goes to standard output which makes it hard to pipeline these tools nicely.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5790:80,pipeline,pipeline,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5790,1,['pipeline'],['pipeline']
Deployability,The sample name map file accepted by GenomicsDBImport can now optionally contain a third; column giving an explicit path to an index for the corresponding GVCF. It is allowed to; specify an explicit index in some lines of the sample name map and not others. Added comprehensive unit and integration tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7967:287,integrat,integration,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7967,1,['integrat'],['integration']
Deployability,"The script is no longer located at scripts/install_R_packages.R, so we should update the readme accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3601:78,update,update,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3601,1,['update'],['update']
Deployability,"The segfault happens in `libgomp`:; ```; # Problematic frame:; # C [libgomp.so.1+0x7fab] omp_get_max_threads+0xb; ```; Here's similar issue, which also used Alpine Linux: https://github.com/bytedeco/javacv/issues/716. The resolution was to move to a different Linux distro. @apeltzer, assuming you want to use Alpine, please try running without `libgomp` installed. This will provide single-threaded AVX PairHMM, which will be faster than the Java PairHMM.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158#issuecomment-358080124:355,install,installed,355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158#issuecomment-358080124,1,['install'],['installed']
Deployability,"The snapshot builds get published to an artifact repository, but I don't think those are accessible from outside of Broad. The build from this morning with your branch is [here](https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot-local/org/broadinstitute/gatk/4.0.11.0-30-g9c4a27b-SNAPSHOT/) if you can access it. Otherwise, for local development, you can do the following:. - pull gatk master from today so it includes your commit; - run `git fetch --tags` (this is optional but it will give your local build a more reasonable version tag); - run `./gradlew install printVersion` to install the locally built gatk into your local machine's maven repository; - change your VariantQC gradle project to include the `maven` gradle plugin if its not already there; - add `mavenLocal()` to your projects' `repositories `closure; - change your gatk dependency to the version number printed out by 'printVersion'; - rebuild VariantQC. Having said all that, what code are you dependent on ? I expect the command line interface to VariantEval, and the VariantUtils and StratificationManager and friends classes all to undergo some refactoring and evolve a bit before the tool has the beta tag removed and the interfaces are stabilized. See https://github.com/broadinstitute/gatk/issues/5439 and https://github.com/broadinstitute/gatk/issues/5440.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440782148:568,install,install,568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440782148,2,['install'],['install']
Deployability,The standard integration/unit tests upload their test report -- the docker tests should as well.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2817:13,integrat,integration,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2817,1,['integrat'],['integration']
Deployability,"The tab completion integration test wasn't actually emitting any output because the classpath contained a list of class names (basenames only, without the "".class"" extension), so no work units were ever created. This PR:. - changes the classpath to use package names that contain CLPs instead of class names; - runs the javadoc in the current JVM (which makes debugging the test so much easier...); - adds an Assert to ensure the javadoc process succeeds. I made the latter change to the doc gen smoke test as well, to make debugging easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6647:19,integrat,integration,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6647,1,['integrat'],['integration']
Deployability,"The test Gencode data sources did not include any genes in flanking distance to the test variants. This update creates a new Gencode data source that includes such regions. Additionally, the Gencode excision script was updated to include a flanking range defaulting to the funcotator 5' flanking defualt (5000 bases). . Fixes #5419",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5423:104,update,update,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5423,2,['update'],"['update', 'updated']"
Deployability,The type of the method changed at some point and the references were never updated.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6478:75,update,updated,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6478,1,['update'],['updated']
Deployability,"The updated jBWA code allows changing scoring parameters for `bwa mem`. ; Specifically, the `BwaMem` class now has a method `updateScoringParameters()`. This ticket is to remind the SV group to update, accordingly, the class `AlignContigsAndCallBreakpointsSpark` and `ContigAligner.java`. Closes #1942 .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2001:4,update,updated,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2001,3,['update'],"['update', 'updateScoringParameters', 'updated']"
Deployability,"The updates based on code review are done, but I need feedback on couple of questions above before I can finalize this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2182#issuecomment-251455000:4,update,updates,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2182#issuecomment-251455000,2,['update'],['updates']
Deployability,"The user has posted an update with the jstack logs and they can be downloaded here (https://gatk.broadinstitute.org/hc/en-us/community/posts/360076845511/comments/360014258071) ; They also provided info that when they run GenomicsDBImport for the two samples in the same command, GenotypeGVCFs completes in 14 minutes. But if they import one sample at a time (using --genomicsdb-update-workspace-path) the GenotypeGVCFs process appears hung.; @nalinigans @mlathara Any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7070#issuecomment-776084422:23,update,update,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7070#issuecomment-776084422,2,['update'],"['update', 'update-workspace-path']"
Deployability,"The user is really eager for this fix to go in, so I told him it will be in the next release (4.1). I hope this is alright.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3528#issuecomment-358781536:85,release,release,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3528#issuecomment-358781536,1,['release'],['release']
Deployability,"The user sent in an update, they found that the argument --min-base-quality-score 25 was the culprit. Because of the default Mutect2 argument --pcr-snv-qual 40, it looks like the base qualities were adjusted to 20 and many were getting filtered out. There still isn't a great explanation though for why this changed with GATK 4.2.0.0 given the [updates](https://github.com/broadinstitute/gatk/releases/tag/4.2.0.0). Any thoughts about what change between 4.1.9.0 and 4.2.0.0 would cause different results @davidbenjamin?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7285#issuecomment-853286706:20,update,update,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7285#issuecomment-853286706,3,"['release', 'update']","['releases', 'update', 'updates']"
Deployability,"The version of `conda` we use on the docker uses environment activation commands that are deprecated in newer versions of conda. Update to the latest published version of miniconda, and update the doc to specify the newer commands. Also change the local environment to use `conda env create -f` rather than `conda env update`. Fixes https://github.com/broadinstitute/gatk/issues/5851 and https://github.com/broadinstitute/gatk/issues/5776.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5866:129,Update,Update,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5866,3,"['Update', 'update']","['Update', 'update']"
Deployability,"The version of dbSNP at the research bundle is 138 for hg19 (updated 8.12.2013), but the latest dbSNP version is 150: [https://www.ncbi.nlm.nih.gov/projects/SNP/snp_summary.cgi?view+summary=view+summary&build_id=150](url) . Is it going to affect my results much if I use 138 instead of 150?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3870:61,update,updated,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3870,1,['update'],['updated']
Deployability,"The warp pipeline tests caught some cases that we apparently didn't have in our integration tests, but now we do!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7670:9,pipeline,pipeline,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7670,2,"['integrat', 'pipeline']","['integration', 'pipeline']"
Deployability,"The workflow for mitochondria will include running `AddOriginalAlignmentTags` on a bam, realigning it to the mitochondria contig only, then running `Mutect2` with `--annotation OriginalAlignment` and `--median-autosomal-coverage` to get the appropriate annotations. Then running `FilterMitochondrialMutectCalls`. . I don't think any of these changes should effect the somatic pipeline. @ldgauthier I didn't change the name of `TLOD` or `tumor sample` in the mitochondria vcf. Maybe we can talk next week about how to best do that?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193:376,pipeline,pipeline,376,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193,1,['pipeline'],['pipeline']
Deployability,"The xbyak ""code is too big"" issue recently started happening on multiple branches (see https://github.com/broadinstitute/gatk/issues/6307), but is intermittent. I'll restart that one. The updated TF I gave you can't be checked in since its OSX specific, and needs additional work to be integrated (see https://github.com/broadinstitute/gatk/issues/6325) so it should be left out for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6330#issuecomment-567055679:188,update,updated,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6330#issuecomment-567055679,2,"['integrat', 'update']","['integrated', 'updated']"
Deployability,Theano version should be 1.0.4. Doesn't have any effect unless trying to install the package manually with pip.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6227:73,install,install,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6227,1,['install'],['install']
Deployability,Then gatk-protected and gatk docker images can specify this one in ``USING``. See gatk-protected scripts/docker for both a deployment script and a Dockerfile that (subset) can be used for a base image.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2457:123,deploy,deployment,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2457,1,['deploy'],['deployment']
Deployability,"Theory from @cmnbroad is below:. ```; I think this is happening because were trying to serialize the class loader sun.misc.Launcher$AppClassLoader), which appears to be reached through the graph by way of via https://github.com/damiencarol/jsr203-hadoop/blob/master/src/main/java/hdfs/jsr203/HadoopFileSystem.java#L82. We probably need to short circuit that with a custom serializer for one of these:. Serialization trace:; classes (sun.misc.Launcher$AppClassLoader); classLoader (org.apache.hadoop.conf.Configuration); conf (org.apache.hadoop.hdfs.DistributedFileSystem); fs (hdfs.jsr203.HadoopFileSystem); hdfs (hdfs.jsr203.HadoopPath); path (htsjdk.samtools.seekablestream.SeekablePathStream); seekableStream (htsjdk.tribble.TribbleIndexedFeatureReader); featureReader (org.broadinstitute.hellbender.engine.FeatureDataSource); featureSources (org.broadinstitute.hellbender.engine.FeatureManager). See, for instance, dbpedia/distributed-extraction-framework#9.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6730#issuecomment-671508579:504,Configurat,Configuration,504,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730#issuecomment-671508579,1,['Configurat'],['Configuration']
Deployability,"There appears to be a memory leak in gCNV coming from Theano 0.9.0, possibly fixed in https://github.com/Theano/Theano/pull/5832. A few possible fixes:. 1) Update Theano to the latest 1.0.4 version. I've tried this and it looks like the leak goes away. Need to confirm reproducibility of results between versions, see also #5730.; 2) Configure Theano 0.9.0 to use MKL, rather than OpenBLAS. It appears the leak is only an issue with the latter. This is a little more complicated, since I now realize that MKL is not actually fully utilized (if at all) in our conda environment. For example, we `pip install numpy`, rather than `conda install` a version from the `default` channel that is compiled against MKL. So we'd need to change a few dependencies in the environment which might have implications for VQSR-CNN. See also #4074. @lucidtronix any thoughts? @jamesemery and @cmnbroad might also be interested, as this could have pretty drastic implications for the size of the python dependencies---if we go with option 1, we might be able to get rid of MKL, etc. Not sure if the memory leak manifests the same across all architectures. Note that I believe this is a separate issue from #5714.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5764:156,Update,Update,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5764,3,"['Update', 'install']","['Update', 'install']"
Deployability,"There are 4 separate commits:; - Upgrade to Barclay 2.0.0 and Picard 2.17.2.; - Changes for CommandLinePluginDescriptor updates (required for the Barclay upgrade); - Updates for Experimental tag (dependent on Barclay upgrade).; - Remove placeholder and obsolete program groups - Part 1 (dependent on Picard upgrade).There are still 3 obsolete program groups (ReadProgramGroup, VariantProgramGroup, and SparkProgramGroup) who's tools need to be redistributed to the new program groups. But thats can be a separate PR since it will be a lot of files.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4070:33,Upgrade,Upgrade,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4070,6,"['Update', 'Upgrade', 'update', 'upgrade']","['Updates', 'Upgrade', 'updates', 'upgrade']"
Deployability,There are a few other performance fixes for SelectVariants coming in the next release of GATK as well. We discovered a number of really pathologically cases that we are fixing bu haven't released yet.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6446#issuecomment-680118909:78,release,release,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6446#issuecomment-680118909,2,['release'],"['release', 'released']"
Deployability,There are a few other prs I want in in htsjdk first but we can do a release whenever really.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6602#issuecomment-642126649:68,release,release,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6602#issuecomment-642126649,1,['release'],['release']
Deployability,"There are a few problems with IntegrationTestSpec that surface when adding CRAM tests to the Reads/BQSRSparkPipelines:; - generated output filenames contain no sam extension, so outputs always are treated as .bam; - it doesn't have explicit knowledge of the reference file, which is needed to do proper file comparisons through the SamAssertionUtils assertSamsEqual methods; - there is code that assumes that any expectedFile that doesn't end in "".bam"" should use text comparison. We could fix these, but I'm not sure what the incremental value-added of this class is when we can just use TestNG for expected exceptions, etc.; it might make more sense to just eliminate this style of test completely.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1562:30,Integrat,IntegrationTestSpec,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1562,1,['Integrat'],['IntegrationTestSpec']
Deployability,There are a lot of sites where a `ReferenceSequenceFile` is created only to load a sequence dictionary from it. These should be replaced with calls to `ReferenceUtils.loadFastaDictionary()`. There may be updates that can be made to `ReferenceUtils` that make use of new methods in `ReferenceSequenceFileFactory`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5180:204,update,updates,204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5180,1,['update'],['updates']
Deployability,"There are a number of GATK code paths that check to ensure that a reference is provided whenever a CRAM input is provided. Since htsjdk now accepts both embedded reference and reference-less (no reference compression) CRAMs, these checks should be removed once we update htsjdk. The CRAM code will defer accessing the reference until one is actually required, and will fail gracefully in the case where it is not provided.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6541:264,update,update,264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6541,1,['update'],['update']
Deployability,"There are no Java code changes in this PR. Tests were done manually. As a reminder, the modified files are still considered experimental. Changes:; - combine_tracks.wdl: Fixes bug where string was compared to a float. Closes #5284 ; - combine_tracks.wdl: Converts the processed seg file into a format for GISTIC2. This is a trivial conversion. Closes #5283 ; - Other changes in `aggregate_combine_tracks.wdl` to support the above, including aggregation of individual GISTIC2 seg files into a single GISTIC2 seg file.; - Added gs urls for necessary auxiliary files in the documentation.; - Added multiple output types for the ABSOLUTE skew parameter to support heterogeneous execution configurations. File, Float, and String. All are the same value.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5287:684,configurat,configurations,684,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5287,1,['configurat'],['configurations']
Deployability,"There are no error messages.; The process was interrupted without any error messages.; I attached the screenshot.; I attached chr14 variant calling (completed) and chr14 variant calling; (interrupted).; In the system monitor, when I am using GATK 4.6.0.0., they are eating up; memory continuously.; When they are reaching up to 512Gb, the process was interrupted.; I tried to run this process on only 2-3 chromosomes, and I found that the; process was completed on chr 14, and the process was interrupted on the; rest of two chromosomes (interval -L).; So I rolled back to GATK 4.5.0.0, the process was normal. I can do; GenotypeGVCFs command entire chromosome simultaneously. My machine has 512Gb memory and 64 cores (5995wx AMD threadripper) dell; 7865 workstation.; Thanks; Jinu Han. On Fri, Jul 19, 2024 at 12:08 AM Gökalp Çelik ***@***.***>; wrote:. > Can you provide your logs that shows the error message?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2236819113>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AG7IXWWGPB73BXPN4Z5E4VTZM7LAFAVCNFSM6AAAAABLBRETECVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMZWHAYTSMJRGM>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2238806751:284,continuous,continuously,284,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2238806751,1,['continuous'],['continuously']
Deployability,There are none as of yet @ldgauthier. What we do have are WDL-ized pipelines that we will follow at https://github.com/gatk-workflows.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3769#issuecomment-349745378:67,pipeline,pipelines,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769#issuecomment-349745378,1,['pipeline'],['pipelines']
Deployability,"There are quite a few v2.1 CRAM test files being used in GATK that should probably be regenerated and replaced with v3.0 files. There are also quite a few CRAM test files floating around in both htsjdk and GATK that have external blocks with content ID=0 (not valid per the spec) and some of those blocks have no actual content:. gatk/src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/print_reads.sorted.queryname.htsjdk-2.1.0.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.bqsr.pipeline.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/validation/single.read.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/validation/another.single.read.cram. These have external blocks with ID=0, but the blocks have no actual content:. gatk/src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram (0 bytes); gatk/src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram (0 bytes). We should regenerate and replace with v3.0 CRAM files.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6018:928,pipeline,pipeline,928,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6018,2,['pipeline'],['pipeline']
Deployability,"There are several cases where ValidateVariants does no actual validation, and issues no warning message. This includes the default case, where the minimal set of required args is provided (these are examples from the doc, which should be updated when this is fixed): . `gatk ValidateVariants -V some.vcf`; `gatk ValidateVariants -V some.vcf -R some.fasta`. Either of these silently results in no validation and no warning message, despite the entire VCF being decoded and traversed, because the default validation type is ""ALL"", which includes validation type ""IDS"". But IDS requires a dbsnp arg, and none was provided, so the code short-circuits out. The default case should probably do whatever validation it can, but at a minimum a warning should be logged. Ironically, if you provide an exclusion on the command line via `--validation-type-to-exclude IDS`, then validation is done. Another no-op case is `--validation-type-to-exclude ALL` (also recommended in the doc), which also should probably be rejected, or at least logged, since it silently does no validation and reports no errors. This tripped up [this user](https://github.com/samtools/htsjdk/issues/1117), and resulted in a downstream BCF issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5862:238,update,updated,238,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862,1,['update'],['updated']
Deployability,"There are too many WDL conventions that work in cromwell 29 and not in 30. Therefore, time to upgrade.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4418:94,upgrade,upgrade,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4418,1,['upgrade'],['upgrade']
Deployability,"There are two commits. The first one factores out code that can be shared between the R and Python executors, along with a few opportunistic changes in existing tests that have bad names. The second has a simple PythonScriptExecutor in the spirit of the RScriptExecutor, along with unit tests, and an example tool and integration test. First pass for https://github.com/broadinstitute/gatk/issues/3501.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3536:318,integrat,integration,318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3536,1,['integrat'],['integration']
Deployability,There haven't been any comments here for about 3 years. Have there been any updates in a separate thread or offline? Is there any hope there may be any eventually?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-1126334162:76,update,updates,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-1126334162,1,['update'],['updates']
Deployability,"There is GATK3 unit and integration test and could port them. BTW, I don't seen a VF unit test. I also looked at the GATK4 code an would expect the same problem would occur.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2301#issuecomment-265794458:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2301#issuecomment-265794458,1,['integrat'],['integration']
Deployability,There is a copy of the 4.1.0.0 pipeline here: https://app.terra.bio/#workspaces/help-gatk/Mitochondria-SNPs-Indels-hg38. We are working on some adjustments to this pipeline to make the low allele fraction calls more reliable with more aggressive filtering and we will put those updates in that same location once they're complete.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-488790341:31,pipeline,pipeline,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-488790341,3,"['pipeline', 'update']","['pipeline', 'updates']"
Deployability,There is a initial release of the faster and more accurate replacement for Hadoop-Bam at:. https://github.com/disq-bio/disq. It would be great to see faster reading of crams in spark GATK with this. Any plans for testing this release?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-436014646:19,release,release,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-436014646,2,['release'],['release']
Deployability,There is a new vulnerability released https://nvd.nist.gov/vuln/detail/CVE-2022-42889#vulnCurrentDescriptionTitle and exploitable as documented in the NIST DB. . A quick scan of the GATK jar shows it ships Apache Commons 1.6 (class location in the jar: /org/apache/commons/text/lookup/). Could you please confirm if the GATK is impacted by this issue and a plan to fix this? . Thanks,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8060:29,release,released,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8060,1,['release'],['released']
Deployability,"There is a potential fix for the ""next on empty iterator"" error in PR #6652 -- this should be part of the next GATK release, and may enable us to close this ticket.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6319#issuecomment-664566481:116,release,release,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6319#issuecomment-664566481,1,['release'],['release']
Deployability,"There is a video recording of Chris L saying so. I’ll get the link to it in a bit. Better yet, I'd like to hear about updates to these plans in person. Sent from an iPhone and typed with my thumbs. . > On May 25, 2018, at 9:18 AM, Lee Lichtenstein <notifications@github.com> wrote:; > ; > @sooheelee I just confirmed that is not the case. Have not confirmed the exact change yet.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-392064633:118,update,updates,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-392064633,1,['update'],['updates']
Deployability,"There is an existing method in GATKTool called getHeaderForSAMWriter that creates and populates the PG record, and it's called by GATKTool.createSAMWriter, so we already do this for BAMs that are created that way (which excludes the Picard tools). We should probably fix MarkDuplicates though. HaplotypeCaller and Mutect2 use HaplotypBAMWriter/SAMFileDestination/HaplotypeBAMDestination, all of which live in gatk, but create their own writers directly, so they need to be updated (and could probably be simplified a bit). We need a similar method for vcf header lines.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2269#issuecomment-278370291:473,update,updated,473,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2269#issuecomment-278370291,2,['update'],['updated']
Deployability,"There is an issue in with gcloud 208.0.0 that prevents the `gcloud dataproc` commands from functioning. We should temporarily pin our version to 207.0.0 instead until the problem can be addressed by google. . ```; Customers affected by this issue are using gcloud version 208.0.0 and may experience an error like ""Problem loading gcloud.dataproc.clusters.create: No module named jsonschema."" when interacting with Google Cloud Dataproc.; Workaround; The workaround is to use gcloud version 207.0.0, a downgrade from 208.0.0 can be done by issuing the command: ""gcloud components update --version 207.0.0"". If installed via apt: sudo apt-get update && sudo apt-get install google-cloud-sdk=207.0.0-0. If installed via yum: sudo yum downgrade google-cloud-sdk-207.0.0; ```. We have to remember to unpin it afterward the problem is fixed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5003:579,update,update,579,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5003,5,"['install', 'update']","['install', 'installed', 'update']"
Deployability,"There is currently one failing integration test:. ```; completedicsdb.GenomicsDBImportIntegrationTest.testGenomicsDBImportFileInputsAgainstCombineGVCFWithMultipleIntervals FAILED; java.lang.AssertionError: actual is longer than expected with at least one additional element: [VC null @ chr20:17970000 Q. of type=SYMBOLIC alleles=[G*, <NON_REF>] attr={} GT=htsjdk.variant.bcf2.BCF2Codec$LazyData@134b79ab filters=; at org.testng.Assert.fail(Assert.java:93); at org.broadinstitute.hellbender.utils.test.BaseTest.assertCondition(BaseTest.java:395); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.lambda$checkGenomicsDBAgainstExpected$8(GenomicsDBImportIntegrationTest.java:326); at java.util.ArrayList.forEach(ArrayList.java:1249); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:319); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testGenomicsDBAgainstCombineGVCFs(GenomicsDBImportIntegrationTest.java:166); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testGenomicsDBImportFileInputsAgainstCombineGVCFWithMultipleIntervals(GenomicsDBImportIntegrationTest.java:107); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-386368519:31,integrat,integration,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-386368519,1,['integrat'],['integration']
Deployability,"There is now no deprecated code in hellbender. This is probably a good way to start a new project. Closes #162 . I had to update `MergeBamAlignmentIntegrationTest` to remove references to a deprecated parameter, so I also fixed most of intellij's style complaints on it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/228:122,update,update,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/228,1,['update'],['update']
Deployability,There needs to be a validation tool for data sources to ensure that they conform to their formats properly. This tool is envisioned to be run just prior to data source release to fix any silent errors.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4380:168,release,release,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4380,1,['release'],['release']
Deployability,"There seems to be no obvious way to read thru the unmapped read pairs in a bam file in Spark. Looking at the code in ```ReadSparkSource#getParallelReads(String, String, List, long)``` it seems that ; perhaps it is possible by setting the appropriate property in Configuration returned by ```ctx.hadoopConfiguration()``` however there is no documentation as to what property that could be. . @droazen I assign it to you initially so that you route it to whoever might be most suited to address this issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2572:262,Configurat,Configuration,262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2572,1,['Configurat'],['Configuration']
Deployability,"There was a confirmed performance regression in `BaseRecalibratorSpark` just before the 4.0 release: https://github.com/broadinstitute/gatk/issues/4376. I suspect that's what's responsible for the results reported above. Until this is patched (most likely in the next GATK release), I'd recommend running the regular `BaseRecalibrator` instead of the spark version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4300#issuecomment-365991967:92,release,release,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4300#issuecomment-365991967,3,"['patch', 'release']","['patched', 'release']"
Deployability,"There were a couple of things I needed to do to get the new Spark code running on a cluster:. i. Go back to using Spark's version of Kryo. Using a different version of Kryo is not actually needed (2.21 used by Spark passes the tests), and actually caused errors on the cluster when run with `--conf spark.driver.userClassPathFirst=true` (which is needed to avoid other library conflicts, like with jopt-simple). ii. Exclude Spark from the JAR file to avoid library conflicts. It's normal to exclude Spark and Hadoop from JAR files since they are supplied by `spark-submit`. Since Gradle doesn't have a 'provided' dependency (see https://github.com/broadinstitute/hellbender/issues/836), I had to do a bit of a workaround with the `shadowJar` target, which is now `sparkJar`. . Here's the command I ran:. ``` bash; NAMENODE=...; SPARK_MASTER=yarn-client; HELLBENDER_HOME=...; spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ReadsPipelineSpark \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/spark-reads-pipeline \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --baseRecalibrationKnownVariants $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/882:1244,pipeline,pipeline,1244,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/882,1,['pipeline'],['pipeline']
Deployability,There were a few dead links in the GATK to http://gatkforums.broadinstitute.org/gatk/discussion/58/companion-utilities-reordersam which is still archived here: https://web.archive.org/web/20160720131152/http://gatkforums.broadinstitute.org/gatk/discussion/58/companion-utilities-reordersam. We should write a new short technical article here: https://gatk.broadinstitute.org/hc/en-us/sections/360007134392-Glossary preserving the knowledge about sort ordering and update the remaining two links in our error messages to be current with that.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8272:464,update,update,464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8272,1,['update'],['update']
Deployability,"There were other tests that checked the existing behavior. Either update those tests with the new behavior, or possibly create a new argument for exclusion padding. That would be more expressive than the newly introduced behavior that makes it impossible to represent certain intervals at all when you have padding specified.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2105#issuecomment-241122870:66,update,update,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2105#issuecomment-241122870,1,['update'],['update']
Deployability,"There's a new [small library for bam reading](https://github.com/hammerlab/spark-bam) from hammer lab that is designed to fix problems in the bam splitting. It sounds promising from they've posted. We've been patching these problems in a very ad-hoc way as we discover them, but they've done a systematic survey to identify them. They also claim it's substantially faster. It's currently missing some important features, like selecting by interval. ; We should investigate if they're performance gains bear out in pratice, and if so if:; 1. We want to use the new library for bam reading; 2. We want to back port their changes to hadoop-bam",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3993:209,patch,patching,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3993,1,['patch'],['patching']
Deployability,"There's a small set of tools that only outputs their results to stdout, making it difficult to use the output in a pipeline/script. This PR adds a way to output simple results from such tools to an (optional) output file. I Added this option to the following tools:; - CountBases; - CountBasesInReference; - CountReads; - CountVariants; - FlagStat. Other tools that might benefit from this (but it will require an API change, so I didn't do it):; - CompareIntervalLists; - ValidateVariants",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7072:115,pipeline,pipeline,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7072,1,['pipeline'],['pipeline']
Deployability,"There's code in the SV pipeline that does exactly this: it takes a pass on the BAM to determine fragment length statistics, and then takes another pass to determine bins that have significantly deviant statistics. Seems to work pretty well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4713#issuecomment-385056876:23,pipeline,pipeline,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4713#issuecomment-385056876,1,['pipeline'],['pipeline']
Deployability,"There's currently no check that the version of `gcloud` that's installed is compatible with the version of gatk-launch, the task here is to:; 1. determine which versions of gcloud are compatible with us; 2. add a check and a helpful warning if the system gcloud is out of date in a way which will cause problems",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3649#issuecomment-333633169:63,install,installed,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3649#issuecomment-333633169,1,['install'],['installed']
Deployability,There's some bad input in the BQSR test; update the input validation test to make sure it can find reads that are malformed in that way.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/557:41,update,update,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/557,1,['update'],['update']
Deployability,"There's some good stuff here that I don't want to lose, but it won't work in the pipeline in its current form. I'm going to close the PR, but let's keep the branch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5132#issuecomment-729911578:81,pipeline,pipeline,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5132#issuecomment-729911578,1,['pipeline'],['pipeline']
Deployability,"These are a bunch of random, mostly just annoying things that I repeatedly encountered during the Java 17 port that we should look into. . **Log Spam Issues:** (these result in lots of error log spam that make the logs super hard to scan when there is a failure):. - The WDL test logs are riddled with “localization by hard link failed” and ""Docker not found"" failures, which makes it hard to scan them for real failures. Can we eliminate/fix these ?; - The logs have a few gradle task dependency warnings - we should hunt down the cause. ; - We routinely pull ~800 branches every time we run git clone for a CI job. Can we do shallow git clones?; - We're using deprecated gradle features that result in warnings in the logs, these should be updated.; - The test runner seems to serialize (via toString) every argument to every test method. Many of these have *huge* ""toString"" representations (i.e., `org.broadinstitute.hellbender.tools.spark.sv.integration.ExtractOriginalAlignmentRecordsByNameSparkIntegrationTest`) that fill the logs with reams of huge test values. We should codify/unify the test case wrapper class that we use in htsjdk for these cases. . **Other Issues:**. - We should review the shadowJar contents - it includes some surprising stuff (i.e., the publish-picard.sh script we use to publish picard).; - Do we still need the unpacktestjar task in `dockertest.gradle`, to work around testNG inability to find tests in a jar ?; - The test matrix job names all look the same in the github UI because only the first N characters are displayed, and they all have the same prefix. We should rename them so they start with unique prefixes.; - The library it.unimi.dsi:fastutil:7.0.61 appears to not be used [Fix] (reported in IntelliJ/Project Structure/Problems).; - It's non-intuitive that the *Dockerfile* builds the `run_unit_tests.sh` script. Is that necessary - can this not be built on demand ? Also, it should be named to run_tests.sh, since it doesn't run unit tests, but rather ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8087:742,update,updated,742,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8087,2,"['integrat', 'update']","['integration', 'updated']"
Deployability,"These are changes we made in order to get the NeuralNetInference branch integration tests to pass, and some example program updates..",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4218:72,integrat,integration,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4218,2,"['integrat', 'update']","['integration', 'updates']"
Deployability,"These are count files containing counts simulated according to the gCNV model, and are used as the primary inputs to generate the rest of the test files downstream. The dictionary is fictional and immaterial, so long as it is carried forward consistently from the count files to downstream outputs (which the tools do automatically). You could pretend that we started with simulated BAMs that were all aligned w.r.t. this fictional reference/dictionary. (It's just more work to simulate at the BAM level, which is why we start with the counts; simulating BAMs would also not increase test coverage in any meaningful way.). There are already a number of checks to guarantee dictionary consistency, but as you can see from that issue, there are a few scenarios where dictionaries from intervals might not be available via the engine. I don't think there should be a need to provide or check against external references/dictionaries at downstream steps; see point 4 in https://github.com/broadinstitute/gatk/issues/6924#issuecomment-719576249 about reverting the code change to allow external dictionaries in PostprocessGermlineCNVCalls. If you like, you can switch the dictionaries in the test files to something real/canonical, but I would still revert the code change. Again, I'm not sure if there was some additional context that I'm missing---e.g., is there some big analysis going on where they need to override sequence dictionaries and/or checks due to mismatched dictionaries in the BAMs? If so, could this be addressed with e.g. UpdateVcfSequenceDictionary or some other solution?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6957#issuecomment-726967714:1536,Update,UpdateVcfSequenceDictionary,1536,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6957#issuecomment-726967714,1,['Update'],['UpdateVcfSequenceDictionary']
Deployability,"These are failing with:. ```; Error: (converted from warning) unable to access index for repository http://lib.stat.cmu.edu/R/CRAN/src/contrib; Execution halted; The command ""if [[ $TEST_DOCKER != true ]]; then sudo mkdir -p /usr/local/lib/R/; sudo mkdir -p site-library; sudo ln -sFv ~/site-library /usr/local/lib/R/site-library; sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9; sudo add-apt-repository ""deb http://cran.rstudio.com/bin/linux/ubuntu trusty/""; sudo apt-get update; sudo apt-get install -y --force-yes r-base-dev=3.1.3-1trusty; sudo apt-get install -y --force-yes r-base-core=3.1.3-1trusty; sudo Rscript scripts/docker/gatkbase/install_R_packages.R; fi;"" failed and exited with 1 during; ```; which has nothing to do with the PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5595#issuecomment-456911203:528,update,update,528,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5595#issuecomment-456911203,3,"['install', 'update']","['install', 'update']"
Deployability,"These changes add arguments specific to the update from GATK 4.5.0.0 -> 4.6.0.0 that special case sites that were flagged previously in the WARP tests. Most of the sites that can now be skipped are based on the no call changes that were expected with this update to JointCalling and ReblockGVCFs. There are also some small changes to HaplotypeCaller at low quality sites that are then dropped by ReblockGVCFs. Additionally there were some expected changes to the Ultima pipelines in HaplotypeCaller and JointCalling which can now be skipped by the VcfComparator tool. Finally if AD is 0 for non-ref reads (which can happen with DRAGEN input), then AS_QD has jitter added which is now accounted for.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8973:44,update,update,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8973,3,"['pipeline', 'update']","['pipelines', 'update']"
Deployability,These initial results suggest that the savings from a pure-Spark pipeline are in the 15-30% range. @tomwhite Do you attribute these savings mostly to avoiding writing/reading intermediate outputs?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3395#issuecomment-341788281:65,pipeline,pipeline,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3395#issuecomment-341788281,1,['pipeline'],['pipeline']
Deployability,These need to be updated to use `gatk` instead of `gatk-launch` and kebob case arguments.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4076:17,update,updated,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4076,1,['update'],['updated']
Deployability,"They now take about the same time, we avoid paying the cost of R installation but pay a cost to build the docker instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2965#issuecomment-349742450:65,install,installation,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2965#issuecomment-349742450,1,['install'],['installation']
Deployability,"They're public, so just install Google Cloud gsutil and copy with `gsutil cp gs://gatk-best-practices/somatic-b37/Mutect2-exome-panel.vcf <local path to copy to>`. Or, if you're running on the cloud, you don't even need to download anything, just run Mutect2 with the cloud paths eg ; ```; gatk Mutect2 -R ref.fasta -I tumor.bam -pon gs://gatk-best-practices/somatic-b37/Mutect2-exome-panel.vcf -O calls.vcf; ```; If you install gsutil this works when running locally as well, but for speed I would recommend downloading the pon. > Is there a reason this is not in the GATK resource bundle?. Not that I can think of.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-481919351:24,install,install,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-481919351,2,['install'],['install']
Deployability,"They've patched the warning message to be an info message instead, but I think it will still show a stacktrace since info is our standard level.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5220#issuecomment-426729414:8,patch,patched,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5220#issuecomment-426729414,1,['patch'],['patched']
Deployability,"Think it might be worth saving a VariantFiltration pass for the bit of code it'd take, but up to you!. ScoreVariantAnnotations will output both the raw ""VQSLOD"" score and the converted sensitivity, so we're free to specify thresholds on either. However, given that different types of models may have scores in different ranges (e.g., BGMM vs. IsolationForest, positive/negative vs. positive-only, etc.), I think it's better to restrict all command-line options to be expressed in terms of a sensitivity. Same thing goes if you decide to filter externally with VariantFiltration for now. Even though you have both quantities available to you, just use the sensitivity. This brings us to questions related to whether we want to keep the old VQSR requirements of having both training and truth sets specified. For example, we could instead drop the distinction between training and truth for the new tools, and always calibrate sensitivity to the training set (you can essentially force this behavior with the current code by specifying training=true,truth=true for all of your resources). And yes, all of the tools should have a variety of command lines in the tests to demonstrate behavior. If you want to explore positive/negative mode, take a look at the *Unlabeled tests. Also feel free to ping me if anything isn't clear!. I'll push another round of minor updates here, too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069376523:1359,update,updates,1359,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069376523,2,['update'],['updates']
Deployability,"This PR Modifies the GvsCreateVDS wdl to no longer store the values for 'yng_status' in the VDS. The field is still used to calculate filtering at the genotype level, but not stored after that. - Example run of GvsCreateVDS [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/e4e9905b-c967-4ced-9c02-41a3117eac84); - Passing integratino test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f6929247-1787-4ff7-b4f0-e367b0652ac8)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8861:365,integrat,integratino,365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8861,1,['integrat'],['integratino']
Deployability,"This PR addresses some issues with tracking of sample loading in GVSImportGenomes.; 1) Due to a bug (unresolved as yet) where the status 'STARTED' can be written to sample_load_status multiple times, the method LoadStatus.getSampleLoadState would NEVER return COMPLETE. This PR fixes the logic to allow for the (unexpected) case of multiple 'STARTED' statuses.; 2) I have modified the SetIsLoadedColumn task in GVSImportGenomes to explicitly look for sample_load_status records with both STARTED and FINISHED to use to update sample_info.is_loaded to true.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8052:519,update,update,519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8052,1,['update'],['update']
Deployability,"This PR adds a task to GvsAssignIds to verify that there are no duplicate sample names in the file provided. [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/af6651c5-37e1-48b6-8514-9c0d326dfc6f) is an example run of BulkIngest that replicates the original reported problem. No sample set provided, the sample id column is not sample_id and there's a duplicate in THAT column.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/25dc14df-c6e5-4710-b9b8-67b04906bc78) is an example run where the updated code runs and reports the problem early-ish without creating database tables that need to be cleaned up.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/b29d3eea-8330-4645-88fe-62bbf3b865bf) is a normal run that passes (same basic idea as the initial problem, except that I removed the duplicate row from the samples table. [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/82098882-8b57-4fe6-ad23-69963c3466f6) is a passing integration test.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8818:579,update,updated,579,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8818,2,"['integrat', 'update']","['integration', 'updated']"
Deployability,This PR adds an integration test for Exomes.; It also adds an optional input to the test to allow you to use the default dockers (and NOT build the gatk override jar) if you so desire. Passing Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/e16edc16-92a7-4a52-834a-1b45e1a2f92c).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8433:16,integrat,integration,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8433,2,"['Integrat', 'integrat']","['Integration', 'integration']"
Deployability,"This PR adds segments VCF writing to `PostprocessGermlineCNVCalls`. Segmentation (Viterbi) and segment quality calculation are performed by `gcnvkernel`. This PR introduces the following additional features:; - Calls and model shards are not required to be provided in sorted order anymore; - The user can specify the ref copy-number state for autosomal contigs, as well as allosomal contigs; - For both intervals and segments VCF output: now we use either `<DUP>` or `<DEL>` alleles (in place of `CN_x` alleles), depending on whether the most likely copy-number call is below or above the ; contig baseline. The contig baseline state is whatever the user has specified for autosomal contigs, and the contig ploidy state on sex chromosomes (from the output of `DetermineGermlineContigPloidy`).; - Fail-fast validations and better test coverage; - Updated cohort and case WDL scripts and WDL tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4396:847,Update,Updated,847,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4396,1,['Update'],['Updated']
Deployability,"This PR adds the 'SCORE' field as an output in the VQSR-Lite derived VCFs; Score is the value from which the `CALIBRATION_SENSITIVITY` is derived. The latter is what we use for filtering based on sensitivity, but Sam and Laura also want the SCORE stored in the VCF. Passing Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/721bc470-a968-4fe4-9be3-a1ddddc9a792)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8423:274,Integrat,Integration,274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8423,1,['Integrat'],['Integration']
Deployability,"This PR allows the extract process to read ploidy information from an optional table and use it when writing out reference data. This code does NOT create that table. In the absence of such data, it will do nothing and behave like before (assuming a ploidy of 2 at all sites and expanding the reference data accordingly). Quickstart extract WITHOUT ploidy table specified:https://app.terra.bio/#workspaces/gvs-dev/GVS%20Tiny%20Quickstart%20hatcher/job_history/fcc47f3f-080c-41f3-9847-0dd1487ef39c. Quickstart extract WITH ploidy table specified: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Tiny%20Quickstart%20hatcher/job_history/2d608711-758f-47d2-ab54-ae825293e4a9. Successful integration run for verifying backwards compatibility: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/d30c9db9-bdeb-4ff7-a236-3d3078258d06. The ploidy table used was based on quickstart data, but had data for samples 5, 9, and 10 manually updated to haploid. This will produce a INCORRECT vcf, inasmuch as it will reflect a mismatch in ploidy between the variant and ref data. But it allows us to see that, when the table is specified, it does in fact use it for writing out the ref data. As expected, shards 0-21 are identical with the only changes being on shards 22 and 23, and with diffs of this form:. ```25106c25106; < chrX	2800975	.	C	CA	.	.	AC=2;AF=0.250;AN=8;AS_QUALapprox=0|108;CALIBRATION_SENSITIVITY=0.9621;QUALapprox=81;SCORE=-0.5449	GT:AD:GQ:RGQ	./.	./.	./.	./.	0/0:.:30	./.	0/0:.:30	0/1:8,3:27:27	./.	0/1:6,5:80:81; ---; > chrX	2800975	.	C	CA	.	.	AC=2;AF=0.286;AN=7;AS_QUALapprox=0|108;CALIBRATION_SENSITIVITY=0.9621;QUALapprox=81;SCORE=-0.5449	GT:AD:GQ:RGQ	./.	./.	./.	./.	0/0:.:30	./.	0:.:30	0/1:8,3:27:27	./.	0/1:6,5:80:81; 25122c25122; < chrX	2805509	.	C	T	.	.	AC=1;AF=0.100;AN=10;AS_QUALapprox=0|360;CALIBRATION_SENSITIVITY=0.8769;QUALapprox=360;SCORE=-0.4865	GT:AD:GQ:RGQ	0/0:.:30	./.	./.	./.	./.	0/0:.:20	0/0:.:30	0/1:14,13:99:360	0/0:.:30	./.; ---; > chrX	2805509	.	C	T	",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8857:683,integrat,integration,683,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8857,2,"['integrat', 'update']","['integration', 'updated']"
Deployability,This PR builds off @lbergelson's `lb_add_header_line_to_genomicsdbimport` branch and fixes:. - [3677](https://github.com/broadinstitute/gatk/issues/3677); - Increments GenomicsDB release to 0.8.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3994:179,release,release,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3994,1,['release'],['release']
Deployability,"This PR changes GvsExtractCallset to optionally pad the output VCFs with a leading zero. They are named in a similar fashion to the (also optionally renamed) interval list shards. If the input `zero_pad_output_vcf_filenames` is set to **true** (the default) the VCFs and interval files will be named as such:; - 0000000000-gg_filterset.vcf.gz; - 0000000000-gg_filterset.vcf.gz.tbi; - 0000000000-gg_filterset.vcf.gz.interval_list; - 0000000001-gg_filterset.vcf.gz; - 0000000001-gg_filterset.vcf.gz.tbi; - 0000000001-gg_filterset.vcf.gz.interval_list; - ... An example workflow is [here](https://app.terra.bio/#workspaces/warp-pipelines/ggrant%20-%20GVS%20Quickstart%20V2%20copy/job_history/3d3fc1e4-7f83-40d7-8f8c-115d4a4de158). If the input `zero_pad_output_vcf_filenames` is set to **false**, the workflow will name things as it has in the past:; - gg_filterset_0.vcf.gz; - gg_filterset_0.vcf.gz.tbi; - 0000000000-scattered.interval_list; - gg_filterset_1.vcf.gz; - gg_filterset_1.vcf.gz.tbi; - 0000000001-scattered.interval_list; - ... An example workflow is [here](https://app.terra.bio/#workspaces/warp-pipelines/ggrant%20-%20GVS%20Quickstart%20V2%20copy/job_history/27bd9b06-4400-4db1-89b4-4bdb5856aaff)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7783:625,pipeline,pipelines,625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7783,2,['pipeline'],['pipelines']
Deployability,"This PR contains several distinct modifications necessary to protect our pipeline against errors when a location is specified on a BQ dataset. 1. modifying several WDLs that used the BQ CLI that specified ""--location=US"" Turns out, it is unnecessary and breaks things when the location is not US; 2. modifying two paths through BigQueryUtils to harden against non-""US"" locations, including explicitly passing in the dataset id to getQueryCostBytesProcessedEstimate so its location can be looked up and passed into the dry run job; 3. cutting our reliance on bqutil to be installed in the location in which our queries run by supplying a local version of ""median"" as a UDF (as udf_media.sql pulled in through changes to BigQueryUtils.java and referenced in feature_extract.sl). Only partially related, this PR also contains the creation of the script/variantstore/utils directory to hold useful scripts, and the useful pushGATKtoGCS script for pushing jars to an easily-referenced location for WDLs (h/t to Miguel). The entire tragic history of successes and failures can be seen in the job history of the workspace https://app.terra.bio/#workspaces/gvs-dev/GVS%20Tiny%20Quickstart%20hatcher/job_history. Every stage of the quickstart can be verified within to--eventually and only after the gods deemed my suffering sufficient--have passed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8047#issuecomment-1270126312:73,pipeline,pipeline,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8047#issuecomment-1270126312,2,"['install', 'pipeline']","['installed', 'pipeline']"
Deployability,This PR contains the GATK code necessary to enable some features present in the recent GenomicsDB update:; - Fixes https://github.com/broadinstitute/gatk/issues/7222; - Adds tests for https://github.com/broadinstitute/gatk/issues/7089; - Fixed an issue identified by @kcibul where the combine operation for certain fields needs to take care to not remap missing fields to NON_REF,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7257:98,update,update,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7257,1,['update'],['update']
Deployability,"This PR converts the Mutect2Filtering engine to be allele specific. This required changes to SomaticClusteringModel and ThresholdCalculator as well as ErrorProbabilities and of course the filters themselves. There are some filters which have not yet been converted, but I am prioritizing the ones in this PR for Sarah Calvo and the mitochondria pipeline. This provides the implementation for dsp-spec-ops tickets 166, 168, 169",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399:345,pipeline,pipeline,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399,1,['pipeline'],['pipeline']
Deployability,"This PR creates a tool for generating split read and paired end SV evidence files from an input WGS CRAM or BAM file for use in the GATK-SV pipeline. This tool emulates the behavior of `svtk collect-pesr`, which is the tool used in the current version of the pipeline. Briefly, it creates two tab-delimited, tabix-able output files. The first stores information about discordant read pairs -- the positions and orientations of a read and its mate, for each read pair marked ""not properly paired"" in the input file. Records are reported only for the upstream read in the pair. The second file contains the locations of all soft clips in the input file, including the coordinate and ""direction"" (right or left clipping) and the count of the number of reads clipped at that position and direction. The integration test expected results file was generated using `svtk collect-pesr` to help ensure that the results are identical. We hope to eventually replace this component of the SV pipeline with this GATK tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6356:140,pipeline,pipeline,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6356,4,"['integrat', 'pipeline']","['integration', 'pipeline']"
Deployability,"This PR deals with long reads with exactly two alignments (no other equally good alignment configuration), mapped to ; * the same chromosome with reference order switch but without strand switch, or; * different chromosomes. This brings us (unfiltered) ~6000 mated BND records, half of which are on canonical chromosomes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3571:91,configurat,configuration,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3571,1,['configurat'],['configuration']
Deployability,"This PR deals with long reads with exactly two alignments (no other equally good alignment configuration), mapped to the same chromosome with strand switch, but NOT significantly overlapping each other. We used to call inversions from such alignments, but it is more appropriate to emit BND records because a lot of times such signal is actually generated from inverted segmental duplications, or simply inverted mobile element insertions. To confidently interpret and distinguish between such events, we need other types of evidence, and is better to be dealt with downstream logic units. Inverted duplications are NOT dealt with in this PR and is going to be in the next. NEEDS TO WAIT UNTIL PART 1 & 2 ARE IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3457:91,configurat,configuration,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3457,1,['configurat'],['configuration']
Deployability,"This PR deals with long reads with exactly two alignments (no other equally good alignment configuration), mapped to the same chromosome with strand switch, significantly overlapping each other on their reference spans. We used to call inversions from such alignments when feasible, but it is more appropriate to emit inverted duplication records. NEEDS TO WAIT UNTIL PARTS 1, 2 AND 3 ARE IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3464:91,configurat,configuration,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3464,1,['configurat'],['configuration']
Deployability,"This PR deals with the test failures that were occurring when we ran ALL chromosomes through the integration test, rather than just chr20 and X and Y (the default). It adds another truth set for all chromosomes.; Also two small changes.; - Skip the cost/table size check for the Hail integration, to allow it to get to the hail part if there are spurious test failures in cost.; - Change the name of the files used for table size and cost checking. Makes it easier to install new test data. Passing integration test on all chromosomes [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/d8837252-26fa-4d40-bdf1-e42ff8932fd1); Passing integration test on chr20/x/y [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f552e7a3-d245-492d-b5e1-a35ba323fae8).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8787:97,integrat,integration,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8787,5,"['install', 'integrat']","['install', 'integration']"
Deployability,This PR expands the GermlineCNVCaller integration test suite and addresses #6893 and #4375. The tests that were added are: . - Numerical accuracy test that checks for changes of gCNV model posterior values as compared to a previously computed model. This test is meant to detect Python library updates that affect gCNV results and unintentional consequences of minor gCNV model changes.; - A test that runs gCNV in the COHORT mode with a pre-trained model as a starting point.; - A test that runs gCNV with an annotated intervals file that contain GC content column. As @samuelklee suggested we should consider adding functionality to the GermlineCNVCallerIntegrationTest to regenerate test files when there is a discrepancy in gCNV model outputs and we are okay with that discrepancy. See example of it in the HaplotypeCallerSparkIntegrationTest class -- specifically note UPDATE_EXACT_MATCH_EXPECTED_OUTPUTS flag. @mwalker174 let me know what you think.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7889:38,integrat,integration,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7889,2,"['integrat', 'update']","['integration', 'updates']"
Deployability,"This PR fixes a bug I found in testing. I was extracting all the samples for an Exome run and it was widely scattered. So there occurred a situation where there no VET entries in one of the shards and a NPE happened.; This PR fixes that and makes it tool generate an empty (well, has a header) VCF, which the GVS workflow can handle. Failing workflow showing the problem [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Exome%20Data%2049k/job_history/9f821329-f2bd-487c-a9af-4a81d0716072). Passing workflow (after the fix) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Exome%20Data%2049k/job_history/52ecbbaa-199d-413b-95fe-2a3285462b43); Passing Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/a2f67baa-9613-4c4e-be3b-85a1b25a3b3b)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8388:662,Integrat,Integration,662,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8388,1,['Integrat'],['Integration']
Deployability,"This PR fixes two bugs. First, the SplitIntervals task would enter WeightedSplitIntervals and hang. I added an extra boolean argument to extract so you can specify that no, you really don't want to use a weighted bed. Relatedly, the code branch for running the original GATK SplitIntervals code wasn't correct, as passing weight-bed-file to it as an argument caused a failure. It uses a slightly hacky method of defining a string in WDL to be empty or not depending on if we use weighted beds, interpolating that string into the bash, then checking to see if it's empty there to transmit that state. There is likely a cleaner way to do this, and in the next revision I will likely rewrite this part cleaner. Second, after SplitIntervals passed we hit an error during ExtractTask. The way it expanded intervals to handle large deletions could sometimes subtract past the start of a chromosome, so that logic needed to be patched in a few separate places to handle the interval for the mitochondrial dna that started much closer to the beginning (instead of having a 10k base pair buffer). This PR has those changes too. Successful run here: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Exome%20Test/job_history/a006a959-9300-42cf-84a7-38c70a35ee21. Successful run after incorporating PR changes: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Exome%20Test/job_history/e2ee3abd-288e-4f1d-b5be-f78cf5400ce9. Successful run after last PR refactoring that allowed me to revert almost all changes to GvsUtils.SplitIntervals: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Exome%20Test/job_history/94fed63a-98ca-466e-8d4c-ac97f24adf37",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8113:920,patch,patched,920,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8113,1,['patch'],['patched']
Deployability,"This PR fixes two problems I noticed relative to how we are treating cross-contig evidence that comes from the alt contigs:. - The cross-contig exclusion rule in `ReadClassifier` was incorrect. Due to the structure of the `if`-`else if` logic in `checkDiscordantPair()`, `SameStrandPair` or `OutiesPair` evidence was still being created for cross-contig pairs based on the strand configuration of the two reads (even though they were aligned to different contigs).; - The `runWholePipeline` script we've been using was not actually setting the cross-contig kill list parameter, meaning no cross-contig evidence was being filtered out. The change makes the number of intervals for CMHMIX WGS1 drop from 31962 to 27645.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3262:380,configurat,configuration,380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3262,1,['configurat'],['configuration']
Deployability,"This PR includes two changes:; 1. Provide a command line argument to toggle the overlapping base quality correction (i.e. min(bq, 20)) before reassembly, which happens in FragmentUtils. I've found, however, that by the time SomaticGenotypingEngine runs, those the quality of these bases get bumped up to what they used to be, so this may be a no-op. I included it in case I missed something, and to be consistent with the branch @fleharty and @madduran have been using.; 2. Provide a command line argument to count the two reads in an overlapping pair separately in StrandArtfiact and StrandBiasBySample. This feature is only available in Mutect i.e. it won't affect other tools that use StrandBiasBySample",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5286:69,toggle,toggle,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5286,1,['toggle'],['toggle']
Deployability,This PR increases the memory for IndexVCF; It also updates SelectVariants to use symlinks so that the VCF and its index file can be in different paths.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8151:51,update,updates,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8151,1,['update'],['updates']
Deployability,This PR is against ah_var_store. Need to make another against EchoCallset. The new reference disk is installed.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/ba18dc3d-0548-48ac-a67b-cec55250de8a) is a passing run of GvsCreateVatFromVDS using quickstart against the new reference.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8746:101,install,installed,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8746,1,['install'],['installed']
Deployability,"This PR is intended to introduce several new tools related to the CleanVcf workflow in GATK-SV, which the use of these tools being documented in https://github.com/broadinstitute/gatk-sv/pull/733. These tools are intended to introduce several enhancements over the existing implementation, including but not limited to:; - Introduce various unit and integration tests into the workflow.; - Create more robust and generalizable tools that can be used independent of _CleanVcf_.; - Improve runtime and execution speed by leveraging Java.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8996:350,integrat,integration,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8996,1,['integrat'],['integration']
Deployability,This PR is now merged and changes will be in the release after v4.1.0.0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5657#issuecomment-462375938:49,release,release,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5657#issuecomment-462375938,1,['release'],['release']
Deployability,This PR is on hold until Picard is updated to use the new google libs: https://github.com/broadinstitute/picard/pull/1903,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1652996952:35,update,updated,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1652996952,1,['update'],['updated']
Deployability,"This PR is the initial stage of implementing the calling of IMPRECISE variants in the SV pipeline. It introduces the concept of an evidence-target link, which joins an evidence interval to its distal target. This is an extension of the 'coherent' evidence concept previously used in determining evidence thresholds for assembly. The code in this PR contains the following changes:. - Evidence intervals and distal targets now are treated as stranded, and evidence-target link clustering depends on overlaps between both intervals and strands.; - Evidence target interval and distal target interval calculations have been modified to make sure that evidence supporting the same event clusters together (has overlapping intervals). This includes several changes such as extending the 'rest-of-fragment-size' calculation to try to capture almost all non-outlier fragment sizes in the library; increasing the split read location uncertainty a little; and being more precise about the boundaries of distal target intervals by taking advantage of information in the MD and MC tags if available.; - Evidence target links are gathered for every piece of evidence supporting a high-quality distal target. ; - Evidence target links are clustered together and store the amount of split-read and read-pair evidence that went into each cluster.; - All evidence target link clusters that are composed of at least 1 split read or at least 2 read pairs are collected in the driver and emitted in a BEDPE formatted file specified in the command line parameters.; - A `PairedStrandedIntervalTree` data structure is introduced to allow `SVIntervalTree`-style lookups for paired intervals. To finish this work, future PRs will 1) use the collected evidence target links to annotate our assembly called-variants with the number of split reads and read pairs observed in the original mappings and 2) create IMPRECISE VCF records for events that have enough evidence-target-link support, first for deletions and then possibl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3469:89,pipeline,pipeline,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469,1,['pipeline'],['pipeline']
Deployability,"This PR makes four changes to the SV pipeline management scripts: First it uses the new glob argument for copying data into HDFS to only copy the requested BAM file and its index, rather than everything in the GCS bucket directory (this is useful when the bucket directory contains multiple samples, as is the case with our HGSV trios). Second, the scripts now respect the project argument at each phase of the pipeline. Third, the output directory will include the name of the cluster so that if multiple samples are being processed by the same branch in parallel it's easier to figure out which results directory contains which sample and the results won't collide if two runs happen to start at the same timestamp. Finally, if the user requests not to copy the FASTQ files from the main management script, the script will not direct the SV discovery tool to write them to disk.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4646:37,pipeline,pipeline,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4646,2,['pipeline'],['pipeline']
Deployability,"This PR makes two changes to Mutect2's filtering. 1. The first change updates `Math.min` to `Math.max` in `applyFiltersAndAccumulateOutputStats()`, which is probably the intended behavior. Unfortunately, this update breaks some of the integration tests at `org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModelIntegrationTest.testOnRealBam`. I'm not quite sure how the dev team would prefer to handle the failed tests, so I thought I'd raise the issue here. 2. In `StrictStrandBiasFilter`, the argument `minReadsOnEachStrand` is not used in the `areAllelesArtifacts()` function. The second update turns on the `minReadsOnEachStrand` argument rather than using the default of 0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6903:70,update,updates,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6903,4,"['integrat', 'update']","['integration', 'update', 'updates']"
Deployability,"This PR modifies the VDS->VAT pipeline to scatter. We take the input sites only VCF, and scatter it.; Successful run at: https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20WGS%2010K%20Callset/job_history/468ab890-a49e-4487-ad12-7813296d9f04",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8122:30,pipeline,pipeline,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8122,1,['pipeline'],['pipeline']
Deployability,This PR modifies the behavior of GvsExtractToPgen to no-call any filtered genotypes; It also allows one to run GvsExtractCallset so that VCFs generated by it also have no-called GTs.; I also took the liberty of renaming 'VQSR Classic' to 'VQSR' and 'VQSR Lite' to 'VETS' in much of the Java code. Passing Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/1e1ed014-47cf-4c95-96f4-5c1284fc4616); Run of tie out pgen to VCF with no-called GTs [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/9e78f44a-f531-450b-acd8-db66cc6454be).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8793:305,Integrat,Integration,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8793,1,['Integrat'],['Integration']
Deployability,"This PR reimplements the overlap detector used in WeighedSplitIntervals in a much faster form for our particular use case. It also involved preprocessing the weighted bed input file in a new way, so the previous weights files will no longer work. As such, there's a new weights file uploaded and referred to as part of this pr. I pulled down the documentation and rationale for the original process from the git issue to a markdown file that can live in our repo, and made python scripts out of the necessary bits of python logic there (as well as a new one to do the further preprocessing step that I added). The motivation for this was the inability of the previous WeightedSplitIntervals task to complete when run against an exome interval list. This new one does, and it does so quickly. The link referenced below is not a ""successful"" run in the Terra sense because it was 190k exomes and that was simply too much for Terra to handle, but it DOES show a successful WeightedSplitIntervals run before the real extract started and I believe that is sufficient to merge. Delaying while ticket VS-189 gets figured out will create an unnecessary delay. Successful integration run: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/294fd6a8-15ed-4722-a63e-bdf089c1c52a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8507:1163,integrat,integration,1163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8507,1,['integrat'],['integration']
Deployability,"This PR removes the use of hadoop distcp to copy reference and sample data into HDFS, and replaces it with the new ParallelCopyGCSDirectoryIntoHDFSSpark tool. Based on initial tests, cluster creation with reference and a 110GB sample BAM file now takes ~8 minutes with SGA installation on the worker nodes and ~5 minutes without SGA installation. @SHuang-Broad can you review?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2576:273,install,installation,273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2576,2,['install'],['installation']
Deployability,This PR resolves all the pre-release M2 stuff except for the launch script. @LeeTL1220 @ruchim,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4048:29,release,release,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4048,1,['release'],['release']
Deployability,"This PR updates GvsWithdrawSamples to:; 1) Use a ""true"" temporary table (uniquely named, goes away after 24 hours); 2) Check if there are any samples in the uploaded list of samples to withdraw that are NOT in the existing sample_info table. Fail and print out the list of samples if so.; 3) Added a boolean flag to allow the user to pass the workflow if condition 2 is true. A) Example [Run](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/26482e64-cc22-4191-b88f-f7765b173450) with 0 samples withdrawn and 0 new samples (samples in the withdrawn file that aren't in sample_info); B) Example [Run](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/00f17100-18c4-4522-8dee-24630ef291b1) with 1 sample withdrawn and 0 new samples (samples in the withdrawn file that aren't in sample_info); C) Example [Run](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/c7dfc547-305c-4b31-aec8-685494b92221) with 1 sample withdrawn and 1 new sample (sample in the withdrawn file that wasn't in sample_info). This run was run with the override flag allowing it to pass; D) Example [Run](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/c2d2c897-ec1b-47ad-9927-70c6d7eb7e9b) with 1 sample withdrawn and 1 new sample (sample in the withdrawn file that wasn't in sample_info). This run failed (as intended)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8599:8,update,updates,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8599,1,['update'],['updates']
Deployability,"This PR updates the Freemarker templates so that the resulting pages will work with the current state of the website code. Most of the changes have to do with functionality I put in to enable hosting multiple doc versions and easy switching between them via a dropdown menu. . I had already done some retrofitting on older tooldocs so the versioned tool docs go back to 3.5, and we can add beta versions of 4 without changing the ""latest supported version"". . The only remaining problem is that I couldn't figure out how to output php instead of html. To test the web integration, I just renamed all *.html to *.php with `for f in *.html; do mv -- ""$f"" ""${f%.html}.php""; done` but that doesn't take care of internal links, which are of course broken as a result. @cmnbroad please let me know if I missed something obvious on this front ^^. . That being said this PR is fully functional as far as I'm concerned.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3165:8,update,updates,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3165,2,"['integrat', 'update']","['integration', 'updates']"
Deployability,"This PR updates the `--use-posteriors-to-calculate-qual` mode to properly treat the star allele as a non-variant (for that site) allele. With this change, if a spanning deletion is present, it is treated as a non-variant allele for that site, and the posterior of no variant allele being present becomes the sum of the posteriors of all genotypes composed of combinations of the reference allele and the star allele.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6856:8,update,updates,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6856,1,['update'],['updates']
Deployability,This PR will have to wait until we have continuous testing up and running for the AVX2 implementation of `SmithWaterman`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4356#issuecomment-364257090:40,continuous,continuous,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4356#issuecomment-364257090,1,['continuous'],['continuous']
Deployability,"This PR:. * fixes a problem observed for a complex event with tandem duplicated sequence and insertion and deletion, which causes the discovery phase of SV pipeline to throw exceptions;; * the fix works by changing how tandem duplications are annotated:; * duplicated sequence is no longer provided, instead the corresponding duplication unit reference span is provided in `DUP_REPET_UNIT_REF_SPAN`,; * the duplicated units on the assembled contigs' CIGAR when aligned to reference is provided in `DUP_ASM_CTG_CIGARS`;; * adds annotation `DUP_ANNOT_FROM_OPT` when tandem repeat annotations were generated by a simple approximation procedure, which should be viewed with care;; * logs the total number of variants and different types; * updated and added tests to reflect these changes. The PR was tested to be runnable based on output from scanning the CHM-mix bam with PR #2444, which discovered the exception.; The number of variants discovered are:. For CHM-mix; ```; 20:43:36.213 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - 204 INVs; 20:43:36.213 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - 2775 DELs; 20:43:36.213 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - 954 DUPs; 20:43:36.213 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - 977 INSs; ```; And for NA12878_PCR-_30X; ```; 22:14:15.653 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - Discovered 4686 variants.; 22:14:15.660 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - 228 INV's; 22:14:15.660 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - 2719 DEL's; 22:14:15.660 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - 835 DUP's; 22:14:15.660 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - 904 INS's; ```; @cwhelan Could you please to review?; @tedsharpe feel free to poke around and test run it. __UPDATE__:; This is to be merged after PR #2444.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2567:156,pipeline,pipeline,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2567,2,"['pipeline', 'update']","['pipeline', 'updated']"
Deployability,"This `DS` annotation has been kicking around in the header for a long time, but I've never seen it in the wild. It doesn't show up in any of our integration tests. We only have the ability to add this annotation if the GenotypingEngine gets a non-null `Map<String, AlignmentContext> stratifiedContexts`, but that doesn't seem to be the case in *_any_* of our tests. Maybe it's a holdover from UnifiedGenotyper?. @davidbenjamin have you seen cases where we `calculateGenotypes` with stratifiedContexts (or refContext or rawContext or likelihoods)? Given that there's zero test coverage, how would you feel about ripping it out and seeing if anyone complains?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5678:145,integrat,integration,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5678,1,['integrat'],['integration']
Deployability,"This adds a hard filter for low variant allele fraction calls. We will not turn this on by default in any of our pipelines, but it will give users an easy option to filter everything below a certain VAF that they don't care about. It also adds a hard filter for low alt depth calls based on a threshold from the median autosomal coverage (that must be supplied as an argument). It takes the cutoff from a Poisson with a mean of 1.5 * median coverage (to account for NuMTs with 3 copies in the autosome) and is tuned to catch 99% of the false positives (which we know will also catch lots of true positives). . It also removes the Polymorphic NUMT annotation (since that's basically what's going into the filter at this point).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5842:113,pipeline,pipelines,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842,1,['pipeline'],['pipelines']
Deployability,"This adds a small test case for the WDL of the filtering pipeline. This still has indels and snps separated out. I can combine them if needed, but we'd like to use different annotations for each mode. This also doesn't actually apply the final filtering (with a threshold) since we still need to add a step to determine the correct threshold. The final VCFs from this workflow should have SCORE INFO annotations for each site. This takes in an array of VCFs (and outputs an array of VCFs) because this is an option for large callsets in the WARP joint genotyping WDL which is where this WDL will eventually be integrated. This test only ensures that the WDL runs and doesn't compare to expected results (the same as the other WDL tests in this repo).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7932:57,pipeline,pipeline,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7932,2,"['integrat', 'pipeline']","['integrated', 'pipeline']"
Deployability,This allow us to simplify our R installation in Travis. . R tests now only test Rscript executor; Using standard ubuntu R in travis instead of the more up to date one; Removing installation of R packages as part of gradle and travis builds; Updating readme,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/518:32,install,installation,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/518,2,['install'],['installation']
Deployability,"This along with the GVCF reblocking branch constitute the new code I'm using for gnomAD v3 on the Gnarly Pipeline. Some of the GDB hacks are gross, but I can't clean it up until after the protobuf update.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4947:105,Pipeline,Pipeline,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4947,2,"['Pipeline', 'update']","['Pipeline', 'update']"
Deployability,"This also includes an upgrade to Picard 2.19, so its in sync with htsjdk now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5812#issuecomment-477125402:22,upgrade,upgrade,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5812#issuecomment-477125402,1,['upgrade'],['upgrade']
Deployability,"This also includes:; * Added FPGA to ```Implementation``` enum of ```VectorLoglessPairHMM```; * Added FPGA to ```Implementation``` enum of ```PairHMM```; * Updated ```FASTEST_AVAILABLE``` value to try FPGA first (then AVX+OMP, then AVX, then regular)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2725:156,Update,Updated,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2725,1,['Update'],['Updated']
Deployability,"This applies to projects that import the GATK jar as part of the build process, but are not part of the GATK itself. All unit and integration tests are (by default) broken, since the BaseTest class requires the mini fasta, even when it should not be required. This causes breakage, since a project built on the GATK should not be expected to have that file at the exact correct place in the filesystem. The tests do not even start.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3029:130,integrat,integration,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029,1,['integrat'],['integration']
Deployability,"This branch takes the version of gatk-public that gatk-protected currently depends on (4.alpha.2-188-g7332d10) and applies @davidbenjamin 's fix to the `TandemRepeat` annotation to it. The only purpose of this PR is to cause a snapshot to be generated -- do not merge!. This is necessary to unblock @davidbenjamin 's work, because the `HaplotypeCaller` tests are failing if we update protected to the latest public head, and although we've fixed some of the issues there are some unexplained failures in the concordance tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2569:377,update,update,377,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2569,1,['update'],['update']
Deployability,"This breaks polygenic score pipelines, which have 0/0 without DP (imputed sites). Maybe just revert and include switching 0/0 to ./. as an option",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1933114855:28,pipeline,pipelines,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1933114855,1,['pipeline'],['pipelines']
Deployability,This brings in recently-merged changes related to headerless SAMRecords; that are needed in order to enable the faster SAMRecord serializer; (SAMRecordToGATKReadAdapterSerializer). Temporarily disabled the SAMRecordToGATKReadAdapterSerializerUnitTest; pending updates in PR #1127.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1153:260,update,updates,260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1153,1,['update'],['updates']
Deployability,"This bumped some transitive dependencies which required a minor update in unrelated classes. We shouldn't merge this until we get a 👍 from the SV team as well as running the jenkins spark tests. I think the SV team is already using 2.2.0 since they've gone to dataproc image 1.2. This will prevent the annoying adam log spam, closes #4186 ; closes #2555",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4314:64,update,update,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4314,1,['update'],['update']
Deployability,"This came up on PR #6351 after a rebase. The branch passes all tests locally (verified on my laptop and on @cmnbroad's) but fails `DocumentationGenerationIntegrationTest.documentationSmokeTest` in the docker integration CI job on Java 8 but not Java 11. The same test passed locally for me even after verifying Java 8 was enabled, refreshing the gradle project, rebasing again etc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991:208,integrat,integration,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991,1,['integrat'],['integration']
Deployability,"This can improve some build configurations for GATK (ony noted the ones in 4.6, but not previos ones):. * `failFast` property for test tasks. This would be useful for PRs; * Declare reasons for dependency resolution rules and constraint dependencies. This could be useful for explaining why some dependencies are not the latest (e.g., protobuf).; * Allow options in the command line. This could be nice for the doc generation.; * Default jacoco is 0.8.0, which improves the coverage report by filtering out some empty constructors",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4659:28,configurat,configurations,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4659,1,['configurat'],['configurations']
Deployability,"This can wait until after release, but will need to be done to get gCNV into FireCloud.; Also, output blocks for Germline CNV calling WDL scripts.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4025:26,release,release,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4025,1,['release'],['release']
Deployability,This causes integration tests to fail.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4839:12,integrat,integration,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4839,1,['integrat'],['integration']
Deployability,This change is dependent on [this recent change](https://github.com/samtools/htsjdk/commit/4f550e1f1afabf21467957fa672ca2a4ad457897#diff-b678735810949d4263df7bd0fffdecb8L42) in htsjdk (and the build will fail without it). Once htsjdk2.0 is available we'll upgrade it in this branch/pr so the two changes can go in together.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1243:256,upgrade,upgrade,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1243,1,['upgrade'],['upgrade']
Deployability,"This change was originally made to allow our joint calling pipeline to scale to handle the hundreds of thousands of samples in the AllOfUs project. I agree that it's problematic and confusing for downstream users. Since AllOfUs recently switched back to using the ./. convention in their callsets in response to similar complaints, we are going to revisit this decision in GATK GenotypeGVCFs and strongly consider reverting back to ./. as well in a future release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1932619397:59,pipeline,pipeline,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1932619397,2,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,"This class is now needed by other pipelines, so let's make it generally available; in the engine.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/476:34,pipeline,pipelines,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/476,1,['pipeline'],['pipelines']
Deployability,"This code (building off of Louis' fixes) adds the following:; - AuthHolder, a replacement for the PipelineOptions. It stores the authentication info we need for GCS and supports both API_KEY and client-secrets.json. I adapted a few classes to accept an AuthHolder.; - BaseRecalibratorOptimizedSpark, a port of the ""shard"" approach I first did on the Dataflow side. Note that currently this code only performs reasonably for small inputs if you specify -L on the command line (for large inputs it doesn't matter).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/987:98,Pipeline,PipelineOptions,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/987,1,['Pipeline'],['PipelineOptions']
Deployability,"This contains a change to toggle the presorted flag used by GatherBAMFiles, and enables some CRAM tests that were previously broken due to htsjdk bugs. Fixes https://github.com/broadinstitute/gatk/issues/1138 and all but one from https://github.com/broadinstitute/gatk/issues/1141.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1255:26,toggle,toggle,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1255,1,['toggle'],['toggle']
Deployability,"This doesn't fix the integration test, but a bug in GvsBulkIngest",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8736:21,integrat,integration,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8736,1,['integrat'],['integration']
Deployability,This epic will track tickets related to work in the annotation engine for the 4.0 release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3274:82,release,release,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3274,1,['release'],['release']
Deployability,"This extends Variant Eval to compare AFs between variants in binned AF buckets based on Thousand Genomes VCF, between the expected AF from Thousand Genomes and the seen one in the actual VCF, to be used as a QC metric for our arrays pipeline.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6039:233,pipeline,pipeline,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6039,1,['pipeline'],['pipeline']
Deployability,This feature has been implemented in GenomicsDB by @kgururaj and is part of the 1.1.0.1 GenomicsDB release. PR #5970 will bring in 1.1.0.1 for this feature.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5570#issuecomment-512902238:99,release,release,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5570#issuecomment-512902238,1,['release'],['release']
Deployability,"This feature would help me obliterate a horrible, horrible hack in my pipeline, thus replacing it with a solution of delight and beauty.; +1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2865#issuecomment-415070630:70,pipeline,pipeline,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2865#issuecomment-415070630,1,['pipeline'],['pipeline']
Deployability,This fixes a bug in handling the defaults for setting and using our default cluster initialization script for the SV pipeline. The master version will error if no init script parameters are specified.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3467:117,pipeline,pipeline,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3467,1,['pipeline'],['pipeline']
Deployability,"This fixes a bug in the `AlleleFrequencyCalculator` that was causing quality to be overestimated for sites with `*` alleles representing spanning deletions. The bug was causing the calculator to not include homozygous `*` genotypes in the sum of non-site specific variant allele probabilities that is the basis for the qual score. The bug was caused by an off-by-one index error: `IndexRange(0,2)` returns `[0,1]`, not `[0,1,2]` as intended. Not including this genotype inflated the quality score for these sites. . Due to interactions with QUAL-based variant and allele trimming, this causes slightly different behavior when HaplotyeCaller is run in modes where it is forced to emit variants for every locus, as can be seen in the `expected/gvcf.basepairResolution.includeNonVariantSites.vcf` test file for `GenotypeGVCFsIntegrationTest`: 1) Sites spanned by a deletion are now reported with a `*` alt allele and have QUAL 0 and a LowQual filter. Also added a mechanism to `GenotypeGCVFsIntegrationTest` to automatically update the expected result files, similar to what already exists in `HaplotypeCallerIntegrationTest` and `CombineGVCFsIntegrationTest`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6859:1022,update,update,1022,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6859,1,['update'],['update']
Deployability,This fixes the first day's downloads on a new release which previously were set to 0. @jonn-smith This is what I was talking about.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7794:46,release,release,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7794,1,['release'],['release']
Deployability,"This handles the case we saw in Shriner's beta files where variants on chrX (and presumably chrY) were represented with a call_GT of ""1."". NOTE: SOME of these changes fixed our code to work for any ploidy, but others only changed our pipeline to work for examples with a ploidy of 1. Specifically, the changes made to . `scripts/variantstore/wdl/extract/populate_alt_allele_table.py` and ; `src/main/resources/org/broadinstitute/hellbender/tools/gvs/filtering/feature_extract.sql`. have made it work for haploid and diploid values, but we'd need to generalize the code that explicitly lists the potential values for GT. Given that we're not seeing cases with a ploidy above 2 yet, doing that can be for a later ticket. Doc with steps I went through to test this:; https://docs.google.com/document/d/1F194j7OQh9ehs5pSdt5yHcsSWrm3WmqDlVVkDFkULuw/edit#heading=h.464spie271ew. Successful extract here:; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Tiny%20Quickstart%20hatcher/job_history/a7cc6ffb-fd98-4142-a211-8235dea10b35. Successful integration run here:; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/8d09d70e-a6f3-42a8-9c81-95065c653f4d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8334:234,pipeline,pipeline,234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8334,2,"['integrat', 'pipeline']","['integration', 'pipeline']"
Deployability,This has since been fixed in another update.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4358#issuecomment-378327894:37,update,update,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4358#issuecomment-378327894,1,['update'],['update']
Deployability,This immediate task is effectively closed by PR #4020 . In the long-run this is really a continuous improvement task.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3497#issuecomment-354784074:89,continuous,continuous,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3497#issuecomment-354784074,1,['continuous'],['continuous']
Deployability,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/443:749,pipeline,pipeline,749,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443,3,"['configurat', 'pipeline']","['configuration', 'pipeline', 'pipelines']"
Deployability,This is a bit of a pain because the sam files produce by htsjdk now all say they're version 1.5. We need to rewrite our sam/bam files to be compliant with the new version (or at the very least update the version strings. ) Alternatively we could change the comparator to ignore versions when comparing.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/758:193,update,update,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/758,1,['update'],['update']
Deployability,"This is a checkpoint PR for https://github.com/broadinstitute/gatk/issues/1237 and https://github.com/broadinstitute/gatk/issues/1643. This is the first step in refactoring metrics collectors so they can be pipelined in Spark and reuse RDDs, but still share metrics computation code between walker and Spark versions. The next step will be to extend MultilevelCollector to be able to merge its own instances in order to support efficient map and reduce phases for multi level collectors. Suggested review order:. -MetricsCollectorSpark: interface to be implemented by all Spark collectors; -MetricsArgs:base class for all collector argument sets; -MetricsCollectorToolSpark: base class for all Spark metrics collector tools; -CollectQualityYieldMetrics: Spark version of QualityYieldMetrics using these new interfaces; -CollectInsertSizeMetricsSpark: existing Spark version of InsertSizeMetrics collector ported; to these interfaces; -CollectMultipleMetricsSpark: Spark version of CollectMultipleMetrics; currently only works; on QualityYieldMetrics and InsertSizeMetrics. The rest of the PR is refactoring existing to get QualityYieldMetrics and InsertSizeMetrics to conform to these interfaces (moving CollectInsertSizeMetrics out of the sv package and Program Groups, etc.). Note that the existing InsertSizeMetrics Spark collector doesn’t really share code with the walker; version (and their command line param sets are way out of sync) but this should be fixed separately from these changes as the interfaces evolve.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1827:207,pipeline,pipelined,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1827,1,['pipeline'],['pipelined']
Deployability,"This is a difference vs. GATK3, which did include reads with deletions in the isActive pileups for both HaplotypeCaller and Mutect2 ( @davidbenjamin take note ). The fix is trivial -- I'll have a patch submitted later today.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3830:196,patch,patch,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3830,1,['patch'],['patch']
Deployability,"This is a duplicate of https://github.com/broadinstitute/gatk/issues/6720, which has already been fixed in https://github.com/broadinstitute/gatk/pull/6726. The doc will appear in the next release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6862#issuecomment-704235329:189,release,release,189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6862#issuecomment-704235329,1,['release'],['release']
Deployability,"This is a hot topic recently, so I already have a doc to compare and contrast: https://docs.google.com/document/d/1qws0owSEc0XGcZGAcxmBOEk8fiWS1Dnv4tvHNgC_xVU/edit?usp=sharing. Gnarly is still a ""beta"" tool. I wanted to add some way to reduce the number of alternate alleles, but that may be easier to do after this recent GenomicsDB update.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1069164647:334,update,update,334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1069164647,1,['update'],['update']
Deployability,"This is a patch to fix the integration test that is broken in the EchoCallset.; There was refactoring done on GvsExtractAvroFilesForHail (in the EchoCallset branch) that has broken the inputs to the integration test on that branch. ; I'm not sure this is the perfect solution, but I'd like to get it merged into EchoCallset so we can unify EchoCallset and ah_var_store",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8737:10,patch,patch,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8737,3,"['integrat', 'patch']","['integration', 'patch']"
Deployability,"This is a problem with your `R` environment -- you need to install the `gplots` package (amongst a few others, if you don't already have them). From https://gatk.broadinstitute.org/hc/en-us/articles/360035889531-What-are-the-requirements-for-running-GATK-; ```; R dependencies; Some of the GATK tools produce plots using R, so if you want to get the plots you'll need to have R and Rscript installed, as well as these R libraries: gsalib, ggplot2, reshape, gplots,; ```. Here's a quick article on installing packages in R if you're unfamiliar (https://www.r-bloggers.com/2010/11/installing-r-packages/). Note, you'll need a version of R that is compatible with these packages",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7006#issuecomment-770272506:59,install,install,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006#issuecomment-770272506,4,['install'],"['install', 'installed', 'installing', 'installing-r-packages']"
Deployability,"This is a prototype of the basic infrastructure that must go in to make the junction tree based Haplotype finding work. I have pulled out a toggle for the HaplotypeCaller that that enables a separate ReadThreadingAssembler codepath for haplotype finding. Right now when this mode is enabled `ExperimentalReadThreadingAssembler` is used in conjunction with `JuncitonTreeKBestHalotypeFinder` to extract only haplotypes that show up in our junction trees with evidence of > 3 reads. This still poses problems with dangling end recovery as definitionally those branches never include complete junction tree data. . I will continue to work on this branch (as it is in a somewhat rough state still) but I would like to at least get some eyes on it before i get too deep in the weeds to at least validate the structural approach I have chosen. . Currently known issues in this branch: ; - Tests are failing due to resolution of non-unique reference sink vertexes, I would solicit help as to how best to resolve the case where junction trees point to both a reference stop allele and a continued path.; - There is at least one very degenerate edge case that might cause the code to hang, I would also ask after what is the best way to close out of looping assembly structures that never have reads to close them (i.e. a ""dangling end"" hom-var that happens to point to a non-unique reference base). ; - Probably after discussion the threshold for discarding junction trees will be changed to instead use paths from the discarded tree first. . Resolves #5925",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6034:140,toggle,toggle,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6034,1,['toggle'],['toggle']
Deployability,"This is a small patch which solves a bug in `FeatureWalker` which was driving me crazy with some of my custom tools. Please, could you have a quick look, @droazen? Thank you in advance!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2467#issuecomment-287483988:16,patch,patch,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2467#issuecomment-287483988,1,['patch'],['patch']
Deployability,"This is a subtask of #133. Extra code is needed to switch between `""INPUT""` and `""input""` which is unfortunate. Replace ""INPUT""/""OUTPUT"" for `CleanSam` and `MarkDuplicates` (along with any others that I missed.) with `StandardArgumentDefinitions.INPUT_LONG_NAME` Then update `SamFileTester` to only use the standard names.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/805:268,update,update,268,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/805,1,['update'],['update']
Deployability,"This is a tool intended to evaluate the performance of genotyping (not sequencing/variant discovery), for example from a genotyping array or imputation pipeline.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7328:152,pipeline,pipeline,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7328,1,['pipeline'],['pipeline']
Deployability,"This is a very minimal change of the testing framework to allow users of the framework to use `IntegrationTestSpec` with their own classes. It solves the problem of a custom `Main` class to run the command line test in programs using the framework (through overriding default behavior), and the loading of `GenomeLocParser` by the `BaseTest` if the test is simply extending `CommandLineProgramTest`. More details for this issue in #2033. Now API users could implements and modify default behavior of `CommandLineProgramTestInterface` and use this test classes in `IntegrationTestSpec`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122:95,Integrat,IntegrationTestSpec,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122,2,['Integrat'],['IntegrationTestSpec']
Deployability,"This is a very simple patch, @cmnbroad. Could you have a look?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-268280677:22,patch,patch,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-268280677,2,['patch'],['patch']
Deployability,"This is actually becoming quite a problem in the new exome pipeline since there are so many exome intervals and these warnings get output once per query/interval. The stderr is totally clogged with them and it's impossible to track the task with the GATK ProgressMeter. @nalinigans I heard you're working on a GDB release -- can we add a quick and dirty logging patch? One solution would be to make a list of annotations that are recalculated in genotyping that don't need to be merged: InbreedingCoeff, AS_InbreedingCoeff, QD, AS_QD, DS, AC, AF, AN, MLEAC, MLEAF",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2689#issuecomment-438822414:59,pipeline,pipeline,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2689#issuecomment-438822414,3,"['patch', 'pipeline', 'release']","['patch', 'pipeline', 'release']"
Deployability,"This is an experiment to see if it's possible to run BWA-MEM on Spark. (Please don't merge.) The basic idea is that it uses JNI to call BWA-MEM's align function to align a batch of read pairs in one go. I think it should complement the work that @SHuang-Broad has been doing in #1701. It would be great to get your (and @akiezun's) feedback on the direction here. A few comments; - Building the native libraries is not integrated, and it's not using the Apache 2 licensed code. I think this could use some of the changes in #1701.; - The ref is assumed to be on the local FS for the moment - it should really be loaded from HDFS. Also, the output is a single SAM file on the local FS, not a sharded BAM as for the rest of the GATK Spark tools.; - It is assumed that read pairs are interleaved and reads in a pair are placed in the same split (by setting `hadoopbam.bam.keep-paired-reads-together`). However, that property only works for queryname sorted BAMs, which isn't the case here, so we need to relax that requirement in Hadoop-BAM.; - I haven't tried this on large inputs, so I don't know how well it performs. To run, I used the following on a cluster. ```; ./gatk-launch BwaSpark \; --ref /home/tom/workspace/jbwa/test/ref.fa \; --input hdfs:///user/$USER/bwa/R.bam \; --output /tmp/bwa.sam \; -- \; --sparkRunner SPARK --sparkMaster yarn-client \; --driver-memory 3G \; --num-executors 1 \; --executor-cores 1 \; --executor-memory 3G \; --archives jbwa-native.tar#jbwa-native \; --conf 'spark.executor.extraLibraryPath=jbwa-native'; ```. The interesting bit is the use of Spark's `--archives` flag to copy a tarball of native libraries (which I built manually) to every executor, and unpacks it in the working directory. Then `spark.executor.extraLibraryPath` is set to add that path to the library path of the executor. This means that you don't have to rely on the native libraries being installed on every node in the cluster.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1750:419,integrat,integrated,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1750,2,"['install', 'integrat']","['installed', 'integrated']"
Deployability,"This is an issue with the Gencode files chosen for the datasources. The Fasta file we use currently is a subset of the total genes in Gencode, so this is an expected error (though it shouldn't be a user error). We have 2 options:; 1) changing the code to throw a warning and ignore variants in transcripts not in the Fasta.; 2) Download a larger set of sequences from Gencode and make sure all transcripts are represented in the Fasta file. My choice is 2 because it is a relatively seamless update (though the data sources will need to be updated, and this will add about 1.6 GB to the data sources). @LeeTL1220 Thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4739#issuecomment-387300313:492,update,update,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4739#issuecomment-387300313,2,['update'],"['update', 'updated']"
Deployability,"This is an update of where I am at with this issue. It turns out that using --forceActive and --dontTrimActiveRegions only worked for picking up some of the het SNP calls with HaplotypeCaller. A fun side effect was that some calls that were made with the 'vanilla' best practices HC options were now being missed with the forceActive/dontTrim options. So our clinical team decided to use samtools/bcftools for a pileup approach in combination with HC. We call variants with samtools/bcftools then filter the 'samtools' vcf for VAF > 0.15 and pass that vcf to HC with the -L flag to force HC to make these calls. This is working, all of the calls we are trying to pick up are now being found with our combined method. We also run the vanilla best practices HC on our data and merge the vanilla and samtools vcfs after they go through HC for downstream hard filtering and annotation. Part of this hybrid vanilla/samtools method is for continuity, we're been running 'vanilla' HC for awhile now and didn't want to completely drop it for our new samtools/HC calling approach, so we are combining both to be extra conservative. We decided to keep HC around for 2 reasons, 1) it's not going to give us as many false positives as a 'pileup' method and 2) our downstream annotation software has been set up for dealing with HC vcf files and switching to another vcf INFO format would be painful. But it certainly has causes some alarm about the 'unknown unknowns' that we could be missing in a clinical context. All of these troublesome variants checked out with Sanger sequencing, so this is definitely a real issue and the problem is occurring in clinically-relevant genes, such as F5. I'm happy to provide additional info to help the GATK development team figure out why these variants are missed with HC in the 'vanilla' best practices mode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-431985127:11,update,update,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-431985127,1,['update'],['update']
Deployability,"This is based on @davidadamsphd's initial work to port mark duplicates to Spark. It's not finished yet, but I wanted to post this for discussion. In particular 7 of the 56 mark duplicates integration tests are failing with ""Cannot get mate information for an unpaired read"" - I'm not sure how to address that. I'd appreciate some help on this one. The code currently has four shuffles: one groupBy in transformFragments (in MarkDuplicatesSparkUtils), two groupBys in transformReads, and one combine (foldByKey) in generateMetrics. The combine is more efficient than the others since it can run on the map side, reducing the amount of data that goes through the shuffle. I think it may be possible to merge the processing of the fragments and the reads to eliminate a shuffle - so there are only two shuffles for the main transform. A fragment would be represented as a pair with an empty second slot, so it can be handed in the processing separately from the true pairs that have both slots filled.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/889:188,integrat,integration,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/889,1,['integrat'],['integration']
Deployability,"This is currently using a Barclay snapshot, and should not be merged until the released version is up.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4270:79,release,released,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4270,1,['release'],['released']
Deployability,This is exactly the sort of nightmare bug we get every java update. Just 1 isn't bad at all. I'm surprised replacing all the hashsets didn't work. It could come down to inadequate tiebreaking in a sort which falls back to identityHash. We saw that in a different bug recently. I'll take a look.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-532701834:60,update,update,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-532701834,1,['update'],['update']
Deployability,"This is fixed by the Barclay upgrade in https://github.com/broadinstitute/gatk/pull/3804, but we really should add an explicit test that uses a Picard interval list with a .list extension that includes a header (i.e., src/test/resources/small_unmerged_picard_intervals.list, but this is only used in a unit test).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3555#issuecomment-344267691:29,upgrade,upgrade,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3555#issuecomment-344267691,1,['upgrade'],['upgrade']
Deployability,"This is fixed in https://github.com/bigdatagenomics/adam/pull/1508, but that project needs to do a release in order for us to get the fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2037#issuecomment-337303234:99,release,release,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2037#issuecomment-337303234,1,['release'],['release']
Deployability,This is for [Issue 5397](https://github.com/broadinstitute/gatk/pull/5397). Got the tests to pass by generating new expected results for the following failing tests and use the GenomicsDBImports folder for expected results as that was updated as part of [PR 5170](https://github.com/broadinstitute/gatk/pull/5471). * testGenomicsDBImportFileInputsAgainstCombineGVCFWithNonDiploidData; * testGenomicsDBImportFileInputs_newMQ. Note that this PR also has merged with master.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5581:235,update,updated,235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5581,1,['update'],['updated']
Deployability,"This is for demo purpose only, so the code is not ready yet to be merged:. ## Description. ### background & goal; Currently, there are two parallel code path for structural variation breakpoint location and type inference using local assembly contig alignment signatures in the pipeline `StructuralVariationDiscoveryPipelineSpark`. * the stable code path: scanning neighbor chimeric alignment pairs of a contig iteratively and outputs inversion breakpoints as symbolic variant `<INV>`, annotated with `INV55` and `INV33` for signaling if it is the left or right breakpoint of the assumed inversion.; * the experimental code path that separates the alignment pre-processing step from the inference step, and studying the alignments in whole; this code path, in addition to outputting insertion, deletion and small duplication calls as does the stable path, outputs ; * BND records representing assembled breakpoints for which type could not be completely determined using only the contig alignments; this includes supposedly inversion breakpoints; * complex (`<CPX>`) variants from assembly contigs with more than 2 alignments; ; The tool proposed in this PR is based on [manual review](https://github.com/broadinstitute/dsde-methods-sv/tree/sh_inv_filter_init/docs/knowledgeBase/variantReview/inversion/chm) of a callset generated a long time ago (but still useful for studying filtering inversion breakpoints), and is designed to be integrated with the experimental code path. ### proposed algo. #### input:; * the ""INV55/INV33""-annotated `BND` records output by the upstream experimental code path; * BND's have related concepts of `MATE` and `PARTNER` (see figure below, left); * `MATE`: novel adjacency, i.e. contiguity on sample that is absent on reference (e.g. mobile element insertions, deletions); * `PARTNER`: novel disruption, i.e. contiguity on reference disrupted on sample (e.g. insertions, deletions). ![inversion_demo](https://user-images.githubusercontent.com/16310888/40271739-6d999b",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4789:278,pipeline,pipeline,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4789,1,['pipeline'],['pipeline']
Deployability,"This is for discussion... @jonn-smith @droazen . Currently, there seems to be a fair amount of code change in order to get Funcotator to work with a new gencode version. . For starters:; - the parser has to recognize the email address and version string; - the MAF output alias `MafOutputRendererConstants` needs to be updated. Is there a way to have this be more seamless? . Ideally, we would have no mandatory code changes. Maybe just warnings that would not block a user. Is this an issue at all? Are we going to scale back the flexibility of datasources?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4786:319,update,updated,319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4786,1,['update'],['updated']
Deployability,This is great! We can solicit feedback on style at the Methods meeting as well. Feel free to spin off low-priority TODOs into issues that we can leave for after release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344587173:161,release,release,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344587173,2,['release'],['release']
Deployability,"This is intended to alleviate transient issues with GermlineCNVCaller inference in which the ELBO converges to a NaN value, by calling the python gCNV code with an updated random seed input.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6866:164,update,updated,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6866,1,['update'],['updated']
Deployability,This is left to the developers who will update the tool docs in <https://github.com/broadinstitute/gatk/issues/3853>.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-346066876:40,update,update,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-346066876,1,['update'],['update']
Deployability,"This is not ready for merge -- I just want to see if tests pass with this configuration. There are still some unresolved vulnerabilities:. ```; [1/7] - pkg:maven/com.google.protobuf/protobuf-java@4.0.0-rc-2 - 3 vulnerabilities found!; [2/7] - pkg:maven/log4j/log4j@1.2.17 - 6 vulnerabilities found!; [3/7] - pkg:maven/org.codehaus.janino/janino@3.1.9 - 1 vulnerability found!; [4/7] - pkg:maven/net.minidev/json-smart@2.4.7 - 1 vulnerability found!; [5/7] - pkg:maven/org.codehaus.jettison/jettison@1.1 - 3 vulnerabilities found!; [6/7] - pkg:maven/org.eclipse.jetty/jetty-util@9.4.48.v20220622 - 1 vulnerability found!; [7/7] - pkg:maven/org.eclipse.jetty/jetty-http@9.4.48.v20220622 - 1 vulnerability found!; ```. Some of these we may be unable to resolve. Eg., the `protobuf-java` version in this branch appears to be the most recent one, but still has open vulnerabilities filed against it. The ancient log4j 1.x version is used by two of our dependencies (`hdf5-java-bindings` and `spark-mllib_2.12`), and is the most recent version. Note that this is completely unrelated to the infamous log4j 2.x vulnerability, which was patched in GATK a long time ago.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8352#issuecomment-1581408853:74,configurat,configuration,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8352#issuecomment-1581408853,2,"['configurat', 'patch']","['configuration', 'patched']"
Deployability,"This is not working. Is there another way to install the python pacakges for `CNNScoreVariants`?. I get this error:. ```; conda create -n gatk -f ./scripts/gatkcondaenv.yml; Collecting package metadata (current_repodata.json): done; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - ./scripts/gatkcondaenv.yml. Current channels:. - https://conda.anaconda.org/bioconda/linux-64; - https://conda.anaconda.org/bioconda/noarch; - https://conda.anaconda.org/conda-forge/linux-64; - https://conda.anaconda.org/conda-forge/noarch; - https://repo.anaconda.com/pkgs/main/linux-64; - https://repo.anaconda.com/pkgs/main/noarch; - https://repo.anaconda.com/pkgs/r/linux-64; - https://repo.anaconda.com/pkgs/r/noarch; - https://conda.anaconda.org/r/linux-64; - https://conda.anaconda.org/r/noarch. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org. and use the search bar at the top of the page. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4822#issuecomment-578660611:45,install,install,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4822#issuecomment-578660611,1,['install'],['install']
Deployability,This is now passing tests with the newly released NIO library (0.5.1). I also successfully ran on a Spark cluster with the new library.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-258498517:41,release,released,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-258498517,1,['release'],['released']
Deployability,"This is something we also want to address in the CNV pipeline soon. However, we typically need to append sample metadata to TSVs (rather than SAMs) and TableReader/TableWriter currently only allows for comment lines starting with `#`. Hence, in #2858 we tack on a `#SAMPLE_NAME=...` header, which is quite hacky. Perhaps we can discuss unifying this sort of thing (along with appending sequence dictionaries when appropriate) across the tools?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3726#issuecomment-338277466:53,pipeline,pipeline,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3726#issuecomment-338277466,1,['pipeline'],['pipeline']
Deployability,"This is super interesting - the Java 11 integration tests that are failing in this last run are exactly the same tests that have been problematic on the Java 17 branch. I looked at the failing values that were being produced on that branch (which we've updated), and they're identical to the failing values seen here. Even on the Java 17 branch, there has been some inconsistency in the failures (they usually fail, but not always).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8102#issuecomment-1329162240:40,integrat,integration,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8102#issuecomment-1329162240,2,"['integrat', 'update']","['integration', 'updated']"
Deployability,"This is the barest bones version of the reads preprocessing pipeline. This adds the following:; - loading reference bases from the Google Genomics API; - Joining overlapping variants with reads; - Joining reference bases with reads; - A pipeline outline for reads preprocessing. There PR is ready to get reviewed. Assigning to Louis, but JP will look at Variants and BQSR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/655:60,pipeline,pipeline,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/655,2,['pipeline'],['pipeline']
Deployability,This is very important for integration tests. Not being able to use large files is significantly slowing porting of existing tools to hellbender. Maybe this will work https://git-lfs.github.com/ maybe something else.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/388:27,integrat,integration,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/388,1,['integrat'],['integration']
Deployability,"This is what I ran (note it's not using the HDFS codepath). Can you try reproducing please? I used to be able to run this in 40 minutes (the whole pipeline, not just HC, and even BQSR is taking a lot longer now). ```bash; gatk ReadsPipelineSpark -I gs://broad-spark-eval-test-data/exome/NA12878.ga2.exome.maq.raw.bam -O gs://broad-spark-eval-test-data/exome/NA12878.ga2.exome.maq.raw.vcf -R; gs://broad-spark-eval-test-data/exome/Homo_sapiens_assembly18.2bit --known-sites gs://broad-spark-eval-test-data/exome/dbsnp_138.hg18.vcf -pairHMM AVX_LOGLESS_CACHING --max-; reads-per-alignment-start 10 \; -- \; --spark-runner GCS --cluster tw-cluster-2 \; --num-executors 8 --executor-cores 8 --executor-memory 32g \; --driver-memory 4g \; --conf spark.dynamicAllocation.enabled=false; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364382087:147,pipeline,pipeline,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364382087,1,['pipeline'],['pipeline']
Deployability,"This isn't high priority for us right now, but I would be happy to review a PR if you wanted to take a stab at a solution @nh13 . None of our formal pipelines use the PID or PGT tags (unless Funcotator does something @jonn-smith ?) so a switch to PS wouldn't be a breaking change for us.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5314#issuecomment-430689684:149,pipeline,pipelines,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5314#issuecomment-430689684,1,['pipeline'],['pipelines']
Deployability,"This isn't just a matter of changing the number. [RegisterCoder was made more stringent](https://cloud.google.com/dataflow/release-notes/java) and this will force some code changes. Hopefully only little ones, but I got only as far as getting an internal Java error and I think that's a sign I should go to bed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/754:123,release,release-notes,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/754,1,['release'],['release-notes']
Deployability,"This isn't necessary for the release, and doesn't yet have some changes that @jamesemery needs, but we might as well give it a bump.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5344#issuecomment-432288695:29,release,release,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5344#issuecomment-432288695,1,['release'],['release']
Deployability,This issue has been fixed here https://github.com/Intel-HLS/GKL/pull/142. The patch for this bug will come out with the next release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6733#issuecomment-788951744:78,patch,patch,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733#issuecomment-788951744,2,"['patch', 'release']","['patch', 'release']"
Deployability,"This issue is to keep a record that we're going to base the initial porting of Picard on version 1.130, released on 3/24/15. This will make it easy to re-sync the tools later on by just diffing against that version to see what changes need to be made.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/331:104,release,released,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/331,1,['release'],['released']
Deployability,This last set of changes is dependent on https://github.com/broadinstitute/barclay/pull/17. Once that's reviewed we'll need to snapshot or release and upgrade to Barclay.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-271290203:139,release,release,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-271290203,2,"['release', 'upgrade']","['release', 'upgrade']"
Deployability,"This likely has to do with your spark configuration. Check on the Spark job's progress through the web interface, which should be something like http://<driver_address>:4040 (see https://spark.apache.org/docs/latest/monitoring.html). . If your BAM is very small, you can also try increasing the number of partitions by reducing --bamPartitionSize.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932:38,configurat,configuration,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932,1,['configurat'],['configuration']
Deployability,"This looks like a good start! I'm not quite sure how you are planning to handle dictionary validation, specifically, but you can take a look at the CNV plotting tools (PlotDenoisedCopyRatios and PlotModeledSegments) to see what level of validation we currently do. We can discuss further in person if you like. (Also, note that those tools take a sequence dictionary as an input to specify which contigs should be plotted; typically, this will be a subset of the full dictionary that excludes alt contigs, etc. Requiring this sequence-dictionary input is somewhat vestigial; previous versions of the pipeline did not include dictionaries in the headers of all CNV data files. Part of making these tools into GATKTools could include switching over to -L to specify regions for plotting.). Finally, are the changes to `-imr` mentioned in #2471 going to be addressed in a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363209925:600,pipeline,pipeline,600,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363209925,1,['pipeline'],['pipeline']
Deployability,This makes the Docker container more interoperable with other GATK containers that might not install to /gatk,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3866:93,install,install,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3866,1,['install'],['install']
Deployability,This matches arguments of various tools used in gCNV pipeline to those used for running large exome cohorts.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8234:53,pipeline,pipeline,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8234,1,['pipeline'],['pipeline']
Deployability,"This method is for unit/integration testing purposes only, and should not be called from tools.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4430:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4430,1,['integrat'],['integration']
Deployability,"This micro-optimization fell out of profiling of the HaplotypeCaller in GVCF mode. . Profiler view over an Exome before this patch:; <img width=""906"" alt=""screen shot 2018-11-30 at 2 06 34 pm"" src=""https://user-images.githubusercontent.com/16102845/49310230-bc44a380-f4ab-11e8-98aa-1c0b321223c0.png"">. Profiler view over the same Exome after this patch:; <img width=""886"" alt=""screen shot 2018-11-30 at 2 20 39 pm"" src=""https://user-images.githubusercontent.com/16102845/49310291-e4cc9d80-f4ab-11e8-9fb3-4d819fbce43a.png"">. I suspect given the remaining 9% runtime could be reduced further by looking more closely at the array operations in `isReadInformativeAboutIndelsOfSize()` . (It should be noted that these profiler results lie within the ReferenceModelForNoVariation codepath which since this is over an Exome we expect the runtime to overall be skewed towards no-variation blocks). Resolves #5648",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5469:125,patch,patch,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5469,2,['patch'],['patch']
Deployability,"This might be related to our upgrading to Spark/Hadoop 3.3.1 in the 4.4.0.0 release -- apart from that, I don't think there were any changes to this specific tool. @lbergelson any thoughts/suggestions?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8307#issuecomment-1535220932:76,release,release,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8307#issuecomment-1535220932,1,['release'],['release']
Deployability,"This moves us to a snapshot of google-cloud-java based off of a branch in my fork here: https://github.com/droazen/google-cloud-java/tree/dr_retry_CloudStorageReadChannel_fetchSize. This patch wraps many more operations within retries, and in our tests resolves the intermittent 503/SSL errors completely when running at scale. This PR also migrates us from setting retry settings per-Path to setting it globally, using a new API from that google-cloud-java branch. This fixes an issue where the number of reopens was getting set to 0 deep in the google-cloud-java library. Resolves #2749; Resolves #2685; Resolves #3118; Resolves #3120; Resolves #3253",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3295:187,patch,patch,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3295,1,['patch'],['patch']
Deployability,"This new PathSeq WDL redesigns the workflow for improved performance in the cloud. Downsampling can be applied to BAMs with high microbial content (ie >10M reads) that normally cause performance issues. . Other improvements include:. * Removed microbial fasta input, as only the sequence dictionary is needed.; * Broke pipeline down to into smaller tasks. This helps reduce costs by a) provisioning fewer resources at the filter and score phases of the pipeline and b) reducing job wall time to minimize the likelihood of VM preemption.; * Filter-only option, which can be used to cheaply estimate the number of microbial reads in the sample.; * Metrics are now parsed so they can be fed as output to the Terra data model.; * CRAM-to-BAM capability; * Updated WDL readme; * Deleted unneeded WDL json configuration, as the configuration can be provided in Terra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6536:319,pipeline,pipeline,319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6536,5,"['Update', 'configurat', 'pipeline']","['Updated', 'configuration', 'pipeline']"
Deployability,This now outputs median coverage in addition to the mean coverage which was already being output before from the Mitochondria pipeline. @ahaessly Could you please take a look at this?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7253:126,pipeline,pipeline,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7253,1,['pipeline'],['pipeline']
Deployability,This or these tool would be use to use piece meal bam files that we can use for local (laptop/desktop) development and integration tests. The input would be SV called variant VCF with and two intervals lists. The first one would indicate for what variants in input we want to gather the evidence reads and the second the supported reference interval in the output (anything outside that interval will be changed to unmapped). The second interval list must include the first interval list since otherwise it would not make any sense.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2504:119,integrat,integration,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2504,1,['integrat'],['integration']
Deployability,"This patch causes some tests to fail in `GenotypeGVCFsIntegrationTest` -- I suspect that the newer output is likely to be more correct, however. Will have to manually inspect the outputs",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8288#issuecomment-1508743628:5,patch,patch,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8288#issuecomment-1508743628,1,['patch'],['patch']
Deployability,"This pr adds a step to the VAT pipeline which will export each chromosome of the VAT (TODO need to add X, Y, M) into it's own directory in GCS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7472:31,pipeline,pipeline,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7472,1,['pipeline'],['pipeline']
Deployability,"This pr adds the subpopulation AC/AN/AF calculations.; It does this by taking in the ancestry table and making sublists of each---then passing that list of samples into the SelectVariants GATK tool. Updated Lucid chart here: https://lucid.app/lucidchart/fee376a4-4b72-481e-a239-a027f7f6ab1f/edit?page=CsG3hy3S1zEH#. Design Doc for this work:; https://docs.google.com/document/d/1FnPu_Jkz2O9rElApAQld0v6iBEFGe22dKarVWcwNxGI/edit. misc:; how should I add the VAT validation to the VAT pipeline? Should it run automatically?. Anvil data version of this table: spec-ops-aou:anvil_100_for_testing.vat_aug19. <img width=""1379"" alt=""Screen Shot 2021-08-11 at 5 38 22 PM"" src=""https://user-images.githubusercontent.com/6863459/129606564-bfc20a68-119a-4072-88b4-aeaf011cc965.png"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7399:199,Update,Updated,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7399,2,"['Update', 'pipeline']","['Updated', 'pipeline']"
Deployability,"This produces a resource that will be used as input to an upcoming tool to filter intervals based on these annotations (as well as coverage statistics). Currently, we have an external python script performing this step in the gCNV pipeline. I also updated the AnnotateIntervals task and calls in WDL, but these changes are untested; the reviewer should check carefully for typos. Currently, all annotations are of double type, but I've added code that can support all types supported by the TSV code as well. Additional tracks can also be added relatively easily. Currently, allowed annotations and their corresponding types are hardcoded; we could possibly move this information to the SAM-style header in the future. For the Umap hg19 k100 single-read mappability track and the segmental-duplication track used by the Talkowski lab, annotation of 1kb bins on hg19 takes less than a minute with the default feature lookahead (which is exposed as a parameter). I tested using the Umap multi-read mappability track (which is orders of magnitude larger, but is actually what is used in the external script), but this is much slower (documentation indicates that the single-read track should be used to dissuade this). We should evaluate whether or not using the single-read track suffices for filtering.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5162:231,pipeline,pipeline,231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5162,2,"['pipeline', 'update']","['pipeline', 'updated']"
Deployability,"This pull request updates the environment to include `pytorch` to gatk conda environment. This required an update to numpy and consequently updates of PyMC3 and its dependencies, as well as parts of gCNV code.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8094:18,update,updates,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8094,3,['update'],"['update', 'updates']"
Deployability,"This pulls the bulk of the pipeline into a separate subworkflow so that the validations (with the mixture samples) can be run. The mixtures have already been subset and tagged, which is why the rest of the pipeline needed to be extracted.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5708:27,pipeline,pipeline,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5708,2,['pipeline'],['pipeline']
Deployability,"This read filter removes unnmapped reads and reads with unmapped mates. When used in combination with `MateOnSameContigOrNoMappedMateReadFilter` this subsets down to reads only on chrM whose mate is also on chrM. If we only used the `MateOnSameContigOrNoMappedMateReadFilter` we end up with reads whose mate is unmapped still in the BAM, but not the unmapped read, which causes problems downstream in the mitochondria pipeline. This read filter will make the subsetting step faster when we no longer need the NuMTs. I would really appreciate this getting in before the next release (on Tuesday). (fyi @droazen) @ldgauthier @jsotobroad",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5826:418,pipeline,pipeline,418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5826,2,"['pipeline', 'release']","['pipeline', 'release']"
Deployability,This release also errors out with a descriptive error message if the length of a field in the data lines does not match the length descriptor in the header - see https://github.com/broadinstitute/gatk/issues/5045.; Error out behavior as per [Laura's comment here](https://github.com/broadinstitute/gatk/issues/5113#issuecomment-413667356),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5397#issuecomment-437140783:5,release,release,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5397#issuecomment-437140783,1,['release'],['release']
Deployability,"This release contains important bugfixes, including a fix for https://github.com/broadinstitute/gatk/issues/8141 (intermittent failure to properly compress outputs)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8409:5,release,release,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8409,1,['release'],['release']
Deployability,This release fixes (among other issues) a bug that could cause the; AVX compatibility check to hang on CentOS machines.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3392:5,release,release,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3392,1,['release'],['release']
