quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Availability,This is a type error: your input argument doesn't match the declared type of the function. Try `assert transform_row_type == mt.row.dtype` before the application of `transform_row_f`. I'll beef up the error reporting of my define_function prototype so the error gets caught before hitting the JVM.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5435#issuecomment-467643750:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/5435#issuecomment-467643750,3,['error'],['error']
Availability,"This is a violation of OOP style -- . ```; class A:; def foo(self):; ... class B(A):; def foo(self, bar):; ... class C(A):; def foo(self, bar, baz):; ...; ```. If I have an `A` and call `foo()` (valid signature for an A!) I'll get an error about calling a function with an incorrect signature. I haven't poked around the CI design enough to understand the intention of the code, but maybe we should just remove the definition from the superclass?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6142#issuecomment-497843719:234,error,error,234,https://hail.is,https://github.com/hail-is/hail/issues/6142#issuecomment-497843719,1,['error'],['error']
Availability,"This is an improvement, but I think we should reconsider the batch state. Thinking out loud: The batch and CI UIs have slightly different displays. If you're running, have had a failed job, but also been cancelled, what should your state be? I think we either need columns in the batch display for open/closed, cancelled, complete and the simple state (open, running, cancelled, failure, success ... where the latter 3 mean complete), or display compound states like ""running failure cancelled"".",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7897:379,failure,failure,379,https://hail.is,https://github.com/hail-is/hail/pull/7897,2,['failure'],['failure']
Availability,"This is an overflow bug that's existed since June 25: https://github.com/hail-is/hail/pull/3833. The implementation was vulnerable to `(a + b) * (c + d) * (b + d) * (a + c)` exceeding max int.; ```; val ad = a * d; val bc = (b * c).toDouble; val det = ad - bc; val chiSquare = (det * det * (a + b + c + d)) / ((a + b) * (c + d) * (b + d) * (a + c)); ```; If so, chiSquare and hence the p-value would be wrong.; The odds ratio was also susceptible to overflow, though less so: if `a * d` or `b * c` exceeded max int. The new implementation converts the ints to floats and is more robust if we switch to allowing float inputs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4192#issuecomment-415137754:579,robust,robust,579,https://hail.is,https://github.com/hail-is/hail/issues/4192#issuecomment-415137754,1,['robust'],['robust']
Availability,"This is better, but I want to go more extreme:. - get rid of TransformedRegionValueAggregator and ZippedRegionValueAggregator. This is a compiler backend. Too much abstraction in your output! Let's compile that shit away.; - ExtractAggregators should return an Array[AggSum]. These are expressions ending in AggSum containing aggregator operations (filter, map, etc.) defined in terms of the aggregated element and associated context.; - Add a function AggSum => RegionValueAggregator. This is the way to generalize: make AggSum into Agg(op: AggOp) where AggOp (like unary and binary op) are all the possible aggregator types, and there is a function that maps the op to the corresponding RegionValueAggregator*; - compiling the Array[AggSum] should product a function that takes the array of aggregators and a single value (with context) of the collection we're aggregating over and updates them with that element. *I think you need an array of arguments to handle things like call_stats which are evaluated in the aggregator scope (the only scope available to evaluate something). Imagine you have `gs.filter(g => g.GT.isHet()).map(g => g.DP).sum() + gs.flatMap(g => g.PL).sum()`. The Array[AggSum] will be. ```; Array(AggSum(AggMap(; AggFilter(AggIn(...), ; ""g"", g.GT.isHet()),; ""g"", (getField (Ref ""g"") ""DP""),; AggSum(AggFlatMap(AggIn(...),; ""g"", (getField (Ref ""g"") ""PL))); ```. The generated function should look like:. ```; def f(aggs: Array[AggSum], region: MemoryBuffer, g: Long, mg: Boolean, ...) {; if (g.GT.isHet()) { // RV-ified, of course; val DP = g.DP // actually fieldOffset; aggs(0).seqOp(DP); }; for (PLi in g.PL) { // actually elementOffset; aggs(1).seqOp(PLi); }; }; ```. This is straight-line and should be fast. It immediately allows you to do common subexpression elimination on aggregator prefixes which is something that is quite common, that is, if you have `gs.filter(g => g.isHet).map(g => g.DP).mean() < 10 gs.filter.map(g => g.GQ).mean() < 50` then in the aggregation fu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2555#issuecomment-350868684:1049,avail,available,1049,https://hail.is,https://github.com/hail-is/hail/pull/2555#issuecomment-350868684,1,['avail'],['available']
Availability,"This is caused by domain-by-domain CSRF tokens introduced in [#14180](https://github.com/hail-is/hail/issues/14180). An unfortunate side effect is that the tokens available on non-auth pages are no longer able to validate requests to the auth/logout API. Given the lack of apparent noise about this bug in our issues and zulip I suspect that this is not a common path for users, and that a fix along the lines of ""require add one button click to go to the User page first before logging out is acceptable"". On the other hand, the risk of a user clicking on the broken Logout button and believing themselves to be logged out when seeing a `401: Unauthorized` page (but actually still having logged-in state in their browser) raises this in my mind to a security bug rather than just a UX bug or an unfortunate user experience. Therefore my proposal is:; 1. To fix the bug as soon as possible; 2. Accept an additional redirect in a user flow which is rarely exercised; 3. To make the smallest number of potentially risky changes to the underlying security architecture; 4. Therefore: Remove the broken ""log out"" link in page headers and replace with a Log out button on the auth[...]/users page which is guaranteed to have the correct CSRF token in state.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14635#issuecomment-2253086187:163,avail,available,163,https://hail.is,https://github.com/hail-is/hail/issues/14635#issuecomment-2253086187,2,['avail'],['available']
Availability,This is causing CI to have 500 errors.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7542:31,error,errors,31,https://hail.is,https://github.com/hail-is/hail/pull/7542,1,['error'],['errors']
Availability,This is definitely no longer high-prio -- we'll throw the correct error message now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6223#issuecomment-500771034:66,error,error,66,https://hail.is,https://github.com/hail-is/hail/issues/6223#issuecomment-500771034,1,['error'],['error']
Availability,This is failing with this message:. ```; + python3 -m pylint --rcfile pylintrc hailtop; ************* Module hailtop.aiotools.weighted_semaphore; /usr/local/lib/python3.7/dist-packages/hailtop/aiotools/weighted_semaphore.py:2:0: E0401: Unable to import 'sortedcontainers' (import-error); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10752#issuecomment-897018931:280,error,error,280,https://hail.is,https://github.com/hail-is/hail/pull/10752#issuecomment-897018931,1,['error'],['error']
Availability,"This is fine: [x.txt](https://github.com/hail-is/hail/files/12231007/x.txt). ```; In [11]: import hail as hl; ...: gwas = hl.read_table(""gwas_filtered.ht""); ...: loci_to_gene = hl.import_table(""x.txt"",impute=True); ...: locus = hl.locus(loci_to_gene.chromosome, loci_to_gene.locus, ""GRCh38""); ...: loci_to_gene = loci_to_gene.annotate(locus=locus); ...: loci_to_gene = loci_to_gene.key_by(""locus""); ...: loci_to_gene = loci_to_gene.select(""gene""); ...: loci_to_gene = loci_to_gene.filter(loci_to_gene.locus.position == 51749536); ...: loci_to_gene = loci_to_gene.checkpoint('/tmp/foo.ht', overwrite=True); ...: print(gwas.collect()); ...: print(loci_to_gene.collect()); ...: gwas.annotate(gene=loci_to_gene[gwas.locus].gene).collect(); 2023-08-01 10:54:33.166 Hail: INFO: Reading table to impute column types; 2023-08-01 10:54:33.864 Hail: INFO: Finished type imputation; Loading field '' as type int32 (imputed); Loading field 'chromosome' as type str (imputed); Loading field 'locus' as type int32 (imputed); Loading field 'gene' as type str (imputed); 2023-08-01 10:54:34.137 Hail: INFO: Coerced sorted dataset; 2023-08-01 10:54:35.270 Hail: INFO: wrote table with 1 row in 1 partition to /tmp/foo.ht; [Struct(locus=Locus(contig=chr8, position=51749536, reference_genome=GRCh38), alleles=['G', 'T'])]; [Struct(locus=Locus(contig=chr8, position=51749536, reference_genome=GRCh38), gene='PXDNL')]; Out[11]: [Struct(locus=Locus(contig=chr8, position=51749536, reference_genome=GRCh38), alleles=['G', 'T'], gene='PXDNL')]; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13339#issuecomment-1660499132:563,checkpoint,checkpoint,563,https://hail.is,https://github.com/hail-is/hail/issues/13339#issuecomment-1660499132,1,['checkpoint'],['checkpoint']
Availability,"This is generating some 500 errors, having a hard time debugging without hail-vdc.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9219#issuecomment-669818238:28,error,errors,28,https://hail.is,https://github.com/hail-is/hail/pull/9219#issuecomment-669818238,1,['error'],['errors']
Availability,This is getting this SQL error in create_batch2_tables:. ERROR 1215 (HY000) at line 70: Cannot add foreign key constraint,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7437#issuecomment-549065979:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/7437#issuecomment-549065979,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"This is going to cause problems down the line. Here's an example where inappropriate use of parentheses does something unexpected:; ```python; In [39]: x = functions.capture(5). In [40]: eval_expr((3 < x) & x > 5); Out[40]: True. In [41]: eval_expr((3 < x) & (x > 5)); Out[41]: False; ```; I'm actually not sure what the order of operations is in [40], but it's clearly wrong.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2640:32,down,down,32,https://hail.is,https://github.com/hail-is/hail/issues/2640,1,['down'],['down']
Availability,"This is great! From a downstream utility perspective, should this return BlockMatrix, or a hail table keyed by sample (more like what hl.hwe_normalized_pca returns)? I feel like most analytics would then be plotting PCs, or using them in models, but I might be missing an application that needs BlockMatrix",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14326#issuecomment-1957636454:22,down,downstream,22,https://hail.is,https://github.com/hail-is/hail/pull/14326#issuecomment-1957636454,1,['down'],['downstream']
Availability,"This is great, thanks @cseed! I've tried the gradlew option, and it worked well on Debian Jessie with java-8-oracle. `./gradlew installDist` worked, and the majority of the tests passed in `./gradlew check` (4 failed; I can give you the details if this is useful). On Ubuntu 16.04 with java-8-openjdk (the default) I get an error:. ```; :compileJava UP-TO-DATE; :compileScala; /home/jk/github/hail/src/main/scala/org/broadinstitute/hail/expr/Type.scala:80: not enough arguments for constructor AnnotationPathException: (msg: String)org.broadinstitute.hail.annotations.AnnotationPathException; throw new AnnotationPathException(); ^; /home/jk/github/hail/src/main/scala/org/broadinstitute/hail/expr/Type.scala:98: not enough arguments for constructor AnnotationPathException: (msg: String)org.broadinstitute.hail.annotations.AnnotationPathException; throw new AnnotationPathException(); ^; /home/jk/github/hail/src/main/scala/org/broadinstitute/hail/expr/Type.scala:424: not enough arguments for constructor AnnotationPathException: (msg: String)org.broadinstitute.hail.annotations.AnnotationPathException; case None => throw new AnnotationPathException(); ^; three errors found; :compileScala FAILED. FAILURE: Build failed with an exception.; ```. Is this a dependency on java-8-oracle do you think?. My immediate problem is solved, as I have hail running now, so this is just out of curiosity really. l think it would be good for new users if you could nail down the dependencies a bit more precisely. For testing and development, it's also really useful to be able to spin up a quick Ubuntu VM, apt-get install a few packages and make a fresh install.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/594#issuecomment-240346120:324,error,error,324,https://hail.is,https://github.com/hail-is/hail/issues/594#issuecomment-240346120,4,"['FAILURE', 'down', 'error']","['FAILURE', 'down', 'error', 'errors']"
Availability,"This is great, thanks for working on this!. > I have not added an example to the documentation that uses a matrix table yet. (This is an https://github.com/hail-is/hail/issues/13481.) I wanted to get some advice about the best way to do this. I think ideally, the example would have a binary phenotype, an allele to test for association, and some stratifying variable. I tried to search through the existing code to find suitable example matrix tables in the docstrings, but I didn't find anything promising. I would appreciate help here. The code that sets up the doctest environment is [here](https://github.com/hail-is/hail/blob/8a0e8e3375f1fc11efb5a443a350a8b4e8a24950/hail/python/hail/conftest.py#L55). In particular, the matrixtable available in doc examples as `ds` lives at `hail/hail/python/hail/docs/data/example.mt`. It has lots of fields you can use:; ```; In [3]: mt = hl.read_matrix_table('python/hail/docs/data/example.mt'). In [4]: mt.describe(); ----------------------------------------; Global fields:; 'global_field_1': int32; 'global_field_2': int32; 'pli': dict<str, float64>; 'populations': array<str>; ----------------------------------------; Column fields:; 's': str; 'sample_qc': struct {; dp_stats: struct {; mean: float64,; stdev: float64,; min: float64,; max: float64; },; gq_stats: struct {; mean: float64,; stdev: float64,; min: float64,; max: float64; },; call_rate: float64,; n_called: int64,; n_not_called: int64,; n_filtered: int64,; n_hom_ref: int64,; n_het: int64,; n_hom_var: int64,; n_non_ref: int64,; n_singleton: int64,; n_snp: int64,; n_insertion: int64,; n_deletion: int64,; n_transition: int64,; n_transversion: int64,; n_star: int64,; r_ti_tv: float64,; r_het_hom_var: float64,; r_insertion_deletion: float64; }; 'is_case': bool; 'pheno': struct {; is_case: bool,; is_female: bool,; age: float64,; height: float64,; blood_pressure: float64,; cohort_name: str; }; 'cov': struct {; PC1: float64; }; 'cov1': float64; 'cov2': float64; 'cohort': str; 'cohorts':",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14255#issuecomment-1932814827:739,avail,available,739,https://hail.is,https://github.com/hail-is/hail/pull/14255#issuecomment-1932814827,1,['avail'],['available']
Availability,"This is in implementation of `linear_regression_rows` that does not rely on any `MatrixToTableApply` nodes. Once `TableKeyBy` is lowered, this should be executable on the service. There are lingering issues:. 1. `TableGroupWithinPartitions` is likely not the right abstraction. It forgets about keying, which forces me to rekey and scan the table even though it's already in order. 2. I don't support chained linear regression (the situation where `y` is a list of lists of phenotypes). I just throw an error there for now. . 3. It's not as fast as the current `linear_regression_rows` (addressing problem 1 should help with this). 4. I don't yet support the `pass_through` field. I want to PR this now because I would like to get the benchmark in so I can continue to measure how this performs in comparison to the current version of `linear_regression_rows`. The tests of this method also serve as useful integration tests for lots of NDArray functionality. Additionally, it'll make it easier to make a smaller PR in the future that adds the new `TableIR` that will hopefully be more suitable than `TableGroupWithinPartitions`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8757:503,error,error,503,https://hail.is,https://github.com/hail-is/hail/pull/8757,1,['error'],['error']
Availability,This is in response to this failure: https://storage.googleapis.com/hail-ci-0-1/ci/7aa524504b8bafe0a4af859e73bc4f9efdaa052c/39a94649482a2512a7a514e6084c5b84f48b8205/index.html. Which might be mis-diagnosed.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4517#issuecomment-428986578:28,failure,failure,28,https://hail.is,https://github.com/hail-is/hail/issues/4517#issuecomment-428986578,1,['failure'],['failure']
Availability,"This is kind of an annoying problem to have because these pip installed versions are frozen in time. I feel like these steps are either redundant (nothing has changed), or will fail because we've updated the checks to improve on what we had at last release. What do these steps really do for us?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11502#issuecomment-1061003165:136,redundant,redundant,136,https://hail.is,https://github.com/hail-is/hail/pull/11502#issuecomment-1061003165,1,['redundant'],['redundant']
Availability,"This is mostly cleanup reducing the amount of the codebase that depends on GSA key files (which are not available in terra or a future keyless hail-vdc). The core bit is instead of threading `credentials_file=""/gsa-key/key.json` through the batch and auth codebase we set `GOOGLE_APPLICATION_CREDENTIALS` in their deployments. I can't think of a scenario where `auth` or `batch` would need to use multiple identities so better to remove their ability to do so and always use the default credentials. I also did a bit of tidying up, using `$GOOGLE_APPLICATION_CREDENTIALS` instead of the hard-coded path and removing the credentials endpoints on the batch-driver which have been unused by workers for many months now.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13596:104,avail,available,104,https://hail.is,https://github.com/hail-is/hail/pull/13596,1,['avail'],['available']
Availability,"This is mostly straightforward, except in the case of PBinary and PString, where I elected to move static methods to instance methods. This was done because these methods completely depend on the PType, and having them as static methods prevents use of non-canonical versions of these methods (regardless of where they are). This includes functions like allocate, which deal with memory layout, and therefore must be configurable by ptype. Places where these static methods are used often include places where a PString or PBinary are passed around. Will finish this up after I get back most likely, or we can punt on the PStirng/PBinary issue for later (but I think it's worth doing now for the reasons outlined above). Stacked on https://github.com/hail-is/hail/pull/7903; ping @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7904:775,ping,ping,775,https://hail.is,https://github.com/hail-is/hail/pull/7904,1,['ping'],['ping']
Availability,"This is my first ever git commit so let me know if there are any changes needed. I tested this functionality by building Hail on my Amazon Linux 2 system before vs after. After removal of the ""sys_platform!='win32'"" the error was no longer happening.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1229010436:220,error,error,220,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1229010436,1,['error'],['error']
Availability,"This is needed to properly implement copy/rename when you don't know if the source is a file or directory. We now only stat dest if treat_dest_as == INFER_DEST. Suppose we do `cp src dest`. There are three cases:. - Treat dest as a directory, and copy `src` to `dest/src`; - Treat dest like the target, and copy `src` to `dest` (whether src is a file or directory).; - Infer the type of dest and act accordingly. If `dest` is a directory, we're in the first case. If dest doesn't exist, or is a file, we're in the second case. I added two tests cases: test_copy_rename_dir_dest_is_target and test_overwrite_rename_dir, which test copying a directory with DEST_IS_TARGET (when the dest exists or not). I already had tests for when we were copying a file. I regenerated the copy test specs because of renames and some minor changes to error checking behavior. I spot checked the differences, and they don't seem worse (e.g. `cp file destfile/` now generates an error instead of ignoring the trailing slash.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10127:833,error,error,833,https://hail.is,https://github.com/hail-is/hail/pull/10127,2,['error'],['error']
Availability,"This is not a real error. It is not the fault of batch that the other; end of the connection did not respond. If batch is having general; network connectivity issues, I would expect to see many other; error log statements.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11383:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/11383,3,"['error', 'fault']","['error', 'fault']"
Availability,"This is not this interface's final form, but it is an important; transitionary step in moving the entire code generation codebase away; from Code[T]. The CodeOrdering interface now (as before) has 12 methods, but before; the function signatures looked like:. def compare(lhs: (Code[Boolean], Code[T]), rhs: (Code[Boolean], Code[T])) -> Code[Int]. They now look like:. def compare(cb: EmitCodeBuilder, lhs: EmitCode, rhs: EmitCode) -> Code[Int]. There have been a lot of miscellaneous changes needed to get this to; work. There's some stuff that needs to be cleaned up, notably in Emit,; it's not always the case that the type of the IR/Aggregator is the same; as the type of the EmitCode that emit produces. I've tried to add; assertions where possible, but if there is an error, then a rather; cryptic 'Cannot pop value off of empty stack' exception is thrown,; generally indicating that an ordering expected an optional value, but; a required emitcode was provided.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9825:773,error,error,773,https://hail.is,https://github.com/hail-is/hail/pull/9825,1,['error'],['error']
Availability,This is now available in 4.80.0 through 5.2.0. Work for this issue is:. 1. Upgrade to latest 4.x.x; 2. Encode cleanup policies in terraform.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13504#issuecomment-1773465652:12,avail,available,12,https://hail.is,https://github.com/hail-is/hail/issues/13504#issuecomment-1773465652,1,['avail'],['available']
Availability,This is part 1 in mitigating the extra rows in the billing tables with redundant resources with the same prices. I'm not sure how long it takes to drop a table of this size. Would prefer to merge in the morning in case there are any issues.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12710:71,redundant,redundant,71,https://hail.is,https://github.com/hail-is/hail/pull/12710,1,['redundant'],['redundant']
Availability,"This is ready for final review. Since Konrad is blocked by it, I suggest, unless there are correctness failures or major performance issues, we merge it and I will address comments in follow up PRs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7875#issuecomment-575711955:103,failure,failures,103,https://hail.is,https://github.com/hail-is/hail/pull/7875#issuecomment-575711955,1,['failure'],['failures']
Availability,This is ready for review. I keep getting unrelated transient errors in this PR.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12742#issuecomment-1458692668:61,error,errors,61,https://hail.is,https://github.com/hail-is/hail/pull/12742#issuecomment-1458692668,1,['error'],['errors']
Availability,"This is ready to look at. i tried to track down the one failure in test_benchmark, but couldn't do so.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9972#issuecomment-772045985:43,down,down,43,https://hail.is,https://github.com/hail-is/hail/pull/9972#issuecomment-772045985,2,"['down', 'failure']","['down', 'failure']"
Availability,"This is really great. . I have some thoughts below, mostly brain storming. Don't take any of it too seriously. Some thoughts:. 1. I thought you wanted to support f-strings. By making the batch file quote double curly parens, that means if you use them in an f-string, you need to write `f'{{{{foo}}}}'` which is a bit much. But that means that non-batch uses of `{}` need to be double-quoted, so `awk '{{ ... }}'` and `f""awk '{{{{ ... }}}}'""`. Hmm. Maybe using the same escape syntax as f-strings is not ideal. . I don't have a no-brainer suggestion. Happy to brainstorm ideas offline. I think ultimately this is a minor syntactic choice. 2. Inputs seem ... almost redundant, because they also appear in the command strings. What about:. ```; .command('shapeit --bed-file {{<subset.ofile}} --chr ' + contig + ' --out {{>ofile}}'); ```. Then the question becomes, how do associate `subset` with the corresponding Python variable? You could use the task label, but then the user has to maintain two sets of names, which isn't ideal. Hmm, maybe this doesn't work. 3. I like arrays of resources!. > `.command('cat {{files}} >> {{ofile}}')`. I wonder, will we ever want arrays to be formatted other than joined with spaces? I worry the user will want more flexibility in formatting, and we'll want that in Python. What about if the argument is a function, it takes a dictionary from resource names to their string representation, and you can format however you want? Then you could write the last command as:. ```; .command(lambda rs: f'cat {' '.join(rs['files'])} >> {rs['ofile']}'); ```. 4. I was confused by this:. > `p.write_output(merger.ofile + "".haps"", ...)`. What's the left hand side? Why isn't this just `merger.ofile`?. This suggests another issue: what if you want to use `ofile` in a plink command, but plink outputs some files with various extensions with `ofile` as the base? We might need an `outputs` that lists (docker local) output files based on a base path.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4937#issuecomment-446733609:665,redundant,redundant,665,https://hail.is,https://github.com/hail-is/hail/pull/4937#issuecomment-446733609,1,['redundant'],['redundant']
Availability,"This is running into the split_multi issue. it *would* be running into this error in the RVD iterator, but we don't perform this check too many places anymore nowadays and it's not hitting this check anywhere after the split happens.; ```; if (localType.kRowOrd.gt(prevK.value, rv)) {; kUR.set(prevK.value); val prevKeyString = kUR.toString(). prevK.setSelect(localType.rowType, localType.kFieldIdx, rv); kUR.set(prevK.value); val currKeyString = kUR.toString(); fatal(; s""""""RVD error! Keys found out of order:; | Current key: $currKeyString; | Previous key: $prevKeyString; |This error can occur after a split_multi if the dataset; |contains both multiallelic variants and duplicated loci.; """""".stripMargin); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6223#issuecomment-498870292:76,error,error,76,https://hail.is,https://github.com/hail-is/hail/issues/6223#issuecomment-498870292,3,['error'],['error']
Availability,This is the cause of master test failures. More detail to follow.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6086:33,failure,failures,33,https://hail.is,https://github.com/hail-is/hail/issues/6086,1,['failure'],['failures']
Availability,"This is the compiled BGEN decoder. there's a fix to the partitioning logic as well. If there's no partitions, it previously errored. I added a `math.max` in case the maxRecordPerPartition is huge and the records is small and their floating point ratio ends up as zero. You can more easily see these changes when ignoring whitespace: https://github.com/hail-is/hail/pull/3916/files?w=1. ---. I reverted back to the `Iterator[Option[RegionValue]]` because per-row allocation isn't that bad and it just seems kind of hard an unnecessary ðŸ¤·â€â™€ï¸ . cc: @patrick-schultz",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3916:124,error,errored,124,https://hail.is,https://github.com/hail-is/hail/pull/3916,1,['error'],['errored']
Availability,"This is the initial terraform setup to spinning up resources in azure, from downloading the `az` cli to getting a kubernetes cluster, database and network running. This contains instructions on initializing terraform using a remote backend in an azure container so multiple people should be able to apply terraform changes and have the same view of the system. Next step is setting up the gateway and internal gateways so that we can communicate between k8s services and VMs in the batch worker subnet.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10815:76,down,downloading,76,https://hail.is,https://github.com/hail-is/hail/pull/10815,1,['down'],['downloading']
Availability,"This is the most recently deployed version of monitoring.yaml. I'm not sure the best way to test it solves the problem that deployments faced. One thing to note is that StatefulSets don't guarantee that all of their constituent pods get deleted when the StatefulSet is deleted. To be sure the pods all get deleted, we'd have to either manually delete them or scale the StatefulSet size down to 0 before deleting it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6343:386,down,down,386,https://hail.is,https://github.com/hail-is/hail/pull/6343,1,['down'],['down']
Availability,"This is the plan for the new Hail CI (tentatively: Hephaestus aka h8s [but Hodor is also in the running, see CI software name in Zulip for the real big questions of our time]). # Expected Repo Structure; Every repository to be tested has at least two files: `hail-ci-build-image` and `hail-ci-build.sh`. The former contains a docker image in a publicly accessible repository. The latter is a shell script that exits with 0 if this branch passes the tests, otherwise it exists with a non-zero code. The logs of this shell script will be shared publicly via the GH PR Status. This script will be executed in the image referenced by `hail-ci-build-image`. # Dockerfile.pr-builder; I carefully wrote a docker file to cache as much gradle crap as possible. # gitHash in Gradle; I pushed `gitHash`'s definition into the `doLast` blocks of the gradle steps that actually need it. `doLast` is only run when the task is actually requested. This allows me to run `downloadDependencies` without creating a dependency on the entire `.git` directory (which changes with each commit, thus invalidating the cache'd docker image).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4066:954,down,downloadDependencies,954,https://hail.is,https://github.com/hail-is/hail/pull/4066,1,['down'],['downloadDependencies']
Availability,"This is the result of some experimentation. With ten-way parallelism, the copier very rarely gets rate-limited. With 75-way parallelism (the default), we almost always experience a tens of transient errors. If we start at ten and back off as in this PR, I can get to 75 with just a handful of transient errors. cc: @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13833:199,error,errors,199,https://hail.is,https://github.com/hail-is/hail/pull/13833,2,['error'],['errors']
Availability,This is the same issue as #8487. Not actually generating the error; throwing code.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8488:61,error,error,61,https://hail.is,https://github.com/hail-is/hail/pull/8488,1,['error'],['error']
Availability,"This is unfortunately about 2x slower -- partly due to the fact; that the column + global concordance calculations are not fused,; and partly because the AggArrayPerElement stuff seems pretty; slow right now and is dragging down the per-sample concordance.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6224:224,down,down,224,https://hail.is,https://github.com/hail-is/hail/pull/6224,1,['down'],['down']
Availability,This is unused and the same as `INTERNAL_GATEWAY_IP` a few variables down,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12005:69,down,down,69,https://hail.is,https://github.com/hail-is/hail/pull/12005,1,['down'],['down']
Availability,"This is used to print the resource name in several error messages, which failed when the error occurred for an item within a ResourceGroup. Proposed fix addressing part of #13191, for your consideration. Fixes #13191",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13192:51,error,error,51,https://hail.is,https://github.com/hail-is/hail/pull/13192,2,['error'],['error']
Availability,"This is why copying is so slow:. ```; ==> NOTE: You are uploading one or more large file(s), which would run; significantly faster if you enable parallel composite uploads. This; feature can be enabled by editing the; ""parallel_composite_upload_threshold"" value in your .boto; configuration file. However, note that if you do this large files will; be uploaded as `composite objects; <https://cloud.google.com/storage/docs/composite-objects>`_,which; means that any user who downloads such objects will need to have a; compiled crcmod installed (see ""gsutil help crcmod""). This is because; without a compiled crcmod, computing checksums on composite objects is; so slow that gsutil disables downloads of composite objects. / [1/1 files][ 4.1 GiB/ 4.1 GiB] 100% Done 45.8 MiB/s ETA 00:00:00; Operation completed over 1 objects/4.1 GiB.; ```. We can also set this with -o GSUtil:parallel_composite_upload_threshold on the command line. https://cloud.google.com/storage/docs/gsutil/commands/cp. We currently use `-m` which is parallel per-file:. If you have a large number of files to transfer you might want to use the; gsutil -m option, to perform a parallel (multi-threaded/multi-processing); copy:. gsutil -m cp -r dir gs://my-bucket",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7024:475,down,downloads,475,https://hail.is,https://github.com/hail-is/hail/pull/7024,2,['down'],['downloads']
Availability,"This is working except I can't figure out how to delete entries from /etc/projects and /etc/projid when the job finishes. You can't copy or move a file to a bind-mounted file in Docker or you get a ""resource or device busy"" error. This will all work without deleting the entries, but then every time you try and add a new project, you get a directory not found error for previously deleted paths, but the operation will continue successfully ignoring the errors. Any ideas on how to get around this? `sed -i` won't work as well as `mv` and `cp`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9076#issuecomment-657239708:224,error,error,224,https://hail.is,https://github.com/hail-is/hail/pull/9076#issuecomment-657239708,3,['error'],"['error', 'errors']"
Availability,"This isn't needed any more, since setAggState() and newAggState() do the right thing when called. At least on my laptop, this brings the one test down to ; ```; Name	Mean	Median	StDev; matrix_table_many_aggs_col_wise	24.275	24.372	0.818; ```; vs with the flag disabled, which is ; ```; Name	Mean	Median	StDev; matrix_table_many_aggs_col_wise	30.147	29.706	1.868; ```; (oops)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6791:146,down,down,146,https://hail.is,https://github.com/hail-is/hail/pull/6791,1,['down'],['down']
Availability,"This isn't quite ready, but PR'ing to draw a line in the sand. There are compile errors in concordance, nirvana, vep and MT. They should all be fixed by the pending PRs with the exception of a few additional fixups in MT (fromLegacy, same, etc.) I will rebase this as those PRs go in and fix up anything else that remains.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2725:81,error,errors,81,https://hail.is,https://github.com/hail-is/hail/pull/2725,1,['error'],['errors']
Availability,"This isn't really our fault. k8s sends us a 400 when a container is in a funky state. Creating this issue so I can find it again later when I run into this. Somehow a container terminates without timing information, and the read logs request returns a 400 instead of a 404. Batch handles this fine (it treats all log read failures the same). Known issue: https://github.com/kubernetes/kubernetes/issues/59296. ```; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:39,890"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (9, 1, 'main') with pod batch-9-job-1-c8b9b2""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:39,890"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1159"", ""message"": ""job (9, 1, 'main') mark complete""}; {""levelname"": ""WARNING"", ""asctime"": ""2019-07-11 14:19:39,899"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""mark_complete:579"", ""message"": ""job (9, 1, 'main') has pod batch-9-job-1-c8b9b2 which is terminated but has no timing information. {'api_version': 'v1',\n 'kind': 'Pod',\n 'metadata': {'annotations': None,\n 'cluster_name': None,\n 'creation_timestamp': datetime.datetime(2019, 7, 11, 14, 19, 34, tzinfo=tzlocal()),\n 'deletion_grace_period_seconds': 30,\n 'deletion_timestamp': datetime.datetime(2019, 7, 11, 14, 20, 4, tzinfo=tzlocal()),\n 'finalizers': None,\n 'generate_name': None,\n 'generation': None,\n 'initializers': None,\n 'labels': {'app': 'batch-job',\n 'batch_id': '9',\n 'hail.is/batch-instance': 'ffa5abc4607849df8e5f0036e7350bcf',\n 'job_id': '1',\n 'task': 'main',\n 'user': 'test',\n 'uuid': '291b9eed73b9433c86ff1f58624cf24d'},\n 'name': 'batch-9-job-1-c8b9b2',\n 'namespace': 'pr-6604-batch-pods-cjklalqnl5u9',\n 'owner_references': None,\n 'resource_version': '86681671',\n 'self_link': '/api/v1/namespaces/pr-6604-batch-pods-cjklalqnl5u9/pods/batch-9-job-1-c8b9b2',\n 'uid': 'e878f906-a3e6-11e9-a4bb-42010a8000af'},\n 'spec': {'active_deadline_seconds': None,\n 'affinity': ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6616:22,fault,fault,22,https://hail.is,https://github.com/hail-is/hail/issues/6616,2,"['failure', 'fault']","['failures', 'fault']"
Availability,"This looks OK to me. The first bit is the stack trace to the retry_transient_errors. The second bit is the stacktfrace for the timeout error. The last part of a Python stack trace is always the name of the exceptional class, e.g.:; ```. In [13]: raise ValueError() ; Traceback (most recent call last):; File ""<ipython-input-13-4954757c312d>"", line 1, in <module>; raise ValueError(); ValueError. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11817#issuecomment-1117649524:135,error,error,135,https://hail.is,https://github.com/hail-is/hail/pull/11817#issuecomment-1117649524,1,['error'],['error']
Availability,This looks a lot like preemption. Are these errors fatal?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6635#issuecomment-511343816:44,error,errors,44,https://hail.is,https://github.com/hail-is/hail/issues/6635#issuecomment-511343816,1,['error'],['errors']
Availability,"This looks fine. Could possibly put something in the Notes section of the docs to address changing block size if folks are running into errors with Hadoop, but if most people will be successful with the default, then I guess it's not necessary.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3697#issuecomment-393976813:136,error,errors,136,https://hail.is,https://github.com/hail-is/hail/pull/3697#issuecomment-393976813,1,['error'],['errors']
Availability,This looks good to me. There's a bunch of test failures mainly in TextTableSuite.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5139#issuecomment-454422936:47,failure,failures,47,https://hail.is,https://github.com/hail-is/hail/pull/5139#issuecomment-454422936,1,['failure'],['failures']
Availability,"This looks like good start. A few comments:; - I prefer using MySQL over auth0 mainly because it simplifies our eventual backup/restore story. If you think that's simpler overall, great. I don't see how integrating our db with their service does anything for us.; - I assume you're planning to pull the user data from MySQL during the login flow and add it to cookie? I think @danking @jigold and I are interested in nailing down the format for the cookie and seeing an example.; - I agree with @danking we should have an internal id field that's an integer. I think we should use that everywhere, and just use the auth0 id to look up the user record during login. So the integer id would be the primary key and the auth0 id would be unique with a secondary index.; - You need to get the GCP service account key and store it in a secret.; - The GCP service account needs permissions on the bucket. It should be bucket writer.; - Name ""user_secrets"" seems overly specific (buckets and service accounts are not secrets). ""user_data""?; - Please don't give the database a public IP.; - From a usability perspective, for user-visible names I have to say I really dislike long uuids and like the k8s-style short random string at the end. For k8s resource, you get this for free with the `generate_name` argument. For other stuff, long-term, this will potentially require retry logic to make it robust.; - I don't like this create table logic (FYI @danking @jigold). Most database users should not have permissions to create databases. There should be a k8s secret with the database root and a secret for each specific database application that only has access to that database.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5618#issuecomment-473583731:425,down,down,425,https://hail.is,https://github.com/hail-is/hail/pull/5618#issuecomment-473583731,4,"['down', 'robust']","['down', 'robust']"
Availability,This looks to me like we just have bad long tails. If we can 90% and 99% test times down further maybe we're basically good. Seems feasible for the entire service backend tests to take <20 minutes.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13076#issuecomment-1553848763:84,down,down,84,https://hail.is,https://github.com/hail-is/hail/pull/13076#issuecomment-1553848763,1,['down'],['down']
Availability,This makes hand running the release slightly less error-prone.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14325:50,error,error-prone,50,https://hail.is,https://github.com/hail-is/hail/pull/14325,1,['error'],['error-prone']
Availability,This might avoid command to long errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8470:33,error,errors,33,https://hail.is,https://github.com/hail-is/hail/pull/8470,1,['error'],['errors']
Availability,"This mirrors the functionality available on `TypedCodecSpec`. In some cases (the shuffler),; you might be handed a buffer that is already configured, but you still want to create a; decoder whose PType is known to be a subtype of PStruct.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8766:31,avail,available,31,https://hail.is,https://github.com/hail-is/hail/pull/8766,1,['avail'],['available']
Availability,"This moves `self.activate` into a `wait_for` with a timeout. We use a tight try-except; around the activation code to provide a precise error message if activation fails. If activation succeeds, we enter the else branch which operates as before. If activation; times out we do not deactivate. This is OK, we probably did not activate. If we did activate,; batch will eventually find out.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8816:136,error,error,136,https://hail.is,https://github.com/hail-is/hail/pull/8816,1,['error'],['error']
Availability,This must have been skipped or lost in a rebase but keeping the resources at minimum is keeping the notebook deployment at max replicas after the workshop. Giving a bit higher request (what I set as the baseline in #10117) should encourage k8s to downscale back to 3 replicas.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10230:247,down,downscale,247,https://hail.is,https://github.com/hail-is/hail/pull/10230,1,['down'],['downscale']
Availability,"This needs a rebase and has some docs failures, IIRC. I'll push fixes to this branch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6510#issuecomment-510519521:38,failure,failures,38,https://hail.is,https://github.com/hail-is/hail/pull/6510#issuecomment-510519521,1,['failure'],['failures']
Availability,This needs a rebase. Ping me when it's ready.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9594#issuecomment-724099162:21,Ping,Ping,21,https://hail.is,https://github.com/hail-is/hail/pull/9594#issuecomment-724099162,1,['Ping'],['Ping']
Availability,"This node filters an NDArray to a smaller NDArray that has only the specified rows/cols/etc. along a specific axis, in the specified order. It will be used for lowering BlockMatrixFilter. If the array of indices along a given axis is missing, then we preserve the original indexing along that axis. If an element in the array of indices is missing, we throw a runtime error. The filter/don't filter decision for a given axis could also be lifted to a compile-time decision, rather than a runtime decision (say by having the type of the filter along that axis being `ttuple[]` instead of `tarray<tint64>`). Unlike NDArraySlice, it does not give the option of reducing the number of dimensions of the NDArray, although I can change that if we have a use for it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8122:368,error,error,368,https://hail.is,https://github.com/hail-is/hail/pull/8122,1,['error'],['error']
Availability,"This now gives a nice error message:. ```; >>> hl.uniroot(lambda x: x * x + 1, -1, 1).value; Error summary: HailException: sign of endpoints must have opposite signs, got: f(min) = 2.0, f(max) = 2.0; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1896#issuecomment-408636691:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/issues/1896#issuecomment-408636691,2,"['Error', 'error']","['Error', 'error']"
Availability,This now passes. ping @chrisvittal,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6263#issuecomment-501361010:17,ping,ping,17,https://hail.is,https://github.com/hail-is/hail/pull/6263#issuecomment-501361010,1,['ping'],['ping']
Availability,"This one isn't a segfault, it's a test failure where somehow for each ndarray in the table, row i + 1 is getting the data array from row i. Cloud workshop and ndarray aggregator pushed this down my priority list, but I will continue to try and fix it and then get back to you.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8952#issuecomment-667098599:39,failure,failure,39,https://hail.is,https://github.com/hail-is/hail/pull/8952#issuecomment-667098599,2,"['down', 'failure']","['down', 'failure']"
Availability,This only yielded a ~20% reduction. Test times are around 16 minutes now down from around 20 minutes.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11212#issuecomment-1039677943:73,down,down,73,https://hail.is,https://github.com/hail-is/hail/pull/11212#issuecomment-1039677943,1,['down'],['down']
Availability,"This opens the possibility for compiler differences to fail builds for our users. The CI server should simply set CXX and CC to clang and rebuild hail. Moreover, we need to ensure the hail build system passes these variables all the way down to `libsimdpp`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1327:237,down,down,237,https://hail.is,https://github.com/hail-is/hail/issues/1327,1,['down'],['down']
Availability,"This particular example works for me today in 0.2.27. When I upped M to 350, I instead got a Java stack overflow error like:. ```; java.lang.StackOverflowError: null; 	at is.hail.expr.ir.Pretty$.is$hail$expr$ir$Pretty$$pretty$1(Pretty.scala:98); 	at is.hail.expr.ir.Pretty$$anonfun$is$hail$expr$ir$Pretty$$pretty$1$6.apply(Pretty.scala:405); 	at is.hail.expr.ir.Pretty$$anonfun$is$hail$expr$ir$Pretty$$pretty$1$6.apply(Pretty.scala:405); 	at is.hail.utils.richUtils.RichIterator$.foreachBetween$extension(RichIterator.scala:32); 	at is.hail.utils.richUtils.RichIterable.foreachBetween(RichIterable.scala:12); 	at is.hail.expr.ir.Pretty$.is$hail$expr$ir$Pretty$$pretty$1(Pretty.scala:405); 	at is.hail.expr.ir.Pretty$.is$hail$expr$ir$Pretty$$pretty$1(Pretty.scala:204); 	at is.hail.expr.ir.Pretty$$anonfun$is$hail$expr$ir$Pretty$$pretty$1$6.apply(Pretty.scala:405); 	at is.hail.expr.ir.Pretty$$anonfun$is$hail$expr$ir$Pretty$$pretty$1$6.apply(Pretty.scala:405); 	at is.hail.utils.richUtils.RichIterator$.foreachBetween$extension(RichIterator.scala:35); 	at is.hail.utils.richUtils.RichIterable.foreachBetween(RichIterable.scala:12); 	at is.hail.expr.ir.Pretty$.is$hail$expr$ir$Pretty$$pretty$1(Pretty.scala:405); 	at is.hail.expr.ir.Pretty$$anonfun$is$hail$expr$ir$Pretty$$pretty$1$6.apply(Pretty.scala:405); 	at is.hail.expr.ir.Pretty$$anonfun$is$hail$expr$ir$Pretty$$pretty$1$6.apply(Pretty.scala:405); 	at is.hail.utils.richUtils.RichIterator$.foreachBetween$extension(RichIterator.scala:32); 	at is.hail.utils.richUtils.RichIterable.foreachBetween(RichIterable.scala:12); 	at is.hail.expr.ir.Pretty$.is$hail$expr$ir$Pretty$$pretty$1(Pretty.scala:405); 	at is.hail.expr.ir.Pretty$$anonfun$is$hail$expr$ir$Pretty$$pretty$1$6.apply(Pretty.scala:405); 	at is.hail.expr.ir.Pretty$$anonfun$is$hail$expr$ir$Pretty$$pretty$1$6.apply(Pretty.scala:405); 	at is.hail.utils.richUtils.RichIterator$.foreachBetween$extension(RichIterator.scala:32); 	at is.hail.utils.richUtils.RichIterable.foreachBetween(RichIte",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5262#issuecomment-555090024:113,error,error,113,https://hail.is,https://github.com/hail-is/hail/issues/5262#issuecomment-555090024,1,['error'],['error']
Availability,"This pod is constantly blocking scale down. There are two of them running anyway, there is no reason not to take one down to allow scale down:; ```; (base) dking@wm28c-761 hail % k get pods -n kube-system -l k8s-app=kube-dns; NAME READY STATUS RESTARTS AGE; kube-dns-7d44cdb5d5-twvfd 4/4 Running 0 14d; kube-dns-7d44cdb5d5-xjq25 4/4 Running 0 14d; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13105:38,down,down,38,https://hail.is,https://github.com/hail-is/hail/pull/13105,3,['down'],['down']
Availability,This prevents an error in _run_command where we attempt to put an int into an array of `java.lang.String`s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1331:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/1331,1,['error'],['error']
Availability,"This probably needs more work to return a 'nice' error for user errors and internal errors (for bug reporting), though with the service, we should have visibility into compiler errors from just the batch id.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11623#issuecomment-1073261565:49,error,error,49,https://hail.is,https://github.com/hail-is/hail/pull/11623#issuecomment-1073261565,4,['error'],"['error', 'errors']"
Availability,"This query is the slowest one we have right now and is making the billing projects pages to be slow. I saw substantial speed improvements using lateral joins. - For querying all open billing projects for a given user, it went from 1.8 seconds to 0.87 seconds.; - For querying all open billing projects (i.e. billing projects page), it went from 5.5 seconds to 2.6 seconds. The speed of the queries should go down further once the aggregated billing project user resources table has been deduped and further improvements after compaction.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13175:408,down,down,408,https://hail.is,https://github.com/hail-is/hail/pull/13175,1,['down'],['down']
Availability,"This reduces the size of the `repo` that's input to a lot of CI steps from ~186Mb to ~68Mb, which is substantial when you look at the build for this PR and see single-digit or low double-digit Mb download speeds ðŸ™ƒ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12312:196,down,download,196,https://hail.is,https://github.com/hail-is/hail/pull/12312,1,['down'],['download']
Availability,"This removes partition key stuff, as needed, down to the IR node level. I haven't touched the signatures of any IR nodes; where needed, I have put the fill row key as the partition key. @patrick-schultz I think this should work without any additional changes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4197:45,down,down,45,https://hail.is,https://github.com/hail-is/hail/pull/4197,1,['down'],['down']
Availability,"This retries all the basic RPC methods of GoogleStorageFS. I saw a transient; error arise from an `open` in generated code. These changes would have; retried the `open` and not failed the job (1 of 50,000 jobs :( ). However,; I am still not sure how to retry an error during actual writing (as opposed; to opening the OutputStream). I think we have to retry the whole partition.; See further discussion in Zulip.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11709:78,error,error,78,https://hail.is,https://github.com/hail-is/hail/pull/11709,2,['error'],['error']
Availability,"This seems fine now (the alternative is to continue using unittest which seems not loved for some reason?). I'll echo patrick that I would prefer we live on a test framework that's maintained. [nose2](http://nose2.readthedocs.io/en/latest/) seems to be a maintained project, but that reddit thread is hot for `pytest`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3096#issuecomment-371837536:113,echo,echo,113,https://hail.is,https://github.com/hail-is/hail/pull/3096#issuecomment-371837536,1,['echo'],['echo']
Availability,This seems like an odd bug?; https://ci.hail.is/repository/download/HailSourceCode_HailMainline_HailCiSpark1/2980:id/build/reports/tests/classes/org.broadinstitute.hail.io.ExportVcfSuite.html#testReadWrite,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1194#issuecomment-268636904:59,down,download,59,https://hail.is,https://github.com/hail-is/hail/pull/1194#issuecomment-268636904,1,['down'],['download']
Availability,"This seems to do it:; ```. In [1]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(32):; ...: j = b.new_job(); ...: j.command(f'cat >/dev/null {"" "".join(b.read_input(""gs://danking/foo.vcf"") for _ in range(1000))}'); ...: b.run(); /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:29: UserWarning: You have specified the GCS requester pays configuration in both your spark-defaults.conf (/Users/dking/miniconda3/lib/python3.10/site-packages/pyspark/conf/spark-defaults.conf) and either an explicit argument or through `hailctl config`. For GCS requester pays configuration, Hail first checks explicit arguments, then `hailctl config`, then spark-defaults.conf.; warnings.warn(; /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/batch/backend.py:786: UserWarning: Using an image ubuntu:22.04 from Docker Hub. Jobs may fail due to Docker Hub rate limits.; warnings.warn(f'Using an image {image} from Docker Hub. '. https://batch.hail.is/batches/8090821 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 33/33 0:00:00 0:01:37; batch 8090821 complete: success; Out[1]: <hailtop.batch_client.client.Batch at 0x1086d1bd0>. In [2]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(300):; ...: j = b.new_job(); ...: j.command(f'echo {""a"" * 11 * 1024}'); ...: b.run(); ```. Perhaps related to creating a fresh service backend?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14051#issuecomment-1834376467:1366,echo,echo,1366,https://hail.is,https://github.com/hail-is/hail/issues/14051#issuecomment-1834376467,1,['echo'],['echo']
Availability,This seems to have failed due to exactly the error it is supposed to fix. The gear in use by CI is not the gear fixed here. I'll bump.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8237#issuecomment-605073218:45,error,error,45,https://hail.is,https://github.com/hail-is/hail/pull/8237#issuecomment-605073218,1,['error'],['error']
Availability,"This should always produce a valid VCF with respect to: https://samtools.github.io/hts-specs/VCFv4.2.pdf. I've changed the behavior of export_vcf so that, like FORMAT field types, unsupported INFO field types must be explicitly converted to String by the user if the user really wants to export them. With good error messages, I think this will cause less confusion.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2414#issuecomment-343611350:311,error,error,311,https://hail.is,https://github.com/hail-is/hail/pull/2414#issuecomment-343611350,1,['error'],['error']
Availability,This should be a type error. I don't think you should be able to use comparison operators on non-primitive types,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6458#issuecomment-505215908:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/issues/6458#issuecomment-505215908,1,['error'],['error']
Availability,This should be all set. I tested backwards compatibility and caught some errors that showed up in the worker logs with regards to iptables lock errors with simultaneous shell calls.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12542#issuecomment-1370274153:73,error,errors,73,https://hail.is,https://github.com/hail-is/hail/pull/12542#issuecomment-1370274153,2,['error'],['errors']
Availability,"This should be configurable, but that was harder than I expected. This should cut down on the number of class A operations we do a bit. It is quite high right now.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11984:82,down,down,82,https://hail.is,https://github.com/hail-is/hail/pull/11984,1,['down'],['down']
Availability,This should be fixed by #8103 etc. Reopen this issue if you see the error again.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8053#issuecomment-588390042:68,error,error,68,https://hail.is,https://github.com/hail-is/hail/issues/8053#issuecomment-588390042,1,['error'],['error']
Availability,"This should be functioning (or very close) in GCP but is basically unimplemented in Azure. Azure needs a secret store like how we use Google Secret Manager that workers can access when they start up to load certificates. Azure Key Vault seems reasonable and can be created through terraform. The structure should mirror that in GCP, where we need a client that can upload the certs to Azure in `create_certs` and download them in the azure CloudWorkerAPI. I would leave this unimplemented in TerraAzure until an overall secrets story is established.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14581#issuecomment-2243030552:413,down,download,413,https://hail.is,https://github.com/hail-is/hail/pull/14581#issuecomment-2243030552,1,['down'],['download']
Availability,"This should be good minus tests and double/triple checking the billing is all correct with units etc.. Ideally, there'd be two situations to test:. 1. A storage size that exceeds the unreserved space (i.e. 375Gi); 2. Multiple smaller jobs requesting unreserved space and we need to spin up a disk for one of them. I don't think there's a reliable way to test 2 other than doing it by hand in my dev namespace. Test 1 should be sufficient for checking the new disk and /io works.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9598#issuecomment-714604941:338,reliab,reliable,338,https://hail.is,https://github.com/hail-is/hail/pull/9598#issuecomment-714604941,1,['reliab'],['reliable']
Availability,This should be ready for review. Only error was black formatting which hopefully I fixed now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11211#issuecomment-1010359404:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/pull/11211#issuecomment-1010359404,1,['error'],['error']
Availability,"This should cut down on expensive py4j calls in import_vcfs, and the; infrastructure should also help us with complex java <=> python; interchanges, by passing the releavant information via primitive types; or strings in all cases. Brief summary:. - Add vectorIrs map to HailContext to store lists of irs that may need; be referenced later. - Switch import_vcfs to returning a json string with the id of the IR; array that is now stored in the vectorIrs map, along with the size of; that array and its type, suitable to passed to tmatrix._from_json. - Add JIRVectorReference to python, which is the deserialized version of; the returned json. - Add JavaMatrixVectorRef, which represents a single IR contained in; some stored IR array.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5613:16,down,down,16,https://hail.is,https://github.com/hail-is/hail/pull/5613,1,['down'],['down']
Availability,This should fix Julia's bug here: https://discuss.hail.is/t/arrayindexoutofboundsexception-error-in-hail-0-2-40/1413/11. I will make a follow up PR tomorrow splitting things up and making a `PCanonicalTupleCode`. I just wanted to get rid of this blatantly wrong thing.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8799:91,error,error-in-hail-,91,https://hail.is,https://github.com/hail-is/hail/pull/8799,1,['error'],['error-in-hail-']
Availability,"This should fix the test_copy failures. The problem was, we were sending a mutable byte iterator for data when inserting a new object. If that insert read some of the data, failed, and was retried, the data that was read was lost and the retry started where the failed insert left off. To retry writes, you need to keep around the data you've sent to resend in case of failure. So you don't have to keep around an unbounded amount of data, Google Storage supports resumable uploads: https://cloud.google.com/storage/docs/resumable-uploads. This allows us to send data in chunks, and release the data after Google reports back that the data has been committed. `StorageClient.insert_object`, when the upload type is resumable (the default), takes an additional argument `bufsize`. This is the amount the amount that the writer will buffer for retries, and the size of the chunks sent to GCS. I kept around the simpler media upload type since I actually want to use it in copy (copy doesn't need to buffer because it can retry by rereading the file being copied from). This code was actually kind of hard to organize. It would be better if the code immediately wrote any incoming data instead of just buffering it until we hit the chunk size, but I didn't find a manageable way to write that. Suggestions welcome, tho it would be good to get this fix in because of the test failures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10023:30,failure,failures,30,https://hail.is,https://github.com/hail-is/hail/pull/10023,3,['failure'],"['failure', 'failures']"
Availability,"This should give a helpful python-level error message bout balding Nichols having an integer column key, but instead I get a Scala match error.; ```; In [9]: hl.export_vcf(hl.balding_nichols_model(3,10,10, n_partitions=3), '/tmp/foo.vcf') ; ```; randomly assigned",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7584:40,error,error,40,https://hail.is,https://github.com/hail-is/hail/issues/7584,2,['error'],['error']
Availability,This should help us avoid more confusing errors down the line since our workers are all running JDK 8 and cannot use JDK 11+ bytecode.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13734:41,error,errors,41,https://hail.is,https://github.com/hail-is/hail/pull/13734,2,"['down', 'error']","['down', 'errors']"
Availability,This should hopefully save on computing things like downcasts for hom-refs.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6896:52,down,downcasts,52,https://hail.is,https://github.com/hail-is/hail/pull/6896,1,['down'],['downcasts']
Availability,"This should make computing the loadings better, since it uses a checkpointed variants table instead of accidentally recomputing the incoming MatrixTable. Also made a change to avoid accidentally clobbering a field name if someone had a field named `idx`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10201:64,checkpoint,checkpointed,64,https://hail.is,https://github.com/hail-is/hail/pull/10201,1,['checkpoint'],['checkpointed']
Availability,This should suppress many spurious CI failures.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8218:38,failure,failures,38,https://hail.is,https://github.com/hail-is/hail/pull/8218,1,['failure'],['failures']
Availability,"This should take the time it takes to run IRSuite back down to ~7 minutes. Still not great, but better than 12.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5582:55,down,down,55,https://hail.is,https://github.com/hail-is/hail/pull/5582,1,['down'],['down']
Availability,"This still causes error messages. `hail -l /mnt/lustre/schoi/projects/TOPMed/BROAD/Chr22/TopMed.Chr${num}.QC.vds.test.log importvcf file:///mnt/lustre/schoi/projects/TOPMed/BROAD/Chr${num}/TopMed_8k.853.vcf.bgz splitmulti annotatevariants expr -c 'va.info.AC = va.info.AC[va.aIndex]' count`. `2016-08-24 16:42:27,052:8532(0x7fef97fff700):ZOO_INFO@log_env@712: Client environment:zookeeper.version=zookeeper C client 3.4.5; 2016-08-24 16:42:27,052:8532(0x7fef97fff700):ZOO_INFO@log_env@716: Client environment:host.name=nid00014; 2016-08-24 16:42:27,052:8532(0x7fef97fff700):ZOO_INFO@log_env@723: Client environment:os.name=Linux; 2016-08-24 16:42:27,052:8532(0x7fef97fff700):ZOO_INFO@log_env@724: Client environment:os.arch=2.6.32-431.el6_1.0000.9051-cray_ari_athena_c_cos; 2016-08-24 16:42:27,052:8532(0x7fef97fff700):ZOO_INFO@log_env@725: Client environment:os.version=#1 SMP Thu Jan 28 18:37:39 UTC 2016; 2016-08-24 16:42:27,052:8532(0x7fef97fff700):ZOO_INFO@log_env@733: Client environment:user.name=schoi; 2016-08-24 16:42:27,052:8532(0x7fef97fff700):ZOO_INFO@log_env@741: Client environment:user.home=/home/users/schoi; 2016-08-24 16:42:27,052:8532(0x7fef97fff700):ZOO_INFO@log_env@753: Client environment:user.dir=/mnt/lustre/schoi/projects/TOPMed/BROAD/Chr22; 2016-08-24 16:42:27,052:8532(0x7fef97fff700):ZOO_INFO@zookeeper_init@786: Initiating client connection, host=192.168.0.1:2181,192.168.0.9:2181,192.168.0.17:2181 sessionTimeout=10000 watcher=0x3b9c8c00a0 sessionId=0 sessionPasswd=<null> context=0x7fed6c000960 flags=0; I0824 16:42:27.052752 8752 sched.cpp:164] Version: 0.25.0; 2016-08-24 16:42:27,053:8532(0x7fef76bfd700):ZOO_INFO@check_events@1703: initiated connection to server [192.168.0.9:2181]; 2016-08-24 16:42:27,070:8532(0x7fef76bfd700):ZOO_INFO@check_events@1750: session establishment complete on server [192.168.0.9:2181], sessionId=0x255cb9ea22102ec, negotiated timeout=10000; I0824 16:42:27.070502 8726 group.cpp:331] Group process (group(1)@192.168.0.15:12239) connect",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/660#issuecomment-242218633:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/issues/660#issuecomment-242218633,1,['error'],['error']
Availability,"This test could run forever if batch is temporarily down between starting the job and the job completing. I'm not entirely sure what to do in this scenario, failing doesn't seem too bad because we weren't actually able to verify the test, but it seems better than potentially having the job hang.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12420:52,down,down,52,https://hail.is,https://github.com/hail-is/hail/pull/12420,1,['down'],['down']
Availability,"This test failed in CI, but worked fine for me locally the 3 times I tested it (takes forever to run). Not sure what's going on. ```; =================================== FAILURES ===================================; _______________________ test_input_dependency_directory ________________________. client = <batch.client.BatchClient object at 0x7fee8fbecbe0>; test_user = {'bucket_name': 'hail-user-bucket-batch-tests', 'gsa_email': 'batch-tests@hail-vdc.iam.gserviceaccount.com', 'gsa_key_secret_name': 'gcp-sa-key-batch-tests', 'ksa_name': 'batch-tests'}. def test_input_dependency_directory(client, test_user):; batch = client.create_batch(); head = batch.create_job('alpine:3.8',; command=['/bin/sh', '-c', 'mkdir -p /io/test/; echo head1 > /io/test/data1 ; echo head2 > /io/test/data2'],; output_files=[('/io/test/', f'gs://{test_user[""bucket_name""]}')]); tail = batch.create_job('alpine:3.8',; command=['/bin/sh', '-c', 'cat /io/test/data1 ; cat /io/test/data2'],; input_files=[(f'gs://{test_user[""bucket_name""]}/test', '/io/')],; parent_ids=[head.id]); tail.wait(); > assert tail.log()['main'] == 'head1\nhead2\n'; E KeyError: 'main'; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5934#issuecomment-485600864:170,FAILURE,FAILURES,170,https://hail.is,https://github.com/hail-is/hail/pull/5934#issuecomment-485600864,3,"['FAILURE', 'echo']","['FAILURES', 'echo']"
Availability,"This test failure has occurred a few times. It's usually been resolved by simply re-running the test without any source code changes. There are at least four recent examples, all on different feature branches: . - [2017-02-21 11:10 UTC](https://ci.hail.is/viewLog.html?buildId=6489&tab=buildResultsDiv&buildTypeId=HailSourceCode_HailCi#); - [2017-02-15 21:51 UTC](https://ci.hail.is/viewLog.html?buildId=5446#2135525582_186_5446_problem); - [2017-02-15 18:45 UTC](https://ci.hail.is/viewLog.html?buildId=5333#1163765489_186_5333_problem); - [2017-02-13 22:42 UTC](https://ci.hail.is/viewLog.html?buildId=4934&tab=buildResultsDiv&buildTypeId=HailSourceCode_HailCi). ```; [11:19:14][:testHail] ======================================================================; [11:19:14][:testHail] ERROR: test_dataset (hail.tests.ContextTests); [11:19:14][:testHail] ----------------------------------------------------------------------; [11:19:14][:testHail] Traceback (most recent call last):; [11:19:14][:testHail] File ""/home/ec2-user/BuildAgent/work/c38e75e72b769a7c/python/hail/tests.py"", line 233, in test_dataset; [11:19:14][:testHail] vds_assoc = vds_assoc.lmmreg(vds_kinship, 'sa.pheno', ['sa.cov1', 'sa.cov2']); [11:19:14][:testHail] File ""<decorator-gen-89>"", line 2, in lmmreg; [11:19:14][:testHail] File ""/home/ec2-user/BuildAgent/work/c38e75e72b769a7c/python/hail/java.py"", line 93, in handle_py4j; [11:19:14][:testHail] raise FatalError(msg); [11:19:14][:testHail] FatalError: lmmreg: failed to fit delta: REML realized at delta upper search boundary e^10 = 22026.465794806718, indicating negligible genetic component of variance. Standard linear regression may be more appropriate.; ```. These are the [offending lines](https://github.com/hail-is/hail/blob/master/python/hail/tests.py#L222-L233):. ```; vds_assoc = (hc.import_vcf(test_resources + '/sample.vcf'); .split_multi(); .variant_qc(); .annotate_samples_expr(; 'sa.culprit = gs.filter(g => v == Variant(""20"", 13753124, ""A"", ""C"")).map(g =",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1416:10,failure,failure,10,https://hail.is,https://github.com/hail-is/hail/issues/1416,2,"['ERROR', 'failure']","['ERROR', 'failure']"
Availability,"This test:. ```python3; p = Pipeline(backend=BatchBackend('https://batch.hail.is')); for _ in range(30000):; p.new_task().command('/bin/true'); p.run(); ```. Revealed a number of issues:; daniel king: Problems Found:; - [x] https://github.com/hail-is/hail/issues/6543 mysql can deadlock itself, requiring you to reissue the db request; - [x] https://github.com/hail-is/hail/issues/6545 of the 20760 pods that were successfully created before #6543 happened, about 800 could not get their logs due to not existing. That's a failure rate of ~4%. The number of failures continues to grow as I type this message (now up to 1280). I'm counting failures this way:; ```; k logs -l app=batch --tail=999999 | grep 'no logs for ' | sed -E 's/^.*no logs for ([^ ]+).*$/\1/' | sort -u | wc -l; ```; - the k8s request latency spiked to 3.47s max 0.6 s mean during this test and stayed elevated for 10 minutes.; - [ ] https://github.com/hail-is/hail/issues/6546 there was a lot of volume mount failures due to, apparently, the secrets, e.g.:; ```; 9m13s Warning FailedMount Pod Unable to mount volumes for pod ""batch-278-job-10258-a49a81_batch-pods(82ea5910-9ccb-11e9-ad88-42010a800049)"": timeout expired waiting for volumes to attach or mount for pod ""batch-pods""/""batch-278-job-10258-a49a81"". list of unmounted volumes=[gsa-key default-token-8h99c]. list of unattached volumes=[gsa-key default-token-8h99c]; ```; - [ ] https://github.com/hail-is/hail/issues/6548 batch takes 4 seconds to render the batch page with 20k jobs (the web browser displays it fine though), e.g. https://batch.hail.is/batches/278; - [ ] https://github.com/hail-is/hail/issues/6548 batch UI search is DOA with 20k jobs; - [ ] https://github.com/hail-is/hail/issues/6556 delete (and likely cancel) will timeout on large batches",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6547:523,failure,failure,523,https://hail.is,https://github.com/hail-is/hail/issues/6547,4,['failure'],"['failure', 'failures']"
Availability,"This took me an incredibly long time to figure out, but I'm pretty sure the issue is that my last test copies the same file twice. Once explicitly as a single file and the second time as part of the directory to copy recursively. I don't think our copier code interacts correctly with Azure Blob Storage in this case and we end up with invalid block ID list errors. I'm still stewing over which option is the best to address this. I could either not have `submit.py` ask to copy the same file twice or I can modify the copier to have a lock on the create blob writer stream so that we don't have this issue. However, I'm worried about deadlocks with our extensive use of semaphores and parallelism. Thoughts?? I think the right thing to do is fix it for now in `submit.py` so we can get this in and then make an issue to make a more durable fix to the copier.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13812#issuecomment-1881894683:358,error,errors,358,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1881894683,1,['error'],['errors']
Availability,This was added in https://github.com/hail-is/hail/pull/12421 to help debug errors in `testSeekMoreThanMaxInt`. We have not seen that transient error in a while and I think the switch to https://github.com/hail-is/hail/pull/12590 might have fixed some underlying misuse of `AppendBlobClient` (by not using it).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13472:75,error,errors,75,https://hail.is,https://github.com/hail-is/hail/pull/13472,2,['error'],"['error', 'errors']"
Availability,"This was causing out-of-order keys to exist and be used in #6223. This doesn't fix that issue specifically, but it will now throw the correct error (and prevent incorrect tables/matrix tables from being written out).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6267:142,error,error,142,https://hail.is,https://github.com/hail-is/hail/pull/6267,1,['error'],['error']
Availability,This was implicitly converted to a pair. SBT complained that; this was probably not what I intended. Not sure why gradle; does not report the same warning as an error.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8356:161,error,error,161,https://hail.is,https://github.com/hail-is/hail/pull/8356,1,['error'],['error']
Availability,This was running locally rather than the spark cluster which I expect relates to the memory error.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755#issuecomment-439415237:92,error,error,92,https://hail.is,https://github.com/hail-is/hail/issues/4755#issuecomment-439415237,1,['error'],['error']
Availability,This was the most confusing error I've seen in a while! ðŸ˜…,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2850:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/2850,1,['error'],['error']
Availability,This wasn't updated when I separated out building and pushing so the `build` target wasn't pushing the image. When I fixed that the cert generation failed because `memory` is no longer available. These changes got everything working again.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14064:185,avail,available,185,https://hail.is,https://github.com/hail-is/hail/pull/14064,1,['avail'],['available']
Availability,"This way the second error will be ""caused by"" the original retry once error. I think; this is worthwhile because otherwise we will never know what the first error was.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11948:20,error,error,20,https://hail.is,https://github.com/hail-is/hail/pull/11948,3,['error'],['error']
Availability,"This will also retry things that are our fault, but that might just be worth it if it avoids most transient errors",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11666#issuecomment-1077884202:41,fault,fault,41,https://hail.is,https://github.com/hail-is/hail/pull/11666#issuecomment-1077884202,2,"['error', 'fault']","['errors', 'fault']"
Availability,"This will enforce even stricter requirements on downstream projects, right? Do we want to do this only for our own builds and use unpinned dependencies in the pip package's setup.py?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11842#issuecomment-1128128100:48,down,downstream,48,https://hail.is,https://github.com/hail-is/hail/pull/11842#issuecomment-1128128100,1,['down'],['downstream']
Availability,"This will fail until #7376 lands and allows the test to create an empty matrix table. - document `sep`; - add two tests for importing empty matrix tables, one with a header and one without; - include the offending lines in error messages when files have different numbers of columns; - consistently use `String.split(separator, 0)` instead of using two different approaches which yield inconsistent results.; - simplify `parseHeader` and generalize to empty files; - improve error message when a row field found in the file does not match one of the row fields specified by `row_fields` (a dictionary from row field name to type). NB: A no-header empty file implies no columns in the MT. We print a warning to this effect when we discover an empty file. Resolves #7242",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7378:223,error,error,223,https://hail.is,https://github.com/hail-is/hail/pull/7378,2,['error'],['error']
Availability,"This will fix the upload location for 0.2 artifacts, and therefore the broken distribution download link.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4583:91,down,download,91,https://hail.is,https://github.com/hail-is/hail/pull/4583,1,['down'],['download']
Availability,This will get site updating with a short downtime while get a proper fix in place for https://github.com/hail-is/hail/issues/4463.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4476:41,downtime,downtime,41,https://hail.is,https://github.com/hail-is/hail/pull/4476,1,['downtime'],['downtime']
Availability,"This would also be slowing down some of the tests on laptops. Not sure about the CI, I don't see `hail.log` published as a CI artifact.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3335#issuecomment-385266926:27,down,down,27,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385266926,1,['down'],['down']
Availability,This would prevent people from using it naively on sample aggregations and getting errors. Can also add a mode that takes an integer nAlleles,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1610:83,error,errors,83,https://hail.is,https://github.com/hail-is/hail/issues/1610,1,['error'],['errors']
Availability,Those env variables most have been copy-pasted from another step because they're neither correct nor necessary. I tried downloading the batch-gsa-key and running `upload-query-jar` with it as the credentials and it succeeded.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11881:120,down,downloading,120,https://hail.is,https://github.com/hail-is/hail/pull/11881,1,['down'],['downloading']
Availability,"Three changes:. 1. I noticed the costs were all 0. I think this is due to `cores_mcpu INTO cores_mcpu` scoping issues in the attempt triggers, where the local variable was always zero. At least changing the local variable name immediately fixed the problem. 2. I wrote a test to verify the costs were non-zero and consistent with the reported timing for the succeeding job. It is hard to do on the cost string, so I included msec_mcpu in the batch/job status response to verify it. In trying to verify it, I noticed that timestamps in the attempts table were slightly truncated compared to start/end times in the status (JSON). This lead to rounding errors and slight disagreement. 3. Rather descend into the floating point rabbit hole of madness, I changed times everywhere to be stored as integers in milliseconds (like unix time, since the epoch). In the database, they are not BIGINT. Millisecond resolution seems fine for everything we're building. 4. (Bonus change!) Don't let timing for jobs be negative. This will require another reset.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7628:650,error,errors,650,https://hail.is,https://github.com/hail-is/hail/pull/7628,1,['error'],['errors']
Availability,"Three things:; 1. Jenkins build #116:. http://hail-ci.broadinstitute.org:8080/job/Hail%20-%20Test%20All%20Branches/116/. of master, revision 6d5fe392b32c7383370b2fc2ea259fb8cff2c1c6, failed several test cases, but I wasn't able to reproduce it on my laptop. Can we get more detailed logs, either by default or in another file, so we can debug build irreproducible build failures? Custom log4j properties for gradle might be a solution.; 1. I tried to rebuild #116 by clicking ""Rebuild"" on the left hand side menu. This resulted in build #119 . http://hail-ci.broadinstitute.org:8080/job/Hail%20-%20Test%20All%20Branches/119/. which is labeled ""rebuild of #116"", but it is a build of a different branch, origin/tp_dbnsfp_bug and a different revision. What's going on?; 1. When I noticed #116 failed, I wanted to find the last build of origin/master that succeeded. Is there a way to do that?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/335:370,failure,failures,370,https://hail.is,https://github.com/hail-is/hail/issues/335,1,['failure'],['failures']
Availability,Throw a good error message if ASYNC_PROFILER_HOME isn't set,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9657:13,error,error,13,https://hail.is,https://github.com/hail-is/hail/pull/9657,1,['error'],['error']
Availability,Throw a useful error message when the resource does not exist instead of throwing an NPE.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4678:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/4678,1,['error'],['error']
Availability,Throw error if user tries to explode a key field,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3854:6,error,error,6,https://hail.is,https://github.com/hail-is/hail/pull/3854,1,['error'],['error']
Availability,"Tim, . This actually isn't bad. I took a stab at the aggregators, and in the case of those that need InitOps and SeqOps, used the existing AggSignature `toPhysical` instance method, which seems to do about the right thing, with minor modification. Also caught some Inference failures! Still have one more to fix, then check over any missing nodes (RunAgg is missing, have a placeholder comment for that, which I'll fill in now.). Only 1 test failing in IRSuite! That is ArrayFold2, which is just a bug we didn't catch before, and has nothing to do with new nodes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7959#issuecomment-579992599:275,failure,failures,275,https://hail.is,https://github.com/hail-is/hail/pull/7959#issuecomment-579992599,1,['failure'],['failures']
Availability,"Tim, can you shoot me down, too?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5528#issuecomment-469476636:22,down,down,22,https://hail.is,https://github.com/hail-is/hail/pull/5528#issuecomment-469476636,1,['down'],['down']
Availability,"Tim, when I run the following command I get the exception below. ~/hail/build/install/hail/bin/hail import -i ~/t2d/GoT2D.first10k.vcf filtervariants --keep -c ""true"" count. I get the following exception. ""[-80"" is not in the original vcf, so Cotton thinks it may be because htsjdk parses the info, then you converts them back to Strings, and then reparses them, so you might have trouble eating your own output. I'll share the vcf with you. I have no trouble filtering based on sample and interval lists, or doing qc or linreg. ```; Exception in thread ""main"" org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost): java.lang.NumberFormatException: For input string: ""[-80""; at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65); at java.lang.Integer.parseInt(Integer.java:580); at java.lang.Integer.parseInt(Integer.java:615); at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272); at scala.collection.immutable.StringOps.toInt(StringOps.scala:30); at org.broadinstitute.hail.methods.AnnotationValueString$$anonfun$toArrayInt$extension$1.apply(Filter.scala:18); at org.broadinstitute.hail.methods.AnnotationValueString$$anonfun$toArrayInt$extension$1.apply(Filter.scala:18); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); at scala.collection.TraversableLike$class.map(TraversableLike.scala:245); at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); at org.broadinstitute.hail.methods.AnnotationValueString$.toArrayInt$extension(Filter.scala:18); at __wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c.__wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c$$a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/120:619,failure,failure,619,https://hail.is,https://github.com/hail-is/hail/issues/120,2,['failure'],['failure']
Availability,"To allow users on GCP to access datasets that are only available on AWS (e.g. pan-ukb LD block matrices and tables). . If trying to read dataset from `s3` path throws `FatalError: UnsupportedFileSystemException: No FileSystem for scheme ""s3""`, then will read with the `s3a` prefix instead.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10527:55,avail,available,55,https://hail.is,https://github.com/hail-is/hail/pull/10527,1,['avail'],['available']
Availability,To avoid `pymysql` packet sequence errors on long-running pods. See https://hail.zulipchat.com/#narrow/stream/300487-Hail-Batch-Dev/topic/PyMysql.20packet.20sequence.20errors/near/289668489 for context. #assign services,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12051:35,error,errors,35,https://hail.is,https://github.com/hail-is/hail/pull/12051,1,['error'],['errors']
Availability,"To avoid classname serialization overhead, we should register all of our classes that are being serialized, with the most important being those which are RDD elements, until we are able to turn on `conf.set(""spark.kryo.registrationRequired"", ""true"")` without error. This will also catch places where we are serializing far more than we thought. Background here:; https://spark.apache.org/docs/latest/tuning.html#data-serialization. Only a small number of classes are registered by default:; https://github.com/apache/spark/blob/v1.4.0/core/src/main/scala/org/apache/spark/serializer/KryoSerializer.scala#L317. More background in first answer here:; http://stackoverflow.com/questions/31394140/require-kryo-serialization-in-spark-scala",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1022:259,error,error,259,https://hail.is,https://github.com/hail-is/hail/issues/1022,1,['error'],['error']
Availability,"To be merged AFTER jb_mendel_y and jb_mendel_docs. This modifies the behavior of Pedigree to discard those samples not in the variant data set when reading in a .fam file, rather than throwing an error when indexing fails, addressing Issue #94. I'd like advice on how best to throw a warning when samples are tossed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/153:196,error,error,196,https://hail.is,https://github.com/hail-is/hail/pull/153,1,['error'],['error']
Availability,"To be merges AFTER jb_mendel_y. Here I have:; 1) added documentation for mendel errors; 2) modified the functions leading to the individual and family files so that the SNP count is recorded in addition to the total count. Talking to analysts, the SNP count is useful for QC because indels are so much more volatile. If analysts will typically want both, it seems better to avoid forcing them to run mendel errors twice (before and after filtering to SNPs). Adding the NSNP column in .imendel and .fmendel breaks the PLINK spec but only very gently: adding one additional (final) column. Once we have a better sense of users needs, we should break it completely to best suit them. I'd feel comfortable breaking up chr:pos:ref:alt into separate columns now if you think the time has come...calling that column SNP is especially confusing given that the variant may be an indel. Next up for mendel will be Issues #94 and #148",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/149:80,error,errors,80,https://hail.is,https://github.com/hail-is/hail/pull/149,2,['error'],['errors']
Availability,"To clarify, that :-1: is my finger hovering over the button. Not a thumbs down",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2829#issuecomment-361434958:74,down,down,74,https://hail.is,https://github.com/hail-is/hail/pull/2829#issuecomment-361434958,1,['down'],['down']
Availability,"To clarify, you could could say this:. `kt.aggregate('rows.filter(r => r.col1 < r.col2).count()')`. but this would produce a symref error:. `kt.aggregate('col1.filter(c => c < col2).count()')`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1410#issuecomment-282414199:132,error,error,132,https://hail.is,https://github.com/hail-is/hail/issues/1410#issuecomment-282414199,1,['error'],['error']
Availability,"To enable easy testing, I also parameterized the methods by the branchingFactor and broke generation of the byte array away from writing the byte array to a file. The key issue is that `k * 1024 % 1024 = 0` for any integer `k`, which we were interpreting as meaning that the last block needed 1024 more elements to be full. There are no errors on write. On read, we try to calculate the number of layers present in the BGEN using `calcDepth` but this fails to correctly guess the layers when the size of the file is not a positive integral power of 1024. The only real changes (the rest are restructuring/whitespace) are using `branchingFactor` in place of `1024` and replacing; ```; - // Pad last layer so last block is 1024 elements (1024*8 bytes); - val paddingRequired = 1024 - (arr.length % 1024); ```; with; ```; + // Pad last layer so last block is branchingFactor elements (branchingFactor*8 bytes); + val danglingElements = (arr.length % branchingFactor); + val paddingRequired =; + if (danglingElements == 0) 0; + else branchingFactor - danglingElements; ```. cc: @jigold one of the PRs you asked me to break out.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3750:337,error,errors,337,https://hail.is,https://github.com/hail-is/hail/pull/3750,1,['error'],['errors']
Availability,"To get rid of the CI errors, then you have to run black on some of your files. ```; PYTHONPATH=${PYTHONPATH:+${PYTHONPATH}:}../hail/python:../gear:../web_common python3 -m black . --line-length=120 --skip-string-normalization --check --diff; --- batch/inst_coll_config.py	2022-06-01 03:13:40.430014 +0000; +++ batch/inst_coll_config.py	2022-06-01 03:15:40.847020 +0000; @@ -307,13 +307,20 @@; if optimal_cost is None or max_regional_maybe_cost < optimal_cost:; optimal_cost = max_regional_maybe_cost; optimal_result = (pool.name, maybe_cores_mcpu, maybe_memory_bytes, maybe_storage_gib); return optimal_result; ; - def select_pool_from_worker_type(self, cloud, pool_label, worker_type, cores_mcpu, memory_bytes, storage_bytes, preemptible):; + def select_pool_from_worker_type(; + self, cloud, pool_label, worker_type, cores_mcpu, memory_bytes, storage_bytes, preemptible; + ):; for pool in self.name_pool_config.values():; - if pool.cloud == cloud and pool.worker_type == worker_type and pool.preemptible == preemptible and pool.label == pool_label:; + if (; + pool.cloud == cloud; + and pool.worker_type == worker_type; + and pool.preemptible == preemptible; + and pool.label == pool_label; + ):; result = pool.convert_requests_to_resources(cores_mcpu, memory_bytes, storage_bytes); if result:; actual_cores_mcpu, actual_memory_bytes, acutal_storage_gib = result; return (pool.name, actual_cores_mcpu, actual_memory_bytes, acutal_storage_gib); return None; @@ -322,11 +329,19 @@; if self.jpim_config.cloud != cloud:; return None; return self.jpim_config.convert_requests_to_resources(machine_type, storage_bytes); ; def select_inst_coll(; - self, cloud, machine_type, pool_label, preemptible, worker_type, req_cores_mcpu, req_memory_bytes, req_storage_bytes; + self,; + cloud,; + machine_type,; + pool_label,; + preemptible,; + worker_type,; + req_cores_mcpu,; + req_memory_bytes,; + req_storage_bytes,; ):; if worker_type is not None and machine_type is None:; result = self.select_pool_from_worker",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11879#issuecomment-1144135068:21,error,errors,21,https://hail.is,https://github.com/hail-is/hail/pull/11879#issuecomment-1144135068,1,['error'],['errors']
Availability,"To make existing gnomAD datasets (already in HailTable/MatrixTable form) available via `load_dataset`:; - For v2 now includes multinucleotide variants (MNVs), proportion expressed across transcript (pext), and linkage disequilibrium (LD); - For v3 now includes mitochondrial DNA (mtDNA). The `load_dataset` function now can open a `BlockMatrix` as well, so the gnomAD v2 LD matrices are available through the datasets API in addition to the tables. Also added try/except blocks to `load_datasets`, to handle errors. For example the `gnomad_annotation_pext` dataset has a url of `gs://gcp-public-data--gnomad/papers/2019-tx-annotation/pre_computed/all.possible.snvs.tx_annotated.021520.ht`, but this is actually a `MatrixTable`. So now when trying to open a `HailTable`, it will try to open as a `MatrixTable` if an error is encountered (and vice versa).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9955:73,avail,available,73,https://hail.is,https://github.com/hail-is/hail/pull/9955,4,"['avail', 'error']","['available', 'error', 'errors']"
Availability,"To properly implement IR sets, I need to staged UnsafeOrdering's, or, at the very least, I need to be able to call them from `Code`-land. Since objects at IR-compile-time are not available at IR-run-time (without shipping them to the nodes and passing them as arguments, which I'd like to avoid), I must be able to call static methods, or have fully code-ified versions of every UnsafeOrdering used in the IR. Whenever possible, I tried to call static methods. In a few cases, I couldn't figure out how to make that work, so I had to reimplement the operation in `Code`. I also had to introduce `BindingCode[T]` which is a type alias for `(FunctionBuilder, StagedBitSet) => Code[T]`. The function builder is used to allocate new variables and the `StagedBitSet` is used to compactly store boolean values. I am also somewhat confused by the `missingGreatest` parameter which existed on the original `UnsafeOrdering`s (which I refactored while Code-ifying). cc: @cseed, I guess this parameter is only sensible on compound data? It seems like there should be a:. ```; def compare(r1: MemoryBuffer, o1: Long, m1: Boolean, r2: MemoryBuffer, o2: Long, m2: Boolean): Int; ```. which correctly applies the `missingGreatest` parameter.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2519:179,avail,available,179,https://hail.is,https://github.com/hail-is/hail/pull/2519,1,['avail'],['available']
Availability,"To replicate, replace the contents of `test_king.py::test_king_small` with:; ```; @fails_local_backend(); def test_king_small():; hl.init(idempotent=True) # Should be no error; hl.stop(); hl.init(idempotent=True) # Should be no error; hl.init(hl.spark_context(), idempotent=True) # Should be no error. plink_path = resource('balding-nichols-1024-variants-4-samples-3-populations'); mt = hl.import_plink(bed=f'{plink_path}.bed',; bim=f'{plink_path}.bim',; fam=f'{plink_path}.fam'); kinship = hl.king(mt.GT); assert_c_king_same_as_hail_king(; resource('balding-nichols-1024-variants-4-samples-3-populations.kin0'),; kinship); ```. Stack trace:; ```; E hail.utils.java.FatalError: IndexOutOfBoundsException: 0; E ; E Java stack trace:; E org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 18.0 failed 1 times, most recent failure: Lost task 7.0 in stage 18.0 (TID 34, localhost, executor driver): java.lang.IndexOutOfBoundsException: 0; E 	at scala.collection.immutable.NumericRange.apply(NumericRange.scala:112); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2131); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2127); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9867:170,error,error,170,https://hail.is,https://github.com/hail-is/hail/issues/9867,5,"['error', 'failure']","['error', 'failure']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. An error arises when executing operations/actions using field entries. For intance executing `mt.AD.show()` would give the following: . ### Error No.1: ; ```python; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); /usr/local/lib/python3.6/site-packages/IPython/core/formatters.py in __call__(self, obj); 700 type_pprinters=self.type_printers,; 701 deferred_pprinters=self.deferred_printers); --> 702 printer.pretty(obj); 703 printer.flush(); 704 return stream.getvalue(). /usr/local/lib/python3.6/site-packages/IPython/lib/pretty.py in pretty(self, obj); 400 if cls is not object \; 401 and callable(cls.__dict__.get('__repr__')):; --> 402 return _repr_pprint(obj, self, cycle); 403 ; 404 return _default_pprint(obj, self, cycle). /usr/local/lib/python3.6/site-packages/IPython/lib/pretty.py in _repr_pprint(obj, p, cycle); 695 """"""A pprint that just redirects to the normal repr function.""""""; 696 # Find newlines and replace them with p.break_(); --> 697 output = repr(obj); 698 for idx,output_line in enumerate(output.splitlines()):; 699 if idx:. /usr/local/lib/python3.6/site-packages/hail/matrixtable.py in __repr__(self); 2521 ; 2522 def __repr__(self):; -> 2523 return self.__str__(); 2524 ; 2525 def _repr_html_(self):. /usr/local/lib/python3.6/site-packages/hail/matrixtable.py in __str__(self); 2515 ; 2516 def __str__(self):; -> 2517 s = self.table_show.__str__(); 2518 if self.displayed_n_cols != self.actual_n_cols:; 2519 s += f""showing the first { self.displayed_n_cols } of { self.actual_n_cols } columns"". /usr/local/lib/python3.6/site-packages/hail/table.py in __str__(self); 1241 ; 1242 def __str__(self):; -> 1243 ret",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:296,error,error,296,https://hail.is,https://github.com/hail-is/hail/issues/7044,2,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hail commit version: 5852a71e9e23. Error received:; ```; amazon-ebs: cd build/deploy; python3 setup.py -q sdist bdist_wheel; amazon-ebs: sed '/^pyspark/d' python/requirements.txt \| xargs python3 -m pip install -U; ==> amazon-ebs: ERROR: Invalid requirement: '#'; ==> amazon-ebs: make: *** [install-on-cluster] Error 123; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10352:328,Error,Error,328,https://hail.is,https://github.com/hail-is/hail/issues/10352,3,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9849:304,error,error,304,https://hail.is,https://github.com/hail-is/hail/issues/9849,5,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. I am aggregating gVCF files using the hail function run_combiner. I am using the command below. ````; hl.experimental.run_combiner(inputs, out_file=output_file, tmp_path=temp_bucket, branch_factor=105, batch_size=100, reference_genome='GRCh38', use_genome_default_intervals=True); ````; I am finding that when the phase 1 portion of the functions creates 10 or 100 temporary mt files that the phase 2 portion is not estimating the temporary mt file names correctly. For example, when trying to aggregate 1k gVCF files, 10 temporary mt files are created in phase 1. These are labeled 0.mt -9.mt. Phase 2, however, looks for a two digit file name i.e. 00.mt. I have found the same thing occur when phase 1 creates 100 temporary mt files when aggregating 10k gVCF files. 100 mt files labeled 00.mt -99.mt are created, but phase2 looks for a three digit name 000.mt. I am assuming this is because there are 10 files and 100 files respectively. I do not see this issue when for example 11 temp mt files are created as 00.mt-10.mt. . An example of the error this throws is . ````; Hail version: 0.2.81-edeb70bc789c; Error summary: HailException: No file or directory found at gs://<path>//combiner-temporary/040b0721-5359-430d-9fe9-019f7eb263f8/_phase1_job1/00.mt; ````. is there a flag that I can add that will circumvent this?. Thank you.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11891:1339,error,error,1339,https://hail.is,https://github.com/hail-is/hail/issues/11891,2,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. I'm working through the GWAS tutorial and getting some strange errors with two different functions. On the 4th line calling hl.import_vcf('data/1kg.vcf.bgz').write('data/1kg.mt', overwrite=True) I'm getting the following error:. ```; File ""gwas_tutorial.py"", line 12, in <module>; hl.import_vcf('data/1kg.vcf.bgz').write('data/1kg.mt',overwrite=True); File ""</Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/decorator.py:decorator-gen-946>"", line 2, in write; File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/typecheck/check.py"", line 561, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/matrixtable.py"", line 2494, in write; Env.backend().execute(MatrixWrite(self._mir, writer)); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/backend/backend.py"", line 106, in execute; result = json.loads(Env.hail().backend.spark.SparkBackend.executeJSON(self._to_java_ir(ir))); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/utils/java.py"", line 240, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: ScalaSigParserError: Unexpected failure. Java stack trace:; org.json4s.scalap.ScalaSigParserError: Unexpected failure; 	at org.json4s.scalap.Rules$$anonfun$expect$1.apply(Rules.scala:73); 	at org.json4s.scalap.scalasig.ClassFileParser$.parse(ClassFileParser.scala:95); 	at org.json4s.reflect",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6299:356,error,errors,356,https://hail.is,https://github.com/hail-is/hail/issues/6299,2,['error'],"['error', 'errors']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Reposting this here from the Forum. https://discuss.hail.is/t/getting-java-heap-error-tried-a-bunch-of-things-with-the-executor-and-memory-settings/2753",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12035:373,error,error-tried-a-bunch-of-things-with-the-executor-and-memory-settings,373,https://hail.is,https://github.com/hail-is/hail/issues/12035,1,['error'],['error-tried-a-bunch-of-things-with-the-executor-and-memory-settings']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. When trying to use the load_dataset() function on any dataset, I receive the following error: . ```; mt = hl.experimental.load_dataset(name='1000_Genomes_chrMT',; version='phase_3',; reference_genome='GRCh37',; region='us',; cloud='gcp'); ```. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-7-5fec92db8e26> in <module>; ----> 1 mt = hl.experimental.load_dataset(name='1000_Genomes_chrMT',; 2 version='phase_3',; 3 reference_genome='GRCh37',; 4 region='us',; 5 cloud='gcp'). ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/hail/experimental/datasets.py in load_dataset(name, version, reference_genome, region, cloud); 109 return hl.read_table(path); 110 elif path.endswith('.mt'):; --> 111 return hl.read_matrix_table(path); 112 elif path.endswith('.bm'):; 113 return hl.linalg.BlockMatrix.read(path). ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/decorator.py in fun(*args, **kw); 230 if not kwsyntax:; 231 args, kw = fix(args, kw, sig); --> 232 return caller(func, *(extras + args), **kw); 233 fun.__name__ = func.__name__; 234 fun.__doc__ = func.__doc__. ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 575 def wrapper(__original_func, *args, **kwargs):; 576 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 577 return __original_func(*args_, **kwargs_); 578 ; 579 return wrapper. ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/hail/methods/impex.py in read_matrix_table(path, _intervals, _filter_intervals, _drop_cols, _drop_rows, _n_partitions); 2009 :class:`.Ma",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10530:380,error,error,380,https://hail.is,https://github.com/hail-is/hail/issues/10530,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. hail v 0.2. I can't build from sources. Error below. $ make install-on-cluster HAIL_COMPILE_NATIVES=1 SPARK_VERSION=2.3.2; make -C src/main/c prebuilt; make[1]: Entering directory `/share/apps/luffy/hail/hail/src/main/c'; make[1]: *** No rule to make target `lz4.h', needed by `build/Decoder.o'. Stop.; make[1]: Leaving directory `/share/apps/luffy/hail/hail/src/main/c'; make: *** [native-lib-prebuilt] Error 2. How can I fix this?. thank you",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7464:333,Error,Error,333,https://hail.is,https://github.com/hail-is/hail/issues/7464,2,['Error'],['Error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; First of all, thank you for making such a highly integrated tool. . I learned that this tool could be run in two modes, on Cloud and locally. Well, I happen to have an HPC server that I can work on, so I'd love to use the tool locally. However, many annotation tools require many annotation data that need to be prepared in advance, and no one has seen the exact format of them. Plus, the annotation data sometimes is stored on a google cloud bucket that is requester paid so I don't have a chance to take a peek at them. Therefore, even I try to fill my configuration file, the annotation data needed cannot be prepared unless I have a template of them. . Pls, consider adding a feature like, if we want to run an annotation job locally, let us download package containing all the necessary annotation data in there. So we can set up the configuration file on our own and run the job on a local HPC server. Much appreciated!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9059:1039,down,download,1039,https://hail.is,https://github.com/hail-is/hail/issues/9059,1,['down'],['download']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; Hello, I am having problems to read vcf file using hail. I installed using conda according to https://hail.is/docs/0.2/getting_started.html#requirements; I created the environment, activated it and installed with pip. When I try to load a vcf file, I am getting:; hl.import_vcf('/Volumes/Macintosh HD2/data/thousands_genome/hector.Q15d5.vcf.gz'); py4j.protocol.Py4JJavaError: An error occurred while calling z:is.hail.HailContext.apply. : is.hail.utils.HailException: Hail requires Java 8, found 12.0.1; Any help? Best, Zillur",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6747:672,error,error,672,https://hail.is,https://github.com/hail-is/hail/issues/6747,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; Versions of software products:. Running on Apache Spark version 2.4.5; SparkUI available at http://vhabosgen72:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-3c86d3ba497a; LOGGING: writing to /dacs1/team/vhabhsxum/tasks/ancestryPainting/hail-20210125-1235-0.2.61-3c86d3ba497a.log. I am running the GWAS tutorial hosted at https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html#Let's-do-a-GWAS. Everything is OK until the line to do GWAS. The error I have is as follows:. -------------- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:372,avail,available,372,https://hail.is,https://github.com/hail-is/hail/issues/9939,3,"['avail', 'error']","['available', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; version 0.2.54-8526838bf99f. When importing matrix table from VCF, the rows have the following schema. ```text; ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'locus': locus<GRCh38> ; 'alleles': array<str> ; 'rsid': str ; 'qual': float64 ; 'filters': set<str> ; 'info': struct {} ; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------; ```. When running `mt.rows().show()` the following error is observed. ```text; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); /opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj); 343 method = get_real_method(obj, self.print_method); 344 if method is not None:; --> 345 return method(); 346 return None; 347 else:. /opt/hail/python/hail/table.py in _repr_html_(self); 1279 ; 1280 def _repr_html_(self):; -> 1281 return self._html_str(); 1282 ; 1283 def _ascii_str(self):. /opt/hail/python/hail/table.py in _html_str(self); 1381 return (f'<tr><td style=""{style}"">' + f'</td><td style=""{style}"">'.join(values) + '</td></tr>\n'); 1382 ; -> 1383 arranged_field_names = PlacementTree.from_named_type('row', self.table.row.dtype); 1384 ; 1385 s = '<table>'. /opt/hail/python/hail/utils/placement_tree.py in from_named_type(name, dtype); 16 if not isinstance(dtype, tstruct):; 17 return PlacementTree(name, 1, 0, []); ---> 18 children = [PlacementTree.from_named_type(name, dtype) for name, dtype in dtype.items()]; 19 width = sum(child.width for child in children); 20 height = max(child.height for child in children) + 1. /opt/hail/pyth",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9833:809,error,error,809,https://hail.is,https://github.com/hail-is/hail/issues/9833,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: . current master. ### What you did:. Read in a giant table of phenotypes (~500k rows x ~3k columns). `; raw_phenos = hl.import_table('gs://phenotype_31063/ukb31063.raw_phenotypes.tsv.bgz',; key='eid', impute=True, types={'eid': hl.tstr}, missing='NA', min_partitions=100); raw_phenos.write('gs://armartin/disparities/ukbb_afr/ukb31063.raw_phenotypes.ht'); `; ### What went wrong (all error messages here, including the full java stack trace):. [Stage 1:> (0 + 100) / 100]Traceback (most recent call last):; File ""/tmp/0fdaf26ceb274d679f571483f658e509/run_prs_afr.py"", line 266, in <module>; main(args); File ""/tmp/0fdaf26ceb274d679f571483f658e509/run_prs_afr.py"", line 125, in main; raw_phenos.write('gs://armartin/disparities/ukbb_afr/ukb31063.raw_phenotypes.ht'); File ""<decorator-gen-652>"", line 2, in write; File ""/tmp/0fdaf26ceb274d679f571483f658e509/hail-devel-5dfbe2ec29f8.zip/hail/typecheck/check.py"", line 546, in wrapper; File ""/tmp/0fdaf26ceb274d679f571483f658e509/hail-devel-5dfbe2ec29f8.zip/hail/table.py"", line 1218, in write; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/0fdaf26ceb274d679f571483f658e509/hail-devel-5dfbe2ec29f8.zip/hail/utils/java.py"", line 210, in deco; hail.utils.java.FatalError: NumberFormatException: For input string: ""1001101010010110"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 46 in stage 1.0 failed 20 times, most recent failure: Lost task 46.19 in stage 1.0 (TID 1559, arm-sw-vq41.c.daly-ibd.internal, executor 6): is.hail.utils.HailException: ukb31063.raw_phenotypes.tsv.bgz: java.lang.NumberFormatException: could not convert ""1001101010010110"" to int32 in column ""10145-0.3""; offending li",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4268:637,error,error,637,https://hail.is,https://github.com/hail-is/hail/issues/4268,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.1-6e815ac. ### What you did: hc.import_bgen('*.bgen) X chromosome cannot be imported, which is a major issue when working on phenotypes linked to blood coagulation, for example. ### What went wrong (all error messages here, including the full java stack trace):. [Stage 1:===============================================> (747 + 9) / 871]Traceback (most recent call last):; File ""regression1.py"", line 22, in <module>; hc.import_bgen('/mnt/volume/imputed_genotypes/*.bgen', sample_file='/mnt/volume/imputed_genotypes/MT.sample').split_multi().write('/mnt/volume/imputed_genotypes/MT_intersect_imputed.vds'); File ""<decorator-gen-285>"", line 2, in write; File ""/usr/local/hail/python/hail/java.py"", line 121, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: Hail only supports diploid genotypes. Found min ploidy equals `1' and max ploidy equals `2'. Java stack trace:; org.apache.spark.SparkException: Job aborted.; at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply$mcV$sp(FileFormatWriter.scala:147); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:121); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:121); at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57); at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:121); at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:101); at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycomput",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2407:458,error,error,458,https://hail.is,https://github.com/hail-is/hail/issues/2407,2,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.1. ### What you did: . kt = hc.import_table([""gnomad_coverage_chr1.tsv"", ""gnomad_coverage_chr2.tsv"", ..], min_partitions=10000). ### What went wrong (all error messages here, including the full java stack trace):. I expected the behavior with min_partitions=10000 to be the same as calling repartition(10000), but the keytable only had # of partitions = # of input .tsv files. I switched to just calling repartition(10000) after importing, and it works as expected. . May be duplicate of #508",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2420:409,error,error,409,https://hail.is,https://github.com/hail-is/hail/issues/2420,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.1. ### What you did:. ### What went wrong (all error messages here, including the full java stack trace):. The docs under ; https://hail.is/docs/stable/hail.HailContext.html?highlight=import_vcf#hail.HailContext.import_vcf; are; ```; If generic equals False (default), Hail makes certain assumptions about the genotype fields, see Representation. On import, Hail filters (sets to no-call) any genotype that violates these assumptions. Hail interprets the format fields: GT, AD, OD, DP, GQ, PL; all others are silently dropped.; ```; but clicking the `Representation` link does lead to any additional details.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3472:302,error,error,302,https://hail.is,https://github.com/hail-is/hail/issues/3472,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.2. ### What you did: read in a Hail Table with 96 rows and 5960 Columns; `table1.row.show(); table2.row.show()`. ### What went wrong (all error messages here, including the full java stack trace):. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-80-bf4d6c719c23> in <module>(); 1 table1.row.show(); ----> 2 table2.row.show(). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). /home/hail/hail.zip/hail/expr/expressions/base_expression.py in show(self, n, width, truncate, types); 677 Print an extra header line with the type of each field.; 678 """"""; --> 679 print(self._show(n, width, truncate, types)); 680 ; 681 def _show(self, n=10, width=90, truncate=None, types=True):. /home/hail/hail.zip/hail/expr/expressions/base_expression.py in _show(self, n, width, truncate, types); 684 if isinstance(source, hl.Table):; 685 if self is source.row:; --> 686 return source._show(n, width, truncate, types); 687 elif self is source.key:; 688 return source.select()._show(n, width, truncate, types). /home/hail/hail.zip/hail/table.py in _show(self, n, width, truncate, types); 1201 ; 1202 def _show(self, n=10, width=90, truncate=None, types=True):; -> 1203 return self._jt.showString(n, joption(truncate), types, width); 1204 ; 1205 def index(self, *exprs):. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3922:393,error,error,393,https://hail.is,https://github.com/hail-is/hail/issues/3922,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.2. ### What you did:; ```; vp_ht = vp_ht.transmute(; locus1=hl.locus(vp_ht.chrom1, vp_ht.pos1),; locus2=hl.locus(vp_ht.chrom1, vp_ht.pos2),; alleles1=[vp_ht.ref1, vp_ht.alt1],; alleles2=[vp_ht.ref2, vp_ht.alt2]; ). vp_mt = hl.MatrixTable.from_rows_table(vp_ht); vp_mt = vp_mt.key_rows_by('locus1', 'alleles1'). mt = mt.annotate_rows(v1=hl.is_defined(vp_mt[(mt.locus, mt.alleles), :])); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; In [49]: mt = mt.annotate_rows(v1=hl.is_defined(vp_mt[(mt.locus, mt.alleles),:])); ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-49-5ea2fe942ada> in <module>(); ----> 1 mt = mt.annotate_rows(v1=hl.is_defined(vp_mt[(mt.locus, mt.alleles),:])). /home/hail/hail.zip/hail/matrixtable.py in annotate_rows(self, **named_exprs); 894 exprs = []; 895 named_exprs = {k: to_expr(v) for k, v in named_exprs.items()}; --> 896 base, cleanup = self._process_joins(*named_exprs.values()); 897; 898 for k, v in named_exprs.items():. /home/hail/hail.zip/hail/matrixtable.py in _process_joins(self, *exprs); 2205 for j in list(e._joins)[::-1]:; 2206 if j.uid not in used_uids:; -> 2207 left = j.join_function(left); 2208 all_uids.extend(j.temp_vars); 2209 used_uids.add(j.uid). /home/hail/hail.zip/hail/matrixtable.py in <lambda>(left); 2157 prefix = 'va'; 2158 joiner = lambda left: (; -> 2159 MatrixTable(left._jvds.annotateRowsVDS(right._jvds, uid))); 2160 else:; 2161 return self.rows().index(*exprs). /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3119:671,error,error,671,https://hail.is,https://github.com/hail-is/hail/issues/3119,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.2.10-91149b50a53c. ### What you did:. ```; qc_ht = qc_mt.annotate_cols(; dp_stats=hl.agg.group_by(qc_mt.qc_platform, hl.agg.stats(qc_mt.DP)),; gq_stats=hl.agg.group_by(qc_mt.qc_platform, hl.agg.stats(qc_mt.GQ)),; callstats=hl.agg.group_by(qc_mt.qc_platform, hl.agg.call_stats(qc_mt.GT, qc_mt.alleles)),; call_rate=hl.agg.group_by(qc_mt.qc_platform, hl.agg.fraction(hl.is_defined(qc_mt.GQ))); ).rows(); ```. ### What went wrong (all error messages here, including the full java stack trace):. So I was distracted and used `annotate_rows` instead of `annotate_cols` and I got what seems to be an 0.1 error message:. ```; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); <ipython-input-44-7491b514f674> in <module>; 3 gq_stats=hl.agg.group_by(qc_mt.qc_platform, hl.agg.stats(qc_mt.GQ)),; 4 callstats=hl.agg.group_by(qc_mt.qc_platform, hl.agg.call_stats(qc_mt.GT, qc_mt.alleles)),; ----> 5 call_rate=hl.agg.group_by(qc_mt.qc_platform, hl.agg.fraction(hl.is_defined(qc_mt.GQ))); 6 ).rows(); 7 # qc_ht = qc_ht.key_by('locus','alleles'). </opt/conda/lib/python3.6/site-packages/decorator.py:decorator-gen-976> in annotate_cols(self, **named_exprs). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 559 def wrapper(__original_func, *args, **kwargs):; 560 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 561 return __original_func(*args_, **kwargs_); 562 ; 563 return wrapper. /home/hail/hail.zip/hail/matrixtable.py in annotate_cols(self, **named_exprs); 995 caller = ""MatrixTable.annotate_cols""; 996 check_annotate_exprs(caller, named_exprs, self._col_indices); --> 997 return self._selec",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5415:687,error,error,687,https://hail.is,https://github.com/hail-is/hail/issues/5415,2,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.2.11-fea176012ee0. ### What you did:. ```; hl.eval({'a':2, None: 1}); ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; ---------------------------------------------------------------------------; ExpressionException Traceback (most recent call last); /home/hail/hail.zip/hail/expr/expressions/expression_typecheck.py in check(self, x, caller, param); 73 try:; ---> 74 return self.coerce(to_expr(x)); 75 except ExpressionException as e:. /home/hail/hail.zip/hail/expr/expressions/base_expression.py in to_expr(e, dtype); 99 if not dtype:; --> 100 dtype = impute_type(e); 101 x = _to_expr(e, dtype). /home/hail/hail.zip/hail/expr/expressions/base_expression.py in impute_type(x); 73 raise ExpressionException(""Cannot impute type of empty dict. Use 'hl.empty_dict' to create an empty dict.""); ---> 74 kts = {impute_type(element) for element in x.keys()}; 75 vts = {impute_type(element) for element in x.values()}. /home/hail/hail.zip/hail/expr/expressions/base_expression.py in <setcomp>(.0); 73 raise ExpressionException(""Cannot impute type of empty dict. Use 'hl.empty_dict' to create an empty dict.""); ---> 74 kts = {impute_type(element) for element in x.keys()}; 75 vts = {impute_type(element) for element in x.values()}. /home/hail/hail.zip/hail/expr/expressions/base_expression.py in impute_type(x); 85 elif x is None:; ---> 86 raise ExpressionException(""Hail cannot impute the type of 'None'""); 87 elif isinstance(x, (hl.expr.builders.CaseBuilder, hl.expr.builders.SwitchBuilder)):. ExpressionException: Hail cannot impute the type of 'None'. The above exception was the direct cause of the following exception:. TypecheckFailure Traceback (most recent call last); /home/hail/hail.zip/hail/typech",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5700:355,error,error,355,https://hail.is,https://github.com/hail-is/hail/issues/5700,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.2.11. ### What you did: ./gradlew -Dspark.version=2.2.1 -Dspark.version=2.2.1 -Dpy4j.version=0.10.4 -Dbreeze.version=0.13.1 shadowJar. ### What went wrong (all error messages here, including the full java stack trace):; :compileJava UP-TO-DATE; :generateBuildInfo; :nativeLib; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux test.cpp -MG -M -MF build/test.d -MT build/test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux ibs.cpp -MG -M -MF build/ibs.d -MT build/ibs.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux davies.cpp -MG -M -MF build/davies.d -MT build/davies.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux cache-tests.cpp -MG -M -MF build/cache-tests.d -MT build/cache-tests.o; g++ -march=s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5659:415,error,error,415,https://hail.is,https://github.com/hail-is/hail/issues/5659,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.2.8-844023079796. ### What you did:. ```; x = hl.utils.range_table(100); x = x.filter(False); x.show(); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-89-65d54ebb6a64> in <module>; 1 x = hl.utils.range_table(100); 2 x = x.filter(False); ----> 3 x.show(). /home/hail/gnomad_hail/utils/plotting.py in new_show(t, n, width, truncate, types); 25 ; 26 def new_show(t, n=10, width=140, truncate=40, types=True):; ---> 27 old_show(t, n, width, truncate, types); 28 hl.Table.show = new_show; 29 . <decorator-gen-848> in show(self, n, width, truncate, types, handler). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561 ; 562 return wrapper. /home/hail/hail.zip/hail/table.py in show(self, n, width, truncate, types, handler); 1331 Handler function for data string.; 1332 """"""; -> 1333 handler(self._show(n, width, truncate, types)); 1334 ; 1335 def index(self, *exprs):. /home/hail/hail.zip/hail/table.py in _show(self, n, width, truncate, types); 1238 ; 1239 column_width = [max(len(fields[i]), len(types[i]), max([len(row[i]) for row in rows])); -> 1240 for i in range(n_fields)]; 1241 ; 1242 column_blocks = []. /home/hail/hail.zip/hail/table.py in <listcomp>(.0); 1238 ; 1239 column_width = [max(len(fields[i]), len(types[i]), max([len(row[i]) for row in rows])); -> 1240 for i in range(n_fields)]; 1241 ; 1242 column_blocks ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5173:389,error,error,389,https://hail.is,https://github.com/hail-is/hail/issues/5173,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.2.9-c3b1183e4246. ### What you did:; ```; pops_for_subpop = pops_ht.aggregate(; hl.agg.filter(; hl.is_defined(pops_ht.pop) & (pops_ht.pop != ""oth""),; hl.agg.group_by(pops_ht.pop, hl.agg.count()); ); ); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; Traceback (most recent call last):; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/sample_qc.py"", line 530, in <module>; main(args); File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/sample_qc.py"", line 458, in main; hl.agg.group_by(pops_ht.pop, hl.agg.count()); File ""</opt/conda/lib/python3.6/site-packages/decorator.py:decorator-gen-764>"", line 2, in aggregate; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/typecheck/check.py"", line 560, in wrapper; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/table.py"", line 1133, in aggregate; File ""</opt/conda/lib/python3.6/site-packages/decorator.py:decorator-gen-436>"", line 2, in analyze; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/typecheck/check.py"", line 560, in wrapper; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/expr/expressions/expression_utils.py"", line 94, in analyze; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/expr/expressions/expression_utils.py"", line 237, in get_refs; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/expr/expressions/expression_utils.py"", line 212, in _get_refs; AttributeError: 'NoneType' object has no attribute '_indices_from_ref'; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [251cbf7beb5f4503ba74e4d69bd09ec3] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call las",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5296:487,error,error,487,https://hail.is,https://github.com/hail-is/hail/issues/5296,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: ; version 0.2-721af83bc30a. ### What you did: ; Import UK Biobank bgen chr10. import hail as hl; import sys; hl.init(); chr=sys.argv[1]; bgen=""/project/ukbiobank/imp/uk.v3/bgen/ukb_imp_chr""+chr+""_v3.bgen""; sample=""/project/ukbiobank/imp/uk.v3/bgen/ukb19416_imp_chr""+chr+""_v3_s487327.sample""; mt=""/project/ukbiobank/imp/uk.v3/mt/ukbb_imp_chr""+chr+""_v3_s487327.mt""; hl.index_bgen(bgen); hl.import_bgen(bgen,sample_file=sample,entry_fields=['GT', 'GP','dosage']).write(mt). ### What went wrong (all error messages here, including the full java stack trace):; ```; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2-721af83bc30a; LOGGING: writing to /restricted/projectnb/ukbiobank/ad/analysis/ad.v1/hail-20181114-1827-0.2-721af83bc30a.log; Exception in thread ""dispatcher-event-loop-8"" Exception in thread ""refresh progress"" java.lang.OutOfMemoryError: GC overhead limit exceeded; at java.util.zip.ZipCoder.getBytes(ZipCoder.java:80); at java.util.zip.ZipFile.getEntry(ZipFile.java:310); at java.util.jar.JarFile.getEntry(JarFile.java:240); at java.util.jar.JarFile.getJarEntry(JarFile.java:223); at sun.misc.URLClassPath$JarLoader.getResource(URLClassPath.java:1042); at sun.misc.URLClassPath.getResource(URLClassPath.java:239); at java.net.URLClassLoader$1.run(URLClassLoader.java:365); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:749,error,error,749,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: `devel-f2b0dca9f506`. ### What you did:. ```; ht.group_by('model', 'rank_id', 'bin').aggregate(titv=ht.n_ti/ht.n_tv, ; min_score=hl.agg.min(ht.min_score),; max_score=hl.agg.min(ht.max_score); ).show(); ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-26-65c5654a1482> in <module>(); 1 ht.group_by('model', 'rank_id', 'bin').aggregate(titv=ht.n_ti/ht.n_tv, ; 2 min_score=hl.agg.min(ht.min_score),; ----> 3 max_score=hl.agg.min(ht.max_score); 4 ).show(). /home/hail/gnomad_hail/utils/plotting.py in new_show(t, n, width, truncate, types); 24 ; 25 def new_show(t, n=10, width=170, truncate=40, types=True):; ---> 26 old_show(t, n, width, truncate, types); 27 hl.Table.show = new_show; 28 . /home/hail/hail.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). /home/hail/hail.zip/hail/table.py in show(self, n, width, truncate, types); 1215 Print an extra header line with the type of each field.; 1216 """"""; -> 1217 print(self._show(n,width, truncate, types)); 1218 ; 1219 def _show(self, n=10, width=90, truncate=None, types=True):. /home/hail/hail.zip/hail/table.py in _show(self, n, width, truncate, types); 1218 ; 1219 def _show(self, n=10, width=90, truncate=None, types=True):; -> 1220 return self._jt.showString(n, joption(truncate), types, width); 1221 ; 1222 def index(self, *exprs):. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4110:485,error,error,485,https://hail.is,https://github.com/hail-is/hail/issues/4110,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-45429b1. ### What you did:; ```; eval_expr(functions.cond(functions.capture(True), 'T', 'F') + functions.cond(functions.capture(True), 'T', 'F')); ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-20-3b0a2ce317c2> in <module>(); ----> 1 eval_expr(functions.cond(functions.capture(True), 'T', 'F') + functions.cond(functions.capture(True), 'T', 'F')). <decorator-gen-365> in eval_expr(expression). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in args_to_expr(func, *args); 176 @decorator; 177 def args_to_expr(func, *args):; --> 178 return func(*(to_expr(a) for a in args)); 179; 180. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in eval_expr(expression); 3576 Result of evaluating `expression`.; 3577 """"""; -> 3578 return eval_expr_typed(expression)[0]; 3579; 3580. <decorator-gen-366> in eval_expr_typed(expression). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in args_to_expr(func, *args); 176 @decorator; 177 def args_to_expr(func, *args):; --> 178 return func(*(to_expr(a) for a in args)); 179; 180. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in eval_expr_typed(expression); 3612 if len(expression._joins) > 0:; 3613 raise ExpressionException(""'eval_expr' methods do not support joins or broadcasts""); -> 3614 r, t = Env.hc().eval_expr_typed(expression._ast.to_hql()); 3615 return r, t; 3616. <decorator-gen-1049> in eval_expr_typed(self, expr). /hadoop_gcs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2653:436,error,error,436,https://hail.is,https://github.com/hail-is/hail/issues/2653,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-4f13f27cd28d. ### What you did:; ipython vcf2mt.py . import hail as hl; hl.init(default_reference='GRCh38'); chr=""22""; vcf=""/project/ukbiobank/imputation/ad.v1/vcf/ukbb.hg38.imputed.chr""+chr+"".dose.vcf.bgz""; mt=""/project/ukbiobank/imputation/ad.v1/mt/ukbb.hg38.imputed.chr""+chr; hl.import_vcf(vcf).write(mt). ### What went wrong (all error messages here, including the full java stack trace):. GC Overhead limit exceeded on Stage 2 of import_vcf.write (See below). ```; Running on Apache Spark version 2.2.0; SparkUI available at http://10.48.225.55:4041; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-4f13f27cd28d; NOTE: This is a beta version. Interfaces may change; during the beta period. We recommend pulling; the latest changes weekly.; [Stage 1:======================================================>(740 + 1) / 741]2018-11-10 22:55:07 Hail: INFO: Coerced almost-sorted dataset; [Stage 2:> (0 + 24) / 741]Exception in thread ""refresh progress"" Exception in thread ""LeaseRenewer:farrell@scc"" java.lang.OutOfMemoryError: GC overhead limit exceeded; java.lang.OutOfMemoryError: GC overhead limit exceeded; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); /restricted/projectnb/ukbiobank/ad/analysis/ad.v1/vcf2mt.py in <module>(); 4 vcf=""/project/ukbiobank/imputation/ad.v1/vcf/ukbb.hg38.imputed.chr""+chr+"".dose.vcf.bgz""; 5 mt=""/project/ukbiobank/imputation/ad.v1/mt/ukbb.hg38.imputed.chr""+chr; ----> 6 hl.import_vcf(vcf).write(mt). /share/pkg/hail/2018-06-18/install/build/distributions/hail-python.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755:593,error,error,593,https://hail.is,https://github.com/hail-is/hail/issues/4755,2,"['avail', 'error']","['available', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-544bf8f. ### What you did: import vcf from delly; ```; import hail as hl; hl.init(default_reference='GRCh38'); hl.import_vcf('/project/casa/vcf.5k/delly/gcad.sv.delly.5k.vcf.bgz').write('/project/casa/vdf.5k/delly'); ```. ### What went wrong (all error messages here, including the full java stack trace):. The CN field is an integer. When the integer is -1 for CN, an error is generated. ./.:0,0,0:0:LowQual:0:0:0:**-1**:0:0:0:0. The header defines CN with this:. ##FORMAT=<ID=CN,Number=1,Type=Integer,Description=""Read-depth based copy-number estimate for autosomal sites"">. ```; Hail version: devel-544bf8f; Error summary: HailException: gcad.sv.delly.5k.vcf.bgz:column 80816: invalid character '-' in integer literal; ... 2:0:0:0:6 ./.:0,0,0:0:LowQual:0:0:0:-1:0:0:0:0 ./.:0,0,0:0:LowQual:0:0:0 ...; ^; offending line: chr1 152267996 DEL00028254 AATATATATACTTTACGTAAAGT A . PASS ...; ```; Here is the full log and exception..... ```; Running on Apache Spark version 2.2.0; SparkUI available at http://10.48.225.55:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-544bf8f; NOTE: This is a beta version. Interfaces may change; during the beta period. We also recommend pulling; the latest changes weekly.; [Stage 1:======================================================>(414 + 2) / 416]2018-04-15 14:38:32 Hail: INFO: Coerced almost-sorted dataset; [Stage 2:> (0 + 34) / 416]Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail/delly_vcf2vdf.py"", line 3, in <module>; hl.import_vcf('/project/casa/vcf.5k/delly/gcad.sv.delly.5k.vcf.bgz').write('/project/casa/vdf.5k/delly'); File ""<decorator-gen-552>"", line 2, in write; File ""/restricted/projectnb/genpro/github/ha",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3379:506,error,error,506,https://hail.is,https://github.com/hail-is/hail/issues/3379,3,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-5b299ddae758. ### What you did: ; ```; hl.utils.hadoop_is_file('gs://gnomad-tmp/pbt_parents_sparse_genotype_matrix/cols_ann.ht/_SUCCESS'); ```. ### What went wrong (all error messages here, including the full java stack trace):. Got a `FileNotFoundException`. Based on the documentation, I was expecting `False`. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-7-5ad16e5a0601> in <module>(); 1 hl.utils.hadoop_exists('gs://gnomad-tmp/pbt_parents_sparse_genotype_matrix/cols_ann.ht/_SUCCESS'); ----> 2 hl.utils.hadoop_is_file('gs://gnomad-tmp/pbt_parents_sparse_genotype_matrix/cols_ann.ht/_SUCCESS'). /home/hail/hail.zip/hail/utils/hadoop_utils.py in hadoop_is_file(path); 164 :obj:`.bool`; 165 """"""; --> 166 return Env.jutils().isFile(path, Env.hc()._jhc); 167 ; 168 . /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: FileNotFoundException: File not found : gs://gnomad-tmp/pbt_parents_sparse_genotype_matrix/cols_ann.ht/_SUCCESS; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3725:428,error,error,428,https://hail.is,https://github.com/hail-is/hail/issues/3725,2,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-5b299ddae758. ### What you did:. ```; print(metrics_ht['vqsr'].globals); hl.eval_expr(metrics_ht['vqsr'].globals); ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; <StructExpression of type struct{}>; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-51-e812f4924948> in <module>(); 1 print(metrics_ht['vqsr'].globals); ----> 2 hl.eval_expr(metrics_ht['vqsr'].globals). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). /home/hail/hail.zip/hail/expr/expressions/expression_utils.py in eval_expr(expression); 135 Result of evaluating `expression`.; 136 """"""; --> 137 return eval_expr_typed(expression)[0]; 138 ; 139 . /home/hail/hail.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). /home/hail/hail.zip/hail/expr/expressions/expression_utils.py in eval_expr_typed(expression); 169 analyze('eval_expr_typed', expression, Indices(expression._indices.source)); 170 ; --> 171 return expression.collect()[0], expression.dtype; 172 ; 173 . /home/hail/hail.zip/hail/expr/expressions/base_expression.py in collect(self); 755 """"""; 756 uid = Env.get_uid(); --> 757 t = self._to_table(uid); 758 return [r[uid] for r in t._select(""collect"", None, hl.struct(**{uid: t[uid]})).collect()]; 759 . /home/hail/hail.zi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3728:404,error,error,404,https://hail.is,https://github.com/hail-is/hail/issues/3728,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-6191d4c. ### What you did: vds.vep(""/vep/vep-gcloud.propertiesâ€). ### What went wrong (all error messages here, including the full java stack trace):. Traceback (most recent call last):; File ""/tmp/2f781c88-64f1-4345-a2b9-433c49d5a099/script_to_submit.py"", line 8, in <module>; vdsvep = vds.vep(""/vep/vep-gcloud.properties""); File ""<decorator-gen-878>"", line 2, in vep; File ""/tmp/2f781c88-64f1-4345-a2b9-433c49d5a099/hail-devel-6191d4ce69aa.zip/hail/utils/java.py"", line 167, in handle_py4j; hail.utils.java.FatalError: Can't zip RDDs with unequal numbers of partitions: List(16979, 16992). Java stack trace:; org.apache.spark.rdd.ZippedPartitionsBaseRDD.getPartitions(ZippedPartitionsRDD.scala:57); 	 at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	 at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	 at scala.Option.getOrElse(Option.scala:121); 	 at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	 at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	 at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	 at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	 at scala.Option.getOrElse(Option.scala:121); 	 at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	 at is.hail.sparkextras.OrderedRDD$.coerce(OrderedRDD.scala:58); 	 at is.hail.sparkextras.OrderedRDD$.apply(OrderedRDD.scala:48); 	 at is.hail.utils.richUtils.RichPairRDD$.toOrderedRDD$extension1(RichPairRDD.scala:44); 	 at is.hail.variant.MatrixTable$.fromLegacy(MatrixTable.scala:84); 	 at is.hail.variant.MatrixTable.copyLegacy(MatrixTable.scala:2019); 	 at is.hail.methods.VEP$.annotate(VEP.scala:407); 	 at is.hail.methods.VEP$.apply(VEP.scala:41",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2666:350,error,error,350,https://hail.is,https://github.com/hail-is/hail/issues/2666,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-63d60cc. ### What you did:. Tried to run ld_prune and pc_relate on 5000 WGS samples. ```; spark-submit --verbose --master yarn --deploy-mode client \; --num-executors 14 \; --executor-cores 6 \; --jars $JAR \; --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator \; --conf ""spark.driver.extraClassPath=$JAR"" \; --conf ""spark.executor.extraClassPath=$JAR"" \; --executor-memory 90G\; --driver-memory 80g\; --conf spark.yarn.executor.memoryOverhead=8000 \; --conf spark.network.timeout=600 \; --conf spark.executor.heartbeatInterval=120\; hc_prune.py; ```. Where hc_prune.py is:. ```; import matplotlib.pyplot as plt; import seaborn. import numpy as np; import pandas as pd; from collections import Counter; from math import log, isnan; from pprint import pprint; # hail; import hail as hl; import hail.expr.aggregators as agg; import hail.expr.functions. hl.init(default_reference='GRCh38'); print(""Read in PASS SNVs""); passed=hl.read_matrix_table('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass'); print(""Filtering Common Variants""); common=passed.filter_rows(passed.variant_qc.AF > 0.01).persist(); common.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass.common'); print(""Pruning LD Variants""); pruned =hl.ld_prune(common,30,r2=0.1, memory_per_core=2048); pruned.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pruned'); print(""Sample 20% of variants for running PC-Relate""); pruned_subsample = pruned.sample_rows(0.2).persist(); print(""Running PC_Relate""); rel = hl.pc_relate(pruned_subsample.GT, 0.01, k=10); rel_df = rel.to_pandas(); rel_df.describe(); pprint(rel_df); rel_df.to_csv('gcad_5k.snv.rel.csv'); ```. ### What went wrong (all error messages here, including the full java stack trace):. Got a memor",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3463:781,heartbeat,heartbeatInterval,781,https://hail.is,https://github.com/hail-is/hail/issues/3463,1,['heartbeat'],['heartbeatInterval']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-63d60cc. ### What you did:; Ran pc_relate on pruned matrix table (500K SNVs) containing 5k samples. About 800 family members are in the dataset. The data includes a number of replicates also. ### What went wrong (all error messages here, including the full java stack trace):. Replicates should have a kinship coefficient near 0.50 with themselves. Instead HAIL pc_relate calculated 0.18. King correctly calculated 0.498 on the exported plink file. ; ```; 279,A-CUHS-CU001167-BL-COL-32167BL1,A-CUHS-CU001167-BL-COL-32167BL1dea,0.18452354646323424; 280,A-CUHS-CU001167-BL-COL-32167BL1,A-CUHS-CU001167-BL-COL-32167BL1der,0.18468831264044877; 281,A-CUHS-CU001167-BL-COL-32167BL1dea,A-CUHS-CU001167-BL-COL-32167BL1der,0.18515942448861653; 282,A-CUHS-CU001167-BL-COL-32167BL1,A-CUHS-CU001167-BL-COL-32167BL1dew,0.1833498632291505; 283,A-CUHS-CU001167-BL-COL-32167BL1dea,A-CUHS-CU001167-BL-COL-32167BL1dew,0.18376901216269165; 284,A-CUHS-CU001167-BL-COL-32167BL1der,A-CUHS-CU001167-BL-COL-32167BL1dew,0.18367338097096797; 285,A-CUHS-CU001167-BL-COL-32167BL1,A-CUHS-CU001167-BL-COL-32167BL1fa,0.18470621273350465; 286,A-CUHS-CU001167-BL-COL-32167BL1dea,A-CUHS-CU001167-BL-COL-32167BL1fa,0.1852915664909736; 287,A-CUHS-CU001167-BL-COL-32167BL1der,A-CUHS-CU001167-BL-COL-32167BL1fa,0.18516143096293416; 288,A-CUHS-CU001167-BL-COL-32167BL1dew,A-CUHS-CU001167-BL-COL-32167BL1fa,0.1838098671960904; 289,A-CUHS-CU001167-BL-COL-32167BL1,A-CUHS-CU001167-BL-COL-32167BL1fr,0.1847714820370011; 290,A-CUHS-CU001167-BL-COL-32167BL1dea,A-CUHS-CU001167-BL-COL-32167BL1fr,0.18525793071221844; 291,A-CUHS-CU001167-BL-COL-32167BL1der,A-CUHS-CU001167-BL-COL-32167BL1fr,0.1852207373990892; 292,A-CUHS-CU001167-BL-COL-32167BL1dew,A-CUHS-CU001167-BL-COL-32167BL1fr,0.183",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3490:476,error,error,476,https://hail.is,https://github.com/hail-is/hail/issues/3490,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-63d60cc. ### What you did:; Tried to run sample_qc on mt table imported from Delly vcf. ; hl.sample_qc(ds). ### What went wrong (all error messages here, including the full java stack trace):. The sample_qc had a problem when alt ref is <DEL>. ```; [Stage 3:> (0 + 140) / 415]Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail.qc/delly-qc.py"", line 35, in <module>; ds = hl.sample_qc(ds); File ""<decorator-gen-902>"", line 2, in sample_qc; File ""/restricted/projectnb/genpro/github/hail/python/hail/typecheck/check.py"", line 490, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/restricted/projectnb/genpro/github/hail/python/hail/methods/qc.py"", line 91, in sample_qc; return MatrixTable(Env.hail().methods.SampleQC.apply(require_biallelic(dataset, 'sample_qc')._jvds, name)); File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: invalid allele ""<DEL>"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 3.0 failed 4 times, most recent failure: Lost task 2.3 in stage 3.0 (TID 160, scc-q01.scc.bu.edu, executor 4): is.hail.utils.HailException: invalid allele ""<DEL>""; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:29); at is.hail.methods.SampleQCCo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:392,error,error,392,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-7cde2bf. ### What you did:; Tried to read in, repartition, and write 3 matrixtables. This then corrupted the previous version (as I used overwrite), so tried to recreate the matrix tables from the original vcf, and could not import. . ### What went wrong (all error messages here, including the full java stack trace):; repartition error:; ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-8-f1eea7557457> in <module>(); ----> 1 hm3_variants_vds = hm3_variants_vds.repartition(100); <decorator-gen-688> in repartition(self, n_partitions, shuffle); /home/hail/hail.zip/hail/typecheck/check.py in _typecheck(__orig_func__, *args, **kwargs); 484 def _typecheck(__orig_func__, *args, **kwargs):; 485 args_, kwargs_ = check_all(__orig_func__, args, kwargs, checkers, is_method=True); --> 486 return __orig_func__(*args_, **kwargs_); 487 ; 488 return decorator(_typecheck); /home/hail/hail.zip/hail/matrixtable.py in repartition(self, n_partitions, shuffle); 2505 Repartitioned dataset.; 2506 """"""; -> 2507 jvds = self._jvds.coalesce(n_partitions, shuffle); 2508 return MatrixTable(jvds); 2509 ; /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:; /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.Capture",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3507:519,error,error,519,https://hail.is,https://github.com/hail-is/hail/issues/3507,2,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-a870693. ### What you did:. ```; In [3]: x = hl.literal([1.0,2.2])\; In [4]: hl.eval_expr(hl.sum(x)); ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-11-c37a34e6bd74> in <module>(); ----> 1 hl.eval_expr(hl.sum(x)). <decorator-gen-355> in eval_expr(expression). ~/tools/hail/python/hail/typecheck/check.py in _typecheck(__orig_func__, *args, **kwargs); 488 def _typecheck(__orig_func__, *args, **kwargs):; 489 args_, kwargs_ = check_all(__orig_func__, args, kwargs, checkers, is_method=False); --> 490 return __orig_func__(*args_, **kwargs_); 491; 492 return decorator(_typecheck). ~/tools/hail/python/hail/expr/expressions/expression_utils.py in eval_expr(expression); 136 Result of evaluating `expression`.; 137 """"""; --> 138 return eval_expr_typed(expression)[0]; 139; 140. <decorator-gen-357> in eval_expr_typed(expression). ~/tools/hail/python/hail/typecheck/check.py in _typecheck(__orig_func__, *args, **kwargs); 488 def _typecheck(__orig_func__, *args, **kwargs):; 489 args_, kwargs_ = check_all(__orig_func__, args, kwargs, checkers, is_method=False); --> 490 return __orig_func__(*args_, **kwargs_); 491; 492 return decorator(_typecheck). ~/tools/hail/python/hail/expr/expressions/expression_utils.py in eval_expr_typed(expression); 172 analyze('eval_expr_typed', expression, Indices(expression._indices.source)); 173; --> 174 return expression.collect()[0], expression.dtype; 175; 176. ~/tools/hail/python/hail/expr/expressions/base_expression.py in collect(self); 770 """"""; 771 uid = Env.get_uid(); --> 772 t = self._to_table(uid); 773 return [r[ui",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3436:391,error,error,391,https://hail.is,https://github.com/hail-is/hail/issues/3436,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-abac611 using Apache Spark version 2.2.0. ### What you did:; Tried converting joint genotyped Delly vcf file to vdf file. ```; import hail as hl; hl.init(default_reference='GRCh38'); hl.import_vcf('/project/casa/vcf.5k/delly/gcad.sv.delly.5k.vcf.bgz').write('/project/casa/vdf.5k/delly'); ```. ### What went wrong (all error messages here, including the full java stack trace):. Error reading a GL field. ; ##FORMAT=<ID=GL,Number=G,Type=Float,Description=""Log10-scaled genotype likelihoods for RR,RA,AA genotypes"">. where the entry was:; 0/1:-66.2667,0,-25.4754:10000:PASS:5639:13071:8160:2:0:0:13:27. Here are the log and error messages... ```; [Stage 1:======================================================>(415 + 1) / 416]2018-04-12 07:57:52 Hail: INFO: Coerced almost-sorted dataset; [Stage 2:> (0 + 36) / 416]Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail/delly_vcf2vdf.py"", line 3, in <module>; hl.import_vcf('/project/casa/vcf.5k/delly/gcad.sv.delly.5k.vcf.bgz').write('/project/casa/vdf.5k/delly'); File ""<decorator-gen-546>"", line 2, in write; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 481, in _typecheck; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 1956, in write; File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: NumberFormatException: For input string: ""-66.2667,0,-25.4754"". Java stack trace:; org.apache.spark.SparkException: Job aborte",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3361:578,error,error,578,https://hail.is,https://github.com/hail-is/hail/issues/3361,3,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-b1d7ad8506d7. ### What you did:. ```; x = hl.literal(hl.set(['A','B'])); x; Out[5]: <SetExpression of type set<str>>; x.contains('A'); Out[6]: <BooleanExpression of type bool>; x.contains('A').value; ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; Traceback (most recent call last):; File ""/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-7-21a57f32eefb>"", line 1, in <module>; x.contains('A').value; File ""/Users/laurent/tools/hail/python/hail/expr/expressions/base_expression.py"", line 786, in value; return hl.eval_expr(self); File ""/Users/laurent/tools/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/laurent/tools/hail/python/hail/expr/expressions/expression_utils.py"", line 137, in eval_expr; return eval_expr_typed(expression)[0]; File ""/Users/laurent/tools/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/laurent/tools/hail/python/hail/expr/expressions/expression_utils.py"", line 171, in eval_expr_typed; return expression.collect()[0], expression.dtype; File ""/Users/laurent/tools/hail/python/hail/expr/expressions/base_expression.py"", line 768, in collect; t = self._to_table(uid); File ""/Users/laurent/tools/hail/python/hail/expr/expressions/base_expression.py"", line 591, in _to_table; df = df.select(**{name: self}); File ""/Users/laurent/tools/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/laurent/tools/hail/python/hail/table.py"", line 893, in select; return self._select('Table.select', value_st",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4078:489,error,error,489,https://hail.is,https://github.com/hail-is/hail/issues/4078,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-ccaf3640241f. ### What you did:. ```; ht = hl.import_table('gs://gnomad/annotations/hail-0.2/ht/genomes/score_rankings/gnomad.sites.RF.newStats24.txt.bgz', types={'chrom': hl.tstr}, impute=True, min_partitions=100).cache(); ht.export('gs://gnomad-tmp/genomes_rf.txt.bgz', parallel=True); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; ---------------------------------------------------------------------------; Py4JError Traceback (most recent call last); <ipython-input-17-671d2e9c22c8> in <module>(); 1 #ht = hl.import_table('gs://gnomad/annotations/hail-0.2/ht/genomes/score_rankings/gnomad.sites.RF.newStats24.txt.bgz', types={'chrom': hl.tstr}, impute=True, min_partitions=100).cache(); ----> 2 ht.export('gs://gnomad-tmp/genomes_rf.txt.bgz', parallel=True). /home/hail/hail.zip/hail/table.py in export(self, output, types_file, header, parallel); 994 """"""; 995 ; --> 996 self._jt.export(output, types_file, header, Env.hail().utils.ExportType.getExportType(parallel)); 997 ; 998 def group_by(self, *exprs, **named_exprs) -> 'GroupedTable':. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 186 import pyspark; 187 try:; --> 188 return f(*args, **kwargs); 189 except py4j.protocol.Py4JJavaError as e:; 190 s = e.java_exception.toString(). /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 321 raise Py4JE",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4033:577,error,error,577,https://hail.is,https://github.com/hail-is/hail/issues/4033,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: f7631a0c96cd. ### What you did:. ```; hl.empty_dict(hl.tint32, hl.tint32).get(0).value; ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; Hail version: devel-f7631a0c96cd; Error summary: HailException: array index out of bounds: 0 / 0. IR: (ArrayRef; (ToArray; (ApplyIR dict; (ArrayFilter __uid_191; (MakeArray Array[Tuple[I ...; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3937:371,error,error,371,https://hail.is,https://github.com/hail-is/hail/issues/3937,2,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:. ### What you did:. ### What went wrong (all error messages here, including the full java stack trace):",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2604:298,error,error,298,https://hail.is,https://github.com/hail-is/hail/issues/2604,4,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:. devel-406fc7f6af42. ### What you did:. Calling `export_elasticsearch` without a `config` argument works fine.; ```python; hl.export_elasticsearch(table, ""host"", 9200, ""someindex"", ""sometype"", 1000, config=None); ```. However, attempting to pass `config`, for example:; ```python; es_config = {""es.write.operation"": ""index""}; hl.export_elasticsearch(table, ""host"", 9200, ""someindex"", ""sometype"", 1000, config=es_config); ```; causes the following error:. ### What went wrong (all error messages here, including the full java stack trace):. ```; Traceback (most recent call last):; File ""/tmp/0ba8fc2c770d4b2ba96dc23c50fd6eab/load_clinvar_to_es.py"", line 105, in <module>; verbose=True,; File ""/tmp/0ba8fc2c770d4b2ba96dc23c50fd6eab/hail_v02_scripts.zip/hail_v02_scripts/utils/elasticsearch/client.py"", line 234, in export_table_to_elasticsearch; File ""/home/hail/hail.zip/hail/typecheck/check.py"", line 547, in wrapper; File ""/home/hail/hail.zip/hail/methods/impex.py"", line 1885, in export_elasticsearch; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/home/hail/hail.zip/hail/utils/java.py"", line 188, in deco; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py"", line 323, in get_return_value; py4j.protocol.Py4JError: An error occurred while calling z:is.hail.io.ElasticsearchConnector.export. Trace:; py4j.Py4JException: Method export([class is.hail.table.Table, class java.lang.String, class java.lang.Integer, class java.lang.String, class java.lang.String, class java.lang.Integer, class java.util.HashMap, class java.lang.Boolean]) does not exist; 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); 	at py4j.reflection.ReflectionEngine.getM",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4063:700,error,error,700,https://hail.is,https://github.com/hail-is/hail/issues/4063,2,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:. eb1e04205793. ### What you did:. https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/Class.20file.20too.20large!. Ran filter_intervals with 200k intervals, got Java ""Class file too large!"" error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3942:467,error,error,467,https://hail.is,https://github.com/hail-is/hail/issues/3942,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; .2, Spark 2.2. ### What you did:; Getting an error about a missing header file when I try to run ./gradlew during Hail installation. ### What went wrong (all error messages here, including the full java stack trace):. In file included from Encoder.cpp:1:0:; ../resources/include/hail/Encoder.h:3:17: fatal error: lz4.h: No such file or directory; #include ""lz4.h""; ^; compilation terminated.; make: *** [build/Encoder.o] Error 1. FAILURE: Build failed with an exception.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4651:299,error,error,299,https://hail.is,https://github.com/hail-is/hail/issues/4651,5,"['Error', 'FAILURE', 'error']","['Error', 'FAILURE', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2-48fb15983780. ### What you did:; Plotting a histogram of mt.sample_qc.r_ti_tv, using tutorial data:. import hail as hl; import bokeh. hl.init(); mt = hl.read_matrix_table('data/1kg.mt'); mt = hl.sample_qc(mt); p = hl.plot.histogram(mt.sample_qc.r_ti_tv); bokeh.io.save(p, 'test.html'). ### What went wrong (all error messages here, including the full java stack trace):. The resulting histogram has very high numbers for Frequency labels (y-axis). There are 284 samples in the tutorial dataset, so I expected frequencies to sum up to that, but y-axis labels are 5.000e+4, 1.000e+5, 1.500e+5, implying much higher counts. . I'm new to Hail and I could be plotting the values wrong and misunderstanding this particular plot (what I wanted to plot was the histogram of Ti/Tv ratios of all the samples). I've noticed the same y-axis labels in the GWAS tutorial in the docs (In [29]). . Thank you for your time.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4776:569,error,error,569,https://hail.is,https://github.com/hail-is/hail/issues/4776,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2-a2eaf89baa0c; ### What you did:; Executed first four lines in https://github.com/hail-is/hail/blob/master/hail/python/hail/docs/tutorials/01-genome-wide-association-study.ipynb; ### What went wrong (all error messages here, including the full java stack trace):. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-4-758eefccad3d> in <module>; ----> 1 hl.import_vcf('data/1kg.vcf.bgz').write('data/1kg.mt', overwrite=True). <decorator-gen-1074> in import_vcf(path, force, force_bgz, header_file, min_partitions, drop_samples, call_fields, reference_genome, contig_recoding, array_elements_required, skip_invalid_loci). ~/bin/anaconda3/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561 ; 562 return wrapper. ~/bin/anaconda3/lib/python3.6/site-packages/hail/methods/impex.py in import_vcf(path, force, force_bgz, header_file, min_partitions, drop_samples, call_fields, reference_genome, contig_recoding, array_elements_required, skip_invalid_loci); 1893 skip_invalid_loci,; 1894 force_bgz,; -> 1895 force; 1896 ); 1897 return MatrixTable(jmt). ~/bin/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. ~/bin/anaconda3/lib/python3.6/site-packages/hail/utils/java.py in dec",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4775:461,error,error,461,https://hail.is,https://github.com/hail-is/hail/issues/4775,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2. ### What you did:; Visited top hit for ""hail matrix table"": https://hail.is/docs/0.2/hailpedia/matrix_table.html. ### What went wrong (all error messages here, including the full java stack trace):; 404 / Not Found . ### Solution; We should add a 301 / permanent redirect: https://support.google.com/webmasters/answer/93633?hl=en",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5095:398,error,error,398,https://hail.is,https://github.com/hail-is/hail/issues/5095,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2. ### What you did:; ```; mt = hl.read_matrix_table('gs://...'); mt = mt.filter_cols(mt.used_in_pca_calculation); print(mt.count_cols()); ```; The MatrixTable has a lot of row and column annotations. `mt.used_in_pca_calculation` is a Boolean column annotation. ### What went wrong (all error messages here, including the full java stack trace):; ```; Traceback (most recent call last):; File ""/tmp/8d5cc778-fdc7-4210-a60b-5efd1f67c45f/subset_genotype_pca.py"", line 8, in <module>; print(mt.count_cols()); File ""/home/hail/hail.zip/hail/matrixtable.py"", line 1950, in count_cols; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/home/hail/hail.zip/hail/utils/java.py"", line 206, in deco; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.expr.MatrixValue.filterSamplesKeep(Relational.scala:110); 	at is.hail.expr.MatrixValue.filterCols(Relational.scala:133); 	at is.hail.expr.FilterCols.execute(Relational.scala:333); 	at is.hail.variant.MatrixTable.value$lzycompute(MatrixTable.scala:536); 	at is.hail.variant.MatrixTable.value(MatrixTable.scala:534); 	at is.hail.variant.MatrixTable.x$16$lzycompute(MatrixTable.scala:541); 	at is.hail.variant.MatrixTable.x$16(MatrixTable.scala:541); 	at is.hail.variant.MatrixTable.colValues$lzycompute(MatrixTable.scala:541); 	at is.hail.variant.MatrixTable.colValues(MatrixTable.scala:541); 	at is.hail.variant.MatrixTable.numCols(MatrixTable.scala:2378); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3173:543,error,error,543,https://hail.is,https://github.com/hail-is/hail/issues/3173,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2; ### What you did:. 1. edited build.gradle to it will accept my spark version like this if (sparkVersion == '2.2.0.2.6.3.0-235') {. 2. Then I ran ./gradlew -Dspark.version=2.2.0.2.6.3.0-235 shadowJar archiveZip command. ### What went wrong (all error messages here, including the full java stack trace):; bild fails. ```; [luffy@wp-hdp-ctrl03 hail]$ ./gradlew -Dspark.version=2.2.0.2.6.3.0-235 shadowJar archiveZip --stacktrace; 1f253167d53c; :compileJava UP-TO-DATE; :generateBuildInfo; :nativeLib; tar -xzf libsimdpp-2.0-rc2.tar.gz; g++ -O3 -march=native -g -std=c++11 -Ilibsimdpp-2.0-rc2 -Wall -Werror -fPIC -ggdb -c -o ibs.o ibs.cpp; cc1plus: error: unrecognized command line option ""-std=c++11""; make: *** [ibs.o] Error 1; :nativeLib FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':nativeLib'.; > Process 'command 'make'' finished with non-zero exit value 2. * Try:; Run with --info or --debug option to get more log output. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':nativeLib'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:69); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35); at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:66); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3705:503,error,error,503,https://hail.is,https://github.com/hail-is/hail/issues/3705,3,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2; ### What you did:; Export hail table to elasticsearch; >>> hl.utils.get_movie_lens('data/'); >>> users = hl.read_table('data/users.ht'); >>> hl.export_elasticsearch(users, 'XX.XXX.XXX.XXX', XXXX, 'data', 'variant', 200,config=N; one, verbose=True). ### What went wrong (all error messages here, including the full java stack trace):. Error:; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""</usr/local/lib/python3.6/site-packages/decorator.py:decorator-gen-1118>"", line 2, in export_elasticsearch; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 561, in wrapper; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/methods/impex.py"", line 2104, in export_elasticsearch; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/table.py"", line 101, in __getattr__; AttributeError: Table instance has no attribute '_jt'",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5583:533,error,error,533,https://hail.is,https://github.com/hail-is/hail/issues/5583,2,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2; ### What you did:; users = hl.read_table('data/users.ht'); hl.export_elasticsearch(users, 'XX.XXX.XXX.XXX', 32565, 'users', 'movies', 200,config=None, verbose=True ). ### What went wrong (all error messages here, including the full java stack trace):; Gotten this error even though the elasticsearch IP and port number 32565 is correct. The IP mentioned in the error 192.168.185.157:9200 was not found anywhere in our EMR or elasticsearch cluster. ; >>> hl.export_elasticsearch(users, 'XX.XXX.XXX.XXX', 32565, 'users', 'movies', 200,config=None, verbose=True ); Config Map(es.nodes -> XX.XXX.XXX.XXX, es.port -> 32565, es.batch.size.entries -> 200, es.index.auto.create -> true); [Stage 0:> (0 + 32) / 65]Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""</usr/local/lib/python3.6/site-packages/decorator.py:decorator-gen-1122>"", line 2, in export_elasticsearch; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 561, in wrapper; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/methods/impex.py"", line 2106, in export_elasticsearch; File ""/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 227, in deco; hail.utils.java.FatalError: EsHadoopNoNodesLeftException: Connection error (check network and/or proxy settings)- all nodes failed; tried [[192.168.185.157:9200, 192.168.81.209:9200]] . Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 73, ip-172-31-10-234.ap",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5643:451,error,error,451,https://hail.is,https://github.com/hail-is/hail/issues/5643,3,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 19213e50. ### What you did:; Tried compiling hail with GCC-8.1.0. ### What went wrong (all error messages here, including the full java stack trace):. Full output from `make` invocation:; ```; echo ""make debug""; make debug; echo ""JAVA_HOME is /usr/lib/jvm/java-8-openjdk-amd64""; JAVA_HOME is /usr/lib/jvm/java-8-openjdk-amd64; echo ""CXX is g++""; CXX is g++; g++ --version; g++ (GCC) 8.1.0; Copyright (C) 2018 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. tar -xzf libsimdpp-2.0-rc2.tar.gz; g++ -O3 -march=native -std=c++11 -Ilibsimdpp-2.0-rc2 -Wall -Werror -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux -c -o ibs.o ibs.cpp; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4, simdpp::arch_avx2::expr_empty>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4, simdpp::arch_avx2::expr_empty>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4, simdpp::arch_avx2::expr_empty>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:253:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:345,error,error,345,https://hail.is,https://github.com/hail-is/hail/issues/3955,4,"['echo', 'error']","['echo', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; Hail .2, Spark 2.2. ### What you did:; Error when I run one of several methods of MatrixTable (write(), count_rows(), etc). ### What went wrong (all error messages here, including the full java stack trace):; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 23, ip-172-31-66-74.ec2.internal, executor 1): java.io.InvalidClassException: is.hail.expr.types.TInterval; local class incompatible: stream classdesc serialVersionUID = -1783603148272890463, local class serialVersionUID = 7653437602465004618",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4650:293,Error,Error,293,https://hail.is,https://github.com/hail-is/hail/issues/4650,4,"['Error', 'error', 'failure']","['Error', 'error', 'failure']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; Hail version: devel-eb1e04205793. ### What you did:. Attempt to `export_vcf` with a MT where some `locus` values are `NA`. ### What went wrong (all error messages here, including the full java stack trace):. Bad error message. Didn't really tell me anything except Java Assertion Error. [Stage 2:===========================================> (1709 + 291) / 2000]Traceback (most recent call last):; File ""/tmp/0eccddcf-0d49-4280-8b79-c43e193b044d/vdstovcf.py"", line 12, in <module>; hail.export_vcf(myvds, 'gs://ibd-exomes/v34meta/exomes.ccdg.vcf.bgz'); File ""/home/hail/hail.zip/hail/typecheck/check.py"", line 547, in wrapper; File ""/home/hail/hail.zip/hail/methods/impex.py"", line 422, in export_vcf; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/home/hail/hail.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: AssertionError: assertion failed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4011:402,error,error,402,https://hail.is,https://github.com/hail-is/hail/issues/4011,3,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; Running on Apache Spark version 2.2.0 version devel-cfdbb87; ### What you did:; This error message is related to this filter:; passed=passed.filter_rows((passed.variant_qc.AC>= 10)); Without this filter it runs OK. This file is a merged vcf file from Lumpy. Some sites may have no alternate alleles called (all 0/0 or ./.). ### What went wrong (all error messages here, including the full java stack trace):; [Stage 2:> (0 + 72) / 125]Traceback (most recent call last):; File ""/restricted/projectnb/casa/wgs.hg38/hail/lumpy/models.all.py"", line 80, in <module>; print(""Filtered Passed Rows:"",passed.count_rows()); File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 2072, in count_rows; File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: NegativeArraySizeException: null. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 30 in stage 2.0 failed 4 times, most recent failure: Lost task 30.3 in stage 2.0 (TID 91, scc-q05.scc.bu.edu, executor 9): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.codegen.generated.C4.apply(Unknown Source); 	at is.hail.codegen.generated.C4.apply(Unknown Source); 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:649); 	at is.hail.HailContext$$anon$2.next(HailCon",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:339,error,error,339,https://hail.is,https://github.com/hail-is/hail/issues/3901,2,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; `devel-17d79be1221e`; ### What you did:; ```; import hail as hl. mt = hl.balding_nichols_model(3, 100, 100); hl.export_vcf(mt, 'foo.vcf.bgz'); ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; Traceback (most recent call last):; File ""foo.py"", line 4, in <module>; hl.export_vcf(mt, 'foo.vcf.bgz'); File ""<decorator-gen-878>"", line 2, in export_vcf; File ""/Users/dking/projects/hail/python/hail/typecheck/check.py"", line 546, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/dking/projects/hail/python/hail/methods/impex.py"", line 424, in export_vcf; joption(typ._convert_to_j(metadata))); File ""/Users/dking/borg/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/Users/dking/projects/hail/python/hail/utils/java.py"", line 210, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: in export_vcf: column key must be type 'str', found: [Lis.hail.expr.types.Type;@1e5a1972. Java stack trace:; is.hail.utils.HailException: in export_vcf: column key must be type 'str', found: [Lis.hail.expr.types.Type;@1e5a1972; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.variant.MatrixTable.requireColKeyString(MatrixTable.scala:392); 	at is.hail.io.vcf.ExportVCF$.apply(ExportVCF.scala:202); 	at is.hail.io.vcf.ExportVCF.apply(ExportVCF.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4283:427,error,error,427,https://hail.is,https://github.com/hail-is/hail/issues/4283,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; `devel-3b014af` (off of `0c96180`); ### What you did:; ```; mt = mt.select_entries(GT=hl.cond(hl.is_defined(mt.GT), hl.struct(), hl.null(hl.tstruct()))); ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; TypeError: 'cond' requires the 'consequent' and 'alternate' arguments to have the same type; consequent: type struct{}; alternate: type struct{}; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3103:438,error,error,438,https://hail.is,https://github.com/hail-is/hail/issues/3103,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; devel-45429b1. ### What you did:; ```; x = functions.capture(5); y = -1.2e-7; eval_expr(x * y); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-53-69c81b591366> in <module>(); ----> 1 eval_expr(x * y). <decorator-gen-365> in eval_expr(expression). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in args_to_expr(func, *args); 176 @decorator; 177 def args_to_expr(func, *args):; --> 178 return func(*(to_expr(a) for a in args)); 179; 180. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in eval_expr(expression); 3576 Result of evaluating `expression`.; 3577 """"""; -> 3578 return eval_expr_typed(expression)[0]; 3579; 3580. <decorator-gen-366> in eval_expr_typed(expression). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in args_to_expr(func, *args); 176 @decorator; 177 def args_to_expr(func, *args):; --> 178 return func(*(to_expr(a) for a in args)); 179; 180. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in eval_expr_typed(expression); 3612 if len(expression._joins) > 0:; 3613 raise ExpressionException(""'eval_expr' methods do not support joins or broadcasts""); -> 3614 r, t = Env.hc().eval_expr_typed(expression._ast.to_hql()); 3615 return r, t; 3616. <decorator-gen-1049> in eval_expr_typed(self, expr). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/utils/java.py in handle_py4j(func, *args, **kwargs); 153 raise FatalError('%s\n\nJava st",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2655:380,error,error,380,https://hail.is,https://github.com/hail-is/hail/issues/2655,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; devel-64a1fac. ### What you did:; run split_multi_hts on a VDS with only GT genotype field. ### What went wrong (all error messages here, including the full java stack trace):; ```; is.hail.utils.HailException: Struct has no field `AD'; Available fields:; GT: Call; <input>:4: newad = if (isDefined(g.AD)); ^; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:27); at is.hail.expr.ParserUtils$.error(Parser.scala:33); at is.hail.expr.AST.parseError(AST.scala:255); at is.hail.expr.Select.typecheckThis(AST.scala:333); at is.hail.expr.AST.typecheckThis(AST.scala:246); at is.hail.expr.AST.typecheck(AST.scala:252); at is.hail.expr.AST$$anonfun$typecheck$1.apply(AST.scala:251); at is.hail.expr.AST$$anonfun$typecheck$1.apply(AST.scala:251); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); at is.hail.expr.AST.typecheck(AST.scala:251); at is.hail.expr.Apply.typecheck(AST.scala:663); at is.hail.expr.AST$$anonfun$typecheck$1.apply(AST.scala:251); at is.hail.expr.AST$$anonfun$typecheck$1.apply(AST.scala:251); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); at is.hail.expr.AST.typecheck(AST.scala:251); at is.hail.expr.Let$$anonfun$typecheck$18.apply(AST.scala:850); at is.hail.expr.Let$$anonfun$typecheck$18.apply(AST.scala:849); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2755:371,error,error,371,https://hail.is,https://github.com/hail-is/hail/issues/2755,5,"['Avail', 'Error', 'error']","['Available', 'ErrorHandling', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; devel-6bb4670. ### What you did:; A number of variant QC steps, then a `vds.write`; The error is probably caused by one of the previous steps. If it helps I can comment out earlier parts to narrow down what actually triggers the error. ### What went wrong (all error messages here, including the full java stack trace):; ```; [Stage 6:> (0 + 8) / 5000]; [Stage 6:> (0 + 4) / 5000]; [Stage 6:> (0 + 8) / 5000]Traceback (most recent call last):; File ""/home/hail/hail.zip/hail/utils/java.py"", line 185, in handle_py4j; File ""/home/hail/hail.zip/hail/table.py"", line 1058, in aggregate; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o30335.query.; : org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 6.0 failed 20 times, most recent failure: Lost task 7.19 in stage 6.0 (TID 179, robert1-w-0.c.ccdg-wgs.internal, executor 4): java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.annotations.RegionValueBuilder.endStruct(RegionValueBuilder.scala:109); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2645); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2615); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(Ordered",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3063:342,error,error,342,https://hail.is,https://github.com/hail-is/hail/issues/3063,4,"['down', 'error']","['down', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; devel-92bbe4b. ### What you did:; I used `join` to combine two VDS. Empty sample schema, different variant schema, no overlapping samples, hardcalls. ### What went wrong (all error messages here, including the full java stack trace):; Got an AssertionError:; ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 20 times, most recent failure: Lost task 0.19 in stage 5.0 (TID 677, mycluster3-w-1.c.ccdg-wgs.internal): java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.annotations.Region.loadInt(Region.scala:36); at is.hail.expr.types.TContainer$.loadLength(TContainer.scala:9); at is.hail.expr.types.TContainer.loadLength(TContainer.scala:27); at is.hail.variant.MatrixTable$$anonfun$105$$anonfun$apply$58.apply(MatrixTable.scala:1702); at is.hail.variant.MatrixTable$$anonfun$105$$anonfun$apply$58.apply(MatrixTable.scala:1685); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:661); at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:655); ```. I can make it work by copying the variant annotation from one VDS to the other before calling `join`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2763:429,error,error,429,https://hail.is,https://github.com/hail-is/hail/issues/2763,3,"['error', 'failure']","['error', 'failure']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; devel-c8ca698. ### What you did:; ```; mt_path = ""gs://gnomad-berylc/myoseq/qc/variant_qc/MYOSEQ.variant.qc.filtered.040318.mt""; myoseq = hl.read_matrix_table(mt_path); qc_mt_common = myoseq.filter_rows(myoseq.va_qc.AF > 0.05). qc_mt_common_syn = qc_mt_common.filter_rows(qc_mt_common.worst_csq == ""synonymous""); results_per_gene_common = (qc_mt_common_syn.group_rows_by(qc_mt_common_syn.vep.ensg_with_most_severe_csq).aggregate(n_non_ref=agg.count_where((qc_mt_common_syn.GT.is_non_ref())))); ```. ### What went wrong (all error messages here, including the full java stack trace):; 2018-05-14 23:45:22 Hail: WARN: modified row key, rescanning to compute ordering...; [Stage 9:=====> (163 + 76) / 1526]---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-12-cefffae1d4ba> in <module>(); ----> 1 results_per_gene_common = (qc_mt_common_syn.group_rows_by(qc_mt_common_syn.vep.ensg_with_most_severe_csq).aggregate(n_non_ref=agg.count_where((qc_mt_common_syn.GT.is_non_ref())))). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-c8ca698c6ed5.zip/hail/matrixtable.py in aggregate(self, **named_exprs); 349 rest_of_key = {k: self._row_keys[k] for k in self._row_keys.keys() if k not in self._partition_key}; 350 base = MatrixTable(; --> 351 base._key_rows_by(""GroupedMatrixTable.group_rows_by"", pk, rest_of_key)._jvds.aggregateRowsByKey(; 352 ',\n'.join(strs))); 353 else:. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-c8ca698c6ed5.zip/hail/matrixtable.py in _key_rows_by(self, caller, pk_dict, rest_of_keys_dict); 706 key_fields = dict(pk_dict, **rest_of_keys_dict); 707; --> 708 return self._select_rows(caller, key_struct=hl.struct(**key_fields), pk_si",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3583:778,error,error,778,https://hail.is,https://github.com/hail-is/hail/issues/3583,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; devel. ### What you did:; ```; hc = HailContext(); past_vds = hc.read(args.past); future_vds = hc.read(args.future). bi_past_vds = past_vds.filter_rows(past_vds.v.is_biallelic()); bi_future_vds = future_vds.filter_rows(future_vds.v.is_biallelic()); bi_summary, bi_samples, bi_variants = methods.concordance(bi_past_vds, bi_future_vds); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-08a1543; WARNING: This is an unstable development build.; 2018-01-17 18:32:09 Hail: INFO: Found 729 overlapping samples; Left: 729 total samples; Right: 729 total samples; 2018-01-17 18:32:10 Hail: WARN: converting OrderedRVD => OrderedRDD; [Stage 0:====================================================>(4627 + 1) / 4628]2018-01-17 18:47:04 Hail: INFO: Coerced sorted dataset; 2018-01-17 18:47:04 Hail: WARN: converting OrderedRVD => OrderedRDD; [Stage 1:> (7 + 28) / 4969]Traceback (most recent call last):; File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/concordance.py"", line 38, in <module>; main(args); File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/concordance.py"", line 19, in main; bi_summary, bi_samples, bi_variants = methods.concordance(bi_past_vds, bi_future_vds); File ""<decorator-gen-1304>"", line 2, in concordance; File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/hail-devel-08a15431a0ef.zip/hail/utils/java.py"", line 155, in handle_py4j; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 30 in stage 1.0 failed 20 times, most recent failure: Lost task 30.19 in stage 1.0 (TID 4847, lfdev2-sw-f5w2.c.broad-mpg",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:620,error,error,620,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; hail: `hail-devel-c8ca698`; ### What you did:; ```; hl.init(); ds = hl.import_plink('gs://testdata/1kg_phase1_chr22.bed',; 'gs://testdata/1kg_phase1_chr22.bim',; 'gs://testdata/1kg_phase1_chr22.fam'); ds = hl.sample_qc(ds); ```; Data was downloaded from [here](https://www.cog-genomics.org/plink/1.9/resources).; ; ### What went wrong (all error messages here, including the full java stack trace):; Spark jobs fail at `treeReduce at SampleQC.scala:206`.; Java Error: `java.lang.NegativeArraySizeException`. Full stack:; See file attached.; [error_message.txt](https://github.com/hail-is/hail/files/2003301/error_message.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3585:492,down,downloaded,492,https://hail.is,https://github.com/hail-is/hail/issues/3585,3,"['Error', 'down', 'error']","['Error', 'downloaded', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; version 0.2.4-f1e6526d34b1. ### What you did:; cd hail/hail. ./gradlew -Dspark.version=2.2.1 -Dbreeze.version=0.13.1 -Dpy4j.version=0.10.4 shadowJar archiveZip. ### What went wrong (all error messages here, including the full java stack trace):; In file included from Decoder.cpp:3:0:; ../resources/include/hail/Decoder.h:3:10: fatal error: lz4.h: No such file or directory; #include ""lz4.h""; ^~~~~~~; compilation terminated.; make: *** [build/Decoder.o] Error 1; :nativeLib FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':nativeLib'.; > Process 'command 'make'' finished with non-zero exit value 2. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 36.47 secs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4880:440,error,error,440,https://hail.is,https://github.com/hail-is/hail/issues/4880,4,"['Error', 'FAILURE', 'error']","['Error', 'FAILURE', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; version devel-51961fa0ef80. ### What you did:; ```v7_gene_maximums_kt = hl.read_table(""gs://gnomad-berylc/tx-annotation/hail2/data/GTEx.v7.max_expression_per_gene_per_tissue.031318.kt"")```. ### What went wrong (all error messages here, including the full java stack trace):; ```---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-5-daf7d8347376> in <module>(); ----> 1 v7_gene_maximums_kt = hl.read_table(""gs://gnomad-berylc/tx-annotation/hail2/data/GTEx.v7.max_expression_per_gene_per_tissue.031318.kt""). <decorator-gen-1046> in read_table(path). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561 ; 562 return wrapper. /home/hail/hail.zip/hail/methods/impex.py in read_table(path); 1865 :class:`.Table`; 1866 """"""; -> 1867 return Table(Env.hc()._jhc.readTable(path)); 1868 ; 1869 @typecheck(t=Table,. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 211 except pyspark.sql.utils.CapturedException as e:; 212 raise FatalError('%s\n\nJava stack tr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4325:469,error,error,469,https://hail.is,https://github.com/hail-is/hail/issues/4325,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:devel-abac611. ### What you did: spark-submit --jars build/libs/hail-all-spark.jar --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator --py-files build/distributions/hail-python.zip --num-executors 6 test.py; where test.y is:; import hail as hl; hl.init(master='yarn',default_reference='GRCh38'); hl.import_vcf('/project/casa/vcf.5k/gatk.hc/adsp-5k.hg38.tileDB.recalibrate_SNP.chr22.biallelic.4795samples.g.vcf.bgz').write('/project/casa/vdf.5k/test.vdf'). ### What went wrong (all error messages here, including the full java stack trace):; Error summary: ClassNotFoundException: is.hail.utils.SerializableHadoopConfiguration; Running on Apache Spark version 2.2.0; SparkUI available at http://10.48.225.55:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-abac611; NOTE: This is a beta version. Interfaces may change; during the beta period. We also recommend pulling; the latest changes weekly.; [Stage 1:======================================================>(243 + 1) / 244]2018-04-10 09:30:24 Hail: INFO: Coerced sorted dataset; Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail/test.py"", line 3, in <module>; hl.import_vcf('/project/casa/vcf.5k/gatk.hc/adsp-5k.hg38.tileDB.recalibrate_SNP.chr22.biallelic.4795samples.g.vcf.bgz').write('/project/casa/vdf.5k/test. vdf'); File ""<decorator-gen-546>"", line 2, in write; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 481, in _typecheck; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 1956, in write; File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342:745,error,error,745,https://hail.is,https://github.com/hail-is/hail/issues/3342,3,"['Error', 'avail', 'error']","['Error', 'available', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. Running on Ubuntu 18.04. I had installed openjdk-11-jre-headless instead of openjdk-8-jre-headless. ### Hail version:; 0.2 ; ### What you did:. ### What went wrong (all error messages here, including the full java stack trace):; 2018-12-04 22:13:57 root: ERROR: IllegalArgumentException: null; From java.lang.IllegalArgumentException: null; at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:46); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:443); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:426); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:103); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:426); at org.apache.xbean.asm5.ClassReader.a(Unknown Source); at org.apache.xbean.asm5.ClassReader.b(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.spark.util.Closu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4896:404,error,error,404,https://hail.is,https://github.com/hail-is/hail/issues/4896,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. Tutorials 05 and 08. ### What you did:; (From tutorial 05-tables). import hail as hl; hl.init(); hl.utils.get_movie_lens('data/'); users = hl.read_table('data/users.ht'). ### What went wrong (all error messages here, including the full java stack trace):. Py4JError: An error occurred while calling o1.readTable. Trace:; py4j.Py4JException: Method readTable([class java.lang.String]) does not exist; 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326); 	at py4j.Gateway.invoke(Gateway.java:272); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3989:431,error,error,431,https://hail.is,https://github.com/hail-is/hail/issues/3989,2,['error'],['error']
Availability,"To reproduce:. ```; >>> import hail as hl; >>> hl._set_flags(cpp='true'); >>> mt = hl.read_table('gs://gnomad-public/release/2.1/ht/exomes/gnomad.exomes.r2.1.sites.ht'); >>> mt._force_count(); ```. gets:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x0000000113aae924, pid=29051, tid=0x0000000000004003; #; ```. This is on OSX. Smaller examples work fine with C++ on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4816:223,error,error,223,https://hail.is,https://github.com/hail-is/hail/issues/4816,1,['error'],['error']
Availability,Topics:; https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/key.20not.20found.3A.20GRCh38/near/247317975; https://discuss.hail.is/t/potential-liftover-issue-error-summary-nosuchelementexception-key-not-found-grch37/2154. Stack trace:; ```; java.util.NoSuchElementException: key not found: GRCh37; 	at scala.collection.MapLike.default(MapLike.scala:235); 	at scala.collection.MapLike.default$(MapLike.scala:234); 	at scala.collection.AbstractMap.default(Map.scala:65); 	at scala.collection.mutable.HashMap.apply(HashMap.scala:69); 	at is.hail.variant.ReferenceGenome.getLiftover(ReferenceGenome.scala:412); 	at is.hail.variant.ReferenceGenome.liftoverLocus(ReferenceGenome.scala:423); 	at __C700Compiled.applyregion0_8(Emit.scala); 	at __C700Compiled.apply(Emit.scala); 	at is.hail.expr.ir.TableMapRows.$anonfun$execute$43(TableIR.scala:1936); ```. See Lindo's comment in the Zulip thread to replicate (hopefully),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10722:182,error,error-summary-nosuchelementexception-key-not-found-,182,https://hail.is,https://github.com/hail-is/hail/issues/10722,1,['error'],['error-summary-nosuchelementexception-key-not-found-']
Availability,"Traceback (most recent call last):; File ""foo.py"", line 4, in <module>; hl.export_vcf(mt, 'foo.vcf.bgz'); File ""<decorator-gen-878>"", line 2, in export_vcf; File ""/Users/dking/projects/hail/python/hail/typecheck/check.py"", line 546, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/dking/projects/hail/python/hail/methods/impex.py"", line 424, in export_vcf; joption(typ._convert_to_j(metadata))); File ""/Users/dking/borg/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/Users/dking/projects/hail/python/hail/utils/java.py"", line 210, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: in export_vcf: column key must be type 'str', found: [Lis.hail.expr.types.Type;@1e5a1972. Java stack trace:; is.hail.utils.HailException: in export_vcf: column key must be type 'str', found: [Lis.hail.expr.types.Type;@1e5a1972; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.variant.MatrixTable.requireColKeyString(MatrixTable.scala:392); 	at is.hail.io.vcf.ExportVCF$.apply(ExportVCF.scala:202); 	at is.hail.io.vcf.ExportVCF.apply(ExportVCF.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail versi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4283:1482,Error,ErrorHandling,1482,https://hail.is,https://github.com/hail-is/hail/issues/4283,1,['Error'],['ErrorHandling']
Availability,Treat them analogously to ref. I think there's potential for an assertion failure now.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/539:74,failure,failure,74,https://hail.is,https://github.com/hail-is/hail/issues/539,1,['failure'],['failure']
Availability,Treat warnings as errors.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/498:18,error,errors,18,https://hail.is,https://github.com/hail-is/hail/pull/498,1,['error'],['errors']
Availability,"Tried running ; `hail read -i file:///mnt/lustre/bavila/denovo/myrioux3.vep.vds exportvcf -o file:///mnt/lustre/bavila/denovo/myrioux3.vep.vcf`. got the following; ```; hail: info: running: read -i file:///mnt/lustre/bavila/denovo/myrioux3.vep.vds; [Stage 1:======================================================>(255 + 1) / 256]hail: info: running: exportvcf -o file:///mnt/lustre/bavila/denovo/myrioux3.vep.vcf; [Stage 2:=====> (2117 + 256) / 19042]hail: exportvcf: caught exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2137 in stage 2.0 failed 4 times, most recent failure: Lost task 2137.3 in stage 2.0 (TID 3028, nid00013.urika.com): java.lang.IllegalArgumentException: Self-suppression not permitted; 	at java.lang.Throwable.addSuppressed(Throwable.java:1043); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1219); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1116); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1095); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:88); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); ```. Full error and log below:. [error.txt](https://github.com/hail-is/hail/files/652656/error.txt); [hail.log.txt](https://github.com/hail-is/hail/files/652665/hail.log.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1185:544,failure,failure,544,https://hail.is,https://github.com/hail-is/hail/issues/1185,5,"['error', 'failure']","['error', 'failure']"
Availability,"Tried to load 1kg public VCF using newest version of hail:; ```; tgp = hl.import_vcf('gs://genomics-public-data/1000-genomes-phase-3/vcf-20150220/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf'); tgp.describe(); tgp.rows().show(); ```; Getting:; ```; hail.utils.java.FatalError: NoSuchElementException: key not found: GT. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 20 times, most recent failure: Lost task 0.19 in stage 2.0 (TID 104, pca-w-1.c.daly-ibd.internal, executor 2): is.hail.utils.HailException: ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf: caught java.util.NoSuchElementException: key not found: GT; offending line: 22	16050075	rs587697622	A	G	100	PASS	AC=1;AF=0.000199681;AN=...; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.utils.Context.wrapException(Context.scala:23); 	at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:761); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); 	at is.hail.rvd.OrderedRVD$$anon$2.hasNext(OrderedRVD.scala:413); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:815); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:815); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:389); 	at scal",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3467:424,failure,failure,424,https://hail.is,https://github.com/hail-is/hail/issues/3467,4,"['Error', 'failure']","['ErrorHandling', 'failure']"
Availability,"Tried to run this code:. `vds.annotate_samples_expr('sa.variant1 = gs.filter(g => v == Variant(""1:55505447:C:T"")).collect()[0].gt')`. But the variant was not in the dataset at all, so got an out of bounds error, but it looked like this:. ```; [Stage 2:======================================================>(278 + 1) / 279]// class version 52.0 (52); // access flags 0x1; public class is/hail/codegen/generated/C0 implements java/io/Serializable scala/Function2 {. // access flags 0x1; public apply(Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;; L0; ALOAD 1; CHECKCAST [Ljava/lang/Object;; LDC 0; AALOAD; INVOKEINTERFACE scala/Function0.apply ()Ljava/lang/Object;; CHECKCAST scala/collection/IndexedSeq; ASTORE 3; ALOAD 3; IFNULL L1; NEW java/lang/Integer; DUP; LDC 0; INVOKESPECIAL java/lang/Integer.<init> (I)V; ASTORE 4; ALOAD 4; IFNULL L2; ALOAD 4; INVOKEVIRTUAL java/lang/Number.intValue ()I; ISTORE 5; ALOAD 3; ILOAD 5; LDC 0; IF_ICMPGE L3; GOTO L4; L4; FRAME FULL [is/hail/codegen/generated/C0 java/lang/Object java/lang/Object scala/collection/IndexedSeq java/lang/Integer I] [scala/collection/IndexedSeq]; ILOAD 5; ALOAD 3; INVOKEINTERFACE scala/collection/IndexedSeq.size ()I; IADD; GOTO L5; L3; FRAME SAME1 scala/collection/IndexedSeq; ILOAD 5; L5; FRAME FULL [is/hail/codegen/generated/C0 java/lang/Object java/lang/Object scala/collection/IndexedSeq java/lang/Integer I] [scala/collection/IndexedSeq I]; INVOKEINTERFACE scala/collection/IndexedSeq.apply (I)Ljava/lang/Object;; GOTO L6; L2; FRAME CHOP 1; ACONST_NULL; L6; FRAME SAME1 java/lang/Object; GOTO L7; L1; FRAME CHOP 1; ACONST_NULL; L7; FRAME SAME1 java/lang/Object; CHECKCAST is/hail/variant/Genotype; ASTORE 6; ALOAD 6; IFNULL L8; ALOAD 6; INVOKEVIRTUAL is/hail/variant/Genotype.unboxedGT ()I; ISTORE 7; ILOAD 7; LDC -1; IF_ICMPEQ L9; GOTO L10; L10; FRAME FULL [is/hail/codegen/generated/C0 java/lang/Object java/lang/Object scala/collection/IndexedSeq T T is/hail/variant/Genotype I] []; NEW java/lang/Integer; DUP; I",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1705:205,error,error,205,https://hail.is,https://github.com/hail-is/hail/issues/1705,1,['error'],['error']
Availability,"Try to ""read"" a vcf, and get this error:. ```; running: read -i chr22.vcf.bgz; Exception in thread ""main"" java.lang.IllegalArgumentException: requirement failed; at scala.Predef$.require(Predef.scala:221); at org.broadinstitute.hail.variant.VariantSampleMatrix$.read(VariantSampleMatrix.scala:23); at org.broadinstitute.hail.driver.Read$.run(Read.scala:21); at org.broadinstitute.hail.driver.Read$.run(Read.scala:6); at org.broadinstitute.hail.driver.Command.run(Command.scala:59); at org.broadinstitute.hail.driver.Main$$anonfun$main$2$$anonfun$4.apply(Main.scala:182); ...; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/163:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/issues/163,1,['error'],['error']
Availability,"Try to give the user information about the failure. A follow up to this is to give a mode to ignore the error, and filter the variant.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6877:43,failure,failure,43,https://hail.is,https://github.com/hail-is/hail/pull/6877,2,"['error', 'failure']","['error', 'failure']"
Availability,"Trying to annotate a table with a reference genome creates tons of temp files, and ultimately fails with errors like:; ```; Mkdirs failed to create file:/tmp/hail.aHapwOHwB9LA (exists=false, cwd=file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1550247966765_0004/container_1550247966765_0004_02_000051). at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:441); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:929); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:910); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:807); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:796); at is.hail.utils.richUtils.RichHadoopConfiguration$.is$hail$utils$richUtils$RichHadoopConfiguration$$create$extension(RichHadoopConfiguration.scala:24); at is.hail.utils.richUtils.RichHadoopConfiguration$.writeFile$extension(RichHadoopConfiguration.scala:296); at is.hail.io.reference.FASTAReader$$anonfun$setup$1.apply(FASTAReader.scala:45); at is.hail.io.reference.FASTAReader$$anonfun$setup$1.apply(FASTAReader.scala:44); at is.hail.utils.package$.using(package.scala:587); at is.hail.utils.richUtils.RichHadoopConfiguration$.readFile$extension(RichHadoopConfiguration.scala:293); at is.hail.io.reference.FASTAReader$.setup(FASTAReader.scala:44); at is.hail.io.reference.FASTAReader$$anonfun$getLocalFastaFileName$1.apply(FASTAReader.scala:30); at is.hail.io.reference.FASTAReader$$anonfun$getLocalFastaFileName$1.apply(FASTAReader.scala:30); at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:901); at is.hail.io.reference.FASTAReader$.getLocalFastaFileName(FASTAReader.scala:30); at is.hail.io.reference.SerializableReferenceSequenceFile.value$lzycompute(FASTAReader.scala:18); at is.hail.io.reference.SerializableReferenceSequenceFile.value(FASTAReader.scala:17); at is.hail.io.reference.FASTAReader.<init>(FASTAReader.scala:77); at is.hai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5371:105,error,errors,105,https://hail.is,https://github.com/hail-is/hail/issues/5371,1,['error'],['errors']
Availability,Trying to build on ubuntu ; Welcome to Ubuntu Xenial Xerus (development branch) (GNU/Linux 4.4.0-16-generic x86_64). This tree builds fine on mac using grade installDist. ; On ubuntu it gives the below failure message. We wondered if it might have something to do with case sensitivity issues in file/path naming (mac maintaining case but being case-insensitive). Let me know if you would like more info. ; :compileJava UP-TO-DATE; :compileScala FAILED. FAILURE: Build failed with an exception.; - What went wrong:; A problem was found with the configuration of task ':compileScala'.; > No value has been specified for property 'zincClasspath'.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/275:202,failure,failure,202,https://hail.is,https://github.com/hail-is/hail/issues/275,2,"['FAILURE', 'failure']","['FAILURE', 'failure']"
Availability,Trying to construct a genotype stream fails with assertion error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1976:59,error,error,59,https://hail.is,https://github.com/hail-is/hail/issues/1976,1,['error'],['error']
Availability,"Trying to make it more ergonomic to simply do `python3 -m pytest batch/test/test_batch.py::test_job` (now works without any extra environment variables or configuration). This involved the following changes:; - Deleted of some env vars that are no longer used / can be easily consolidated into existing ones; - Gave defaults to those testing env variables for which there are reasonable defaults. E.g. `DOCKER_ROOT_IMAGE` and `HAIL_GENETICS_HAIL_IMAGE`.; - Pushed other environment variables for which there are not reasonable defaults into the tests that need them. If you run a test that requires `HAIL_CLOUD`, you'll still get an error that that env variable is unset and you should set it. But, if you just want to run a single test that doesn't need `HAIL_CLOUD` it won't get in the way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12862:633,error,error,633,https://hail.is,https://github.com/hail-is/hail/pull/12862,1,['error'],['error']
Availability,"Trying to run a bunch of 201 aggregators + uniroot on a custom branch (https://github.com/konradjk/hail/tree/freq_filter), and getting:; ```; Traceback (most recent call last):; File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/generate_frequency_data.py"", line 141, in <module>; try_slack(args.slack_channel, main, args); File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/pyscripts_CSD0RS.zip/gnomad_hail/utils/slack.py"", line 112, in try_slack; File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/pyscripts_CSD0RS.zip/gnomad_hail/utils/slack.py"", line 95, in try_slack; File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/generate_frequency_data.py"", line 121, in main; mt, sample_table = generate_frequency_data(mt, args.subpop, args.downsampling, args.genomes); File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/generate_frequency_data.py"", line 102, in generate_frequency_data; mt = mt.annotate_rows(freq=frequency_expression); File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/hail-1e2e8c7e8.zip/hail/matrixtable.py"", line 905, in annotate_rows; File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/hail-1e2e8c7e8.zip/hail/typecheck/check.py"", line 547, in wrapper; File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/hail-1e2e8c7e8.zip/hail/matrixtable.py"", line 2893, in _select_rows; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/hail-1e2e8c7e8.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: RuntimeException: Method code too large!. Java stack trace:; java.lang.RuntimeException: Method code too large!; 	at is.hail.relocated.org.objectweb.asm.MethodWriter.a(Unknown Source); 	at is.hail.relocated.org.objectweb.asm.ClassWriter.toByteArray(Unknown Source); 	at is.hail.asm4s.FunctionBuilder.classAsBytes(FunctionBuilder.scala:306); 	at is.hail.asm4s.FunctionBuilder.result(FunctionBuilder.scala:340); 	at is.hail.expr.CM.runWithDelayedValues(CM.scala:80); 	at is.hail.expr.Parser$.is$hail$expr$Parser$$evalNoTypeCheck(Parser.s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3746:709,down,downsampling,709,https://hail.is,https://github.com/hail-is/hail/issues/3746,1,['down'],['downsampling']
Availability,Trying to slowly add more reliability to the `hailctl` CLI. This adds some very basic tests for the `hailctl batch billing` subcommand that mocks the `BatchClient` so it's just testing that command line parsing and yaml dumping don't break. Most of the other noise in this PR is a refactor. I moved `hail/python/test/hailtop/hailctl/config/conftest.py` up a level so I could reuse its `CLIRunner` fixture across all `hailctl` test modules. That fixture sets a new config directory per test so if you use it in a test the test won't accidentally use or modify the user's actual hailctl config.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13490:26,reliab,reliability,26,https://hail.is,https://github.com/hail-is/hail/pull/13490,1,['reliab'],['reliability']
Availability,"Turns out we didn't support `--dry-run` on `dataproc connect`. I'm not totally satisfied with this, as the command that gets printed out isn't runnable, because it will lack quotes around the `--ssh-flag=-D 1000` part. I tried adding the quotes into the command, thinking it would work but just be redundant, but I couldn't get it to work. I suppose I could have the printing logic go through the list and replace that bit with a quoted version. Let me know what you think.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7128:298,redundant,redundant,298,https://hail.is,https://github.com/hail-is/hail/pull/7128,1,['redundant'],['redundant']
Availability,Two big changes. Catch any errors and release the semaphore. Restart failed workers in the concurrent worker pool.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6804:27,error,errors,27,https://hail.is,https://github.com/hail-is/hail/pull/6804,1,['error'],['errors']
Availability,Two high-level comments:; - Here is the default documentation:. https://ci.hail.is/repository/download/HailSourceCode_HailCi/846:id/docs/index.html#exportaggregate. Some documentation of the output format and maybe and example or two (with and without `--by-matrix`) would be awesome.; - We need at least some testing. I think a simple aggregation on a small file that you verify by hand would be sufficient. I'll look over the code and let you know if I have additional comments.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/837#issuecomment-249244766:94,down,download,94,https://hail.is,https://github.com/hail-is/hail/pull/837#issuecomment-249244766,2,['down'],['download']
Availability,"Two of your comments deal with my elimination of redundant sources of information, so I'll address both here. I'm basically thinking of us when we have to debug this system. It's confusing if there's two sources of truth or if we're manually calling `deploy.sh` to isolate issues with that from issues with gradle, I don't want to have two separate knobs to spin. If they accidentally get out of sync that's gonna be double confusing (imagine a PyPI version that disagrees with hail's internal version). How about we put these two versions into two single-line, plain text files and have _generated... load the files to initialize the variables?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4812#issuecomment-440805512:49,redundant,redundant,49,https://hail.is,https://github.com/hail-is/hail/pull/4812#issuecomment-440805512,1,['redundant'],['redundant']
Availability,Two rare events is notable and probably indicates an error anyway. Let us prefer; to get information as soon as possible.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11769:53,error,error,53,https://hail.is,https://github.com/hail-is/hail/pull/11769,1,['error'],['error']
Availability,TypeCheck bottom-up instead of top-down.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6002:35,down,down,35,https://hail.is,https://github.com/hail-is/hail/pull/6002,1,['down'],['down']
Availability,"Ugh, and in Azure, the batch-driver was too slow coming alive and it failed the build. Retried.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11622#issuecomment-1076608471:56,alive,alive,56,https://hail.is,https://github.com/hail-is/hail/pull/11622#issuecomment-1076608471,1,['alive'],['alive']
Availability,"Ugh, discovered a problem with race conditions surrounding the `test.cpp` build path. Can cause failures with a naked `make -jN test` on a clean directory. Fixing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5354#issuecomment-464188754:96,failure,failures,96,https://hail.is,https://github.com/hail-is/hail/pull/5354#issuecomment-464188754,1,['failure'],['failures']
Availability,"Ugh, it is failing because movie lens download is timing out again.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5082#issuecomment-451988168:38,down,download,38,https://hail.is,https://github.com/hail-is/hail/pull/5082#issuecomment-451988168,1,['down'],['download']
Availability,"Unassigning until I fix errors in CI, apologies for the noise",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13745#issuecomment-1739787547:24,error,errors,24,https://hail.is,https://github.com/hail-is/hail/pull/13745#issuecomment-1739787547,1,['error'],['errors']
Availability,"Unclear what changed. GKE release history doesn't specify when Docker was upgraded to 19.03.1. We think Notebook worked in the past. Anyway, the fix is to never specify ""m"" (lowercase m) as the size modifier for a Kubernetes memory limit. Docker silently drops the ""m"" which means the limit is set to a few thousand bytes (e.g. 3500m becomes 3.5kB). The resulting error message is this:; ```; Failed create pod sandbox: rpc error: code = Unknown desc = failed to start sandbox container for pod ""notebook-worker-9l2wq"": Error response from daemon: OCI runtime create failed: container_linux.go:345: starting container process caused ""process_linux.go:303: getting the final child's pid from pipe caused \""read init-p: connection reset by peer\"""": unknown; ```; Which you can see in `kubectl describe pod`:; ```; Warning FailedCreatePodSandBox 73s (x13 over 85s) kubelet, gke-vdc-non-preemptible-pool-5-80798769-kp8n Failed create pod sandbox: rpc error: code = Unknown desc = failed to start sandbox container for pod ""notebook-worker-9l2wq"": Error response from daemon: OCI runtime create failed: container_linux.go:345: starting container process caused ""process_linux.go:303: getting the final child's pid from pipe caused \""read init-p: connection reset by peer\"""": unknown; Normal SandboxChanged 73s (x12 over 84s) kubelet, gke-vdc-non-preemptible-pool-5-80798769-kp8n Pod sandbox changed, it will be killed and re-created.; ```. We narrowed down to this error by trial and error of removing and adding lines of the YAML file. https://github.com/kubernetes/kubernetes/issues/79950. The fix is to use `Mi` not `m`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8165:364,error,error,364,https://hail.is,https://github.com/hail-is/hail/issues/8165,8,"['Error', 'down', 'error']","['Error', 'down', 'error']"
Availability,"Unclear what's wrong, but this k8s container got stuck in container creating. ```; (base) dking@wmb16-359 # k describe pods -n test job-4-7xqf9; Name: job-4-7xqf9; Namespace: test; Node: gke-vdc-non-preemptible-pool-0106a51b-zsmg/10.128.0.5; Start Time: Thu, 17 Jan 2019 16:31:42 -0500; Labels: app=batch-job; hail.is/batch-instance=21706daa42404f5489a53bb5ad22a068; uuid=b4fbcb0d4e2045e8bc4aea6b012ffad6; Annotations: <none>; Status: Pending; IP: ; Containers:; default:; Container ID: ; Image: alpine; Image ID: ; Port: <none>; Host Port: <none>; Command:; sleep; 1; State: Waiting; Reason: ContainerCreating; Ready: False; Restart Count: 0; Environment:; POD_IP: (v1:status.podIP); POD_NAME: job-4-7xqf9 (v1:metadata.name); Mounts:; /var/run/secrets/kubernetes.io/serviceaccount from default-token-85kwr (ro); Conditions:; Type Status; Initialized True ; Ready False ; PodScheduled True ; Volumes:; default-token-85kwr:; Type: Secret (a volume populated by a Secret); SecretName: default-token-85kwr; Optional: false; QoS Class: BestEffort; Node-Selectors: <none>; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s; node.kubernetes.io/unreachable:NoExecute for 300s; Events:; Type Reason Age From Message; ---- ------ ---- ---- -------; Normal SandboxChanged 11m (x171 over 1h) kubelet, gke-vdc-non-preemptible-pool-0106a51b-zsmg Pod sandbox changed, it will be killed and re-created.; Warning FailedSync 6m kubelet, gke-vdc-non-preemptible-pool-0106a51b-zsmg error determining status: rpc error: code = Unknown desc = Error: No such container: 741291eb67b9026c0fe4ac52d1f5a553ea420f07f5a7d7368c9dba93e707a079; Warning FailedCreatePodSandBox 1m (x203 over 1h) kubelet, gke-vdc-non-preemptible-pool-0106a51b-zsmg Failed create pod sandbox: rpc error: code = Unknown desc = NetworkPlugin kubenet failed to set up pod ""job-4-7xqf9_test"" network: Error adding container to network: failed to allocate for range 0: no IP addresses available in range set: 10.32.3.1-10.32.3.254; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5168:1068,Toler,Tolerations,1068,https://hail.is,https://github.com/hail-is/hail/issues/5168,7,"['Error', 'Toler', 'avail', 'error']","['Error', 'Tolerations', 'available', 'error']"
Availability,"Unexcludes the `hail/` subdirectory from the files the `ruff` linter (not to be confused with the `ruff` formatter) looks at, and fixes the errors it raises.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14150:140,error,errors,140,https://hail.is,https://github.com/hail-is/hail/pull/14150,1,['error'],['errors']
Availability,"Unfortunately, I can't figure out the verification errors.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9604#issuecomment-713144112:51,error,errors,51,https://hail.is,https://github.com/hail-is/hail/pull/9604#issuecomment-713144112,1,['error'],['errors']
Availability,"Unfortunately, the CI results are private to protect against inadvertent secret leaks. It looks like the docs are failing. The `Locus` should be `hl.Locus`. I suspect the test will pass with that change. ```; =================================== FAILURES ===================================; __________ [doctest] hail.expr.functions.cochran_mantel_haenszel_test __________; 834 Examples; 835 --------; 836 >>> a = [56, 61, 73, 71]; 837 >>> b = [69, 257, 65, 48]; 838 >>> c = [40, 57, 71, 55]; 839 >>> d = [77, 301, 79, 48]; 840 >>> hl.eval(hl.cochran_mantel_haenszel_test(a, b, c, d)); 841 Struct(test_statistic=5.0496881823306765, p_value=0.024630370456863417); 842 ; 843 >>> mt = ds.filter_rows(mt.locus == Locus(20, 10633237)); UNEXPECTED EXCEPTION: NameError(""name 'Locus' is not defined""); Traceback (most recent call last):; File ""/usr/lib/python3.9/doctest.py"", line 1334, in __run; exec(compile(example.source, filename, ""single"",; File ""<doctest hail.expr.functions.cochran_mantel_haenszel_test[5]>"", line 1, in <module>; NameError: name 'Locus' is not defined; /usr/local/lib/python3.9/dist-packages/hail/expr/functions.py:843: UnexpectedException; 835 --------; 836 >>> a = [56, 61, 73, 71]; 837 >>> b = [69, 257, 65, 48]; 838 >>> c = [40, 57, 71, 55]; 839 >>> d = [77, 301, 79, 48]; 840 >>> hl.eval(hl.cochran_mantel_haenszel_test(a, b, c, d)); 841 Struct(test_statistic=5.0496881823306765, p_value=0.024630370456863417); 842 ; 843 >>> mt = ds.filter_rows(mt.locus == Locus(20, 10633237)); 844 >>> mt.count_rows(); Expected:; 1; Got:; 9. /usr/local/lib/python3.9/dist-packages/hail/expr/functions.py:844: DocTestFailure; 845 1; 846 >>> a, b, c, d = mt.aggregate_entries(; 847 ... hl.tuple([; 848 ... hl.array([hl.agg.count_where(mt.GT.is_non_ref() & mt.pheno.is_case & mt.pheno.is_female), hl.agg.count_where(mt.GT.is_non_ref() & mt.pheno.is_case & ~mt.pheno.is_female)]),; 849 ... hl.array([hl.agg.count_where(mt.GT.is_non_ref() & ~mt.pheno.is_case & mt.pheno.is_female), hl.agg.count_wher",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14255#issuecomment-1961918395:245,FAILURE,FAILURES,245,https://hail.is,https://github.com/hail-is/hail/pull/14255#issuecomment-1961918395,1,['FAILURE'],['FAILURES']
Availability,Unkey the cols seems wrong. It makes the contract of `entries()` much more complicated. I guess a warning or error that makes the user decide between manually unkeying the columns or shuffling would be best? (I guess that means implementing a shuffling option for small data.),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4646#issuecomment-433473971:109,error,error,109,https://hail.is,https://github.com/hail-is/hail/issues/4646#issuecomment-433473971,1,['error'],['error']
Availability,Update ErrorMessages.md,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1212:7,Error,ErrorMessages,7,https://hail.is,https://github.com/hail-is/hail/pull/1212,1,['Error'],['ErrorMessages']
Availability,Update FAQ ErrorMessages.md on changing SPARK_LOCAL_DIRS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1027:11,Error,ErrorMessages,11,https://hail.is,https://github.com/hail-is/hail/pull/1027,1,['Error'],['ErrorMessages']
Availability,"Update on this. I am getting the same errors when doing `group_cols_by` for another aggregation method. This is a matrixtable with 2 variants and 245k samples. ```python; ancestry_table = hl.Table.from_pandas(ancestry.astype({""person_id"":str}), key='person_id'); mt = mt.annotate_cols(ancestry = ancestry_table[mt.s].ancestry); mt_gtstats_vals = mt.group_cols_by(mt.ancestry).aggregate(gt_stats_ancestry=hl.agg.call_stats(mt.GT, mt.alleles)); mt_gtstats_vals.gt_stats_ancestry.AF.export(af_ancestry_bucket); ```. ```; [Stage 23:> (0 + 1) / 1]; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); /tmp/ipykernel_231/1465831350.py in <module>; ----> 1 mt_gtstats_vals.gt_stats_ancestry.AF.export(af_ancestry_bucket). <decorator-gen-634> in export(self, path, delimiter, missing, header). /opt/conda/lib/python3.7/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 575 def wrapper(__original_func, *args, **kwargs):; 576 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 577 return __original_func(*args_, **kwargs_); 578 ; 579 return wrapper. /opt/conda/lib/python3.7/site-packages/hail/expr/expressions/base_expression.py in export(self, path, delimiter, missing, header); 1068 **{output_col_name: hl.delimit(column_names, delimiter)}); 1069 file_contents = header_table.union(file_contents); -> 1070 file_contents.export(path, delimiter=delimiter, header=False); 1071 ; 1072 @typecheck_method(n=int, _localize=bool). <decorator-gen-1190> in export(self, output, types_file, header, parallel, delimiter). /opt/conda/lib/python3.7/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 575 def wrapper(__original_func, *args, **kwargs):; 576 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 577 return __original_func(*args_, **kwargs_); 578 ; 579 return wrapper. /opt/conda/lib/py",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619:38,error,errors,38,https://hail.is,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619,1,['error'],['errors']
Availability,"Update the following docs:; annotatevariants_expr.md; HailExpressionLanguage.md; splitmulti.md, these lines:. ```; 108 filtervariants expr -c 'va.info.AC[va.aIndex] < 10' --remove; 118 annotatevariants expr -c 'va.info.AC = va.info.AC[va.aIndex]'; ```. Update error message in AST. ```; 1905 Hint: For accessing `A'-numbered info fields in split variants, `va.info.field[va.aIndex]' is correct"""""".stripMargin); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/663#issuecomment-242074915:260,error,error,260,https://hail.is,https://github.com/hail-is/hail/pull/663#issuecomment-242074915,1,['error'],['error']
Availability,"Update to this, tried running the same script with the bgen file as v1.2 instead (was v1.1 in initial posted issue), but it gives the same issue/stack trace:. ```; SparkException: Job aborted due to stage failure: Task 1.0 in stage 5.0 (TID 2681) had a not serializable result: is.hail.io.bgen.Bgen12GenotypeIterator; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.Bgen12GenotypeIterator, value: Bgen12GenotypeIterator(0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apac",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:205,failure,failure,205,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783,1,['failure'],['failure']
Availability,"Updated db.py to allow user to specify region as shown below. `db = hl.experimental.DB(region='us')`; `mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics')`. Data will be accessed from the requester pays bucket in the region specified by the user, available regions are `'us'` and `'eu'`. Modified the following to include region parameter:; - `DB` class ; - `Dataset.from_name_and_json()`. Added method `DatasetVersion.insert_region()` to replace `'{region}'` in `DatasetVersion.url` instance variable with the specified region.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9410:246,avail,available,246,https://hail.is,https://github.com/hail-is/hail/pull/9410,1,['avail'],['available']
Availability,"Updated db.py to require user to specify region as shown below, so that data will be accessed from the requester pays bucket in the region specified by the user, available regions are `'us'` and `'eu'`. . `db = hl.experimental.DB(region='us')`; `mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics')`. Entries in the `annotation_db.json` file were modified to the following format:. ```; ""dataset_name"": { ""description"": ""some description here"",; ""key_properties"": [],; ""url"": ""https://www.someurlhere.com"",; ""versions"": [{""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""one_version""},; {""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""another_version""}]}; ```. The `annotation_db.json` file is now used by the `load_dataset()` function in `datasets.py` as well, any dataset in the JSON file should now be able to be loaded this way. Made changes to the following:; - `DB` class now requires a `region` parameter.; - `Dataset.from_name_and_json()` has had a `custom_config` parameter added that indicates whether or not the user has supplied their own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and rai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9496:162,avail,available,162,https://hail.is,https://github.com/hail-is/hail/pull/9496,1,['avail'],['available']
Availability,"Updated the datasets/annotation_db.json config file with datasets currently available in bucket at gs://hail-datasets-hail-data, also updated docs to reflect the datasets available via the `load_datasets()` function.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9331:76,avail,available,76,https://hail.is,https://github.com/hail-is/hail/pull/9331,2,['avail'],['available']
Availability,"Updates needed for the following:. ```sh; > Task :compileTestScala; Pruning sources from previous analysis, due to incompatible CompileSetup.; /io/repo/hail/src/test/scala/is/hail/annotations/ScalaToRegionValue.scala:9: type mismatch;; found : is.hail.expr.types.physical.PType; required: is.hail.expr.types.virtual.Type; rvb.addAnnotation(t, a); ^; /io/repo/hail/src/test/scala/is/hail/annotations/StagedRegionValueSuite.scala:487: type mismatch;; found : is.hail.expr.types.physical.PType; required: is.hail.expr.types.physical.PBaseStruct; SafeRow(t, region, copyOff); ^; /io/repo/hail/src/test/scala/is/hail/expr/ir/Aggregators2Suite.scala:46: type mismatch;; found : is.hail.expr.types.virtual.TStruct; required: is.hail.expr.types.physical.PType; val argOff = ScalaToRegionValue(region, argT, argVs); ^; /io/repo/hail/src/test/scala/is/hail/expr/ir/Aggregators2Suite.scala:177: type mismatch;; found : is.hail.expr.types.virtual.Type; required: is.hail.expr.types.physical.PType; val voff = ScalaToRegionValue(region, stream.typ, lit); ^; /io/repo/hail/src/test/scala/is/hail/nativecode/RegionValueIteratorSuite.scala:73: type mismatch;; found : is.hail.expr.types.physical.PTuple; required: is.hail.expr.types.virtual.Type; rvb.addAnnotation(t, r); ^; /io/repo/hail/src/test/scala/is/hail/nativecode/RegionValueIteratorSuite.scala:133: type mismatch;; found : is.hail.expr.types.physical.PTuple; required: is.hail.expr.types.virtual.Type; Error occurred in an application involving default arguments.; rvb.addAnnotation(t, r); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6711#issuecomment-515048174:1446,Error,Error,1446,https://hail.is,https://github.com/hail-is/hail/pull/6711#issuecomment-515048174,1,['Error'],['Error']
Availability,"Updates the requirements on [avro](https://github.com/apache/avro) to permit the latest version.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/apache/avro/releases"">avro's releases</a>.</em></p>; <blockquote>; <h2>Apache Avro 1.11.0</h2>; <p>The Apache Avro community is pleased to announce the release of Avro 1.11.0!</p>; <p>All signed release artifacts, signatures and verification instructions can; be found here: <a href=""https://avro.apache.org/releases.html"">https://avro.apache.org/releases.html</a></p>; <p>This release includes 120 Jira issues, including some interesting features:</p>; <p>Specification: AVRO-3212 Support documentation tags for FIXED types; C#: AVRO-2961 Support dotnet framework 5.0; C#: AVRO-3225 Prevent memory errors when deserializing untrusted data; C++: AVRO-2923 Logical type corrections; Java: AVRO-2863 Support Avro core on android; Javascript: AVRO-3131 Drop support for node.js 10; Perl: AVRO-3190 Fix error when reading from EOF; Python: AVRO-2906 Improved performance validating deep record data; Python: AVRO-2914 Drop Python 2 support; Python: AVRO-3004 Drop Python 3.5 support; Ruby: AVRO-3108 Drop Ruby 2.5 support</p>; <p>For the first time, the 1.11.0 release includes experimental support for; Rust. Work is continuing on this donated SDK, but we have not versioned and; published official artifacts for this release.</p>; <p>Python: The avro package fully supports Python 3. We will no longer publish a; separate avro-python3 package</p>; <p>And of course upgraded dependencies to latest versions, CVE fixes and more:; <a href=""https://issues.apache.org/jira/issues/?jql=project%3DAVRO%20AND%20fixVersion%3D1.11.0"">https://issues.apache.org/jira/issues/?jql=project%3DAVRO%20AND%20fixVersion%3D1.11.0</a></p>; <p>The link to all fixed JIRA issues and a brief summary can be found at:; <a href=""https://github.com/apache/avro/releases/tag/release-1.11.0"">https://github.com/apache/avro/releases/tag/relea",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11475:790,error,errors,790,https://hail.is,https://github.com/hail-is/hail/pull/11475,1,['error'],['errors']
Availability,"Updates the requirements on [pandas](https://github.com/pandas-dev/pandas) to permit the latest version.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/pandas-dev/pandas/releases"">pandas's releases</a>.</em></p>; <blockquote>; <h2>Pandas 1.4.1</h2>; <p>This is the first patch release in the 1.4.x series and includes some regression fixes and bug fixes. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.4.1/whatsnew/v1.4.1.html"">full whatsnew</a> for a list of all the changes.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <pre><code>conda install pandas; </code></pre>; <p>Or via PyPI:</p>; <pre><code>python3 -m pip install --upgrade pandas; </code></pre>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pandas-dev/pandas/commit/06d230151e6f18fdb8139d09abf539867a8cd481""><code>06d2301</code></a> RLS: 1.4.1</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/47e3b409deb41f18e30e447579cba3a246db050e""><code>47e3b40</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45587"">#45587</a>: DOC: append deprecation (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45942"">#45942</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/f61dfde6abbe33e143e83c6685e4b3c1c488f92b""><code>f61dfde</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45936"">#45936</a>: DOC: 1.4.1 release date (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45941"">#45941</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/28f5e9093377f72742b60e458949b7b4714141ed""><code>28f5e90</code></a> B",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11521:631,avail,available,631,https://hail.is,https://github.com/hail-is/hail/pull/11521,1,['avail'],['available']
Availability,"Users/dking/hail-20190327-1827-0.2.11-cf54f08305d1.log; Traceback (most recent call last):; File ""<stdin>"", line 4, in <module>; File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/matrixtable.py"", line 2371, in count; return (self.count_rows(), self.count_cols()); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/matrixtable.py"", line 2331, in count_rows; TableCount(MatrixRowsTable(self._mir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/backend/backend.py"", line 94, in execute; self._to_java_ir(ir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/utils/java.py"", line 227, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): is.hail.utils.HailException: foo: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; offending line: 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:20); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.utils.Context.wrapException(Context.scala:19); 	at is.hail.utils.WithContext.wrap(Context.scala:43); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:375); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:2322,Error,Error,2322,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['Error'],['Error']
Availability,"Using hail 0.2.32, `hailctl dataproc submit` results in the following error:. ```; hailctl dataproc submit hail-test {python file} -- {arguments to script}; Submitting to cluster 'hail-test'...; gcloud command:; gcloud dataproc jobs submit pyspark {python file} \; --cluster=hail-test \; --files= \; --py-files=/var/folders/7y/hvrzyxts3xg74r3m2jbq0kc0zt3g3z/T/pyscripts_srh2ze4a.zip \; --properties= \; -- \; {arguments to script}; ERROR: (gcloud.dataproc.jobs.submit.pyspark) The required property [region] is not currently set.; It can be set on a per-command basis by re-running your command with the [--region] flag. You may set it for your current workspace by running:. $ gcloud config set dataproc/region VALUE. or it can be set temporarily by the environment variable [CLOUDSDK_DATAPROC_REGION]; Traceback (most recent call last):; File ""/Users/aarong/Documents/gtex-wgs/.devenv/bin/hailctl"", line 8, in <module>; sys.exit(main()); File ""/Users/aarong/Documents/gtex-wgs/.devenv/lib/python3.7/site-packages/hailtop/hailctl/__main__.py"", line 94, in main; cli.main(args); File ""/Users/aarong/Documents/gtex-wgs/.devenv/lib/python3.7/site-packages/hailtop/hailctl/dataproc/cli.py"", line 107, in main; jmp[args.module].main(args, pass_through_args); File ""/Users/aarong/Documents/gtex-wgs/.devenv/lib/python3.7/site-packages/hailtop/hailctl/dataproc/submit.py"", line 78, in main; check_call(cmd); File ""/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py"", line 363, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError; ``` . However, adding `--region us-central1` to any location in the argument string to hailctl dataproc submit results in the argument being picked up as an input to the script, not to the underlying gcloud command",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8078:70,error,error,70,https://hail.is,https://github.com/hail-is/hail/issues/8078,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Using the Master branch version and Spark 2.2.1, I am getting the same error. Is Spark 2.2,1 supported? Any suggestions?. ```; /gradlew -Dspark.version=2.2.1 shadowJar archiveZip; fdf130b2f5d4. FAILURE: Build failed with an exception. * Where:; Build file '/restricted/projectnb/genpro/github/hail/build.gradle' line: 57. * What went wrong:; A problem occurred evaluating root project 'hail'.; > Unknown Spark version 2.2.1. Set breeze.version and py4j.version properties for Spark 2.2.1. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 6.187 secs; ```; ```; env|grep SPARK; SPARK_HOME=/share/pkg/spark/2.2.1/install; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3001#issuecomment-375939652:71,error,error,71,https://hail.is,https://github.com/hail-is/hail/issues/3001#issuecomment-375939652,2,"['FAILURE', 'error']","['FAILURE', 'error']"
Availability,"Using this TSV,; ```; id	foo_1	foo_2	foo_3	bar_1	bar_2	bar_3; a	1	2	3	4	5	6; b	7	8	9	10	11	12; c	13	14	15	16	17	18; ```. This code; ```; import hail as hl. ds = hl.import_matrix_table(""test.tsv"", row_fields={""id"": hl.tstr}, entry_type=hl.tfloat); ds = ds.annotate_cols(prefix=ds.col_id.split(""_"")[0]). t = ds.group_cols_by(ds.prefix).aggregate(**{"""": hl.agg.approx_median(ds.x)}).make_table(); t.show(); ```. Throws an error `HailException: approx_cdf already initialized` on Hail 0.2.28 and 0.2.30. On Hail 0.2.26, that code worked and output; ```; +--------+-----+----------+----------+; | row_id | id | bar | foo |; +--------+-----+----------+----------+; | int64 | str | float64 | float64 |; +--------+-----+----------+----------+; | 0 | ""a"" | 5.00e+00 | 2.00e+00 |; | 1 | ""b"" | 1.10e+01 | 8.00e+00 |; | 2 | ""c"" | 1.70e+01 | 1.40e+01 |; +--------+-----+----------+----------+; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7824:419,error,error,419,https://hail.is,https://github.com/hail-is/hail/issues/7824,1,['error'],['error']
Availability,VCF combiner assertion error about schema mismatches,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10813:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/issues/10813,1,['error'],['error']
Availability,VD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829); Caused by: is.hail.utils.HailException: cannot set missing field for required type +PFloat64; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:207); 	at is.hail.io.vcf.VCFLine.parseAddInfoArrayDouble(LoadVCF.scala:1034); 	at is.hail.io.vcf.VCFLine.parseAddInfoField(LoadVCF.scala:1055); 	at is.hail.io.vcf.VCFLine.addInfoField(LoadVCF.scala:1075); 	at is.hail.io.vcf.VCFLine.parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	... 21 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2608); 	at scala.collection.mutable.ResizableArray.foreach(R,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:9212,Error,ErrorHandling,9212,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['Error'],['ErrorHandling']
Availability,"VDS.write(VariantSampleMatrix.scala:1073); 	at org.broadinstitute.hail.driver.Write$.run(Write.scala:35); 	at org.broadinstitute.hail.driver.Write$.run(Write.scala:6); 	at org.broadinstitute.hail.driver.Command.runCommand(Command.scala:259); 	at org.broadinstitute.hail.driver.Command.run(Command.scala:264); 	at sun.reflect.GeneratedMethodAccessor54.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 35 in stage 7.0 failed 20 times, most recent failure: Lost task 35.19 in stage 7.0 (TID 6963, gnomad-prod-sw-m8lk.c.broad-mpg-gnomad.internal): org.apache.spark.SparkException: Task failed while writing rows; 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:261); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.Thread",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1202:3892,failure,failure,3892,https://hail.is,https://github.com/hail-is/hail/issues/1202,1,['failure'],['failure']
Availability,VEP error - Can't zip RDDs with unequal numbers of partitions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2666:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/2666,1,['error'],['error']
Availability,VEP tolerates invalid json,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4465:4,toler,tolerates,4,https://hail.is,https://github.com/hail-is/hail/pull/4465,1,['toler'],['tolerates']
Availability,"VMs or use a single multi-threaded JVM, we'll need to ensure the top-level; ClassLoader *does not have Hail on its classpath*. I looked briefly at this approach and found it; more work than the current approach. ---. My apologies for eliminating JVMProcess in this PR. It's an unrelated change which facilitated my; understanding of worker.py. I essentially inlined JVMProcess into JVMJob and eliminated any duplicative; code. ---. After making this change I restored the tests. Some tests had bitrotted. In the process of fixing; those tests, I found a few other bugs. Fixing these lower-level bugs unlocked a number of new; tests. One test (which was added since the service tests were removed) had to be marked as failing. Some; Hail operations rely on writing to the local file system. Implementing that properly in the Query; Worker will take some thought. Here are the bugs I fixed:. 1. Correct the error message raised when tests are run in a non-main thread (we look for this; message and start an event loop for Hail's async code because asyncio refuses to start an event; loop in a non-main thread). 2. Use a `SafeRow` to copy the globals data out of a Region and into durable, GC'ed objects. 3. Re-enable serialization of GoogleStorageFS (including its private key, which we really shouldn't; do; Tim is working on it), which was broken (presumably) when we changed Scala versions. The; `var` modifier ensures the name is compiled as a JVM field. 4. Correctly convert from a `Byte` to an `Int`. By default `Byte` to `Int` conversion (which is done; automatically when you return a `Byte` from a function whose return type is `Int`) is; sign-preserving. That means that the byte `0000 1111` is converted to the `Int` 15 and the byte; `1000 1111` is converted to the `Int` -113. The contract of; [`InputStream.read`](https://docs.oracle.com/javase/8/docs/api/java/io/InputStream.html#read--); is to return the unsigned integeral value of the next `Byte` or `-1` if we've reached the end of; t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10314:1842,error,error,1842,https://hail.is,https://github.com/hail-is/hail/pull/10314,1,['error'],['error']
Availability,Validation code was not updated when adding azure https support. Made this check a bit more robust and tested locally. Resolves #13049,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13051:92,robust,robust,92,https://hail.is,https://github.com/hail-is/hail/pull/13051,1,['robust'],['robust']
Availability,VariantSampleMatrix$$anonfun$1.apply(VariantSampleMatrix.scala:72); 	at is.hail.utils.richUtils.RichHadoopConfiguration$.is$hail$utils$richUtils$RichHadoopConfiguration$$using$extension(RichHadoopConfiguration.scala:226); 	at is.hail.utils.richUtils.RichHadoopConfiguration$.readFile$extension(RichHadoopConfiguration.scala:251); 	at is.hail.variant.VariantSampleMatrix$.readFileMetadata(VariantSampleMatrix.scala:72); 	at is.hail.variant.VariantSampleMatrix$.read(VariantSampleMatrix.scala:51); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:434); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:433); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.HailContext.readAll(HailContext.scala:433); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: devel-6ee2919; Error summary: MappingException: Did not find value which can be converted into java.lang.String; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2159:8640,Error,Error,8640,https://hail.is,https://github.com/hail-is/hail/issues/2159,1,['Error'],['Error']
Availability,"Verified that before #3510 was merged into master, if this PR had been added to master, it would have caught the issue. The stack trace directly fingers the EmitPackDecoder, which is exactly what one would hope to happen:. ```; FatalError: AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 3.0 failed 1 times, most recent failure: Lost task 3.0 in stage 3.0 (TID 18, localhost, executor driver): java.lang.AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker; 	at scala.Predef$.assert(Predef.scala:170); 	at is.hail.asm4s.FunctionBuilder.result(FunctionBuilder.scala:291); 	at is.hail.io.EmitPackDecoder$.apply(RowStore.scala:637); 	at is.hail.io.PackCodecSpec.buildDecoder(RowStore.scala:110); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:550); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:546); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3521#issuecomment-387199916:424,failure,failure,424,https://hail.is,https://github.com/hail-is/hail/pull/3521#issuecomment-387199916,2,['failure'],['failure']
Availability,"Version:; Apache Spark version 2.4.3; Hail version 0.2.19-c6ec8b76eb26. When exporting a table, the following error occurs when running on a yarn cluster. It does not occur when running locally. Any suggestions on this?. ```; Container exited with a non-zero exit code 127. Error file: prelaunch.err.; Last 4096 bytes of prelaunch.err :; Last 4096 bytes of stderr :; SLF4J: Class path contains multiple SLF4J bindings.; SLF4J: Found binding in [jar:file:/data04/hadoop/yarn/local/usercache/farrell/filecache/291/__spark_libs__4347827829503170766.zip/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.5.0-292/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.; SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]; 19/09/06 15:54:22 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 19/09/06 15:54:30 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; /usr/java/default/bin/java: symbol lookup error: /data01/hadoop/yarn/local/usercache/farrell/appcache/application_1565788829616_0098/container_e2451_1565788829616_0098_01_000011/tmp/jniloader3452911880890326608netlib-native_system-linux-x86_64.so: undefined symbol: cblas_dgemv. ```; -----------------------------------------------------------------------------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7008:110,error,error,110,https://hail.is,https://github.com/hail-is/hail/issues/7008,3,"['Error', 'error']","['Error', 'error']"
Availability,"Very preliminary. Builds test instead of main by default, output looks like this:. ```; ~/hail/libhail/build$ ./test; RUN test_int64_value; RUN test_int64_value OK; RUN test_int32_value; RUN test_int32_value OK; RUN test_bool_value; RUN test_bool_value OK; ...; ```. Added `std::string render(...)` to format module. Added some format tests. Added `CHECK_EQ` macro that prints the details on failure:. ```; ../src/hail/test.hpp:42: assert failed:; CHECK_EQ(render(FormatAddress(nullptr)), ""0x0000000000000000""); with values:; CHECK_EQ(0000000000000000, 0x0000000000000000); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10231:392,failure,failure,392,https://hail.is,https://github.com/hail-is/hail/pull/10231,1,['failure'],['failure']
Availability,"VirtualHost discrimination](https://httpd.apache.org/docs/2.4/vhosts/name-based.html) based on information from the [TeamCity wiki](https://confluence.jetbrains.com/pages/viewpage.action?pageId=74845225#HowTo...-SetUpTeamCitybehindaProxyServer):. ``` apache; <IfModule mod_ssl.c>; <VirtualHost *:443>; # The ServerName directive sets the request scheme, hostname and port that; # the server uses to identify itself. This is used when creating; # redirection URLs. In the context of virtual hosts, the ServerName; # specifies what hostname must appear in the request's Host: header to; # match this virtual host. For the default virtual host (this file) this; # value is not decisive as it is used as a last resort host regardless.; # However, you must set it for any further virtual host explicitly.; ServerName hail.is; ServerAlias www.hail.is. ServerAdmin webmaster@localhost; DocumentRoot /var/www/html. RedirectMatch 404 /\.git. # Available loglevels: trace8, ..., trace1, debug, info, notice, warn,; # error, crit, alert, emerg.; # It is also possible to configure the loglevel for particular; # modules, e.g.; #LogLevel info ssl:warn. ErrorLog ${APACHE_LOG_DIR}/error.log; CustomLog ${APACHE_LOG_DIR}/access.log combined. # For most configuration files from conf-available/, which are; # enabled or disabled at a global level, it is possible to; # include a line for only one particular virtual host. For example the; # following line enables the CGI configuration for this host only; # after it has been globally disabled with ""a2disconf"".; #Include conf-available/serve-cgi-bin.conf; SSLCertificateFile /etc/letsencrypt/live/hail.is/fullchain.pem; SSLCertificateKeyFile /etc/letsencrypt/live/hail.is/privkey.pem; Include /etc/letsencrypt/options-ssl-apache.conf; </VirtualHost>. <VirtualHost *:443>; ServerName ci.hail.is; ServerAdmin webmaster@localhost. LoadModule proxy_module /usr/lib/apache2/modules/mod_proxy.so; LoadModule proxy_http_module /usr/lib/apache2/modules/mod_proxy_http.so; ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/674#issuecomment-243899170:1318,error,error,1318,https://hail.is,https://github.com/hail-is/hail/issues/674#issuecomment-243899170,1,['error'],['error']
Availability,"WIP pull request. - [x] Write tests to replicate existing errors. - [ ] Write test to replicate stalled request. - [ ] Resolve stalled request. However, I think we should consider writing a more complete solution to this. As far as I can tell, our use of threads is fragile; following Flask recommendations w.r.t reliance on production-ready WSGI server seems a good idea. Happy to take that on. I'd also like to move away from Flask for API stuff. While not likely to be a bottleneck for many moons, there are solutions rumored to be far faster (Falcon, esp using Cpython).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5065:58,error,errors,58,https://hail.is,https://github.com/hail-is/hail/pull/5065,1,['error'],['errors']
Availability,WTF - I'm getting this error in a PR - https://ci.hail.is/jobs/30344/log. also see this message at the bottom: . 2019-05-30 19:47:48 Hail: WARN: struct{idx: int32} has no field row_idx at <root>.<array>.end for value JInt(10),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6223#issuecomment-497480960:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/issues/6223#issuecomment-497480960,1,['error'],['error']
Availability,"Wait, there's no error. Shouldn't this drop alleles though? Transmute I thought did...",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3673#issuecomment-392915822:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/issues/3673#issuecomment-392915822,1,['error'],['error']
Availability,"Was getting assertion error when initializing a DB instance in cases where datasets are on only one cloud platform. Specifically with the panUKB Hail tables that are only on AWS and not on GCP, running `db = hl.experimental.DB(region='us', cloud='gcp')` would fail at the assertion to check cloud in `DatasetVersion.from_json()`. To fix, I just made `DatasetVersion.from_json()` return `None` when a version is not available on the specified cloud platform so that it can be filtered out in `Dataset.from_name_and_json()`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10360#issuecomment-825010405:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/10360#issuecomment-825010405,2,"['avail', 'error']","['available', 'error']"
Availability,"Was throwing exception failures. Return optional by default. Handle; TInt32 since there can be two TInt32, required and optional.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2455:23,failure,failures,23,https://hail.is,https://github.com/hail-is/hail/pull/2455,1,['failure'],['failures']
Availability,Wasn't sure if this should raise an error or just continue.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6539:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/pull/6539,1,['error'],['error']
Availability,Watching - AoU is seeing this error with 0.2.126,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960#issuecomment-1802068296:30,error,error,30,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1802068296,1,['error'],['error']
Availability,"We *should* be handling this error already - there's code that matches this exact message here: https://github.com/hail-is/hail/blob/8362afaefa8829e720f5affc9b482c2568e8299d/hail/src/main/scala/is/hail/services/NettyProxy.scala#L21-L31. Following the logic through, it looks like we retry this kind of exception indefinitely UNLESS the netty `Epoll` is not available...",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12980#issuecomment-1545975559:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/issues/12980#issuecomment-1545975559,2,"['avail', 'error']","['available', 'error']"
Availability,We almost always want to raise an error on a bad status.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9864:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/9864,1,['error'],['error']
Availability,"We always ensure that `cleanup` is run, but in order to ensure that `post_job_complete` is run we need to ensure we get through any computation in cleanup and `mark_complete` that could potentially hang. So we add timeouts to any yield points in those functions and broadly catch exceptions so we always continue in the cleanup/mark_complete process regardless of failure.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12944:364,failure,failure,364,https://hail.is,https://github.com/hail-is/hail/pull/12944,1,['failure'],['failure']
Availability,"We apparently did not exercise this code path much before I fixed batch to treat ImagePullBackOff as failure. Really confusing error message because `write_gs_file` returns `None` which is not iterable so you get a type error on line 565. The real issue is that you're trying to deconstruct a pair as `uri, err` and you received `None`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6810:101,failure,failure,101,https://hail.is,https://github.com/hail-is/hail/pull/6810,3,"['error', 'failure']","['error', 'failure']"
Availability,We are down to 164 docs failures and I am tired. I will work on it more another time. Then we will be able to enable nitpicky and our docs will never have broken links.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9403:7,down,down,7,https://hail.is,https://github.com/hail-is/hail/pull/9403,2,"['down', 'failure']","['down', 'failures']"
Availability,"We are increasingly seeing errors from ""Connection reset"" which we switched from ""transient"" to ""retry once"". The current code makes it impossible to determine if we are correctly retrying this error once. If we see that there are a lot of ""Connection reset"" errors that happen twice we should perhaps change ""retry once"" to ""retry five times"" or use a more generous delay.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12984:27,error,errors,27,https://hail.is,https://github.com/hail-is/hail/pull/12984,3,['error'],"['error', 'errors']"
Availability,"We are trying to setup hail `0.2.72` on spark `3.1.2` version. However, we are also facing similar error. * java version: `OpenJDK 64-Bit Server VM, 1.8.0_242`; * scala version: `2.12.10`; * py4j: `0.10.9`; * Python: `3.7.10`. <details>; <summary>Stacktrace</summary>. ```; Py4JJavaError: An error occurred while calling o126.exists.; : java.lang.NoClassDefFoundError: com/amazonaws/AmazonClientException; 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at org.apache.hadoop.conf.Configuration.getClassByNameOrNull(Configuration.java:2532); 	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2497); 	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2593); 	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3269); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3301); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3352); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3320); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:479); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:361); 	at is.hail.io.fs.HadoopFS.fileStatus(HadoopFS.scala:164); 	at is.hail.io.fs.FS.exists(FS.scala:183); 	at is.hail.io.fs.FS.exists$(FS.scala:181); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:70); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.Ca",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10590#issuecomment-899322610:99,error,error,99,https://hail.is,https://github.com/hail-is/hail/issues/10590#issuecomment-899322610,2,['error'],['error']
Availability,"We are unlikely to support this in the short term, but are planning to refine our VCF parsing and VDS model to include this down the road.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1010#issuecomment-256957523:124,down,down,124,https://hail.is,https://github.com/hail-is/hail/issues/1010#issuecomment-256957523,1,['down'],['down']
Availability,"We can [reserve specific IP addresses](https://cloud.google.com/compute/docs/ip-addresses/reserve-static-internal-ip-address) for use later (like we do with internal gateway), but as far as I can tell the model is you assign a network or subnet an IP address range and that should be available to any resources created in it. I guess the proper way to ensure this would be to then use a range for job IPs that is outside the internal IP address range given to our default network.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11051#issuecomment-965671928:284,avail,available,284,https://hail.is,https://github.com/hail-is/hail/pull/11051#issuecomment-965671928,1,['avail'],['available']
Availability,We can directly download the key and specify the repository. I used these instructions:; - https://wiki.debian.org/DebianRepository/UseThirdParty; - https://launchpad.net/~deadsnakes/+archive/ubuntu/ppa. This builds in like 2 minutes rather than 4. The frontend part avoids issues in downstream docker files where the installer might try to interact with the user. I noticed that some package was updated and now pulls in `tzdata` which asks you to select a timezone at install-time (if Debian frontend is interactive).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10356:16,down,download,16,https://hail.is,https://github.com/hail-is/hail/pull/10356,2,['down'],"['download', 'downstream']"
Availability,"We can talk more about how to handle lines with errors, but that won't be part of this fix.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/361#issuecomment-216535908:48,error,errors,48,https://hail.is,https://github.com/hail-is/hail/issues/361#issuecomment-216535908,1,['error'],['errors']
Availability,"We cancel in two cases:; 1. A (dev|) deploy failed.; 2. A batch was found open but unknown to us. In the former case, we should delete the batch. The batch contains no extra information; everything we need to know is in the failure message. In the latter case, an open batch does not cost us anything and; cannot be cancelled anyway, so we choose to ignore them. Such a batch; should only come into existence when CI dies in the middle of submission; which should be quite rare.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9725:224,failure,failure,224,https://hail.is,https://github.com/hail-is/hail/pull/9725,1,['failure'],['failure']
Availability,We could throw a nicer error,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3696#issuecomment-393680136:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/issues/3696#issuecomment-393680136,1,['error'],['error']
Availability,"We currently have several hail sparse matrix tables that contain up to 10,000 aggregated gVCF files that we aggregated using run_combiner(). We are trying to merge these tables together with a script that makes use of your combine_gvcfs function that is defined in your experimental vcf combiner library. We have successfully succeeded in doing this for merging multiple sparse matrix table into a final table of around 18,000 gVCFs. We are now trying to do this for just under 110,00 gVCFs. The script runs for a while and seems to fail at the very end. Based on the logs, it looks like it is writing to output when it fails. We monitored our resources on google cloud and there is not an issue with cluster CPU or memory usage. We believe the problem stems from not having enough memory in the individual executors at this stage. We are currently using the default of:. spark.executor.memory=10117m; spark.executor.memoryOverhead=15175m. We would like to scale this up and re-run. Do you have any recommended settings for a job of this size?. For reference, below is the error message that we received. Thank you in advance.; ````; Hail version: 0.2.81-edeb70bc789c; Error summary: SparkException: Job aborted due to stage failure: Task 2476 in stage 0.0 failed 20 times, most recent failure: Lost task 2476.20 in stage 0.0 (TID 6571) (<clusterinfo>.internal executor 1128): ExecutorLostFailure (executor 1128 exited caused by one of the running tasks) Reason: Container from a bad node: container_1659731953912_0002_01_001691 on host: cluster-himem-w-0.c.gbsc-gcp-project.internal. Exit status: 143. Diagnostics: [2022-08-10 20:11:38.904]Container killed on request. Exit code is 143; [2022-08-10 20:11:38.904]Container exited with a non-zero exit code 143. ; [2022-08-10 20:11:38.905]Killed by external signal-; ````",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12083:1073,error,error,1073,https://hail.is,https://github.com/hail-is/hail/issues/12083,4,"['Error', 'error', 'failure']","['Error', 'error', 'failure']"
Availability,"We definitely need a mechanism to force a stream pipeline (or sub-pipeline) to put all allocations in a single region, and avoid any region management overhead. Then, for example, in table lowering we can set a flag on any single-row stream processing to use a single region, preserving the existing behavior. I have some thoughts on how to do that. We can just pass an ""allocator"" to EmitStream, which is a Region factory, that stream nodes must use to create new regions. An allocator that creates new regions gives the ""free between rows"" behavior. To implement the ""within one row"" behavior, we can pass down an allocator that returns regions backed by a single fixed RegionMemory, with no-op freeing. Maybe that needs to be put in place before this can merge?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9106#issuecomment-661877761:608,down,down,608,https://hail.is,https://github.com/hail-is/hail/pull/9106#issuecomment-661877761,1,['down'],['down']
Availability,"We do not yet have pyright running on the Hail python package nor the tests. Without this change, I get failures on push.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14124:104,failure,failures,104,https://hail.is,https://github.com/hail-is/hail/pull/14124,1,['failure'],['failures']
Availability,We don't have any examples here: https://hail.is/docs/0.2/aggregators.html?highlight=filter#hail.expr.aggregators.downsample,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8241:114,down,downsample,114,https://hail.is,https://github.com/hail-is/hail/issues/8241,1,['down'],['downsample']
Availability,"We don't use near line or cold line storage, so this change should be okay. However, there is a requirement on who can download the files that I am concerned about. > Note that for such uploads, crcmod is required for downloading regardless of whether the parallel composite upload option is on or not. For some distributions this is easy (e.g., it comes pre-installed on macOS), but in other cases some users have found it difficult. Because of this, at present parallel composite uploads are disabled by default. Google is actively working with a number of the Linux distributions to get crcmod included with the stock distribution. Once that is done we will re-enable parallel composite uploads by default in gsutil.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7024#issuecomment-529229251:119,down,download,119,https://hail.is,https://github.com/hail-is/hail/pull/7024#issuecomment-529229251,2,['down'],"['download', 'downloading']"
Availability,"We end up getting exceptions like this, happens every time we get to the end of the file:; ```; RuntimeException: error reading tabix-indexed file src/test/resources/gvcfs/recoding/HG00187.hg38.g.vcf.gz: i=0, curOff=2469855232, expected=2468020224; ```; These virtual offsets correspond to these pairs of absolute|decompressed offset; ```; 2469855232 => 37687|0; 2468020224 => 37659|0; ```; Looking at these, they differ by 28, which is the size of the empty bgzip block at the end. And so when we refresh: we go too far.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9304#issuecomment-676615090:114,error,error,114,https://hail.is,https://github.com/hail-is/hail/pull/9304#issuecomment-676615090,1,['error'],['error']
Availability,We fixed all the known issues and install-editable now seems reliable and fast.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13691#issuecomment-1758609203:61,reliab,reliable,61,https://hail.is,https://github.com/hail-is/hail/pull/13691#issuecomment-1758609203,1,['reliab'],['reliable']
Availability,We get a lot of errors about files that already exist. Hail commands are usually not retryable because there are file paths that might have been partly written to. This tightly scopes the retries to just the I/O. It also avoids keeping the output stream open for a long period of time.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13152:16,error,errors,16,https://hail.is,https://github.com/hail-is/hail/pull/13152,1,['error'],['errors']
Availability,"We get a lot of spurious Grafana alerts because batch-driver has unclosed `aiohttp.ClientSession` objects. `aiohttp` can [report the creation location](https://github.com/aio-libs/aiohttp/blob/master/aiohttp/client.py#L242-L247), but only when aysncio is in debug mode. I am hesitant to enable debug mode because I suspect it will slow down everything by grabbing stack traces for every coroutine (so that it can report an error later). I adapted the code from the linked asyncio code and tested it as follows:. ```; In [1]: import aiohttp; ...: import traceback; ...: import sys; ...:; ...: oldinit = aiohttp.ClientSession.__init__; ...: def newinit(self, *args, **kwargs):; ...: oldinit(self, *args, **kwargs); ...: self._source_traceback: Optional[; ...: traceback.StackSummary; ...: ] = traceback.extract_stack(sys._getframe(1)); ...: aiohttp.ClientSession.__init__ = newinit. In [2]: aiohttp.ClientSession(); <ipython-input-1-028690903e5f>:7: DeprecationWarning: The object should be created within an async function; oldinit(self, *args, **kwargs); Out[2]: <aiohttp.client.ClientSession at 0x104ab3850>. In [3]: aiohttp.ClientSession(); <ipython-input-1-028690903e5f>:7: DeprecationWarning: The object should be created within an async function; oldinit(self, *args, **kwargs); Out[3]: <aiohttp.client.ClientSession at 0x104dac8b0>. In [4]: aiohttp.ClientSession(); <ipython-input-1-028690903e5f>:7: DeprecationWarning: The object should be created within an async function; oldinit(self, *args, **kwargs); Out[4]: <aiohttp.client.ClientSession at 0x104daeec0>. In [5]:. Do you really want to exit ([y]/n)? y; Unclosed client session; client_session: <aiohttp.client.ClientSession object at 0x104ab3850>; source_traceback: Object created at (most recent call last):; File ""/Users/dking/miniconda3/bin/ipython"", line 8, in <module>; sys.exit(start_ipython()); File ""/Users/dking/miniconda3/lib/python3.10/site-packages/IPython/__init__.py"", line 128, in start_ipython; return launch_new_instance(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13421:336,down,down,336,https://hail.is,https://github.com/hail-is/hail/pull/13421,2,"['down', 'error']","['down', 'error']"
Availability,We got an error because a BatchBuilder has no id attribute,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8121:10,error,error,10,https://hail.is,https://github.com/hail-is/hail/pull/8121,1,['error'],['error']
Availability,"We had a couple PRs fail because the database reached its [max connections](https://portal.azure.com/#@haildev.onmicrosoft.com/resource/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/haildev/providers/Microsoft.DBforMySQL/servers/db-393222c4/metrics). We should probably be resilient to this, but I figured we should be able to handle our normal PR load. I also checked GCP and their default is 4k. Azure sets its cap at 1250. I haven't applied any terraform since you've made your changes. Is that safe to do?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11329:293,resilien,resilient,293,https://hail.is,https://github.com/hail-is/hail/pull/11329,1,['resilien'],['resilient']
Availability,"We have a CI problem leading to random erroneous test failures, and the system isn't designed to run the tests twice for a single commit. Can you add a new commit to the PR with `git commit -m ""bump"" --allow-empty`?; Sorry!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6937#issuecomment-524832178:54,failure,failures,54,https://hail.is,https://github.com/hail-is/hail/pull/6937#issuecomment-524832178,1,['failure'],['failures']
Availability,"We have a difference of opinion about the risks involved in using whatever; compiler happens to show up as $(CXX); to try to compile arbitrarily large auto-generated C++ files, and maybe; about what happens when that fails; and gives an error message about something in the middle of 12000 lines of; code that bears no obvious relationship; to what the user is doing. Or when that compiler takes 15 minutes to; compile it. It's the C++ equivalent of; the JVM ""no, that's just too much bytecode"". Or worst of all, it compiles; it but the code gives the wrong answers; because that particular compiler has a bug, and we never tested the; combination of our codegen with *that*; compiler/version. A couple of years ago I was seeing g++ take 40-60 seconds to compile; something that clang did in 2 seconds; (fairly heavily templated code generated for an SQL query, so very much in; the same ballpark as parts of Hail),; which contributes to my concern about this, especially on linux where g++; is the default. So in the long run I expect we'll ship a compiler, or specify a compiler.; But that becomes a problem in itself; if we want the shipped compiler to work on a variety of OS'es. When I did; that before it was all Ubuntu-14.04; and Ubuntu-16.04, and it was manageable to build it for two platforms. On Thu, Aug 2, 2018 at 9:59 PM cseed <notifications@github.com> wrote:. > *@cseed* commented on this pull request.; > ------------------------------; >; > In src/main/c/NativeModule.cpp; > <https://github.com/hail-is/hail/pull/3973#discussion_r207422997>:; >; > > +}; > +; > +std::string strip_suffix(const std::string& s, const char* suffix) {; > + size_t len = s.length();; > + size_t n = strlen(suffix);; > + if ((n > len) || (strncmp(&s[len-n], suffix, n) != 0)) return s;; > + return std::string(s, 0, len-n);; > +}; > +; > +std::string get_cxx_name() {; > + char* p = ::getenv(""CXX"");; > + if (p) return std::string(p);; > + // We prefer clang because it has faster compile; > + auto s = run",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-410127709:237,error,error,237,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410127709,1,['error'],['error']
Availability,We have configured curl to retry so we should always prefer it to wget. I also; fixed that long-standing mistake I made when I added retry-all-errors before; it was supported in our version of curl.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11649:143,error,errors,143,https://hail.is,https://github.com/hail-is/hail/pull/11649,1,['error'],['errors']
Availability,"We have some problem with running nirvana in hail and we use the sample file of GWAS Tutorial. Code: ; hl.utils.get_1kg('data/'); vcfVds = hl.import_vcf('data/1kg.vcf.bgz', min_partitions=8); vds = hl.nirvana(vcfVds,'data/nirvana.properties'). Version:; Running on Apache Spark version 2.2.1; Hail version: 0.2.10-ceb85fc87544. We got this error massage:; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-1226>"", line 2, in nirvana; File ""/seqslab/hail/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 561, in wrapper; File ""/seqslab/hail/hail/build/distributions/hail-python.zip/hail/methods/qc.py"", line 860, in nirvana; File ""/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/seqslab/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 227, in deco; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.methods.Nirvana$.annotate(Nirvana.scala:361); at is.hail.methods.Nirvana$.apply(Nirvana.scala:487); at is.hail.methods.Nirvana.apply(Nirvana.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.10-ceb85fc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5657:340,error,error,340,https://hail.is,https://github.com/hail-is/hail/issues/5657,1,['error'],['error']
Availability,We have to mirror a lot of our utilities across python and scala. Looks like this error never made it to python and we just hadn't encountered it in our python client until a user hit it yesterday.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12170:82,error,error,82,https://hail.is,https://github.com/hail-is/hail/pull/12170,1,['error'],['error']
Availability,"We mix the two right now, with most of the new code using quotes. I; feel that quotes are a better solution given the prevalence of markdown; editors (like Zulip) where copy-pasting an error message with backticks; leads to badly formatted renderings. cc @cseed who I believe favored the use of the backtick style in the first place.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5761:185,error,error,185,https://hail.is,https://github.com/hail-is/hail/pull/5761,1,['error'],['error']
Availability,"We narrowed it down to star alleles. I think @lfrancioli has a PR for it, but not sure if it's through yet?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1518#issuecomment-287838501:15,down,down,15,https://hail.is,https://github.com/hail-is/hail/issues/1518#issuecomment-287838501,1,['down'],['down']
Availability,"We need at least one pool without taints to schedule the kube-system services (e.g. dns). Therefore, I propose:; - make the non-preemptible pool untainted,; - keep taint on preemptibles so kube-system pods are not scheduled there,; - and keep tolerations for preemptible pods,; - use nodeSelector to force preemptible pods to be scheduled on the preemptible pool. In fact, I put nodeSelectos on all pods, although it isn't strictly necessary for non-preemptible pods. Sound good?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7784:243,toler,tolerations,243,https://hail.is,https://github.com/hail-is/hail/pull/7784,1,['toler'],['tolerations']
Availability,"We needed to await cancelled tasks to handle the error that was raised inside the task. Otherwise, I think what would happen is the unhandled cancelled error would cause an exception to be thrown when the main thread finally returned (file finished downloading) because errors in the cancelled tasks weren't ignored. For reference, the original error was this:. ```; Unclosed client session; client_session: <aiohttp.client.ClientSession object at 0x7fe17e8c4bd0>; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/usr/local/lib/python3.7/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/usr/local/lib/python3.7/site-packages/batch/copy/__main__.py"", line 34, in <module>; asyncio.run(main()); File ""/usr/local/lib/python3.7/asyncio/runners.py"", line 43, in run; return loop.run_until_complete(main); File ""/usr/local/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete; return future.result(); concurrent.futures._base.CancelledError; sys:1: RuntimeWarning: coroutine 'retry_transient_errors' was never awaited; RuntimeWarning: Enable tracemalloc to get the object allocation traceback; ```. https://stackoverflow.com/questions/57089430/asyncio-task-cancel-is-is-synchronous. It's possible I'm wrong and this code doesn't do anything. If that's the case, then I need additional help.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10534#issuecomment-853098749:49,error,error,49,https://hail.is,https://github.com/hail-is/hail/pull/10534#issuecomment-853098749,5,"['down', 'error']","['downloading', 'error', 'errors']"
Availability,We now mock this test so we've lost the ability to specifically diagnose this error. Hopefully this is useful if a similar bug crops up in the future.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13951#issuecomment-2214404544:78,error,error,78,https://hail.is,https://github.com/hail-is/hail/issues/13951#issuecomment-2214404544,1,['error'],['error']
Availability,"We now use an API token linked to hailgenetics instead of password auth. In order to do the org request, Daniel set up 2FA. There's no way to set up 2FA. There are recovery codes in the ""usual place"". No one besides Daniel can currently log into hailgenetics PyPI account as a result (other than using recovery codes).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13598#issuecomment-1808759767:164,recover,recovery,164,https://hail.is,https://github.com/hail-is/hail/issues/13598#issuecomment-1808759767,2,['recover'],['recovery']
Availability,"We observed some sporadic failures, but the error was always less than .011. This raises the tolerance to .015, which should be a comfortable margin.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14058:26,failure,failures,26,https://hail.is,https://github.com/hail-is/hail/pull/14058,3,"['error', 'failure', 'toler']","['error', 'failures', 'tolerance']"
Availability,"We only copy if the image isn't already present. I think this code is not what you want in mirror images. We should copy if the contents change as well. ```; copy_if_not_present() {; src_image=$1; dest_image=$2; if ! skopeo inspect ""docker://docker.io/$1"";; then; echo ""$1 does not exist yet, doing nothing""; elif skopeo inspect ""docker://$2"";; then; echo ""$2 already exists, doing nothing""; else; echo ""$2 does not exist, copying $1 to $2""; copy_image $1 $2; fi; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13536#issuecomment-1703073465:264,echo,echo,264,https://hail.is,https://github.com/hail-is/hail/pull/13536#issuecomment-1703073465,3,['echo'],['echo']
Availability,"We only have `make` commands for running `pylint` on subdirectories that have been kept up to date with its rules, but the `pylintrc` doesn't actually contain any indication of which subdirectories should be ignored when running `pylint`. This makes the use of language servers that run `pylint` on the file that's open frustrating, as files in the ignored subdirectories will often be full of `pylint` suggestions. This change adds the relevant subdirectories to the `pylintrc` file. Note that this does not necessarily enable us to run `pylint` directly on those subdirectories with the equivalent `make` commands to the ones that already exist, because there is no way that I've found to make `pylint` ignore the `__init__.py` file of whatever module it's being run on, so running it on `hail/python/hail`, for example, produces many errors.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14060:837,error,errors,837,https://hail.is,https://github.com/hail-is/hail/pull/14060,1,['error'],['errors']
Availability,"We probably should have better retry logic, but hopefully this will alleviate some of the errors in the short term.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11883:90,error,errors,90,https://hail.is,https://github.com/hail-is/hail/pull/11883,1,['error'],['errors']
Availability,"We recently encountered a batch submission that eventually failed after numerous errors like this one â€” but nonetheless submitted a new batch containing zero jobs. ```; [â€¦]; File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 792, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 834, in retry_transient_errors_with_debug_string; st = ''.join(traceback.format_stack()); . The most recent error was <class 'hailtop.httpx.ClientResponseError'> 500, message='Internal Server Error', url=URL('http://batch.hail/api/v1alpha/batches/485962/updates/1/jobs/create') body='500 Internal Server Error\n\nServer got itself in trouble'. ; Traceback (most recent call last):; File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 809, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/aiocloud/common/session.py"", line 117, in _request_with_valid_authn; return await self._http_session.request(method, url, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/httpx.py"", line 148, in request_and_raise_for_status; raise ClientResponseError(; hailtop.httpx.ClientResponseError: 500, message='Internal Server Error', url=URL('http://batch.hail/api/v1alpha/batches/485962/updates/1/jobs/create') body='500 Internal Server Error\n\nServer got itself in trouble'; 2024-09-25 01:54:55,288 - hailtop.utils 835 - WARNING - A transient error occured. We will automatically retry. We have thus far seen 50 transient errors (next delay: 60.0s).; ```. The corresponding server-side error was. ```; pymysql.err.DataError: (1406, \""Data too long for column 'value' at row 106\""); ```. coming from the `INSERT INTO job_attributes â€¦` query in `insert_jobs_into_db()`. We write a list of the samples being processed as a job attribute, and it turned out th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14702:81,error,errors,81,https://hail.is,https://github.com/hail-is/hail/issues/14702,4,"['Error', 'error']","['Error', 'error', 'errors']"
Availability,"We recently encountered jobs that failed due to syntax errors in the shell script generated by Hail, stemming from code such as. ```python; job.command('touch before'); job.command('\n'.join(f'echo {shlex.quote(msg)}' for msg in messages)); job.command('touch after'); ```. Occasionally `messages` is an empty list, so this evaluates to `job.command('')` and the eventual shell script submitted by Hail contains. ```sh/bin/bash' '-c' '; â€¦; {; touch before; }; {. }; {; touch after; }; â€¦; ```. Shell compound commands like `{ â€¦ }` must contain at least one command, so this is a syntax error. Empty commands could be rewritten to generate e.g. [`:`](https://pubs.opengroup.org/onlinepubs/9799919799/utilities/V3_chap02.html#tag_19_17) such as. ```sh; â€¦; {; :; }; â€¦; ```. but it seems easier and probably less surprising to just omit them.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14700#issuecomment-2372547180:55,error,errors,55,https://hail.is,https://github.com/hail-is/hail/pull/14700#issuecomment-2372547180,3,"['echo', 'error']","['echo', 'error', 'errors']"
Availability,"We recently had a debugging odyssey due to the following code:. ```python; import hailtop.batch as hb. def make_job(batch):; job = batch.new_job(name='test'); return job # Oops, forgot to also return the output resource. batch = hb.Batch(name='test'); my_job, my_output = make_job(batch); ```. This lead to the following error message:. ```; Traceback (most recent call last):; File ""â€¦/borkscript.py"", line 8, in <module>; my_job, my_output = make_job(batch); File ""â€¦/site-packages/hailtop/batch/job.py"", line 125, in __getitem__; return self._get_resource(item); File ""â€¦/site-packages/hailtop/batch/job.py"", line 118, in _get_resource; r = self._batch._new_job_resource_file(self, value=item); File ""â€¦/site-packages/hailtop/batch/batch.py"", line 405, in _new_job_resource_file; jrf = _resource.JobResourceFile(value, source); File ""â€¦/site-packages/hailtop/batch/resource.py"", line 128, in __init__; super().__init__(value); File ""â€¦/site-packages/hailtop/batch/resource.py"", line 48, in __init__; assert value is None or isinstance(value, str); AssertionError; ```. Of course, in a 400-line script it took a long while to figure out what the traceback that seemed to have little to do with any dubious code of ours was trying to tell us, and to notice that the actual problem was the `return` 200 lines away!. The problem is that these classes define `__getitem__()` so their resources can be accessed as if via a dict. The assignment into multiple variables causes Python to try to interpret the RHS as something iterable, and as `__getitem__` is defined, it will use `__getitem__(0)`, `__getitem__(1)`,... to implement that iteration. These classes are not really iterable, so define a no-op `__iter__()` to prevent this. With this, we get:. ```; Traceback (most recent call last):; File ""â€¦/borkscript.py"", line 8, in <module>; my_job, my_output = make_job(batch); File ""â€¦/site-packages/hailtop/batch/job.py"", line 127, in __iter__; raise TypeError(f'{type(self).__name__!r} object is not iterable')",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14390:321,error,error,321,https://hail.is,https://github.com/hail-is/hail/pull/14390,1,['error'],['error']
Availability,"We recently put in a couple PRs that improve performance on these searches so thought I would update here. They were mostly changes to things upstream of the portion of code we have been focusing on and change how data is initially read in, but the biggest performance gain we got was adding `hl._set_flags(use_new_shuffle='1')`. A lot of the focus was around how we handle searches in multiple data types which has been out of the scope of this work so far, so for the search we've been profiling here its only came down to like 80 seconds, but figured its worth sharing. Hopefully this does not cause to catastrophic of a merge conflict for you guys. https://github.com/broadinstitute/seqr/pull/3873; https://github.com/broadinstitute/seqr/pull/3876",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13882#issuecomment-1945174111:517,down,down,517,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1945174111,1,['down'],['down']
Availability,"We saw this error in production:; ```; pymysql.err.IntegrityError: (1062, ""Duplicate entry '7433-432443' for key 'PRIMARY'""); ```; hand deploy in progress already.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8014:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/8014,1,['error'],['error']
Availability,"We seem to be running into spark/yarn scheduling limitations causing stages to often fail with a large number of partitions. Here, we implement a very simple chunking strategy to run spark jobs with a limited number of partitions at a time. The maximum parallelism is controlled by a new `spark_max_stage_parallelism` feature flag, which defaults to MAXINT until we can figure out a good default. Also, this change corrects a small error in logic for partition indices for call caching. The `resultHandler` argument of [`runJob`] is called with the job's partition index, not the index of the partition within the RDD. So we need to index into the `partitions` sequence when populating the results buffer. CHANGELOG: Add 'spark_max_stage_parallelism' flag to allow users to run pipelines with a large number of partitions in chunks. By default, hail still attempts to run all partitions in a stage at once. . [`runJob`]: https://spark.apache.org/docs/latest/api/scala/org/apache/spark/SparkContext.html#runJob[T,U](rdd:org.apache.spark.rdd.RDD[T],func:(org.apache.spark.TaskContext,Iterator[T])=%3EU,partitions:Seq[Int],resultHandler:(Int,U)=%3EUnit)(implicitevidence$11:scala.reflect.ClassTag[U]):Unit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14590:432,error,error,432,https://hail.is,https://github.com/hail-is/hail/pull/14590,1,['error'],['error']
Availability,"We should add docs that describe how to do this to:; 1. `hl.default_reference`, obviously; 2. Deprecate the `reference_genome` parameter to `hl.init` and instruct users to use `hl.default_reference`. Inform that this parameter has confusing interactions with ReferenceGenome, so we're removing it.; 3. `hl.ReferenceGenome.__init__` should refer users to that. . I think we should also make a separate PR that improves the `hl.import_vcf` error message. If the backend throws an error like; ```; HailException: Invalid locus '1:249367215' found. Position '249367215' is not within the range [1-249250621] for reference genome 'GRCh37'.; ```; `import_vcf` should catch and wrap with another exception that suggests you use a `reference_genome` parameter or `hl.default_reference`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13856#issuecomment-1771234741:438,error,error,438,https://hail.is,https://github.com/hail-is/hail/issues/13856#issuecomment-1771234741,2,['error'],['error']
Availability,"We should treat `python-dill` like other images in the `hailgenetics` DockerHub repo and not hard-code our own registry into the docs. I also removed the `batch-worker` image from the publicly available images, not sure why that was in there but it seems wrong.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12230:193,avail,available,193,https://hail.is,https://github.com/hail-is/hail/pull/12230,1,['avail'],['available']
Availability,"We spoke about this in person, but I had this mostly typed up in this buffer so I'll leave it here for future us. Some context on the docker build cache'ing situation. Originally, Docker would use any image layer it had as a cache source. This was noted as a severe security vulnerability because I could make an image that claims to be the result of `apt-get install curl` but actually was the result of `apt-get install virus`. In response, Docker banned the use of non-locally-built (i.e. from the Internet) image layers as cache sources. I believe there may have been other motivations as well, but I did not carefully investigate. https://github.com/moby/moby/issues/26065 documents the desire for a way to use non-locally-built images as a cache source. https://github.com/moby/moby/pull/26839 implements this. Unfortunately, and I cannot find documentation on this, `--cache-from X` means ""cache only from X"". If you pass multiple `--cache-from`s each one is used as a cache source, but it is not possible to say ""use all local images as a cache source"" (other than enumerating them all). [`--cache-from` was included in v1.13.0](https://github.com/moby/moby/releases/tag/v1.13.0), released January 2017. Another subtlety of `--cache-from` is that it does not pull the image in question if it is not found locally. I only found this documented [in a comment on the implementing PR](https://github.com/moby/moby/pull/26839#issuecomment-277383550). Docker seems to be in maintenance mode and all new development is going into Moby. The replacement for `docker build` is called [`buildkit`](https://github.com/moby/buildkit). Build Kit has a more reasonable cache'ing strategy wherein [one exports and imports ones cache](https://github.com/moby/buildkit#exportingimporting-build-cache-not-image-itself) to a trusted repository.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5623#issuecomment-474154073:1476,mainten,maintenance,1476,https://hail.is,https://github.com/hail-is/hail/pull/5623#issuecomment-474154073,1,['mainten'],['maintenance']
Availability,We still have the error log. This produces a lot of logs and I have never used it for debugging purposes.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11978:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/11978,1,['error'],['error']
Availability,"We test against GCP's dataproc product, which, afaik, is using google's [""container optimized OS""](https://cloud.google.com/container-optimized-os/docs/). We also test local-mode with Debian 9.5 (for no particular reason). We don't currently have plans to test other distributions. ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container marked as failed: container_e2435_1542127286896_0109_02_000004 on host: scc-q06.scc.bu.edu. Exit status: 1. Diagnostics: Exception from container-launch.; Container id: container_e2435_1542127286896_0109_02_000004; Exit code: 1; Stack trace: ExitCodeException exitCode=1:; at org.apache.hadoop.util.Shell.runCommand(Shell.java:576); ```. This means the JVM process on the worker node is not successfully starting. My first guess is that we still have not resolved your hail native library issues. What does `ldd --version` return on your leader node and on all of your worker nodes? If those versions are not equal, then hail will not work properly.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-454163838:345,failure,failure,345,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-454163838,2,['failure'],['failure']
Availability,We throw an error if field is nested and the name argument is passed.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5321:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/5321,1,['error'],['error']
Availability,"We tried loading a large bgen file (chr21 - 950k Variants, 150k samples) from UK Biobank. It seemed to proceed ok and generate a VDS file that was loadable, but upon looking at variantqc, it appears that at the large majority of sites, all homref calls are missing. There were no 'tolerance too low' messages while loading, and this property seems to be retained across several runs with difference tolerances.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/714:281,toler,tolerance,281,https://hail.is,https://github.com/hail-is/hail/issues/714,2,['toler'],"['tolerance', 'tolerances']"
Availability,We tried updated to zstd-jni 1.5.5-11 from 1.5.5-2. 4 Failures. [6873](https://batch.hail.is/batches/8093977/jobs/6873) execute(...)_stage2_table_native_writer_job4933	Failed		13s 631ms	$0.0001; [7157](https://batch.hail.is/batches/8093977/jobs/7157) execute(...)_stage2_table_native_writer_job5217	Failed		15s 919ms	$0.0001; [8854](https://batch.hail.is/batches/8093977/jobs/8854) execute(...)_stage2_table_native_writer_job6914	Failed		1 minute 12s	$0.0006; [12795](https://batch.hail.is/batches/8093977/jobs/12795) execute(...)_stage2_table_native_writer_job10855	Failed		21s 305ms	$0.0002,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13979#issuecomment-1843738845:54,Failure,Failures,54,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1843738845,1,['Failure'],['Failures']
Availability,"We used a one off script, an attempt was made to use `Copier.copy`, but that wasn't reliable enough. We also needed to rename destination files beyond what the sync (or copy) tool is capable of.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14601#issuecomment-2214648226:84,reliab,reliable,84,https://hail.is,https://github.com/hail-is/hail/issues/14601#issuecomment-2214648226,1,['reliab'],['reliable']
Availability,"We want to error if the output exists since the combiner will overwrite the output path. However we don't want to do this if the combiner is done, since if the user is rerunning a script with the combiner in the middle of it, they are generally doing some post-processing on the combiner's output and we (and the users) would probably rather just skip the combiner if possible.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14397:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/pull/14397,1,['error'],['error']
Availability,"We want to track Hail's performance with every release for a number of reasons, including but not limited to: ; - Measure how we are doing in delivering value to scientists; - Measure the effect of changes, test our intuition and learn how to improve the product. ; - Compare our solution with others; - Catch unexpected regressions. As of the time of writing, benchmarks are run rarely and have rotted somewhat. There's a bit of work required to get them going again. There's also some work in getting them running in CI and capturing the results. Very roughly, I think work can broken down as follows:; - [ ] get benchmarks passing; - [ ] organise trials with learnings from https://www.zora.uzh.ch/id/eprint/170445/1/emse_smb_cloud.pdf; - [x] run bechmarks in ci on deploy and store the results somewhere appropriate, fail if there's something really awful ; - [ ] visualise results on some appropriate cadance for trends. Might be nice to have a graphic on our github page. . I think many of these can be done in parallel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14221:587,down,down,587,https://hail.is,https://github.com/hail-is/hail/issues/14221,1,['down'],['down']
Availability,"We were getting lots of exceptions when an instance was no longer reachable because it had either been preempted or idled out. The driver could have been offline or the monitor instances / health check loop ran before the activity log monitor was able to process the delete instance events. This PR attempts to tone down the exceptions such that we only get errors for instances that are likely to be zombies (no contact for 5 minutes) rather than normally disappearing instances. However, I do think we should have a separate Grafana alert for when we have lots of instances being deactivated because they couldn't contact the driver as that's a sign of a bigger problem.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12184:316,down,down,316,https://hail.is,https://github.com/hail-is/hail/pull/12184,2,"['down', 'error']","['down', 'errors']"
Availability,"We weren't actually running the tests in QoB previously. I enabled the tests in #14062, but they all still passed even with the error. ```; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_default_arguments; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float64; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_0_and_1; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float32; ```. My guess is our test suite isn't robust enough. I don't think we test with any family relationships -- all unrelated samples.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100:128,error,error,128,https://hail.is,https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100,2,"['error', 'robust']","['error', 'robust']"
Availability,"We weren't actually testing the compaction in test and dev, which is probably why we had those initial errors in production.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13476:103,error,errors,103,https://hail.is,https://github.com/hail-is/hail/pull/13476,1,['error'],['errors']
Availability,We weren't checking for a key even though the docs said the table needed to be keyed. This led to undefined behavior for `distinct`. Not sure what the error mode for `collect_by_key` was.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5548:151,error,error,151,https://hail.is,https://github.com/hail-is/hail/pull/5548,1,['error'],['error']
Availability,"We will get errors about methods not being well formed if we don't define every label on an IEmitCode, so we have to consume each one even if we don't do anything with it. . I also moved `StreamLen` to `emitI`, because we were pointlessly switching back and forth from `EmitCode` to `IEmitCode`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10330:12,error,errors,12,https://hail.is,https://github.com/hail-is/hail/pull/10330,1,['error'],['errors']
Availability,We'll likely use the [ASM library](http://asm.ow2.org/index.html) which is available in [maven](https://mvnrepository.com/artifact/org.ow2.asm/asm-parent/5.1). For:. ```; if cond then cnsq else altr; ```. the emitter should produce the byte code:. ```; COMPILE[[cond]]; ifnull (lengthOf(COMPILE[[cnsq]]) + lengthOf(COMPILE[[altr]]) + 4); checkcast offset_to_java_lang_Boolean_class; invokevirtual offset_to_java_lang_Boolean_booleanValue; ifne (lengthOf(COMPILE[[cnsq]]) + 1); COMPILE[[cnsq]]; COMPILE[[altr]]; checkcast offset_to_resultType; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/813:75,avail,available,75,https://hail.is,https://github.com/hail-is/hail/issues/813,1,['avail'],['available']
Availability,"We're upsetting the robots of the world by not having a `robots.txt` to instruct how they should crawl the website. As retribution, they crawl everything, so this robots.txt doesn't change any indexing behavior but if there's anything we don't want indexed I can add here. Requests for `/robots.txt` and `/favicon.ico` make up a non-trivial amount of site's error logs now, so I also added a symlink to the image we use as our favicon. Hopefully this helps to further quiet the logs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10052:358,error,error,358,https://hail.is,https://github.com/hail-is/hail/pull/10052,1,['error'],['error']
Availability,We've been seeing an error for a little while which may have some similarities to this: [Zulip](https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/SocketException.20when.20writing.20Table/near/355702095),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12980#issuecomment-1534318489:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/issues/12980#issuecomment-1534318489,1,['error'],['error']
Availability,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9593:586,error,errors,586,https://hail.is,https://github.com/hail-is/hail/pull/9593,2,"['down', 'error']","['downloads', 'errors']"
Availability,"We've recently updated from 0.2.126ish to 0.2.130ish, and encountered some teething issues with the new (to us) metadata server. Jobs using `gsutil` failed as their attempts to get credentials from the server resulted in 404. There seems to have been two problems:. 1. As shown (also via `curl`) in [batch 454410](https://batch.hail.populationgenomics.org.au/batches/454410/jobs/1), our `gsutil` queried for `http://169.254.169.254/computeMetadata/v1/instance/service-accounts` (without a final `/`) which resulted in a 404. I don't know if there's a more elegant way for the server to accept both, rather than just adding a route with and without. 2. With that fixed, [batch 454418](https://batch.hail.populationgenomics.org.au/batches/454418/jobs/1) shows a failure within `GetInstanceScopes()`. This is failing because the metadata server does not implement the `â€¦/scopes` endpoint. PR #14019 implemented only so much as is needed for `hail` and `gcloud` to get access tokens for hail GSAs so they can then make API calls to GCS or Hail Batch, but we seem to have needed a bit more. Not sure why you didn't encounter this yourselves: possibly sufficiently different versions of `gsutil` or the cloud SDK, or perhaps you are better at remembering to use `gcloud` rather than `gsutil` than we are!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14566#issuecomment-2132539331:760,failure,failure,760,https://hail.is,https://github.com/hail-is/hail/pull/14566#issuecomment-2132539331,1,['failure'],['failure']
Availability,"We've run into this on Hail Batch 0.2.108. Binaries unfortunately sometimes produce binary output in logs (through `stdout` or `stderr`), e.g. `tabix` does that when it encounters the wrong input format. It appears that Hail Batch doesn't display _any_ log in such circumstances. That makes debugging the underlying issue really hard. For some reason, this seems to specifically happen with the byte value of 128. A simple way to reproduce this is to run the following commands in a batch:. ```python; job.command(""echo 'hi there :)'""); job.command(""echo -n -e '\\x80'""); ```. This will result in a `ERROR: could not find log file`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12614:515,echo,echo,515,https://hail.is,https://github.com/hail-is/hail/issues/12614,3,"['ERROR', 'echo']","['ERROR', 'echo']"
Availability,We've seen this error before on other deployments with no easy fix. I'll continue to investigate over the next couple days and get back to you.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1003#issuecomment-256194596:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/issues/1003#issuecomment-256194596,1,['error'],['error']
Availability,"Website is an aiohttp application which templates docs pages and normal pages. This opens the path; towards unifying the visual appearance of hail.is, the docs, and the services. I simplified documentation generation at the cost of building the docs twice per commit. A new step,; `make_pip_versioned_docs` builds the pip version of the docs without testing them. `make_docs`; continues to work as it did before. The website uses the docs from `make_pip_versioned_docs`. The; GCS docs location is now completely unused. Website has four key folders:. - `website/website/pages/`: Jinja2 templated HTML pages. Served at `/`. - `website/website/docs/`: Hail & Batch docs pages, all HTML pages are templated with Jinja2.; Served at `/docs`. - `website/website/templates/`: Jinaj2 templates that are used in pages or in docs. - `website/website/static/`: Non-templated files. Served at `/static`. The website can be developed locally in or outside of Docker:; ```; make -C website run; ```; or; ```; make -C website rundocker; ```. ---. I had to rename site to website due to a Python package conflict. I also deleted two unused css; files. I also removed PLINK from hail_run_image because it was slowing down my iteration speed; and was a long-term FIXME anyway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10056:1200,down,down,1200,https://hail.is,https://github.com/hail-is/hail/pull/10056,1,['down'],['down']
Availability,"Weird, I can't replicate the `testShuffleIR` failure any more.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9106#issuecomment-664632027:45,failure,failure,45,https://hail.is,https://github.com/hail-is/hail/pull/9106#issuecomment-664632027,1,['failure'],['failure']
Availability,"Weirdly, GCR returns a 500 for an invalid repository name instead of a 404, so we retry it endlessly. We need to special-case our transient errors to treat 500s with ""Invalid repository name"" messages as *not* transient errors, and then give the user the error message that their image repository is invalid. This follows the same pattern that we use for invalid image names.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12152:140,error,errors,140,https://hail.is,https://github.com/hail-is/hail/pull/12152,3,['error'],"['error', 'errors']"
Availability,"Welcome @ryerobinson, and thanks for the Pull Request! Could you report exactly the error that you saw when building hail? `sys_platform!='win32'` is necessary to install the dependencies on Windows, so there is probably an alternative solution to the error that works for all platforms.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1230330783:84,error,error,84,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1230330783,2,['error'],['error']
Availability,"Well yes. What I mean is in an automated fashion. We haven't deployed any builds in around a day because of this error, the deploy job keeps restarting and it was very difficult for me to interrogate what was going on.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5489#issuecomment-468434816:113,error,error,113,https://hail.is,https://github.com/hail-is/hail/pull/5489#issuecomment-468434816,1,['error'],['error']
Availability,Welp. OK. Looks like we're stuck on 6.8.21 forever. I have no idea why the CI is NPE'ing. My local system gives all manner of other inexplicable error messages (mostly about class loading). Things are fine when done through `./gradlew test` though. It's just the test jar that seems broken.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8801#issuecomment-629593668:145,error,error,145,https://hail.is,https://github.com/hail-is/hail/pull/8801#issuecomment-629593668,1,['error'],['error']
Availability,"Wenhan observed this error after I gave her a branch using google cloud storage 2.30.1. I've reported this new transient error to the client API repo, but I doubt it will be fixed. https://github.com/googleapis/java-storage/issues/2337. SSL errors seem like the kind of thing we should not retry forever since they could indicate a bad actor.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14094:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/pull/14094,3,['error'],"['error', 'errors']"
Availability,"Were you using the old copier or the new (not yet merged) `hailctl fs sync`? I had hoped the latter was finally robust enough for real use. `hailtop.aiotools.copy` is indeed not very reliable. Regardless, using the rewrite action when the source and destination agree is the correct move.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14601#issuecomment-2214474849:112,robust,robust,112,https://hail.is,https://github.com/hail-is/hail/issues/14601#issuecomment-2214474849,2,"['reliab', 'robust']","['reliable', 'robust']"
Availability,"What do you mean by ""a maintenance error is generated in Ghost""? I kind of assumed that the website wasn't working right now because the tests finished and `cleanup_deploy_blog` shut down the blog in the PR namespace. The ""endpoint"" that I'm passing in to the `wait` command for the blog in build.yaml is `/`, which *should* do the right thing interally because the URL that's actually being constructed in `wait-for.py` becomes `http://{service}.{namespace}/{namespace}/{service}{endpoint}`, which gives you the right thing. The test failure that I'm running into currently has to do with the fact that the wait command there queries the endpoint without going through either the router or the gateway, (since it's e.g. hitting http://blog.wang/wang/blog/ directly), so it's getting the 301 redirect to https because the `X-Forwarded-Proto` header isn't set. I'm not sure what the right fix is in this case.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7381#issuecomment-548102338:23,mainten,maintenance,23,https://hail.is,https://github.com/hail-is/hail/pull/7381#issuecomment-548102338,4,"['down', 'error', 'failure', 'mainten']","['down', 'error', 'failure', 'maintenance']"
Availability,"What do you mean by validation? . For the 'annotation line' are you suggesting a general error-catching wrapper? I actually really like that, and I'll give it a go. > CNV work; > What I want to do with CNVs is something like ; > ; > ```; > val files: Array[String]; > sc.paralellize(files); > .map { f => readTable(f, config...) }; > .,map (convert to a hail better cnv representation); > ```; > ; > Can't do that if readTable gives you an RDD",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/462#issuecomment-233007740:89,error,error-catching,89,https://hail.is,https://github.com/hail-is/hail/pull/462#issuecomment-233007740,1,['error'],['error-catching']
Availability,"What do you think about converting `Job.regions()` to `Job.tolerations(regions=['us-central1'], pools=['standard', 'highmem'])` where we don't support the `pools` option yet. I'm not in love with this, but it is a different option.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12221#issuecomment-1269917803:59,toler,tolerations,59,https://hail.is,https://github.com/hail-is/hail/pull/12221#issuecomment-1269917803,1,['toler'],['tolerations']
Availability,What does the error look like in Python? Can we add that to transient_errors?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11329#issuecomment-1032033995:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/pull/11329#issuecomment-1032033995,1,['error'],['error']
Availability,"What errors?. I'll run CI on this, but I don't expect the spark 2 stuff to have any problems.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9524#issuecomment-701068245:5,error,errors,5,https://hail.is,https://github.com/hail-is/hail/pull/9524#issuecomment-701068245,1,['error'],['errors']
Availability,"What if all commands were proxied through the gateway api? We already have an authentication layer, with support for 2FA (though in an alpha state, doesn't handle fancier things like merging multiple social accounts). So permissions can be granted on a per-user basis. Currently we can define any scopes for our own APIs, or use Github's available API's (or pass both along to CI). . It may still be useful to have CI grab and validate a gateway-api generated token containing the necessary scopes, although this would add overhead, and may not be as necessary if CI is only available through the gateway api. Another alternative is that it validates against Auth0, but I'd like to reduce/remove that overhead if securely possible.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4556#issuecomment-449069425:338,avail,available,338,https://hail.is,https://github.com/hail-is/hail/issues/4556#issuecomment-449069425,2,['avail'],['available']
Availability,What is the output of this script?. ```; echo $HAIL_HOME; echo $PYTHONPATH; echo $SPARK_CLASSPATH; ```. This might be caused by an incorrect compilation of hail. The output of the above script will tell us more about what to check next.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-337352607:41,echo,echo,41,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337352607,3,['echo'],['echo']
Availability,What might be the issue as I had an error reported while running:. hail importvcf /user/jkoskela/ibd/vcf/v30_ibd_exomes.vcf.bgz splitmulti \. > write -o /user/jkoskela/ibd/hail/v30_split_ibd.vds; > hail: info: running: importvcf /user/jkoskela/ibd/vcf/v30_ibd_exomes.vcf.bgz; > [Stage 0:====================================================>(4569 + 1) / 4570]hail: info: Coerced sorted dataset; > hail: info: running: splitmulti; > hail: info: running: write -o /user/jkoskela/ibd/hail/v30_split_ibd.vds; > [Stage 2:> (0 + 162) / 4570]hail: write: caught exception: org.apache.spark.SparkException: Job aborted. Log can be found in:. /humgen/atgu1/fs03/jkoskela/hail.log,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/913:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/issues/913,1,['error'],['error']
Availability,What were the errors? It should be OK to hold the job object around and e.g. use it to ask for logs even if the job is deleted.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5655#issuecomment-475664544:14,error,errors,14,https://hail.is,https://github.com/hail-is/hail/pull/5655#issuecomment-475664544,1,['error'],['errors']
Availability,Whatever is failing here is likely different from the interval pipeline failures seen in https://github.com/hail-is/hail/issues/13748 and related tickets because GVS team has confirmed that 0.2.126 reduces peak RAM usage from >50GB to 11GB.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960#issuecomment-1791064886:72,failure,failures,72,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1791064886,1,['failure'],['failures']
Availability,"When CI is testing itself, it will start pods in `test`, but `test` is missing the user secret. ```; (hail) dking@wmb16-359 # k get secrets user-jwt-vkqfw -n test ; Error from server (NotFound): secrets ""user-jwt-vkqfw"" not found; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5897#issuecomment-484122046:165,Error,Error,165,https://hail.is,https://github.com/hail-is/hail/pull/5897#issuecomment-484122046,1,['Error'],['Error']
Availability,"When I attempt to rewrite `transform` to use a function, I'm getting a parser error. ```; is.hail.utils.HailException: no conversion found for __uid_1(struct{locus: locus<GRCh38>, alleles: array<str>, rsid: str, qual: float64, filters: set<str>, info: struct{BaseQRankSum: float64, ClippingRankSum: float64, DP: int32, END: int32, ExcessHet: float64, MQ: float64, MQRankSum: float64, MQ_DP: int32, QUALapprox: int32, RAW_MQ: float64, ReadPosRankSum: float64, VarDP: int32}, __entries: array<struct{AD: array<int32>, DP: int32, GQ: int32, GT: call, MIN_DP: int32, PGT: call, PID: str, PL: array<int32>, SB: array<int32>}>}); 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.expr.ir.package$.invoke(package.scala:76); 	at is.hail.expr.ir.IRParser$.ir_value_expr_1(Parser.scala:751); 	at is.hail.expr.ir.IRParser$.ir_value_expr(Parser.scala:517); 	at is.hail.expr.ir.IRParser$.ir_value_expr_1(Parser.scala:718); 	at is.hail.expr.ir.IRParser$.ir_value_expr(Parser.scala:517); 	at is.hail.expr.ir.IRParser$.named_value_ir(Parser.scala:500); 	at is.hail.expr.ir.IRParser$$anonfun$named_value_irs$1.apply(Parser.scala:495); 	at is.hail.expr.ir.IRParser$$anonfun$named_value_irs$1.apply(Parser.scala:495); 	at is.hail.expr.ir.IRParser$.repUntil(Parser.scala:282); 	at is.hail.expr.ir.IRParser$.named_value_irs(Parser.scala:495); 	at is.hail.expr.ir.IRParser$.ir_value_expr_1(Parser.scala:714); 	at is.hail.expr.ir.IRParser$.ir_value_expr(Parser.scala:517); 	at is.hail.expr.ir.IRParser$.table_ir_1(Parser.scala:943); 	at is.hail.expr.ir.IRParser$.table_ir(Parser.scala:850); 	at is.hail.expr.ir.IRParser$.table_ir_1(Parser.scala:942); 	at is.hail.expr.ir.IRParser$.table_ir(Parser.scala:850); 	at is.hail.expr.ir.IRParser$$anonfun$table_ir_children$1.apply(Parser.scala:846); 	at is.hail.expr.ir.IRParser$$anonfun$table_ir_children$1.apply(Parser.scala:846); 	at is.hail.expr.ir.IRParser$.repUntil(Parser.scala:282); 	at is.ha",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5435#issuecomment-467547718:78,error,error,78,https://hail.is,https://github.com/hail-is/hail/pull/5435#issuecomment-467547718,3,"['Error', 'error']","['ErrorHandling', 'error']"
Availability,"When I last tried to fix this up, I somehow missed the GCS client dependency. This; uses the in cluster location if it is available otherwise it lets Google try to find; the key.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8652:122,avail,available,122,https://hail.is,https://github.com/hail-is/hail/pull/8652,1,['avail'],['available']
Availability,"When I ran the tutorial with the downloadable 'data/1kg.vds', it throws a fatal error ; ``HailException: Invalid VDS: old version [4]; Recreate VDS with current version of Hail.``. Would it be possible for you to provide an updated VDS or the underlying VCF to build a new VDS? I'm running Hail version devel-6d7d270",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2067:33,down,downloadable,33,https://hail.is,https://github.com/hail-is/hail/issues/2067,2,"['down', 'error']","['downloadable', 'error']"
Availability,"When I run the current GRM with BlockMatrix locally on profile225.hardcalls.vds (2535 samples, 225k variants), I get:. ```; java.lang.ArrayIndexOutOfBoundsException: 1048578; ```. When I run on profile.hardcalls.vds (only 25k variants), I get:. ```; java.lang.OutOfMemoryError: Java heap space; ```. When I cut profile down to only 10k variants, grm takes about 66s:. ```; read: 1.874s; grm: 1m5.9s; ```. The respective numbers using this PR are 9m36s, 39s, and 12s (so a ~5x speedup in the last case). I'd like to try this on a cluster as well with profile225k. Comparing the output for 10k, the doubles look to agree to around 16 digits (we print a 2 or 3 more than that). The computeGrammianMatrix function is used by Spark SVD for tall-skinny matrices. It's defined on RowMatrix as:. ```; def computeGramianMatrix(): Matrix = {; val n = numCols().toInt; checkNumColumns(n); // Computes n*(n+1)/2, avoiding overflow in the multiplication.; // This succeeds when n <= 65535, which is checked above; val nt: Int = if (n % 2 == 0) ((n / 2) * (n + 1)) else (n * ((n + 1) / 2)). // Compute the upper triangular part of the gram matrix.; val GU = rows.treeAggregate(new BDV[Double](new Array[Double](nt)))(; seqOp = (U, v) => {; RowMatrix.dspr(1.0, v, U.data); U; }, combOp = (U1, U2) => U1 += U2). RowMatrix.triuToFull(n, GU.data); }; ```. dspr calls to the corresponding BLAS Level 2 command, which updates A to A + x.t \* x in place:; http://www.netlib.org/lapack/explore-html/d7/d15/group__double__blas__level2_ga22adb497a4f41eabc6a8dcac6f326183.html#ga22adb497a4f41eabc6a8dcac6f326183. Down the line we might also consider using BLAS level 3 dsyrk on each partition, which updates A to A + B.t \* B:; http://www.netlib.org/lapack/explore-html/d1/d54/group__double__blas__level3_gae0ba56279ae3fa27c75fefbc4cc73ddf.html#gae0ba56279ae3fa27c75fefbc4cc73ddf. @cseed The ArrayIndex exception on profile225k in the current master is concerning, and may be related to serialization. Here is the full stack t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/801#issuecomment-247861703:319,down,down,319,https://hail.is,https://github.com/hail-is/hail/pull/801#issuecomment-247861703,2,['down'],['down']
Availability,"When I test this, I get; ```; FatalError: IllegalFormatConversionException: d != java.lang.String. Java stack trace:; is.hail.utils.HailException: Encountered invalid type for format string %d: format specifier d does not accept type java.lang.String; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:15); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:15); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.expr.ir.functions.UtilFunctions$.format(UtilFunctions.scala:168); 	at __C12Compiled.__m15format(Emit.scala); ... java.util.IllegalFormatConversionException: d != java.lang.String; 	at java.util.Formatter$FormatSpecifier.failConversion(Formatter.java:4302); 	at java.util.Formatter$FormatSpecifier.printInteger(Formatter.java:2793); 	at java.util.Formatter$FormatSpecifier.print(Formatter.java:2747); 	at java.util.Formatter.format(Formatter.java:2520); 	at java.util.Formatter.format(Formatter.java:2455); 	at java.lang.String.format(String.java:2940); 	at is.hail.expr.ir.functions.UtilFunctions$.format(UtilFunctions.scala:165); 	at __C12Compiled.__m15format(Emit.scala); ... Hail version: 0.2.74-4d495f1c5e01; Error summary: IllegalFormatConversionException: d != java.lang.String; ```. Why is the summary not the `HailException` string?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10827:270,Error,ErrorHandling,270,https://hail.is,https://github.com/hail-is/hail/pull/10827,5,['Error'],"['Error', 'ErrorHandling']"
Availability,"When I try applying this patch:. ```diff; diff --git a/batch/batch/worker/worker.py b/batch/batch/worker/worker.py; index 9d3d89498b..a9106b7a60 100644; --- a/batch/batch/worker/worker.py; +++ b/batch/batch/worker/worker.py; @@ -1228,22 +1228,28 @@ class Container:; return config; ; async def _get_in_container_user(self) -> Tuple[int, int]:; + # https://docs.docker.com/engine/reference/builder/#user; assert self.image.image_config; user = self.image.image_config['Config']['User']; if not user:; return 0, 0; if "":"" in user:; - uid, gid = user.split("":""); - else:; - uid, gid = await self._read_user_from_rootfs(user); - return int(uid), int(gid); + user, group = user.split("":""); + try:; + return int(user), int(group); + except ValueError:; + return await self._read_uid_gid_from_rootfs(user); + try:; + return int(user), 0; + except ValueError:; + return await self._read_uid_gid_from_rootfs(user); ; - async def _read_user_from_rootfs(self, user) -> Tuple[str, str]:; + async def _read_uid_gid_from_rootfs(self, user: str) -> Tuple[int, int]:; with open(f'{self.image.rootfs_path}/etc/passwd', 'r', encoding='utf-8') as passwd:; for record in passwd:; if record.startswith(user):; _, _, uid, gid, _, _, _ = record.split("":""); - return uid, gid; + return int(uid), int(gid); raise ValueError(""Container user not found in image's /etc/passwd""); ; def _mounts(self, uid: int, gid: int) -> List[MountSpecification]:; ```. I can run the container successfully but it fails with the following error:. ```; mkdir: cannot create directory '/io/batch': Permission denied; ```. Which is caused by the following line inserted by the `hailtop.batch` client library:. ```; mkdir -p /io/batch/4c8107/NjztN; ```. so images with non-existent users would fail to run on batch regardless of whether we were using crun / docker / podman, because Batch assumes that the user in the container will have permission to write to `/io`, regardless of whether the job requires input/output files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13679#issuecomment-1728424448:1495,error,error,1495,https://hail.is,https://github.com/hail-is/hail/issues/13679#issuecomment-1728424448,1,['error'],['error']
Availability,"When I was writing `hailctl batch init`, I used that method to parse the remote_tmpdir to check if the bucket existed and to add permissions. I kept getting errors because my remote_tmpdir was `gs://hail-jigold-random-token` and I didn't specify a path name beyond the bucket name.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13435#issuecomment-1679759856:157,error,errors,157,https://hail.is,https://github.com/hail-is/hail/pull/13435#issuecomment-1679759856,1,['error'],['errors']
Availability,"When accessing two VDS files in `gs://hail-common/`, I got two errors. 1. gs://hail-common/all_coding_plus_minus_50bp_vep.vds. ```; File ""<decorator-gen-162>"", line 2, in read; File ""/home/ec2-user/BuildAgent/work/c38e75e72b769a7c/python/hail/java.py"", line 113, in handle_py4j; hail.java.FatalError: HailException: missing partitioner.json.gz when loading VDS, create with HailContext.write_partitioning. Java stack trace:; is.hail.utils.HailException: missing partitioner.json.gz when loading VDS, create with HailContext.write_partitioning.; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:20); 	at is.hail.variant.VariantDataset$.liftedTree1$1(VariantDataset.scala:89); 	at is.hail.variant.VariantDataset$.read(VariantDataset.scala:84); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:414); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:413); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.HailContext.readAll(HailContext.scala:413); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractC",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1683:63,error,errors,63,https://hail.is,https://github.com/hail-is/hail/issues/1683,3,"['Error', 'error']","['ErrorHandling', 'errors']"
Availability,When building hail from source on an Apple M1 MacBook Pro . `make install HAIL_COMPILE_NATIVES=1 `. I get . ```; /Library/Developer/CommandLineTools/usr/bin/make -C src/main/c prebuilt; c++ -march=native -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/Library/Java/JavaVirtualMachines/jdk-17.0.1.jdk/Contents/include -I/Library/Java/JavaVirtualMachines/jdk-17.0.1.jdk/Contents/include/darwin testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; clang: error: the clang compiler does not support '-march=native'; ```. This issue is related specifically to new MacBook hardware and not hail itself but I cannot find an obvious way to fix this from searching online. Has anyone seen this and know how to resolve the issue?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11729:554,error,error,554,https://hail.is,https://github.com/hail-is/hail/issues/11729,1,['error'],['error']
Availability,"When buliding hail , There are several problems ï¼Œplease helpï¼Œthanks. [root@**\* hail]# gradle shadowJar; Using a seed of [1] for testing.; Build file '/**_/hail/build.gradle': line 188; useAnt has been deprecated and is scheduled to be removed in Gradle 3.0. The Ant-Based Scala compiler is deprecated, please see https://docs.gradle.org/current/userguide/scala_plugin.html.; :compileJava UP-TO-DATE; :compileScala; /**_/hail/src/main/scala/org/broadinstitute/hail/expr/AST.scala:135: not enough arguments for constructor AnnotationPathException: (msg: String)org.broadinstitute.hail.annotations.AnnotationPathException; throw new AnnotationPathException(); ^; /**_/hail/src/main/scala/org/broadinstitute/hail/expr/AST.scala:153: not enough arguments for constructor AnnotationPathException: (msg: String)org.broadinstitute.hail.annotations.AnnotationPathException; throw new AnnotationPathException(); ^; /**_/hail/src/main/scala/org/broadinstitute/hail/expr/AST.scala:162: not enough arguments for constructor AnnotationPathException: (msg: String)org.broadinstitute.hail.annotations.AnnotationPathException; throw new AnnotationPathException(); ^; /**_/hail/src/main/scala/org/broadinstitute/hail/expr/AST.scala:661: not enough arguments for constructor AnnotationPathException: (msg: String)org.broadinstitute.hail.annotations.AnnotationPathException; case None => throw new AnnotationPathException(); ^; /**_/hail/src/main/scala/org/broadinstitute/hail/expr/AST.scala:753: not enough arguments for constructor AnnotationPathException: (msg: String)org.broadinstitute.hail.annotations.AnnotationPathException; throw new AnnotationPathException(); ^; 5 errors found; :compileScala FAILED. FAILURE: Build failed with an exception.; - What went wrong:; Execution failed for task ':compileScala'.; ; > Compilation failed; - Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 39.537 secs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/454:1656,error,errors,1656,https://hail.is,https://github.com/hail-is/hail/issues/454,2,"['FAILURE', 'error']","['FAILURE', 'errors']"
Availability,"When commands are submitted there's currently an error when I don't provide the proper arguments for a function. This way I don't waste time running things only to have the job crash after it's been going for a while. There should be similar functionality when I submit a command that tries to filter by/annotate with a file that doesn't exist. If you can distinguish when this file will be automatically generated by earlier commands in the script, then that would be nice. If not, then you could just have a warning if the command line has a function using a file that doesn't currently exist.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/413:49,error,error,49,https://hail.is,https://github.com/hail-is/hail/issues/413,1,['error'],['error']
Availability,"When creating a global map using annotateglobal exprbysample, any variant annotation after that fails by Map not serializable error",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1179:126,error,error,126,https://hail.is,https://github.com/hail-is/hail/issues/1179,1,['error'],['error']
Availability,"When loading a plink binary file, if the delimiter is incorrect it currently fails with the following cryptic error:. caught scala.MatchError: [Ljava.lang.String;@459f703f (of class [Ljava.lang.String;). This was a file with spaces (where the default is tab). As space seems to be the default for plink2, which was used to make these files, it may be worth allowing either by default.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/709:110,error,error,110,https://hail.is,https://github.com/hail-is/hail/issues/709,1,['error'],['error']
Availability,"When the kube event loop fails, it should be restarted by `run_forever`. Understanding why we lose connection to k8s seems fruitful and important, but does not explain why batch becomes unstable / non-communicative after a kube event loop failure.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4984#issuecomment-450915405:239,failure,failure,239,https://hail.is,https://github.com/hail-is/hail/issues/4984#issuecomment-450915405,1,['failure'],['failure']
Availability,"When the number of fields in `x` is really huge, this optimization creates huge chains of `Let` bindings which cause stack size issues in downstream IR analysis passes. (we can remove this cap once our passes will no longer run into stack size issues on very deep IRs.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7726:138,down,downstream,138,https://hail.is,https://github.com/hail-is/hail/pull/7726,1,['down'],['downstream']
Availability,When the user fails to provide a lambda to an aggregation; they now receive a suggestion to use a lambda rather than; a Scala match error. @tpoterba this should hold us over until we have something nicer like that `projectT` function. resolves #786,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/788:132,error,error,132,https://hail.is,https://github.com/hail-is/hail/pull/788,1,['error'],['error']
Availability,"When trying to create a dataproc cluster using the results of `make -C hail install-editable` and `make -C hail install-hailctl`, the Jupyter server can't be connected to because it runs into the error described [here](https://stackoverflow.com/questions/77549493/modulenotfounderror-no-module-named-jupyter-server-contents). This change bumps the version of `notebook` that we use in the `init_notebook.py` script in order to make that work again.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14563:196,error,error,196,https://hail.is,https://github.com/hail-is/hail/pull/14563,1,['error'],['error']
Availability,"When trying to lift over the gnomAD 3.1 hail table to GRCh37, I encounter the error mentioned above. This code works:. ```python; import hail as hl. hail_table = 'gs://gcp-public-data--gnomad/release/3.1.1/ht/genomes/gnomad.genomes.v3.1.1.sites.ht'; chain_file = 'gs://hail-common/references/grch38_to_grch37.over.chain.gz'; ht = hl.read_table(hail_table).head(10_000). GRCh37 = hl.get_reference('GRCh37'); GRCh38 = hl.get_reference('GRCh38'); GRCh38.add_liftover(chain_file, GRCh37). hl.eval(hl.liftover(hl.locus('chr1', 1034245, 'GRCh38'), 'GRCh37')); # Locus(contig=1, position=969625, reference_genome=GRCh37); ```. However, when trying to lift over the entire table it fails:; ```; ht = ht.annotate(; locus_GRCh37 = hl.liftover(ht.locus, 'GRCh37'); ); ht.show(); ```. I got the same error when trying to lift over an older gnomAD version (2.1) from GRCh37 to GRCh38, which used to work according to my best knowledge. Also, this way of lifting over a hail table is following the recommended process on the documentation [here](https://hail.is/docs/0.2/guides/genetics.html?highlight=prs#liftover-variants-from-one-coordinate-system-to-another). I'm quite confident there must be something I'm doing wrong, but now I'm stuck, any help would be highly welcome. Thanks!. The code is running on a Google Cloud Dataproc cluster, Python 3.8, hail version: `'0.2.71-f3a54b530979'`. Error stack:; ```python; --------------------------------------------------------------------------- / 1]; FatalError Traceback (most recent call last); /opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj); 700 type_pprinters=self.type_printers,; 701 deferred_pprinters=self.deferred_printers); --> 702 printer.pretty(obj); 703 printer.flush(); 704 return stream.getvalue(). /opt/conda/miniconda3/lib/python3.8/site-packages/IPython/lib/pretty.py in pretty(self, obj); 392 if cls is not object \; 393 and callable(cls.__dict__.get('__repr__')):; --> 394 return _repr_pprint(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:78,error,error,78,https://hail.is,https://github.com/hail-is/hail/issues/10682,2,['error'],['error']
Availability,"When using this command `filtervariants -c /user/xiaoli/LCR-hs37d5.interval_list --remove`, I got this error message: ; `hail: filtervariants: caught exception: scala.MatchError: [Ljava.lang.String;@56d822dc (of class [Ljava.lang.String;)`. The input file is formatted:; 1 1 10000; 1 10016 10464; 1 10656 10784; 1 28576 28603; 1 30852 30959; 1 31712 31733; 1 33440 33464; 1 33504 33541. It might be because that it cannot take tab delimited file with only three columns. At least we need a clear warning message.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/319:103,error,error,103,https://hail.is,https://github.com/hail-is/hail/issues/319,1,['error'],['error']
Availability,"When we attempt to build the vep 95 docker image, we have issues installing LibXML causing later failures. Not sure why this is happening.; From https://batch.hail.is/batches/8209583/jobs/27; ```; #13 423.5 Building and testing XML-LibXML-2.0210 ... ! Installing XML::LibXML failed. See /root/.cpanm/work/1727981951.12888/build.log for details. Retry with --force to force install it.; #13 453.0 FAIL; ```; leading to; ```; #13 724.7 ! Installing the dependencies failed: Module 'XML::LibXML' is not installed, Module 'XML::LibXML::Reader' is not installed; #13 724.7 ! Bailing out the installation for BioPerl-1.7.8.; #13 724.7 ! Installing the dependencies failed: Module 'Bio::Root::Version' is not installed; #13 724.7 ! Bailing out the installation for Bio-BigFile-1.07.; #13 724.7 63 distributions installed; #13 ERROR: executor failed running [/bin/sh -c export KENT_SRC=$PWD/kent-335_base/src && export MACHTYPE=$(uname -m) && export CFLAGS=""-fPIC"" && export MYSQLINC=""mysql_config --include | sed -e 's/^-I//g'"" && export MYSQLLIBS=""mysql_config --libs"" && wget https://github.com/ucscGenomeBrowser/kent/archive/v335_base.tar.gz && tar xzf v335_base.tar.gz && cd $KENT_SRC/lib && echo 'CFLAGS=""-fPIC""' > ../inc/localEnvironment.mk && make clean && make && cd ../jkOwnLib && make clean && make && mkdir -p $VEP_DIR/cpanm && export PERL5LIB=\$PERL5LIB:$HOME/cpanm/lib/perl5 && cpanm Bio::DB::BigFile]: exit code: 1; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14710:97,failure,failures,97,https://hail.is,https://github.com/hail-is/hail/issues/14710,3,"['ERROR', 'echo', 'failure']","['ERROR', 'echo', 'failures']"
Availability,"When we download files from GCS, they lose their permissions. Git complains and then the checkout fails.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10414:8,down,download,8,https://hail.is,https://github.com/hail-is/hail/pull/10414,1,['down'],['download']
Availability,When will it be available to use?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14375#issuecomment-1972078374:16,avail,available,16,https://hail.is,https://github.com/hail-is/hail/pull/14375#issuecomment-1972078374,1,['avail'],['available']
Availability,"When workers shut down, we get warning logs about unclosed client sessions, as seen in #14261. While it can be difficult to derive the source of the client session, I think it's the one held by the `GCPWorkerAPI`. I've added an exit stack and added the session's close method to it. I also made a small change to `Worker`. I find it can be difficult to determine whether or not a particular class should close a client session because it's not always clear who owns it. Without a clear way to communicate this in python, I think we should just never transfer ownership of a `ClientSession` and always assume that if an object's constructor takes a client session, it should be assumed a borrow and not close the session when the object is closed. As such, I moved the call to `client_session()` into the `Worker` constructor so it's clear that the worker owns the session.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14418:18,down,down,18,https://hail.is,https://github.com/hail-is/hail/pull/14418,1,['down'],['down']
Availability,"Whenever the batch driver shuts down we have some errors due to unclosed aiohttp `ClientSession`s. Deploying the driver in asyncio debug mode revealed that these sessions were in the `ComputeClient` and `LoggingClient`, which we don't call `close` on (and we don't use them as context managers). After this change I was able to delete my driver pod without any unclosed client session errors (though plenty of cancelled errors, which is a separate issue.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10634:32,down,down,32,https://hail.is,https://github.com/hail-is/hail/pull/10634,4,"['down', 'error']","['down', 'errors']"
Availability,"Which exception was being masked?. We currently use this `deserialize` function to construct reader/writer classes, like MatrixVCFReader. This class does a bunch of work on construction, including throwing user-facing errors. Wrapping these errors in a `MappingException` (which becomes the top-level error, and the one in the summary in Python) is wrong. Obscuring full stack traces is wrong too. The correct thing is to stop doing a bunch of work on class construction, but until we make that change, I think that right now, we should continue peeling off the mapping exception",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6156#issuecomment-494809361:26,mask,masked,26,https://hail.is,https://github.com/hail-is/hail/pull/6156#issuecomment-494809361,4,"['error', 'mask']","['error', 'errors', 'masked']"
Availability,"While I was running the script shown below. I got the error message. I attach the log file. Do you know what cause the errors ? Thanks . ```; hail -l /medpop/afib/schoi/projects/TOPMed/Script/log/TopMed.Chr22.QC.vds.log \; importvcf file:///medpop/afib/schoi/projects/TOPMed/Data/BROAD/Link/Chr22/*.bgz splitmulti \; filtervariants expr -c 'v.contig == ""X"" || v.contig == ""Y"" || v.contig == ""MT""' --remove \; filtersamples list -i file:///medpop/afib/schoi/projects/TOPMed/Result/TopMed_nodup.6998.sample.map --keep \; sampleqc -o file:///medpop/afib/schoi/projects/TOPMed/Result/SampleQC/chrom/TOPMed.PreQC.sampleqc.chr22.tsv \; variantqc -o file:///medpop/afib/schoi/projects/TOPMed/Result/VariantQC/chrom/TOPMed.PreQC.variantqc.chr22.tsv \; annotatevariants expr -c 'va.info.AC = va.info.AC[va.aIndex]' \; filtergenotypes -c '(g.ad[0] + g.ad[1]) / g.dp < 0.9 || (g.isHomRef && (g.ad[0] / g.dp < 0.9 || g.gq < 20)) || (g.isHet && (g.ad[1] / g.dp < 0.20 || g.pl[0] < 20)) || (g.isHomVar && (g.ad[1] / g.dp < 0.9 || g.pl[0] < 20)) || g.dp > 200' --remove \; variantqc -o file:///medpop/afib/schoi/projects/TOPMed/Result/VariantQC/chrom/TOPMed.QCstep1.variantqc.Chr22.tsv \; annotatevariants intervals -r va.isLCF -i file:///medpop/afib/schoi/projects/TOPMed/Data/LCR/LCR.interval_list \; annotatevariants expr -c 'va.AC1 = va.qc.AC,; va.good = ((va.info.QD > 3 && v.altAllele.isIndel) || (va.info.QD > 2 && v.altAllele.isSNP)) && (va.qc.callRate > 0.95)' \; annotateglobal expr -c 'global.badVQSLOD = variants.count(va.pass),; global.badQD = variants.count((va.info.QD <= 3 && v.altAllele.isIndel) || (va.info.QD <= 2 && v.altAllele.isSNP)),; global.badCallRate = variants.count(va.qc.callRate <= 0.95),; global.nIndel_1 = variants.count(v.altAllele.isIndel && va.AC1 > 0),; global.nSNP_1 = variants.count(v.altAllele.isSNP && va.AC1 > 0),; global.nIndel_2 = variants.count(v.altAllele.isIndel && va.AC1 > 0 && va.pass),; global.nSNP_2 = variants.count(v.altAllele.isSNP && va.AC1 > 0 && va.pass),; gl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/660:54,error,error,54,https://hail.is,https://github.com/hail-is/hail/issues/660,2,['error'],"['error', 'errors']"
Availability,"While only used in a few places, this helps us generate; much better code in the case where we emit error-checking; IRs as below:. ```; If; <error_condition>; Die err_msg; <value we want>; ```. The code generator for the `If` node uses `SType.canonical` to; choose its result type, and casts both consequent and alternate; values to that type. We want the stype of the result here to be; the type of the alternate `<value we want>`, which we can achieve; by adding unreachable types/codes for the `SType.canonical` logic.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10539:100,error,error-checking,100,https://hail.is,https://github.com/hail-is/hail/pull/10539,1,['error'],['error-checking']
Availability,"While running QoB jobs, we observed some errors relating to compression validation or unexpected end of line/file. It was suggested that after certain errors, the reader may be in an unsuable state, so we recreate it after an error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13371:41,error,errors,41,https://hail.is,https://github.com/hail-is/hail/pull/13371,3,['error'],"['error', 'errors']"
Availability,"While running mendel_errors:; ```; hail.utils.java.FatalError: ClassCastException: is.hail.codegen.generated.C71 cannot be cast to is.hail.asm4s.AsmFunction7. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 143 in stage 13.0 failed 20 times, most recent failure: Lost task 143.19 in stage 13.0 (TID 4198, exomes2-sw-k2p2.c.broad-mpg-gnomad.internal, executor 212): java.lang.ClassCastException: is.hail.codegen.generated.C71 cannot be cast to is.hail.asm4s.AsmFunction7; 	at is.hail.expr.MatrixFilterEntries$$anonfun$54.apply(Relational.scala:1752); 	at is.hail.expr.MatrixFilterEntries$$anonfun$54.apply(Relational.scala:1750); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); [...]; 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:935); 	at is.hail.sparkextras.ContextRDD.collect(ContextRDD.scala:132); 	at is.hail.rvd.OrderedRVD$.getPartitionKeyInfo(OrderedRVD.scala:478); 	at is.hail.rvd.OrderedRVD$.getPartitionKeyInfo(OrderedRVD.scala:488); 	at is.hail.rvd.OrderedRVD$.coerce(OrderedRVD.scala:556); 	at is.hail.rvd.OrderedRVD$.coerce(OrderedRVD.scala:514); 	at is.hail.table.Table.toOrderedRVD(Table.scala:1152); 	at is.hail.table.Table.distinctByKey(Table.scala:540); 	at sun.reflect.Nati",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446:236,failure,failure,236,https://hail.is,https://github.com/hail-is/hail/issues/3446,2,['failure'],['failure']
Availability,"While this seems to currently be a functioning improvement on what we had before, it's still slower than I'd like it to be for Jacob's use case and getting unexpected OOM errors, working on it now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6723#issuecomment-515481261:171,error,errors,171,https://hail.is,https://github.com/hail-is/hail/pull/6723#issuecomment-515481261,1,['error'],['errors']
Availability,"While trying to fix some weird errors, I realized this was more complicated than necessary and, I; think, broken. In the new implementation, a BatchPoolFuture is a thin wrapper around an asyncio.Future. Instead of; tracking the value and any exceptions manually, the BatchPoolFuture relies on asyncio.Future. I think the diff is not very helpful, just look at the new, simpler implementation. I also forgot to close the ServiceBackend, I now do that in the cleanup method that happens after all future complete.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10322:31,error,errors,31,https://hail.is,https://github.com/hail-is/hail/pull/10322,1,['error'],['errors']
Availability,"While working on Hail Query on Hail Batch, I frequently encountered transient; errors in rmtree when cleaning up temporary cloud directories. This change; ensures rmtree is resilient to such failures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10935:79,error,errors,79,https://hail.is,https://github.com/hail-is/hail/pull/10935,3,"['error', 'failure', 'resilien']","['errors', 'failures', 'resilient']"
Availability,"Whoa, it worked. I included one change that might have warranted re-review. I was getting errors becomes some Jobs, on which delete had been called, were still being used. I tracked it down to a recent cancel => delete change in `PR.update_from_completed_batch_job`. If look at that function, it is clear delete is not OK because in several cases the build object keep a handle to the job. I reverted it, and now clear all the fields of Job when it is deleted. https://github.com/hail-is/hail/pull/5655/files#diff-433f83d97fa8a526a3f8cff52590e422R479; https://github.com/hail-is/hail/pull/5655/files#diff-0c1f876ad25335b076837f768f727566R59",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5655#issuecomment-475474180:90,error,errors,90,https://hail.is,https://github.com/hail-is/hail/pull/5655#issuecomment-475474180,4,"['down', 'error']","['down', 'errors']"
Availability,Why did you need to add back `downcastToPK` and `upcast`? I tried to make those unnecessary with `KeyedOrderedRVD`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3186#issuecomment-375789138:30,down,downcastToPK,30,https://hail.is,https://github.com/hail-is/hail/pull/3186#issuecomment-375789138,1,['down'],['downcastToPK']
Availability,Why do delete and query throw errors whenever the path is non-empty? Is there some magic recursion happening to prune to move to the end of the path?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1007#issuecomment-257220862:30,error,errors,30,https://hail.is,https://github.com/hail-is/hail/pull/1007#issuecomment-257220862,1,['error'],['errors']
Availability,"Why prefer nodeSelector to tolerations/taints?. I thought we would have two taints: preemptible, non-preemptible. Pods must tolerate at least one (in practice, pods will tolerate no more than one). If a pod has no toleration, it is unscheduable. In this setting, Pods must set nodeSelector to exactly one of preemptible, non-preemptible. If they specify no nodeSelector, they'll be scheduled anywhere. It seems like the main difference is if we forget to specify the kind of pod this is. I feel like we should prefer the unscheduable case, rather than silently working. Are there other motivations for changing to nodeSelector? If someone accidentally tolerates two taints, that will jump out more in code review.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7636#issuecomment-560586209:27,toler,tolerations,27,https://hail.is,https://github.com/hail-is/hail/pull/7636#issuecomment-560586209,5,['toler'],"['tolerate', 'tolerates', 'toleration', 'tolerations']"
Availability,Why would we want the behavior to be that a user has to explicitly cancel batches on a failure? This code already does that:. ```python3; async def async_result_or_cancel_all(future):; try:; return await future.async_result(timeout=timeout); except Exception as err:; for fut in futures:; fut.cancel(); raise err; if chunksize > 1:; return (val; for future in futures; for val in await async_result_or_cancel_all(future)); return (await async_result_or_cancel_all(future); for future in futures); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10761#issuecomment-894501440:87,failure,failure,87,https://hail.is,https://github.com/hail-is/hail/pull/10761#issuecomment-894501440,1,['failure'],['failure']
Availability,"Will merge cleanly when https://github.com/hail-is/hail/pull/3560 lands. I needed to remove `RegionValue.copy` and `Region.copy` because they necessarily create regions that aren't managed by an `RVDContext`. `RegionValue.copy` is only used in three places. . - `Table.toMatrixTable`: Here, I took the somewhat inefficient choice of creating `SafeRow`s. If `toMatrixTable` is a performance bottleneck, we might want to reconsider this. It's not totally obvious how to do this. I think I'd need to explicitly serialize/deserialize these values and modify `reduceByKey` to explicitly provide the `RVDContext`. Anyway, this works and I don't think it's _that_ slow. (I guess I should check that). - `OrderedRVD.localKeySort` & `LocalLDPrune.pruneLocal`: in both cases we need keep a handful of region values around per-partition. This does not lend itself to region-based-allocation. I solve this with two copies and a fresh region per value. Putting a value into `localKeySort`'s queue requires copying it into a fresh region. Taking a value out of the queue requires copying it into the consumer's region and closing/freeing the region it was living in. There fresh region is alive as long as the value is in the queue. I had to modify `RVDContext` to track `Region`s that get closed early. This seems a bit inefficient. Maybe I should track children as a `Set`?. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3579:1175,alive,alive,1175,https://hail.is,https://github.com/hail-is/hail/pull/3579,1,['alive'],['alive']
Availability,"With Hail 0.2-721af83bc30a, it is now getting a java heap space error.... ipython vcf2mt.py 22; ```; Running on Apache Spark version 2.2.1; SparkUI available at http://10.48.225.55:4041; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2-721af83bc30a; LOGGING: writing to /restricted/projectnb/ukbiobank/ad/analysis/ad.v1/hail-20181113-2115-0.2-721af83bc30a.log; Converting vcf /project/ukbiobank/imp/ad.v1/vcf/ukbb.hg38.imputed.chr22.dose.vcf.gz to mt /project/ukbiobank/imp/ad.v1/mt/ukbb.hg38.imputed.chr22.mt; [Stage 1:====> (59 + 24) / 741]---------------------------------------------------------------------------; FatalError Traceback (most recent call last); /restricted/projectnb/ukbiobank/ad/analysis/ad.v1/vcf2mt.py in <module>; 6 mt=""/project/ukbiobank/imp/ad.v1/mt/ukbb.hg38.imputed.chr""+chr+"".mt""; 7 print(""Converting vcf ""+vcf+"" to mt ""+ mt); ----> 8 hl.import_vcf(vcf,force_bgz=True).write(mt). <decorator-gen-891> in write(self, output, overwrite, stage_locally, _codec_spec). /share/pkg/hail/2018-10-31/install/build/distributions/hail-python.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561; 562 return wrapper. /share/pkg/hail/2018-10-31/install/build/distributions/hail-python.zip/hail/matrixtable.py in write(self, output, overwrite, stage_locally, _codec_spec); 2146 """"""; 2147; -> 2148 self._jvds.write(output, overwrite, stage_locally, _codec_spec); 2149; 2150 def globals_table(self) -> Table:. /share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /share/pkg",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635:64,error,error,64,https://hail.is,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635,2,"['avail', 'error']","['available', 'error']"
Availability,"With [this code](https://github.com/hail-is/hail/blob/81b0b20ea96278ca74c17b7618d53c330a5ee15f/hail/src/main/scala/is/hail/backend/service/Worker.scala#L182) commented out, error looks like [this](https://gist.github.com/iris-garden/33e7b0508f06f7e6aa4c17bd8c4d92b7)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12468#issuecomment-1834392857:173,error,error,173,https://hail.is,https://github.com/hail-is/hail/pull/12468#issuecomment-1834392857,1,['error'],['error']
Availability,"With google, we're only seeing 429s, our transient error code has some of the cases:. https://github.com/hail-is/hail/blob/2e9ca86bfdca9cb29ae18cf5cecbe04828bb4bd3/hail/python/hailtop/utils/utils.py#L642-L645",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14595#issuecomment-2201432395:51,error,error,51,https://hail.is,https://github.com/hail-is/hail/issues/14595#issuecomment-2201432395,1,['error'],['error']
Availability,"Without these changes, my IDE cannot deduce that the return value of, say, `select` is a `Table` which prevents jump-to-definition on subsequent method calls. I also received an error about `Table.collect` returning an `ArrayExpression` which it will only do when `_localize=False`. `overload` teaches this fact to the type system. I didn't use the specific expression in `base_expression.py` because that would require an import circularity.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13468:178,error,error,178,https://hail.is,https://github.com/hail-is/hail/pull/13468,1,['error'],['error']
Availability,"Without this `make test-local` fails because there is no running server. This ensures that `make test-local` first starts a server to test against. Recreated for stacked PRs from #4785. ---. The `until curl ...` nonsense is because the server takes some time to start up, so we poll until we get a successful return value from `curl`. `-f` means return non-zero-exit-code on failure. `-L` means follow redirects (not really necessary here, but I think it's good practice to use `-L`). `BATCH_USE_KUBE_CONFG=1` tells batch to use the latent kubernetes configuration, which means the developer must already have set up `kubectl`. This is a reasonable expectation for a developer of `batch`. The `trap cleanup EXIT` ensures we run cleanup before the shell exits. `trap ""exit 24"" INT TERM` converts interruption (`Ctrl-c`) and termination (`kill -15`) into an `EXIT` signal. We do this to ensure that the exit handler is called once. if we did `trap cleanup EXIT INT TERM` some shells would call `cleanup` twice. Once for the interruption and once for the shell exiting. Inside `cleanup` we `trap """" INT TERM` to make `Ctrl-c` do nothing, because the user COUGH cotton COUGH might smash ctrl-c repeatedly and we might not kill the subprocess before they kills us ;).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4786:375,failure,failure,375,https://hail.is,https://github.com/hail-is/hail/pull/4786,1,['failure'],['failure']
Availability,"Without this `make test-local` fails because there is no running server. This ensures that `make test-local` first starts a server to test against. The `until curl ...` nonsense is because the server takes some time to start up, so we poll until we get a successful return value from `curl`. `-f` means return non-zero-exit-code on failure. `-L` means follow redirects (not really necessary here, but I think it's good practice to use `-L`). `BATCH_USE_KUBE_CONFG=1` tells batch to use the latent kubernetes configuration, which means the developer must already have set up `kubectl`. This is a reasonable expectation for a developer of `batch`. The `trap cleanup EXIT` ensures we run cleanup before the shell exits. `trap ""exit 24"" INT TERM` converts interruption (`Ctrl-c`) and termination (`kill -15`) into an `EXIT` signal. We do this to ensure that the exit handler is called once. if we did `trap cleanup EXIT INT TERM` some shells would call `cleanup` twice. Once for the interruption and once for the shell exiting. Inside `cleanup` we `trap """" INT TERM` to make `Ctrl-c` do nothing, because the user COUGH cotton COUGH might smash ctrl-c repeatedly and we might not kill the subprocess before they kills us ;).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4785:332,failure,failure,332,https://hail.is,https://github.com/hail-is/hail/pull/4785,1,['failure'],['failure']
Availability,"Without this change, no error is raised and we never record; that there was a check incremental failure.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11279:24,error,error,24,https://hail.is,https://github.com/hail-is/hail/pull/11279,2,"['error', 'failure']","['error', 'failure']"
Availability,"Without this empty file, mypy ignores the type annotations present in these modules. Adding; this file enables downstream modules (like CI and batch) to check the type annotations; provided by hailtop, gear, and web_common. See more information here: https://mypy.readthedocs.io/en/stable/installed_packages.html#making-pep-561-compatible-packages",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9899:111,down,downstream,111,https://hail.is,https://github.com/hail-is/hail/pull/9899,1,['down'],['downstream']
Availability,"Workers can dynamically attach disks to themselves to accommodate jobs that request storage that the VM cannot accommodate. In certain circumstances like preemption, the VM can disappear before it is able to delete its own disks, so the Batch Driver scans for disks that are no longer attached (orphaned) and deletes them. It looks like our disk cleanup loop was broken due to inadvertent mutation that leads to an assertion error if the same `params` argument is used in multiple invocations of `GoogleComputeClient.list`. This is preventing orphaned disks from being deleted, costing us money. Additional details are in #14613. Fixes #14613",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14614:425,error,error,425,https://hail.is,https://github.com/hail-is/hail/pull/14614,1,['error'],['error']
Availability,"Working backwards, we need to not return a 500 on error. We could return a BadRequest error code with the message 'invalid spec' and then handle the MJC database call on the driver. I chose instead to have the worker to post job complete so we get the error message with the stack trace showing up in the UI as having the normal job flow seemed cleaner to me last week then special casing `schedule_job` on the driver. `post job complete` needs a job object to get the status to send back to the driver. However, a `Job` has two concrete implementations and we don't know which the bad job is because we can't get the spec. Furthermore, the `Job` class does a lot of work based on the spec right now. So I thought it was clearer to just create a new class that had the status, but nothing else. After writing this out, it's probably better to have the driver MJC upon error rather than from the worker. The code below would be more complicated. We'd have to get the traceback / error message from the response from the worker. ```python3; try:; await client_session.post(; f'http://{instance.ip_address}:5000/api/v1alpha/batches/jobs/create',; json=body,; timeout=aiohttp.ClientTimeout(total=2),; ); await instance.mark_healthy(); except aiohttp.ClientResponseError as e:; await instance.mark_healthy(); if e.status == 403:; log.info(f'attempt already exists for job {id} on {instance}, aborting'); if e.status == 503:; log.info(f'job {id} cannot be scheduled because {instance} is shutting down, aborting'); raise e; except Exception:; await instance.incr_failed_request_count(); raise; ```. And the error handling would look something like this:. ```python3; try:; body = await job_config(app, record, attempt_id); except Exception:; log.exception('while making job config'); status = {; 'version': STATUS_FORMAT_VERSION,; 'worker': None,; 'batch_id': batch_id,; 'job_id': job_id,; 'attempt_id': attempt_id,; 'user': record['user'],; 'state': 'error',; 'error': traceback.format_exc(),; 'container_s",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11391#issuecomment-1048213078:50,error,error,50,https://hail.is,https://github.com/hail-is/hail/pull/11391#issuecomment-1048213078,10,['error'],['error']
Availability,"Working in cluster. Fixes the below error, the origin of which I'm not quite sure: does it happen because wherever CI builds this has spark2.4 installed, or is spark2.4 pulled by gradlew shadowJar (I don't see where this happens, but I also haven't looked very carefully). ```; install-hail-locally:; 	rm -rf build; 	(cd ../hail && GRADLE_OPTS=-Xmx2048m ./gradlew shadowJar --gradle-user-home /gradle-cache); 	mkdir -p build/hail/jars; 	mkdir -p build/hail/python; 	cp -a ../hail/build/libs/hail-all-spark.jar build/hail/jars; 	cp -a ../hail/python/hail build/hail/python. build-hail-base: build-spark-base install-hail-locally; ```. <img width=""814"" alt=""Screenshot 2019-04-10 13 22 01"" src=""https://user-images.githubusercontent.com/5543229/55902941-79ea4c00-5b9a-11e9-9899-8e37311c4d06.png"">. ; Only issue I see is; """"""; 2019-04-10 18:00:59 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Setting default log level to ""WARN""; """""""". not sure if that's new, but googling around suggests the typical solution is warning suppression. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5850:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/pull/5850,1,['error'],['error']
Availability,"Working on failure in takeByAnnotationAnnotation. Error is segmentation fault, triggered by presence of null values, in either key or value position of Row(). Reverting recent RVB and SRVB changes did not fix, so issue does not appear to be there (also no uses of .pType in these files)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8142#issuecomment-590029353:11,failure,failure,11,https://hail.is,https://github.com/hail-is/hail/pull/8142#issuecomment-590029353,3,"['Error', 'failure', 'fault']","['Error', 'failure', 'fault']"
Availability,"Working on it. Gradle/Scala tests pass. Python (Python 3.6.7) also probably pass, I encountered a missing R library error on 501, will re-run in the morning with it installed. Need to better understand the context of the changes, and whether any additional tests needed to cover them. edit: For instance, the serializers don't have tests, but it may not matter if they don't introduce public functionality (beyond that consumed by tested functions).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5138#issuecomment-456288536:116,error,error,116,https://hail.is,https://github.com/hail-is/hail/pull/5138#issuecomment-456288536,1,['error'],['error']
Availability,"Wow `deploy_auth` failed with this:. ```; /controller.sh: line 35: 7 Segmentation fault (core dumped) ""${COMMAND[@]}""; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14382#issuecomment-1971696481:82,fault,fault,82,https://hail.is,https://github.com/hail-is/hail/pull/14382#issuecomment-1971696481,1,['fault'],['fault']
Availability,Wow this is supremely annoying. https://github.com/jupyter/notebook/issues/3397 Jupyter is basically known to be broken for the normal use case of most Asyncio libraries. The recommended fix is to use a third party monkey patch. I'll revisit this if 1kg download continue to be a frequent issue.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8218#issuecomment-599765193:254,down,download,254,https://hail.is,https://github.com/hail-is/hail/pull/8218#issuecomment-599765193,1,['down'],['download']
Availability,"Wow, talk about a *tour de force* of debugging, well done!!. ---. OK, so this kinda makes sense. We are importing our own copies of the GCS libraries and renaming them all to `is.hail.relocated....`. We do this so that we're not stuck with whatever version Dataproc is including. We pin our dataproc image version to `2.1.2-debian11` (see [here](https://github.com/hail-is/hail/blob/main/hail/python/hailtop/hailctl/dataproc/start.py#L147)) which [was released in January 2023](https://cloud.google.com/dataproc/docs/release-notes#January_23_2023). The latest available version of [Dataproc's Debian images](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) is 2.1.25-debian11 which depends on GoogleCloudDataproc hadoop connector version [2.2.15](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/2.2.15) which relies on Google Cloud Storage client library version [2.22.3](https://github.com/GoogleCloudDataproc/hadoop-connectors/commit/8b79f025ef5e8231de827f4c620cd23e230c3489). I have [a PR](https://github.com/hail-is/hail/pull/13732) to upgrade us to 2.27.1 because the library broke retries in versions [2.25.0, 2.27.0). AFAICT, Google's image version page only shows the most recent five. There's no way to go back further in time. Luckily, the way back machine has [a March 2023 capture](https://web.archive.org/web/20230307225815/https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) which includes our version. 2.1.2-debian11 used Google Cloud Dataproc hadoop connector version [2.2.9](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/v2.2.9) This version of the hadoop connector was [using some alpha version of a gRPC version of the cloud storage library](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/18f6e9f1c745e1854d76bea9362e2332898d8895/pom.xml#L96C1-L97C1). I'm not sure what's up with that. OK, here's my proposal: let's change that IMAGE_VERSION to the latest one ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645:560,avail,available,560,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645,1,['avail'],['available']
Availability,"YGMENTS-1086606](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1086606) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-PYGMENTS-1088505](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1088505) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-5750273](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-5750273) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **711/1000** <br/> **Why?** Mature exploit, Has a fix available, CVSS 6.5 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-SPHINX-570772](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-570772) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:5874,avail,available,5874,https://hail.is,https://github.com/hail-is/hail/pull/13717,3,['avail'],['available']
Availability,"YK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14211:3169,avail,available,3169,https://hail.is,https://github.com/hail-is/hail/pull/14211,1,['avail'],['available']
Availability,"YK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `40.5.0 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14365:3239,avail,available,3239,https://hail.is,https://github.com/hail-is/hail/pull/14365,1,['avail'],['available']
Availability,"Ya I was wondering too which is why I tried this out. It was helpful in observing how much the number of files is the bottleneck for the copy tool. Takes between 15-20 seconds to copy down all 5k files in the repo while jobs that copy more MB but in fewer files are [much better](https://ci.hail.is/batches/6235246/jobs/52). I don't exactly prefer how, but it feels silly to spend 25% of the time of `auth_image` downloading the entire repo when you need just the auth directory",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12371#issuecomment-1289877495:184,down,down,184,https://hail.is,https://github.com/hail-is/hail/pull/12371#issuecomment-1289877495,2,['down'],"['down', 'downloading']"
Availability,"Yea, binary incompatibility is as good a guess as any. I'm sure it's this commit though. What's the best way to break down the commit into likely culprits that I could test?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513#issuecomment-429132148:118,down,down,118,https://hail.is,https://github.com/hail-is/hail/issues/4513#issuecomment-429132148,1,['down'],['down']
Availability,Yeah I think this doesn't much matter once we've eliminated uses of netlib. Hail will get a link error instead of falling back on hopelessly slow non-native libraries.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5040#issuecomment-570319184:97,error,error,97,https://hail.is,https://github.com/hail-is/hail/issues/5040#issuecomment-570319184,1,['error'],['error']
Availability,"Yeah but it would really mess with debugging. I think probably still worth keeping the `unify_exprs` and `TypeError` lines (it'll be a little redundant, but it's just type checking so shouldn't be slow)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7088#issuecomment-533099406:142,redundant,redundant,142,https://hail.is,https://github.com/hail-is/hail/pull/7088#issuecomment-533099406,1,['redundant'],['redundant']
Availability,"Yeah, I think I agree that we have a unique UUID. What I'm more skeptical of is: what if we throw an exception in a `write`? Do we clean up all the open resources? If not, that could totally leave a writer open that will conflict when we retry (even if we retried on a different VM!). ---. `retryTransientErrors` expects partition code to be safe to execute twice, but otherwise it's quite simple:. ```scala; def retryTransientErrors[T](f: => T): T = {; var delay = 0.1; var errors = 0; while (true) {; try {; return f; } catch {; case e: Exception =>; errors += 1; if (errors == 1 && isRetryOnceError(e)); return f; if (!isTransientError(e)); throw e; if (errors % 10 == 0); log.warn(s""encountered $errors transient errors, most recent one was $e""); }; delay = sleepAndBackoff(delay); }. throw new AssertionError(""unreachable""); }; ```; and this is the call site:; ```scala; val htc = new ServiceTaskContext(i); var result: Array[Byte] = null; var userError: HailException = null; try {; retryTransientErrors {; result = f(context, htc, theHailClassLoader, fs); }; } catch {; case err: HailException => userError = err; }; htc.close(); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1531592331:475,error,errors,475,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1531592331,12,['error'],['errors']
Availability,"Yeah, I'm working on smaller images in down time between other meetings",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9481#issuecomment-700750562:39,down,down,39,https://hail.is,https://github.com/hail-is/hail/pull/9481#issuecomment-700750562,1,['down'],['down']
Availability,"Yeah, agreed. I've never taken inventory of the full test suite. This was the first bug that caused an error message though, previous ones have just been about things being too slow. So we'll need benchmarks to catch that stuff.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7146#issuecomment-536022939:103,error,error,103,https://hail.is,https://github.com/hail-is/hail/pull/7146#issuecomment-536022939,1,['error'],['error']
Availability,"Yeah, it says no such method found. One of many bad expr error messages",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/846#issuecomment-249639159:57,error,error,57,https://hail.is,https://github.com/hail-is/hail/issues/846#issuecomment-249639159,1,['error'],['error']
Availability,"Yeah, no trailing bin. I think we can sanity-check the SPARK_HOME setting in the HailContext constructor to give a more informative error message.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2062#issuecomment-319707620:132,error,error,132,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319707620,1,['error'],['error']
Availability,"Yeah, one test fails.`test_annotate_col_agg_lowering`. This error is encountered on the worker. It gets raised there, then the driver encounters it and re-raises it. That's how we ultimately see it on the client-side.; ```; E HailException: Premature end of file: expected 4 bytes, found 0; E is.hail.utils.HailException: Premature end of file: expected 4 bytes, found 0; E 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17); E 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17); E 	at is.hail.utils.package$.fatal(package.scala:78); E 	at is.hail.utils.richUtils.RichInputStream$.readFully$extension1(RichInputStream.scala:13); E 	at is.hail.io.StreamBlockInputBuffer.readBlock(InputBuffers.scala:546); E 	at is.hail.io.LZ4InputBlockBuffer.readBlock(InputBuffers.scala:584); E 	at is.hail.io.BlockingInputBuffer.readBlock(InputBuffers.scala:382); E 	at is.hail.io.BlockingInputBuffer.ensure(InputBuffers.scala:388); E 	at is.hail.io.BlockingInputBuffer.readByte(InputBuffers.scala:405); E 	at is.hail.io.LEB128InputBuffer.readByte(InputBuffers.scala:217); E 	at is.hail.io.LEB128InputBuffer.readInt(InputBuffers.scala:223); E 	at __C3100collect_distributed_array.__m3103INPLACE_DECODE_r_int32_TO_r_int32(Unknown Source); E 	at __C3100collect_distributed_array.__m3147INPLACE_DECODE_r_struct_of_r_int32ANDr_int64END_TO_r_struct_of_r_int32ANDr_int64END(Unknown Source); E 	at __C3100collect_distributed_array.__m3146INPLACE_DECODE_r_array_of_r_struct_of_r_int32ANDr_int64END_TO_r_dict_of_r_int32ANDr_int64(Unknown Source); E 	at __C3100collect_distributed_array.__m3141DECODE_r_struct_of_r_int32ANDr_array_of_r_int32ANDr_float64ANDr_array_of_r_float64ANDr_int64ANDr_array_of_r_struct_of_r_int32ANDr_int64ENDEND_TO_SBaseStructPointer(Unknown Source); E 	at __C3100collect_distributed_array.__m3128split_StreamFor_region24_75(Unknown Source); E 	at __C3100collect_distributed_array.__m3128split_StreamFor(Unknown Source); E 	at __C3100collect_distributed_array.__m3125begin_group_0",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11681#issuecomment-1079785317:60,error,error,60,https://hail.is,https://github.com/hail-is/hail/pull/11681#issuecomment-1079785317,5,"['Error', 'error']","['ErrorHandling', 'error']"
Availability,"Yeah, sorry about this. I've been working on de novo stuff on the side and am really unhappy about the current trio abstraction (pasting a bunch of code in from Mendel errors). I'll review as it is now, though, so we can get this in.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/753#issuecomment-257355964:168,error,errors,168,https://hail.is,https://github.com/hail-is/hail/pull/753#issuecomment-257355964,1,['error'],['errors']
Availability,"Yeah, that error indicates that those are old format VDS's, so Hail won't load them unless someone with write access to hail-common uses the ""write_partioning"" method to update them. I'll handle that now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1683#issuecomment-295745615:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/issues/1683#issuecomment-295745615,1,['error'],['error']
Availability,"Yeah, that was a weird failure. I wonder if a node got preempted and createDatabase2 is not idempotent.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7863#issuecomment-573896406:23,failure,failure,23,https://hail.is,https://github.com/hail-is/hail/pull/7863#issuecomment-573896406,1,['failure'],['failure']
Availability,"Yeah, there is some bug in `import_vcf -> _same` checkpointing before filter also fixes it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11450#issuecomment-1061869461:49,checkpoint,checkpointing,49,https://hail.is,https://github.com/hail-is/hail/pull/11450#issuecomment-1061869461,1,['checkpoint'],['checkpointing']
Availability,"Yeah, this PR really shouldn't have introduced the kinds of failures we're seeing. That seems to be the refrain of all of my lowering refactoring PRs though!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7567#issuecomment-557024561:60,failure,failures,60,https://hail.is,https://github.com/hail-is/hail/pull/7567#issuecomment-557024561,1,['failure'],['failures']
Availability,"Yeah. Really odd that prometheus doesn't somehow signal that it needs more memory, or exits as failure. It just sits and spins.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6773#issuecomment-517021923:95,failure,failure,95,https://hail.is,https://github.com/hail-is/hail/issues/6773#issuecomment-517021923,1,['failure'],['failure']
Availability,Yep! Loaded it up and it worked without error. Thanks!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3015#issuecomment-373027311:40,error,error,40,https://hail.is,https://github.com/hail-is/hail/issues/3015#issuecomment-373027311,1,['error'],['error']
Availability,"Yep, I bumped into the Breeze bug a while back while trying to upgrade Hail to Spark 3 internally, and realized it'd be a blocker downstream. I've only seen issues on the Python side; for example:; ```; ______________________________________________________________________________ Tests.test_block_matrix_entries ______________________________________________________________________________. self = <test.hail.linalg.test_linalg.Tests testMethod=test_block_matrix_entries>. @fails_local_backend(); def test_block_matrix_entries(self):; n_rows, n_cols = 5, 3; rows = [{'i': i, 'j': j, 'entry': float(i + j)} for i in range(n_rows) for j in range(n_cols)]; schema = hl.tstruct(i=hl.tint32, j=hl.tint32, entry=hl.tfloat64); table = hl.Table.parallelize([hl.struct(i=row['i'], j=row['j'], entry=row['entry']) for row in rows], schema); table = table.annotate(i=hl.int64(table.i),; j=hl.int64(table.j)).key_by('i', 'j'); ; ndarray = np.reshape(list(map(lambda row: row['entry'], rows)), (n_rows, n_cols)); ; for block_size in [1, 2, 1024]:; block_matrix = BlockMatrix.from_numpy(ndarray, block_size); entries_table = block_matrix.entries(); self.assertEqual(entries_table.count(), n_cols * n_rows); self.assertEqual(len(entries_table.row), 3); > self.assertTrue(table._same(entries_table)); E AssertionError: False is not true. test/hail/linalg/test_linalg.py:868: AssertionError; ----------------------------------------------------------------------------------- Captured stdout call ------------------------------------------------------------------------------------; Table._same: rows differ:; Row mismatch:; L: [Struct(entry=1.0)]; R: [Struct(entry=0.0)]; Row mismatch:; L: [Struct(entry=2.0)]; R: [Struct(entry=0.0)]; Row mismatch:; L: [Struct(entry=1.0)]; R: [Struct(entry=0.0)]; Row mismatch:; L: [Struct(entry=2.0)]; R: [Struct(entry=0.0)]; Row mismatch:; L: [Struct(entry=3.0)]; R: [Struct(entry=0.0)]; Row mismatch:; L: [Struct(entry=2.0)]; R: [Struct(entry=0.0)]; Row mismatch:; L: [Struct(e",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9524#issuecomment-701539406:130,down,downstream,130,https://hail.is,https://github.com/hail-is/hail/pull/9524#issuecomment-701539406,1,['down'],['downstream']
Availability,"Yep, just waiting on final (unrelated) fixes to go through on the v3.1.1; nuclear variant release files before pinging them about copying over all; our changed files. On Wed, Mar 10, 2021 at 3:29 PM Dan King ***@***.***> wrote:. > I'll wait for Grace to chime in about the desired public location.; >; > â€”; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/pull/10169#issuecomment-796049879>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABNSGHRVFLHDPK26N3MKTXLTC7CBTANCNFSM4Y42HNKA>; > .; >",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10169#issuecomment-797031640:111,ping,pinging,111,https://hail.is,https://github.com/hail-is/hail/pull/10169#issuecomment-797031640,1,['ping'],['pinging']
Availability,"Yes the errors were fatal, but using non-preemtible instances fixed it, so will close this issue. Thanks.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6635#issuecomment-513887926:8,error,errors,8,https://hail.is,https://github.com/hail-is/hail/issues/6635#issuecomment-513887926,1,['error'],['errors']
Availability,Yes with the caveat that I was going to look at the worker logs in the PR test namespace just to make sure there were no hidden errors that would be problematic. I broke the logging query generator -- fixed in #13813 -- and didn't think this was urgent. I'll take a look at the logs now without that fix in.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13728#issuecomment-1769106759:128,error,errors,128,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1769106759,1,['error'],['errors']
Availability,Yes! I definitely want to assert no errors in the logs. I think we're very close to being able to assert that.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10920#issuecomment-956533915:36,error,errors,36,https://hail.is,https://github.com/hail-is/hail/pull/10920#issuecomment-956533915,1,['error'],['errors']
Availability,"Yes, I looked into this, it is a transient error that should be retried. I will change batch2 to use the retry infrastructure after this PR goes in: https://github.com/hail-is/hail/pull/7284",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7287#issuecomment-542232729:43,error,error,43,https://hail.is,https://github.com/hail-is/hail/pull/7287#issuecomment-542232729,1,['error'],['error']
Availability,"Yes, I receive the same bug today, when I follow the instruction: https://hail.is/docs/0.2/install/other-cluster.html ; I believe this is a bug caused by pip or setuptools. If you downgrade the pip to 8.1.1, you will get another bug. . > cd build/deploy; python3 setup.py -q sdist bdist_wheel; sed '/^pyspark/d' python/requirements.txt | xargs python3 -m pip install -U; Exception:; Traceback (most recent call last):; File ""/home/ubuntu/.local/lib/python3.6/site-packages/pip/basecommand.py"", line 209, in main; status = self.run(options, args); File ""/home/ubuntu/.local/lib/python3.6/site-packages/pip/commands/install.py"", line 287, in run; wheel_cache; File ""/home/ubuntu/.local/lib/python3.6/site-packages/pip/basecommand.py"", line 270, in populate_requirement_set; wheel_cache=wheel_cache; File ""/home/ubuntu/.local/lib/python3.6/site-packages/pip/req/req_install.py"", line 230, in from_line; wheel_cache=wheel_cache, constraint=constraint); File ""/home/ubuntu/.local/lib/python3.6/site-packages/pip/req/req_install.py"", line 77, in __init__; req = pkg_resources.Requirement.parse(req); File ""/home/ubuntu/.local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py"", line 3036, in parse; req, = parse_requirements(s); ValueError: not enough values to unpack (expected 1, got 0)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10352#issuecomment-826316427:180,down,downgrade,180,https://hail.is,https://github.com/hail-is/hail/issues/10352#issuecomment-826316427,1,['down'],['downgrade']
Availability,"Yes, PR #137 treats the hemizygous Y case as well. As with Plink, I do not consider hets at homozygous sites to be Mendel errors, but rather sequencing errors. Users should deal with them separately as they see fit.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/91#issuecomment-235397652:122,error,errors,122,https://hail.is,https://github.com/hail-is/hail/issues/91#issuecomment-235397652,2,['error'],['errors']
Availability,"Yes, it failed on master. It was failing in OrderedRVDType, because the key `idx` didn't match the partition key `[idx, a]`. The error only happens if `idx` is in both the old and new key.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3749#issuecomment-396753521:129,error,error,129,https://hail.is,https://github.com/hail-is/hail/pull/3749#issuecomment-396753521,1,['error'],['error']
Availability,"Yes, it will exit(0), but upon any job failure `state` will be ""failure"", and the STDOUT message will be ""batch {bc_batch.id} complete: failure"" instead of ""Batch completed successfully"" as in the LocalBackend case currently. We rely on exception handling to catch job errors for LocalBackend.run, and the current bug occurs because of an improperly formed ternary expression (we can tell this because `verbose` should not enable `-e`). cc @jigold, @danking, what are your thoughts?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9297#issuecomment-675599575:39,failure,failure,39,https://hail.is,https://github.com/hail-is/hail/pull/9297#issuecomment-675599575,4,"['error', 'failure']","['errors', 'failure']"
Availability,"Yes. > seems odd to put null as position. I agree. That's why we need your new IR with no positions!. > Will this change slow things down unnecessarily if drop_samples is not used immediately after a read?. Yes, possibly a little, since FilterSamples needs to handle the case where not all samples are filtered. Options: specialize the case in FilterSamples when the condition is false (or true -- no-op) or add a DropSamples node. I prefer the former. FilterSamples is somewhat better in the coming OrderedRDD2/RegionValueBuilder stuff. The implementation has almost no overhead for when the condition is false. I say leave this as is and we'll pick that up when my later PRs go in.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2285#issuecomment-336261462:133,down,down,133,https://hail.is,https://github.com/hail-is/hail/pull/2285#issuecomment-336261462,1,['down'],['down']
Availability,"Yes. from scala.concurrent.ExecutionContext:. ```; object ExecutionContext {; /**; * The explicit global `ExecutionContext`. Invoke `global` when you want to provide the global; * `ExecutionContext` explicitly.; *; * The default `ExecutionContext` implementation is backed by a work-stealing thread pool.; * It can be configured via the following [[scala.sys.SystemProperties]]:; *; * `scala.concurrent.context.minThreads` = defaults to ""1""; * `scala.concurrent.context.numThreads` = defaults to ""x1"" (i.e. the current number of available processors * 1); * `scala.concurrent.context.maxThreads` = defaults to ""x1"" (i.e. the current number of available processors * 1); * `scala.concurrent.context.maxExtraThreads` = defaults to ""256""; *; * The pool size of threads is then `numThreads` bounded by `minThreads` on the lower end and `maxThreads` on the high end.; *; * The `maxExtraThreads` is the maximum number of extra threads to have at any given time to evade deadlock,; * see [[scala.concurrent.BlockContext]].; *; * @return the global `ExecutionContext`; */; def global: ExecutionContextExecutor = Implicits.global.asInstanceOf[ExecutionContextExecutor]. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9775#issuecomment-738140989:529,avail,available,529,https://hail.is,https://github.com/hail-is/hail/pull/9775#issuecomment-738140989,2,['avail'],['available']
Availability,"Yes. it runs fine on our regular cluster locally. As a workaround, we; are qsubing our hail jobs for each chromosome with --master local[16]; reading the matrix tables stored on our gpfs system. Those are running; fine on the UK Biobank data. When we try to running the same job with; master=yarn on the hadoop cluster that error occurs. An earlier version of; Hail (before the GLIBC error) was running fine on the Hadoop cluster. John. On Wed, Dec 19, 2018 at 6:28 PM Tim Poterba <notifications@github.com>; wrote:. > sorry to lose this! I think we're not as good at keeping on top of issue; > comments as forum posts/zulip/etc.; >; > I have no idea what this is coming from, never seen something like this; > before.; >; > Can you run pyspark stuff normally?; >; > â€”; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/issues/4733#issuecomment-448783924>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AB3rDZkqSvk3zcRuS41UEh_xHLQ5ccabks5u6sk1gaJpZM4YPdeC>; > .; >. -- ; John Farrell, Ph.D.; Biomedical Genetics-Evans 218; Boston University Medical School; 72 East Concord Street; Boston, MA. ph: 617-358-3562 (New Number)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-448845809:324,error,error,324,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-448845809,2,['error'],['error']
Availability,"You can now say:. ```; async with db.start() as tx:; await tx.just_execute(sql); row = await tx.execute_fetchone(sql, args); ...; ```. Transactions support all the database utility functions. If the transaction context manager exists with an exception, the transaction is rolled back, otherwise it is committed. You also can explicitly rollback or commit the transaction, although it can't be used again after that. I also added an execute_many function. I use this in the front end instead of dropping down to aiomysql to create explicit transactions. Note on internal changes: I no longer use autocommit now that transaction boundaries are explicit. You can start a read only transaction, and I do that by default for execute_and_fetch{one, all}, although maybe those should be renamed select_and_fetch{one, all} to make their read-only nature apparent (MySQL throws an error if you try to modify something in a read-only transaction). This follows mysql best transaction performance recommendations as described here: https://dev.mysql.com/doc/refman/5.6/en/optimizing-innodb-transaction-management.html and https://dev.mysql.com/doc/refman/5.6/en/innodb-performance-ro-txn.html. FYI @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7641:336,rollback,rollback,336,https://hail.is,https://github.com/hail-is/hail/pull/7641,3,"['down', 'error', 'rollback']","['down', 'error', 'rollback']"
Availability,"You have a few failures, rvb.addAnnotation(t, a) needs to be rvb.addAnnotation(t.virtualType, a)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6711#issuecomment-514763348:15,failure,failures,15,https://hail.is,https://github.com/hail-is/hail/pull/6711#issuecomment-514763348,1,['failure'],['failures']
Availability,You have a file naming error in build.yaml.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7916#issuecomment-575914242:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/pull/7916#issuecomment-575914242,1,['error'],['error']
Availability,You have a pylint error with trailing whitespace.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9822#issuecomment-764957523:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/9822#issuecomment-764957523,1,['error'],['error']
Availability,"You have an error based on where the maven code is being run (not the directory with the pom file).; ```; [[1;31mERROR[m] Failed to execute goal [32morg.apache.maven.plugins:maven-dependency-plugin:2.8:resolve[m [1m(default-cli)[m: [1;31mGoal requires a project to execute but there is no POM in this directory (/). Please verify you invoked Maven from the correct directory.[m -> [1m[Help 1][m; [[1;31mERROR[m] ; [[1;31mERROR[m] To see the full stack trace of the errors, re-run Maven with the [1m-e[m switch.; [[1;31mERROR[m] Re-run Maven using the [1m-X[m switch to enable full debug logging.; [[1;31mERROR[m] ; [[1;31mERROR[m] For more information about the errors and possible solutions, please read the following articles:; [[1;31mERROR[m] [1m[Help 1][m http://cwiki.apache.org/confluence/display/MAVEN/MissingProjectException; The command '/bin/sh -c mvn dependency:resolve && rm pom.xml test-jar-with-dependencies.xml' returned a non-zero code: 1; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6050#issuecomment-489712270:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/6050#issuecomment-489712270,3,['error'],"['error', 'errors']"
Availability,You have an import error,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7886#issuecomment-574836135:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/7886#issuecomment-574836135,1,['error'],['error']
Availability,"You have test errors:. ```; io/test/test_batch.py::Test::test_restartable_insert FAILED; _________________________ Test.test_restartable_insert _________________________. self = <test.test_batch.Test testMethod=test_restartable_insert>. def test_restartable_insert(self):; def every_third_time():; nonlocal i; i += 1; if i % 3 == 0:; return True; return False; with aiohttp.ClientSession(raise_for_status=True,; > timeout=aiohttp.ClientTimeout(total=60)) as real_session:. io/test/test_batch.py:441: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <aiohttp.client.ClientSession object at 0x7f96a2a4d550>. def __enter__(self) -> None:; > raise TypeError(""Use async with instead""); E TypeError: Use async with instead. usr/local/lib/python3.6/dist-packages/aiohttp/client.py:964: TypeError; ```. ```; self._tasks = ordered_tasks; try:; self._backend._run(self, dry_run, verbose, delete_scratch_on_exit, **backend_kwargs); finally:; > self._backend.close(); E AttributeError: 'LocalBackend' object has no attribute 'close'; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7875#issuecomment-575754393:14,error,errors,14,https://hail.is,https://github.com/hail-is/hail/pull/7875#issuecomment-575754393,1,['error'],['errors']
Availability,"You removed the ""wasSplit"" requirement so error is not thrown in BiallelicMethodSuite:. ```; interceptRequire {; multi.variantQC(); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2422#issuecomment-343779308:42,error,error,42,https://hail.is,https://github.com/hail-is/hail/pull/2422#issuecomment-343779308,1,['error'],['error']
Availability,You still have an error in there.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5467#issuecomment-468314466:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/5467#issuecomment-468314466,1,['error'],['error']
Availability,You still have test failures.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9035#issuecomment-658331383:20,failure,failures,20,https://hail.is,https://github.com/hail-is/hail/pull/9035#issuecomment-658331383,1,['failure'],['failures']
Availability,"You'll get an error [if the character set is incompatible with the collation](https://dev.mysql.com/doc/refman/8.0/en/charset-collation-compatibility.html), so as long as this passes CI it should be fine on that account. As to why that particular collation, I found it on the [case sensitivity in string searches page](https://dev.mysql.com/doc/refman/8.0/en/case-sensitivity.html). The default is `utf8mb4_0900_ai_ci` and the first case sensitive alternative mentioned is this one. The change log indicates that ""as"" means accent sensitive and ""cs"" means case sensitive. The 0900 seems to refer to Unicode 9.0.0. Anyway, it seems sensible to use a Unicode collation rather than a binary one because Unicode encodings have more meaning than their bytes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12276#issuecomment-1268732639:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/pull/12276#issuecomment-1268732639,1,['error'],['error']
Availability,"You'll have to provide me with the full error to help, I don't know where that's coming from. Perhaps I edited another function elsewhere and didn't include it up there. > that are each in the same 2 genes. The same two genes? How can a gene appear twice when you've grouped by the gene id?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13882#issuecomment-1830286991:40,error,error,40,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1830286991,1,['error'],['error']
Availability,"You'll note that `check_hail_37` is failing because of an infinite recursion bug. I believe it's pylint's fault through its `astroid` depenency, though I'm not sure what the change in pandas 1.1.5 is that causes this. Mentioned here: https://github.com/hail-is/hail/pull/9804",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9819#issuecomment-744092288:106,fault,fault,106,https://hail.is,https://github.com/hail-is/hail/pull/9819#issuecomment-744092288,1,['fault'],['fault']
Availability,You're getting a doctest failure @tpoterba,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7404#issuecomment-548046645:25,failure,failure,25,https://hail.is,https://github.com/hail-is/hail/pull/7404#issuecomment-548046645,1,['failure'],['failure']
Availability,You're getting an assertion error in MatrixIR,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3857#issuecomment-400791168:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/3857#issuecomment-400791168,1,['error'],['error']
Availability,"You've essentially done the same though saying that there will never be more than 32 regions in GCP (the `VARCHAR(32)`). The corresponding JSON would be O(32 * length-of-region-str), which would be just as error-prone, though possibly considerably longer. This is why I thought it was a space-saving issue.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12221#issuecomment-1274914725:206,error,error-prone,206,https://hail.is,https://github.com/hail-is/hail/pull/12221#issuecomment-1274914725,1,['error'],['error-prone']
Availability,"Your application master container failed with exit code 11. There was no human interpretable error message, but googling turned up this:. http://stackoverflow.com/questions/31284799/spark-streaming-job-exited-with-code-11. Hitting ""spark.yarn.max.executor.failures"" would be totally consistent with the observed behavior, although I'm not sure why we didn't get the same error message. http://spark.apache.org/docs/latest/running-on-yarn.html. Again, this is related to the 1.5 bug I mentioned before: executors killed to give resources to other jobs shouldn't be counted as killed. Let's try again with two changes:; 1. I increased max executor failures to 500 in `hail-new-vep`.; 2. Instead of using repartition, use `importvcf -n 1000 /path/to/my.vcf.bgz splitmulti ...`. I think this will fix all the problems.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/302#issuecomment-211046143:93,error,error,93,https://hail.is,https://github.com/hail-is/hail/issues/302#issuecomment-211046143,4,"['error', 'failure']","['error', 'failures']"
Availability,"Your diff includes the Genotype class (which changed in master yesterday). Try fetching the current master, rebasing, and force pushing (you might want to copy your branch first to ease recovery in case you have trouble with rebasing)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1288#issuecomment-274950856:186,recover,recovery,186,https://hail.is,https://github.com/hail-is/hail/pull/1288#issuecomment-274950856,1,['recover'],['recovery']
Availability,"Your errors are a result of -0.0, as https://github.com/hail-is/hail/issues/6086",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6050#issuecomment-490955457:5,error,errors,5,https://hail.is,https://github.com/hail-is/hail/pull/6050#issuecomment-490955457,1,['error'],['errors']
Availability,"Yup, it looks like that was the problem. That was totally my fault too. Thanks Milo!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6663#issuecomment-514793080:61,fault,fault,61,https://hail.is,https://github.com/hail-is/hail/issues/6663#issuecomment-514793080,1,['fault'],['fault']
Availability,Zstd bgen error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12608:10,error,error,10,https://hail.is,https://github.com/hail-is/hail/issues/12608,1,['error'],['error']
Availability,[AzureStorageFS] more transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12873:32,error,errors,32,https://hail.is,https://github.com/hail-is/hail/pull/12873,1,['error'],['errors']
Availability,[Benchmark] fix error by adding .json ext to file name,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9669:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/9669,1,['error'],['error']
Availability,[Benchmark] fixes (for 500 server error),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9477:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/9477,1,['error'],['error']
Availability,[CI] Do not error if a job for an unknown PR is received,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4669:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/4669,1,['error'],['error']
Availability,[DB] Remove redundant f-strings and validate ints,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14669:12,redundant,redundant,12,https://hail.is,https://github.com/hail-is/hail/pull/14669,1,['redundant'],['redundant']
Availability,[QoB] Driver does not retry transient errors in the one-partition fast path,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:38,error,errors,38,https://hail.is,https://github.com/hail-is/hail/issues/12982,1,['error'],['errors']
Availability,[QoB] Novel transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12980:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/issues/12980,1,['error'],['error']
Availability,[QoB] new transient error: java.net.SocketTimeoutException: connect timed out,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13074:20,error,error,20,https://hail.is,https://github.com/hail-is/hail/issues/13074,1,['error'],['error']
Availability,[QoB] protect reference download with a lock,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11949:24,down,download,24,https://hail.is,https://github.com/hail-is/hail/pull/11949,1,['down'],['download']
Availability,"[This](https://github.com/hail-is/hail/commit/9f186be0111d241756484136a2ffa8eb1a8a1feb) commit imports the `decorator` library, which isn't available by default on google cloud dataproc machines. . One can get around it (by rolling this commit back or by installing the library), but it makes the google cloud tutorial not work by default.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1459:140,avail,available,140,https://hail.is,https://github.com/hail-is/hail/issues/1459,1,['avail'],['available']
Availability,[WIP] Fix billing tables with redundant billing information,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12715:30,redundant,redundant,30,https://hail.is,https://github.com/hail-is/hail/pull/12715,1,['redundant'],['redundant']
Availability,[aiocloud] refresh access tokens after transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14083:49,error,errors,49,https://hail.is,https://github.com/hail-is/hail/pull/14083,1,['error'],['errors']
Availability,[aiogoogle] make aiogoogle tests resilient,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10947:33,resilien,resilient,33,https://hail.is,https://github.com/hail-is/hail/pull/10947,1,['resilien'],['resilient']
Availability,[aiogoogle] use resumable uploads to make writes resilient,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10023:49,resilien,resilient,49,https://hail.is,https://github.com/hail-is/hail/pull/10023,1,['resilien'],['resilient']
Availability,[aiotools.fs] retry transient errors in tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10954:30,error,errors,30,https://hail.is,https://github.com/hail-is/hail/pull/10954,1,['error'],['errors']
Availability,[aiotools] Log exception is task manager task errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13453:46,error,errors,46,https://hail.is,https://github.com/hail-is/hail/pull/13453,1,['error'],['errors']
Availability,[annotationdb] more informative error when can't find compatible annotation dataset,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10515:32,error,error,32,https://hail.is,https://github.com/hail-is/hail/pull/10515,1,['error'],['error']
Availability,[auth] retry transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8677:23,error,errors,23,https://hail.is,https://github.com/hail-is/hail/pull/8677,1,['error'],['errors']
Availability,[auth] teach token to error on missing token file,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7020:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/7020,1,['error'],['error']
Availability,[batch-client] teach java about another transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9785:50,error,error,50,https://hail.is,https://github.com/hail-is/hail/pull/9785,1,['error'],['error']
Availability,[batch/copy] fix for sporadic copy failures (1/2),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10260:35,failure,failures,35,https://hail.is,https://github.com/hail-is/hail/pull/10260,1,['failure'],['failures']
Availability,[batch2] a config error won't have a timing field,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7542:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/7542,1,['error'],['error']
Availability,[batch2] fix startup failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7442:21,failure,failure,21,https://hail.is,https://github.com/hail-is/hail/pull/7442,1,['failure'],['failure']
Availability,[batch2] fix status if error occurred when getting the job config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7522:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/pull/7522,1,['error'],['error']
Availability,[batch2] lock down secrets and service accounts to non-ci users,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7662:14,down,down,14,https://hail.is,https://github.com/hail-is/hail/pull/7662,1,['down'],['down']
Availability,[batch2] slim down worker image,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7233:14,down,down,14,https://hail.is,https://github.com/hail-is/hail/pull/7233,1,['down'],['down']
Availability,[batch] Add container str to deletion error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10805:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/pull/10805,1,['error'],['error']
Availability,[batch] Add download logs button,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11841:12,down,download,12,https://hail.is,https://github.com/hail-is/hail/pull/11841,1,['down'],['download']
Availability,[batch] Add error to missing k8s log message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6461:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/6461,1,['error'],['error']
Availability,[batch] Add failure reason to logs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6260:12,failure,failure,12,https://hail.is,https://github.com/hail-is/hail/pull/6260,1,['failure'],['failure']
Availability,[batch] Add k8s secret/sa cache and retry transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7850:52,error,errors,52,https://hail.is,https://github.com/hail-is/hail/pull/7850,1,['error'],['errors']
Availability,[batch] Add more logging for disk formatting errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11867:45,error,errors,45,https://hail.is,https://github.com/hail-is/hail/pull/11867,1,['error'],['errors']
Availability,[batch] Add user error for bad gcsfuse creds,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10645:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/10645,1,['error'],['error']
Availability,[batch] Batch Client needs robust tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6722:27,robust,robust,27,https://hail.is,https://github.com/hail-is/hail/issues/6722,1,['robust'],['robust']
Availability,[batch] Batch charges for private instance creation that fails with exhausted resource errors.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14505:87,error,errors,87,https://hail.is,https://github.com/hail-is/hail/issues/14505,1,['error'],['errors']
Availability,[batch] Batch should give useful error message on 401 unauthorized,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7839:33,error,error,33,https://hail.is,https://github.com/hail-is/hail/issues/7839,1,['error'],['error']
Availability,[batch] Batch workers log with ERROR severity when job is canceled,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13803:31,ERROR,ERROR,31,https://hail.is,https://github.com/hail-is/hail/issues/13803,1,['ERROR'],['ERROR']
Availability,[batch] Catch 500 error messages in dev ui pages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10503:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/10503,1,['error'],['error']
Availability,[batch] Clarify DockerHub error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11148:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/pull/11148,1,['error'],['error']
Availability,[batch] Do not log user errors as exceptions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14253:24,error,errors,24,https://hail.is,https://github.com/hail-is/hail/pull/14253,1,['error'],['errors']
Availability,[batch] Don't create jobs while shutting down the worker,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10594:41,down,down,41,https://hail.is,https://github.com/hail-is/hail/pull/10594,1,['down'],['down']
Availability,[batch] Don't error if no regions are in the database on startup,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12374:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/pull/12374,1,['error'],['error']
Availability,[batch] Don't rmtree if any errors occur while unmounting,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12985:28,error,errors,28,https://hail.is,https://github.com/hail-is/hail/pull/12985,1,['error'],['errors']
Availability,[batch] Dont log an exception if the exception is a user error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10636:57,error,error,57,https://hail.is,https://github.com/hail-is/hail/pull/10636,1,['error'],['error']
Availability,[batch] Dont log user errors from JVM jobs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11376:22,error,errors,22,https://hail.is,https://github.com/hail-is/hail/pull/11376,1,['error'],['errors']
Availability,[batch] Error if PythonJob functions are called with incompatible signature,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12734:8,Error,Error,8,https://hail.is,https://github.com/hail-is/hail/pull/12734,1,['Error'],['Error']
Availability,[batch] Fix JVM file exists error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12397:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/12397,1,['error'],['error']
Availability,[batch] Fix UI to make user errors clear,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10329:28,error,errors,28,https://hail.is,https://github.com/hail-is/hail/pull/10329,2,['error'],['errors']
Availability,[batch] Fix checking error message for crun kill,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10988:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/pull/10988,1,['error'],['error']
Availability,[batch] Fix deadlock errors when inserting attempts and attempt resources,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11959:21,error,errors,21,https://hail.is,https://github.com/hail-is/hail/pull/11959,1,['error'],['errors']
Availability,[batch] Fix errors on the worker,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11686:12,error,errors,12,https://hail.is,https://github.com/hail-is/hail/pull/11686,1,['error'],['errors']
Availability,[batch] Fix local backend too many args error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10508:40,error,error,40,https://hail.is,https://github.com/hail-is/hail/pull/10508,1,['error'],['error']
Availability,[batch] Fix publicly available images to include the right mirror,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11048:21,avail,available,21,https://hail.is,https://github.com/hail-is/hail/pull/11048,1,['avail'],['available']
Availability,[batch] Ignore device not found errors in resource usage code,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12752:32,error,errors,32,https://hail.is,https://github.com/hail-is/hail/pull/12752,1,['error'],['errors']
Availability,[batch] Job groups transient error causing a 400 to the user,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14413:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/issues/14413,1,['error'],['error']
Availability,[batch] Logging error: hail_logging.py: 18 fails assertion.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14261:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/issues/14261,1,['error'],['error']
Availability,[batch] Make error messages clearer in the UI and formatted correctly,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10545:13,error,error,13,https://hail.is,https://github.com/hail-is/hail/pull/10545,2,['error'],['error']
Availability,[batch] Mitigate accrued_costs test failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11420:36,failure,failure,36,https://hail.is,https://github.com/hail-is/hail/pull/11420,1,['failure'],['failure']
Availability,[batch] Mitigate test failures by extending batch client timeout,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12709:22,failure,failures,22,https://hail.is,https://github.com/hail-is/hail/pull/12709,1,['failure'],['failures']
Availability,[batch] More debugging information for network namespace errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13509:57,error,errors,57,https://hail.is,https://github.com/hail-is/hail/pull/13509,1,['error'],['errors']
Availability,[batch] More graceful resource usage error handling,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12609:37,error,error,37,https://hail.is,https://github.com/hail-is/hail/pull/12609,1,['error'],['error']
Availability,[batch] Quiet down MJC and MJS logging exceptions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12496:14,down,down,14,https://hail.is,https://github.com/hail-is/hail/pull/12496,1,['down'],['down']
Availability,[batch] Reduce non-essential warning / error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10702:39,error,error,39,https://hail.is,https://github.com/hail-is/hail/pull/10702,1,['error'],['error']
Availability,[batch] Reduce redundant SQL queries for mark_healthy,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11889:15,redundant,redundant,15,https://hail.is,https://github.com/hail-is/hail/pull/11889,1,['redundant'],['redundant']
Availability,[batch] Remove lint errors from test_batch and test_accounts,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12147:20,error,errors,20,https://hail.is,https://github.com/hail-is/hail/pull/12147,1,['error'],['errors']
Availability,[batch] Remove redundant env variable for internal gateway ip,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12005:15,redundant,redundant,15,https://hail.is,https://github.com/hail-is/hail/pull/12005,1,['redundant'],['redundant']
Availability,"[batch] Submitting a Batch using the hailtop.batch library may raise ""Cannot enter into task"" errors",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14051:94,error,errors,94,https://hail.is,https://github.com/hail-is/hail/issues/14051,1,['error'],['errors']
Availability,[batch] Teach BatchPoolExecutor how to handle container errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9543:56,error,errors,56,https://hail.is,https://github.com/hail-is/hail/pull/9543,1,['error'],['errors']
Availability,[batch] Tone down access log messages that are not helpful,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11897:13,down,down,13,https://hail.is,https://github.com/hail-is/hail/pull/11897,1,['down'],['down']
Availability,[batch] Tone down healthcheck exception,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12184:13,down,down,13,https://hail.is,https://github.com/hail-is/hail/pull/12184,1,['down'],['down']
Availability,[batch] Treat unauthorized in docker error message as permission denied,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12708:37,error,error,37,https://hail.is,https://github.com/hail-is/hail/pull/12708,1,['error'],['error']
Availability,[batch] Type checker for dictionaries causes a 500 on failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14350:54,failure,failure,54,https://hail.is,https://github.com/hail-is/hail/issues/14350,1,['failure'],['failure']
Availability,[batch] Update docker client timeout transient error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11942:47,error,error,47,https://hail.is,https://github.com/hail-is/hail/pull/11942,1,['error'],['error']
Availability,[batch] Use /io if available for container volumes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12777:19,avail,available,19,https://hail.is,https://github.com/hail-is/hail/pull/12777,1,['avail'],['available']
Availability,[batch] a deleted batch zombie jobs causes assertion errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6737:53,error,errors,53,https://hail.is,https://github.com/hail-is/hail/issues/6737,1,['error'],['errors']
Availability,[batch] a little gcloud auth resilience,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6797:29,resilien,resilience,29,https://hail.is,https://github.com/hail-is/hail/pull/6797,1,['resilien'],['resilience']
Availability,[batch] add docker retry for specific 500 errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7715:42,error,errors,42,https://hail.is,https://github.com/hail-is/hail/pull/7715,1,['error'],['errors']
Availability,[batch] add error information to debug message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6469:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/6469,1,['error'],['error']
Availability,[batch] add more error information when missing header,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10216:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/10216,1,['error'],['error']
Availability,[batch] add short error message for batch job with unknown image,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10506:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/10506,1,['error'],['error']
Availability,[batch] add transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8189:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/8189,1,['error'],['error']
Availability,[batch] adjust Hail's cost structure to recover operating expenses,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13526:40,recover,recover,40,https://hail.is,https://github.com/hail-is/hail/issues/13526,1,['recover'],['recover']
Availability,[batch] assertion error in delete_pod,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6753:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/issues/6753,1,['error'],['error']
Availability,[batch] better debug info on batch test failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10948:40,failure,failure,40,https://hail.is,https://github.com/hail-is/hail/pull/10948,1,['failure'],['failure']
Availability,[batch] better error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6911:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/6911,1,['error'],['error']
Availability,[batch] catch errors reading logs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6034:14,error,errors,14,https://hail.is,https://github.com/hail-is/hail/pull/6034,1,['error'],['errors']
Availability,[batch] cleanup error message for unknown instance,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10325:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/10325,1,['error'],['error']
Availability,[batch] close all the jvms when the worker shuts down,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11432:49,down,down,49,https://hail.is,https://github.com/hail-is/hail/pull/11432,1,['down'],['down']
Availability,[batch] db must rollback if spec write fails or is cancelled,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11404:16,rollback,rollback,16,https://hail.is,https://github.com/hail-is/hail/pull/11404,1,['rollback'],['rollback']
Availability,[batch] demote callback failure to info,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11383:24,failure,failure,24,https://hail.is,https://github.com/hail-is/hail/pull/11383,1,['failure'],['failure']
Availability,[batch] do not log user errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11377:24,error,errors,24,https://hail.is,https://github.com/hail-is/hail/pull/11377,1,['error'],['errors']
Availability,[batch] downgrade gcsfuse to avoid gcsfuse bug,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12749:8,down,downgrade,8,https://hail.is,https://github.com/hail-is/hail/pull/12749,1,['down'],['downgrade']
Availability,"[batch] driver holds open aiomysql connections after the event loop is destroyed, this triggers a bunch of error logs and a grafana alert",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13863:107,error,error,107,https://hail.is,https://github.com/hail-is/hail/issues/13863,1,['error'],['error']
Availability,[batch] enable 5 JP instances in tests and alleviate failures,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11928:53,failure,failures,53,https://hail.is,https://github.com/hail-is/hail/pull/11928,1,['failure'],['failures']
Availability,[batch] ensure batches are cancelled on error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10762:40,error,error,40,https://hail.is,https://github.com/hail-is/hail/pull/10762,1,['error'],['error']
Availability,[batch] error in get container status results in exit code set to zero even though log retrieval failed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8083:8,error,error,8,https://hail.is,https://github.com/hail-is/hail/issues/8083,1,['error'],['error']
Availability,[batch] failure resilience on insert,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7875:8,failure,failure,8,https://hail.is,https://github.com/hail-is/hail/pull/7875,2,"['failure', 'resilien']","['failure', 'resilience']"
Availability,[batch] fix another logging error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8975:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/8975,1,['error'],['error']
Availability,[batch] fix assertion error in mark_job_task_complete,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6367:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/6367,1,['error'],['error']
Availability,[batch] fix cancellation notification error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7990:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/pull/7990,1,['error'],['error']
Availability,[batch] fix container process is already dead error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8131:46,error,error,46,https://hail.is,https://github.com/hail-is/hail/pull/8131,1,['error'],['error']
Availability,[batch] fix duplicate key insert error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8307:33,error,error,33,https://hail.is,https://github.com/hail-is/hail/pull/8307,1,['error'],['error']
Availability,[batch] fix error msg with multiple jobs with same pod,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6476:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/6476,1,['error'],['error']
Availability,[batch] fix exit code if error is in container execution,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8784:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/8784,1,['error'],['error']
Availability,[batch] fix exit code when error occurred,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8088:27,error,error,27,https://hail.is,https://github.com/hail-is/hail/pull/8088,1,['error'],['error']
Availability,[batch] fix http error code,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7820:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/7820,1,['error'],['error']
Availability,[batch] fix infinite attempts of pvc creation with failure code 403,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6249:51,failure,failure,51,https://hail.is,https://github.com/hail-is/hail/pull/6249,1,['failure'],['failure']
Availability,[batch] fix insertion error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7912:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/7912,1,['error'],['error']
Availability,[batch] fix scheduler error if allocated_cores not found,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7707:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/7707,1,['error'],['error']
Availability,[batch] fix syntax errors in cancel_batch_in_db,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9724:19,error,errors,19,https://hail.is,https://github.com/hail-is/hail/pull/9724,1,['error'],['errors']
Availability,[batch] fix test unauthorized users to be resilient to transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8230:42,resilien,resilient,42,https://hail.is,https://github.com/hail-is/hail/pull/8230,2,"['error', 'resilien']","['errors', 'resilient']"
Availability,[batch] fix user cancel/delete request blocking if driver down,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7913:58,down,down,58,https://hail.is,https://github.com/hail-is/hail/pull/7913,1,['down'],['down']
Availability,[batch] fix worker error handling and add types,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10987:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/10987,1,['error'],['error']
Availability,[batch] give a reasonable error message when no batch billing project is set,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8651:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/pull/8651,1,['error'],['error']
Availability,[batch] handle error in post_job_complete in worker,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8094:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/8094,1,['error'],['error']
Availability,[batch] high log retrieval failure rate (at least 5%),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6545:27,failure,failure,27,https://hail.is,https://github.com/hail-is/hail/issues/6545,1,['failure'],['failure']
Availability,[batch] image pull back off means container failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6784:44,failure,failure,44,https://hail.is,https://github.com/hail-is/hail/pull/6784,1,['failure'],['failure']
Availability,[batch] improve error messages on checks,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9497:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/9497,1,['error'],['error']
Availability,[batch] instance RAM and disk usage is not available in GCP Monitoring,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13903:43,avail,available,43,https://hail.is,https://github.com/hail-is/hail/issues/13903,1,['avail'],['available']
Availability,[batch] lock down disk size until cost calculation is per-instance,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7854:13,down,down,13,https://hail.is,https://github.com/hail-is/hail/pull/7854,1,['down'],['down']
Availability,[batch] locking down secrets and service accounts,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8155:16,down,down,16,https://hail.is,https://github.com/hail-is/hail/pull/8155,1,['down'],['down']
Availability,[batch] log setup failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6961:18,failure,failure,18,https://hail.is,https://github.com/hail-is/hail/pull/6961,1,['failure'],['failure']
Availability,[batch] make tests resilient to concurrent batches,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10928:19,resilien,resilient,19,https://hail.is,https://github.com/hail-is/hail/pull/10928,1,['resilien'],['resilient']
Availability,[batch] merge failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6871:14,failure,failure,14,https://hail.is,https://github.com/hail-is/hail/pull/6871,1,['failure'],['failure']
Availability,[batch] mitigate some of the cost test failures,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11448:39,failure,failures,39,https://hail.is,https://github.com/hail-is/hail/pull/11448,1,['failure'],['failures']
Availability,[batch] more information on integrity error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8632:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/pull/8632,1,['error'],['error']
Availability,[batch] more robust k8s event stream watch,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6511:13,robust,robust,13,https://hail.is,https://github.com/hail-is/hail/pull/6511,1,['robust'],['robust']
Availability,[batch] mysterious error related to unicode,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7769:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/issues/7769,1,['error'],['error']
Availability,[batch] new docker error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8029:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/issues/8029,1,['error'],['error']
Availability,[batch] new transient docker error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11488:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/pull/11488,1,['error'],['error']
Availability,[batch] novel error in copying container logs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8053:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/issues/8053,1,['error'],['error']
Availability,[batch] provide sufficient information to debug transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14151:58,error,errors,58,https://hail.is,https://github.com/hail-is/hail/pull/14151,1,['error'],['errors']
Availability,[batch] quiet down every kind of transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12712:14,down,down,14,https://hail.is,https://github.com/hail-is/hail/pull/12712,2,"['down', 'error']","['down', 'error']"
Availability,[batch] raise error in check incremental,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11279:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/pull/11279,1,['error'],['error']
Availability,[batch] remove redundant super class,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13541:15,redundant,redundant,15,https://hail.is,https://github.com/hail-is/hail/pull/13541,1,['redundant'],['redundant']
Availability,[batch] retry docker image not found error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8442:37,error,error,37,https://hail.is,https://github.com/hail-is/hail/pull/8442,1,['error'],['error']
Availability,[batch] retry downloading jar file,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11857:14,down,downloading,14,https://hail.is,https://github.com/hail-is/hail/pull/11857,1,['down'],['downloading']
Availability,[batch] robust against job tasks running multiple times,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6537:8,robust,robust,8,https://hail.is,https://github.com/hail-is/hail/pull/6537,1,['robust'],['robust']
Availability,[batch] skip ERROR events,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6800:13,ERROR,ERROR,13,https://hail.is,https://github.com/hail-is/hail/pull/6800,1,['ERROR'],['ERROR']
Availability,[batch] sometimes a posting to a keep-alive container fails,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6754:38,alive,alive,38,https://hail.is,https://github.com/hail-is/hail/issues/6754,1,['alive'],['alive']
Availability,[batch] sometimes k8s can send you an error event with no content,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6750:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/issues/6750,1,['error'],['error']
Availability,[batch] track various failure modes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6604:22,failure,failure,22,https://hail.is,https://github.com/hail-is/hail/pull/6604,1,['failure'],['failure']
Availability,[batch] use correct not found error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10918:30,error,error,30,https://hail.is,https://github.com/hail-is/hail/pull/10918,1,['error'],['error']
Availability,[batch] validation errors should be 400 BAD REQUEST,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5032:19,error,errors,19,https://hail.is,https://github.com/hail-is/hail/pull/5032,1,['error'],['errors']
Availability,[batch] variety of errors from the 3000 pod test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6707:19,error,errors,19,https://hail.is,https://github.com/hail-is/hail/issues/6707,1,['error'],['errors']
Availability,[batch] workers have open tasks on shutting down,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13908:44,down,down,44,https://hail.is,https://github.com/hail-is/hail/issues/13908,1,['down'],['down']
Availability,[batch][ci] better error message when the deploy test fails,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8337:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/8337,1,['error'],['error']
Availability,[batch][ci] tolerate preemptibles,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6664:12,toler,tolerate,12,https://hail.is,https://github.com/hail-is/hail/pull/6664,1,['toler'],['tolerate']
Availability,[batch][dag6] Include first 500 character of HTTP body on errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4792:58,error,errors,58,https://hail.is,https://github.com/hail-is/hail/pull/4792,2,['error'],['errors']
Availability,[batch][hail] pervasively retry transient errors in synchronous code,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8391:42,error,errors,42,https://hail.is,https://github.com/hail-is/hail/pull/8391,1,['error'],['errors']
Availability,[batch][hotfix] address driver looping failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8814:39,failure,failure,39,https://hail.is,https://github.com/hail-is/hail/pull/8814,1,['failure'],['failure']
Availability,[benchmark] Don't double-log about downloading,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11813:35,down,downloading,35,https://hail.is,https://github.com/hail-is/hail/pull/11813,1,['down'],['downloading']
Availability,[benchmark] Fix errors in running and analyzing benchmarks,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7878:16,error,errors,16,https://hail.is,https://github.com/hail-is/hail/pull/7878,1,['error'],['errors']
Availability,[benchmark] Make benchmark-on-pipeline more robust,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7877:44,robust,robust,44,https://hail.is,https://github.com/hail-is/hail/pull/7877,1,['robust'],['robust']
Availability,"[benchmark] Tolerate failure in `run`, improve `compare`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6630:12,Toler,Tolerate,12,https://hail.is,https://github.com/hail-is/hail/pull/6630,2,"['Toler', 'failure']","['Tolerate', 'failure']"
Availability,[benchmark] Tolerate tests that kill backend and mark as failed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12838:12,Toler,Tolerate,12,https://hail.is,https://github.com/hail-is/hail/pull/12838,1,['Toler'],['Tolerate']
Availability,[benchmark] Use `wget` instead of urllib to download resources,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7747:44,down,download,44,https://hail.is,https://github.com/hail-is/hail/pull/7747,1,['down'],['download']
Availability,[benchmark] cat output file in case of permissions errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8329:51,error,errors,51,https://hail.is,https://github.com/hail-is/hail/pull/8329,1,['error'],['errors']
Availability,[bugfix][hail] Capture error rather than printing it,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8150:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/pull/8150,1,['error'],['error']
Availability,[build.yaml] Scale down batch-driver before deleting instances,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11896:19,down,down,19,https://hail.is,https://github.com/hail-is/hail/pull/11896,1,['down'],['down']
Availability,[build.yaml] fix deploy failures,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12486:24,failure,failures,24,https://hail.is,https://github.com/hail-is/hail/pull/12486,1,['failure'],['failures']
Availability,"[build] Clarify tag target to echo about release, open browser on OSX",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7072:30,echo,echo,30,https://hail.is,https://github.com/hail-is/hail/pull/7072,1,['echo'],['echo']
Availability,[build] Quiet down tar commands,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7036:14,down,down,14,https://hail.is,https://github.com/hail-is/hail/pull/7036,1,['down'],['down']
Availability,[ci2] loud failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6054:11,failure,failure,11,https://hail.is,https://github.com/hail-is/hail/pull/6054,1,['failure'],['failure']
Availability,[ci] Bring max number of concurrent PRs down to three,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11762:40,down,down,40,https://hail.is,https://github.com/hail-is/hail/pull/11762,1,['down'],['down']
Availability,[ci] Handle errors in heal loop,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13115:12,error,errors,12,https://hail.is,https://github.com/hail-is/hail/pull/13115,1,['error'],['errors']
Availability,[ci] Make git clone resilient to failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8667:20,resilien,resilient,20,https://hail.is,https://github.com/hail-is/hail/pull/8667,2,"['failure', 'resilien']","['failure', 'resilient']"
Availability,[ci] Recover from missing deploy jobs as well,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4683:5,Recover,Recover,5,https://hail.is,https://github.com/hail-is/hail/pull/4683,1,['Recover'],['Recover']
Availability,[ci] We should scan the logs of every service for error conditions on PR tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7625:50,error,error,50,https://hail.is,https://github.com/hail-is/hail/issues/7625,1,['error'],['error']
Availability,[ci] add url to zulip failure notification,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7917:22,failure,failure,22,https://hail.is,https://github.com/hail-is/hail/pull/7917,1,['failure'],['failure']
Availability,[ci] better ci information on deploy failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9781:37,failure,failure,37,https://hail.is,https://github.com/hail-is/hail/pull/9781,1,['failure'],['failure']
Availability,[ci] better errors on bad github response and fix too many status updates,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8480:12,error,errors,12,https://hail.is,https://github.com/hail-is/hail/pull/8480,1,['error'],['errors']
Availability,[ci] change mention for deploy failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10178:31,failure,failure,31,https://hail.is,https://github.com/hail-is/hail/pull/10178,1,['failure'],['failure']
Availability,[ci] do not tag anyone in deploy failures,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11386:33,failure,failures,33,https://hail.is,https://github.com/hail-is/hail/pull/11386,1,['failure'],['failures']
Availability,"[ci] fix ""GitHubAPI object has no attribute 'get'"" error",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8402:51,error,error,51,https://hail.is,https://github.com/hail-is/hail/pull/8402,1,['error'],['error']
Availability,[ci] fix ci bug when a PR hits a merge failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8428:39,failure,failure,39,https://hail.is,https://github.com/hail-is/hail/pull/8428,1,['failure'],['failure']
Availability,[ci] fix index.html template parse error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6414:35,error,error,35,https://hail.is,https://github.com/hail-is/hail/pull/6414,1,['error'],['error']
Availability,[ci] fix print logs on failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8437:23,failure,failure,23,https://hail.is,https://github.com/hail-is/hail/pull/8437,1,['failure'],['failure']
Availability,[ci] hail_curl_image is redundant. kill it.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14490:24,redundant,redundant,24,https://hail.is,https://github.com/hail-is/hail/pull/14490,1,['redundant'],['redundant']
Availability,[ci] handle assertion errors in update_github loop,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6377:22,error,errors,22,https://hail.is,https://github.com/hail-is/hail/pull/6377,1,['error'],['errors']
Availability,"[ci] if no logs are available for a job, do not 500",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6586:20,avail,available,20,https://hail.is,https://github.com/hail-is/hail/issues/6586,1,['avail'],['available']
Availability,[ci] improve error message when we exceed the commit SHA status limit,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8540:13,error,error,13,https://hail.is,https://github.com/hail-is/hail/pull/8540,1,['error'],['error']
Availability,[ci] improve formatting of build errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6811:33,error,errors,33,https://hail.is,https://github.com/hail-is/hail/pull/6811,1,['error'],['errors']
Availability,[ci] make ci tests resilient to slow ci,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5801:19,resilien,resilient,19,https://hail.is,https://github.com/hail-is/hail/pull/5801,1,['resilien'],['resilient']
Availability,[ci] make scope available to migrations,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7708:16,avail,available,16,https://hail.is,https://github.com/hail-is/hail/pull/7708,1,['avail'],['available']
Availability,[ci] make test deployment tolerate preemptibles,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7871:26,toler,tolerate,26,https://hail.is,https://github.com/hail-is/hail/pull/7871,1,['toler'],['tolerate']
Availability,[ci] recover from deleted batches,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6406:5,recover,recover,5,https://hail.is,https://github.com/hail-is/hail/pull/6406,1,['recover'],['recover']
Availability,[ci] report merge failure exception in deploy_status,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9387:18,failure,failure,18,https://hail.is,https://github.com/hail-is/hail/pull/9387,1,['failure'],['failure']
Availability,[ci] teach CI to raise an error when a buildstep duplicates parents,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8829:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/pull/8829,1,['error'],['error']
Availability,[ci] we need a pip install that retries transient errors for use inside docker.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8390:50,error,errors,50,https://hail.is,https://github.com/hail-is/hail/issues/8390,1,['error'],['errors']
Availability,[compiler] Add Trap node for error handling in FoldConstants,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10611:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/pull/10611,1,['error'],['error']
Availability,[compiler] Add more informative failure for methods with too many params,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12513:32,failure,failure,32,https://hail.is,https://github.com/hail-is/hail/pull/12513,1,['failure'],['failure']
Availability,[compiler] Fix bad export_vcf filters error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11168:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/pull/11168,1,['error'],['error']
Availability,[compiler] rewrite ExtractIntervalFilters to be more robust,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13355:53,robust,robust,53,https://hail.is,https://github.com/hail-is/hail/pull/13355,1,['robust'],['robust']
Availability,[copy] Fix assertion error on exceptions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10226:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/pull/10226,1,['error'],['error']
Availability,"[curl] pervasively use retries, report errors, follow redirects",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11183:39,error,errors,39,https://hail.is,https://github.com/hail-is/hail/pull/11183,1,['error'],['errors']
Availability,[datasets api] switch to https for downloading CADD,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8509:35,down,downloading,35,https://hail.is,https://github.com/hail-is/hail/pull/8509,1,['down'],['downloading']
Availability,[datasets] update gnomAD datasets available via Datasets API/Annotation DB,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11608:34,avail,available,34,https://hail.is,https://github.com/hail-is/hail/pull/11608,1,['avail'],['available']
Availability,[datasets] update pan-UKB datasets and make available via GCS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12073:44,avail,available,44,https://hail.is,https://github.com/hail-is/hail/pull/12073,1,['avail'],['available']
Availability,[dbuf] more resilience to intermitent failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8219:12,resilien,resilience,12,https://hail.is,https://github.com/hail-is/hail/pull/8219,2,"['failure', 'resilien']","['failure', 'resilience']"
Availability,[debug] hailctl batch submit transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14149:39,error,errors,39,https://hail.is,https://github.com/hail-is/hail/pull/14149,1,['error'],['errors']
Availability,[deploy] assert sufficient space is available at PyPI in deploy,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13118:36,avail,available,36,https://hail.is,https://github.com/hail-is/hail/pull/13118,1,['avail'],['available']
Availability,[dev] Make test-dataproc target robust to __pycache__,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6622:32,robust,robust,32,https://hail.is,https://github.com/hail-is/hail/pull/6622,1,['robust'],['robust']
Availability,[docker] Teach Hail Ubuntu Image how to resiliently install apt packages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9594:40,resilien,resiliently,40,https://hail.is,https://github.com/hail-is/hail/pull/9594,1,['resilien'],['resiliently']
Availability,[docker] Trim down service images,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12578:14,down,down,14,https://hail.is,https://github.com/hail-is/hail/pull/12578,1,['down'],['down']
Availability,[docker] bump nest_asyncio version to fix transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10705:52,error,error,52,https://hail.is,https://github.com/hail-is/hail/pull/10705,1,['error'],['error']
Availability,[docker] retry apt download at most 3 times,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9565:19,down,download,19,https://hail.is,https://github.com/hail-is/hail/pull/9565,1,['down'],['download']
Availability,[docker] slim down base image by 700 MB,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9414:14,down,down,14,https://hail.is,https://github.com/hail-is/hail/pull/9414,1,['down'],['down']
Availability,[docs] Add a download link for a .tar.gz with tutorials,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6986:13,down,download,13,https://hail.is,https://github.com/hail-is/hail/pull/6986,1,['down'],['download']
Availability,[docs] Document fix for BLAS error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7051:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/pull/7051,1,['error'],['error']
Availability,[echo] implement a TCP echo server,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9681:1,echo,echo,1,https://hail.is,https://github.com/hail-is/hail/pull/9681,2,['echo'],['echo']
Availability,[feature] Add checkpoint methods to MT/Table,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5528:14,checkpoint,checkpoint,14,https://hail.is,https://github.com/hail-is/hail/pull/5528,1,['checkpoint'],['checkpoint']
Availability,[fs] Add azure blob path to FileNotFound error in read,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11214:41,error,error,41,https://hail.is,https://github.com/hail-is/hail/pull/11214,1,['error'],['error']
Availability,[fs] Add sink write failure in ABS to transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14430:20,failure,failure,20,https://hail.is,https://github.com/hail-is/hail/pull/14430,2,"['error', 'failure']","['errors', 'failure']"
Availability,[fs] Fix some errors closing sessions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10522:14,error,errors,14,https://hail.is,https://github.com/hail-is/hail/pull/10522,1,['error'],['errors']
Availability,[fs] rare transient error when writing to google cloud storage,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13742:20,error,error,20,https://hail.is,https://github.com/hail-is/hail/issues/13742,1,['error'],['error']
Availability,[gear/auth] do not log on cancelled error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10916:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/pull/10916,1,['error'],['error']
Availability,[gear] Retry Too many connections error for mysql,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11330:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/11330,1,['error'],['error']
Availability,[gear] Retry transient errors on database pool creation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14309:23,error,errors,23,https://hail.is,https://github.com/hail-is/hail/pull/14309,1,['error'],['errors']
Availability,[gear] add retry on deadlock errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7782:29,error,errors,29,https://hail.is,https://github.com/hail-is/hail/pull/7782,1,['error'],['errors']
Availability,[gear] retry can't connect to mysql error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8237:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/pull/8237,1,['error'],['error']
Availability,[ggplot] avoid weird dataframe error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12337:31,error,error,31,https://hail.is,https://github.com/hail-is/hail/pull/12337,1,['error'],['error']
Availability,[hail.fs] make rmtree retry transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10935:38,error,errors,38,https://hail.is,https://github.com/hail-is/hail/pull/10935,1,['error'],['errors']
Availability,[hail] Bad error message from export_vcf,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7584:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/issues/7584,1,['error'],['error']
Availability,[hail] Fix bad error messages in aggregator transformations,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7762:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/7762,1,['error'],['error']
Availability,[hail] Fix crash when constant-folding functions that throw errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7642:60,error,errors,60,https://hail.is,https://github.com/hail-is/hail/pull/7642,1,['error'],['errors']
Availability,[hail] Implement staged downsample aggregator,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7197:24,down,downsample,24,https://hail.is,https://github.com/hail-is/hail/pull/7197,1,['down'],['downsample']
Availability,[hail] Push down interval filters into reads with index,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7342:12,down,down,12,https://hail.is,https://github.com/hail-is/hail/pull/7342,1,['down'],['down']
Availability,[hail] Raise a warning instead of an error on `hl.init(sc=sc)`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7172:37,error,error,37,https://hail.is,https://github.com/hail-is/hail/pull/7172,1,['error'],['error']
Availability,[hail] RegionPool echoes at a doubling size threshold,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7076:18,echo,echoes,18,https://hail.is,https://github.com/hail-is/hail/pull/7076,1,['echo'],['echoes']
Availability,[hail] Useful error message instead of NPE on missing resource,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4678:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/pull/4678,1,['error'],['error']
Availability,[hail] Warnings are errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5951:20,error,errors,20,https://hail.is,https://github.com/hail-is/hail/pull/5951,1,['error'],['errors']
Availability,[hail] Wrap AbstractRVDSpec.read failure to log the path,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9514:33,failure,failure,33,https://hail.is,https://github.com/hail-is/hail/pull/9514,1,['failure'],['failure']
Availability,[hail] bad error message in import_matrix_table,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['error'],['error']
Availability,[hail] bad error on locus_from_global_position OOB,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8114:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/issues/8114,1,['error'],['error']
Availability,[hail] error if IR is defined in neither emit nor emitI,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8713:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/pull/8713,1,['error'],['error']
Availability,[hail] fix init_notebook.py error handling,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9002:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/9002,1,['error'],['error']
Availability,[hail] fix init_notebook.py error handling 2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9003:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/9003,1,['error'],['error']
Availability,[hail] fix location of hail jar in error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11179:35,error,error,35,https://hail.is,https://github.com/hail-is/hail/pull/11179,1,['error'],['error']
Availability,[hail] improve error message for MatrixTable.__getitem__,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6781:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/6781,1,['error'],['error']
Availability,[hail] include Python stack trace in ArrayRef out-of-bounds error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7792:60,error,error,60,https://hail.is,https://github.com/hail-is/hail/pull/7792,1,['error'],['error']
Availability,[hail] make Hail PyPI deployment robust,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4812:33,robust,robust,33,https://hail.is,https://github.com/hail-is/hail/pull/4812,1,['robust'],['robust']
Availability,[hail] nicer error msg for ibd,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6063:13,error,error,13,https://hail.is,https://github.com/hail-is/hail/pull/6063,1,['error'],['error']
Availability,[hail] no more double close errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9001:28,error,errors,28,https://hail.is,https://github.com/hail-is/hail/pull/9001,1,['error'],['errors']
Availability,[hail] retry gradle download,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8782:20,down,download,20,https://hail.is,https://github.com/hail-is/hail/pull/8782,1,['down'],['download']
Availability,[hail] retry transient errors in get_1kg,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8218:23,error,errors,23,https://hail.is,https://github.com/hail-is/hail/pull/8218,1,['error'],['errors']
Availability,[hail] using a reference fasta seems to trigger mkdirs errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6564:55,error,errors,55,https://hail.is,https://github.com/hail-is/hail/issues/6564,1,['error'],['errors']
Availability,[hail][bad error message] Improve errors when trying to import dirs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5302:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/pull/5302,2,['error'],"['error', 'errors']"
Availability,[hail][bugfix] Don't push down intervals into old files,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7588:26,down,down,26,https://hail.is,https://github.com/hail-is/hail/pull/7588,1,['down'],['down']
Availability,[hail][bugfix] Fix divide by zero error in `hl.concordance`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7976:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/7976,1,['error'],['error']
Availability,[hail][feature] Improve DictExpression.__getitem__ error message.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6202:51,error,error,51,https://hail.is,https://github.com/hail-is/hail/pull/6202,1,['error'],['error']
Availability,[hail][hailctl] hailctl fails with cryptic error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6565:43,error,error,43,https://hail.is,https://github.com/hail-is/hail/issues/6565,1,['error'],['error']
Availability,[hail][internal] Improve error messages when normalize names fails,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8764:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/8764,1,['error'],['error']
Availability,[hail][ir] improve error message when unify fails in PruneDeadFields,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8728:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/8728,1,['error'],['error']
Availability,[hail][ir] teach function registry to raise helpful errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8716:52,error,errors,52,https://hail.is,https://github.com/hail-is/hail/pull/8716,1,['error'],['errors']
Availability,[hailctl dataproc] Tolerate user passing --pkgs that we set,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8946:19,Toler,Tolerate,19,https://hail.is,https://github.com/hail-is/hail/pull/8946,1,['Toler'],['Tolerate']
Availability,[hailctl] Error in `hailctl dataproc modify` instead of silently exit,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7717:10,Error,Error,10,https://hail.is,https://github.com/hail-is/hail/pull/7717,1,['Error'],['Error']
Availability,[hailctl] Improve VEP region error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8462:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/pull/8462,1,['error'],['error']
Availability,[hailctl] error on unrecognized arguments,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12524:10,error,error,10,https://hail.is,https://github.com/hail-is/hail/pull/12524,1,['error'],['error']
Availability,[hailctl] generate a friendly error message if not authenticated,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7035:30,error,error,30,https://hail.is,https://github.com/hail-is/hail/pull/7035,1,['error'],['error']
Availability,[hailctl] retry copy paste login on transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8669:46,error,error,46,https://hail.is,https://github.com/hail-is/hail/pull/8669,1,['error'],['error']
Availability,[hailctl][devdeploy] improve error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8846:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/pull/8846,1,['error'],['error']
Availability,[hailgenetics/hail] slim down to ~1.5GiB from 2.8GiB,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12526:25,down,down,25,https://hail.is,https://github.com/hail-is/hail/pull/12526,1,['down'],['down']
Availability,[hailtop.batch] Fix BatchPoolExecutor to cancel batches on errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10696:59,error,errors,59,https://hail.is,https://github.com/hail-is/hail/pull/10696,1,['error'],['errors']
Availability,[hailtop.utils] Add address not available as a retryable error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14185:32,avail,available,32,https://hail.is,https://github.com/hail-is/hail/pull/14185,2,"['avail', 'error']","['available', 'error']"
Availability,[hailtop.utils] Add new transient error to the list,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11817:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/11817,1,['error'],['error']
Availability,[hailtop.utils] Add quota exceeded to transient error list,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10620:48,error,error,48,https://hail.is,https://github.com/hail-is/hail/pull/10620,1,['error'],['error']
Availability,"[hailtop.utils] include std{out, err} in subprocess failure exception",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7457:52,failure,failure,52,https://hail.is,https://github.com/hail-is/hail/pull/7457,1,['failure'],['failure']
Availability,[hailtop] Add TransportError to list of transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8111:50,error,errors,50,https://hail.is,https://github.com/hail-is/hail/pull/8111,1,['error'],['errors']
Availability,[hailtop] Don't log rate limit errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14605:31,error,errors,31,https://hail.is,https://github.com/hail-is/hail/pull/14605,1,['error'],['errors']
Availability,[hailtop] Don't log rate limit errors at info or warning level,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14595:31,error,errors,31,https://hail.is,https://github.com/hail-is/hail/issues/14595,1,['error'],['errors']
Availability,[hailtop] Dont assume exact error message match for ClientPayloadError retrying,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14545:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/14545,1,['error'],['error']
Availability,[hailtop] add new transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11169:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/11169,1,['error'],['error']
Availability,[hailtop] add retry once errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11917:25,error,errors,25,https://hail.is,https://github.com/hail-is/hail/pull/11917,1,['error'],['errors']
Availability,[hailtop] avoid errors on rare transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13921:16,error,errors,16,https://hail.is,https://github.com/hail-is/hail/pull/13921,2,['error'],['errors']
Availability,[hailtop] batch client: only retry temporary failures,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7215:45,failure,failures,45,https://hail.is,https://github.com/hail-is/hail/pull/7215,1,['failure'],['failures']
Availability,[hailtop] better errors in Azure FS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11292:17,error,errors,17,https://hail.is,https://github.com/hail-is/hail/pull/11292,1,['error'],['errors']
Availability,[hailtop] eagerly give transient error info and include delay,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11769:33,error,error,33,https://hail.is,https://github.com/hail-is/hail/pull/11769,1,['error'],['error']
Availability,[hailtop] fix retry transient errors not falling through if statements,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8103:30,error,errors,30,https://hail.is,https://github.com/hail-is/hail/pull/8103,1,['error'],['errors']
Availability,[hailtop] improve stack traces for retry once errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11948:46,error,errors,46,https://hail.is,https://github.com/hail-is/hail/pull/11948,1,['error'],['errors']
Availability,[hailtop] less noisy and less scary warning for transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11818:58,error,errors,58,https://hail.is,https://github.com/hail-is/hail/pull/11818,1,['error'],['errors']
Availability,[hailtop] log every tenth error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7759:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/pull/7759,1,['error'],['error']
Availability,[hailtop] use the exact same error message for sync and async,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10312:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/pull/10312,1,['error'],['error']
Availability,[hailtop] we forgot to note one of the two error codes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11043:43,error,error,43,https://hail.is,https://github.com/hail-is/hail/pull/11043,1,['error'],['error']
Availability,[hailtop] yet another transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13817:32,error,error,32,https://hail.is,https://github.com/hail-is/hail/pull/13817,1,['error'],['error']
Availability,[hailtop][batch] unify & simplify docker transient error handling,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11943:51,error,error,51,https://hail.is,https://github.com/hail-is/hail/pull/11943,2,['error'],['error']
Availability,[hdinsight] fix syntax error in hdinisght/resources/install-vep.sh,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12870:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/pull/12870,1,['error'],['error']
Availability,"[image-fetcher,site] clean up normal bash output from error logs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9991:54,error,error,54,https://hail.is,https://github.com/hail-is/hail/pull/9991,1,['error'],['error']
Availability,[image-fetcher] only redirect errors to stderr and remove old Make rules,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9930:30,error,errors,30,https://hail.is,https://github.com/hail-is/hail/pull/9930,1,['error'],['errors']
Availability,[infra] dev namespaces should scale down,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14020:36,down,down,36,https://hail.is,https://github.com/hail-is/hail/issues/14020,1,['down'],['down']
Availability,[infra] use skopeo for copying when its available,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11190:40,avail,available,40,https://hail.is,https://github.com/hail-is/hail/pull/11190,1,['avail'],['available']
Availability,[is.hail.services] more transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10945:34,error,errors,34,https://hail.is,https://github.com/hail-is/hail/pull/10945,1,['error'],['errors']
Availability,[java-services] add new transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11402:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/11402,1,['error'],['error']
Availability,[jvm-services] add retry once errors to JVM too,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11947:30,error,errors,30,https://hail.is,https://github.com/hail-is/hail/pull/11947,1,['error'],['errors']
Availability,[k8s] Hail should have no k8s error logs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13557:30,error,error,30,https://hail.is,https://github.com/hail-is/hail/issues/13557,1,['error'],['error']
Availability,[k8s] Scale down dev namespaces every night,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13462:12,down,down,12,https://hail.is,https://github.com/hail-is/hail/pull/13462,1,['down'],['down']
Availability,[k8s] more PDBs to allow scale down of non-preemptibles,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13384:31,down,down,31,https://hail.is,https://github.com/hail-is/hail/pull/13384,1,['down'],['down']
Availability,[linting] Catch unintended errors in check-sql.sh,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13745:27,error,errors,27,https://hail.is,https://github.com/hail-is/hail/pull/13745,1,['error'],['errors']
Availability,[notebook] Fix error page,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7158:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/7158,1,['error'],['error']
Availability,[notebook] Make notebook deletion reliable,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4863:34,reliab,reliable,34,https://hail.is,https://github.com/hail-is/hail/pull/4863,1,['reliab'],['reliable']
Availability,[notebook] Tolerate spot instances on Azure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11107:11,Toler,Tolerate,11,https://hail.is,https://github.com/hail-is/hail/pull/11107,1,['Toler'],['Tolerate']
Availability,[notebook] download the course tar,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4965:11,down,download,11,https://hail.is,https://github.com/hail-is/hail/pull/4965,1,['down'],['download']
Availability,[notebook] fix notebook error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7255:24,error,error,24,https://hail.is,https://github.com/hail-is/hail/pull/7255,1,['error'],['error']
Availability,[notebook] fix resource requests so deployment can downscale,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10230:51,down,downscale,51,https://hail.is,https://github.com/hail-is/hail/pull/10230,1,['down'],['downscale']
Availability,[notebook] fix syntactic error in JSON,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4990:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/4990,1,['error'],['error']
Availability,[notebook] workaround for pip error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5227:30,error,error,30,https://hail.is,https://github.com/hail-is/hail/pull/5227,1,['error'],['error']
Availability,[pipeline] fix failed jobs error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6354:27,error,error,27,https://hail.is,https://github.com/hail-is/hail/pull/6354,1,['error'],['error']
Availability,[pipeline] fix job id in error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6255:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/6255,1,['error'],['error']
Availability,[pipeline] tricky errors on typos,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8011:18,error,errors,18,https://hail.is,https://github.com/hail-is/hail/issues/8011,1,['error'],['errors']
Availability,[pytest] Treat most warnings as errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12322:32,error,errors,32,https://hail.is,https://github.com/hail-is/hail/pull/12322,1,['error'],['errors']
Availability,"[qob] In GCS, recreate the ReadChannel if a transient error occurs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13730:54,error,error,54,https://hail.is,https://github.com/hail-is/hail/pull/13730,1,['error'],['error']
Availability,[qob] Invalidate batch cache on error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12519:32,error,error,32,https://hail.is,https://github.com/hail-is/hail/pull/12519,1,['error'],['error']
Availability,[qob] cleanup QoB tests without erroring,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13564:32,error,erroring,32,https://hail.is,https://github.com/hail-is/hail/pull/13564,1,['error'],['erroring']
Availability,[qob] install-for-qob errors if javac is not 1.8,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13734:22,error,errors,22,https://hail.is,https://github.com/hail-is/hail/pull/13734,1,['error'],['errors']
Availability,[qob] log4j errors are showing up in JVM container logs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13242:12,error,errors,12,https://hail.is,https://github.com/hail-is/hail/issues/13242,1,['error'],['errors']
Availability,[qob] novel transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13075:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/13075,1,['error'],['error']
Availability,[qob] permissions error is not propagated back to driver job properly,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['error'],['error']
Availability,[qob] retry transient errors reading the results file,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12867:22,error,errors,22,https://hail.is,https://github.com/hail-is/hail/pull/12867,1,['error'],['errors']
Availability,[qob][batch] do not list all jobs on failure (plus: types!),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13500:37,failure,failure,37,https://hail.is,https://github.com/hail-is/hail/pull/13500,1,['failure'],['failure']
Availability,[query/service] fast path for checkpoint and persist,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11677:30,checkpoint,checkpoint,30,https://hail.is,https://github.com/hail-is/hail/pull/11677,1,['checkpoint'],['checkpoint']
Availability,[query/service] fix some errors revealed by pyright,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11600:25,error,errors,25,https://hail.is,https://github.com/hail-is/hail/pull/11600,1,['error'],['errors']
Availability,[query/service] make available driver progress information,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11746:21,avail,available,21,https://hail.is,https://github.com/hail-is/hail/pull/11746,1,['avail'],['available']
Availability,[query/service] retry entire partition when we encounter transient errors in compiled code,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11716:67,error,errors,67,https://hail.is,https://github.com/hail-is/hail/pull/11716,1,['error'],['errors']
Availability,[query/service] use error id to raise user-friendly errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11624:20,error,error,20,https://hail.is,https://github.com/hail-is/hail/pull/11624,4,['error'],"['error', 'errors']"
Availability,[query/services] retry Azure errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11919:29,error,errors,29,https://hail.is,https://github.com/hail-is/hail/pull/11919,1,['error'],['errors']
Availability,[query/vds] Don't error if combiner is finished and output exists,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14397:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/14397,1,['error'],['error']
Availability,[query] Add `hl.die` function for error checking.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8865:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/8865,1,['error'],['error']
Availability,[query] Add back line context to table parsing errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8900:47,error,errors,47,https://hail.is,https://github.com/hail-is/hail/pull/8900,1,['error'],['errors']
Availability,[query] Add better error to CastMatrixToTable length check,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12178:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/12178,1,['error'],['error']
Availability,"[query] Add good error messages for semi/anti join, fix semantics",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12316:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/12316,1,['error'],['error']
Availability,[query] Add more transient error handling,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14516:27,error,error,27,https://hail.is,https://github.com/hail-is/hail/pull/14516,1,['error'],['error']
Availability,[query] Add nicer errors for unsupported functionality in the service,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11641:18,error,errors,18,https://hail.is,https://github.com/hail-is/hail/pull/11641,1,['error'],['errors']
Availability,[query] Automatically copy logs off spark driver before failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14431:56,failure,failure,56,https://hail.is,https://github.com/hail-is/hail/issues/14431,1,['failure'],['failure']
Availability,[query] Better error message on locus_windows,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11321:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/11321,1,['error'],['error']
Availability,[query] Better error message when using `in` incorrectly,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9164:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/9164,1,['error'],['error']
Availability,[query] Better error messages for unsupported types in export_vcf,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13682:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/13682,1,['error'],['error']
Availability,[query] Better import vcf error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10819:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/pull/10819,1,['error'],['error']
Availability,[query] Better intersect assertion error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8701:35,error,error,35,https://hail.is,https://github.com/hail-is/hail/pull/8701,1,['error'],['error']
Availability,[query] Copy spark driver log to remote tmpdir on error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14447:50,error,error,50,https://hail.is,https://github.com/hail-is/hail/pull/14447,1,['error'],['error']
Availability,[query] Don't error on VCF export when haploid call is unphased,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14375:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/pull/14375,1,['error'],['error']
Availability,[query] Erroneous error on export_vcf when exporting haploid calls,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14330:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/issues/14330,1,['error'],['error']
Availability,[query] ErrorIDs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10655:8,Error,ErrorIDs,8,https://hail.is,https://github.com/hail-is/hail/pull/10655,1,['Error'],['ErrorIDs']
Availability,[query] Failures to communicate with the spark/local backend result in cryptic error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14557:8,Failure,Failures,8,https://hail.is,https://github.com/hail-is/hail/issues/14557,2,"['Failure', 'error']","['Failures', 'error']"
Availability,[query] Fix Benchmark Failures,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13954:22,Failure,Failures,22,https://hail.is,https://github.com/hail-is/hail/pull/13954,1,['Failure'],['Failures']
Availability,[query] Fix `hl.agg.downsample` inside array_agg or group_by,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8273:20,down,downsample,20,https://hail.is,https://github.com/hail-is/hail/pull/8273,1,['down'],['downsample']
Availability,[query] Fix attr error for struct collections,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8466:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/8466,1,['error'],['error']
Availability,[query] Fix bad error message from `mt.make_table()` with missing keys,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8275:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/8275,1,['error'],['error']
Availability,"[query] Fix bug in call decoding, add error ID to lgt_to_gt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11022:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/pull/11022,2,['error'],['error']
Availability,[query] Fix corner case assertion failure in tabix read,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9304:34,failure,failure,34,https://hail.is,https://github.com/hail-is/hail/pull/9304,1,['failure'],['failure']
Availability,[query] Fix error context for import_table impute too,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8906:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/8906,1,['error'],['error']
Availability,[query] Fix errors in LowerToCDA.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9202:12,error,errors,12,https://hail.is,https://github.com/hail-is/hail/pull/9202,1,['error'],['errors']
Availability,[query] Fix int overflow in generic lines and add error for size limit,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10790:50,error,error,50,https://hail.is,https://github.com/hail-is/hail/pull/10790,1,['error'],['error']
Availability,[query] Fix magic collection struct errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10608:36,error,errors,36,https://hail.is,https://github.com/hail-is/hail/pull/10608,1,['error'],['errors']
Availability,[query] Fix partitioner memory error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8987:31,error,error,31,https://hail.is,https://github.com/hail-is/hail/pull/8987,1,['error'],['error']
Availability,[query] Good error for `localize_entries` to existing field name,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12080:13,error,error,13,https://hail.is,https://github.com/hail-is/hail/pull/12080,1,['error'],['error']
Availability,[query] GoogleFS: recreate reader on transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13371:47,error,error,47,https://hail.is,https://github.com/hail-is/hail/pull/13371,1,['error'],['error']
Availability,[query] Improve error handling and job tracking in ServiceBackend,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14751:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/14751,1,['error'],['error']
Availability,[query] Improve error message from hadoop_ls when file does not exist,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10007:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/10007,1,['error'],['error']
Availability,[query] Improve file compatibility error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10191:35,error,error,35,https://hail.is,https://github.com/hail-is/hail/pull/10191,1,['error'],['error']
Availability,"[query] In Azure, QoB sees elevated rates of weird errors from the Azure Blob Storage SDK",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13351:51,error,errors,51,https://hail.is,https://github.com/hail-is/hail/issues/13351,1,['error'],['errors']
Availability,"[query] In Google, large pipelines which encounter transient errors often fail to cleanly restart.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13356:61,error,errors,61,https://hail.is,https://github.com/hail-is/hail/issues/13356,1,['error'],['errors']
Availability,[query] Include file in metadata parse error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8879:39,error,error,39,https://hail.is,https://github.com/hail-is/hail/pull/8879,1,['error'],['error']
Availability,[query] Include info field key in parse error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10211:40,error,error,40,https://hail.is,https://github.com/hail-is/hail/pull/10211,1,['error'],['error']
Availability,[query] Inspect error causes in isRetryOnceError,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11963:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/11963,1,['error'],['error']
Availability,[query] Log FASTA downloads,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12217:18,down,downloads,18,https://hail.is,https://github.com/hail-is/hail/pull/12217,1,['down'],['downloads']
Availability,[query] Make export entries by col more fault-tolerant,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8558:40,fault,fault-tolerant,40,https://hail.is,https://github.com/hail-is/hail/pull/8558,1,['fault'],['fault-tolerant']
Availability,[query] MakeNDArray uses Better Python Error system,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10095:39,Error,Error,39,https://hail.is,https://github.com/hail-is/hail/pull/10095,1,['Error'],['Error']
Availability,[query] Match Error Unreachable Interval,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10765:14,Error,Error,14,https://hail.is,https://github.com/hail-is/hail/pull/10765,1,['Error'],['Error']
Availability,"[query] Memory error in VDS combiner after adding, then immidiately dropping a field.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14705:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/issues/14705,1,['error'],['error']
Availability,[query] NDArray Matmul Better Error Message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10298:30,Error,Error,30,https://hail.is,https://github.com/hail-is/hail/pull/10298,1,['Error'],['Error']
Availability,[query] Provide more informative error on tabix crash,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9065:33,error,error,33,https://hail.is,https://github.com/hail-is/hail/pull/9065,1,['error'],['error']
Availability,[query] Remove unused and redundant requirements,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13988:26,redundant,redundant,26,https://hail.is,https://github.com/hail-is/hail/pull/13988,1,['redundant'],['redundant']
Availability,[query] Retry downloadStreamWithResponse in AzureStorageFS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12261:14,down,downloadStreamWithResponse,14,https://hail.is,https://github.com/hail-is/hail/pull/12261,1,['down'],['downloadStreamWithResponse']
Availability,[query] Retry transient errors in HadoopFS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12411:24,error,errors,24,https://hail.is,https://github.com/hail-is/hail/pull/12411,1,['error'],['errors']
Availability,[query] SIGSEGV from downsample aggregator,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8240:21,down,downsample,21,https://hail.is,https://github.com/hail-is/hail/issues/8240,1,['down'],['downsample']
Availability,[query] Slightly better Error Message from realized_relationship_matrix,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9733:24,Error,Error,24,https://hail.is,https://github.com/hail-is/hail/pull/9733,1,['Error'],['Error']
Availability,[query] Throw a validation error for queries that read/write same path,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8327:27,error,error,27,https://hail.is,https://github.com/hail-is/hail/pull/8327,1,['error'],['error']
Availability,[query] Throw better error in VCFLine.nextField if separator is not a tab,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9494:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/pull/9494,1,['error'],['error']
Availability,[query] Unhandled transient error for GCS 503s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13937:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/issues/13937,1,['error'],['error']
Availability,[query] Update ExportVCF error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14742:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/14742,1,['error'],['error']
Availability,[query] Update requiredness of DownsampleAggregator,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8299:31,Down,DownsampleAggregator,31,https://hail.is,https://github.com/hail-is/hail/pull/8299,1,['Down'],['DownsampleAggregator']
Availability,[query] Use error code for ArrayRef,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10119:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/10119,1,['error'],['error']
Availability,[query] Use fast LZ4 codec for Table.checkpoint,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9264:37,checkpoint,checkpoint,37,https://hail.is,https://github.com/hail-is/hail/pull/9264,1,['checkpoint'],['checkpoint']
Availability,[query] Zip length mismatch error on join,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13486:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/issues/13486,1,['error'],['error']
Availability,[query] add a small & incomplete test suite for good index errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12566:59,error,errors,59,https://hail.is,https://github.com/hail-is/hail/pull/12566,1,['error'],['errors']
Availability,[query] add max_iterations and tolerance parameters to all iterative regressions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11759:31,toler,tolerance,31,https://hail.is,https://github.com/hail-is/hail/pull/11759,1,['toler'],['tolerance']
Availability,[query] address another rare Google error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12523:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/pull/12523,1,['error'],['error']
Availability,[query] await batch debug info on error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12494:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/12494,1,['error'],['error']
Availability,[query] bad error message in ir/renderer.py,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13788:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/issues/13788,1,['error'],['error']
Availability,[query] bad error message when indexing a matrix table with row keys,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14237:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/issues/14237,1,['error'],['error']
Availability,[query] bad error message when user needs to use array_elements_required=False,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13346:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/issues/13346,1,['error'],['error']
Availability,[query] better error message in union_cols,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13144:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/13144,1,['error'],['error']
Availability,[query] better error message when info array field has missing elements,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14105:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/14105,1,['error'],['error']
Availability,[query] better error messages for hstack and vstack,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12636:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/12636,1,['error'],['error']
Availability,[query] better hl.nd.concatenate error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12750:33,error,error,33,https://hail.is,https://github.com/hail-is/hail/pull/12750,1,['error'],['error']
Availability,[query] cleave Backend paths into normal parallelize and parallelize returning errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14085:79,error,errors,79,https://hail.is,https://github.com/hail-is/hail/pull/14085,1,['error'],['errors']
Availability,[query] error in Make if git is missing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12872:8,error,error,8,https://hail.is,https://github.com/hail-is/hail/pull/12872,1,['error'],['error']
Availability,[query] error when annotating a matrix table with a table (joins),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13339:8,error,error,8,https://hail.is,https://github.com/hail-is/hail/issues/13339,1,['error'],['error']
Availability,[query] error when sampling an entries table,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14303:8,error,error,8,https://hail.is,https://github.com/hail-is/hail/issues/14303,1,['error'],['error']
Availability,[query] fix error in hardy_weinberg_test docs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10750:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/10750,1,['error'],['error']
Availability,[query] fix lint errors in matrixtable.py,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8749:17,error,errors,17,https://hail.is,https://github.com/hail-is/hail/pull/8749,1,['error'],['errors']
Availability,[query] fix matrix table query error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9110:31,error,error,31,https://hail.is,https://github.com/hail-is/hail/pull/9110,1,['error'],['error']
Availability,[query] handle retry once errors in the correct order,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12160:26,error,errors,26,https://hail.is,https://github.com/hail-is/hail/pull/12160,2,['error'],['errors']
Availability,"[query] hl.plot.manhattan uses `collect_all=True` to mean ""do not downsample",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13696:66,down,downsample,66,https://hail.is,https://github.com/hail-is/hail/issues/13696,1,['down'],['downsample']
Availability,[query] import_table better error empty missing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11078:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/11078,1,['error'],['error']
Availability,[query] import_vcf: tolerate Flag fields with invalid number,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10491:20,toler,tolerate,20,https://hail.is,https://github.com/hail-is/hail/pull/10491,1,['toler'],['tolerate']
Availability,[query] improve error message when HAIL_CLOUD is unset,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12687:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/12687,1,['error'],['error']
Availability,[query] improve error message when rng_nonce is unparseable,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12688:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/12688,1,['error'],['error']
Availability,[query] improve hl.agg.call_stats error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12676:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/12676,1,['error'],['error']
Availability,[query] increase tolerance in approx_cdf tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14058:17,toler,tolerance,17,https://hail.is,https://github.com/hail-is/hail/pull/14058,1,['toler'],['tolerance']
Availability,[query] increase whitening test tolerance,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12921:32,toler,tolerance,32,https://hail.is,https://github.com/hail-is/hail/pull/12921,1,['toler'],['tolerance']
Availability,[query] persist is checkpoint,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11936:19,checkpoint,checkpoint,19,https://hail.is,https://github.com/hail-is/hail/pull/11936,1,['checkpoint'],['checkpoint']
Availability,[query] persist=checkpoint in all backends,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12309:16,checkpoint,checkpoint,16,https://hail.is,https://github.com/hail-is/hail/pull/12309,1,['checkpoint'],['checkpoint']
Availability,[query] pipeline triggers type inference failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13699:41,failure,failure,41,https://hail.is,https://github.com/hail-is/hail/issues/13699,1,['failure'],['failure']
Availability,[query] provide a better error message in test_ndarray_solve,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10365:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/10365,1,['error'],['error']
Availability,[query] rare Google Cloud Storage error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13721:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/issues/13721,1,['error'],['error']
Availability,[query] relax tolerance in local whitening test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14053:14,toler,tolerance,14,https://hail.is,https://github.com/hail-is/hail/pull/14053,1,['toler'],['tolerance']
Availability,[query] show and checkpoint are very slow in Jupyter Notebooks; they are not slow outside Jupyter,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13690:17,checkpoint,checkpoint,17,https://hail.is,https://github.com/hail-is/hail/issues/13690,1,['checkpoint'],['checkpoint']
Availability,[query][qob] simplify QoB error handling and fix flaky test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12470:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/pull/12470,2,['error'],['error']
Availability,"[ruff](https://beta.ruff.rs/docs/) is a *very* fast linter that we can use as a drop-in replacement for flake8 and isort. Fast enough to run in a pre-commit hook. While there are many pylint rules implemented in ruff, it is not at parity with pylint yet. This PR replaces flake8 and isort in favor of ruff but does not remove pylint yet. Nevertheless, from what I have seen so far ruff + mypy does catch a vast swath of everyday errors, and I have found that the 30+ seconds it can take to run pylint on any of our python modules is a deterrent to me linting often and catching lint errors early. So I added Makefile targets such as `check-batch-fast` that run all the linters except for pylint. The `check-batch` rule now does `check-batch-fast` and `pylint-batch`. So linter coverage should have strictly increased in CI, but there is a <5s linting target now available for devs in addition to the >30s it can take to also run pylint. You can also now just run `ruff .` in the root of the repo and it completes for me in 0.293 seconds. For the most part in this PR, I added ruff, with the config enabling flake8 + isort + pylint rules, then disabled rules until there were no errors, save for a few rules that I thought to just fix immediately. These mostly line up with the flake8 rules we had already disabled. I also then added ruff's own ruleset ([RUF](https://beta.ruff.rs/docs/rules/#ruff-specific-rules-ruf)) particularly because I appreciated the `asyncio-dangling-task` and `unused-noqa` rules.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12967:429,error,errors,429,https://hail.is,https://github.com/hail-is/hail/pull/12967,4,"['avail', 'error']","['available', 'errors']"
Availability,[scorecard] tolerate rate limiting,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6303:12,toler,tolerate,12,https://hail.is,https://github.com/hail-is/hail/pull/6303,1,['toler'],['tolerate']
Availability,[service-base] fix libsass by downgrading google-cloud-profiler,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12544:30,down,downgrading,30,https://hail.is,https://github.com/hail-is/hail/pull/12544,1,['down'],['downgrading']
Availability,[services-java] new transient error observed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11407:30,error,error,30,https://hail.is,https://github.com/hail-is/hail/pull/11407,1,['error'],['error']
Availability,[services/Java] retry retryable http client errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8802:44,error,errors,44,https://hail.is,https://github.com/hail-is/hail/pull/8802,1,['error'],['errors']
Availability,[services] Yet Another Transient Error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10468:33,Error,Error,33,https://hail.is,https://github.com/hail-is/hail/pull/10468,1,['Error'],['Error']
Availability,[services] also increase memory available,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9453:32,avail,available,32,https://hail.is,https://github.com/hail-is/hail/pull/9453,1,['avail'],['available']
Availability,[services] indicate how many errors we have seen,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12984:29,error,errors,29,https://hail.is,https://github.com/hail-is/hail/pull/12984,1,['error'],['errors']
Availability,[services] more transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10310:26,error,errors,26,https://hail.is,https://github.com/hail-is/hail/pull/10310,1,['error'],['errors']
Availability,[services] reliably retry all requests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13029:11,reliab,reliably,11,https://hail.is,https://github.com/hail-is/hail/pull/13029,1,['reliab'],['reliably']
Availability,[services] stop treating all logs as error logs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9845:37,error,error,37,https://hail.is,https://github.com/hail-is/hail/pull/9845,1,['error'],['error']
Availability,[shuffler] retry transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9404:27,error,errors,27,https://hail.is,https://github.com/hail-is/hail/pull/9404,1,['error'],['errors']
Availability,[site] actually check that site is alive,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8492:35,alive,alive,35,https://hail.is,https://github.com/hail-is/hail/pull/8492,1,['alive'],['alive']
Availability,"[this comment](https://github.com/hail-is/hail/pull/8265#issuecomment-601360575) describes the test failure -- it looks like something was a numpy array, but is now a nested list.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8265#issuecomment-601665796:100,failure,failure,100,https://hail.is,https://github.com/hail-is/hail/pull/8265#issuecomment-601665796,1,['failure'],['failure']
Availability,[transient-error] new transient error from GCS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13170:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/pull/13170,2,['error'],['error']
Availability,[transient-errors] will it ever end?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13043:11,error,errors,11,https://hail.is,https://github.com/hail-is/hail/pull/13043,1,['error'],['errors']
Availability,[utils] Add invalid grant to python retry-once errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12170:47,error,errors,47,https://hail.is,https://github.com/hail-is/hail/pull/12170,1,['error'],['errors']
Availability,[utils] Fix cancelled task errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10534:27,error,errors,27,https://hail.is,https://github.com/hail-is/hail/pull/10534,1,['error'],['errors']
Availability,[utils] Fix transient error for rateLimitExceeded,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10613:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/10613,1,['error'],['error']
Availability,[utils] YATE: Yet Another Transient Error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10442:36,Error,Error,36,https://hail.is,https://github.com/hail-is/hail/pull/10442,1,['Error'],['Error']
Availability,[utils] include stack trace in retry-transient-errors log,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9716:47,error,errors,47,https://hail.is,https://github.com/hail-is/hail/pull/9716,1,['error'],['errors']
Availability,[utils] more transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10924:23,error,errors,23,https://hail.is,https://github.com/hail-is/hail/pull/10924,1,['error'],['errors']
Availability,[utils] treat 500 as a transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8044:33,error,error,33,https://hail.is,https://github.com/hail-is/hail/pull/8044,1,['error'],['error']
Availability,[vcf combiner] Fix error in determining intermidiate file names,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11962:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/11962,1,['error'],['error']
Availability,[website] fix change_log.md & treat pandoc warnings as errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11960:55,error,errors,55,https://hail.is,https://github.com/hail-is/hail/pull/11960,1,['error'],['errors']
Availability,[website] fix linting errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10171:22,error,errors,22,https://hail.is,https://github.com/hail-is/hail/pull/10171,1,['error'],['errors']
Availability,[website] minimal changes to enable downloading the tutorials.tar.gz,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10302:36,down,downloading,36,https://hail.is,https://github.com/hail-is/hail/pull/10302,1,['down'],['downloading']
Availability,[wip] replicate rvd partitioner failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11354:32,failure,failure,32,https://hail.is,https://github.com/hail-is/hail/pull/11354,1,['failure'],['failure']
Availability,\; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc \; WHEEL_FOR_AZURE= \; WEBSITE_TAR=/path/to/www.tar.gz \; hail/scripts/release.sh. +++ dirname -- hail/scripts/release.sh; ++ cd -- hail/scripts; ++ pwd; + SCRIPT_DIR=/Users/dking/projects/hail/hail/scripts; + arguments='HAIL_PIP_VERSION HAIL_VERSION GIT_VERSION REMOTE WHEEL GITHUB_OAUTH_HEADER_FILE HAIL_GENETICS_HAIL_IMAGE HAIL_GENETICS_HAIL_IMAGE_PY_3_10 HAIL_GENETICS_HAIL_IMAGE_PY_3_11 HAIL_GENETICS_HAILTOP_IMAGE HAIL_GENETICS_VEP_GRCH37_85_IMAGE HAIL_GENETICS_VEP_GRCH38_95_IMAGE WHEEL_FOR_AZURE WEBSITE_TAR'; + for varname in '$arguments'; + '[' -z 0.2.123 ']'; + echo HAIL_PIP_VERSION=0.2.123; HAIL_PIP_VERSION=0.2.123; + for varname in '$arguments'; + '[' -z 0.2.123-abcdef123 ']'; + echo HAIL_VERSION=0.2.123-abcdef123; HAIL_VERSION=0.2.123-abcdef123; + for varname in '$arguments'; + '[' -z abcdef123 ']'; + echo GIT_VERSION=abcdef123; GIT_VERSION=abcdef123; + for varname in '$arguments'; + '[' -z origin ']'; + echo REMOTE=origin; REMOTE=origin; + for varname in '$arguments'; + '[' -z /path/to/the.whl ']'; + echo WHEEL=/path/to/the.whl; WHEEL=/path/to/the.whl; + for varname in '$arguments'; + '[' -z /path/to/github/oauth/header/file ']'; + echo GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://u,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:1868,echo,echo,1868,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,2,['echo'],['echo']
Availability,\; REMOTE=origin \; WHEEL=build/deploy/dist/hail-0.2.128-py3-none-any.whl \; GITHUB_OAUTH_HEADER_FILE=abc123 \; HAIL_GENETICS_HAIL_IMAGE=abc123 \; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=a \; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=b \; HAIL_GENETICS_HAILTOP_IMAGE=c \; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=d \; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=e \; WHEEL_FOR_AZURE=f \; WEBSITE_TAR=g \; bash scripts/release.sh; +++ dirname -- scripts/release.sh; ++ cd -- scripts; ++ pwd; + SCRIPT_DIR=/Users/dking/projects/hail/hail/scripts; + arguments='HAIL_PIP_VERSION HAIL_VERSION GIT_VERSION REMOTE WHEEL GITHUB_OAUTH_HEADER_FILE HAIL_GENETICS_HAIL_IMAGE HAIL_GENETICS_HAIL_IMAGE_PY_3_10 HAIL_GENETICS_HAIL_IMAGE_PY_3_11 HAIL_GENETICS_HAILTOP_IMAGE HAIL_GENETICS_VEP_GRCH37_85_IMAGE HAIL_GENETICS_VEP_GRCH38_95_IMAGE WHEEL_FOR_AZURE WEBSITE_TAR'; + for varname in '$arguments'; + '[' -z 0.2.128 ']'; + echo HAIL_PIP_VERSION=0.2.128; HAIL_PIP_VERSION=0.2.128; + for varname in '$arguments'; + '[' -z 0.2.128-91d328e7fc84 ']'; + echo HAIL_VERSION=0.2.128-91d328e7fc84; HAIL_VERSION=0.2.128-91d328e7fc84; + for varname in '$arguments'; + '[' -z 91d328e7fc84686936ffd4f370c8c104b2d78b2a ']'; + echo GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a; GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a; + for varname in '$arguments'; + '[' -z origin ']'; + echo REMOTE=origin; REMOTE=origin; + for varname in '$arguments'; + '[' -z build/deploy/dist/hail-0.2.128-py3-none-any.whl ']'; + echo WHEEL=build/deploy/dist/hail-0.2.128-py3-none-any.whl; WHEEL=build/deploy/dist/hail-0.2.128-py3-none-any.whl; + for varname in '$arguments'; + '[' -z abc123 ']'; + echo GITHUB_OAUTH_HEADER_FILE=abc123; GITHUB_OAUTH_HEADER_FILE=abc123; + for varname in '$arguments'; + '[' -z abc123 ']'; + echo HAIL_GENETICS_HAIL_IMAGE=abc123; HAIL_GENETICS_HAIL_IMAGE=abc123; + for varname in '$arguments'; + '[' -z a ']'; + echo HAIL_GENETICS_HAIL_IMAGE_PY_3_10=a; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=a; + for varname in '$arguments'; + '[' -z b ']'; ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:11567,echo,echo,11567,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,1,['echo'],['echo']
Availability,"](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315331) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315452](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315452) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315972](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315972) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315975) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:4526,avail,available,4526,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['avail'],['available']
Availability,"](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315331) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315452](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315452) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315972](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315972) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315975) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:4518,avail,available,4518,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['avail'],['available']
Availability,"](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315452) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315972](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315972) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315975) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![high severity](https://res.cl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:4895,avail,available,4895,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['avail'],['available']
Availability,"](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315452) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315972](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315972) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315975) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![high severity](https://res.cl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:4887,avail,available,4887,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['avail'],['available']
Availability,"]) == mt.ss.nt2) &; (flip_text(mt.alleles[1]) == mt.ss.nt1)),; mt.ss.ldpred_inf_beta); .or_missing()). # filter bgen matrixtable down to only SNPs with betas; mt = mt.filter_rows(hl.is_defined(mt.beta)). # filter bgen matrixtable to only include people in scoring sample; mt = mt.filter_cols(hl.is_defined(sampleids[mt.s])). # score sample; mt = mt.annotate_cols(prs=hl.agg.sum(mt.beta * mt.dosage)). # write out table with sample IDs and PRS scores; mt.cols().export('gs://ukbb_prs/prs/UKB_'+pheno+'_PRS_22.txt'). parser = argparse.ArgumentParser(); parser.add_argument(""--phenotype"", help=""name of the sumstat phenotype""); args = parser.parse_args(). try:; start = time.time(); main(args.phenotype); end = time.time(); message = ""Success! Job was completed in %s"" % time.strftime(""%H:%M:%S"", time.gmtime(end - start)); send_message(message); except Exception as e:; send_message(""Fail.""); ```. ""Failure Reason"":; ```; Job aborted due to stage failure: Task 98 in stage 13.0 failed 20 times, most recent failure: Lost task 98.19 in stage 13.0 (TID 22699, ccarey-sw-xt4j.c.ukbb-robinson.internal, executor 68): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:914);",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:2907,failure,failure,2907,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681,1,['failure'],['failure']
Availability,"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. func = <function export_vcf at 0x7fa13c4d9938>, args = (<hail.dataset.VariantDataset object at 0x7fa13c3c9390>, 'file:///scratch/test_vcf_export.vcf.bgz', None, False, False), kwargs = {}; e = Py4JJavaError(u'An error occurred while calling o160.exportVCF.\n', JavaObject id=o162), tpl = JavaObject id=o210; deepest = 'ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found'; full = 'java.lang.RuntimeException: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.map...mmand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748). '. @decorator; def handle_py4j(func, *args, **kwargs):; try:; r = func(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full = tpl._1(), tpl._2(); raise FatalError('%s\n\nJava stack trace:\n%s\n'; 'Hail version: %s\n'; > 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); E FatalError: ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found; E; E Java stack trace:; E java.lang.RuntimeException: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found; E at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2227); E at org.apache.hadoop.mapred.JobConf.getOutputCommitter(JobConf.java:726); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1051); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); E at org.apache.spark.rdd.RDDOperationScope$.withScope(RDD",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3946:3374,Error,Error,3374,https://hail.is,https://github.com/hail-is/hail/issues/3946,1,['Error'],['Error']
Availability,"_From @alexb-3 on October 20, 2015 19:43_. These could be implemented as infix methods of a no-overhead RichDouble wrapper class, though we need some flexibility in setting the tolerance. For example, a computation like an exact test might use a stricter tolerance (say 1e-12) than a test (say 1e-6). _Copied from original issue: cseed/hail#84_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/51:177,toler,tolerance,177,https://hail.is,https://github.com/hail-is/hail/issues/51,2,['toler'],['tolerance']
Availability,"_From @alexb-3 on September 30, 2015 20:42_. Note that we are using BibTeX with the common `bibfile.bib`, and that we need a make tool that runs PDFTeX and BibTeX until no errors remain. _Copied from original issue: cseed/hail#68_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/47:172,error,errors,172,https://hail.is,https://github.com/hail-is/hail/issues/47,1,['error'],['errors']
Availability,"_From @cseed on August 26, 2015 14:37_. When designing, consider plinkseq `--mask` option:. https://atgu.mgh.harvard.edu/plinkseq/masks.shtml. and bcftools filter expressions:. https://samtools.github.io/bcftools/bcftools.html#expressions. _Copied from original issue: cseed/hail#15_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/16:77,mask,mask,77,https://hail.is,https://github.com/hail-is/hail/issues/16,2,['mask'],"['mask', 'masks']"
Availability,"_From @cseed on October 22, 2015 13:56_. Andrea is running into some problems with the Estonian dataset in sampleqc:. ```; Exception in thread ""main"" org.apache.spark.SparkException: Job aborted due to stage failure: Total size of serialized results of 2689 tasks (2.0 GB) is bigger than spark.driver.maxResultSize (2.0 GB); ```. _Copied from original issue: cseed/hail#89_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/53:208,failure,failure,208,https://hail.is,https://github.com/hail-is/hail/issues/53,1,['failure'],['failure']
Availability,"_From @cseed on September 1, 2015 15:48_. Need general strategy for error reporting. We can't use asserts for input data validation (e.g., reading tsv files, command line flags, etc.) Need to generate good error messages with feedback about line numbers, etc. _Copied from original issue: cseed/hail#42_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/33:68,error,error,68,https://hail.is,https://github.com/hail-is/hail/issues/33,2,['error'],['error']
Availability,"_From @jbloom22 on September 29, 2015 17:21_. Once we handle multi-allelic sites, we will need to adapt mendel errors so that, for example, it does not double count errors in multi-allelic trios. _Copied from original issue: cseed/hail#65_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/45:111,error,errors,111,https://hail.is,https://github.com/hail-is/hail/issues/45,2,['error'],['errors']
Availability,"__6} --varianceRatioFile=${__RESOURCE_FILE__8}; --SAIGEOutputFile=${__RESOURCE_FILE__748} --groupFile=${__RESOURCE_FILE__20}; --sparseSigmaFile=${__RESOURCE_FILE__9} --IsSingleVarinGroupTest=TRUE --IsOutputAFinCaseCtrl=TRUE; 2>&1 | tee ${__RESOURCE_FILE__749}; env:; - name: POD_IP; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: status.podIP; - name: POD_NAME; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: metadata.name; image: konradjk/saige:0.35.8.2.2; imagePullPolicy: IfNotPresent; name: main; resources:; requests:; cpu: ""1""; memory: 500M; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /gsa-key; name: gsa-key; - mountPath: /io; name: batch-2554-job-4-8vvgl; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: default-token-8h99c; readOnly: true; dnsPolicy: ClusterFirst; enableServiceLinks: true; nodeName: gke-vdc-preemptible-pool-9c7148b2-4gq2; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: default; serviceAccountName: default; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: gsa-key; secret:; defaultMode: 420; secretName: konradk-gsa-key; - name: batch-2554-job-4-8vvgl; persistentVolumeClaim:; claimName: batch-2554-job-4-8vvgl; - name: default-token-8h99c; secret:; defaultMode: 420; secretName: default-token-8h99c; status:; conditions:; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; status: ""True""; type: Initialized; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466:6367,toler,tolerations,6367,https://hail.is,https://github.com/hail-is/hail/issues/6466,1,['toler'],['tolerations']
Availability,"__6} --varianceRatioFile=${__RESOURCE_FILE__8}; --SAIGEOutputFile=${__RESOURCE_FILE__748} --groupFile=${__RESOURCE_FILE__20}; --sparseSigmaFile=${__RESOURCE_FILE__9} --IsSingleVarinGroupTest=TRUE --IsOutputAFinCaseCtrl=TRUE; 2>&1 | tee ${__RESOURCE_FILE__749}; env:; - name: POD_IP; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: status.podIP; - name: POD_NAME; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: metadata.name; image: konradjk/saige:0.35.8.2.2; imagePullPolicy: IfNotPresent; name: main; resources:; requests:; cpu: ""1""; memory: 500M; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /gsa-key; name: gsa-key; - mountPath: /io; name: batch-2554-job-4-8vvgl; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: default-token-8h99c; readOnly: true; dnsPolicy: ClusterFirst; enableServiceLinks: true; nodeName: gke-vdc-preemptible-pool-9c7148b2-4gq2; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: default; serviceAccountName: default; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: gsa-key; secret:; defaultMode: 420; secretName: konradk-gsa-key; - name: batch-2554-job-4-8vvgl; persistentVolumeClaim:; claimName: batch-2554-job-4-8vvgl; - name: default-token-8h99c; secret:; defaultMode: 420; secretName: default-token-8h99c; status:; conditions:; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T12:37:07Z""; status: ""True""; type: Initialized; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T12:37:07Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: """,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649:14642,toler,tolerations,14642,https://hail.is,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649,1,['toler'],['tolerations']
Availability,"___/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 12 2017 14:00:23); SparkSession available as 'spark'. In [1]: from hail import *; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); <ipython-input-1-3181c5d8fca5> in <module>(); ----> 1 from hail import *. /opt/Software/hail/python/hail/__init__.py in <module>(); ----> 1 import hail.expr; 2 from hail.representation import *; 3 from hail.context import HailContext; 4 from hail.dataset import VariantDataset; 5 from hail.expr import *. /opt/Software/hail/python/hail/expr.py in <module>(); 1 import abc; 2 from hail.java import scala_object, Env, jset; ----> 3 from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; 4 ; 5 . /opt/Software/hail/python/hail/representation/__init__.py in <module>(); ----> 1 from hail.representation.variant import Variant, Locus, AltAllele; 2 from hail.representation.interval import Interval; 3 from hail.representation.genotype import Genotype, Call; 4 from hail.representation.annotations import Struct; 5 from hail.representation.pedigree import Trio, Pedigree. /opt/Software/hail/python/hail/representation/variant.py in <module>(); 1 from hail.java import scala_object, Env, handle_py4j; ----> 2 from hail.typecheck import *; 3 ; 4 class Variant(object):; 5 """""". /opt/Software/hail/python/hail/typecheck/__init__.py in <module>(); ----> 1 from check import *; 2 ; 3 __all__ = ['typecheck',; 4 'typecheck_method',; 5 'none',. ImportError: No module named 'check'. In [2]: hc = HailContext(sc); ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-2-2e980fcce31d> in <module>(); ----> 1 hc = HailContext(sc). NameError: name 'HailContext' is not defined. In [3]: ; ```; There are still some errors, is there something wrong with my configurations?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-321152609:3939,error,errors,3939,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321152609,1,['error'],['errors']
Availability,"___________ test_callback _________________________________. client = <hailtop.batch_client.client.BatchClient object at 0x7f9cbc23b610>. async def test_callback(client):; import nest_asyncio # pylint: disable=import-outside-toplevel; ; nest_asyncio.apply(); ; app = web.Application(); callback_bodies = []; callback_event = asyncio.Event(); ; def url_for(uri):; host = os.environ['HAIL_BATCH_WORKER_IP']; port = os.environ['HAIL_BATCH_WORKER_PORT']; return f'http://{host}:{port}{uri}'; ; async def callback(request):; body = await request.json(); callback_bodies.append(body); callback_event.set(); return web.Response(); ; app.add_routes([web.post('/test', callback)]); runner = web.AppRunner(app); await runner.setup(); site = web.TCPSite(runner, '0.0.0.0', 5000); await site.start(); ; try:; token = secrets.token_urlsafe(32); b = create_batch(; client, callback=url_for('/test'), attributes={'foo': 'bar', 'name': 'test_callback'}, token=token; ); head = b.create_job('alpine:3.8', command=['echo', 'head']); b.create_job('alpine:3.8', command=['echo', 'tail'], parents=[head]); b.submit(); await asyncio.wait_for(callback_event.wait(), 5 * 60); callback_body = callback_bodies[0]; ; # verify required fields present; callback_body.pop('cost'); callback_body.pop('msec_mcpu'); callback_body.pop('time_created'); callback_body.pop('time_closed'); callback_body.pop('time_completed'); callback_body.pop('duration'); callback_body.pop('duration_ms'); callback_body.pop('cost_breakdown'); > assert callback_body == {; 'id': b.id,; 'user': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 26",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:1124,echo,echo,1124,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427,1,['echo'],['echo']
Availability,"_avx2::uint16<8>; T = simdpp::arch_avx2::uint8<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint8<16>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint8<16>]â€™; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:129:36: required from â€˜simdpp::arch_avx2::uint16<8>::uint16(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint8<16>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_or.h:69:58: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint16<8>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint16<8>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint8<16>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:21,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:104:7: note: â€˜class simdpp::arch_avx2::uint16<8>â€™ declared here; class uint16<8, void> : public any_int16<8, uint16<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::uint32<4>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:7376,error,error,7376,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"_avx2::uint8<16>; T = simdpp::arch_avx2::uint32<4>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::uint32<4>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::uint32<4>]â€™; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:129:36: required from â€˜simdpp::arch_avx2::uint8<16>::uint8(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint32<4>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_or.h:101:42: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint8<16>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint8<16>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint32<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:19,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:104:7: note: â€˜class simdpp::arch_avx2::uint8<16>â€™ declared here; class uint8<16, void> : public any_int8<16, uint8<16,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint8<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:9144,error,error,9144,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"_avx2::uint8<16>; T = simdpp::arch_avx2::uint64<2>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::uint64<2>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::uint64<2>]â€™; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:129:36: required from â€˜simdpp::arch_avx2::uint8<16>::uint8(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint64<2>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_or.h:150:42: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint8<16>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint8<16>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint64<2>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:19,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:104:7: note: â€˜class simdpp::arch_avx2::uint8<16>â€™ declared here; class uint8<16, void> : public any_int8<16, uint8<16,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::uint8<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:12681,error,error,12681,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"_avx2::uint8<32>; T = simdpp::arch_avx2::uint32<8>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint32<8>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint32<8>]â€™; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:110:36: required from â€˜simdpp::arch_avx2::uint8<32>::uint8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint32<8>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_not.h:64:43: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint8<32>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint8<32>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint32<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:91:7: note: â€˜class simdpp::arch_avx2::uint8<32>â€™ declared here; class uint8<32, void> : public any_int8<32, uint8<32,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint8<32>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:23372,error,error,23372,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"_avx2::uint8<32>; T = simdpp::arch_avx2::uint64<4>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint64<4>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint64<4>]â€™; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:110:36: required from â€˜simdpp::arch_avx2::uint8<32>::uint8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint64<4>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_not.h:94:43: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint8<32>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint8<32>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint64<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:91:7: note: â€˜class simdpp::arch_avx2::uint8<32>â€™ declared here; class uint8<32, void> : public any_int8<32, uint8<32,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint8<32>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:26907,error,error,26907,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"_configuration,; 491 optimizer_iterations,; 492 gcs_requester_pays_project=gcs_requester_pays_project,; 493 gcs_requester_pays_buckets=gcs_requester_pays_buckets,; 494 ); 495 if not backend.fs.exists(tmpdir):; 496 backend.fs.mkdir(tmpdir); File /databricks/python/lib/python3.10/site-packages/hail/backend/spark_backend.py:126, in SparkBackend.__init__(self, idempotent, sc, spark_conf, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmpdir, local_tmpdir, skip_logging_configuration, optimizer_iterations, gcs_requester_pays_project, gcs_requester_pays_buckets); 124 jhc = hail_package.HailContext.getOrCreate(jbackend, branching_factor, optimizer_iterations); 125 else:; --> 126 jbackend = hail_package.backend.spark.SparkBackend.apply(; 127 jsc,; 128 app_name,; 129 master,; 130 local,; 131 log,; 132 True,; 133 append,; 134 skip_logging_configuration,; 135 min_block_size,; 136 tmpdir,; 137 local_tmpdir,; 138 gcs_requester_pays_project,; 139 gcs_requester_pays_buckets,; 140 ); 141 jhc = hail_package.HailContext.apply(jbackend, branching_factor, optimizer_iterations); 143 self._jsc = jbackend.sc(); File /databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355, in JavaMember.__call__(self, *args); 1349 command = proto.CALL_COMMAND_NAME +\; 1350 self.command_header +\; 1351 args_command +\; 1352 proto.END_COMMAND_PART; 1354 answer = self.gateway_client.send_command(command); -> 1355 return_value = get_return_value(; 1356 answer, self.gateway_client, self.target_id, self.name); 1358 for temp_arg in temp_args:; 1359 if hasattr(temp_arg, ""_detach""):; File /databricks/spark/python/pyspark/errors/exceptions/captured.py:230, in capture_sql_exception.<locals>.deco(*a, **kw); 226 converted = convert_exception(e.java_exception); 227 if not isinstance(converted, UnknownException):; 228 # Hide where the exception came from that shows a non-Pythonic; 229 # JVM exception message.; --> 230 raise converted from None; 231 else:; 232 raise; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14462:5777,error,errors,5777,https://hail.is,https://github.com/hail-is/hail/issues/14462,1,['error'],['errors']
Availability,"_debug_string('', 0, f, *args, **kwargs); File ""/Users/rye/opt/anaconda3/lib/python3.9/site-packages/hailtop/utils/utils.py"", line 792, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/Users/rye/opt/anaconda3/lib/python3.9/site-packages/hail/backend/service_backend.py"", line 515, in _read_output; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: GoogleJsonResponseException: 404 Not Found; GET https://storage.googleapis.com/download/storage/v1/b/wes-bipolar-tmp-4day/o/bge-wave-1-VQSR%2FparallelizeAndComputeWithIndex%2FgCyfD7XOt_MQrrCGc4Q-RrrWPb3cTAbhhcV28BCntiU=%2Fresult.2706?alt=media; No such object: wes-bipolar-tmp-4day/bge-wave-1-VQSR/parallelizeAndComputeWithIndex/gCyfD7XOt_MQrrCGc4Q-RrrWPb3cTAbhhcV28BCntiU=/result.2706. Java stack trace:; is.hail.relocated.com.google.cloud.storage.StorageException: 404 Not Found; GET https://storage.googleapis.com/download/storage/v1/b/wes-bipolar-tmp-4day/o/bge-wave-1-VQSR%2FparallelizeAndComputeWithIndex%2FgCyfD7XOt_MQrrCGc4Q-RrrWPb3cTAbhhcV28BCntiU=%2Fresult.2706?alt=media; No such object: wes-bipolar-tmp-4day/bge-wave-1-VQSR/parallelizeAndComputeWithIndex/gCyfD7XOt_MQrrCGc4Q-RrrWPb3cTAbhhcV28BCntiU=/result.2706; 	at is.hail.relocated.com.google.cloud.storage.StorageException.translate(StorageException.java:163); 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:297); 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.load(HttpStorageRpc.java:730); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.lambda$readAllBytes$24(StorageImpl.java:574); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103); 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at is.hail.relocated.com.google.cloud.storage.Retrying.run(Retrying.java:60); 	at is.hail.r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13409:4807,down,download,4807,https://hail.is,https://github.com/hail-is/hail/issues/13409,1,['down'],['download']
Availability,"_fetchall; > async for row in tx.execute_and_fetchall(sql, args, query_name):\n File ""/usr/local/lib/python3.9/dist-packages/gear/database.py"", line 257, in execute_and_fetchall; > await cursor.execute(sql, args)\n File ""/usr/local/lib/python3.9/dist-packages/aiomysql/cursors.py"", line 239, in execute; > await self._query(query)\n File ""/usr/local/lib/python3.9/dist-packages/aiomysql/cursors.py"", line 457, in _query; > await conn.query(q)\n File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 469, in query; > await self._read_query_result(unbuffered=unbuffered)\n File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 683, in _read_query_result; > await result.read()\n File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 1164, in read; > first_packet = await self.connection._read_packet()\n File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 652, in _read_packet; > packet.raise_for_error()\n File ""/usr/local/lib/python3.9/dist-packages/pymysql/protocol.py"", line 219, in raise_for_error; > err.raise_mysql_exception(self._data)\n File ""/usr/local/lib/python3.9/dist-packages/pymysql/err.py"", line 150, in raise_mysql_exception; > raise errorclass(errno, errval); > pymysql.err.OperationalError: (1054, ""Unknown column 'cancelled.id' in 'on clause'""); > ```. This error strikes me as odd because `cancelled.id` has been updated to `cancelled.batch_id` in `delete_prev_cancelled_job_group_cancellable_resources_records`:. [batch/driver/main.py](https://github.com/hail-is/hail/blob/c6e3c660035379e6fe3f96fb4385f8b3c7e8d436/batch/batch/driver/main.py#L1474). Based on the error, it looks like the `main.py` being executed at `/usr/local/lib/python3.9/dist-packages/batch/driver/main.py` is still using the old version of the code, the changes from the PR were not correctly reflected in the environment. Is it possible that we might be missing a `pip install` step to ensure the latest code is deployed?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14672#issuecomment-2353226053:1969,error,errorclass,1969,https://hail.is,https://github.com/hail-is/hail/pull/14672#issuecomment-2353226053,3,['error'],"['error', 'errorclass']"
Availability,"_message_path': '/dev/termination-log',; 'termination_message_policy': 'File',; 'tty': None,; 'volume_devices': None,; 'volume_mounts': [{'mount_path': '/gsa-key',; 'mount_propagation': None,; 'name': 'gsa-key',; 'read_only': None,; 'sub_path': None},; {'mount_path': '/io',; 'mount_propagation': None,; 'name': 'batch-2554-job-4-8vvgl',; 'read_only': None,; 'sub_path': None},; {'mount_path': '/var/run/secrets/kubernetes.io/serviceaccount',; 'mount_propagation': None,; 'name': 'default-token-8h99c',; 'read_only': True,; 'sub_path': None}],; 'working_dir': None}],; 'dns_config': None,; 'dns_policy': 'ClusterFirst',; 'enable_service_links': True,; 'host_aliases': None,; 'host_ipc': None,; 'host_network': None,; 'host_pid': None,; 'hostname': None,; 'image_pull_secrets': None,; 'init_containers': None,; 'node_name': 'gke-vdc-preemptible-pool-9c7148b2-4gq2',; 'node_selector': None,; 'priority': 500000,; 'priority_class_name': 'user',; 'readiness_gates': None,; 'restart_policy': 'Never',; 'runtime_class_name': None,; 'scheduler_name': 'default-scheduler',; 'security_context': {'fs_group': None,; 'run_as_group': None,; 'run_as_non_root': None,; 'run_as_user': None,; 'se_linux_options': None,; 'supplemental_groups': None,; 'sysctls': None},; 'service_account': 'default',; 'service_account_name': 'default',; 'share_process_namespace': None,; 'subdomain': None,; 'termination_grace_period_seconds': 30,; 'tolerations': [{'effect': None,; 'key': 'preemptible',; 'operator': None,; 'toleration_seconds': None,; 'value': 'true'},; {'effect': 'NoExecute',; 'key': 'node.kubernetes.io/not-ready',; 'operator': 'Exists',; 'toleration_seconds': 300,; 'value': None},; {'effect': 'NoExecute',; 'key': 'node.kubernetes.io/unreachable',; 'operator': 'Exists',; 'toleration_seconds': 300,; 'value': None}],; 'volumes': [{'aws_elastic_block_store': None,; 'azure_disk': None,; 'azure_file': None,; 'cephfs': None,; 'cinder': None,; 'config_map': None,; 'downward_api': None,; 'empty_dir': None,; 'fc':",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649:5313,toler,tolerations,5313,https://hail.is,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649,1,['toler'],['tolerations']
Availability,"_typecheck(__orig_func__, *args, **kwargs):; 492 args_, kwargs_ = check_all(__orig_func__, args, kwargs, checkers, is_method=False); --> 493 return __orig_func__(*args_, **kwargs_); 494; 495 return decorator(_typecheck). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-0c961806173f.zip/hail/methods/qc.py in vep(dataset, config, block_size, name, csq); 545; 546 require_row_key_variant(dataset, 'vep'); --> 547 return MatrixTable(Env.hail().methods.VEP.apply(dataset._jvds, config, 'va.`{}`'.format(name), csq, block_size)); 548; 549. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-0c961806173f.zip/hail/utils/java.py in deco(*args, **kwargs); 236 # this is a hack to suppress the original error's stack trace; 237 if _exception:; --> 238 raise _exception; 239; 240 return deco. FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.variant.MatrixTable.orderedRVDLeftJoinDistinctAndInsert(MatrixTable.scala:982); 	at is.hail.methods.VEP$.annotate(VEP.scala:429); 	at is.hail.methods.VEP$.apply(VEP.scala:434); 	at is.hail.methods.VEP.apply(VEP.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractComma",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3099:2703,error,error,2703,https://hail.is,https://github.com/hail-is/hail/issues/3099,1,['error'],['error']
Availability,"_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int8<32>; T = simdpp::arch_avx2::uint16<16>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int8<32>; T = simdpp::arch_avx2::uint16<16>]â€™; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:51:35: required from â€˜simdpp::arch_avx2::int8<32>::int8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::expr_bit_or<simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::uint16<16> >, simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::uint16<16> > > >]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:69:36: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::int8<32>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::int8<32>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint16<16>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:32:7: note: â€˜class simdpp::arch_avx2::int8<32>â€™ declared here; class int8<32, void> : public any_int8<32, int8<32,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int32<4>; T = simdpp::arch_avx2::int64<2>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_av",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:65970,error,error,65970,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"_â€™ from an array of â€˜const class simdpp::arch_avx2::int64<2>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:33:7: note: â€˜class simdpp::arch_avx2::int32<4>â€™ declared here; class int32<4, void> : public any_int32<4, int32<4,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int64<2>; T = simdpp::arch_avx2::int32<4>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int64<2>; T = simdpp::arch_avx2::int32<4>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int64<2>; T = simdpp::arch_avx2::int32<4>]â€™; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:56:35: required from â€˜simdpp::arch_avx2::int64<2>::int64(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::int32<4>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:265:25: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::int64<2>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::int64<2>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::int32<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/type",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:68892,Mask,MaskCastOverride,68892,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"_â€™ from an array of â€˜const class simdpp::arch_avx2::int64<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:24,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:32:7: note: â€˜class simdpp::arch_avx2::int32<8>â€™ declared here; class int32<8, void> : public any_int32<8, int32<8,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int64<4>; T = simdpp::arch_avx2::int32<8>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int64<4>; T = simdpp::arch_avx2::int32<8>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int64<4>; T = simdpp::arch_avx2::int32<8>]â€™; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:51:35: required from â€˜simdpp::arch_avx2::int64<4>::int64(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int32<8>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:296:25: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::int64<4>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::int64<4>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::int32<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/type",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:77823,Mask,MaskCastOverride,77823,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"`'/api/v1alpha/batches/create-fast'` is a Batch API endpoint that allows you to create a batch, submit jobs, and start them running all in one HTTP request. It makes a few transactions within the endpoint and must be idempotent. One of the failure modes it must watch for is when a Batch Update to add some new jobs and/or job groups to a batch has already successfully been committed, but the request is retried for X reason. In that scenario, we want to just return a 200 to the client. We do this already, but there was an oversight when creating job groups where those branches did not include the full response payload, which results in intermittent errors on the client when it can't retrieve `resp['last_job_group_id']`. This fixes that so we always return the same JSON.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14589:240,failure,failure,240,https://hail.is,https://github.com/hail-is/hail/pull/14589,2,"['error', 'failure']","['errors', 'failure']"
Availability,"`), 0) AS SIGNED) AS `usage`; FROM aggregated_billing_project_user_resources_v3; + LEFT JOIN resources ON resources.resource_id = aggregated_billing_project_user_resources_v3.resource_id; {where_statement}; - GROUP BY billing_project, `user`, resource_id; + GROUP BY billing_project, `user`, deduped_resource_id; LOCK IN SHARE MODE; -) AS new ON old.billing_project = new.billing_project AND old.`user` = new.`user` AND old.deduped_resource_id = new.resource_id; +) AS new ON old.billing_project = new.billing_project AND old.`user` = new.`user` AND old.deduped_resource_id = new.deduped_resource_id; WHERE new.`usage` != old.`usage`; LIMIT 100;; ''',; where_args + where_args); ; bad_bp_user_records = [record async for record in bad_bp_user_records]; - failing_bp_users = []; for record in bad_bp_user_records:; print(f'found bad bp user record {record}'); failing_bp_users.append((record['billing_project'], record['user'])); ; - if bad_bp_user_records:; - raise Exception(f'errors found in audit'); + if failing_bp_users:; + raise Exception(f'errors found in audit'); ; print(f'finished auditing bp user records in {time.time() - bp_user_audit_start}s'); ```; Manual audit succeeded:. ```; mysql> SELECT old.billing_project, old.`user`, old.deduped_resource_id, old.`usage`, new.`usage`, ABS(new.`usage` - old.`usage`) AS usage_diff; -> FROM (; -> SELECT billing_project, `user`, deduped_resource_id, CAST(COALESCE(SUM(`usage`), 0) AS SIGNED) AS `usage`; -> FROM aggregated_billing_project_user_resources_v2; -> LEFT JOIN resources ON resources.resource_id = aggregated_billing_project_user_resources_v2.resource_id; -> GROUP BY billing_project, `user`, deduped_resource_id; -> LOCK IN SHARE MODE; -> ) AS old; -> LEFT JOIN (; -> SELECT billing_project, `user`, deduped_resource_id, CAST(COALESCE(SUM(`usage`), 0) AS SIGNED) AS `usage`; -> FROM aggregated_billing_project_user_resources_v3; -> LEFT JOIN resources ON resources.resource_id = aggregated_billing_project_user_resources_v3.resource_id",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13117:1921,error,errors,1921,https://hail.is,https://github.com/hail-is/hail/pull/13117,2,['error'],['errors']
Availability,`-x` logs each line of `start-nginx.sh` that runs and I don't expect anything in here to fail / the code itself to provide useful context in a failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9945:143,failure,failure,143,https://hail.is,https://github.com/hail-is/hail/pull/9945,1,['failure'],['failure']
Availability,"`. activate NAME` might silently fail if `NAME` does not exist or `conda` is not configured. `. ./loadconda` tries to find conda in a variety of places and configure it (meaning source `conda.sh`). After this, `conda activate NAME` will work correctly. ---. This is already in my batch dag PR, but that's getting bogged down in test issues, and this is blocking @akotlar 's https://github.com/hail-is/hail/pull/5065 PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5066:320,down,down,320,https://hail.is,https://github.com/hail-is/hail/pull/5066,1,['down'],['down']
Availability,`./gradlew -Dspark.version=3.1.1 shadowJar archiveZip`; failed for the main branch. ```; FAILURE: Build failed with an exception. * What went wrong:; Task 'archiveZip' not found in root project 'hail'.; ```. any suggestion?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3001#issuecomment-908358179:89,FAILURE,FAILURE,89,https://hail.is,https://github.com/hail-is/hail/issues/3001#issuecomment-908358179,1,['FAILURE'],['FAILURE']
Availability,"`/usr/lib/spark` I see reference of scala 2.12.15 same as in the hail logs; ```sh; $ cat /usr/lib/spark/RELEASE ; Spark 3.3.2-amzn-0.1 built for Hadoop 3.3.3-amzn-3.1; Build flags: -Divy.home=/home/release/.ivy2 -Dsbt.ivy.home=/home/release/.ivy2 -Duser.home=/home/release -Drepo.maven.org= -Dreactor.repo=file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" which is different from old value """"; printf ""0.2.124"" > env/HAIL_PIP_VERSION; echo 0.2.124-13536b531342 > python/hail/hail_version; echo 0.2.124 > python/hail/hail_pip_version; cp -f python/hail/hail_version python/hailtop/hail_version; printf 'hail_version=""0.2.124-13536b531342"";' > python/hail/docs/_static/hail_version.js; printf 'hail_pip_version=""0.2.124""' >> python/hail/docs/_static/hail_version.js; cloud_base is set to ""gs://hail-3",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:1477,down,downgraded,1477,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,1,['down'],['downgraded']
Availability,"`0.2.39-d38fca12930d`. ```; ht_out = ht.group_by(_x=True).aggregate(; ...: data=hl.agg.downsample(; ...: hl.log10(eur_freq.gnomad_genomes_af), hl.log10(eur_freq.af / 2),; ...: [ht.pass_status, hl.str(hl.abs(hl.log(eur_freq.gnomad_genomes_af / eur_freq.gnomad_exomes_af, 2)) > 2)]); ...: ).explode('data').key_by().drop('_x'); Traceback (most recent call last):; File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-59-3a16f061373b>"", line 5, in <module>; ).explode('data').key_by().drop('_x'); File ""<decorator-gen-1731>"", line 2, in drop; File ""/Users/konradk/hail/hail/python/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/konradk/hail/hail/python/hail/table.py"", line 965, in drop; protected_key = set(self._row_indices.protected_key); File ""/Users/konradk/hail/hail/python/hail/expr/expressions/indices.py"", line 42, in protected_key; self._cached_key = self._get_key(); File ""/Users/konradk/hail/hail/python/hail/expr/expressions/indices.py"", line 56, in _get_key; assert isinstance(self.source, hl.MatrixTable); AssertionError; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8751:87,down,downsample,87,https://hail.is,https://github.com/hail-is/hail/issues/8751,1,['down'],['downsample']
Availability,"`; [Stage 3:> (0 + 140) / 415]Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail.qc/delly-qc.py"", line 35, in <module>; ds = hl.sample_qc(ds); File ""<decorator-gen-902>"", line 2, in sample_qc; File ""/restricted/projectnb/genpro/github/hail/python/hail/typecheck/check.py"", line 490, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/restricted/projectnb/genpro/github/hail/python/hail/methods/qc.py"", line 91, in sample_qc; return MatrixTable(Env.hail().methods.SampleQC.apply(require_biallelic(dataset, 'sample_qc')._jvds, name)); File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: invalid allele ""<DEL>"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 3.0 failed 4 times, most recent failure: Lost task 2.3 in stage 3.0 (TID 160, scc-q01.scc.bu.edu, executor 4): is.hail.utils.HailException: invalid allele ""<DEL>""; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:29); at is.hail.methods.SampleQCCombiner$.alleleIndices(SampleQC.scala:44); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:178); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:175); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:175); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:170); a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:1512,failure,failure,1512,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['failure'],['failure']
Availability,"`; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiohttp 3.8.5 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **551/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13366:1467,avail,available,1467,https://hail.is,https://github.com/hail-is/hail/pull/13366,2,['avail'],['available']
Availability,"`; {""levelname"": ""ERROR"", ""asctime"": ""2019-09-30 19:09:54,555"", ""filename"": ""ci.py"", ""funcNameAndLine"": ""update_loop:315"", ""message"": ""hail-is/hail:master update failed due to exception"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/connector.py\"", line 929, in _wrap_create_connection\n await self._loop.create_connection(*args, **kwargs))\n File \""uvloop/loop.pyx\"", line 1904, in create_connection\n File \""uvloop/loop.pyx\"", line 1883, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/ci/ci.py\"", line 311, in update_loop\n await wb.update(app)\n File \""/usr/local/lib/python3.6/dist-packages/ci/github.py\"", line 518, in update\n await self._update(app)\n File \""/usr/local/lib/python3.6/dist-packages/ci/github.py\"", line 540, in _update\n await self._update_batch(batch_client)\n File \""/usr/local/lib/python3.6/dist-packages/ci/github.py\"", line 652, in _update_batch\n await self._update_deploy(batch_client)\n File \""/usr/local/lib/python3.6/dist-packages/ci/github.py\"", line 609, in _update_deploy\n 'target_branch': self.branch.short_str()\n File \""/usr/local/lib/python3.6/dist-packages/hailtop/batch_client/aioclient.py\"", line 476, in list_batches\n batches = await self._get('/api/v1alpha/batches', params=params)\n File \""/usr/local/lib/python3.6/dist-packages/hailtop/batch_client/aioclient.py\"", line 455, in _get\n self.url + path, params=params, headers=self._headers)\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/client.py\"", line 484, in _request\n timeout=real_timeout\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/connector.py\"", line 523, in connect\n proto = await self._create_connection(req, traces, timeout)\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/connector.py\"", line 85",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7166:18,ERROR,ERROR,18,https://hail.is,https://github.com/hail-is/hail/issues/7166,1,['ERROR'],['ERROR']
Availability,"`>=` is not compatible with wildcards:; ```; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; /usr/local/lib/python3.7/dist-packages/setuptools/installer.py:30: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.; SetuptoolsDeprecationWarning,; error in hail setup command: 'install_requires' must be a string or list of strings containing valid project/version requirement specifiers; Expected end or semicolon (after version specifier); google-cloud-storage>=1.25.*; ~~~~~~^; make: *** [Makefile:248: build/deploy/dist/hail-0.2.109-py3-none-any.whl] Error 1; ```. I'm not sure why this hasn't shown up before, but we couldn't deploy 0.2.109 without this fix. #assign services",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12677:337,error,error,337,https://hail.is,https://github.com/hail-is/hail/pull/12677,2,"['Error', 'error']","['Error', 'error']"
Availability,"`ArrayScan` is implemented in such a way that a scan on an empty array will read some uninitialized memory:. ```; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.23-7f06f94534d5; >>> hl.eval(hl.empty_array(hl.tint32).scan(lambda x,y: x + y, 0)); [0]; >>> hl.eval(hl.array([1, 2, 3]).scan(lambda x,y: x + y, 0)); [0, 1, 3, 6]; >>> hl.eval(hl.empty_array(hl.tint32).scan(lambda x,y: x + y, 0)); [643629112]; >>> hl.eval(hl.empty_array(hl.tarray(hl.tint32)).scan(lambda x,y: y, hl.empty_array(hl.tint32))); #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010ef85ded, pid=49261, tid=0x0000000000009903; #; # JRE version: Java(TM) SE Runtime Environment (8.0_211-b12) (build 1.8.0_211-b12); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.211-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x585ded]; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/mturner/Documents/hail/hail/python/hs_err_pid49261.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #; ```. This is because `ArrayScan` claims to have `len+1` elements, where `len` is the length of the inner stream. However, it will only call the consumer continuation during the `addElements` loop of the inner stream. Thus, if the inner stream is empty, the consumer continuation is never called. So the resulting effect is that we return an initialized array with length 1.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7135:556,error,error,556,https://hail.is,https://github.com/hail-is/hail/issues/7135,2,['error'],['error']
Availability,"`BlockMatrix.filterCols` and `BlockMatrix.filterRows` has a bug where the smaller blocks located on the edge of the matrix are not always correctly handled when they're of a smaller size than the rest of the blocks. The source of this problem was the fact that `BlockMatrix.scala` line 1515 below, which was calling `blockDims(split.index)`. This was a problem because `split.index` is a partition index, not a block index. The fix was to convert it to a block index and then call `blockDims`. The rest of this PR is some white space fixes, a spelling error, and an additional test case for BlockMatrix filtering that would fail in current master because of this bug.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7146:552,error,error,552,https://hail.is,https://github.com/hail-is/hail/pull/7146,1,['error'],['error']
Availability,"`IRSuite.scala` has a class `IRSuite` which has this inheritance sequence:; - `HailSuite`; - `TestNGSuite`; - `Suite`; - `Assertions` (among other interfaces). `Assertions` has [`assertThrows` with one argument](http://doc.scalatest.org/3.0.8/org/scalatest/testng/TestNGSuite.html#assertThrows[T<:AnyRef](f:=>Any)(implicitclassTag:scala.reflect.ClassTag[T],implicitpos:org.scalactic.source.Position):org.scalatest.Assertion). Unfortunately, `IRSuite.scala` also contains `import is.hail.TestUtils._`. This also brings into scope an `assertThrows` with two parameters. I have not bothered to understand Scala's name resolution strategy. SBT 1.3.8 refuses to acknowledge the existence of the `TestUtils.assertThrows` and instead tries to convert the two arguments into a pair and then pass those to `Assertions.assertThrows`. This rightfully raises a warning which we treat as errors. Both gradle and SBT have Scala version set to 2.11.8. I've fixed this by prefixing the assertThrows with `is.hail.TestUtils.assertThrows`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8359:875,error,errors,875,https://hail.is,https://github.com/hail-is/hail/issues/8359,1,['error'],['errors']
Availability,"`Invalid method, methods may have at most 255 arguments` error when running the gnomad-browser pipeline with Hail 0.2.105",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12533:57,error,error,57,https://hail.is,https://github.com/hail-is/hail/issues/12533,1,['error'],['error']
Availability,`MT.make_table` throws a bad error if a key is NA,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8222:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/issues/8222,1,['error'],['error']
Availability,`Method too large` error when running the gnomad-browser pipeline with Hail 0.2.105,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12531:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/issues/12531,1,['error'],['error']
Availability,"`Table._select` got way too complicated (mostly my fault) when key changing moved from `TableMapRows` to `TableKeyBy`. Making `_select` a simple wrapper around `TableMapRows`, and moving the key logic to `key_by`, made both way simpler. I then realized the `key_by` code could be even simpler by adding some rules to the optimizer to clean up the case where all new keys are existing fields. I actually think some things had gotten broken in the old `_select` (performance wise). In particular, in `split_multi`, in the `split_rows` function with `rekey=false`, I think it's supposed to extend the key from `['locus']` to `['locus', 'alleles']`, but that wasn't happening. I changed `key_by` to no longer accept `key_by(None)` or `key_by([])`, both of which should now be `key_by()`, which is more consistent with the rest of our interface, but is a breaking change. Is it worth the disruption? Should I add a warning? Or just continue to accept both?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4455:51,fault,fault,51,https://hail.is,https://github.com/hail-is/hail/pull/4455,1,['fault'],['fault']
Availability,`Too many arguments in method signature in class file` error when running the gnomad-browser pipeline with Hail 0.2.105,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:55,error,error,55,https://hail.is,https://github.com/hail-is/hail/issues/12532,1,['error'],['error']
Availability,"`_delete` retries transient errors. The `.../delete` endpoints return 404 for batches that do not exist, which, I suppose, is reasonable. On the client-side, we need to ignore 404s to ensure idempotency.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12478:28,error,errors,28,https://hail.is,https://github.com/hail-is/hail/pull/12478,1,['error'],['errors']
Availability,"``; prometheus-async 19.2.0 requires prometheus-client, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;) <br/>[SNYK-PYTHON-AIOHTTP-6209406](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209406) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **718/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-6209407](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209407) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3ZGRlNzcwZi0yMzMyLTQ5ZjktOWI1My05ZDY1OGJlOTVjMm",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14228:1464,avail,available,1464,https://hail.is,https://github.com/hail-is/hail/pull/14228,1,['avail'],['available']
Availability,"```; ""error"": ""Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 384, in _make_request; six.raise_from(e, None); File ""<string>"", line 2, in raise_from; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 380, in _make_request; httplib_response = conn.getresponse(); File ""/usr/local/lib/python3.6/http/client.py"", line 1354, in getresponse; response.begin(); File ""/usr/local/lib/python3.6/http/client.py"", line 307, in begin; version, status, reason = self._read_status(); File ""/usr/local/lib/python3.6/http/client.py"", line 268, in _read_status; line = str(self.fp.readline(_MAXLINE + 1), ""iso-8859-1""); File ""/usr/local/lib/python3.6/socket.py"", line 586, in readinto; return self._sock.recv_into(b); File ""/usr/local/lib/python3.6/ssl.py"", line 1012, in recv_into; return self.read(nbytes, buffer); File ""/usr/local/lib/python3.6/ssl.py"", line 874, in read; return self._sslobj.read(len, buffer); File ""/usr/local/lib/python3.6/ssl.py"", line 631, in read; v = self._sslobj.read(len, buffer); socket.timeout: The read operation timed out. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/requests/adapters.py"", line 449, in send; timeout=timeout; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 638, in urlopen; _stacktrace=sys.exc_info()[2]); File ""/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py"", line 368, in increment; raise six.reraise(type(error), error, _stacktrace); File ""/usr/local/lib/python3.6/site-packages/urllib3/packages/six.py"", line 686, in reraise; raise value; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 600, in urlopen; chunked=chunked); File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 386, in _make_request; self._raise_timeout(err=e, url=url, timeout_value=read_timeout); F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8053:6,error,error,6,https://hail.is,https://github.com/hail-is/hail/issues/8053,1,['error'],['error']
Availability,"```; # cat foo; 7	75216143	75216143	C/T	+; # python <<EOF; import hail as hl; hl.import_matrix_table(; 'foo',; row_fields={f'f{i}': hl.tstr for i in range(5)},; no_header=True).count(); EOF; ```; produces:; ```; Hail version: 0.2.11-cf54f08305d1; Error summary: HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; ```; I expect it to say something like ""yo dawg, you forgot to have entries, maybe you actually want import_table"". full output:; ```; Initializing Spark and Hail with default parameters...; using hail jar at /Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/hail-all-spark.jar; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; 19/03/27 18:27:22 WARN Utils: Your hostname, wmb16-359 resolves to a loopback address: 127.0.0.1; using 10.1.1.163 instead (on interface en0); 19/03/27 18:27:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; Running on Apache Spark version 2.2.3; SparkUI available at http://10.1.1.163:4041; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.11-cf54f08305d1; LOGGING: writing to /Users/dking/hail-20190327-1827-0.2.11-cf54f08305d1.log; Traceback (most recent call last):; File ""<stdin>"", line 4, in <module>; File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/matrixtable.py"", line 2371, in count; return (self.count_rows(), self.count_cols()); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/matrixtable.py"", line 2331, in count_rows; TableCount(MatrixRowsTable(self._mir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/backend/backend.py"", line 94, in execute; self._to_java_ir(ir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/py4j/java_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:247,Error,Error,247,https://hail.is,https://github.com/hail-is/hail/issues/5718,2,['Error'],['Error']
Availability,"```; # gsutil cat gs://hail-ci-0-1/ci/46808cb\*/038a6de7ce33b218b8d45160f224cae1feaf1c5a/job.log; failed to get container status {"""" """"}: rpc error: code = OutOfRange desc = EOF% . ```; The three most recent commits:. ```; * 6d17db60a - (23 minutes ago) add batch client timeouts, set timeout in ci (#4586) - Daniel King (HEAD -> fix-batch-client, hi/master, master); * 74d5e7560 - (23 minutes ago) fix a few issues with hl.plot.histogram (#4681) - Tim Poterba; * 038a6de7c - (45 minutes ago) refresh from batch (#4670) - Daniel King; ```. #4586 was never tested against 75d5e7560. This is bad. We can look at the log of statuses posted to GitHub:; ```; # curl -sSL api.github.com/repos/hail-is/hail/commits/46808cb224dbaa2d4fbae9f4fc90439e2eed8730/statuses | less; ```; [46808cb224dbaa2d4fbae9f4fc90439e2eed8730-statuses.txt](https://github.com/hail-is/hail/files/2531246/46808cb224dbaa2d4fbae9f4fc90439e2eed8730-statuses.txt). Before the merge status goes in we see this one:; ```; {; ""url"": ""https://api.github.com/repos/hail-is/hail/statuses/46808cb224dbaa2d4fbae9f4fc90439e2eed8730"",; ""avatar_url"": ""https://avatars2.githubusercontent.com/u/106194?v=4"",; ""id"": 5728320639,; ""node_id"": ""MDEzOlN0YXR1c0NvbnRleHQ1NzI4MzIwNjM5"",; ""state"": ""success"",; ""description"": ""successful build"",; ""target_url"": ""https://storage.googleapis.com/hail-ci-0-1/ci/46808cb224dbaa2d4fbae9f4fc90439e2eed8730/038a6de7ce33b218b8d45160f224cae1feaf1c5a/index.html"",; ""context"": ""hail-ci-0-1"",; ""created_at"": ""2018-10-30T18:51:09Z"",; ""updated_at"": ""2018-10-30T18:51:09Z"",; ""creator"": {; ""login"": ""danking"", ...; }; },; ```. and before that:. ```; {; ""url"": ""https://api.github.com/repos/hail-is/hail/statuses/46808cb224dbaa2d4fbae9f4fc90439e2eed8730"",; ""avatar_url"": ""https://avatars2.githubusercontent.com/u/106194?v=4"",; ""id"": 5728220065,; ""node_id"": ""MDEzOlN0YXR1c0NvbnRleHQ1NzI4MjIwMDY1"",; ""state"": ""pending"",; ""description"": ""build 38 pending. target: 038a6de7ce33"",; ""target_url"": null,; ""context"": ""hail-ci-0-1"",; ""cr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4685:142,error,error,142,https://hail.is,https://github.com/hail-is/hail/issues/4685,1,['error'],['error']
Availability,"```; # xsltproc -o fuckyou.html --html fuckyou.xslt; compilation error: file fuckyou.xslt line 2 element stylesheet; xsltParseStylesheetProcess : document is not a stylesheet; # vim fuckyou.xslt ; # cat fuckyou.xslt ; <?xml version=""1.0"" encoding=""ISO-8859-15""?>; <xsl:stylesheet version=""1.0"" xmlns:xsl=""http://www.w3.org/1999/XSL/Transform"">; </xsl:stylesheet>; # xsltproc -o fuckyou.html --html fuckyou.xslt; ```. www.w3.org definitely speaks TLS based on `curl`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8511#issuecomment-611277147:65,error,error,65,https://hail.is,https://github.com/hail-is/hail/pull/8511#issuecomment-611277147,1,['error'],['error']
Availability,"```; (1146, \""Table 'pr-7592-notebook-yi0bdn43fu8g.workshops' doesn't exist\"")""; ```. I'm not sure what's going on, but I noticed the notebook server cannot respond to /images due to this error. We should be scanning the logs of every service for ERROR log messages on each PR. I saw this because the image-fetchers are failing",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7624:188,error,error,188,https://hail.is,https://github.com/hail-is/hail/issues/7624,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"```; (b'', b""+ mkdir -p repos/hail-is/hail; + cd repos/hail-is/hail; + '[' '!' -d .git ']'; + git reset --merge; error: Entry 'hail/src/main/scala/is/hail/HailContext.scala' not uptodate. Cannot merge.; fatal: Could not reset index file to revision 'HEAD'.; ""); ```; https://ci.hail.is/watched_branches/0/pr/9048",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9051:113,error,error,113,https://hail.is,https://github.com/hail-is/hail/issues/9051,1,['error'],['error']
Availability,"```; * installing *source* package â€˜ncdf4â€™ ...; ** package â€˜ncdf4â€™ successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package â€˜ncdf4â€™; * removing â€˜/usr/local/lib/R/3.3/site-library/ncdf4â€™; ERROR: dependency â€˜ncdf4â€™ is not available for package â€˜GWASToolsâ€™; * removing â€˜/usr/local/lib/R/3.3/site-library/GWASToolsâ€™; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:250,Error,Error,250,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057,4,"['ERROR', 'Error', 'avail']","['ERROR', 'Error', 'available']"
Availability,"```; + CHANGED=yes; + [[ -e notebook/get-deployed-sha.sh ]]; + [[ yes != no ]]; + cd notebook; + /bin/bash hail-ci-deploy.sh; cat: notebook-image: No such file or directory; sed -e ""s,@sha@,17a365c57d0f,"" \; -e ""s,@image@,,"" \; < deployment.yaml.in > deployment.yaml; kubectl apply -f deployment.yaml; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""/v1, Resource=services"", GroupVersionKind: ""/v1, Kind=Service""; Name: ""notebook"", Namespace: ""batch-pods""; Object: &{map[""metadata"":map[""labels"":map[""app"":""notebook""] ""name"":""notebook"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""spec"":map[""ports"":[map[""port"":'P' ""protocol"":""TCP"" ""targetPort"":'\u1388']] ""selector"":map[""app"":""notebook""]] ""apiVersion"":""v1"" ""kind"":""Service""]}; from server for: ""deployment.yaml"": services ""notebook"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get services in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Makefile:4: recipe for target 'deploy' failed; make: *** [deploy] Error 1; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4656:302,Error,Error,302,https://hail.is,https://github.com/hail-is/hail/issues/4656,3,"['Error', 'error']","['Error', 'error']"
Availability,```; + cd /io; + rm -rf repo; + mkdir repo; + cd repo; + '[' '!' -d .git ']'; + retry clone; + clone; ++ mktemp -d; + dir=/tmp/tmp.Txkg8yv5oW; + git clone https://github.com/hail-is/hail.git /tmp/tmp.Txkg8yv5oW; Cloning into '/tmp/tmp.Txkg8yv5oW'...; error: RPC failed; curl 56 GnuTLS recv error (-54): Error in the pull function.; fatal: The remote end hung up unexpectedly; fatal: protocol error: bad pack header; ++ ls -A /tmp/tmp.Txkg8yv5oW. real	1m0.562s; user	0m0.135s; sys	0m0.086s; + git config user.email ci@hail.is; fatal: not in a git directory; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8170:251,error,error,251,https://hail.is,https://github.com/hail-is/hail/issues/8170,4,"['Error', 'error']","['Error', 'error']"
Availability,```; + date; Mon Mar 30 22:11:05 UTC 2020; + rm -rf repo; + mkdir repo; + cd repo; + '[' '!' -d .git ']'; + retry clone; + clone; + set -e; ++ mktemp -d; + dir=/tmp/tmp.3H7wTmq0R2; + git clone https://github.com/danking/hail.git /tmp/tmp.3H7wTmq0R2; Cloning into '/tmp/tmp.3H7wTmq0R2'...; error: RPC failed; curl 56 GnuTLS recv error (-54): Error in the pull function.; fatal: The remote end hung up unexpectedly; fatal: early EOF; fatal: index-pack failed; ++ ls -A /tmp/tmp.3H7wTmq0R2. real	0m3.373s; user	0m0.006s; sys	0m0.025s; + git config user.email ci@hail.is; fatal: not in a git directory; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8397:289,error,error,289,https://hail.is,https://github.com/hail-is/hail/issues/8397,3,"['Error', 'error']","['Error', 'error']"
Availability,"```; + make -k check-services; PYTHONPATH=""hail/python:auth:batch:ci:memory:notebook:monitoring:website:gear:web_common"" python3 -m flake8 --config setup.cfg auth; auth/auth/auth.py:515:86: W291 trailing whitespace; make: *** [Makefile:42: check-auth] Error 1; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12889#issuecomment-1515270732:252,Error,Error,252,https://hail.is,https://github.com/hail-is/hail/pull/12889#issuecomment-1515270732,1,['Error'],['Error']
Availability,```; /usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py:192: Warning: Converting column '' from VARCHAR to TEXT; await self._do_get_result(); ```. These mysterious two lines are printed to my batch log when I run a big test (1000 jobs). The [Server Error Reference](https://dev.mysql.com/doc/refman/8.0/en/server-error-reference.html) indicates this is error 1246. A [MySQL bug](https://bugs.mysql.com/bug.php?id=26090) suggests that ER_AUTO_CONVERT might be raised when one attempts to insert unicode into a varchar column. I don't understand why our column has the empty string as a name.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7769:257,Error,Error,257,https://hail.is,https://github.com/hail-is/hail/issues/7769,3,"['Error', 'error']","['Error', 'error', 'error-reference']"
Availability,"```; : is.hail.utils.package$FatalException: symbol `v' not found; Available symbols:; va: Struct; table: Struct; x: Dict[Int, Struct]; <input>:1:va.split_allele = let x = table.`va.split_allele` in range(v.nAltAlleles)[1:].map(i => if(x.contains(i)) x[i].val else NA: String); ```. Note: No idea if this impacts other `annotate_variants...`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1378:67,Avail,Available,67,https://hail.is,https://github.com/hail-is/hail/issues/1378,1,['Avail'],['Available']
Availability,"```; ERROR	| 2019-07-09 09:52:15,823 	| web_protocol.py 	| log_exception:355 | Error handling request; Jul 9, 2019 @ 05:52:15.824; Traceback (most recent call last):; Jul 9, 2019 @ 05:52:15.824; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py"", line 418, in start; Jul 9, 2019 @ 05:52:15.824; resp = await task; Jul 9, 2019 @ 05:52:15.824; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 458, in _handle; Jul 9, 2019 @ 05:52:15.824; resp = await handler(request); Jul 9, 2019 @ 05:52:15.824; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_urldispatcher.py"", line 157, in handler_wrapper; Jul 9, 2019 @ 05:52:15.824; result = await result; Jul 9, 2019 @ 05:52:15.824; File ""/usr/local/lib/python3.6/dist-packages/aiohttp_jinja2/__init__.py"", line 91, in wrapped; Jul 9, 2019 @ 05:52:15.824; context = await coro(*args); Jul 9, 2019 @ 05:52:15.824; File ""/ci/ci.py"", line 118, in get_pr; Jul 9, 2019 @ 05:52:15.824; status = await pr.batch.status(); Jul 9, 2019 @ 05:52:15.824; File ""/usr/local/lib/python3.6/dist-packages/hailtop/batch_client/aioclient.py"", line 209, in status; Jul 9, 2019 @ 05:52:15.824; return await self._client._get(f'/api/v1alpha/batches/{self.id}'); Jul 9, 2019 @ 05:52:15.824; File ""/usr/local/lib/python3.6/dist-packages/hailtop/batch_client/aioclient.py"", line 412, in _get; Jul 9, 2019 @ 05:52:15.824; self.url + path, params=params, cookies=self._cookies, headers=self._headers); Jul 9, 2019 @ 05:52:15.824; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/client.py"", line 581, in _request; Jul 9, 2019 @ 05:52:15.824; resp.raise_for_status(); Jul 9, 2019 @ 05:52:15.824; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/client_reqrep.py"", line 942, in raise_for_status; Jul 9, 2019 @ 05:52:15.824; headers=self.headers); Jul 9, 2019 @ 05:52:15.824; aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found'; Jul 9, 2019 @ 05:52:15.824; INFO	| 2019-07-09 09:52:15,824 	| web_log.py 	| log:233 | 1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6587:5,ERROR,ERROR,5,https://hail.is,https://github.com/hail-is/hail/issues/6587,2,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,```; Error summary: ClassCastException: is.hail.annotations.BroadcastValue cannot be cast to org.apache.spark.sql.Row; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3236:5,Error,Error,5,https://hail.is,https://github.com/hail-is/hail/issues/3236,1,['Error'],['Error']
Availability,```; Error summary: FileNotFoundException: Item not found: gnomad-berylc/tx-annotation/hail0.2/gnomad.exomes.r2.0.2.tx_annotated.PLIgenes.012618.kt; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2818:5,Error,Error,5,https://hail.is,https://github.com/hail-is/hail/issues/2818,1,['Error'],['Error']
Availability,"```; Error summary: ZipException: File does not conform to block gzip format.; ```; Good to print the file in a large pipeline, but especially tricky in a glob",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8118:5,Error,Error,5,https://hail.is,https://github.com/hail-is/hail/issues/8118,1,['Error'],['Error']
Availability,"```; Error; Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2272, in run; await self.jvm.execute(; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2872, in execute; raise JVMUserError(exception); JVMUserError: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at is.hail.JVMEntryway.retrieveException(JVMEntryway.java:253); 	at is.hail.JVMEntryway.finishFutures(JVMEntryway.java:215); 	at is.hail.JVMEntryway.main(JVMEntryway.java:185); Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:122); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750); Caused by: java.lang.reflect.InvocationTargetException; 	at sun.reflect.GeneratedMethodAccessor62.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); 	... 7 more; Caused by: java.lang.IllegalArgumentException: bound must be positive; 	at java.util.Random.nextInt(Random.java:388); 	at scala.util.Random.nextInt(Random.scala:70); 	at is.hail.services.package$.delayMsForTry(package.scala:47); 	at is.hail.services.package$.retryTransientErrors(package.scala:186); 	at is.hail.io.fs.Goo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:5,Error,Error,5,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888,1,['Error'],['Error']
Availability,"```; FilterGenotypes.run(state, Array(""--remove"", ""-c"", ""g.ad(0) < 5"")); hail: fatal: parse error in condition: org.broadinstitute.hail.methods.FilterOption[Array[Int]] does not take parameters; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/147:92,error,error,92,https://hail.is,https://github.com/hail-is/hail/issues/147,1,['error'],['error']
Availability,"```; Hail version: 0.2.38-16624ac88829; Error summary: AssertionError: assertion failed: +PCStruct{locus:PCLocus(GRCh37),alleles:PCArray[PCString],gene:+PCString,annotation:+PCString,__iruid_97596:+PCArray[+PCStruct{gene:+PCString,annotation:+PCString,`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+PCArray[PCStruct{AF_Allele2:PFloat64,imputationInfo:PFloat64,BETA:PFloat64,SE:PFloat64,`p.value.NA`:PFloat64,`AF.Cases`:PFloat64,`AF.Controls`:PFloat64,Pvalue:PFloat64}]}]}, struct{locus: locus<GRCh37>, alleles: array<str>, __iruid_97596: array<struct{gene: str, annotation: str, `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`: array<struct{AF_Allele2: float64, imputationInfo: float64, BETA: float64, SE: float64, `p.value.NA`: float64, `AF.Cases`: float64, `AF.Controls`: float64, Pvalue: float64}>}>}; ...; at scala.Predef$.assert(Predef.scala:170); at is.hail.expr.ir.TableAggregateByKey.execute(TableIR.scala:1879); at is.hail.expr.ir.TableFilter.execute(TableIR.scala:581); at is.hail.expr.ir.TableOrderBy.execute(TableIR.scala:1971); at is.hail.expr.ir.TableSubset$class.execute(TableIR.scala:626); at is.hail.expr.ir.TableHead.execute(TableIR.scala:634); at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:1176); ```; pipeline:; ```; mt = hl.read_matrix_table(...); x = mt._filter_partitions(range(1)); x.entries().show(); ```; version is some minor commits off of f836e49cb179117837aaae7614b6bdd28febe857",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8694:40,Error,Error,40,https://hail.is,https://github.com/hail-is/hail/issues/8694,1,['Error'],['Error']
Availability,"```; Hi, Today I updated the new verion of hail ï¼Œand try to re-build it, but I encountered some issues. ; ```; ## ï¼ˆ1ï¼‰ â€œgradle checkâ€ ERROR ï¼š/tmp/jniloader803664626041947143netlib-native_system-linux-x86_64.so: undefined symbol: cblas_dgemv. The â€œ~/hail $ gradle installDistâ€ went successfullyï¼Œbut when I do ""~/hail $ gradle check"",it got some error:. ........; Gradle suite > Gradle test > org.broadinstitute.hail.methods.LinearRegressionSuite.testNonNumericPheno PASSED; Running test: Test method testWithImportFam(org.broadinstitute.hail.methods.LinearRegressionSuite); /opt/BioDir/jdk/jdk1.8.0_91/bin/java: symbol lookup error: /tmp/jniloader803664626041947143netlib-native_system-linux-x86_64.so: undefined symbol: cblas_dgemv; :test FAILED. FAILURE: Build failed with an exception.; - What went wrong:; Execution failed for task ':test'.; ; > Process 'Gradle Test Executor 1' finished with non-zero exit value 127; - Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 5 mins 6.833 secs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/565:133,ERROR,ERROR,133,https://hail.is,https://github.com/hail-is/hail/issues/565,4,"['ERROR', 'FAILURE', 'error']","['ERROR', 'FAILURE', 'error']"
Availability,"```; In [10]: eval_expr_typed(functions.capture([1,2,3]).map(lambda x: x.to_int64()).append([1.0, 2.0, 3.0])); Error summary: HailException: No function found with name `append' and argument types (Array[Int64], Array[Float64]); <input>:1:[ 1, 2, 3 ].map(__uid_2 => `__uid_2`.toInt64()).append([ 1.0, 2.0, 3.0 ]); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2691:111,Error,Error,111,https://hail.is,https://github.com/hail-is/hail/issues/2691,1,['Error'],['Error']
Availability,"```; In [1]: hl.utils.range_table(1).annotate(**{'a b c' : 5}).order_by('a b c')._force_count(); ```. ```. is.hail.utils.HailException: invalid struct filter operation: fields [ ``, ` b c` ] not found; Existing struct fields: [ idx, `a b c` ]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.expr.types.virtual.TStruct.filterSet(TStruct.scala:295); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5277:262,Error,ErrorHandling,262,https://hail.is,https://github.com/hail-is/hail/issues/5277,2,['Error'],['ErrorHandling']
Availability,"```; Lots of local cleanups.; Use `' for quoting inside error messages.; Added SuperCommand, ToplevelCommands. Use for annotatevariants and annotatesamples.; Try to make multiple instances of (essentially) same error message consistent.; Added option to LoadVCF, ImportVCF to skip genotypes. Use in importannotations.; Fixed some bugs in FatalException handling.; Moved Type.parse to trait Parsable.; Added Parser.parseAnnotationTypes.; Added `type_expr' non-terminal to Parser.; Prefer `import ...expr._' to `import ...expr' and `expr.Foo'.; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/228:56,error,error,56,https://hail.is,https://github.com/hail-is/hail/pull/228,2,['error'],['error']
Availability,```; Py4JJavaError: An error occurred while calling z:is.hail.HailContext.apply.; : java.util.NoSuchElementException: spark.serializer; at org.apache.spark.SparkConf$$anonfun$get$1.apply(SparkConf.scala:245); at org.apache.spark.SparkConf$$anonfun$get$1.apply(SparkConf.scala:245); at scala.Option.getOrElse(Option.scala:121); at org.apache.spark.SparkConf.get(SparkConf.scala:245); at is.hail.HailContext$.checkSparkConfiguration(HailContext.scala:108); at is.hail.HailContext$.apply(HailContext.scala:180); at is.hail.HailContext.apply(HailContext.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:282); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:745); ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3860:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/issues/3860,1,['error'],['error']
Availability,"```; Traceback (most recent call last):; File ""/tmp/09d98b2f-4a41-4652-9eba-e319bfda2ca4/sandbox.py"", line 17, in <module>; pprint(hc.read('%s/variantqc/exacv2_rf.vds' % root, sites_only=True).filter_variants_intervals('gs://exac2/temp').head()); File ""/tmp/09d98b2f-4a41-4652-9eba-e319bfda2ca4/utils.py"", line 201, in head; return json.loads(self.variants_keytable().to_dataframe().toJSON().first()); File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py"", line 1328, in first; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py"", line 1310, in take; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/context.py"", line 933, in runJob; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; for criterion, pop in criteria_pops:; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.; : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 20 times, most recent failure: Lost task 0.19 in stage 5.0 (TID 20022, exac-sw-3pdd.c.broad-mpg-gnomad.internal): java.lang.ClassCastException: scala.Tuple2 cannot be cast to org.apache.spark.sql.Row; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1311:1007,error,error,1007,https://hail.is,https://github.com/hail-is/hail/issues/1311,3,"['error', 'failure']","['error', 'failure']"
Availability,"```; Traceback (most recent call last):; File ""/tmp/aa0cd79aaa1a4f1ba652555c05c4bf85/pyscripts_rlCXpu.zip/gnomad_hail/slack_utils.py"", line 77, in try_slack; func(*args); File ""/tmp/aa0cd79aaa1a4f1ba652555c05c4bf85/assign_subpops.py"", line 16, in main; pop_table = exome_pop_table.union(genome_pop_table); File ""<decorator-gen-484>"", line 2, in union; File ""/tmp/aa0cd79aaa1a4f1ba652555c05c4bf85/hail-devel-3da0e7424af0.zip/hail/typecheck/check.py"", line 481, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/tmp/aa0cd79aaa1a4f1ba652555c05c4bf85/hail-devel-3da0e7424af0.zip/hail/table.py"", line 1496, in union; return Table(self._jt.union([table._jt for table in tables])); File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/tmp/aa0cd79aaa1a4f1ba652555c05c4bf85/hail-devel-3da0e7424af0.zip/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.table.Table.union(Table.scala:931); at is.hail.table.Table.union(Table.scala:928); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748). Hail v",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3404:957,Error,Error,957,https://hail.is,https://github.com/hail-is/hail/issues/3404,1,['Error'],['Error']
Availability,"```; Traceback (most recent call last):; File ""<stdin>"", line 5, in <module>; File ""/mnt/lustre/tpoterba/hail-inst/python/pyhail/dataset.py"", line 77, in annotate_samples_expr; return self.hc.run_command(self, pargs); File ""/mnt/lustre/tpoterba/hail-inst/python/pyhail/context.py"", line 45, in run_command; cmd_args); File ""/opt/spark/spark-1.5.2/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py"", line 538, in __call__; File ""/opt/spark/spark-1.5.2/python/pyspark/sql/utils.py"", line 36, in deco; return f(*a, **kw); File ""/opt/spark/spark-1.5.2/python/lib/py4j-0.8.2.1-src.zip/py4j/protocol.py"", line 300, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o417.run.; : org.apache.spark.SparkDriverExecutionException: Execution error; at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1024); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1493); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1458); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1447); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:567); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1824); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1007); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108); at org.apache.spark.rdd.RDD.withScope(RDD.scala:310); at org.apache.spark.rdd.RDD.reduce(RDD.scala:989); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1118); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1107:665,error,error,665,https://hail.is,https://github.com/hail-is/hail/issues/1107,2,['error'],['error']
Availability,"```; body='{\\n \""error\"": {\\n \""code\"": 403,\\n \""message\"": \""Quota exceeded for quota group \\'default\\' and limit \\'Queries per user per 100 seconds\\' of service \\'compute.googleapis.com\\' for consumer \\'project_number:859893752941\\'.\"",\\n \""errors\"": [\\n {\\n \""message\"": \""Quota exceeded for quota group \\'default\\' and limit \\'Queries per user per 100 seconds\\' of service \\'compute.googleapis.com\\' for consumer \\'project_number:859893752941\\'.\"",\\n \""domain\"": \""usageLimits\"",\\n \""reason\"": \""rateLimitExceeded\""\\n }\\n ],\\n \""status\"": \""PERMISSION_DENIED\""\\n }\\n}; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10613:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/10613,2,['error'],"['error', 'errors']"
Availability,"```; echo $SPARK_CLASSPATH; /Users/ih/languages/hail.is/hail/build/libs/hail-all-spark.jar; ```; SPARK_CLASSPATH is set correctly, however, I still get the error message; ```; >>> hc = HailContext(); Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-422>"", line 2, in __init__; File ""/Users/ih/languages/hail.is/hail/python/hail/typecheck/check.py"", line 226, in _typecheck; return f(*args, **kwargs); File ""/Users/ih/languages/hail.is/hail/python/hail/context.py"", line 83, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable; ```. What do I need to do about the driverClassPath?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2062#issuecomment-319712395:5,echo,echo,5,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319712395,2,"['echo', 'error']","['echo', 'error']"
Availability,"```; from hail import *; hc = HailContext(); input_vcf = ""gs://seqr-hail/reference_data/GRCh38/1kg/ALL.GRCh38_sites.20170504.vcf.gz""; vds = hc.import_vcf(input_vcf, npartitions=1000, force=True); ```. causes. ```; FatalErrorTraceback (most recent call last); <ipython-input-4-5e86630fbae5> in <module>(); ----> 1 vds = hc.import_vcf(input_vcf, npartitions=1000, force=True). <decorator-gen-291> in import_vcf(self, path, force, force_bgz, header_file, npartitions, sites_only, store_gq, pp_as_pl, skip_bad_ad, generic, call_fields). /home/hail/pyhail-hail-is-master-ebabd77.zip/hail/java.pyc in handle_py4j(func, *args, **kwargs); 111 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 112 'Hail version: %s\n'; --> 113 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); 114 except py4j.protocol.Py4JError as e:; 115 if e.args[0].startswith('An error occurred while calling'):. FatalError: IllegalArgumentException: Size exceeds Integer.MAX_VALUE. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, seqr-pipeline-cluster-grch38-w-0.c.seqr-project.internal): java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE; 	at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:869); 	at org.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskStore.scala:103); 	at org.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskStore.scala:91); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1310); 	at org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:105); 	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:438); 	at org.apache.spark.storage.BlockManager.get(BlockManager.scala:606); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:663); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); 	at or",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1806:720,Error,Error,720,https://hail.is,https://github.com/hail-is/hail/issues/1806,2,"['Error', 'error']","['Error', 'error']"
Availability,"```; gsutil cat gs://hail-ci-0-1/deploy/ef349a51016f\*/job-log; ```. the last few lines:. ```; + make push-batch; docker build -t batch .; time=""2018-09-26T00:14:20Z"" level=error msg=""failed to dial gRPC: cannot connect to the Docker daemon. Is 'docker daemon' running on this host?: dial unix /var/run/docker.sock: connect: permission denied""; Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.38/build?buildargs=%7B%7D&cachefrom=%5B%5D&cgroupparent=&cpuperiod=0&cpuquota=0&cpusetcpus=&cpusetmems=&cpushares=0&dockerfile=Dockerfile&labels=%7B%7D&memory=0&memswap=0&networkmode=default&rm=1&session=vhnl6wchhs00sgt8raa35j7m7&shmsize=0&t=batch&target=&ulimits=null&version=1: dial unix /var/run/docker.sock: connect: permission denied; time=""2018-09-26T00:14:20Z"" level=error msg=""Can't add file /hail/repo/batch/batch/server.py to tar: io: read/write on closed pipe""; Makefile:14: recipe for target 'build-batch' failed; make: *** [build-batch] Error 1; ```. this is failing all deploys of hail, which is safe, but it prevents our users from getting updates.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4443:173,error,error,173,https://hail.is,https://github.com/hail-is/hail/issues/4443,3,"['Error', 'error']","['Error', 'error']"
Availability,"```; hail read -i profile.vds annotatesamples tsv -i sampleInfo.tsv -t 'Age: Int, Health: Double' -r sa.info filtersamples --keep -c 'sa.info.Health > 0.2' linreg -y sa.info.Health -c 'sa.info.Age' -r va.linreg exportvariants -c 'Variant=v, Beta = va.linreg.beta, Pval = va.linreg.pval' -o linreg.tsv; ```. ```; [Stage 1:> (0 + 7) / 7]hail: exportvariants: caught exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 1.0 failed 1 times, most recent failure: Lost task 5.0 in stage 1.0 (TID 13, localhost): java.lang.ArrayIndexOutOfBoundsException: 357; at org.broadinstitute.hail.methods.LinRegBuilder$$anonfun$stats$1.apply$mcVI$sp(LinearRegression.scala:80); at org.broadinstitute.hail.methods.LinRegBuilder$$anonfun$stats$1.apply(LinearRegression.scala:80); at org.broadinstitute.hail.methods.LinRegBuilder$$anonfun$stats$1.apply(LinearRegression.scala:80); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofInt.foreach(ArrayOps.scala:156); at org.broadinstitute.hail.methods.LinRegBuilder.stats(LinearRegression.scala:80); at org.broadinstitute.hail.methods.LinearRegression$$anonfun$apply$4.apply(LinearRegression.scala:130); at org.broadinstitute.hail.methods.LinearRegression$$anonfun$apply$4.apply(LinearRegression.scala:129); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$41$$anonfun$apply$42.apply(PairRDDFunctions.scala:700); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$41$$anonfun$apply$42.apply(PairRDDFunctions.scala:700); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$20.next(Iterator.scala:635); at scala.collection.Iterator$$anon$20.next(Iterator.scala:633); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/336:433,failure,failure,433,https://hail.is,https://github.com/hail-is/hail/issues/336,2,['failure'],['failure']
Availability,"```; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 567 in stage 86.0 failed 20 times, most recent failure: Lost task 567.19 in stage 86.0 (TID 59449, exomes-sw-73zg.c.broad-mpg-gnomad.internal, executor 41): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:417); 	at is.hail.annotations.RegionValueBuilder.addField(RegionValueBuilder.scala:345); 	at is.hail.annotations.RegionValueBuilder.addField(RegionValueBuilder.scala:351); 	at is.hail.expr.ir.MatrixAggregateColsByKey$$anonfun$33$$anonfun$apply$15.apply(MatrixIR.scala:1016); 	at is.hail.expr.ir.MatrixAggregateColsByKey$$anonfun$33$$anonfun$apply$15.apply(MatrixIR.scala:972); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1106); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1100); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1106); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1100); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1106); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1100); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:89",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4263:144,failure,failure,144,https://hail.is,https://github.com/hail-is/hail/issues/4263,2,['failure'],['failure']
Availability,"```; hail: info: SparkUI: http://10.131.101.159:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-f69b497; >>> print sc; <SparkContext master=yarn appName=PySparkShell>; >>> print hc; <hail.context.HailContext object at 0x1f15350>; >>> hc.import_vcf(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: import_vcf() takes at least 2 arguments (1 given); >>> hc.import_vcf('/hail/sample.vcf'); [Stage 0:> (0 + 1) / 2]Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-313>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: SparkException: Failed to get broadcast_4_piece0 of broadcast_4. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 6, com2, executor 1): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:691,Error,Error,691,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807,3,"['Error', 'failure']","['Error', 'failure']"
Availability,"```; import hail as hl; ds = hl.balding_nichols_model(3, 100, 100); ds.annotate_globals(x=[1,2,3]); ```; The above script breaks on devel clusters.; ```; py4j.protocol.Py4JJavaError: An error occurred while calling o64.annotateGlobalExpr.; : java.lang.NoClassDefFoundError: is/hail/asm4s/AsmFunction2; 	at java.lang.ClassLoader.defineClass1(Native Method); 	at java.lang.ClassLoader.defineClass(ClassLoader.java:763); 	at java.lang.ClassLoader.defineClass(ClassLoader.java:642); 	at is.hail.asm4s.package$HailClassLoader$.liftedTree1$1(package.scala:174); 	at is.hail.asm4s.package$HailClassLoader$.loadOrDefineClass(package.scala:170); 	at is.hail.asm4s.package$.loadClass(package.scala:181); 	at is.hail.asm4s.FunctionBuilder$$anon$1.apply(FunctionBuilder.scala:312); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:84); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:82); 	at is.hail.expr.Parser$$anonfun$is$hail$expr$Parser$$evalNoTypeCheck$1.apply(Parser.scala:64); 	at is.hail.expr.Parser$$anonfun$12$$anonfun$apply$6.apply(Parser.scala:172); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2982:186,error,error,186,https://hail.is,https://github.com/hail-is/hail/issues/2982,1,['error'],['error']
Availability,"```; is.hail.utils.HailException: hybrid.m37m.vcf.bgz: caught htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 458249: unparsable vcf record with allele M; offending line: 3	60830534	.	M	C	40	.	.	GT:AD	1/1:0,40; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.utils.Context.wrapException(Context.scala:23); 	at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:742); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.hasNext(OrderedRVD.scala:733); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$11.apply(OrderedRVD.scala:491); 	at is.hail.rvd.OrderedRVD$$anonfun$11.apply(OrderedRVD.scala:490); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 458249: unparsable vcf record with allele M; 	at htsjdk.variant.vcf.AbstractVCFCodec.generateException(AbstractVCFCodec.j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3015:278,Error,ErrorHandling,278,https://hail.is,https://github.com/hail-is/hail/issues/3015,2,['Error'],['ErrorHandling']
Availability,"```; kubectl apply -f deployment.yaml; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""/v1, Resource=namespaces"", GroupVersionKind: ""/v1, Kind=Namespace""; Name: ""batch-pods"", Namespace: """"; Object: &{map[""apiVersion"":""v1"" ""kind"":""Namespace"" ""metadata"":map[""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""] ""name"":""batch-pods"" ""namespace"":""""]]}; from server for: ""deployment.yaml"": namespaces ""batch-pods"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get namespaces in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""/v1, Resource=serviceaccounts"", GroupVersionKind: ""/v1, Kind=ServiceAccount""; Name: ""batch-svc"", Namespace: ""batch-pods""; Object: &{map[""kind"":""ServiceAccount"" ""metadata"":map[""name"":""batch-svc"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""apiVersion"":""v1""]}; from server for: ""deployment.yaml"": serviceaccounts ""batch-svc"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get serviceaccounts in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=roles"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=Role""; Name: ""batch-pods-admin"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""Role"" ""metadata"":map[""name"":""batch-pods-admin"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""rules"":[map[""apiGroups"":[""""] ""resources"":[""pods""] ""verbs"":[""get"" ""list"" ""watch"" ""create"" ""update"" ""patch"" ""delete""]] map[""apiGroups"":[""""] ""resources"":[""pods/log""] ""verbs"":[""get""]]]]}; from server for: ""deployment.yaml"": roles.rbac.author",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4609:39,Error,Error,39,https://hail.is,https://github.com/hail-is/hail/issues/4609,4,"['Error', 'error']","['Error', 'error']"
Availability,"```; mu = mutation_ht.aggregate(hl.agg.group_by(; hl.struct(context=mutation_ht.context, ref=mutation_ht.ref, alt=mutation_ht.alt,; methylation_level=mutation_ht.methylation_level),; hl.agg.collect(mutation_ht.mu_snp))); ```; got:; ```; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1.0 (TID 11, localhost, executor driver): com.esotericsoftware.kryo.KryoException: sun.reflect.generics.reflectiveObjects.NotImplementedException; Serialization trace:; m (is.hail.annotations.aggregators.KeyedRegionValueAggregator); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:101); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:315); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:386); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: sun.reflect.generics.reflectiveObjects.NotImplementedException; 	at is.hail.annotations.UnKryoSerializable$class.write(UnsafeRow.scala:15); 	at is.hail.annotations.UnsafeRow.write(UnsafeRow.scala:141); 	at com.esotericsoftware.kryo.serializers.DefaultSerializers$KryoSerializableSerializer.write(DefaultSerializers.java:505); 	at com.esotericsoftware.kryo.serializers.DefaultSerializers$KryoSerializa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4215:314,failure,failure,314,https://hail.is,https://github.com/hail-is/hail/issues/4215,2,['failure'],['failure']
Availability,"```; tpoterba@tim2-m:~$ sudo `which pip` install /usr/lib/spark/python/; Processing /usr/lib/spark/python; Complete output from command python setup.py egg_info:. If you are installing pyspark from spark source, you must first build Spark and; run sdist. To build Spark with maven you can run:; ./build/mvn -DskipTests clean package; Building the source dist is done in the Python directory:; cd python; python setup.py sdist; pip install dist/*.tar.gz. ----------------------------------------; Command ""python setup.py egg_info"" failed with error code 255 in /tmp/pip-req-build-r4aje_7z/; You are using pip version 10.0.1, however version 19.1.1 is available.; You should consider upgrading via the 'pip install --upgrade pip' . ```. :(",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6297#issuecomment-500615508:543,error,error,543,https://hail.is,https://github.com/hail-is/hail/pull/6297#issuecomment-500615508,2,"['avail', 'error']","['available', 'error']"
Availability,"```; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:20:29,378"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:20:42,418"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:20:49,707"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: Object of type 'datetime' is not JSON serializable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6707:20,ERROR,ERROR,20,https://hail.is,https://github.com/hail-is/hail/issues/6707,2,['ERROR'],['ERROR']
Availability,"```; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-29 12:31:18,857"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1270"", ""message"": ""k8s event stream failed due to: "", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1268, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1253, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1195, in update_job_with_pod\n err = await app['k8s'].delete_pod(name=pod.metadata.name)\n File \""/usr/local/lib/python3.6/dist-packages/batch/k8s.py\"", line 46, in delete_pod\n assert name is not None\nAssertionError""}; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6753:20,ERROR,ERROR,20,https://hail.is,https://github.com/hail-is/hail/issues/6753,1,['ERROR'],['ERROR']
Availability,"```; {""levelname"": ""INFO"", ""asctime"": ""2019-07-26 23:46:41,095"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1263"", ""message"": ""received event ERROR None""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-26 23:46:41,095"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1266"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1264, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1248, in pod_changed\n job = await Job.from_k8s_labels(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 388, in from_k8s_labels\n batch_id = pod.metadata.labels['batch_id']\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-26 23:46:44,287"", ""filename"": ""web_log.py"", ""funcNameAndLine"": ""log:233"", ""message"": ""10.32.34.1 [26/Jul/2019:23:46:44 +0000] \""GET /healthcheck HTTP/1.1\"" 200 177 \""-\"" \""kube-probe/1.13+\"""", ""remote_address"": ""10.32.34.1"", ""request_start_time"": ""[26/Jul/2019:23:46:44 +0000]"", ""first_request_line"": ""GET /healthcheck HTTP/1.1"", ""response_status"": 200, ""response_size"": 177, ""request_header"": {""Referer"": ""-"", ""User-Agent"": ""kube-probe/1.13+""}}; ```. why even send this ðŸ¤·â€â™€",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6750:159,ERROR,ERROR,159,https://hail.is,https://github.com/hail-is/hail/issues/6750,2,['ERROR'],['ERROR']
Availability,"```; {; ""levelname"": ""ERROR"",; ""asctime"": ""2019-07-02 13:17:00,483"",; ""filename"": ""web_protocol.py"",; ""funcNameAndLine"": ""log_exception:355"",; ""message"": ""Error handling request"",; ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py\"", line 418, in start\n resp = await task\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py\"", line 458, in _handle\n resp = await handler(request)\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/web_urldispatcher.py\"", line 157, in handler_wrapper\n result = await result\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 914, in create_jobs\n success = await jobs_builder.commit()\n File \""/usr/local/lib/python3.6/dist-packages/batch/database.py\"", line 161, in commit\n await cursor.executemany(self._jobs_sql, self._jobs)\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 283, in executemany\n self._get_db().encoding))\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 318, in _do_execute_many\n r = await self.execute(sql + postfix)\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 239, in execute\n await self._query(query)\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 457, in _query\n await conn.query(q)\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 428, in query\n await self._read_query_result(unbuffered=unbuffered)\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 622, in _read_query_result\n await result.read()\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 1105, in read\n first_packet = await self.connection._read_packet()\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 593, in _read_packet\n packet.check_error()\n File \""/usr/local/lib/python3.6/dist-packages/pymysql/protocol.py\"", line 220, in ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6543:22,ERROR,ERROR,22,https://hail.is,https://github.com/hail-is/hail/issues/6543,2,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,```Error summary: Error: Multiple ES-Hadoop versions detected in the classpath; please use only one; jar:file:/tmp/7a54aa23-f38b-40e4-8068-3ea48ee212a0/hail-annotateAlleles01.jar; jar:file:/usr/lib/spark/jars/hail-0.1-6e815ac3d973-Spark-2.0.2.jar; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2272:3,Error,Error,3,https://hail.is,https://github.com/hail-is/hail/issues/2272,2,['Error'],['Error']
Availability,"```pycon; In [1]: import hail as hl. In [2]: hl.init(); 2022-03-11 14:49:23 WARN Utils:69 - Your hostname, metis resolves to a loopback address: 127.0.0.1; using 192.168.1.169 instead (on interface eth0); 2022-03-11 14:49:23 WARN Utils:69 - Set SPARK_LOCAL_IP if you need to bind to another address; 2022-03-11 14:49:23 WARN NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 3.1.2; SparkUI available at http://192.168.1.169:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.90-92e40ce648a8; LOGGING: writing to /home/cdv/src/hail/hail/hail-20220311-1449-0.2.90-92e40ce648a8.log. In [3]: mt = hl.import_vcf('src/test/resources/sample.vcf').filter_rows(False). In [4]: ht = mt._localize_entries('entries', 'columns'). In [5]: groups = ht.group_by(the_key=ht.key).aggregate(value=hl.agg.collect(ht.row_value)).collect(); 2022-03-11 14:50:08 Hail: INFO: Coerced sorted dataset; 2022-03-11 14:50:10 Hail: INFO: Ordering unsorted dataset with network shuffle1]. In [6]: len(groups); Out[6]: 346. In [7]: mt = mt.checkpoint('~/tmp/hail/sample.vcf.filtered.mt'); 2022-03-11 14:51:14 Hail: INFO: wrote matrix table with 0 rows and 100 columns in 0 partitions to ~/tmp/hail/sample.vcf.filtered.mt. In [8]: ht = mt._localize_entries('entries', 'columns'). In [9]: groups_native = ht.group_by(the_key=ht.key).aggregate(value=hl.agg.collect(ht.row_value)).collect(). In [10]: len(groups_native); Out[10]: 0; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11562:629,avail,available,629,https://hail.is,https://github.com/hail-is/hail/issues/11562,2,"['avail', 'checkpoint']","['available', 'checkpoint']"
Availability,"```python; >>> hl.eval(hl.min_rep(hl.locus('1', 10000), ['G', hl.null(hl.tstr)])); ```; I don't have any problem with this erroring, but it's mode should be more user friendly. Either that or we allow `NA` in `min_rep` (just return the NA) in the `alleles` array and don't use it for the purposes of actually `min_rep`ping.; ```; java.lang.NullPointerException: null ; at is.hail.codegen.generated.C172.method_2(Unknown Source) ; at is.hail.codegen.generated.C172.method_1(Unknown Source) ; at is.hail.codegen.generated.C172.apply(Unknown Source) ; at is.hail.codegen.generated.C172.apply(Unknown Source) ; at is.hail.expr.ir.Interpret$$anonfun$apply$33.apply(Interpret.scala:711) ; at is.hail.expr.ir.Interpret$$anonfun$apply$33.apply(Interpret.scala:690) ; at is.hail.utils.package$.using(package.scala:596); at is.hail.annotations.Region$.scoped(Region.scala:18); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:690); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:91); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:61); at is.hail.expr.ir.FoldConstants$$anonfun$apply$1$$anonfun$apply$2.apply(FoldConstants.scala:30); at is.hail.expr.ir.FoldConstants$$anonfun$apply$1$$anonfun$apply$2.apply(FoldConstants.scala:8); at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:15); at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:25); at is.hail.expr.ir.FoldConstants$$anonfun$apply$1.apply(FoldConstants.scala:8); at is.hail.expr.ir.FoldConstants$$anonfun$apply$1.apply(FoldConstants.scala:7); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:8); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:7); at is.hail.utils.package$.using(package.scala:596); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6889:123,error,erroring,123,https://hail.is,https://github.com/hail-is/hail/issues/6889,2,"['error', 'ping']","['erroring', 'ping']"
Availability,"```python; import hail as hl; hl.init(); hl.utils.get_1kg('data'); mt = hl.read_matrix_table('data/1kg.mt'); mt.entries().show(10); df = mt.entries().to_pandas(); ```. ```; Hail version: 0.2.18-08ec699f0fd4; Error summary: HailException: optimization changed type!; before: Table{global:Struct{},key:[],row:Struct{`locus.contig`:String,`locus.position`:Int32,alleles:Array[String],rsid:String,qual:Float64,filters:Array[String],`info.AC`:Array[Int32],`info.AF`:Array[Float64],`info.AN`:Int32,`info.BaseQRankSum`:Float64,`info.ClippingRankSum`:Float64,`info.DP`:Int32,`info.DS`:Boolean,`info.FS`:Float64,`info.HaplotypeScore`:Float64,`info.InbreedingCoeff`:Float64,`info.MLEAC`:Array[Int32],`info.MLEAF`:Array[Float64],`info.MQ`:Float64,`info.MQ0`:Int32,`info.MQRankSum`:Float64,`info.QD`:Float64,`info.ReadPosRankSum`:Float64,`info.set`:String,s:String,`GT.alleles`:Array[Int32],`GT.phased`:Boolean,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}}; after: Table{global:Struct{},key:[],row:Struct{`locus.contig`:String,`locus.position`:Int32,alleles:Array[String],rsid:String,qual:Float64,filters:Array[String],`info.AC`:Array[Int32],`info.AF`:Array[Float64],`info.AN`:Int32,`info.BaseQRankSum`:Float64,`info.ClippingRankSum`:Float64,`info.DP`:Int32,`info.DS`:Boolean,`info.FS`:Float64,`info.HaplotypeScore`:Float64,`info.InbreedingCoeff`:Float64,`info.MLEAC`:Array[Int32],`info.MLEAF`:Array[Float64],`info.MQ`:Float64,`info.MQ0`:Int32,`info.MQRankSum`:Float64,`info.QD`:Float64,`info.ReadPosRankSum`:Float64,`info.set`:String,s:String,`GT.alleles`:Array[Int32],`GT.phased`:Boolean,AD:Array[+Int32],DP:Int32,GQ:Int32,PL:Array[+Int32]}}; ```. Randomly assigned @catoverdrive, cc: @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6766:208,Error,Error,208,https://hail.is,https://github.com/hail-is/hail/issues/6766,1,['Error'],['Error']
Availability,"```python; vds.filter_variants_expr('v => va.pass').count(); ```. ```; vds.filter_variants_expr('v => va.pass').count(); ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-44-0380f72331b7> in <module>(); ----> 1 vds.filter_variants_expr('v => va.pass').count(). <decorator-gen-223> in filter_variants_expr(self, condition, keep). /Users/tpoterba/hail/python/hail/java.py in handle_py4j(func, *args, **kwargs); 111 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 112 'Hail version: %s\n'; --> 113 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); 114 except py4j.protocol.Py4JError as e:; 115 if e.args[0].startswith('An error occurred while calling'):. FatalError: UnsupportedOperationException: null. Java stack trace:; java.lang.UnsupportedOperationException: null; 	at is.hail.expr.AST.typecheckThis(AST.scala:215); 	at is.hail.expr.AST.typecheckThis(AST.scala:213); 	at is.hail.expr.AST.typecheck(AST.scala:219); 	at is.hail.expr.Parser$.is$hail$expr$Parser$$eval(Parser.scala:57); 	at is.hail.expr.Parser$.parseExpr(Parser.scala:67); 	at is.hail.expr.Parser$.parseTypedExpr(Parser.scala:77); 	at is.hail.variant.VariantSampleMatrix.filterVariantsExpr(VariantSampleMatrix.scala:1229); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:7",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1623:586,Error,Error,586,https://hail.is,https://github.com/hail-is/hail/issues/1623,2,"['Error', 'error']","['Error', 'error']"
Availability,"`aiohttp.ClientOSError` inherits from `OSError`, so we can just use `errno` or `strerror` directly. We should not directly use the `args` because one of the subclasses of `ClientOSError` sets them to *its* arguments after initializing its super classes with the expected arguments:. ```python3; class ClientConnectorError(ClientOSError):; """"""Client connector error. Raised in :class:`aiohttp.connector.TCPConnector` if; a connection can not be established.; """""". def __init__(self, connection_key: ConnectionKey, os_error: OSError) -> None:; self._conn_key = connection_key; self._os_error = os_error; super().__init__(os_error.errno, os_error.strerror); self.args = (connection_key, os_error); ```. I also tried to remove `e.args` from the `ClientPayloadError` case (the one right above this, and the only one still using `e.args`), but neither that class nor any super class sets a field with the error message (in fact, no fields are ever set so we can only use `e.args`).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13921:359,error,error,359,https://hail.is,https://github.com/hail-is/hail/pull/13921,2,['error'],['error']
Availability,`check-services` error: `on-shutdown` needs a ` # pylint: disable=unused-argument`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10106#issuecomment-801560644:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/10106#issuecomment-801560644,1,['error'],['error']
Availability,"`create_database_pool` does not actually make a connection, rather it sets up a `_PoolContextManager`. We need to make sure this line. ```python; self.pool = await self.async_exit_stack.enter_async_context(x); ```. is covered by transient error handling.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14309:239,error,error,239,https://hail.is,https://github.com/hail-is/hail/pull/14309,1,['error'],['error']
Availability,`hail: fatal: parse error in condition: reflective typecheck has failed: value DUMMY is not a member of __infoClass; `. There's got to be a better way to do this.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/84:20,error,error,20,https://hail.is,https://github.com/hail-is/hail/issues/84,1,['error'],['error']
Availability,"`hail` was hanging after all commands completed when running kudu commands against the quickstart. From the thread dump, it looked like it was spinning in the kudu client. Shutting down the kudu context seemed to fix the problem. See any problems with this patch? Also, I removed latest. It didn't seem to be used. ```; diff --git a/src/main/scala/org/kududb/spark/KuduContext.scala b/src/main/scala/org/kududb/spark/KuduContext.scala; index c48dcd4..71be7d2 100644; --- a/src/main/scala/org/kududb/spark/KuduContext.scala; +++ b/src/main/scala/org/kududb/spark/KuduContext.scala; @@ -41,8 +41,6 @@ class KuduContext(@transient sc: SparkContext,. val broadcastedKuduMaster = sc.broadcast(kuduMaster). - LatestKuduContextCache.latest = this; -; /**; * A simple enrichment of the traditional Spark RDD foreachPartition.; * This function differs from the original in that it offers the; @@ -169,10 +167,6 @@ class KuduContext(@transient sc: SparkContext,; def fakeClassTag[T]: ClassTag[T] = ClassTag.AnyRef.asInstanceOf[ClassTag[T]]; }. -object LatestKuduContextCache {; - var latest:KuduContext = null; -}; -; object KuduClientCache {; var kuduClient: KuduClient = null; var asyncKuduClient: AsyncKuduClient = null; @@ -195,4 +189,14 @@ object KuduClientCache {; asyncKuduClient; }. + def close() {; + if (kuduClient != null) {; + kuduClient.close(); + kuduClient = null; + }; + if (asyncKuduClient != null) {; + asyncKuduClient.close(); + asyncKuduClient = null; + }; + }; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/242#issuecomment-220667612:181,down,down,181,https://hail.is,https://github.com/hail-is/hail/pull/242#issuecomment-220667612,2,['down'],['down']
Availability,"`hl.balding_nichols_model` generates a MatrixTable representing a genetic dataset randomly drawn according to the Balding Nichols model.; ```; In [5]: hl.balding_nichols_model(2,3,3).show() ; 2019-08-15 10:38:05 Hail: INFO: balding_nichols_model: generating genotypes for 2 populations, 3 samples, and 3 variants...; +---------------+------------+------+------+------+; | locus | alleles | 0.GT | 1.GT | 2.GT |; +---------------+------------+------+------+------+; | locus<GRCh37> | array<str> | call | call | call |; +---------------+------------+------+------+------+; | 1:1 | [""A"",""C""] | 0/0 | 0/0 | 0/1 |; | 1:2 | [""A"",""C""] | 1/1 | 1/1 | 1/1 |; | 1:3 | [""A"",""C""] | 1/1 | 0/1 | 0/0 |; +---------------+------------+------+------+------+. ```; These MatrixTables are useful both as examples and test datasets for genetics-related Hail code. Unfortunately, the loci are chosen sequentially starting with chromosome 1, position 1. This region of chromosome 1 is in the telomere. Many genetic annotations contain no information in this region. As a result, `hl.balding_nichols_model` is not useful when demonstrating the annotation database or third-party genetic annotations. We want to enhance `hl.balding_nichols_model` to select variants (loci-allele-array pairs) that are likely to appear in real genetic datasets. One very simple model would be to draw variants according to their alternate/minor allele frequency in the gnomAD or 1000 Genomes datasets. An additional improvement would be to generate chromosomes roughly proportionally to their true sizes. These changes should not significantly slow down the method. We may want to include a small dataset of allele frequencies with Hail for use when the requested number of variants is small, only loading the full gnomAD or 1000 Genomes allele frequencies when the requested number of variants is in the millions or tens of millions. This functionality should be enabled and disabled by a parameter to `hl.balding_nichols_model`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6880:1606,down,down,1606,https://hail.is,https://github.com/hail-is/hail/issues/6880,1,['down'],['down']
Availability,"`hl.eval_expr(hl.literal([1,2,3])/hl.literal([1,2]))`. ```; FatalError: HailException: array index out of bounds: 2 / 2. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 36.0 failed 20 times, most recent failure: Lost task 0.19 in stage 36.0 (TID 55, exomes-w-1.c.broad-mpg-gnomad.internal, executor 3): is.hail.utils.HailException: array index out of bounds: 2 / 2; 	at is.hail.codegen.generated.C166.apply(Unknown Source); 	at is.hail.codegen.generated.C166.apply(Unknown Source); 	at is.hail.expr.TableMapRows$$anonfun$55$$anonfun$apply$29.apply(Relational.scala:1877); 	at is.hail.expr.TableMapRows$$anonfun$55$$anonfun$apply$29.apply(Relational.scala:1872); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIte",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3653:198,failure,failure,198,https://hail.is,https://github.com/hail-is/hail/issues/3653,2,['failure'],['failure']
Availability,`hl.eval_expr(ht.globals)` errors when globals is empty,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3728:27,error,errors,27,https://hail.is,https://github.com/hail-is/hail/issues/3728,1,['error'],['errors']
Availability,"`hl.literal(float('nan')).value` works as expected, the trouble arised when parsing non-numeric values inside an array, e.g. `[float('nan'), float('inf'), float('-inf')]`. ```; Error summary: JsonParseException: Non-standard token 'NaN': enable JsonParser.Feature.ALLOW_NON_NUMERIC_NUMBERS to allow; at [Source: {""__uid_3"": [NaN, Infinity, -Infinity]}; line: 1, column: 17]; ```. I'm not sure how to enable this feature:; https://github.com/FasterXML/jackson-core/wiki/JsonParser-Features. ### Hail version:; master; c908fd74abd819f4fcfbcdad88c5db6bf77083b2. ### What you did:. `hl.literal([float('nan')]).value`. ### What went wrong (all error messages here, including the full java stack trace):. hl.literal([float('nan'), float('inf'), float('-inf')]).value; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-3-ea2ec4f5df06> in <module>(); ----> 1 hl.literal([float('nan'), float('inf'), float('-inf')]).value. ~/hail/python/hail/expr/expressions/base_expression.py in value(self); 773 ; 774 """"""; --> 775 return hl.eval_expr(self); 776 ; 777 . ~/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/hail/python/hail/expr/expressions/expression_utils.py in eval_expr(expression); 135 Result of evaluating `expression`.; 136 """"""; --> 137 return eval_expr_typed(expression)[0]; 138 ; 139 . ~/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/hail/python/hail/expr/expressions/expression_utils.py in eval_expr_typed(expression); 169 analyze('eval_expr_typed', expression, Indices(expression._indices.sou",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3785:177,Error,Error,177,https://hail.is,https://github.com/hail-is/hail/issues/3785,2,"['Error', 'error']","['Error', 'error']"
Availability,"`ht = ht.join(possible_ht, 'outer')`; gave:; ```; Java stack trace:; java.lang.IllegalArgumentException: requirement failed; at scala.Predef$.require(Predef.scala:212); at is.hail.rvd.OrderedRVD.<init>(OrderedRVD.scala:37); at is.hail.rvd.KeyedOrderedRVD.orderedJoin(KeyedOrderedRVD.scala:38); at is.hail.rvd.OrderedRVD.orderedJoin(OrderedRVD.scala:283); at is.hail.expr.ir.TableJoin.execute(TableIR.scala:436); at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:652); at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:495); at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:652); at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:652); at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:495); at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:652); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:591); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:49); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:24); at is.hail.table.Table.write(Table.scala:606); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748). Hail version: devel-02b7ad0299d7; Error summary: IllegalArgumentException: requirement failed; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4216:1737,Error,Error,1737,https://hail.is,https://github.com/hail-is/hail/issues/4216,1,['Error'],['Error']
Availability,"`import_bgen` fails because there are no reference genomes on worker nodes. `import_bgen` needs to read the index file. Reading the index file means parsing a type. Parsing a locus type means looking up a reference genome. The error message comes from line 588 in `ReferenceGenome.scala` by way of line 70 of `IndexReader.scala`:; ```scala; val keyType = IRParser.parseType(metadata.keyType); ```. The root cause seems to be #5512, in which we [stop loading the genomes from resources](https://github.com/hail-is/hail/pull/5512/files#diff-16c24a9c4265932816e9e88806f5a2abL527).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5673:227,error,error,227,https://hail.is,https://github.com/hail-is/hail/issues/5673,1,['error'],['error']
Availability,`kubectl describe pod POD_NAME` will tell you there reasons the pod could not be scheduled. I often see this issue when we run out of available CPU.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5269#issuecomment-461105202:134,avail,available,134,https://hail.is,https://github.com/hail-is/hail/issues/5269#issuecomment-461105202,1,['avail'],['available']
Availability,"`large_range_matrix_table_sum()` failed in the benchmarks, looking into that. When I ran it locally, seemed to be allocating more memory than I would think, so there's probably a leak there. Otherwise, I think this is safe to review while I track this one down (and maybe you'll catch the cause of this). ```; 2020-03-26 12:41:14 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (792.0K blocks / 15.3M chunks), thread 70: Executor task launch worker for task 10; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8315#issuecomment-604542228:256,down,down,256,https://hail.is,https://github.com/hail-is/hail/pull/8315#issuecomment-604542228,1,['down'],['down']
Availability,`max-idle` and `max-age` have been available since 258 https://cloud.google.com/sdk/docs/release-notes#25800_2019-08-13; We already require >=285 https://github.com/hail-is/hail/blob/main/hail/python/hailtop/hailctl/dataproc/cli.py#L16,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10362:35,avail,available,35,https://hail.is,https://github.com/hail-is/hail/pull/10362,1,['avail'],['available']
Availability,"`monitor_billing_updates` occasionally fails due to deadlocks on this query, but as it's read-only it should be fine to retry. Changing to `select_and_fetchall` uses read-only transactions and retries those transient errors.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14337:217,error,errors,217,https://hail.is,https://github.com/hail-is/hail/pull/14337,1,['error'],['errors']
Availability,`oldwarn` is somehow `None` which spams us with instance log errors. We can revisit the warning level in a PR if this is really important. https://cloudlogging.app.goo.gl/VmUohrJSNo6EjsK56,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14243:61,error,errors,61,https://hail.is,https://github.com/hail-is/hail/pull/14243,1,['error'],['errors']
Availability,`orjson` 3.9.15 fixed the rare segfault that we saw in `3.9.11`. Besides just updating to latest patch and minor versions:. - Removed a redundant requirement of `orjson` in `gear/requirements.txt` -- it inherits `orjson` from hailtop; - Bokeh `3.4` made a breaking change w.r.t. the `circle` method on figures. I have restricted the bounds for `bokeh` to avoid this breaking change but will follow up with a PR that changes our usage of bokeh to follow the deprecation/upgrade advice and undo the bounds restriction,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14471:136,redundant,redundant,136,https://hail.is,https://github.com/hail-is/hail/pull/14471,1,['redundant'],['redundant']
Availability,"`pheno_file = p.read_input_group(**{'gz': pheno_path})` works if `pheno_path` is a string. But if it's a ResourceFile object (don't ask how I arrived at that), the pipeline still submits, but the localizing files step fails without obvious error (localizes the other files and then dies silently).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6979:240,error,error,240,https://hail.is,https://github.com/hail-is/hail/issues/6979,1,['error'],['error']
Availability,"`pip install -e .`; Defaulting to user installation because normal site-packages is not writeable; Obtaining file:///home/skr/hail2/hail; Installing build dependencies ... done; Checking if build backend supports build_editable ... done; Getting requirements to build editable ... error; error: subprocess-exited-with-error; ; Ã— Getting requirements to build editable did not run successfully.; â”‚ exit code: 1; â•°â”€> [14 lines of output]; error: Multiple top-level packages discovered in a flat-layout: ['tls', 'gear', 'hail', 'auth', 'blog', 'infra', 'batch', 'query', 'docker', 'memory', 'devbin', 'gateway', 'website', 'grafana', 'notebook', 'graphics', 'datasets', 'monitoring', 'web_common', 'prometheus', 'letsencrypt'].; ; To avoid accidental inclusion of unwanted files or directories,; setuptools will not proceed with this build.; ; If you are trying to create a single distribution with multiple packages; on purpose, you should not rely on automatic discovery.; Instead, consider the following options:; ; 1. set up custom discovery (`find` directive with `include` or `exclude`); 2. use a `src-layout`; 3. explicitly set `py_modules` or `packages` with a list of names; ; To find more information, look for ""package discovery"" on setuptools docs.; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; error: subprocess-exited-with-error. Ã— Getting requirements to build editable did not run successfully.; â”‚ exit code: 1; â•°â”€> See above for output.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12844#issuecomment-1502112290:281,error,error,281,https://hail.is,https://github.com/hail-is/hail/issues/12844#issuecomment-1502112290,7,['error'],['error']
Availability,"`read()` with no argument is `read(-1)`. Python's [`read`](https://docs.python.org/3/library/io.html#io.RawIOBase.read) and aiohttp's [`read`](https://docs.aiohttp.org/en/stable/streams.html#aiohttp.StreamReader.read) will return all bytes until EOF if their argument is `-1`. Python:; > Read up to size bytes from the object and return them. As a convenience, if size is unspecified or -1, all bytes until EOF are returned. Otherwise, only one system call is ever made. Fewer than size bytes may be returned if the operating system call returns fewer than size bytes.; > ; > If 0 bytes are returned, and size was not 0, this indicates end of file. If the object is in non-blocking mode and no bytes are available, None is returned.; >; > The default implementation defers to readall() and readinto(). Aiohttp:; > Read up to n bytes. If n is not provided, or set to -1, read until EOF and return all read bytes.; >; > If the EOF was received and the internal buffer is empty, return an empty bytes object. We should document that our `read` follows these same rules in `hailtop.aiotools.stream.ReadableStream.read`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10771#issuecomment-904688934:704,avail,available,704,https://hail.is,https://github.com/hail-is/hail/pull/10771#issuecomment-904688934,1,['avail'],['available']
Availability,`request_retry_transient_errors` is a charlatan. It does not retry errors that occur in reading the response body. I eliminated it in favor of the tried and true `retry_transient_errors` and some new helper methods that initiate the request *and* read the response.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13029:67,error,errors,67,https://hail.is,https://github.com/hail-is/hail/pull/13029,1,['error'],['errors']
Availability,"`self._run_fut` will blow up with a `ContainerDeletedError` when the container is forcibly stopped in `Container.kill`. The task running `Container.kill` wants to block on the deletion and cleanup of the container, hence the `await self._run_fut`, but it shouldn't itself be interrupted by the container deletion error. This fixes a bug where if a JVM job wanted to delete the JVM a job was running in for X reason, it wouldn't get passed `jvm.kill` and the user would see a Job deleted error stacktrace instead of useful diagnostic information.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11848:313,error,error,313,https://hail.is,https://github.com/hail-is/hail/pull/11848,2,['error'],['error']
Availability,"`test_summarize_run` is segfaulting on the CI server, but it runs fine for me locally (in fact, I can run all of `test_expr.py` with no failures). can somebody else try cloning this branch and running tests locally?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6742#issuecomment-520512516:136,failure,failures,136,https://hail.is,https://github.com/hail-is/hail/pull/6742#issuecomment-520512516,1,['failure'],['failures']
Availability,"`test_weighted_linear_regression`?. ### Version. 0.2.131-37a5ba226bae. ### Relevant log output. ```shell; ----> 1 gwas_weights = hl._linear_regression_rows_nd(y=mt.y,; 2 x=mt.GT.n_alt_alleles(),; 3 covariates=[1.0],; 4 weights=mt.weights). File <decorator-gen-1734>:2, in _linear_regression_rows_nd(y, x, covariates, block_size, weights, pass_through). File ~/hail/hail/python/hail/typecheck/check.py:585, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 582 @decorator; 583 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 584 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 585 return __original_func(*args_, **kwargs_). File ~/hail/hail/python/hail/methods/statgen.py:717, in _linear_regression_rows_nd(y, x, covariates, block_size, weights, pass_through); 714 res = res.select_globals(); 716 temp_file_name = hl.utils.new_temp_file(""_linear_regression_rows_nd"", ""result""); --> 717 res = res.checkpoint(temp_file_name); 719 return res. File <decorator-gen-1234>:2, in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). File ~/hail/hail/python/hail/typecheck/check.py:585, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 582 @decorator; 583 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 584 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 585 return __original_func(*args_, **kwargs_). File ~/hail/hail/python/hail/table.py:1963, in Table.checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1960 hl.current_backend().validate_file(output); 1962 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1963 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1964 _assert_type = self._type; 1965 _load_refs = False. File <decorator-gen-1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14594:1550,checkpoint,checkpoint,1550,https://hail.is,https://github.com/hail-is/hail/issues/14594,1,['checkpoint'],['checkpoint']
Availability,`time ../Downloads/plink_mac/plink --bfile src/test/resources/svip_3_2013 --missing`; real 0m0.383s; user 0m0.293s; sys 0m0.072s. Hail reading bed to vds -- 11s (intelliJ test). `time ../Downloads/plink_mac/plink --bgen src/test/resources/bigger.bgen --sample src/test/resources/bigger.sample --make-bed --out testplink`. real 0m9.164s; user 0m8.429s; sys 0m0.520s. Hail reading bgen to vds -- 40s (IntelliJ test),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/72#issuecomment-155571444:9,Down,Downloads,9,https://hail.is,https://github.com/hail-is/hail/pull/72#issuecomment-155571444,2,['Down'],['Downloads']
Availability,`to_json` was broken on `Failure` objects,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5229:25,Failure,Failure,25,https://hail.is,https://github.com/hail-is/hail/pull/5229,1,['Failure'],['Failure']
Availability,"`va` needs to be available inside the aggregator init operations, so needs to be bound outside the arrayagg.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5883:17,avail,available,17,https://hail.is,https://github.com/hail-is/hail/pull/5883,1,['avail'],['available']
Availability,a downloadable link to the distributions can be found here: ; https://hail.is/docs/stable/getting_started.html. The current link for Spark 2.0.2 is https://storage.googleapis.com/hail-common/distributions/0.1/Hail-0.1-4238176-Spark-2.0.2.zip,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2062#issuecomment-320243052:2,down,downloadable,2,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-320243052,1,['down'],['downloadable']
Availability,a few errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7858:6,error,errors,6,https://hail.is,https://github.com/hail-is/hail/pull/7858,1,['error'],['errors']
Availability,"a few things happening here, most of which was me trying to not have to explicitly list dependencies in the shadowJar/shadowTestJar tasks:; - upgraded gradle to 5.0 and some plugins to be compatible; - split compile dependencies into ""bundled"" and ""unbundled"" to more explicitly separate the things we want in the jars and dependencies that we don't want bundled/are currently depending on the spark installation for. I did it this way because the shadowJar `exclude` filter does not let you exclude transitive dependencies, and I just wanted to exclude the entire spark/scala dependency tree.; - there was a problem where trying to run the tests kept giving me the ""Could not find or load main class org.testng.TestNG"" error, despite the class clearly being findable from the classpath I was providing. I added some excludes per this:; https://stackoverflow.com/questions/51455197/gradle-fatjar-could-not-find-or-load-main-class; (although I believe this is no longer strictly necessary after excluding all the transitive spark dependencies)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6248:720,error,error,720,https://hail.is,https://github.com/hail-is/hail/pull/6248,1,['error'],['error']
Availability,"a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92784"">kubernetes/kubernetes#92784</a>, <a href=""https://github.com/pohly""><code>@â€‹pohly</code></a>) [SIG API Machinery, Apps, Auth, CLI, Instrumentation, Node, Scheduling, Storage and Testing]</li>; <li>Go1.14.4 is now the minimum version required for building Kubernetes (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92438"">kubernetes/kubernetes#92438</a>, <a href=""https://github.com/liggitt""><code>@â€‹liggitt</code></a>) [SIG API Machinery, Auth, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Network, Node, Release, Storage and Testing]</li>; <li>Hide managedFields from kubectl edit command (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91946"">kubernetes/kubernetes#91946</a>, <a href=""https://github.com/soltysh""><code>@â€‹soltysh</code></a>) [SIG CLI]</li>; <li>K8s.io/apimachinery - scheme.Convert() now uses only explicitly registered conversions - default reflection based conversion is no longer available. <code>+k8s:conversion-gen</code> tags can be used with the <code>k8s.io/code-generator</code> component to generate conversions. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/90018"">kubernetes/kubernetes#90018</a>, <a href=""https://github.com/wojtek-t""><code>@â€‹wojtek-t</code></a>) [SIG API Machinery, Apps and Testing]</li>; <li>Kube-proxy: add <code>--bind-address-hard-fail</code> flag to treat failure to bind to a port as fatal (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89350"">kubernetes/kubernetes#89350</a>, <a href=""https://github.com/SataQiu""><code>@â€‹SataQiu</code></a>) [SIG Cluster Lifecycle and Network]</li>; <li>Kubebuilder validation tags are set on metav1.Condition for CRD generation (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92660"">kubernetes/kubernetes#92660</a>, <a href=""https://github.com/damemi""><code>@â€‹damemi</code></",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:8796,avail,available,8796,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['avail'],['available']
Availability,"a.burden.pheno',; [13:46:55]	[:makeHailDocs] covariates=['sa.burden.cov1', 'sa.burden.cov2'])); [13:46:55]	[:makeHailDocs] Exception raised:; [13:46:55]	[:makeHailDocs] Traceback (most recent call last):; [13:46:55]	[:makeHailDocs] File ""/usr/lib64/python2.7/doctest.py"", line 1315, in __run; [13:46:55]	[:makeHailDocs] compileflags, 1) in test.globs; [13:46:55]	[:makeHailDocs] File ""<doctest default[0]>"", line 7, in <module>; [13:46:55]	[:makeHailDocs] covariates=['sa.burden.cov1', 'sa.burden.cov2'])); [13:46:55]	[:makeHailDocs] File ""<decorator-gen-233>"", line 2, in linreg_burden; [13:46:55]	[:makeHailDocs] File ""/home/ec2-user/BuildAgent/work/c38e75e72b769a7c/python/hail/java.py"", line 119, in handle_py4j; [13:46:55]	[:makeHailDocs] 'Error summary: %s' % (msg, e.message, Env.hc().version, msg)); [13:46:55]	[:makeHailDocs] FatalError: An error occurred while calling into JVM, probably due to invalid parameter types.; [13:46:55]	[:makeHailDocs] ; [13:46:55]	[:makeHailDocs] Java stack trace:; [13:46:55]	[:makeHailDocs] An error occurred while calling o3918.linregBurden. Trace:; [13:46:55]	[:makeHailDocs] py4j.Py4JException: Method linregBurden([class java.lang.String, class java.lang.String, class java.lang.String, class java.lang.String, class java.lang.String, class [Ljava.lang.String;]) does not exist; [13:46:55]	[:makeHailDocs] 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); [13:46:55]	[:makeHailDocs] 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326); [13:46:55]	[:makeHailDocs] 	at py4j.Gateway.invoke(Gateway.java:272); [13:46:55]	[:makeHailDocs] 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); [13:46:55]	[:makeHailDocs] 	at py4j.commands.CallCommand.execute(CallCommand.java:79); [13:46:55]	[:makeHailDocs] 	at py4j.GatewayConnection.run(GatewayConnection.java:214); [13:46:55]	[:makeHailDocs] 	at java.lang.Thread.run(Thread.java:745); [13:46:55]	[:makeHailDocs] ; [13:46:55]	[:makeHailDocs] ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1708#issuecomment-297039203:1692,error,error,1692,https://hail.is,https://github.com/hail-is/hail/pull/1708#issuecomment-297039203,1,['error'],['error']
Availability,a.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:50); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:462); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:498); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:63); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:350); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$1(SparkBackend.scala:495); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.backend.spark.SparkBackend.executeEncode(SparkBackend.scala:494); 	at jdk.internal.reflect.GeneratedMethodAccessor109.invoke(Unknown Source); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182); 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106); 	at java.base/java.lang.Thread.run(Thread.java:829). Hail version: 0.2.122-be9d88a80695; Error summary: ArrayIndexOutOfBoundsException: Index 177860 out of bounds for length 177860; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:11591,Error,Error,11591,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124,1,['Error'],['Error']
Availability,"a14a00fed93dc55a5e01e4eba0e3d77b0a89fc""><code>5da14a0</code></a> Add benchmark for loading empty objects</li>; <li><a href=""https://github.com/ijl/orjson/commit/12b867c7bfbd9c6404b2f2e859c134822af05e73""><code>12b867c</code></a> cargo update, nightly-2022-02-13</li>; <li><a href=""https://github.com/ijl/orjson/commit/ab633b6d0fa064b0c4b248bee8dc1062f0fe9d32""><code>ab633b6</code></a> Build x86_64 musllinux wheels (<a href=""https://github-redirect.dependabot.com/ijl/orjson/issues/242"">#242</a>)</li>; <li><a href=""https://github.com/ijl/orjson/commit/8bf078b27e7479f2cfbea1bac7155d4449ce7e30""><code>8bf078b</code></a> Cross compile wheels for armv7l on GitHub Actions (<a href=""https://github-redirect.dependabot.com/ijl/orjson/issues/241"">#241</a>)</li>; <li><a href=""https://github.com/ijl/orjson/commit/c196f0e55bd51d3693d381ccc06f2fd4b5443d86""><code>c196f0e</code></a> 3.6.6</li>; <li><a href=""https://github.com/ijl/orjson/commit/81890b097f7a479d1c1e697d21467952e0be24a9""><code>81890b0</code></a> Fix 53-bit error on value between isize and usize</li>; <li><a href=""https://github.com/ijl/orjson/commit/8fc1e8989d6a72581aa71533384cb1ef9a260ebc""><code>8fc1e89</code></a> Fast conditional for zoneinfo.ZoneInfo</li>; <li><a href=""https://github.com/ijl/orjson/commit/853ffbdf8dc5f34792765c22aa835e1b67d90a76""><code>853ffbd</code></a> fix(errors): adjust column offset if not at char boundary</li>; <li>Additional commits viewable in <a href=""https://github.com/ijl/orjson/compare/3.6.4...3.6.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=orjson&package-manager=pip&previous-version=3.6.4&new-version=3.6.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11572:3786,error,error,3786,https://hail.is,https://github.com/hail-is/hail/pull/11572,1,['error'],['error']
Availability,"a2:. https://github.com/holoviz/panel/issues/3260. This may be transient and may be solved by bokeh / jinja2 folks but thought I'd let you know in case you hit this issue. ```; ../conda/envs/glow/lib/python3.7/site-packages/bokeh/core/templates.py:43: in <module>; from jinja2 import Environment, Markup, FileSystemLoader; E ImportError: cannot import name 'Markup' from 'jinja2' (/home/circleci/conda/envs/lib/python3.7/site-packages/jinja2/__init__.py); [error] java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; [error] 	at scala.Predef$.require(Predef.scala:281); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14(build.sbt:288); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14$adapted(build.sbt:278); [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49); [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62); [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:67); [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:280); [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19); [error] 	at sbt.Execute.work(Execute.scala:289); [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:280); [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); [error] 	at java.lang.Thread.run(Thread.java:748); [error] (hail / hailtest) java.lang.IllegalArgumentException: requirement failed: Python tests in Hail en",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11705:1350,error,error,1350,https://hail.is,https://github.com/hail-is/hail/issues/11705,1,['error'],['error']
Availability,"a931de0"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""42.0.2""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6050294"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-CRYPTOGRAPHY-6126975"",""SNYK-PYTHON-CRYPTOGRAPHY-6210214"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,509,454,616,584,479,509,509,509,509,589,509,691,399,479,399,539,479,479,616,616,489,519],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. ðŸ¦‰ [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); ðŸ¦‰ [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); ðŸ¦‰ [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); ðŸ¦‰ [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14329:13446,avail,available,13446,https://hail.is,https://github.com/hail-is/hail/pull/14329,1,['avail'],['available']
Availability,a:1147); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapCols.execute(MatrixIR.scala:1364); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapCols.execute(MatrixIR.scala:1364); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixAggregateColsByKey.execute(MatrixIR.scala:839); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapRows.execute(MatrixIR.scala:1147); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixRowsTable.execute(TableIR.scala:763); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:603); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:48); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:23); at is.hail.table.Table.write(Table.scala:604); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748). Hail version: devel-cb98819b64ad; Error summary: AssertionError: assertion failed: type mismatch:; name: global; actual: +Struct{}; expect: Struct{}; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4127:3899,Error,Error,3899,https://hail.is,https://github.com/hail-is/hail/issues/4127,1,['Error'],['Error']
Availability,"a:2069); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Hail version: devel-824968e; Error summary: AssertionError: assertion failed; ```; import_vcf error:; Just stayed at 0 out of 1 complete on the cloud, looked into the processes, it had failed 9 times, and here's the message I could dig out:; ```; is.hail.utils.HailException: hapmap_3.3_hg19_pop_stratified_af.vcf.gz: caught java.lang.NegativeArraySizeException: null; offending line: chr7 71494997 rs844684 A C . PASS AC=1191;AF=0.42627;ALL={A*...; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:17); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.utils.Context.wrapException(Context.scala:23); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:767); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:911); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at is.hail.io.RichContextRDDRegionValue$$anonfun$6$$anonfun$apply$1$$anonfun$apply$2$$anonfun$apply$3$$anonfun$apply$4.apply(RowStore.scala:922); at is.hail.io.RichContextRDDRegionValue$$anonfun$6$$anonfun$apply$1$$anonfun$apply$2$$anonfun$apply$3$$anonfun$apply$4.apply(RowStore.scala:915); at is.hail.utils.package$.using(package.scala:577); at is.hail.io.RichContextRD",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3507:11977,Error,ErrorHandling,11977,https://hail.is,https://github.com/hail-is/hail/issues/3507,1,['Error'],['ErrorHandling']
Availability,"a> chore(main): release 2.17.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1854"">#1854</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/1425dd97cb7d4a58f0bbededeca543f1a89c7d5d""><code>1425dd9</code></a> fix: update BaseStorageReadChannel to be left open unless explicitly closed (...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/4491f73e1fe4baed1ace132cba9f8cc1557ffa33""><code>4491f73</code></a> chore(main): release 2.17.1-SNAPSHOT (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1849"">#1849</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/fb3ae9c172f6176a52815cc7ffc09175f23d0df8""><code>fb3ae9c</code></a> chore(main): release 2.17.0 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1804"">#1804</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/3ab745207badbd4971f2fb62ed92e1703625214a""><code>3ab7452</code></a> chore(test): increase debug logging for failure cases in GapicUnbufferedWrita...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/c8bf3c70cca81ed87a52939fe7da58889c8f55ce""><code>c8bf3c7</code></a> fix: update GrpcStorageImpl#update to support fine-grained update of BucketIn...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/3345ac9eec286ee3108c08bdbe263eba59085ad3""><code>3345ac9</code></a> test: add test to verify <code>lifecycle.rule.condition.age_days = 0</code> (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1846"">#1846</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/45dc983a4af8e7feb937263ce611bd34eda37e03""><code>45dc983</code></a> feat: update GrpcBlobReadChannel to allow seek/limit after read (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1834"">#1834</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/b8f43169a504080",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12598:14715,failure,failure,14715,https://hail.is,https://github.com/hail-is/hail/pull/12598,1,['failure'],['failure']
Availability,"a>; thread_pool, lambda: fun(*args, **kwargs)); OSError: [Errno 39] Directory not empty: '/tmp/JnQ2m'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py"", line 409, in rmtree; await rm_dir(pool, contents_tasks_by_dir.get(path, []), path); File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py"", line 387, in rm_dir; excs = [exc; File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py"", line 389, in <listcomp>; for exc in [t.exception()]; File ""/usr/lib/python3.9/asyncio/futures.py"", line 214, in exception; raise exc; asyncio.exceptions.CancelledError. [2023-08-02 05:33:14] test/hail/utils/test_hl_hadoop_and_hail_fs.py::test_hadoop_methods_3[local] ERROR; [2023-08-02 05:43:14] test/hail/utils/test_hl_hadoop_and_hail_fs.py::test_read_overwrite[remote] SKIPPED; ```; ```; ==================================== ERRORS ====================================; ______________ ERROR at teardown of test_hadoop_methods_3[local] _______________. pool = <hailtop.utils.utils.OnlineBoundedGather2 object at 0x7f263d7a6fa0>; contents_tasks = [<Task finished name='Task-63869' coro=<OnlineBoundedGather2.call.<locals>.run_and_cleanup() done, defined at /usr/loc...2.call.<locals>.run_and_cleanup() done, defined at /usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py:398>>]; path = '/tmp/JnQ2m'. async def rm_dir(pool: OnlineBoundedGather2,; contents_tasks: List[asyncio.Task],; path: str):; assert listener is not None; listener(1); if contents_tasks:; await pool.wait(contents_tasks); try:; > await self.rmdir(path). /usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py:378: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; /usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py:352: in rmdir; return await blocking_to_async(self._thread_pool, os.rmdir, path); /usr/l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13361:4710,ERROR,ERRORS,4710,https://hail.is,https://github.com/hail-is/hail/issues/13361,2,['ERROR'],"['ERROR', 'ERRORS']"
Availability,"a></li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Some text goes missing during wrapping when it contains double width characters <a href=""https://redirect.github.com/Textualize/rich/issues/3176"">Textualize/rich#3176</a></li>; <li>Ensure font is correctly inherited in exported HTML <a href=""https://redirect.github.com/Textualize/rich/issues/3104"">Textualize/rich#3104</a></li>; <li>Fixed typing for <code>FloatPrompt</code>.</li>; </ul>; <h2>[13.6.0] - 2023-09-30</h2>; <h3>Added</h3>; <ul>; <li>Added Python 3.12 to classifiers.</li>; </ul>; <h2>[13.5.3] - 2023-09-17</h2>; <h3>Fixed</h3>; <ul>; <li>Markdown table rendering issue with inline styles and links <a href=""https://redirect.github.com/Textualize/rich/issues/3115"">Textualize/rich#3115</a></li>; <li>Fix Markdown code blocks on a light background <a href=""https://redirect.github.com/Textualize/rich/issues/3123"">Textualize/rich#3123</a></li>; </ul>; <h2>[13.5.2] - 2023-08-01</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs assertion error</li>; </ul>; <h2>[13.5.1] - 2023-07-31</h2>; <h3>Fixed</h3>; <ul>; <li>Fix tilde character (<code>~</code>) not included in link regex when printing to console <a href=""https://redirect.github.com/Textualize/rich/issues/3057"">Textualize/rich#3057</a></li>; </ul>; <h2>[13.5.0] - 2023-07-29</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs not expanding spans.</li>; <li>Fixed TimeElapsedColumn from showing negative.</li>; <li>Fix for escaping strings with a trailing backslash <a href=""https://redirect.github.com/Textualize/rich/issues/2987"">Textualize/rich#2987</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Textualize/rich/commit/7f580bdcf07a3b269a0e786b6a3aa9c804f393cf""><code>7f580bd</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3293"">#3293</a> from Textualize/bump1371</li>; <li><a href=""https://github.com/Textua",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14376:3597,error,error,3597,https://hail.is,https://github.com/hail-is/hail/pull/14376,2,['error'],['error']
Availability,"a></li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Some text goes missing during wrapping when it contains double width characters <a href=""https://redirect.github.com/Textualize/rich/issues/3176"">Textualize/rich#3176</a></li>; <li>Ensure font is correctly inherited in exported HTML <a href=""https://redirect.github.com/Textualize/rich/issues/3104"">Textualize/rich#3104</a></li>; <li>Fixed typing for <code>FloatPrompt</code>.</li>; </ul>; <h2>[13.6.0] - 2023-09-30</h2>; <h3>Added</h3>; <ul>; <li>Added Python 3.12 to classifiers.</li>; </ul>; <h2>[13.5.3] - 2023-09-17</h2>; <h3>Fixed</h3>; <ul>; <li>Markdown table rendering issue with inline styles and links <a href=""https://redirect.github.com/Textualize/rich/issues/3115"">Textualize/rich#3115</a></li>; <li>Fix Markdown code blocks on a light background <a href=""https://redirect.github.com/Textualize/rich/issues/3123"">Textualize/rich#3123</a></li>; </ul>; <h2>[13.5.2] - 2023-08-01</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs assertion error</li>; </ul>; <h2>[13.5.1] - 2023-07-31</h2>; <h3>Fixed</h3>; <ul>; <li>Fix tilde character (<code>~</code>) not included in link regex when printing to console <a href=""https://redirect.github.com/Textualize/rich/issues/3057"">Textualize/rich#3057</a></li>; </ul>; <h2>[13.5.0] - 2023-07-29</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs not expanding spans.</li>; <li>Fixed TimeElapsedColumn from showing negative.</li>; <li>Fix for escaping strings with a trailing backslash <a href=""https://redirect.github.com/Textualize/rich/issues/2987"">Textualize/rich#2987</a></li>; <li>Fixed exception in Markdown with partial table <a href=""https://redirect.github.com/Textualize/rich/issues/3053"">Textualize/rich#3053</a></li>; <li>Fixed the HTML export template so that the <code>&lt;html&gt;</code> tag comes before the <code>&lt;head&gt;</code> tag <a href=""https://redirect.github.com/Textualize/rich/issues/3021"">Textualize/rich#3021</a></li>; <li>Fixed issue with custom classes overwriting",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14012:3624,error,error,3624,https://hail.is,https://github.com/hail-is/hail/pull/14012,2,['error'],['error']
Availability,"ability: float64, h2_liability_se: float64, h2_z: float64, h2_observed: float64, h2_observed_se: float64, intercept: float64, intercept_se: float64, ratio: float64, ratio_se: float64}, sldsc_25bin: struct{h2_liability: float64, h2_liability_se: float64, h2_z: float64, h2_observed: float64, h2_observed_se: float64, intercept: float64, intercept_se: float64, ratio: float64, ratio_se: float64}, rhemc_25bin: struct{h2_liability: float64, h2_liability_se: float64, h2_z: float64, h2_observed: float64, h2_observed_se: float64}, rhemc_8bin: struct{h2_liability: float64, h2_liability_se: float64, h2_observed: float64, h2_observed_se: float64, h2_z: float64}, rhemc_25bin_50rv: struct{h2_observed: float64, h2_observed_se: float64, h2_liability: float64, h2_liability_se: float64, h2_z: float64}, final: struct{h2_observed: float64, h2_observed_se: float64, h2_liability: float64, h2_liability_se: float64, h2_z: float64}}, qcflags: struct{GWAS_run: bool, defined_h2: bool, significant_z: bool, in_bounds_h2: bool, normal_lambda: bool, normal_ratio: bool, EUR_plus_1: bool, pass_all: bool}, N_ancestry_QC_pass: int32}, saige_version: str, inv_normalized: bool, pop: str, lambda_gc: float64, n_variants: int64, n_sig_variants: int64, saige_heritability: float64}))}; at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:15); at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:15); at is.hail.utils.package$.fatal(package.scala:78); at is.hail.expr.ir.PruneDeadFields$.isSupertype(PruneDeadFields.scala:75); at is.hail.rvd.RVDCoercer.coerce(RVD.scala:31); at is.hail.rvd.RVD$.coerce(RVD.scala:1262); at is.hail.rvd.RVD.changeKey(RVD.scala:143); at is.hail.rvd.RVD.changeKey(RVD.scala:136); [...]; java.util.NoSuchElementException: key not found: 0; at scala.collection.immutable.Map$Map1.apply(Map.scala:114); at is.hail.expr.ir.PruneDeadFields$.$anonfun$isSupertype$2(PruneDeadFields.scala:62); at is.hail.expr.ir.PruneDeadFields$.$anonfun$isSupertype$2$adapted(PruneDeadFields.scala:61); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10858:3483,Error,ErrorHandling,3483,https://hail.is,https://github.com/hail-is/hail/issues/10858,4,['Error'],['ErrorHandling']
Availability,able.executeWithValue(Promise.scala:40); at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248); at scala.concurrent.Promise$class.complete(Promise.scala:55); at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293); at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136); at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40); at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248); at scala.concurrent.Promise$class.complete(Promise.scala:55); at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153); at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326); at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293); at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136); at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40); at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248); at scala.concurrent.Promise$class.complete(Promise.scala:55); at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.processBatch$1(BatchingExecutor.scala:63); at scala.concurren,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:217388,recover,recover,217388,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['recover'],['recover']
Availability,"abot.com/grpc/grpc/issues/30655"">#30655</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/d0f491285f74f8b07dec7f1c745a6636f3a691de""><code>d0f4912</code></a> Bump version to 1.48.1-pre1 (on v1.48.x branch) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30627"">#30627</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/a8065cb662ca35f2b57efd636b1ac193d327ed74""><code>a8065cb</code></a> Backport EventEngine Forkables (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30605"">#30605</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/796a8ddcfe629c1ef7beae117efce2004886ecd9""><code>796a8dd</code></a> xDS interop: add missing image tagging to the buildscripts (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30520"">#30520</a>) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30529"">#30529</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/0d20b3fac16f901bd19f116b71cfec538bb57160""><code>0d20b3f</code></a> subchannel list: fix ubsan error (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30393"">#30393</a>) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30412"">#30412</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/9479089ac8cb99e66a71eab687b06ce220a94838""><code>9479089</code></a> xds interop: choose correct cluster in grpc_xds_k8s_lb_python.sh (1.48.x back...</li>; <li><a href=""https://github.com/grpc/grpc/commit/d2054ec6c6e8abcecf0e24b0b4ee75035d80c3cc""><code>d2054ec</code></a> Bump version to 1.48.0 (on v1.48.x branch) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30326"">#30326</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/4c51abf12053e3c43a62059c693322ea992b35ce""><code>4c51abf</code></a> Bump version to 1.48.0-pre1 (on v1.48.x branch) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30194"">#30194</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/46bd0be2c99aa8228ec5d93d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12201:4826,error,error,4826,https://hail.is,https://github.com/hail-is/hail/pull/12201,1,['error'],['error']
Availability,ach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:25); 	at is.hail.expr.ir.ExtractIntervalFilters$.apply(ExtractIntervalFilters.scala:254); 	at is.hail.expr.ir.Optimize$.optimize(Optimize.scala:19); 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:49); 	at is.hail.expr.ir.CompileAndEvaluate$$anonfun$optimizeIR$1$1.apply(CompileAndEvaluate.scala:20); 	at is.hail.expr.ir.CompileAndEvaluate$$anonfun$optimizeIR$1$1.apply(CompileAndEvaluate.scala:20); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:20); 	at is.hail.expr.ir.CompileAndEvaluate$.optimizeIR$1(CompileAndEvaluate.scala:20); 	at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:24); 	at is.hail.backend.Backend.execute(Backend.scala:86); 	at is.hail.backend.Backend.executeJSON(Backend.scala:92); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.16-e95038bbed35; Error summary: MatchError: locus<GRCh37> (of class is.hail.expr.types.virtual.TLocus); ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6458:6757,Error,Error,6757,https://hail.is,https://github.com/hail-is/hail/issues/6458,1,['Error'],['Error']
Availability,"ache.spark.SparkException: Job aborted due to stage failure: Task 56 in stage 4.0 failed 20 times, most recent failure: Lost task 56.19 in stage 4.0 (TID 48622) (jsealock-schema-sw-43bq.c.daly-neale-sczmeta.internal executor 3): is.hail.utils.HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 125; VEP Error output:; docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.; See 'docker run --help'. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.methods.VEP$.waitFor(VEP.scala:73); 	at is.hail.methods.VEP.$anonfun$execute$5(VEP.scala:231); 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.utils.richUtils.RichContextRDD$$anon$1.hasNext(RichContextRDD.scala:69); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator.foreach(Iterator.scala:943); 	at scala.collection.Iterator.foreach$(Iterator.scala:943); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431); 	at is.hail.io.RichContextRDDRegionValue$.writeRowsPar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936:1216,Error,ErrorHandling,1216,https://hail.is,https://github.com/hail-is/hail/issues/12936,1,['Error'],['ErrorHandling']
Availability,"ache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:723); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:723); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onError(DAGScheduler.scala:1741); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:52); 2019-01-22 13:12:06 AbstractConnector: INFO: Stopped Spark@1433e9ec{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-01-22 13:12:06 SparkUI: INFO: Stopped Spark web UI at http://10.48.225.55:4040; 2019-01-22 13:12:06 DAGScheduler: INFO: Job 0 failed: fold at RVD.scala:603, took 14.445174 s; 2019-01-22 13:12:06 DAGScheduler: INFO: ResultStage 0 (fold at RVD.scala:603) failed in 14.237 s due to Stage cancelled because SparkContext was shut down; 2019-01-22 13:12:06 root: ERROR: SparkException: Job 0 cancelled because SparkContext was shut down; From org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down; at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:820); at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:818); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:818); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1750); at org.apache.spark.util.EventLoop.stop(EventLoop.scala:83); at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1669); at org.apache.spark.SparkContext$$anonfun$stop$8.apply$mcV$sp(SparkContext.scala:1928); at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317); at org.apache.spark.SparkContext.stop(SparkContext.scala:1927); at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:1872); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:6",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:206577,down,down,206577,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['down'],['down']
Availability,ache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:204); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1$$anonfun$3.apply(FileFormatWriter.scala:129); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1$$anonfun$3.apply(FileFormatWriter.scala:128); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Caused by: is.hail.utils.HailException: Hail only supports diploid genotypes. Found min ploidy equals `1' and max ploidy equals `2'.; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:27); at is.hail.io.bgen.BgenRecordV12.getValue(BgenRecord.scala:203); at is.hail.io.bgen.BgenLoader$$anonfun$10$$anonfun$apply$5.apply(BgenLoader.scala:76); at is.hail.io.bgen.BgenLoader$$anonfun$10$$anonfun$apply$5.apply(BgenLoader.scala:75); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); at scala.collection.Iterator$$anon$1.next(Iterator.scala:1010); at is.hail.sparkextras.OrderedRDD$$anon$3.next(OrderedRDD.scala:241); at is.hail.sparkextras.OrderedRDD$$anon$3.next(OrderedRDD.scala:234); at is.hail.sparkextras.OrderedRDD$$anonfun$apply$8$$anon$2.next(OrderedRDD.scala:202); at is.hail.sparkextras.OrderedRDD$$anonfun$apply$8$$anon$2.next(OrderedRDD.scala:195); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scal,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2407:5335,Error,ErrorHandling,5335,https://hail.is,https://github.com/hail-is/hail/issues/2407,1,['Error'],['ErrorHandling']
Availability,"action$$anonfun$extract$6.apply(Extraction.scala:392); 	at org.json4s.Extraction$.customOrElse(Extraction.scala:606); 	at org.json4s.Extraction$.extract(Extraction.scala:392); 	at org.json4s.Extraction$.extract(Extraction.scala:39); 	at org.json4s.ExtractableJsonAstNode.extract(ExtractableJsonAstNode.scala:21); 	at org.json4s.jackson.Serialization$.read(Serialization.scala:50); 	at org.json4s.Serialization$class.read(Serialization.scala:30); 	at org.json4s.jackson.Serialization$.read(Serialization.scala:17); 	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1117); 	at is.hail.expr.ir.IRParser$.matrix_ir(Parser.scala:1053); 	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$2.apply(Parser.scala:1269); 	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$2.apply(Parser.scala:1269); 	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1253); 	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1269); 	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1268); 	at is.hail.expr.ir.IRParser.parse_matrix_ir(Parser.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:483); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.2.14-8dcb6722c72a; Error summary: MatchError: 17 (of class java.lang.Integer); ```. Any ideas on what is causing this? It seems like something in Spark itself, but I can't trace it down. I'm running Apache Spark version 2.4.1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6299:18709,Error,Error,18709,https://hail.is,https://github.com/hail-is/hail/issues/6299,2,"['Error', 'down']","['Error', 'down']"
Availability,"actually that error isn't even so bad, it says ""drop"" in it. I'm closing this! âš”ï¸",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3673#issuecomment-392915045:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/issues/3673#issuecomment-392915045,1,['error'],['error']
Availability,actually will reopen when the downsample PR goes in,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7131#issuecomment-539046228:30,down,downsample,30,https://hail.is,https://github.com/hail-is/hail/pull/7131#issuecomment-539046228,1,['down'],['downsample']
Availability,"actually, given the error output, it looks like `apply` isn't converting to `fApply` at all -- we wouldn't see this error if it were converting correctly",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/147#issuecomment-172043157:20,error,error,20,https://hail.is,https://github.com/hail-is/hail/issues/147#issuecomment-172043157,2,['error'],['error']
Availability,"ad-task/commit/0fdebf3c7ad43ed4739d0400c333a72b32f5d514""><code>0fdebf3</code></a> Improve verify example</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/019089b9554692674d6baee7df7d4d884f310cc9""><code>019089b</code></a> Correctly create list of output files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/fa2739ded05333ba46d8f50bb3b2a3721cf0ca86""><code>fa2739d</code></a> Create target directories at a central place</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/02b8e1a79d9e00acd61f9ac42e5555619fe2247a""><code>02b8e1a</code></a> Prevent duplicate destination files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0b65ca2f17c8890a3ec34cf80cde52ee5413cbec""><code>0b65ca2</code></a> Call eachFile action only once per source</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/717877121299cea8f216d3a595eaa56731a6acd3""><code>7178771</code></a> Support changing a target file's relative path in an eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e5af1bd7f9daa8a9222aee0dd1b703727cb5e94e""><code>e5af1bd</code></a> Bump version number to 5.3.0-SNAPSHOT</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/3.2.0...5.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=3.2.0&new-version=5.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:4678,down,download-task,4678,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['down'],['download-task']
Availability,"ad_namespaced_pod_log_with_http_info; collection_formats=collection_formats); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 334, in call_api; _return_http_data_only, collection_formats, _preload_content, _request_timeout); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 168, in __call_api; _request_timeout=_request_timeout); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 355, in request; headers=headers); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/rest.py"", line 231, in GET; query_params=query_params); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/rest.py"", line 222, in request; raise ApiException(http_resp=r); {""levelname"": ""INFO"", ""asctime"": ""2019-07-02 13:36:45,525"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""mark_complete:542"", ""message"": ""no logs for batch-278-job-6858-5879db due to previous error, rescheduling pod Error: (404)\nReason: Not Found\nHTTP response headers: HTTPHeaderDict({'Audit-Id': '891f2153-6a94-42ff-8fe1-edf644051234', 'Content-Type': 'application/json', 'Date': 'Tue, 02 Jul 2019 13:36:45 GMT', 'Content-Length': '218'})\nHTTP response body: {\""kind\"":\""Status\"",\""apiVersion\"":\""v1\"",\""metadata\"":{},\""status\"":\""Failure\"",\""message\"":\""pods \\\""batch-278-job-6858-5879db\\\"" not found\"",\""reason\"":\""NotFound\"",\""details\"":{\""name\"":\""batch-278-job-6858-5879db\"",\""kind\"":\""pods\""},\""code\"":404}\n\n""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-02 13:36:45,541"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""set_state:457"", ""message"": ""job (278, 6858, 'main') changed state: Running -> Ready""}; ```. Here are events that don't contain the string ""Successfully assigned batch-pods"": [events.log](https://github.com/hail-is/hail/files/3350320/events.log). There's a lot of issue with secrets getting mounted and a couple container creation failures, but nothing that obviously suggests a problem with reading logs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6545:2192,error,error,2192,https://hail.is,https://github.com/hail-is/hail/issues/6545,4,"['Error', 'Failure', 'error', 'failure']","['Error', 'Failure', 'error', 'failures']"
Availability,add triangle and downcode to docs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3025:17,down,downcode,17,https://hail.is,https://github.com/hail-is/hail/pull/3025,1,['down'],['downcode']
Availability,add useful error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/788:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/pull/788,1,['error'],['error']
Availability,"added `curlylint` to lint jinja templates in `check` targets and fixed existing errors that it found. Also standardized on two-space indentation and a more consistent style of indenting jinja templates: everything inside an html div is indented two spaces, no exceptions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10172:80,error,errors,80,https://hail.is,https://github.com/hail-is/hail/pull/10172,1,['error'],['errors']
Availability,added cmake download to python docs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1241:12,down,download,12,https://hail.is,https://github.com/hail-is/hail/pull/1241,1,['down'],['download']
Availability,"added some logic to allow `CallCC` code to be emitted more than once in the same function (see `testDuplicateCallCC`, which used to cause bytecode verification errors).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7055#issuecomment-531960975:160,error,errors,160,https://hail.is,https://github.com/hail-is/hail/pull/7055#issuecomment-531960975,1,['error'],['errors']
Availability,adding _read_if_exists to checkpoint,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5636:26,checkpoint,checkpoint,26,https://hail.is,https://github.com/hail-is/hail/pull/5636,1,['checkpoint'],['checkpoint']
Availability,addresses poor error message in https://github.com/hail-is/hail/issues/4033,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4036#issuecomment-408955855:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/4036#issuecomment-408955855,1,['error'],['error']
Availability,"adings"", version='2.1', reference_genome='GRCh38'). File ~/.local/lib/python3.8/site-packages/hail/experimental/datasets.py:115, in load_dataset(name, version, reference_genome, region, cloud); 107 raise ValueError(f'Region {repr(region)} not available for dataset'; 108 f' {repr(name)} on cloud platform {repr(cloud)}.\n'; 109 f'Available regions: {regions}.'); 111 path = [dataset['url'][cloud][region]; 112 for dataset in datasets[name]['versions']; 113 if all([dataset['version'] == version,; 114 dataset['reference_genome'] == reference_genome])]; --> 115 assert len(path) == 1; 116 path = path[0]; 117 if path.startswith('s3://'):. AssertionError: ; ```. I'm a new Hail user and don't have the full context here, but it seems like there are at least three problems:. 1. An assert failed in production code, which indicates either the presence of a bug or an incorrect use of assert (e.g. using assert to check for value errors).; 2. The assert has no corresponding error message, so the user learns that something has gone wrong but can't easily tell what.; 3. The assert is bare. Bare asserts can get optimized out of code in ways that are difficult to foresee in advance, and are generally deprecated in favor of the `if error_condition: raise AssertionError(...)` pattern (see: https://discuss.python.org/t/stop-ignoring-asserts-when-running-in-optimized-mode/13132). **The Big Picture**. The bare assert pattern is used over 3k times in Hail. To be fair, many of these usages occur in test directories, where they're fine. But they also occur in application code, and often in the dangerous form `assert(expr1, expr2)` which will never fail (because a tuple with two falsy elements is truthy in python). These asserts are never actually getting checked. . Fixing all of them would be a heavy lift. One compromise solution might be to add a bare assert rule to the linter (e.g. https://pypi.org/project/flake8-assert-msg/). This would prevent the introduction of further bare asserts to the ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12952:1302,error,error,1302,https://hail.is,https://github.com/hail-is/hail/issues/12952,1,['error'],['error']
Availability,"adius': 1e7, 'overwrite': True }). with hl.TemporaryDirectory(ensure_exists=True) as tmp:; mt = hl.balding_nichols_model(3, 100, 100); bm_ldadj = hl.linalg.BlockMatrix.random(100, 100). starts_and_stops = hl.linalg.utils.locus_windows(mt.locus, radius=args.radius, _localize=False); bm_ldadj = bm_ldadj._sparsify_row_intervals_expr(starts_and_stops, blocks_only=False). # sparcify to a triangle matrix; bm_ldadj = bm_ldadj.sparsify_triangle(); bm_ldadj = bm_ldadj.checkpoint(f'{tmp}/ldadj', overwrite=args.overwrite, force_row_major=True). # This is required, as the squaring/multiplication densifies, so this re-sparsifies.; ht = hl.utils.genomic_range_table(100); n = 100. r2 = bm_ldadj ** 2; r2_adj = ((n - 1.0) / (n - 2.0)) * r2 - (1.0 / (n - 2.0)); starts_and_stops = hl.linalg.utils.locus_windows(ht.locus, args.radius, _localize=False); r2_adj = r2_adj._sparsify_row_intervals_expr(starts_and_stops, blocks_only=False); r2_adj = r2_adj.sparsify_triangle(); r2_adj = r2_adj.checkpoint(f'{tmp}/adj', overwrite=args.overwrite). if __name__ == '__main__':; main(); ```. ### Version. 0.2.128. ### Relevant log output. ```shell; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.128-17247d8990c6; LOGGING: writing to /home/edmund/.local/src/hail/hail-20240508-1553-0.2.128-17247d8990c6.log; Traceback (most recent call last):; File ""/home/edmund/.local/share/pyenv/versions/3.9.18/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.local/share/pyenv/versions/3.9.18/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/__main__.py"", line 39, in <module>; cli.main(); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14537:1169,checkpoint,checkpoint,1169,https://hail.is,https://github.com/hail-is/hail/issues/14537,1,['checkpoint'],['checkpoint']
Availability,"after a few more minutes of thought, a warning is probably not sufficient here. We have to assume that losing parallelism means that the computation will never finish. There aren't really any good options:. - error; - unkey the cols too; - shuffle",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4646#issuecomment-433472683:209,error,error,209,https://hail.is,https://github.com/hail-is/hail/issues/4646#issuecomment-433472683,1,['error'],['error']
Availability,"ages can be buffered in memory. The default is to write both to stdout without buffering, as before. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104873"">kubernetes/kubernetes#104873</a>, <a href=""https://github.com/pohly""><code>@â€‹pohly</code></a>)</li>; <li>JobTrackingWithFinalizers graduates to beta. Feature is enabled by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105687"">kubernetes/kubernetes#105687</a>, <a href=""https://github.com/alculquicondor""><code>@â€‹alculquicondor</code></a>)</li>; <li>Kube-apiserver: Fixes handling of CRD schemas containing literal null values in enums. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104969"">kubernetes/kubernetes#104969</a>, <a href=""https://github.com/liggitt""><code>@â€‹liggitt</code></a>)</li>; <li>Kube-apiserver: The <code>rbac.authorization.k8s.io/v1alpha1</code> API version is removed; use the <code>rbac.authorization.k8s.io/v1</code> API, available since v1.8. The <code>scheduling.k8s.io/v1alpha1</code> API version is removed; use the <code>scheduling.k8s.io/v1</code> API, available since v1.14. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104248"">kubernetes/kubernetes#104248</a>, <a href=""https://github.com/liggitt""><code>@â€‹liggitt</code></a>)</li>; <li>Kube-scheduler: support for configuration file version <code>v1beta1</code> is removed. Update configuration files to v1beta2(xref: <a href=""https://github-redirect.dependabot.com/kubernetes/enhancements/issues/2901"">kubernetes/enhancements#2901</a>) or v1beta3 before upgrading to 1.23. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104782"">kubernetes/kubernetes#104782</a>, <a href=""https://github.com/kerthcet""><code>@â€‹kerthcet</code></a>)</li>; <li>KubeSchedulerConfiguration provides a new field <code>MultiPoint</code> which will register a plugin for all valid extension points (<a href=""https://github-redirect",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:8002,avail,available,8002,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['avail'],['available']
Availability,"ages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:7836,error,error,7836,https://hail.is,https://github.com/hail-is/hail/issues/9939,1,['error'],['error']
Availability,"ah, good point. yes, it caused an error on range_matrix_table(1, 1). _force_count_rows()",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3387#issuecomment-381986471:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/3387#issuecomment-381986471,1,['error'],['error']
Availability,"ail version devel-17a988f2a628; 2018-10-09 15:04:33 SharedState: INFO: loading hive config file: file:/Users/michafla/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml; 2018-10-09 15:04:33 SharedState: INFO: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/').; 2018-10-09 15:04:33 SharedState: INFO: Warehouse path is 'file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/'.; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@16ba3696{/SQL,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2780d0b8{/SQL/json,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@7cea1161{/SQL/execution,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@696b1f0{/SQL/execution/json,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@14d32b0c{/static/sql,null,AVAILABLE,@Spark}; 2018-10-09 15:04:34 StateStoreCoordinatorRef: INFO: Registered StateStoreCoordinator endpoint; 2018-10-09 15:04:34 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 15:04:34 SparkSqlParser: INFO: Parsing command: SHOW TABLES; 2018-10-09 15:04:36 SparkContext: INFO: Starting job: collect at utils.scala:44; 2018-10-09 15:04:36 DAGScheduler: INFO: Got job 0 (collect at utils.scala:44) with 1 output partitions; 2018-10-09 15:04:36 DAGScheduler: INFO: Final stage: ResultStage 0 (collect at utils.scala:44); 2018-10-09 15:04:36 DAGScheduler: INFO: Parents of final stage: List(); 2018-10-09 15:04:36 DAGScheduler: INFO: Missing parents: List(); 2018-10-09 15:04:36 DAGScheduler: INFO: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents; 2018-10-09 15:0",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:14518,AVAIL,AVAILABLE,14518,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['AVAIL'],['AVAILABLE']
Availability,"ail.expr.ir.IRParser', 'parse_value_ir'), kwargs = {}; pyspark = <module 'pyspark' from '/miniconda3/lib/python3.7/site-packages/pyspark/__init__.py'>, s = 'java.lang.RuntimeException: typ: inference failure: \n(MakeArray Array[Int32])'; tpl = JavaObject id=o1962, deepest = 'NoSuchElementException: next on empty iterator'; full = 'java.lang.RuntimeException: typ: inference failure: \n(MakeArray Array[Int32])\n\tat is.hail.expr.ir.IR$class.typ(IR....a:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\n\n'. def deco(*args, **kwargs):; import pyspark; try:; return f(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; s = e.java_exception.toString(); ; # py4j catches NoSuchElementExceptions to stop array iteration; if s.startswith('java.util.NoSuchElementException'):; raise; ; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full = tpl._1(), tpl._2(); raise FatalError('%s\n\nJava stack trace:\n%s\n'; 'Hail version: %s\n'; > 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; E hail.utils.java.FatalError: NoSuchElementException: next on empty iterator; E ; E Java stack trace:; E java.lang.RuntimeException: typ: inference failure: ; E (MakeArray Array[Int32]); E 	at is.hail.expr.ir.IR$class.typ(IR.scala:34); E 	at is.hail.expr.ir.MakeArray.typ(IR.scala:135); E 	at is.hail.expr.ir.IRParser$.ir_value_expr_1(Parser.scala:889); E 	at is.hail.expr.ir.IRParser$.ir_value_expr(Parser.scala:680); E 	at is.hail.expr.ir.IRParser$$anonfun$ir_value_children$1.apply(Parser.scala:676); E 	at is.hail.expr.ir.IRParser$$anonfun$ir_value_children$1.apply(Parser.scala:676); E 	at is.hail.expr.ir.IRParser$.repUntil(Parser.scala:301); E 	at is.hail.expr.ir.IRParser$.ir_value_children(Parser.scala:676); E 	at is.hail.expr.ir.IRParser$.ir_value_expr_1(Parser.scala:1084); E 	at is.hail.expr.ir.IRParser$.ir_value_expr(Parser.scala:680); E 	at is.hail.expr.ir.IRParser$$anonfun$parse_value_ir",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7969#issuecomment-579035930:3466,Error,Error,3466,https://hail.is,https://github.com/hail-is/hail/pull/7969#issuecomment-579035930,1,['Error'],['Error']
Availability,"ail.expr.ir.Infer$.apply(Infer.scala:59); 	at is.hail.expr.ir.InferIR$class.typ(IR.scala:58); 	at is.hail.expr.ir.InsertFields.typ(IR.scala:154); 	at is.hail.expr.ir.MatrixMapEntries.<init>(MatrixIR.scala:1075); 	at is.hail.variant.MatrixTable.selectEntries(MatrixTable.scala:641); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-0eb009391fd5; Error summary: AssertionError: assertion failed: mismatch:; array<int32>; array<int32>; ApplyComparisonOp(GT(int32,int32),GetField(ArrayRef(GetField(Ref(va,struct{locus: locus<GRCh37>, alleles: array<str>, rsid: str, qual: float64, filters: set<str>, info: struct{NEGATIVE_TRAIN_SITE: bool, HWP: float64, AC: array<int32>, culprit: str, MQ0: int32, ReadPosRankSum: float64, AN: int32, InbreedingCoeff: float64, AF: array<float64>, GQ_STDDEV: float64, FS: float64, DP: int32, GQ_MEAN: float64, POSITIVE_TRAIN_SITE: bool, VQSLOD: float64, ClippingRankSum: float64, BaseQRankSum: float64, MLEAF: array<float64>, MLEAC: array<int32>, MQ: float64, QD: float64, END: int32, DB: bool, HaplotypeScore: float64, MQRankSum: float64, CCC: int32, NCC: int32, DS: bool}, `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`: array<struct{GT: call, AD: array<int32>, DP: int32, GQ: int32, PL: array<int32>}>}),the entries! [877f12a8827e18f61222c6c8c5fb04a8]),Ref(i,int32)),DP),I32(20)); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4134:5067,Error,Error,5067,https://hail.is,https://github.com/hail-is/hail/issues/4134,1,['Error'],['Error']
Availability,"ail/hail-devel-0c961806173f.zip/hail/methods/qc.py in vep(dataset, config, block_size, name, csq); 545; 546 require_row_key_variant(dataset, 'vep'); --> 547 return MatrixTable(Env.hail().methods.VEP.apply(dataset._jvds, config, 'va.`{}`'.format(name), csq, block_size)); 548; 549. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-0c961806173f.zip/hail/utils/java.py in deco(*args, **kwargs); 236 # this is a hack to suppress the original error's stack trace; 237 if _exception:; --> 238 raise _exception; 239; 240 return deco. FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.variant.MatrixTable.orderedRVDLeftJoinDistinctAndInsert(MatrixTable.scala:982); 	at is.hail.methods.VEP$.annotate(VEP.scala:429); 	at is.hail.methods.VEP$.apply(VEP.scala:434); 	at is.hail.methods.VEP.apply(VEP.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-2c596b7; Error summary: AssertionError: assertion failed; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3099:3916,Error,Error,3916,https://hail.is,https://github.com/hail-is/hail/issues/3099,1,['Error'],['Error']
Availability,"ail/linalg/blockmatrix.py"", line 698, in write_from_entry_expr; mt.select_entries(**{field: entry_expr})._write_block_matrix(path, overwrite, field, block_size); File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/matrixtable.py"", line 4112, in _write_block_matrix; 'blockSize': block_size})); File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/backend/spark_backend.py"", line 296, in execute; result = json.loads(self._jhc.backend().executeJSON(jir)); File ""/share/pkg.7/spark/2.4.3/install/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/backend/spark_backend.py"", line 41, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: FileNotFoundException: /scratch/.writeBlocksRDD-l5om7fTy3akZKCYbLDY4AD.crc (Too many open files). Java stack trace:; java.lang.RuntimeException: error while applying lowering 'InterpretNonCompilable'; at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:26); at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:28); at is.hail.backend.spark.SparkBackend.is$hail$backend$spark$SparkBackend$$_execute(SparkBackend.scala:317); at is.hail.backend.spark.SparkBackend$$anonfun$execute$1.apply(SparkBackend.scala:304); at is.hail.backend.spark.SparkBackend$$anonfun$execute$1.apply(SparkBackend.scala:303); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:20); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:18); at is.hai",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403:7410,error,error,7410,https://hail.is,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403,1,['error'],['error']
Availability,"ailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:4174,echo,echo,4174,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,1,['echo'],['echo']
Availability,"aio-libs/aiohttp/issues/7374"">#7374</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/01d9b70e5477cd746561b52225992d8a2ebde953""><code>01d9b70</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7370"">#7370</a>/22c264ce backport][3.8] fix: Spelling error fixed (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7371"">#7371</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/3577b1e3719d4648fa973dbdec927f78f9df34dd""><code>3577b1e</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7359"">#7359</a>/7911f1e9 backport][3.8] ï£” Set up secretless publishing to PyPI (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7360"">#7360</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/8d45f9c99511cd80140d6658bd9c11002c697f1c""><code>8d45f9c</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7333"">#7333</a>/3a54d378 backport][3.8] Fix TLS transport is <code>None</code> error (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7357"">#7357</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/dd8e24e77351df9c0f029be49d3c6d7862706e79""><code>dd8e24e</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7343"">#7343</a>/18057581 backport][3.8] Mention encoding in <code>yarl.URL</code> (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7355"">#7355</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/40874103ebfaa1007d47c25ecc4288af873a07cf""><code>4087410</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7346"">#7346</a>/346fd202 backport][3.8] ï£” Bump vendored llhttp to v8.1.1 (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7352"">#7352</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.8.4...v3.8.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://depend",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13270:5348,error,error,5348,https://hail.is,https://github.com/hail-is/hail/pull/13270,5,['error'],['error']
Availability,"aio-libs/aioredis-py/releases"">aioredis's releases</a>.</em></p>; <blockquote>; <h2>v2.0.1</h2>; <p>Version v2.0.1</p>; <h2>Features</h2>; <ul>; <li>Added Python 3.10 to CI &amp; Updated the Docs (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1160"">#1160</a>)</li>; <li>Enable mypy in CI (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1101"">#1101</a>)</li>; <li>Synchronized reading the responses from a connection (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1106"">#1106</a>)</li>; </ul>; <h2>Fixes</h2>; <ul>; <li>Remove del from Redis (Fixes <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1115"">#1115</a>) (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1227"">#1227</a>)</li>; <li>fix socket.error raises (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1129"">#1129</a>)</li>; <li>Fix buffer is closed error when using PythonParser class (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1213"">#1213</a>)</li>; </ul>; <h2>Version v2.0.0</h2>; <p>Version 2.0 is a complete rewrite of aioredis. Starting with this version, aioredis now follows the API of <a href=""https://github.com/andymccurdy/redis-py"">redis-py</a>, so you can easily adapt synchronous code that uses redis-py for async applications with aioredis-py.</p>; <p><strong>NOTE:</strong> This version is <em>not</em> compatible with earlier versions of aioredis. If you upgrade, you will need to make code changes.</p>; <p>For more details, read our <a href=""https://aioredis.readthedocs.io/en/latest/migration/"">documentation on migrating to version 2.0</a>.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aioredis-py/blob/master/CHANGELOG.md"">aioredis's changelog</a>.</em></p>; <blockquote>; <h2>2.0.1 - (2021-12-20)</h2>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11569:1176,error,error,1176,https://hail.is,https://github.com/hail-is/hail/pull/11569,1,['error'],['error']
Availability,"aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3M2M5M2ZlNi0yOWM3LTQ4MWMtYTBiYy1lMzFkYzc3N2Q",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14041:1544,avail,available,1544,https://hail.is,https://github.com/hail-is/hail/pull/14041,1,['avail'],['available']
Availability,"aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4ZmFmZmYwNi1jOTI2LTQ5NjEtOTI4MC1iNGI0OTczNTg",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14038:1552,avail,available,1552,https://hail.is,https://github.com/hail-is/hail/pull/14038,1,['avail'],['available']
Availability,"al support of <code>Kernel32Util.formatMessage</code> - <a href=""https://github.com/overpathz""><code>@â€‹overpathz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1490"">#1490</a>: Adds support for a custom <code>SymbolProvider</code> in <code>NativeLibrary</code> &amp; <code>Library</code> - <a href=""https://github.com/soywiz""><code>@â€‹soywiz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1491"">#1491</a>: Update libffi to v3.4.4 - <a href=""https://github.com/matthiasblaesing""><code>@â€‹matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1487"">#1487</a>: Add 'uses' information to OSGI metadata in MANIFEST.MF to improve stability of package resolution - <a href=""https://github.com/sratz""><code>@â€‹sratz</code></a>.</li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1452"">#1452</a>: Fix memory allocation/handling for error message generation in native library code (<code>dispatch.c</code>) - <a href=""https://github.com/matthiasblaesing""><code>@â€‹matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1460"">#1460</a>: Fix win32 variant date conversion in DST offest window and with millisecond values - <a href=""https://github.com/eranl""><code>@â€‹eranl</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1472"">#1472</a>: Fix incorrect bitmask in <code>c.s.j.Pointer#createConstant(int)</code> - <a href=""https://github.com/dbwiddis""><code>@â€‹dbwiddis</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1481"">#1481</a>: Fix NPE in NativeLibrary when unpacking from classpath is disabled - <a href=""https://github.com/trespasserw""><code>@â€‹trespasserw</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1489"">#1489</a>: Fixes typo in <code>OpenGL3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:2559,error,error,2559,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['error'],['error']
Availability,"al user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. <details>; <summary>âš ï¸ <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Use of a Broken or Risky Cryptographic Algorithm <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6149518](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6149518) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6157248](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6157248) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **451/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.3 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-62",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14234:1097,avail,available,1097,https://hail.is,https://github.com/hail-is/hail/pull/14234,1,['avail'],['available']
Availability,"al user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. <details>; <summary>âš ï¸ <b>Warning</b></summary>. ```; msal-extensions 1.1.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **554/1000** <br/> **Why?** Has a fix available, CVSS 6.8 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | N",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:1097,avail,available,1097,https://hail.is,https://github.com/hail-is/hail/pull/14327,1,['avail'],['available']
Availability,"al(signal.SIGINT, signal.SIG_IGN); ---> 77 proc = Popen(command, stdin=PIPE, preexec_fn=preexec_func, env=env); 78 else:; 79 # preexec_fn not supported on Windows. /scratch/PI/dpwall/computeEnvironments/miniconda2/lib/python2.7/subprocess.pyc in __init__(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags); 388 p2cread, p2cwrite,; 389 c2pread, c2pwrite,; --> 390 errread, errwrite); 391 except Exception:; 392 # Preserve original exception in case os.close raises. /scratch/PI/dpwall/computeEnvironments/miniconda2/lib/python2.7/subprocess.pyc in _execute_child(self, args, executable, preexec_fn, close_fds, cwd, env, universal_newlines, startupinfo, creationflags, shell, to_close, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite); 1022 raise; 1023 child_exception = pickle.loads(data); -> 1024 raise child_exception; 1025; 1026. OSError: [Errno 2] No such file or directory. and the second error we would get would be. ------------------------------------------------------------------------- Py4JJavaError Traceback (most recent call last) <ipython-input-6-93fa734a63bb> in <module>() ----> 1 hc_nate = HailContext() /scratch/PI/dpwall/computeEnvironments/hail/python/hail/context.pyc in __init__(self, sc, appName, master, local, log, quiet, append, parquet_compression, min_block_size, branching_factor, tmp_dir) 60 self._jhc = scala_object(self._hail, 'HailContext').apply( 61 jsc, appName, joption(master), local, log, quiet, append, ---> 62 parquet_compression, min_block_size, branching_factor, tmp_dir) 63 64 self._jsc = self._jhc.sc() /share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args) 1131 answer = self.gateway_client.send_command(command) 1132 return_value = get_return_value( -> 1133 answer, self.gateway_client, self.target_id, self.name) 1134 1135 for temp_arg in temp_args: /share/sw/free/spark.2.1.0/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1525:3175,error,error,3175,https://hail.is,https://github.com/hail-is/hail/issues/1525,1,['error'],['error']
Availability,"al: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: All done; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. Notice:; 1. The total memory available on the machine is less than 52 GiB (= 53,248 MiB), indeed it is a full 1025 MiB below the advertised amount.; 2. Once all the components of the Dataproc cluster have started (but before any Hail Query jobs are submitted) the total memory available is already depleted to 42760 MiB. Recall that Hail allocates 41 GiB (= 41,984 MiB) to its JVM. This leaves the Python process and all other daemons on the system only 776 MiB of excess RAM. For reference `python3 -c 'import hail'` needs 206 MiB. ---. We must address this situation. It seems safe to assume that the system daemons will use a constant 9.5 GiB of RAM. Moreover the advertised RAM amount is at least 1 GiB larger than reality. I propose:; 1. The driver memory calculation in `hailctl dataproc` should take the advertised RAM amount, subtract 10.5 GiB, and then use 90% of the remaining value. For an n1-highmem-8, that reduces our allocation from 41 GiB to 37 GiB yielding an additional 4GiB to Python and deamon memory fluctuations.; 2. AoU RWB needs to review its memory settings for Spark driver nodes to ensure that the JVM is set to an appropriate maximum heap size. For what it's worth, I think the reason we didn't get an outcry from our local scientific community is that many of them have transitioned to Query-on-Batch where we have exact and total control over the memory available to the driver and the workers.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:3538,avail,available,3538,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790,2,['avail'],['available']
Availability,"alMessage(e.java_exception); --> 111 raise FatalError('%s\n\nJava stack trace:\n%s\n\nERROR SUMMARY: %s' % (deepest, full, deepest)); 112 except py4j.protocol.Py4JError as e:; 113 if e.args[0].startswith('An error occurred while calling'):. FatalError: HailException: malformed.vcf: caught htsjdk.tribble.TribbleException$InternalCodecException: The allele with index 10026357 is not defined in the REF/ALT columns in the record; offending line: 20	10026348	.	A	G	7535.22	PASS	HWP=1.0;AC=2;culprit=Inbreedi... Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3, localhost): is.hail.utils.HailException: malformed.vcf: caught htsjdk.tribble.TribbleException$InternalCodecException: The allele with index 10026357 is not defined in the REF/ALT columns in the record; offending line: 20	10026348	.	A	G	7535.22	PASS	HWP=1.0;AC=2;culprit=Inbreedi...; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:10); 	at is.hail.utils.package$.fatal(package.scala:20); 	at is.hail.utils.TextContext.wrapException(Context.scala:15); 	at is.hail.utils.WithContext.map(Context.scala:27); 	at is.hail.io.vcf.LoadVCF$$anonfun$14$$anonfun$apply$7.apply(LoadVCF.scala:301); 	at is.hail.io.vcf.LoadVCF$$anonfun$14$$anonfun$apply$7.apply(LoadVCF.scala:301); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$7$$anon$2.hasNext(OrderedRDD.scala:210); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1763); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1134); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1134); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882:2222,Error,ErrorHandling,2222,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882,1,['Error'],['ErrorHandling']
Availability,"alize/rich/issues/3176"">Textualize/rich#3176</a></li>; <li>Ensure font is correctly inherited in exported HTML <a href=""https://redirect.github.com/Textualize/rich/issues/3104"">Textualize/rich#3104</a></li>; <li>Fixed typing for <code>FloatPrompt</code>.</li>; </ul>; <h2>The Python 3.12 release</h2>; <p>Mostly a meta update in readiness for the release of Python3.12</p>; <h2>[13.6.0] - 2023-09-30</h2>; <h3>Added</h3>; <ul>; <li>Added Python 3.12 to classifiers.</li>; </ul>; <h2>Markdown fixes</h2>; <h2>[13.5.3] - 2023-09-17</h2>; <h3>Fixed</h3>; <ul>; <li>Markdown table rendering issue with inline styles and links <a href=""https://redirect.github.com/Textualize/rich/issues/3115"">Textualize/rich#3115</a></li>; <li>Fix Markdown code blocks on a light background <a href=""https://redirect.github.com/Textualize/rich/issues/3123"">Textualize/rich#3123</a></li>; </ul>; <h2>v13.5.2</h2>; <p>Bugfix</p>; <h2>[13.5.2] - 2023-08-01</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs assertion error</li>; </ul>; <h2>v13.5.1</h2>; <p>Very minor update to URL highlighting</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/Textualize/rich/blob/master/CHANGELOG.md"">rich's changelog</a>.</em></p>; <blockquote>; <h2>[13.7.1] - 2023-02-28</h2>; <h3>Fixed</h3>; <ul>; <li>Updated the widths of some characters <a href=""https://redirect.github.com/Textualize/rich/pull/3289"">Textualize/rich#3289</a></li>; </ul>; <h2>[13.7.0] - 2023-11-15</h2>; <h3>Added</h3>; <ul>; <li>Adds missing parameters to Panel.fit <a href=""https://redirect.github.com/Textualize/rich/issues/3142"">Textualize/rich#3142</a></li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Some text goes missing during wrapping when it contains double width characters <a href=""https://redirect.github.com/Textualize/rich/issues/3176"">Textualize/rich#3176</a></li>; <li>Ensure font is correctly inherited in exported HTML <a href=""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14376:1880,error,error,1880,https://hail.is,https://github.com/hail-is/hail/pull/14376,2,['error'],['error']
Availability,"alize/rich/issues/3176"">Textualize/rich#3176</a></li>; <li>Ensure font is correctly inherited in exported HTML <a href=""https://redirect.github.com/Textualize/rich/issues/3104"">Textualize/rich#3104</a></li>; <li>Fixed typing for <code>FloatPrompt</code>.</li>; </ul>; <h2>The Python 3.12 release</h2>; <p>Mostly a meta update in readiness for the release of Python3.12</p>; <h2>[13.6.0] - 2023-09-30</h2>; <h3>Added</h3>; <ul>; <li>Added Python 3.12 to classifiers.</li>; </ul>; <h2>Markdown fixes</h2>; <h2>[13.5.3] - 2023-09-17</h2>; <h3>Fixed</h3>; <ul>; <li>Markdown table rendering issue with inline styles and links <a href=""https://redirect.github.com/Textualize/rich/issues/3115"">Textualize/rich#3115</a></li>; <li>Fix Markdown code blocks on a light background <a href=""https://redirect.github.com/Textualize/rich/issues/3123"">Textualize/rich#3123</a></li>; </ul>; <h2>v13.5.2</h2>; <p>Bugfix</p>; <h2>[13.5.2] - 2023-08-01</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs assertion error</li>; </ul>; <h2>v13.5.1</h2>; <p>Very minor update to URL highlighting</p>; <h2>[13.5.1] - 2023-07-31</h2>; <h3>Fixed</h3>; <ul>; <li>Fix tilde character (<code>~</code>) not included in link regex when printing to console <a href=""https://redirect.github.com/Textualize/rich/issues/3057"">Textualize/rich#3057</a></li>; </ul>; <h2>Mostly cake, one or two puppies</h2>; <p><a href=""https://textual.textualize.io/blog/2023/07/29/pull-requests-are-cake-or-puppies/"">https://textual.textualize.io/blog/2023/07/29/pull-requests-are-cake-or-puppies/</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/Textualize/rich/blob/master/CHANGELOG.md"">rich's changelog</a>.</em></p>; <blockquote>; <h2>[13.7.0] - 2023-11-15</h2>; <h3>Added</h3>; <ul>; <li>Adds missing parameters to Panel.fit <a href=""https://redirect.github.com/Textualize/rich/issues/3142"">Textualize/rich#3142</a></l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14012:1628,error,error,1628,https://hail.is,https://github.com/hail-is/hail/pull/14012,2,['error'],['error']
Availability,all builds are failing because the repository the hosts the shadow jar plugin is down,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10985#issuecomment-1011304877:81,down,down,81,https://hail.is,https://github.com/hail-is/hail/pull/10985#issuecomment-1011304877,1,['down'],['down']
Availability,"alled parameters. `a` and `c` which do not start with dashes, are called arguments. `-o`, which starts with a dash, is an option. This PR makes the following changes:. - For dataproc commands taking extra gcloud parameters, all parameters after a double-dash (--) are passed to gcloud.; - The actual rule is slightly more complicated, but I think the above rule is the right take away. In detail, extra parameters are passed to gcloud. Unknown options (starting with a dash) before `--` are reported as an error. So arguments (not options) before `--` and all parameters after are passed to gcloud. ; - Short options don't need a `=` when specifying a value. It is now `-p2`, not `-p=2`.; - While I was making breaking changes, I changed `dataproc submit` `--gcloud_configuration` to `--gcloud-configuration`. I am happy to undo this one.; - Group arguments must go before the next command. Write `hailctl dataproc --beta start ...` not `hailctl dataproc start --beta ...`, which is an error since `start` has no option `--beta`. This PR rewrites argument parsing to use click instead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line parameters, parses them, and calls the original function. The option options are pretty self-explanatory. - To access an argument to a group (like `dataproc --beta`) in a (sub",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9842:1264,error,error,1264,https://hail.is,https://github.com/hail-is/hail/pull/9842,1,['error'],['error']
Availability,"alse`, step 3 succeeds. ### What went wrong (all error messages here, including the full java stack trace):; ```; 2018-06-19 17:15:41 Hail: INFO: vep: annotated 2 variants; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/opt/hail/python/hail/table.py"", line 1195, in show; print(self._show(n,width, truncate, types)); File ""/opt/hail/python/hail/table.py"", line 1198, in _show; return self._jt.showString(n, joption(truncate), types, width); File ""/opt/spark-2.2.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/opt/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;). Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 11.0 failed 1 times, most recent failure: Lost task 0.0 in stage 11.0 (TID 11, localhost, executor driver): scala.MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;); 	at is.hail.annotations.RegionValueBuilder.addAnnotation(RegionValueBuilder.scala:489); 	at is.hail.methods.VEP$$anonfun$9$$anonfun$apply$4.apply(VEP.scala:350); 	at is.hail.methods.VEP$$anonfun$9$$anonfun$apply$4.apply(VEP.scala:345); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:926); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:920); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3790:1363,failure,failure,1363,https://hail.is,https://github.com/hail-is/hail/issues/3790,1,['failure'],['failure']
Availability,also add module functions to download and import 1KG and Movie Lens data,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3203:29,down,download,29,https://hail.is,https://github.com/hail-is/hail/pull/3203,1,['down'],['download']
Availability,also added test for this change:; https://github.com/hail-is/hail/pull/4228. made sure that it errored without that change,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4237:95,error,errored,95,https://hail.is,https://github.com/hail-is/hail/pull/4237,1,['error'],['errored']
Availability,also changes the error message to display `<<<empty key>>>` as the list of keys. fixes #6663,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6736:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/6736,1,['error'],['error']
Availability,also have rebase conflict and test failures,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7134#issuecomment-535987529:35,failure,failures,35,https://hail.is,https://github.com/hail-is/hail/pull/7134#issuecomment-535987529,1,['failure'],['failures']
Availability,also see test failure,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3019#issuecomment-369657687:14,failure,failure,14,https://hail.is,https://github.com/hail-is/hail/pull/3019#issuecomment-369657687,1,['failure'],['failure']
Availability,"also, NB: I got this error after trying the script one last time; ```; ERROR: (gcloud.iam.service-accounts.keys.create) RESOURCE_EXHAUSTED: Maximum number of keys on account reached.; - '@type': type.googleapis.com/google.rpc.RetryInfo; retryDelay: 86401s; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4502#issuecomment-427220196:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/pull/4502#issuecomment-427220196,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"also, this error message is WAY better and fully debuggable.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1623#issuecomment-290762181:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/issues/1623#issuecomment-290762181,1,['error'],['error']
Availability,"amazon-ebs: Collecting azure-storage-blob==12.11.0; 914 | amazon-ebs: Downloading azure_storage_blob-12.11.0-py3-none-any.whl (346 kB); 915 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 346.4/346.4 kB 41.0 MB/s eta 0:00:00; 916 | amazon-ebs: Collecting bokeh<2.0,>1.3; 917 | amazon-ebs: Downloading bokeh-1.4.0.tar.gz (32.4 MB); 918 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 32.4/32.4 MB 48.4 MB/s eta 0:00:00; 919 | amazon-ebs: Preparing metadata (setup.py): started; 920 | amazon-ebs: Preparing metadata (setup.py): finished with status 'done'; 921 | amazon-ebs: Requirement already satisfied: boto3<2.0,>=1.17 in /usr/local/lib/python3.7/site-packages (1.24.78); 922 | amazon-ebs: Requirement already satisfied: botocore<2.0,>=1.20 in /usr/local/lib/python3.7/site-packages (1.27.78); 923 | amazon-ebs: Collecting decorator<5; 924 | amazon-ebs: Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); 925 | amazon-ebs: Collecting Deprecated<1.3,>=1.2.10; 926 | amazon-ebs: Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB); 927 | amazon-ebs: Collecting dill<0.4,>=0.3.1.1; 928 | amazon-ebs: Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB); 929 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 95.8/95.8 kB 15.3 MB/s eta 0:00:00; 930 | amazon-ebs: Collecting google-auth==1.27.0; 931 | amazon-ebs: Downloading google_auth-1.27.0-py2.py3-none-any.whl (135 kB); 932 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 135.6/135.6 kB 30.6 MB/s eta 0:00:00; 933 | amazon-ebs: Collecting google-cloud-storage==1.25.*; 934 | amazon-ebs: Downloading google_cloud_storage-1.25.0-py2.py3-none-any.whl (73 kB); 935 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 73.4/73.4 kB 22.1 MB/s eta 0:00:00; 936 | amazon-ebs: Collecting humanize==1.0.0; 937 | amazon-ebs: Downloading humanize-1.0.0-py2.py3-none-any.whl (51 kB); 938 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 51.9/51.9 kB 14.6 MB/s eta 0:00:00; 939 | amazon-ebs: Collecting hurry.filesi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:4055,Down,Downloading,4055,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,"amp;to=2024-04-08&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab_server+involves%3AAshokChoudhary11+updated%3A2024-03-11..2024-04-08&amp;type=Issues""><code>@â€‹AshokChoudhary11</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab_server+involves%3Aholzman+updated%3A2024-03-11..2024-04-08&amp;type=Issues""><code>@â€‹holzman</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab_server+involves%3Amanics+updated%3A2024-03-11..2024-04-08&amp;type=Issues""><code>@â€‹manics</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab_server+involves%3Awelcome+updated%3A2024-03-11..2024-04-08&amp;type=Issues""><code>@â€‹welcome</code></a></p>; <h2>v2.25.4</h2>; <h2>2.25.4</h2>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab_server/compare/v2.25.3...15e796699f04e06db9ed23a689d454feae36ffbd"">Full Changelog</a>)</p>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Use updated releaser workflows <a href=""https://redirect.github.com/jupyterlab/jupyterlab_server/pull/442"">#442</a> (<a href=""https://github.com/blink1073""><code>@â€‹blink1073</code></a>)</li>; <li>Use json5 typings <a href=""https://redirect.github.com/jupyterlab/jupyterlab_server/pull/441"">#441</a> (<a href=""https://github.com/blink1073""><code>@â€‹blink1073</code></a>)</li>; <li>Enforce pytest 7 <a href=""https://redirect.github.com/jupyterlab/jupyterlab_server/pull/439"">#439</a> (<a href=""https://github.com/blink1073""><code>@â€‹blink1073</code></a>)</li>; <li>Fix test util typings <a href=""https://redirect.github.com/jupyterlab/jupyterlab_server/pull/437"">#437</a> (<a href=""https://github.com/blink1073""><code>@â€‹blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab_server/graphs/contributors?from=2024-02-14&amp;to=2024-03-11&amp;type=c"">GitHub contributors page for this release</a>)</p>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14483:2089,Mainten,Maintenance,2089,https://hail.is,https://github.com/hail-is/hail/pull/14483,1,['Mainten'],['Maintenance']
Availability,"an array of â€˜const class simdpp::arch_avx2::int16<16>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:91:7: note: â€˜class simdpp::arch_avx2::uint8<32>â€™ declared here; class uint8<32, void> : public any_int8<32, uint8<32,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint32<8>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint32<8>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint32<8>]â€™; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:110:36: required from â€˜simdpp::arch_avx2::uint8<32>::uint8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint32<8>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_not.h:64:43: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint8<32>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint8<32>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint32<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:22747,Mask,MaskCastOverride,22747,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"an array of â€˜const class simdpp::arch_avx2::int16<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:19,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:104:7: note: â€˜class simdpp::arch_avx2::uint8<16>â€™ declared here; class uint8<16, void> : public any_int8<16, uint8<16,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int16<16>; T = simdpp::arch_avx2::uint8<32>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int16<16>; T = simdpp::arch_avx2::uint8<32>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int16<16>; T = simdpp::arch_avx2::uint8<32>]â€™; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:56:36: required from â€˜simdpp::arch_avx2::int16<16>& simdpp::arch_avx2::int16<16>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint8<32>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/shuffle_bytes16.h:85:11: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::int16<16>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::int16<16>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint8<32>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:19161,Mask,MaskCastOverride,19161,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"an array of â€˜const class simdpp::arch_avx2::int16<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:104:7: note: â€˜class simdpp::arch_avx2::uint32<4>â€™ declared here; class uint32<4, void> : public any_int32<4, uint32<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::int16<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::int16<16>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::int16<16>]â€™; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:110:36: required from â€˜simdpp::arch_avx2::uint32<8>::uint32(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int16<16>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_reduce_mul.h:181:30: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint32<8>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint32<8>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::int16<16>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:86928,Mask,MaskCastOverride,86928,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"an array of â€˜const class simdpp::arch_avx2::uint32<16>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:38,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64.h:87:7: note: â€˜class simdpp::arch_avx2::uint64<8>â€™ declared here; class uint64<N, void> : public any_int64<N, uint64<N,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<16>; T = simdpp::arch_avx2::uint64<8>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<16>; T = simdpp::arch_avx2::uint64<8>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<16>; T = simdpp::arch_avx2::uint64<8>]â€™; libsimdpp-2.0-rc2/simdpp/types/int32.h:105:36: required from â€˜simdpp::arch_avx2::uint32<N>& simdpp::arch_avx2::uint32<N>::operator=(const simdpp::arch_avx2::any_vec<(N * 4), V>&) [with V = simdpp::arch_avx2::uint64<8, simdpp::arch_avx2::expr_empty>; unsigned int N = 16]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:598:8: required from â€˜void simdpp::arch_avx2::detail::insn::v_sse_transpose32x4(V&, V&, V&, V&) [with V = simdpp::arch_avx2::uint32<16>; D = simdpp::arch_avx2::uint64<8>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:533:62: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:97934,Mask,MaskCastOverride,97934,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"an array of â€˜const class simdpp::arch_avx2::uint32<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:91:7: note: â€˜class simdpp::arch_avx2::uint8<32>â€™ declared here; class uint8<32, void> : public any_int8<32, uint8<32,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint8<32>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint8<32>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint8<32>]â€™; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:110:36: required from â€˜simdpp::arch_avx2::uint32<8>::uint32(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint8<32>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_not.h:64:45: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint32<8>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint32<8>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint8<32>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:24514,Mask,MaskCastOverride,24514,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"an array of â€˜const class simdpp::arch_avx2::uint32<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:27,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:91:7: note: â€˜class simdpp::arch_avx2::uint64<4>â€™ declared here; class uint64<4, void> : public any_int64<4, uint64<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint64<4>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint64<4>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint64<4>]â€™; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:114:36: required from â€˜simdpp::arch_avx2::uint32<8>& simdpp::arch_avx2::uint32<8>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint64<4, simdpp::arch_avx2::expr_empty>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:181:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint32<8>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint32<8>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint64<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:44902,Mask,MaskCastOverride,44902,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"an array of â€˜const class simdpp::arch_avx2::uint64<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:91:7: note: â€˜class simdpp::arch_avx2::uint8<32>â€™ declared here; class uint8<32, void> : public any_int8<32, uint8<32,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint8<32>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint8<32>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint8<32>]â€™; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:110:36: required from â€˜simdpp::arch_avx2::uint64<4>::uint64(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint8<32>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_not.h:94:45: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint64<4>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint64<4>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint8<32>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:28049,Mask,MaskCastOverride,28049,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"an array of â€˜const class simdpp::arch_avx2::uint8<32>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:24,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:91:7: note: â€˜class simdpp::arch_avx2::uint32<8>â€™ declared here; class uint32<8, void> : public any_int32<8, uint32<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint64<4>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint64<4>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint64<4>]â€™; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:110:36: required from â€˜simdpp::arch_avx2::uint8<32>::uint8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint64<4>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_not.h:94:43: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint8<32>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint8<32>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint64<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:26282,Mask,MaskCastOverride,26282,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"an; from pprint import pprint; # hail; import hail as hl; import hail.expr.aggregators as agg; import hail.expr.functions. hl.init(default_reference='GRCh38'); print(""Read in PASS SNVs""); passed=hl.read_matrix_table('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass'); print(""Filtering Common Variants""); common=passed.filter_rows(passed.variant_qc.AF > 0.01).persist(); common.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass.common'); print(""Pruning LD Variants""); pruned =hl.ld_prune(common,30,r2=0.1, memory_per_core=2048); pruned.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pruned'); print(""Sample 20% of variants for running PC-Relate""); pruned_subsample = pruned.sample_rows(0.2).persist(); print(""Running PC_Relate""); rel = hl.pc_relate(pruned_subsample.GT, 0.01, k=10); rel_df = rel.to_pandas(); rel_df.describe(); pprint(rel_df); rel_df.to_csv('gcad_5k.snv.rel.csv'); ```. ### What went wrong (all error messages here, including the full java stack trace):. Got a memory error. but not sure what memory needs to be increased. The job seems to restart but does not progress and need to kill. . java.lang.OutOfMemoryError: Java heap spaceop. Running on Apache Spark version 2.2.0; SparkUI available at http://10.48.225.55:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-63d60cc; NOTE: This is a beta version. Interfaces may change; during the beta period. We also recommend pulling; the latest changes weekly.; Read in PASS SNVs; Filtering Common Variants; [Stage 0:==================================================>(96600 + 1) / 96601]2018-04-27 20:54:43 Hail: INFO: wrote 11341822 items in 96601 partitions; Pruning LD Variants; [Stage 1:==================================================>(96598 + 3) / 96601]2018-04-27 21:19:04 Hail: INFO: Running LD prune with nSamples=4795, nVariants=11341822, nPartitions=96601, and maxQueueSize=429841.; [Stage 2:=========================================> (79823 + 18) / 96601]jav",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3463:2003,error,error,2003,https://hail.is,https://github.com/hail-is/hail/issues/3463,1,['error'],['error']
Availability,"anager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:236); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:305); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:84); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 134; ```; When I dig into the container logs, the stdout is empty on most, stderr is full of warnings, but no errors:; ```; 18/03/02 15:28:07 WARN com.google.cloud.hadoop.gcsio.GoogleCloudStorageReadChannel: Channel for 'gs://gnomad/coverage/hail-0.2/coverage/exomes/parts/part_partition1049.vds/entries/rows/parts/part-0095' is not open.; ```; But then one machine I logged into had:; ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fa70eb59074, pid=4361, tid=0x00007fa707702700; #; # JRE version: OpenJDK Runtime Environment (8.0_131-b11) (build 1.8.0_131-8u131-b11-1~bpo8+1-b11); # Java VM: OpenJDK 64-Bit Server VM (25.131-b11 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libconscrypt_openjdk_jni.so+0x43074]; [error occurred during error reporting (printing problematic frame), id 0xb]. # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1519994715701_0001/container_1519994715701_0001_01_000558/hs_err_pid4361.log; # [ timer expired, abort... ]; ```; But said log file has no information. The job is finishing, just with a high (~50-100%) task failure rate.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3053:4213,error,error,4213,https://hail.is,https://github.com/hail-is/hail/issues/3053,5,"['error', 'failure']","['error', 'failure']"
Availability,"and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; Versions of software products:. Running on Apache Spark version 2.4.5; SparkUI available at http://vhabosgen72:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-3c86d3ba497a; LOGGING: writing to /dacs1/team/vhabhsxum/tasks/ancestryPainting/hail-20210125-1235-0.2.61-3c86d3ba497a.log. I am running the GWAS tutorial hosted at https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html#Let's-do-a-GWAS. Everything is OK until the line to do GWAS. The error I have is as follows:. -------------- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:1042,ERROR,ERROR,1042,https://hail.is,https://github.com/hail-is/hail/issues/9939,1,['ERROR'],['ERROR']
Availability,annotate_rows failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5147:14,failure,failure,14,https://hail.is,https://github.com/hail-is/hail/issues/5147,1,['failure'],['failure']
Availability,anonfun$apply$22.apply(ContextRDD.scala:308); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:139); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:139); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-c8ca698; Error summary: NegativeArraySizeException: null,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3583:15798,Error,Error,15798,https://hail.is,https://github.com/hail-is/hail/issues/3583,1,['Error'],['Error']
Availability,"another possible error - I think prune dead fields might be broken if you have a same-name row field on the left and right, and only use the `_1` version from the right table.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4311#issuecomment-420261417:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/issues/4311#issuecomment-420261417,1,['error'],['error']
Availability,"api server bits into CI (maybe should be prioritized earlier...I prefer to get draft of major functions done first; am new to writing tests for React/Node). ## Near-term goals (<= 6 mo); 1. Upload, download; 2. Launch clusters, pay for them; 3. ?. ## Longer-term goals; 1. Much simpler interface to Hail. I would like steps that can be performed without programming to be done so. I would prefer fasta->variant filtering to be done as in Bystro (at least from the interface standpoint), i.e without opening up a notebook. Common analyses pipelines should also be possible without any interaction with a python notebook: GWAS, rare-variant (SKAT) analyses have, it seems, relatively few permutations. Those should be behind UI primitives. At each stage of a ; 2. Social network bits: users should be able to share job state with other users (requested by Bystro users on 22q consortium project) at the least.; 3. Record job state using something like Merkle tree. Checkout state. Aka ""blockchain""; 4. Cooperative analysis: provide system for people to validate analyses; ; Basic idea: . 1) People donate computational resources for ad-hoc heterogenous clusters. ; 2) People donate intellectual capital. Re-run analyses without the full available code. See if they can replicate (not p-values, but order). Could generate multiple-hypothesis-test corrected aggregate. These users get publication credit as consortia; 3) People donate minor intellectual capital: Re-run analysis with full available code. Report on success. This will catch bugs, and non-deterministic results (for instance, if reported accuracy depends on local minima..similar or better minima may only occur once in a great while). Similar to 2. ## Timetables; 1-3a: 12/10/18; 3b: by 12/15/18; 4a-4b: by 12/12/18; 4c-d: by 12/15/18. This probably shouldn't be merged for a while. Still working on authentication handling for third party APIs. All first party APIs (our stuff) is well controlled, can be extended from existing codebase.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931:9045,avail,available,9045,https://hail.is,https://github.com/hail-is/hail/pull/4931,2,['avail'],['available']
Availability,application/octet-stream 2023-06-09T12:44:22+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/2/31Owgv/status.json BlockBlob Hot 4453 application/octet-stream 2023-06-09T12:44:22+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/bunch/dK3o5ZfXmYSkP5TA/specs BlockBlob Hot 1264 application/octet-stream 2023-06-09T12:43:37+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/bunch/dK3o5ZfXmYSkP5TA/specs.idx BlockBlob Hot 16 application/octet-stream 2023-06-09T12:43:37+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/bunch/eOrFpVrN98GBIizi/specs BlockBlob Hot 1264 application/octet-stream 2023-06-09T12:43:34+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/bunch/eOrFpVrN98GBIizi/specs.idx BlockBlob Hot 16 application/octet-stream 2023-06-09T12:43:34+00:00; ```. I looked at the status:. ```; az storage blob download --account-name haildevtest --container test --name batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/2/31Owgv/status.json | jq '.' | less; ```. which contained an error (I un-escaped the string here):. ```; JVMUserError: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at is.hail.JVMEntryway.retrieveException(JVMEntryway.java:253); 	at is.hail.JVMEntryway.finishFutures(JVMEntryway.java:215); 	at is.hail.JVMEntryway.main(JVMEntryway.java:185); Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:122); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadP,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13160:3663,error,error,3663,https://hail.is,https://github.com/hail-is/hail/pull/13160,1,['error'],['error']
Availability,"aproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternati",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:3930,echo,echo,3930,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,1,['echo'],['echo']
Availability,"apt) from 1.13.3 to 1.14.1.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/GrahamDumpleton/wrapt/blob/develop/docs/changes.rst"">wrapt's changelog</a>.</em></p>; <blockquote>; <h2>Version 1.14.1</h2>; <p><strong>Bugs Fixed</strong></p>; <ul>; <li>When the post import hooks mechanism was being used, and a Python package with; its own custom module importer was used, importing modules could fail if the; custom module importer didn't use the latest Python import hook finder/loader; APIs and instead used the deprecated API. This was actually occurring with the; <code>zipimporter</code> in Python itself, which was not updated to use the newer Python; APIs until Python 3.10.</li>; </ul>; <h2>Version 1.14.0</h2>; <p><strong>Bugs Fixed</strong></p>; <ul>; <li>; <p>Python 3.11 dropped <code>inspect.formatargspec()</code> which was used in creating; signature changing decorators. Now bundling a version of this function; which uses <code>Parameter</code> and <code>Signature</code> from <code>inspect</code> module when; available. The replacement function is exposed as <code>wrapt.formatargspec()</code>; if need it for your own code.</p>; </li>; <li>; <p>When using a decorator on a class, <code>isinstance()</code> checks wouldn't previously; work as expected and you had to manually use <code>Type.__wrapped__</code> to access; the real type when doing instance checks. The <code>__instancecheck__</code> hook is; now implemented such that you don't have to use <code>Type.__wrapped__</code> instead; of <code>Type</code> as last argument to <code>isinstance()</code>.</p>; </li>; <li>; <p>Eliminated deprecation warnings related to Python module import system, which; would have turned into broken code in Python 3.12. This was used by the post; import hook mechanism.</p>; </li>; </ul>; <p><strong>New Features</strong></p>; <ul>; <li>Binary wheels provided on PyPi for <code>aarch64</code> Linux systems and macOS; native silicon where supported b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12102:1117,avail,available,1117,https://hail.is,https://github.com/hail-is/hail/pull/12102,1,['avail'],['available']
Availability,"ar/180856479). From Zulip:; > By comparison, on my wired laptop (which should be strictly slower than in GCP), I can download and extract a tar -cvzf archive in 7.2 seconds; > ...; > The 20 seconds is: clone from github.com, git-merge; > The 7.2 seconds is: download from GCS, untar; > Just ran the test in the cloud using the google cloud sdk image started by k run, 3.7 seconds; > The download is super fast, like a second; > the untar is about the same in both contexts, 1.2 seconds; > But the download drops from 4.7 to ~1.5. Chris pointed out I should skip going to disk and pipe into tar, I have not timed that yet. I was seeing fetch being more like 8 minutes to my repository. My repository is significantly larger than Alex's. I could delete some old branches to address this. ---. > for inputs/outputs, I wonder if we should have a flag that indicates it is an archive and do the archive/extract automatically (like you've done here but more generally), and stop using cp -r. I almost went down this route. It would save a couple lines of tar/untar in runImage steps. I felt the savings wasn't worth the effort of implementing it. In the buildImage case (what this PR addressed), I think it's worth it to keep images small. > for downstream steps that only need a small part of the repo, is it better to copy out different pieces (archived or no) rather than copy the whole thing and extra the parts you need?. I haven't investigated this. I agree, there exists an inflection point where the size of data overcomes GCS latency and GCS-throughput / tar-decompress is the bottleneck. There's something to be said for tar'ing everything except for `.git`, but I didn't carefully check which steps need it and which steps do not. ---. In conclusion, I'd say this PR is necessary for #7534, and #7534 is a big quality of life improvement for those of us with large repos running tests on images that are deep on the critical path (the shuffler test is behind 3 images and build hail, which also c",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7626#issuecomment-560442927:1202,down,down,1202,https://hail.is,https://github.com/hail-is/hail/pull/7626#issuecomment-560442927,2,['down'],['down']
Availability,"arch` without a `config` argument works fine.; ```python; hl.export_elasticsearch(table, ""host"", 9200, ""someindex"", ""sometype"", 1000, config=None); ```. However, attempting to pass `config`, for example:; ```python; es_config = {""es.write.operation"": ""index""}; hl.export_elasticsearch(table, ""host"", 9200, ""someindex"", ""sometype"", 1000, config=es_config); ```; causes the following error:. ### What went wrong (all error messages here, including the full java stack trace):. ```; Traceback (most recent call last):; File ""/tmp/0ba8fc2c770d4b2ba96dc23c50fd6eab/load_clinvar_to_es.py"", line 105, in <module>; verbose=True,; File ""/tmp/0ba8fc2c770d4b2ba96dc23c50fd6eab/hail_v02_scripts.zip/hail_v02_scripts/utils/elasticsearch/client.py"", line 234, in export_table_to_elasticsearch; File ""/home/hail/hail.zip/hail/typecheck/check.py"", line 547, in wrapper; File ""/home/hail/hail.zip/hail/methods/impex.py"", line 1885, in export_elasticsearch; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/home/hail/hail.zip/hail/utils/java.py"", line 188, in deco; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py"", line 323, in get_return_value; py4j.protocol.Py4JError: An error occurred while calling z:is.hail.io.ElasticsearchConnector.export. Trace:; py4j.Py4JException: Method export([class is.hail.table.Table, class java.lang.String, class java.lang.Integer, class java.lang.String, class java.lang.String, class java.lang.Integer, class java.util.HashMap, class java.lang.Boolean]) does not exist; 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:339); 	at py4j.Gateway.invoke(Gateway.java:274); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4063:1553,error,error,1553,https://hail.is,https://github.com/hail-is/hail/issues/4063,1,['error'],['error']
Availability,"are you sure it's a dataproc problem?. If scalding is using java unsafe in a not-guaranteed-to-work way, then a core dump s totally possible. Example - the JVM will sometimes tolerate misaligned floats/ints, and sometimes will crash.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3053#issuecomment-419972098:175,toler,tolerate,175,https://hail.is,https://github.com/hail-is/hail/issues/3053#issuecomment-419972098,1,['toler'],['tolerate']
Availability,"aring metadata (setup.py): started; 942 | amazon-ebs: Preparing metadata (setup.py): finished with status 'done'; 943 | amazon-ebs: Collecting janus<1.1,>=0.6; 944 | amazon-ebs: Downloading janus-1.0.0-py3-none-any.whl (6.9 kB); 945 | amazon-ebs: Requirement already satisfied: Jinja2==3.0.3 in /usr/local/lib/python3.7/site-packages (3.0.3); 946 | amazon-ebs: Collecting nest_asyncio==1.5.4; 947 | amazon-ebs: Downloading nest_asyncio-1.5.4-py3-none-any.whl (5.1 kB); 948 | amazon-ebs: Requirement already satisfied: numpy<2 in /usr/local/lib64/python3.7/site-packages (1.21.6); 949 | amazon-ebs: Collecting orjson==3.6.4; 950 | amazon-ebs: Downloading orjson-3.6.4-cp37-cp37m-manylinux_2_24_x86_64.whl (249 kB); 951 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 249.9/249.9 kB 45.1 MB/s eta 0:00:00; 952 | amazon-ebs: Requirement already satisfied: pandas<1.5.0,>=1.3.0 in /usr/local/lib64/python3.7/site-packages (1.3.5); 953 | amazon-ebs: Collecting parsimonious<0.9; 954 | amazon-ebs: Downloading parsimonious-0.8.1.tar.gz (45 kB); 955 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 45.1/45.1 kB 10.2 MB/s eta 0:00:00; 956 | amazon-ebs: Preparing metadata (setup.py): started; 957 | amazon-ebs: Preparing metadata (setup.py): finished with status 'done'; 958 | amazon-ebs: Collecting plotly<5.11,>=5.5.0; 959 | amazon-ebs: Downloading plotly-5.10.0-py2.py3-none-any.whl (15.2 MB); 960 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 15.2/15.2 MB 57.8 MB/s eta 0:00:00; 961 | amazon-ebs: Collecting PyJWT; 962 | amazon-ebs: Downloading PyJWT-2.5.0-py3-none-any.whl (20 kB); 963 | amazon-ebs: Collecting python-json-logger==2.0.2; 964 | amazon-ebs: Downloading python_json_logger-2.0.2-py3-none-any.whl (7.4 kB); 965 | amazon-ebs: Collecting requests==2.25.1; 966 | amazon-ebs: Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB); 967 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 61.2/61.2 kB 15.6 MB/s eta 0:00:00; 968 | amazon-ebs: Requirement already satisf",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:6151,Down,Downloading,6151,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,"ark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) at org.apache.sparkapache.spark.rdd.RDD.iterator(RDD.scala:288) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.sparkitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) at org.apache.spark.rdd.RDDputeOrReadCheckpoint(RDD.scala:324) at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) at org.apache.spark.rdd.MapPartitionsRDD.compute(MaD.scala:288) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpointla:90) at org.apache.spark.scheduler.Task.run(Task.scala:121) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:4cala:414) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$ailureException: Failure while fetching StreamChunkId{streamId=830947795015, chunkIndex=0}: java.nio.file.NoSuchFileException: /data03/hadoop/yarn/t sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.javannel(UnixFileSystemProvider.java:214) at java.nio.file.Files.newByteChannel(Files.java:361) at java.nio.file.Files.newByteChannel(Files.java:40rage.BlockManager.getBlockData(BlockManager.scala:382) at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.rator$$anon$11.next(Iterator.scala:410) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.apache.sparkler.processFetchRequest(TransportRequestHandler.java:130) at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHetty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerCactChannelHandlerContext.java:340) at io.n",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:7424,Failure,Failure,7424,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['Failure'],['Failure']
Availability,"ark.rdd.ZippedPartitionsBaseRDD.getPartitions(ZippedPartitionsRDD.scala:57); 	 at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	 at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	 at scala.Option.getOrElse(Option.scala:121); 	 at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	 at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	 at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	 at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	 at scala.Option.getOrElse(Option.scala:121); 	 at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	 at is.hail.sparkextras.OrderedRDD$.coerce(OrderedRDD.scala:58); 	 at is.hail.sparkextras.OrderedRDD$.apply(OrderedRDD.scala:48); 	 at is.hail.utils.richUtils.RichPairRDD$.toOrderedRDD$extension1(RichPairRDD.scala:44); 	 at is.hail.variant.MatrixTable$.fromLegacy(MatrixTable.scala:84); 	 at is.hail.variant.MatrixTable.copyLegacy(MatrixTable.scala:2019); 	 at is.hail.methods.VEP$.annotate(VEP.scala:407); 	 at is.hail.methods.VEP$.apply(VEP.scala:412); 	 at is.hail.methods.VEP.apply(VEP.scala); 	 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	 at java.lang.reflect.Method.invoke(Method.java:498); 	 at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	 at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	 at py4j.Gateway.invoke(Gateway.java:280); 	 at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	 at py4j.commands.CallCommand.execute(CallCommand.java:79); 	 at py4j.GatewayConnection.run(GatewayConnection.java:214); 	 at java.lang.Thread.run(Thread.java:748); Hail version: devel-6191d4c; Error summary: Can't zip RDDs with unequal numbers of partitions: List(16979, 16992)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2666:2799,Error,Error,2799,https://hail.is,https://github.com/hail-is/hail/issues/2666,1,['Error'],['Error']
Availability,"ark_backend('to_pandas').to_pandas(self, flatten); 2706 ; 2707 @staticmethod. ~/anaconda3/lib/python3.6/site-packages/hail/backend/backend.py in to_pandas(self, t, flatten); 66 ; 67 def to_pandas(self, t, flatten):; ---> 68 return self.to_spark(t, flatten).toPandas(); 69 ; 70 def from_pandas(self, df, key):. ~/anaconda3/lib/python3.6/site-packages/hail/backend/backend.py in to_spark(self, t, flatten); 63 if flatten:; 64 t = t.flatten(); ---> 65 return pyspark.sql.DataFrame(t._jt.toDF(Env.hc()._jsql_context), Env.sql_context()); 66 ; 67 def to_pandas(self, t, flatten):. ~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. ~/anaconda3/lib/python3.6/site-packages/hail/utils/java.py in deco(*args, **kwargs); 225 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 226 'Hail version: %s\n'; --> 227 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 228 except pyspark.sql.utils.CapturedException as e:; 229 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: AssertionError: assertion failed: type mismatch:; name: global; actual: Struct{bn:Struct{n_populations:Int32,n_samples:Int32,n_variants:Int32,n_partitions:Int32,pop_dist:Array[Int32],fst:Array[Float64],mixture:Boolean},__uid_882:Array[Struct{sample_idx:Int32,pop:Int32,s:String}]}; expect: Struct{bn:Struct{n_populations:Int32,n_samples:Int32,n_variants:Int32,n_partitions:Int32,pop_dist:Array[Int32],fst:Array[Float64],mixture:Boolean},__cols:Array[Struct{sample_idx:Int32,pop:Int32,s:String}]}. Java stack trace:; is.hail.utils.HailException: Error while typechecking IR:; (MakeStruct; (bn; (GetField bn; (Ref global)))); 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.expr.ir.T",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5212:2415,Error,Error,2415,https://hail.is,https://github.com/hail-is/hail/issues/5212,1,['Error'],['Error']
Availability,"array of â€˜const class simdpp::arch_avx2::float32<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:104:7: note: â€˜class simdpp::arch_avx2::uint32<4>â€™ declared here; class uint32<4, void> : public any_int32<4, uint32<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::float64<2>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::float64<2>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::float64<2>]â€™; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:129:36: required from â€˜simdpp::arch_avx2::uint32<4>::uint32(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::float64<2>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/test_bits.h:73:39: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint32<4>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint32<4>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::float64<2>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:94075,Mask,MaskCastOverride,94075,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"array of â€˜const class simdpp::arch_avx2::float64<2>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:104:7: note: â€˜class simdpp::arch_avx2::uint32<4>â€™ declared here; class uint32<4, void> : public any_int32<4, uint32<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint64<8>; T = simdpp::arch_avx2::uint32<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<8>; T = simdpp::arch_avx2::uint32<16>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<8>; T = simdpp::arch_avx2::uint32<16>]â€™; libsimdpp-2.0-rc2/simdpp/types/int64.h:106:36: required from â€˜simdpp::arch_avx2::uint64<N>& simdpp::arch_avx2::uint64<N>::operator=(const simdpp::arch_avx2::any_vec<(N * 8), V>&) [with V = simdpp::arch_avx2::uint32<16, simdpp::arch_avx2::expr_empty>; unsigned int N = 8]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:590:8: required from â€˜void simdpp::arch_avx2::detail::insn::v_sse_transpose32x4(V&, V&, V&, V&) [with V = simdpp::arch_avx2::uint32<16>; D = simdpp::arch_avx2::uint64<8>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:533:62: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:95851,Mask,MaskCastOverride,95851,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"array of â€˜const class simdpp::arch_avx2::uint64<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:24,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:91:7: note: â€˜class simdpp::arch_avx2::uint32<8>â€™ declared here; class uint32<8, void> : public any_int32<8, uint32<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::float64<4>; T = simdpp::arch_avx2::float32<8>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::float64<4>; T = simdpp::arch_avx2::float32<8>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::float64<4>; T = simdpp::arch_avx2::float32<8>]â€™; libsimdpp-2.0-rc2/simdpp/types/float64x4.h:55:37: required from â€˜simdpp::arch_avx2::float64<4>& simdpp::arch_avx2::float64<4>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::float32<8, simdpp::arch_avx2::expr_empty>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:275:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::float64<4>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::float64<4>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::float32<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:46739,Mask,MaskCastOverride,46739,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"ary. It has happened twice. The failing partition is different in each run. 1. 49340 https://batch.hail.is/batches/8069235/jobs/51280; 2. 25997 https://batch.hail.is/batches/8083195/jobs/27937. The pipeline runs two table collects to get sample information, then converts the matrix table to a table of ndarrays of the value `hl.int(hl.is_defined(mt.GT))`. The entries are getting subsetted, so there is skipping going on. In both cases, we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {""name"":""B",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:995,error,error,995,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623,2,['error'],"['error', 'errors']"
Availability,"as automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - gear/pinned-requirements.txt. <details>; <summary>âš ï¸ <b>Warning</b></summary>. ```; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiohttp 3.8.5 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxNGQyZDIxMi00ZjI4LTQ0OGEtYWRkNS02NThkNDE",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13847:1045,avail,available,1045,https://hail.is,https://github.com/hail-is/hail/pull/13847,1,['avail'],['available']
Availability,"as automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - gear/pinned-requirements.txt. <details>; <summary>âš ï¸ <b>Warning</b></summary>. ```; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiohttp 3.8.5 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-5926907](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-5926907) | `urllib3:` <br> `1.26.16 -> 1.26.17` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4MmZhNTRjZC0yOGI4LTQ3OTUtYWFjNy02MDE0NjY",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13771:1045,avail,available,1045,https://hail.is,https://github.com/hail-is/hail/pull/13771,1,['avail'],['available']
Availability,ase; HAIL_PIP_VERSION=0.2.128 \; HAIL_VERSION=0.2.128-91d328e7fc84 \; GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a \; REMOTE= \; WHEEL=build/deploy/dist/hail-0.2.128-py3-none-any.whl \; GITHUB_OAUTH_HEADER_FILE=abc123 \; HAIL_GENETICS_HAIL_IMAGE=abc123 \; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=a \; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=b \; HAIL_GENETICS_HAILTOP_IMAGE=c \; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=d \; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=e \; WHEEL_FOR_AZURE=f \; WEBSITE_TAR=g \; bash scripts/release.sh; +++ dirname -- scripts/release.sh; ++ cd -- scripts; ++ pwd; + SCRIPT_DIR=/Users/dking/projects/hail/hail/scripts; + arguments='HAIL_PIP_VERSION HAIL_VERSION GIT_VERSION REMOTE WHEEL GITHUB_OAUTH_HEADER_FILE HAIL_GENETICS_HAIL_IMAGE HAIL_GENETICS_HAIL_IMAGE_PY_3_10 HAIL_GENETICS_HAIL_IMAGE_PY_3_11 HAIL_GENETICS_HAILTOP_IMAGE HAIL_GENETICS_VEP_GRCH37_85_IMAGE HAIL_GENETICS_VEP_GRCH38_95_IMAGE WHEEL_FOR_AZURE WEBSITE_TAR'; + for varname in '$arguments'; + '[' -z 0.2.128 ']'; + echo HAIL_PIP_VERSION=0.2.128; HAIL_PIP_VERSION=0.2.128; + for varname in '$arguments'; + '[' -z 0.2.128-91d328e7fc84 ']'; + echo HAIL_VERSION=0.2.128-91d328e7fc84; HAIL_VERSION=0.2.128-91d328e7fc84; + for varname in '$arguments'; + '[' -z 91d328e7fc84686936ffd4f370c8c104b2d78b2a ']'; + echo GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a; GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a; + for varname in '$arguments'; + '[' -z '' ']'; + echo. + usage; + cat; ++ basename scripts/release.sh; ++ basename scripts/release.sh; usage: release.sh. All arguments are specified by environment variables. For example:. HAIL_PIP_VERSION=0.2.123; HAIL_VERSION=0.2.123-abcdef123; GIT_VERSION=abcdef123; REMOTE=origin; WHEEL=/path/to/the.whl; GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123ab,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:14539,echo,echo,14539,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,1,['echo'],['echo']
Availability,"aset['reference_genome'] == reference_genome])]; --> 115 assert len(path) == 1; 116 path = path[0]; 117 if path.startswith('s3://'):. AssertionError: ; ```. I'm a new Hail user and don't have the full context here, but it seems like there are at least three problems:. 1. An assert failed in production code, which indicates either the presence of a bug or an incorrect use of assert (e.g. using assert to check for value errors).; 2. The assert has no corresponding error message, so the user learns that something has gone wrong but can't easily tell what.; 3. The assert is bare. Bare asserts can get optimized out of code in ways that are difficult to foresee in advance, and are generally deprecated in favor of the `if error_condition: raise AssertionError(...)` pattern (see: https://discuss.python.org/t/stop-ignoring-asserts-when-running-in-optimized-mode/13132). **The Big Picture**. The bare assert pattern is used over 3k times in Hail. To be fair, many of these usages occur in test directories, where they're fine. But they also occur in application code, and often in the dangerous form `assert(expr1, expr2)` which will never fail (because a tuple with two falsy elements is truthy in python). These asserts are never actually getting checked. . Fixing all of them would be a heavy lift. One compromise solution might be to add a bare assert rule to the linter (e.g. https://pypi.org/project/flake8-assert-msg/). This would prevent the introduction of further bare asserts to the codebase, and encourage authors to clean up existing bare asserts on files they touch. The `assert` keyword is an unfortunate language wart that makes it very easy for developers to write error-checking code that is itself incorrect. I'd encourage considering the alternate pattern `if error_condition: raise AssertionError(...)` and gradually migrating the codebase off of bare asserts. Thanks for all of your work on Hail!. ### Version. hail 0.2.115-10932c754edb. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12952:2519,error,error-checking,2519,https://hail.is,https://github.com/hail-is/hail/issues/12952,1,['error'],['error-checking']
Availability,"assLoader. That's why ClassLoaders always prefer to load a class from the parent ClassLoader's; classes. When we decide to re-use JVMs or use a single multi-threaded JVM, we'll need to ensure the top-level; ClassLoader *does not have Hail on its classpath*. I looked briefly at this approach and found it; more work than the current approach. ---. My apologies for eliminating JVMProcess in this PR. It's an unrelated change which facilitated my; understanding worker.py. I essentially inlined JVMProcess into JVMJob and eliminated any duplicative; code. ---. After making this change I restored the tests. Some tests had bitrotted. In the process of fixing; those tests, I found a few other bugs. Fixing these lower-level bugs unlocked a number of new; tests. A couple tests (which were added since the service tests were removed) had to be marked as; failing. Here are the bugs I fixed:. 1. Correct the error message raised when tests are run in a non-main thread (we look for this; message and start an event loop for Hail's async code because asyncio refuses to start an event; loop in a non-main thread). 2. Use a `SafeRow` to copy the globals data out of a Region and into durable, GC'ed objects. 3. Re-enable serialization of GoogleStorageFS (including its private key, which we really shouldn't; do; Tim is working on it), which was broken (presumably) when we changed Scala versions. The; `var` modifier ensures the name is compiled as a JVM field. 4. Correctly convert from a `Byte` to an `Int`. By default `Byte` to `Int` conversion (which is done; automatically when you return a `Byte` from a function whose return type is `Int`) is; sign-preserving. That means that the byte `0000 1111` is converted to the `Int` 15 and the byte; `1000 1111` is converted to the `Int` -113. The contract of; [`InputStream.read`](https://docs.oracle.com/javase/8/docs/api/java/io/InputStream.html#read--); is to return the unsigned integeral value of the next `Byte` or `-1` if we've reached the end of; t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10390:1701,error,error,1701,https://hail.is,https://github.com/hail-is/hail/pull/10390,1,['error'],['error']
Availability,assertion error near the end of writing out a VDS to bucket,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1822:10,error,error,10,https://hail.is,https://github.com/hail-is/hail/issues/1822,1,['error'],['error']
Availability,assertion failed error when using concordance,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['error'],['error']
Availability,"ast):; File ""/restricted/projectnb/genpro/github/hail.qc/delly-qc.py"", line 35, in <module>; ds = hl.sample_qc(ds); File ""<decorator-gen-902>"", line 2, in sample_qc; File ""/restricted/projectnb/genpro/github/hail/python/hail/typecheck/check.py"", line 490, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/restricted/projectnb/genpro/github/hail/python/hail/methods/qc.py"", line 91, in sample_qc; return MatrixTable(Env.hail().methods.SampleQC.apply(require_biallelic(dataset, 'sample_qc')._jvds, name)); File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: invalid allele ""<DEL>"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 3.0 failed 4 times, most recent failure: Lost task 2.3 in stage 3.0 (TID 160, scc-q01.scc.bu.edu, executor 4): is.hail.utils.HailException: invalid allele ""<DEL>""; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:29); at is.hail.methods.SampleQCCombiner$.alleleIndices(SampleQC.scala:44); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:178); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:175); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:175); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:170); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:1569,failure,failure,1569,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['failure'],['failure']
Availability,"astOverride>::run(const T&) [with R = simdpp::arch_avx2::int32<8>; T = simdpp::arch_avx2::uint64<4>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int32<8>; T = simdpp::arch_avx2::uint64<4>]â€™; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:55:35: required from â€˜simdpp::arch_avx2::int32<8>& simdpp::arch_avx2::int32<8>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint64<4, simdpp::arch_avx2::expr_bit_and<simdpp::arch_avx2::uint64<4, simdpp::arch_avx2::int32<8> >, simdpp::arch_avx2::uint64<4, simdpp::arch_avx2::uint64<4> > > >]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:305:32: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::int32<8>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::int32<8>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint64<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:24,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:32:7: note: â€˜class simdpp::arch_avx2::int32<8>â€™ declared here; class int32<8, void> : public any_int32<8, int32<8,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::int8<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:82190,error,error,82190,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"astOverride>::run(const T&) [with R = simdpp::arch_avx2::int64<2>; T = simdpp::arch_avx2::uint64<2>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int64<2>; T = simdpp::arch_avx2::uint64<2>]â€™; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:60:35: required from â€˜simdpp::arch_avx2::int64<2>& simdpp::arch_avx2::int64<2>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint64<2>]â€™; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:53:73: required from â€˜simdpp::arch_avx2::int64<2>::int64(const simdpp::arch_avx2::uint64<2, E>&) [with E = void]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:277:25: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::int64<2>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::int64<2>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint64<2>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:26,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:33:7: note: â€˜class simdpp::arch_avx2::int64<2>â€™ declared here; class int64<2, void> : public any_int64<2, int64<2,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int64<4>; T = simdpp::arch_avx2::uint64<4>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:108904,error,error,108904,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"astOverride>::run(const T&) [with R = simdpp::arch_avx2::int64<4>; T = simdpp::arch_avx2::uint64<4>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int64<4>; T = simdpp::arch_avx2::uint64<4>]â€™; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:55:35: required from â€˜simdpp::arch_avx2::int64<4>& simdpp::arch_avx2::int64<4>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint64<4>]â€™; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:48:73: required from â€˜simdpp::arch_avx2::int64<4>::int64(const simdpp::arch_avx2::uint64<4, E>&) [with E = void]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:307:25: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::int64<4>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::int64<4>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint64<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:27,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:32:7: note: â€˜class simdpp::arch_avx2::int64<4>â€™ declared here; class int64<4, void> : public any_int64<4, int64<4,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int8<32>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:110852,error,error,110852,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"at __C2005collect_distributed_array_matrix_native_writer.apply_region1_27(Unknown Source); 	at __C2005collect_distributed_array_matrix_native_writer.apply(Unknown Source); 	at __C2005collect_distributed_array_matrix_native_writer.apply(Unknown Source); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$6(BackendUtils.scala:52); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$5(BackendUtils.scala:51); 	at is.hail.backend.spark.SparkBackendComputeRDD.compute(SparkBackend.scala:751); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). is.hail.utils.HailException: cannot set missing field for required type +PCString; ```. Notice in particular:; ```; AS_VQSLOD=.,.;AS_YNG=.,.; ```; These fields are array fields containing missing values. By default, Hail errors when parsing these due to the inherent ambiguity of a single dot: is it a missing array or an array with one, missing, element. The error message should suggest that the user try using array_elements_required. The docs for `import_vcf` should provide enough information for the user to understand what this does. We should also consider making this the default. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13346:2871,error,errors,2871,https://hail.is,https://github.com/hail-is/hail/issues/13346,2,['error'],"['error', 'errors']"
Availability,"at is.hail.annotations.Region$.scoped(Region.scala:18); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:9); 	at is.hail.backend.Backend.execute(Backend.scala:56); 	at is.hail.backend.Backend.executeJSON(Backend.scala:62); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:745). org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3, localhost, executor driver): is.hail.utils.HailException: Hail only supports 8-bit probabilities, found 16.; 	at is.hail.codegen.generated.C_bgen_rdd_decoder_13.apply(Unknown Source); 	at is.hail.codegen.generated.C_bgen_rdd_decoder_13.apply(Unknown Source); 	at is.hail.io.bgen.BgenRecordIteratorWithoutFilter.next(BgenRDD.scala:222); 	at is.hail.io.bgen.BgenRecordIteratorWithoutFilter.next(BgenRDD.scala:206); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410); 	at scala.collection.TraversableOnce$FlattenOps$$anon$1.hasNext(TraversableOnce.scala:464); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); 	at scala.collection.Iterator$class.foreach(Iterator.scala:891); 	at scala.collection.AbstractIterator.foreach(Iterato",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:4093,failure,failure,4093,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['failure'],['failure']
Availability,"at is.hail.annotations.Region$.scoped(Region.scala:18); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:9); 	at is.hail.backend.Backend.execute(Backend.scala:77); 	at is.hail.backend.Backend.executeJSON(Backend.scala:96); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). org.apache.spark.SparkException: Job aborted due to stage failure: Task 40 in stage 7.0 failed 20 times, most recent failure: Lost task 40.19 in stage 7.0 (TID 3171, seqr-loading-cluster-sw-z91p.c.seqr-project.internal, executor 14): is.hail.utils.HailException: cannot set missing field for required type +PCStruct{info:PCStruct{ALLELEID:PInt32}}; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:74); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:210); 	at is.hail.rvd.RVD$$anonfun$24$$anonfun$apply$17.apply(RVD.scala:974); 	at is.hail.rvd.RVD$$anonfun$24$$anonfun$apply$17.apply(RVD.scala:967); 	at is.hail.utils.FlipbookIterator$$anon$5.<init>(FlipbookIterator.scala:176); 	at is.hail.utils.FlipbookIterator.map(FlipbookIterator.scala:174); 	at is.hail.utils.FlipbookIterator.map(FlipbookIterator.scala:145); 	at is.hail.rvd.RVD$$anonfun$24.apply(RVD.scala:967); 	at is.hail.rvd.RVD$$anonfun$24.apply(RVD.scala:963); 	at is.hail.rvd.KeyedRVD$$anonf",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:51113,failure,failure,51113,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['failure'],['failure']
Availability,"at java.lang.reflect.Method.invoke(Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); 	... 7 more; Caused by: is.hail.backend.service.EndOfInputException; 	at is.hail.backend.service.ServiceBackendSocketAPI2.read(ServiceBackend.scala:497); 	at is.hail.backend.service.ServiceBackendSocketAPI2.readInt(ServiceBackend.scala:510); 	at is.hail.backend.service.ServiceBackendSocketAPI2.executeOneCommand(ServiceBackend.scala:561); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6(ServiceBackend.scala:462); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6$adapted(ServiceBackend.scala:461); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$5(ServiceBackend.scala:461); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:141); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4(ServiceBackend.scala:460); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4$adapted(ServiceBackend.scala:459); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$3(ServiceBackend.scala:459); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:141); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.main(ServiceBackend.scala:458); 	at is.hail.backend.service.Main$.main(Main.scala:15); 	at is.hail.backend.service.Main.main(Main.scala); 	... 11 more; ```. Which suggests that the service backend experienced an EOF somewhere in the first four bytes of the input file. Unfortunately, we automatically cleanup the input and output files, so I can't investigate further. This PR reads the input and output files and stores them in the error message so that next time this happens we get more information.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13160:6913,error,error,6913,https://hail.is,https://github.com/hail-is/hail/pull/13160,1,['error'],['error']
Availability,atReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:170); at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:45); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:108); at scala.colle,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:2966,Heartbeat,HeartbeatReceiver,2966,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Heartbeat'],['HeartbeatReceiver']
Availability,"ataproc/bdutil/configure_docker.sh; /run/docker.sock; /tmp/dataproc/uninstall/docker-ce; /tmp/dataproc/components/uninstall/docker-ce.running; /tmp/dataproc/components/uninstall/docker-ce.done; /tmp/dataproc/components/pre-uninstall/docker-ce.running; /tmp/dataproc/components/pre-uninstall/docker-ce.done; /etc/apt/preferences.d/docker-ce.pref; /etc/apt/preferences.d/docker-ce-cli.pref; /etc/apt/sources.list.d/docker.list; /var/lib/apt/lists/download.docker.com_linux_debian_dists_buster_InRelease; /var/lib/apt/lists/download.docker.com_linux_debian_dists_buster_stable_binary-amd64_Packages; ```. </details>. There is a `/run/docker.sock` but notice it is not `/var/run/...`. However, if I install Docker by hand into this worker of a *non-Hail* Dataproc cluster, it just works. ---. I also tried to replicate the failure using an initialization action, but that also just worked.; ```; gcloud dataproc clusters create dk-test2 --initialization-actions=gs://hail-common/dk-test.sh; ```; `gs://hail-common/dk-test.sh`:; ```; apt-get update; apt-get -y install \; apt-transport-https \; ca-certificates \; curl \; gnupg2 \; software-properties-common \; tabix; curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -; sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable""; apt-get update; apt-get install -y --allow-unauthenticated docker-ce; ```. ---. Our users often report this error. In my experience, it has happened in 2/8 test_dataproc steps that I have run myself or seen run. The more workers you have, the higher the chance at least one worker fails. As @bpblanken suggested [here](https://github.com/hail-is/hail/issues/12936#issuecomment-1589956412), restarting docker on a failed worker works. Docker starts fine. However, I missed a subtlety: we must restart *after* installation but *before* we try to pull our VEP docker image. I also added a sleep in hopes that gives various things a chance to die off.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936#issuecomment-1709120751:13711,down,download,13711,https://hail.is,https://github.com/hail-is/hail/issues/12936#issuecomment-1709120751,3,"['down', 'error']","['download', 'error']"
Availability,"atch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:20:42,418"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:20:49,707"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: Object of type 'datetime' is not JSON serializable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 608, in mark_complete\n json.dumps(pod_status.to_dict()))\n File \""/usr/lib/python3.6/json/__init__.py\"", line 231, in dumps\n return _default_encoder.encode(obj)\n File \""/usr/lib/python3.6/json/encoder.py\"", line 199, in encode\n chunks = self.iterencode(o, _one_shot=T",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6707:1722,ERROR,ERROR,1722,https://hail.is,https://github.com/hail-is/hail/issues/6707,1,['ERROR'],['ERROR']
Availability,"atch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:21:41,499"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:22:42,128"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:23:31,398"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6707:4685,ERROR,ERROR,4685,https://hail.is,https://github.com/hail-is/hail/issues/6707,1,['ERROR'],['ERROR']
Availability,"atch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:22:42,128"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:23:31,398"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:25:18,329"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6707:5536,ERROR,ERROR,5536,https://hail.is,https://github.com/hail-is/hail/issues/6707,1,['ERROR'],['ERROR']
Availability,"atch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:23:31,398"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:25:18,329"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: Object of type 'datetime' is not JSON serializable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 608, in mark_complete\n json.dumps(pod_status.to_dict()))\n File \""/usr/lib/python3.6/json/__init__.py\"", line 231, in dumps\n return _default_encoder.encode(obj)\n File \""/usr/lib/python3.6/json/encoder.py\"", line 199, in encode\n chunks = self.iterencode(o, _one_shot=T",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6707:6387,ERROR,ERROR,6387,https://hail.is,https://github.com/hail-is/hail/issues/6707,1,['ERROR'],['ERROR']
Availability,ate.evaluateToJSON(CompileAndEvaluate.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:745). is.hail.utils.HailException: foo: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; offending line: 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:20); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.utils.Context.wrapException(Context.scala:19); 	at is.hail.utils.WithContext.wrap(Context.scala:43); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:375); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:575); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:573); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.apply(ContextRDD.scala:405); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.apply(ContextRDD.scala:405); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:10219,Error,ErrorHandling,10219,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['Error'],['ErrorHandling']
Availability,ate.scala:45); at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:600); at is.hail.backend.spark.SparkBackend.$anonfun$execute$4(SparkBackend.scala:636); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); at is.hail.backend.spark.SparkBackend.$anonfun$execute$3(SparkBackend.scala:631); at is.hail.backend.spark.SparkBackend.$anonfun$execute$3$adapted(SparkBackend.scala:630); at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); at is.hail.utils.package$.using(package.scala:664); at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); at is.hail.utils.package$.using(package.scala:664); at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); at is.hail.backend.spark.SparkBackend.$anonfun$withExecuteContext$2(SparkBackend.scala:407); at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:393); at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:630); at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:79); at sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:83); at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:82); at sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:822); at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:79); at sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:794); at sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:199); at sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:544); at sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:509); at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.127-d82c34a83360; Error summary: NullPointerException: null; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14249:7469,Error,Error,7469,https://hail.is,https://github.com/hail-is/hail/issues/14249,1,['Error'],['Error']
Availability,"ate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.5</h2>; <p>Maintenance:</p>; <ul>; <li>Publish signed artifacts to Gradle plugin portal</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.4</h2>; <p>Bug fixes:</p>; <ul>; <li>Fix deadlock in <code>DownloadExtension</code> if <code>max-workers</code> equals 1 (thanks to <a href=""https://github.com/beatbrot""><code>@â€‹beatbrot</code></a> for spotting this, see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/205"">#205</a>)</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1b5d69760d19cb7f88cbc837ee46456c494c0696""><code>1b5d697</code></a> Bump up version number to 5.2.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/7d6de83037ca41cd2f2f31830b43e43720e45b3a""><code>7d6de83</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1da8f078e22412475b694ce07b890148b8a5e4fc""><code>1da8f07</code></a> Add comment</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/9703f764df56c52626f7d6f44bca8b1d51312389""><code>9703f76</code></a> Use pooling connection manager instead of basic one</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/306172e4c6532e185c8a6a9998bca7d22d2d0c63""><code>306172e</code></a> Bump up version number to 5.2.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b9df0c0daa080450772c365f16a9406fe0ca607a""><code>b9df0c0</code></a> Document eachFile action</li>; <li><a href=""https://github.com/michel",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:3048,down,download-task,3048,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['down'],['download-task']
Availability,"ated by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - gear/requirements.txt. <details>; <summary>âš ï¸ <b>Warning</b></summary>. ```; kubernetes-asyncio 19.15.1 requires aiohttp, which is not installed.; aiohttp-session 2.12.0 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14039:1078,avail,available,1078,https://hail.is,https://github.com/hail-is/hail/pull/14039,1,['avail'],['available']
Availability,"ated size 34.3 KiB, free 434.4 MiB); 2022-05-14 12:09:09 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 434.4 MiB); 2022-05-14 12:09:09 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on 10.40.3.21:33951 (size: 3.2 KiB, free: 434.4 MiB); 2022-05-14 12:09:09 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:311; 2022-05-14 12:09:11 root: INFO: RegionPool: FREE: 64.0K allocated (64.0K blocks / 0 chunks), regions.size = 1, 0 current java objects, thread 30: Thread-4; 2022-05-14 12:09:11 root: ERROR: HailException: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; From is.hail.utils.HailException: /data/public/prs/ex_antonk.bim:1013423: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; offending line: 11	.	0	135009883	CT	C; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:30); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:28); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.utils.Context.wrapException(Context.scala:21); 	at is.hail.utils.WithContext.foreach(Context.scala:51); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2(LoadPlink.scala:37); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2$adapted(LoadPlink.scala:36); 	at scala.collection.Iterator.foreach(Iterator.scala:941); 	at scala.collection.Iterator.foreach$(Iterator.scala:941); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1(LoadPlink.scala:36); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1$adapted(LoadPlink.scala:35); 	at is.hail.io.fs.FS.$anonfun$readLines$1(FS.scala:222); 	at is.hail.utils.package$.using(package.scala:640); 	at is.hail.io.fs.FS.readLines(FS.scala:213); 	at is.hail.io.fs.FS.readLines$(FS.scala:211); 	at is.hail.io.fs.HadoopFS.readL",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:1555,Error,ErrorHandling,1555,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['Error'],['ErrorHandling']
Availability,"ates (including the; > VeriSign root certs that signed the public certs that gateway uses, different; > from the internal certs that our services use).; >; > In particular, note that the error says ""unable to get local issuer; > certificate."" That means that the local trust store lacks a certificate that; > trusts the remote server's certificate. In Dania's case, the default python on; > OS X lacks all certificates, so every remote server is untrusted. In notebook's; > case, ssl_client_session creates an SSL/TLS session that only trusts Hail; > internal services (in particular, it does not trust the certificates that; > gateway uses for incoming public traffic). The error also says that the server; > in question is workshop.hail.is which is a public domain (note the hail.is), so; > that traffic is going through the public gateway with its public certificates.; >; > ```; > # don't have dev credentials to connect through internal.hail.is; > ready_url = deploy_config.external_url(; > service,; > f'/instance/{notebook[""notebook_token""]}/?token={notebook[""jupyter_token""]}'); > try:; > async with ssl_client_session(; > timeout=aiohttp.ClientTimeout(total=1),; > headers=headers,; > cookies=cookies) as session:; > async with session.get(ready_url) as resp:; > ```. I also changed the names and functionality of the functions in tls. Now; `in_cluster_ssl_context` will error if there is no ssl configuration found; instead of silently (and confusingly) using an SSLContext suited for public; communication (and wrong for in-cluster communication). I added `get_context_specific_client_ssl_context` which should only be used in; publicly consumable tools (*never* in a service). This function allows the same; tool to be used inside and outside the cluster. It will load the correct certs; for your environment (it will load public certs if you're outside the cluster,; it will load in-cluster-only certs if you're in the cluster). I also added types to `tls.py` and fixed some type errors.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9120:1792,error,error,1792,https://hail.is,https://github.com/hail-is/hail/pull/9120,2,['error'],"['error', 'errors']"
Availability,"atingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). During handling of the above exception, another exception occurred:. Py4JJavaError Traceback (most recent call last); /bmrn/apps/hail/0.2.72-spark-3.1.2/python/hail-0.2.72-py3-none-any.egg/hail/backend/py4j_backend.py in deco(*args, **kwargs); 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:. /bmrn/apps/python/miniconda/64/3.7/envs/piranha_0.2.0_20210812/lib/python3.7/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 327 ""An error occurred while calling {0}{1}{2}.\n"".; --> 328 format(target_id, ""."", name), value); 329 else:. Py4JJavaError: An error occurred while calling z:is.hail.backend.spark.SparkBackend.apply.; : java.lang.IllegalArgumentException: requirement failed; 	at scala.Predef$.require(Predef.scala:268); 	at is.hail.backend.spark.SparkBackend$.apply(SparkBackend.scala:218); 	at is.hail.backend.spark.SparkBackend.apply(SparkBackend.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10590#issuecomment-899322610:4656,error,error,4656,https://hail.is,https://github.com/hail-is/hail/issues/10590#issuecomment-899322610,1,['error'],['error']
Availability,"ation_1519994715701_0003/container_1519994715701_0003_01_000102/stderr. 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:972); 	at org.apache.hadoop.util.Shell.run(Shell.java:869); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1170); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:236); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:305); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:84); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 134; ```; When I dig into the container logs, the stdout is empty on most, stderr is full of warnings, but no errors:; ```; 18/03/02 15:28:07 WARN com.google.cloud.hadoop.gcsio.GoogleCloudStorageReadChannel: Channel for 'gs://gnomad/coverage/hail-0.2/coverage/exomes/parts/part_partition1049.vds/entries/rows/parts/part-0095' is not open.; ```; But then one machine I logged into had:; ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fa70eb59074, pid=4361, tid=0x00007fa707702700; #; # JRE version: OpenJDK Runtime Environment (8.0_131-b11) (build 1.8.0_131-8u131-b11-1~bpo8+1-b11); # Java VM: OpenJDK 64-Bit Server VM (25.131-b11 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libconscrypt_openjdk_jni.so+0x43074]; [error occurred during error reporting (printing problematic frame), id 0xb]. # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more infor",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3053:3919,error,errors,3919,https://hail.is,https://github.com/hail-is/hail/issues/3053,1,['error'],['errors']
Availability,"ator.scala:435); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); 	at scala.collection.Iterator$class.foreach(Iterator.scala:891); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1334); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1334); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.2.31-6060f9c971cc; Error summary: HailException: Hail only supports 8-bit probabilities, found 16. How can I solve it? Or why is it happening?. Thank you very much!. Kind regards,; Catarina",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:19854,Error,Error,19854,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['Error'],['Error']
Availability,"ators$.apply(Compile.scala:249); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:618); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:50); 	at is.hail.table.Table.aggregate(Table.scala:373); 	at is.hail.table.Table.aggregate(Table.scala:369); 	at is.hail.table.Table.aggregateJSON(Table.scala:364); 	at sun.reflect.GeneratedMethodAccessor45.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-414f3f183bd5; Error summary: RuntimeException: Class file too large!; ```; Code was:; ```; cutoff = 10. agg_expr = {; 'downsampling': hl.agg.collect(ht.downsamplings)[0]; }; locations = list(zip(('syn', 'mis', 'lof'), ('', '', '_classic_hc'))); agg_expr.update({; f'median_expected_{var}_{pop}': [hl.median(hl.agg.collect(ht[f'exp_{var}_{pop}{var_loc}'][i])) for i in range(length)]; for length, pop in pop_lengths; for var, var_loc in locations; }); agg_expr.update({; f'median_observed_{var}_{pop}': [hl.median(hl.agg.collect(ht[f'obs_{var}_{pop}{var_loc}'][i])) for i in range(length)]; for length, pop in pop_lengths; for var, var_loc in locations; }); agg_expr.update({; f'mean_expected_{var}_{pop}': [hl.agg.mean(ht[f'exp_{var}_{pop}{var_loc}'][i]) for i in range(length)]; for length, pop in pop_lengths; for var, var_loc in locations; }); agg_expr.update({; f'mean_observed_{var}_{pop}': [hl.agg.mean(ht[f'obs_{var}_{pop}{var_loc}'][i]) for i in range(length)]; for length, pop in pop_lengths; for var, var_loc in locations; }); agg_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4516:1826,Error,Error,1826,https://hail.is,https://github.com/hail-is/hail/issues/4516,1,['Error'],['Error']
Availability,attribute name for compatibility with &lt;code&gt;pytest-xdist&lt;/code&gt; 2. (&lt;code&gt;[#305](https://github.com/pytest-dev/pytest-html/issues/305) &amp;lt;https://github.com/pytest-dev/pytest-html/issues/305&amp;gt;&lt;/code&gt;_)&lt;/p&gt;; &lt;ul&gt;; &lt;li&gt;Thanks to &lt;code&gt;@Zac-HD &amp;lt;https://github.com/Zac-HD&amp;gt;&lt;/code&gt;_ for the fix&lt;/li&gt;; &lt;/ul&gt;; &lt;/li&gt;; &lt;li&gt;; &lt;p&gt;Post process HTML generation to allow teardown to appear in the HTML output. (&lt;code&gt;[#131](https://github.com/pytest-dev/pytest-html/issues/131) &amp;lt;https://github.com/pytest-dev/pytest-html/issues/131&amp;gt;&lt;/code&gt;_)&lt;/p&gt;; &lt;ul&gt;; &lt;li&gt;Thanks to &lt;code&gt;@iwanb &amp;lt;https://github.com/iwanb&amp;gt;&lt;/code&gt;_ for reporting and &lt;code&gt;@csm10495 &amp;lt;https://github.com/csm10495&amp;gt;&lt;/code&gt;_ for the fix&lt;/li&gt;; &lt;/ul&gt;; &lt;/li&gt;; &lt;/ul&gt;; &lt;p&gt;2.1.1 (2020-03-18)&lt;/p&gt;; &lt;pre&gt;&lt;code&gt;; * Fix issue with funcargs causing failures. (`[#282](https://github.com/pytest-dev/pytest-html/issues/282) &amp;lt;https://github.com/pytest-dev/pytest-html/issues/282&amp;gt;`_). * Thanks to `@ssbarnea &amp;lt;https://github.com/ssbarnea&amp;gt;`_ for reporting and `@christiansandberg &amp;lt;https://github.com/christiansandberg&amp;gt;`_ for the fix. 2.1.0 (2020-03-09); &lt;/code&gt;&lt;/pre&gt;; &lt;!-- raw HTML omitted --&gt;; &lt;/blockquote&gt;; &lt;p&gt;... (truncated)&lt;/p&gt;; &lt;/details&gt;; &lt;details&gt;; &lt;summary&gt;Commits&lt;/summary&gt;. &lt;ul&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/a1639ef4d9bdc89daa037fd0bfc003bdf2e99865&quot;&gt;&lt;code&gt;a1639ef&lt;/code&gt;&lt;/a&gt; Update CHANGES.rst (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/411&quot;&gt;#411&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/727b305a5707a937b42789436,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11524:12878,failure,failures,12878,https://hail.is,https://github.com/hail-is/hail/pull/11524,1,['failure'],['failures']
Availability,"ature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: . current master. ### What you did:. Read in a giant table of phenotypes (~500k rows x ~3k columns). `; raw_phenos = hl.import_table('gs://phenotype_31063/ukb31063.raw_phenotypes.tsv.bgz',; key='eid', impute=True, types={'eid': hl.tstr}, missing='NA', min_partitions=100); raw_phenos.write('gs://armartin/disparities/ukbb_afr/ukb31063.raw_phenotypes.ht'); `; ### What went wrong (all error messages here, including the full java stack trace):. [Stage 1:> (0 + 100) / 100]Traceback (most recent call last):; File ""/tmp/0fdaf26ceb274d679f571483f658e509/run_prs_afr.py"", line 266, in <module>; main(args); File ""/tmp/0fdaf26ceb274d679f571483f658e509/run_prs_afr.py"", line 125, in main; raw_phenos.write('gs://armartin/disparities/ukbb_afr/ukb31063.raw_phenotypes.ht'); File ""<decorator-gen-652>"", line 2, in write; File ""/tmp/0fdaf26ceb274d679f571483f658e509/hail-devel-5dfbe2ec29f8.zip/hail/typecheck/check.py"", line 546, in wrapper; File ""/tmp/0fdaf26ceb274d679f571483f658e509/hail-devel-5dfbe2ec29f8.zip/hail/table.py"", line 1218, in write; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/0fdaf26ceb274d679f571483f658e509/hail-devel-5dfbe2ec29f8.zip/hail/utils/java.py"", line 210, in deco; hail.utils.java.FatalError: NumberFormatException: For input string: ""1001101010010110"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 46 in stage 1.0 failed 20 times, most recent failure: Lost task 46.19 in stage 1.0 (TID 1559, arm-sw-vq41.c.daly-ibd.internal, executor 6): is.hail.utils.HailException: ukb31063.raw_phenotypes.tsv.bgz: java.lang.NumberFormatException: could not convert ""1001101010010110"" to int32 in column ""10145-0.3""; offending line: 3314275 NA 1 NA NA NA NA NA 0 1959 31 NA NA 36 NA NA 98 NA N...",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4268:1671,failure,failure,1671,https://hail.is,https://github.com/hail-is/hail/issues/4268,2,['failure'],['failure']
Availability,"atures:</p>; <ul>; <li>Add possibility to set request <code>method</code> and <code>body</code></li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; <li>Improve documentation</li>; <li>Add integration tests for Gradle 8.0.1</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4c983ed5cd229fa64912294737c858c2ba8486d6""><code>4c983ed</code></a> Bump up version number to 5.4.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/cc20442ab67bf37687c08e67af7e7de3a21c8fbe""><code>cc20442</code></a> Add integration tests for Gradle 8.0.2</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/472920e572e4cf45d321868874ced50ad8d1e2d5""><code>472920e</code></a> Add possibility to set request method and body</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/82e70cae2a8d48b4f5165a9b543d4e65bb793d88""><code>82e70ca</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86a15f1c16eb729dc71b6caf30237d07b8e0bb01""><code>86a15f1</code></a> Fix compiler warnings and deprecations</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86363072c8239330b28976109a622bdd073507b6""><code>8636307</code></a> Negative timeouts are actually not allowed</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4ff0ff0e63e0dd45f231990d0dcebffde6e6b709""><code>4ff0ff0</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a1858b494b5f3a51ccef7580c243c6dfdf520731""><code>a1858b4</code></a> Merge pull request <a href=""https://redirect.github.com/michel-kraemer/gradle-download-task/issues/295"">#295</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/c1e21",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:1278,down,download-task,1278,https://hail.is,https://github.com/hail-is/hail/pull/12893,1,['down'],['download-task']
Availability,"atus 'done'; 958 | amazon-ebs: Collecting plotly<5.11,>=5.5.0; 959 | amazon-ebs: Downloading plotly-5.10.0-py2.py3-none-any.whl (15.2 MB); 960 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 15.2/15.2 MB 57.8 MB/s eta 0:00:00; 961 | amazon-ebs: Collecting PyJWT; 962 | amazon-ebs: Downloading PyJWT-2.5.0-py3-none-any.whl (20 kB); 963 | amazon-ebs: Collecting python-json-logger==2.0.2; 964 | amazon-ebs: Downloading python_json_logger-2.0.2-py3-none-any.whl (7.4 kB); 965 | amazon-ebs: Collecting requests==2.25.1; 966 | amazon-ebs: Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB); 967 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 61.2/61.2 kB 15.6 MB/s eta 0:00:00; 968 | amazon-ebs: Requirement already satisfied: scipy<1.8,>1.2 in /usr/local/lib64/python3.7/site-packages (1.7.3); 969 | amazon-ebs: Requirement already satisfied: sortedcontainers==2.4.0 in /usr/local/lib/python3.7/site-packages (2.4.0); 970 | amazon-ebs: Collecting tabulate==0.8.9; 971 | amazon-ebs: Downloading tabulate-0.8.9-py3-none-any.whl (25 kB); 972 | amazon-ebs: Requirement already satisfied: tqdm==4.* in /usr/local/lib/python3.7/site-packages (4.64.1); 973 | amazon-ebs: Collecting uvloop==0.16.0; 974 | amazon-ebs: Downloading uvloop-0.16.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.8 MB); 975 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.8/3.8 MB 113.0 MB/s eta 0:00:00; 976 | ==> amazon-ebs: ERROR: Ignored the following versions that require a different python version: 1.22.0 Requires-Python >=3.8; 1.22.0rc1 Requires-Python >=3.8; 1.22.0rc2 Requires-Python >=3.8; 1.22.0rc3 Requires-Python >=3.8; 1.22.1 Requires-Python >=3.8; 1.22.2 Requires-Python >=3.8; 1.22.3 Requires-Python >=3.8; 1.22.4 Requires-Python >=3.8; 1.23.0 Requires-Python >=3.8; 1.23.0rc1 Requires-Python >=3.8; 1.23.0rc2 Requires-Python >=3.8; 1.23.0rc3 Requires-Python >=3.8; 1.23.1 Requires-Python >=3.8; 1.23.2 Requires-Python >=3.8; 1.23.3 Requires-Python >=3.8; 1.4.0 Requires-Py",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:7415,Down,Downloading,7415,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,"auth.py"", line 86, in wrapped; return await fun(request, userdata, *args, **kwargs); File ""/usr/local/lib/python3.6/dist-packages/batch/front_end/front_end.py"", line 383, in ui_get_job_log; 'job_log': await _get_job_log(request.app, batch_id, job_id, user); File ""/usr/local/lib/python3.6/dist-packages/batch/front_end/front_end.py"", line 112, in _get_job_log; job_log = await job._read_logs(); File ""/usr/local/lib/python3.6/dist-packages/batch/batch.py"", line 49, in _read_logs; return await self.app['driver'].read_pod_logs(self._pod_name); File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 160, in __getitem__; return self._state[key]; KeyError: 'driver'; ```. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.6/dist-packages/google/cloud/storage/blob.py"", line 636, in download_to_file; self._do_download(transport, file_obj, download_url, headers, start, end); File ""/usr/local/lib/python3.6/dist-packages/google/cloud/storage/blob.py"", line 574, in _do_download; download.consume(transport); File ""/usr/local/lib/python3.6/dist-packages/google/resumable_media/requests/download.py"", line 171, in consume; self._process_response(result); File ""/usr/local/lib/python3.6/dist-packages/google/resumable_media/_download.py"", line 171, in _process_response; response, _ACCEPTABLE_STATUS_CODES, self._get_status_code; File ""/usr/local/lib/python3.6/dist-packages/google/resumable_media/_helpers.py"", line 96, in require_status_code; *status_codes; google.resumable_media.common.InvalidResponse: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py"", line 418, in start; resp = await task; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 458, in _handle; resp = await handler(request); File ""/usr/l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7412:1933,down,download,1933,https://hail.is,https://github.com/hail-is/hail/pull/7412,1,['down'],['download']
Availability,"automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. <details>; <summary>âš ï¸ <b>Warning</b></summary>. ```; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiohttp 3.8.5 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **551/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `41.0.2 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13370:1046,avail,available,1046,https://hail.is,https://github.com/hail-is/hail/pull/13370,1,['avail'],['available']
Availability,ava:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); 	Suppressed: is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-2LzGioRNy6RqIS2pfXIoSO&uploadType=resumable&upload_id=ADPycdvZ5HhnGfOKt5TE1qXWiHpqIpZnXVTYWuWUCXNPRF9HqyCB-4LvRsxNX6SUWRgk13pYrzYaa9-wXlvNZt1oct0ptaEz0bS3; chunkOffset: 16777216; chunkLength: 16777216; localOffset: 268435456; remoteOffset: 285212672; lastChunk: false. 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:267); 		at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911:5094,recover,recover,5094,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911,1,['recover'],['recover']
Availability,ava:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); 	Suppressed: is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-6BO4gZ18Lheigp3ir9RSOh&uploadType=resumable&upload_id=ADPycduiXx2Jtiy_0Ll131_pPeEYKnnA23Hlk28_9TFESUMaubA9OqLK_n8Td5rPhTXnlpssGo796Q4bJxUeblhmSaYcCSWAMg2k; chunkOffset: 16777216; chunkLength: 16777216; localOffset: 1325400064; remoteOffset: 1342177280; lastChunk: false. 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:267); 		at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756:4901,recover,recover,4901,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756,2,['recover'],['recover']
Availability,"ava:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). During handling of the above exception, another exception occurred:. Py4JJavaError Traceback (most recent call last); /bmrn/apps/hail/0.2.72-spark-3.1.2/python/hail-0.2.72-py3-none-any.egg/hail/backend/py4j_backend.py in deco(*args, **kwargs); 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:. /bmrn/apps/python/miniconda/64/3.7/envs/piranha_0.2.0_20210812/lib/python3.7/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 327 ""An error occurred while calling {0}{1}{2}.\n"".; --> 328 format(target_id, ""."", name), value); 329 else:. Py4JJavaError: An error occurred while calling z:is.hail.backend.spark.SparkBackend.apply.; : java.lang.IllegalArgumentException: requirement failed; 	at scala.Predef$.require(Predef.scala:268); 	at is.hail.backend.spark.SparkBackend$.apply(SparkBackend.scala:218); 	at is.hail.backend.spark.SparkBackend.apply(SparkBackend.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(T",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10590#issuecomment-899322610:4776,error,error,4776,https://hail.is,https://github.com/hail-is/hail/issues/10590#issuecomment-899322610,1,['error'],['error']
Availability,"avigate to `http://localhost:3000`. \# lines: Most come from the package.json.lock files. These maintain versioning information.; * [It is recommended to check in .lock files]( https://stackoverflow.com/questions/44206782/do-i-commit-the-package-lock-json-file-created-by-npm-5); * They're huge, sorry.; # Documentation; ### JS; https://javascript.info. We use the subset termed [ES2018](https://flaviocopes.com/es2018/). Compatibility across all browsers is ensured by [transpilation using BabelJS, to some lower JS target](https://babeljs.io/docs/en/). Polyfills should not be used, except when impossible to support a browser (this is configurable). I mostly don't care about anything that isn't an evergreen browser, so I think we should support: Edge, Safari, Chrome, Firefox. Among those we *may* want to care about, [IE11 has ~2% global use (more if only desktop browsers)](https://caniuse.com/#feat=flexbox); ### NodeJS; We use 10.15. [This is the latest LTS release](https://nodejs.org/en/download/). ### Versioning / dependency management; TL;DR: `npm`; ```sh; npm init # creates a package.json file, which tracks dependencies; npm install next react react-dom # install 3 packages and save them to the dependencies property; ```. #### package.json; The file that tracks dependencies, and their semantic versioning numbers. Shape:; ```json; {; ""name"": ""hail-web-client"",; ""version"": ""0.2.0"",; ""scripts"": {; ""dev"": ""next"",; ""build"": ""next build"",; ""start"": ""NODE_ENV=production SSL=true next start""; },; ""author"": ""Hail Team"",; ""license"": ""MIT"",; ""dependencies"": {; ""next"": ""^7.0.2-canary.50"",; ""react"": ""^16.7.0"",; ""react-dom"": ""^16.7.0""; },; ""devDependencies"": {; }; }; ```; * Scripts are thing that can be run by typing, in shell `npm run`. Ex: `npm run dev`. ### Async, Await, Promises and callback (WIP); Javascript is async-first. This is most obvious in Node.js, which is the most popular library for server-side JS.; * [How event loop works](https://nodejs.org/en/docs/guides/event-l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:2216,down,download,2216,https://hail.is,https://github.com/hail-is/hail/pull/5162,1,['down'],['download']
Availability,"avro) to permit the latest version.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/apache/avro/releases"">avro's releases</a>.</em></p>; <blockquote>; <h2>Apache Avro 1.11.0</h2>; <p>The Apache Avro community is pleased to announce the release of Avro 1.11.0!</p>; <p>All signed release artifacts, signatures and verification instructions can; be found here: <a href=""https://avro.apache.org/releases.html"">https://avro.apache.org/releases.html</a></p>; <p>This release includes 120 Jira issues, including some interesting features:</p>; <p>Specification: AVRO-3212 Support documentation tags for FIXED types; C#: AVRO-2961 Support dotnet framework 5.0; C#: AVRO-3225 Prevent memory errors when deserializing untrusted data; C++: AVRO-2923 Logical type corrections; Java: AVRO-2863 Support Avro core on android; Javascript: AVRO-3131 Drop support for node.js 10; Perl: AVRO-3190 Fix error when reading from EOF; Python: AVRO-2906 Improved performance validating deep record data; Python: AVRO-2914 Drop Python 2 support; Python: AVRO-3004 Drop Python 3.5 support; Ruby: AVRO-3108 Drop Ruby 2.5 support</p>; <p>For the first time, the 1.11.0 release includes experimental support for; Rust. Work is continuing on this donated SDK, but we have not versioned and; published official artifacts for this release.</p>; <p>Python: The avro package fully supports Python 3. We will no longer publish a; separate avro-python3 package</p>; <p>And of course upgraded dependencies to latest versions, CVE fixes and more:; <a href=""https://issues.apache.org/jira/issues/?jql=project%3DAVRO%20AND%20fixVersion%3D1.11.0"">https://issues.apache.org/jira/issues/?jql=project%3DAVRO%20AND%20fixVersion%3D1.11.0</a></p>; <p>The link to all fixed JIRA issues and a brief summary can be found at:; <a href=""https://github.com/apache/avro/releases/tag/release-1.11.0"">https://github.com/apache/avro/releases/tag/release-1.11.0</a></p>; <p>In addition, language-specific release ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11475:990,error,error,990,https://hail.is,https://github.com/hail-is/hail/pull/11475,1,['error'],['error']
Availability,"avx2::uint32<4>; T = simdpp::arch_avx2::int32<4>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::int32<4>]â€™; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:133:36: required from â€˜simdpp::arch_avx2::uint32<4>& simdpp::arch_avx2::uint32<4>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::int32<4, simdpp::arch_avx2::expr_empty>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_avg.h:250:8: required from â€˜V simdpp::arch_avx2::detail::insn::v_emul_avg_i32(const V&, const V&) [with V = simdpp::arch_avx2::int32<4>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_avg.h:199:31: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint32<4>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint32<4>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::int32<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:104:7: note: â€˜class simdpp::arch_avx2::uint32<4>â€™ declared here; class uint32<4, void> : public any_int32<4, uint32<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::int32<8>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:115099,error,error,115099,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"avx2::uint32<4>; T = simdpp::arch_avx2::uint8<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint8<16>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint8<16>]â€™; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:129:36: required from â€˜simdpp::arch_avx2::uint32<4>::uint32(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint8<16>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_or.h:101:58: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint32<4>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint32<4>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint8<16>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:104:7: note: â€˜class simdpp::arch_avx2::uint32<4>â€™ declared here; class uint32<4, void> : public any_int32<4, uint32<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::uint64<2>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:10913,error,error,10913,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"avx2::uint32<8>; T = simdpp::arch_avx2::int32<8>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::int32<8>]â€™; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:114:36: required from â€˜simdpp::arch_avx2::uint32<8>& simdpp::arch_avx2::uint32<8>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int32<8, simdpp::arch_avx2::expr_empty>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_avg.h:250:8: required from â€˜V simdpp::arch_avx2::detail::insn::v_emul_avg_i32(const V&, const V&) [with V = simdpp::arch_avx2::int32<8>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_avg.h:211:31: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint32<8>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint32<8>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::int32<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:24,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:91:7: note: â€˜class simdpp::arch_avx2::uint32<8>â€™ declared here; class uint32<8, void> : public any_int32<8, uint32<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int32<4>; T = simdpp::arch_avx2::uint32<4>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:117104,error,error,117104,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"avx2::uint32<8>; T = simdpp::arch_avx2::uint8<32>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint8<32>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint8<32>]â€™; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:110:36: required from â€˜simdpp::arch_avx2::uint32<8>::uint32(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint8<32>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_not.h:64:45: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint32<8>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint32<8>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint8<32>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:24,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:91:7: note: â€˜class simdpp::arch_avx2::uint32<8>â€™ declared here; class uint32<8, void> : public any_int32<8, uint32<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint64<4>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:25140,error,error,25140,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"avx2::uint64<2>; T = simdpp::arch_avx2::uint8<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::uint8<16>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::uint8<16>]â€™; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:125:36: required from â€˜simdpp::arch_avx2::uint64<2>::uint64(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint8<16>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_or.h:150:58: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint64<2>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint64<2>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint8<16>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:26,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:102:7: note: â€˜class simdpp::arch_avx2::uint64<2>â€™ declared here; class uint64<2, void> : public any_int64<2, uint64<2,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int16<8>; T = simdpp::arch_avx2::uint8<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:14450,error,error,14450,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"avx2::uint64<4>; T = simdpp::arch_avx2::uint8<32>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint8<32>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint8<32>]â€™; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:110:36: required from â€˜simdpp::arch_avx2::uint64<4>::uint64(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint8<32>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_not.h:94:45: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint64<4>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint64<4>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint8<32>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:27,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:91:7: note: â€˜class simdpp::arch_avx2::uint64<4>â€™ declared here; class uint64<4, void> : public any_int64<4, uint64<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint16<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:28675,error,error,28675,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"ay of â€˜const class simdpp::arch_avx2::int16<16>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:22,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:92:7: note: â€˜class simdpp::arch_avx2::uint16<16>â€™ declared here; class uint16<16, void> : public any_int16<16, uint16<16,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int8<32>; T = simdpp::arch_avx2::uint16<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int8<32>; T = simdpp::arch_avx2::uint16<16>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int8<32>; T = simdpp::arch_avx2::uint16<16>]â€™; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:51:35: required from â€˜simdpp::arch_avx2::int8<32>::int8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::expr_bit_or<simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::uint16<16> >, simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::uint16<16> > > >]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:69:36: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::int8<32>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::int8<32>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint16<16>â€™; use assignment or ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:65185,Mask,MaskCastOverride,65185,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"ay of â€˜const class simdpp::arch_avx2::int8<32>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:22,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:92:7: note: â€˜class simdpp::arch_avx2::uint16<16>â€™ declared here; class uint16<16, void> : public any_int16<16, uint16<16,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::int16<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::int16<16>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::int16<16>]â€™; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:115:37: required from â€˜simdpp::arch_avx2::uint16<16>& simdpp::arch_avx2::uint16<16>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int16<16, simdpp::arch_avx2::expr_empty>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:64:37: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint16<16>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint16<16>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::int16<16>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:63338,Mask,MaskCastOverride,63338,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"ay of â€˜const class simdpp::arch_avx2::uint32<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:22,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:92:7: note: â€˜class simdpp::arch_avx2::uint16<16>â€™ declared here; class uint16<16, void> : public any_int16<16, uint16<16,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint16<8>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint16<8>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint16<8>]â€™; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:133:36: required from â€˜simdpp::arch_avx2::uint32<4>& simdpp::arch_avx2::uint32<4>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint16<8, simdpp::arch_avx2::expr_empty>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:114:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint32<4>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint32<4>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint16<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:35719,Mask,MaskCastOverride,35719,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"ay of â€˜const class simdpp::arch_avx2::uint8<32>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:22,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:92:7: note: â€˜class simdpp::arch_avx2::uint16<16>â€™ declared here; class uint16<16, void> : public any_int16<16, uint16<16,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint64<2>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint64<2>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint64<2>]â€™; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:133:36: required from â€˜simdpp::arch_avx2::uint16<8>& simdpp::arch_avx2::uint16<8>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint64<2, simdpp::arch_avx2::expr_empty>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:453:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint16<8>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint16<8>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint64<2>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:52298,Mask,MaskCastOverride,52298,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"ay/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/et",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:4245,echo,echo,4245,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,1,['echo'],['echo']
Availability,"azure_identity-1.6.0-py2.py3-none-any.whl (108 kB); 912 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 108.5/108.5 kB 28.5 MB/s eta 0:00:00; 913 | amazon-ebs: Collecting azure-storage-blob==12.11.0; 914 | amazon-ebs: Downloading azure_storage_blob-12.11.0-py3-none-any.whl (346 kB); 915 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 346.4/346.4 kB 41.0 MB/s eta 0:00:00; 916 | amazon-ebs: Collecting bokeh<2.0,>1.3; 917 | amazon-ebs: Downloading bokeh-1.4.0.tar.gz (32.4 MB); 918 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 32.4/32.4 MB 48.4 MB/s eta 0:00:00; 919 | amazon-ebs: Preparing metadata (setup.py): started; 920 | amazon-ebs: Preparing metadata (setup.py): finished with status 'done'; 921 | amazon-ebs: Requirement already satisfied: boto3<2.0,>=1.17 in /usr/local/lib/python3.7/site-packages (1.24.78); 922 | amazon-ebs: Requirement already satisfied: botocore<2.0,>=1.20 in /usr/local/lib/python3.7/site-packages (1.27.78); 923 | amazon-ebs: Collecting decorator<5; 924 | amazon-ebs: Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); 925 | amazon-ebs: Collecting Deprecated<1.3,>=1.2.10; 926 | amazon-ebs: Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB); 927 | amazon-ebs: Collecting dill<0.4,>=0.3.1.1; 928 | amazon-ebs: Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB); 929 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 95.8/95.8 kB 15.3 MB/s eta 0:00:00; 930 | amazon-ebs: Collecting google-auth==1.27.0; 931 | amazon-ebs: Downloading google_auth-1.27.0-py2.py3-none-any.whl (135 kB); 932 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 135.6/135.6 kB 30.6 MB/s eta 0:00:00; 933 | amazon-ebs: Collecting google-cloud-storage==1.25.*; 934 | amazon-ebs: Downloading google_cloud_storage-1.25.0-py2.py3-none-any.whl (73 kB); 935 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 73.4/73.4 kB 22.1 MB/s eta 0:00:00; 936 | amazon-ebs: Collecting humanize==1.0.0; 937 | amazon-ebs: Downloading humanize-1.0.0-py2.py3-none-",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:3924,Down,Downloading,3924,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,"b config; INFO	2022-03-02 19:06:31,656	job.py	schedule_job:443	schedule job (99, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,662	job.py	schedule_job:443	schedule job (100, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,663	job.py	schedule_job:443	schedule job (98, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:32,455	job.py	schedule_job:443	schedule job (101, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:32,455	job.py	schedule_job:443	schedule job (102, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:33,456	hail_logging.py	log:40	https POST /pr-11438-default-g6cibyji6520/batch-driver/api/v1alpha/instances/activate done in 3.2369999999998527s: 200; ERROR	2022-03-02 19:06:33,492	job.py	schedule_job:473	error while scheduling job (95, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/u",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:2921,ERROR,ERROR,2921,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['ERROR'],['ERROR']
Availability,"b': 1},; {'a': 'bar', 'b': 2},; {'a': 'bar', 'b': 2}],; hl.tstruct(a=hl.tstr, b=hl.tint32),; key='a'); t2 = hl.Table.parallelize([; {'t': 'foo', 'x': 3.14},; {'t': 'bar', 'x': 2.78},; {'t': 'bar', 'x': -1},; {'t': 'quam', 'x': 0}],; hl.tstruct(t=hl.tstr, x=hl.tfloat64),; key='t'). t1.join(t2, how='outer').show(). # or. t1.join(t2, how='right').show(); ```. ### What went wrong (all error messages here, including the full java stack trace):. FatalError: HailException: OrderedRVD error! Unexpected PK in partition 1; Range bounds for partition 1: ([bar]-[foo]]; Invalid PK: [quam]; Full key: [quam]. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 1 times, most recent failure: Lost task 0.0 in stage 19.0 (TID 24, localhost, executor driver): is.hail.utils.HailException: OrderedRVD error! Unexpected PK in partition 1; Range bounds for partition 1: ([bar]-[foo]]; Invalid PK: [quam]; Full key: [quam]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1012); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.RVD$$anonfun$4$$anon$1.hasNext(RVD.scala:226); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.hasNext(OrderedRVD.scala:1015); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); 	at is.hail.utils.richUtils.RichIterator$$anon$5.isValid(RichIterator.scala:21); 	at is.hail.utils.StagingIterator.isValid(Fli",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:1090,Error,ErrorHandling,1090,https://hail.is,https://github.com/hail-is/hail/issues/4055,1,['Error'],['ErrorHandling']
Availability,"b.com/Azure/azure-sdk-for-python/commit/9f66f6bce7d777b34c03dc9a633148acd0c4f238""><code>9f66f6b</code></a> [Storage] Revert removing aiohttp dependency for storage.blob.aio (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25084"">#25084</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e40d3e1d985cee13a2e0d070fb8e04958905f468""><code>e40d3e1</code></a> [storage.blob] Remove aiohttp as dependency for storage.blob.aio (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/24965"">#24965</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/7915719f211cc1217dfca6f3973a2b1f04c2e3f5""><code>7915719</code></a> [Storage] Prepare for STG83 GA release (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25040"">#25040</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/155eb8b69b3cd2f8ef992cf1436bf2751769ac42""><code>155eb8b</code></a> [Storage] Add <code>progress_hook</code> to file-share upload/download (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/24997"">#24997</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/66dd3bef2d6e531e83cefd65be4cbbf41fcf2531""><code>66dd3be</code></a> [Storage] Fix more flaky lease tests (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25011"">#25011</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/030141734a239fa6fb1aa7a8c43d322c82753510""><code>0301417</code></a> [Storage] Add argument to perf tests to use client-side encryption (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/24978"">#24978</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.11.0...azure-storage-blob_12.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility sc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12109:3742,down,download,3742,https://hail.is,https://github.com/hail-is/hail/pull/12109,1,['down'],['download']
Availability,"b.com/alden-ilao""><code>@â€‹alden-ilao</code></a>)</li>; </ul>; <h3>Documentation improvements</h3>; <ul>; <li>Fix link to yarn docs in extension migration guide <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15640"">#15640</a> (<a href=""https://github.com/krassowski""><code>@â€‹krassowski</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/graphs/contributors?from=2023-12-29&amp;to=2024-01-19&amp;type=c"">GitHub contributors page for this release</a>)</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyterlab/jupyterlab/blob/@jupyterlab/lsp@4.0.12/CHANGELOG.md"">jupyterlab's changelog</a>.</em></p>; <blockquote>; <h2>4.0.12</h2>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/compare/v4.0.11...69079ec413cbe6d173f0a667c15802b76423ece5"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Fix jupyterlab downgrade issue on extension installation <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15650"">#15650</a> (<a href=""https://github.com/Sarthug99""><code>@â€‹Sarthug99</code></a>)</li>; <li>Fix search highlights removal on clearing input box <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15690"">#15690</a> (<a href=""https://github.com/krassowski""><code>@â€‹krassowski</code></a>)</li>; <li>Add scroll margin to headings for better alignment <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15703"">#15703</a> (<a href=""https://github.com/krassowski""><code>@â€‹krassowski</code></a>)</li>; <li>Fix shortcut UI failing on filtering when empty command is given <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15695"">#15695</a> (<a href=""https://github.com/krassowski""><code>@â€‹krassowski</code></a>)</li>; <li>Fix connection loop issue with standalone foreign document in LSP <a href=""https://redirect.github.com/jupyterlab/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14218:6130,down,downgrade,6130,https://hail.is,https://github.com/hail-is/hail/pull/14218,1,['down'],['downgrade']
Availability,"b/python3.10/site-packages/hail/backend/backend.py in persist(self, dataset); 167 from hail.context import TemporaryFilename; 168 tempfile = TemporaryFilename(prefix=f'persist_{type(dataset).__name__}'); --> 169 persisted = dataset.checkpoint(tempfile.__enter__()); 170 self._persisted_locations[persisted] = (tempfile, dataset); 171 return persisted. <decorator-gen-1330> in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1329 ; 1330 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1331 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1332 _assert_type = self._type; 1333 _load_refs = False. <decorator-gen-1332> in write(self, output, overwrite, stage_locally, _codec_spec). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in write(self, output, overwrite, stage_locally, _codec_spec); 1375 hl.current_backend().validate_file_scheme(output); 1376 ; -> 1377 Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWr",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:4350,checkpoint,checkpoint,4350,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124,1,['checkpoint'],['checkpoint']
Availability,"b/python3.6/ssl.py"", line 874, in read; return self._sslobj.read(len, buffer); File ""/usr/lib/python3.6/ssl.py"", line 631, in read; v = self._sslobj.read(len, buffer); socket.timeout: The read operation timed out. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/lib/python3/dist-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/usr/lib/python3/dist-packages/pip/commands/install.py"", line 342, in run; requirement_set.prepare_files(finder); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 821, in unpack_url; hashes=hashes; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 659, in unpack_http_url; hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 882, in _download_http_url; _download_url(resp, link, content_file, hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 603, in _download_url; hashes.check_against_chunks(downloaded_chunks); File ""/usr/lib/python3/dist-packages/pip/utils/hashes.py"", line 46, in check_against_chunks; for chunk in chunks:; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 571, in written_chunks; for chunk in chunks:; File ""/usr/lib/python3/dist-packages/pip/utils/ui.py"", line 139, in iter; for x in it:; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 560, in resp_read; decode_content=False):; File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 436, in stream; data = self.read(amt=amt, decode_content=decode_content); File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 401, in read; raise IncompleteRead(self._fp_bytes_read, self.leng",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8390:1706,down,download,1706,https://hail.is,https://github.com/hail-is/hail/issues/8390,1,['down'],['download']
Availability,"b1.</li>; <li>Added support for deleting versions in <code>delete_blobs</code> by supplying <code>version_id</code>.</li>; </ul>; <h2>azure-storage-blob_12.13.0b1</h2>; <h2>12.13.0b1 (2022-06-15)</h2>; <h3>Features Added</h3>; <ul>; <li>Added support for service version 2021-08-06.</li>; <li>Added a new version of client-side encryption for blobs (version 2.0) which utilizes AES-GCM-256 encryption.; If you are currently using client-side encryption, it is <strong>highly recommended</strong> to switch to a form of server-side; encryption (Customer-Provided Key, Encryption Scope, etc.) or version 2.0 of client-side encryption. The encryption; version can be specified on any client constructor via the <code>encryption_version</code> keyword (<code>encryption_version='2.0'</code>).</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/13989b5b1253e26f3f3ee24013a3013fea1bdf73""><code>13989b5</code></a> [Storage] Fix ranged download for client-side encryption (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25522"">#25522</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e90af4374bfd7c139737ad2888fcd269b3023520""><code>e90af43</code></a> DataLake funny dependency (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25129"">#25129</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/cbec3383039ffeb46760268d1a8f81cf1b4d2219""><code>cbec338</code></a> [AutoRelease] t2-storagecache-2022-07-06-35884(Do not merge) (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25089"">#25089</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/dc7c5a16d39df8a8d4b838a7240e58f64fc824f2""><code>dc7c5a1</code></a> [Storage] API View Feedback For STG84 GA (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12109:1659,down,download,1659,https://hail.is,https://github.com/hail-is/hail/pull/12109,1,['down'],['download']
Availability,"b>Warning</b></summary>. ```; jupyter 1.0.0 requires notebook, which is not installed.; beautifulsoup4 4.12.2 requires soupsieve, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **554/1000** <br/> **Why?** Has a fix available, CVSS 6.8 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **624/1000** <br/> **Why?** Has a fix available, CVSS 8.2 | Arbitrary Code Execution <br/>[SNYK-PYTHON-IPYTHON-2348630](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-2348630) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | Proof of Concept ; !",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:1427,avail,available,1427,https://hail.is,https://github.com/hail-is/hail/pull/13717,1,['avail'],['available']
Availability,"b_private_instance_cancel ; -------------------------------- live log setup --------------------------------; 2023-09-06T21:45:24 INFO test.conftest conftest.py:14:log_before_after starting test; 2023-09-06T21:45:24 INFO hailtop.aiocloud.aioazure.credentials credentials.py:99:default_credentials using credentials file /test-gsa-key/key.json; -------------------------------- live log call ---------------------------------; 2023-09-06T21:45:25 INFO azure.identity.aio._internal.get_token_mixin get_token_mixin.py:93:get_token ClientSecretCredential.get_token succeeded; 2023-09-06T21:45:25 INFO batch_client.aioclient aioclient.py:809:_submit created batch 191; submit job bunches â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 1/1 0:00:00 0:00:00; 2023-09-06T21:47:17 WARNING hailtop.utils utils.py:842:retry_transient_errors_with_debug_string A transient error occured. We will automatically retry. Do not be alarmed. We have thus far seen 2 transient errors (next delay: 3.794s). The most recent error was <class 'asyncio.exceptions.TimeoutError'> . . +++++++++++++++++++++++++++++++++++ Timeout ++++++++++++++++++++++++++++++++++++. ~~~~~~~~~~~~~~~~~~~~~ Stack of asyncio_0 (140387515627072) ~~~~~~~~~~~~~~~~~~~~~; File ""/usr/lib/python3.9/threading.py"", line 937, in _bootstrap; self._bootstrap_inner(); File ""/usr/lib/python3.9/threading.py"", line 980, in _bootstrap_inner; self.run(); File ""/usr/lib/python3.9/threading.py"", line 917, in run; self._target(*self._args, **self._kwargs); File ""/usr/lib/python3.9/concurrent/futures/thread.py"", line 81, in _worker; work_item = work_queue.get(block=True). +++++++++++++++++++++++++++++++++++ Timeout ++++++++++++++++++++++++++++++++++++; FAILED; _________________ test_always_run_job_private_instance_cancel __________________. client = <hailtop.batch_client.client.BatchClient object at 0x7fae899806a0>. def test_always_run_job_private_instance_cancel(client: BatchClient):; b = create_batch(client); resources = {'machine_type': smallest_machine_ty",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13582:1116,error,error,1116,https://hail.is,https://github.com/hail-is/hail/issues/13582,1,['error'],['error']
Availability,bad 'analyze' error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3020:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/issues/3020,1,['error'],['error']
Availability,bad error message and crash for files named .bgz that are plaintext,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/425:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/425,1,['error'],['error']
Availability,bad error message if spark.serializer is wrong,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3860:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/3860,1,['error'],['error']
Availability,bad error message in Table.order_by(field from other table),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4920:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/4920,1,['error'],['error']
Availability,bad error message on export_vcf,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4283:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/4283,1,['error'],['error']
Availability,bad error message related to indices,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4039:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/4039,1,['error'],['error']
Availability,bad error messages for Table.group_by,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4070:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/4070,1,['error'],['error']
Availability,bad error on hl.import_table(hail_table_path),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5129:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/5129,1,['error'],['error']
Availability,"bad news, though -- after playing with the thing a bit longer and trying to bump the partition number up, it's really not reliable. At all.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7087#issuecomment-532883549:122,reliab,reliable,122,https://hail.is,https://github.com/hail-is/hail/pull/7087#issuecomment-532883549,1,['reliab'],['reliable']
Availability,"bands.append(keep_fams_ht.mother_id).append(keep_fams_ht.father_id)); ----> 2 relateds = keep_fams_ht.explode(keep_fams_ht.relateds).key_by('relateds').distinct(). /home/hail/hail.zip/hail/table.py in distinct(self); 2607 """"""; 2608 hail.methods.misc.require_key(self, ""distinct""); -> 2609 return Table(self._jt.distinctByKey()); 2610 ; 2611 table_type.set(Table). /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 182 import pyspark; 183 try:; --> 184 return f(*args, **kwargs); 185 except py4j.protocol.Py4JJavaError as e:; 186 s = e.java_exception.toString(). /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 317 raise Py4JJavaError(; 318 ""An error occurred while calling {0}{1}{2}.\n"".; --> 319 format(target_id, ""."", name), value); 320 else:; 321 raise Py4JError(. Py4JJavaError: An error occurred while calling o1507.distinctByKey.; : java.util.NoSuchElementException: None.get; 	at scala.None$.get(Option.scala:347); 	at scala.None$.get(Option.scala:345); 	at is.hail.expr.TableMapRows.execute(Relational.scala:2089); 	at is.hail.expr.TableMapRows.execute(Relational.scala:2064); 	at is.hail.expr.TableExplode.execute(Relational.scala:2166); 	at is.hail.expr.TableUnkey.execute(Relational.scala:1857); 	at is.hail.expr.TableMapRows.execute(Relational.scala:2064); 	at is.hail.expr.TableKeyBy.execute(Relational.scala:1820); 	at is.hail.expr.TableKeyBy.execute(Relational.scala:1820); 	at is.hail.table.Table.value$lzycompute(Table.scala:237); 	at is.hail.table.Table.value(Table.scala:232); 	at is.hail.table.Table.x$5$lzycompute(Table.scala:240); 	at is.hail.table.Table.x$5(Table.scala:240); 	at is.hail.tab",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3814:2475,error,error,2475,https://hail.is,https://github.com/hail-is/hail/issues/3814,1,['error'],['error']
Availability,"base64 can contain some symbols, can the cluster names handle it? I normally use `tr`:. ```; $ echo `LC_CTYPE=C tr -dc 'a-z0-9' < /dev/urandom | head -c 8`; k1awyx7o; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4241#issuecomment-417796578:95,echo,echo,95,https://hail.is,https://github.com/hail-is/hail/pull/4241#issuecomment-417796578,1,['echo'],['echo']
Availability,"batch checks authentication for all endpoints except `/alive`. Two endpoints are now considered ""internal"" and must originate from the batch server itself. Summary of Changes; - hailjwt is used by batch to verify cookies; - all batch endpoints except `/alive` require a valid cookie or are internal; - a make target `test-deploy` and associated files for testing a deploy of batch; - update pipeline to use batch and users",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5844:55,alive,alive,55,https://hail.is,https://github.com/hail-is/hail/pull/5844,2,['alive'],['alive']
Availability,"batch deployment is still failing; [batch.log](https://github.com/hail-is/hail/files/2507610/batch.log); ```; a8466a39326493a8d0acb9347f3f640127e7a082fb85471dc56e57c7960d62c6: digest: sha256:3e72c4e3d33d3009fcd08cdaf4e8601535eadce37c3004d6371f802638aa09f5 size: 2002; echo ""gcr.io/broad-ctsa/batch:a8466a39326493a8d0acb9347f3f640127e7a082fb85471dc56e57c7960d62c6"" > batch-image; sed -e ""s,@sha@,$(git rev-parse --short=12 HEAD),"" \; -e ""s,@image@,$(cat batch-image),"" \; < deployment.yaml.in > deployment.yaml; kubectl apply -f deployment.yaml; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""apps/v1beta2, Resource=deployments"", GroupVersionKind: ""apps/v1beta2, Kind=Deployment""; Name: ""batch-deployment"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""apps/v1beta2"" ""kind"":""Deployment"" ""metadata"":map[""labels"":map[""app"":""batch"" ""hail.is/sha"":""9d4cd6d6e0a0""] ""name"":""batch-deployment"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""spec"":map[""replicas"":'\x01' ""selector"":map[""matchLabels"":map[""app"":""batch""]] ""template"":map[""metadata"":map[""labels"":map[""app"":""batch"" ""hail.is/sha"":""9d4cd6d6e0a0""]] ""spec"":map[""containers"":[map[""image"":""gcr.io/broad-ctsa/batch:a8466a39326493a8d0acb9347f3f640127e7a082fb85471dc56e57c7960d62c6"" ""name"":""batch"" ""ports"":[map[""containerPort"":'\u1388']]]] ""serviceAccountName"":""batch-svc""]]]]}; from server for: ""deployment.yaml"": deployments.apps ""batch-deployment"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get deployments.apps in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""/v1, Resource=services"", GroupVersionKind: ""/v1, Kind=Service""; Name: ""batch"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""v1"" ""kind"":""Service"" ""metadata"":map[""labels"":map[""app"":""batch""] ""name"":""batch"" ""namespace"":""batch-",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4609#issuecomment-432377914:268,echo,echo,268,https://hail.is,https://github.com/hail-is/hail/issues/4609#issuecomment-432377914,3,"['Error', 'echo', 'error']","['Error', 'echo', 'error']"
Availability,"batch log:. ```; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-29 12:35:40,389"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""polling_event_loop:1343"", ""message"": ""Could not poll due to exception: HTTPConnectionPool(host='10.32.16.16', port=5001): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ff2413b8470>: Failed to establish a new connection: [Errno 113] No route to host',))"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\"", line 159, in _new_conn\n (self._dns_host, self.port), self.timeout, **extra_kw)\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\"", line 80, in create_connection\n raise err\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\"", line 70, in create_connection\n sock.connect(sa)\nOSError: [Errno 113] No route to host\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\"", line 600, in urlopen\n chunked=chunked)\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\"", line 354, in _make_request\n conn.request(method, url, **httplib_request_kw)\n File \""/usr/lib/python3.6/http/client.py\"", line 1239, in request\n self._send_request(method, url, body, headers, encode_chunked)\n File \""/usr/lib/python3.6/http/client.py\"", line 1285, in _send_request\n self.endheaders(body, encode_chunked=encode_chunked)\n File \""/usr/lib/python3.6/http/client.py\"", line 1234, in endheaders\n self._send_output(message_body, encode_chunked=encode_chunked)\n File \""/usr/lib/python3.6/http/client.py\"", line 1026, in _send_output\n self.send(msg)\n File \""/usr/lib/python3.6/http/client.py\"", line 964, in send\n self.connect()\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\"", line 181, in connect\n conn = self._new_conn()\n ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6754:32,ERROR,ERROR,32,https://hail.is,https://github.com/hail-is/hail/issues/6754,1,['ERROR'],['ERROR']
Availability,batch sometimes shows exit code 0 success when a job is a failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8473:58,failure,failure,58,https://hail.is,https://github.com/hail-is/hail/issues/8473,1,['failure'],['failure']
Availability,better error handling on initial read of vds metadata,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2173:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/pull/2173,1,['error'],['error']
Availability,better error message and behaviour when parsing malformed vcf,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/361:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/issues/361,1,['error'],['error']
Availability,better error message for partition mismatch,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1183:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/pull/1183,1,['error'],['error']
Availability,better error messages for invalid dev deploy,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7074:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/issues/7074,1,['error'],['error']
Availability,better fb error handling,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2330:10,error,error,10,https://hail.is,https://github.com/hail-is/hail/pull/2330,1,['error'],['error']
Availability,"ble(); .flatten(); .select(['va.info.MQRankSum']); ); print(rf_kt.schema()). rf_df = rf_kt.to_dataframe(); rf_df.printSchema(); rf_df.show(); ```. And here is the output and stacktrace as it crashes when running `show()`:. ```; Struct {; `va.info.MQRankSum`: Double; }; root; |-- va.info.MQRankSum: double (nullable = true); Traceback (most recent call last):; File ""/tmp/db4d8e04-85c9-4eba-b0b3-4ade69200fd3/test.py"", line 60, in <module>; rf_df.show(); File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py"", line 287, in show; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; for criterion, pop in criteria_pops:; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o73.showString.; : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 20 times, most recent failure: Lost task 0.19 in stage 2.0 (TID 2520, gnomad-prod-sw-s89f.c.broad-mpg-gnomad.internal): java.lang.IndexOutOfBoundsException: 21; at scala.collection.mutable.ResizableArray$class.apply(ResizableArray.scala:43); at scala.collection.mutable.ArrayBuffer.apply(ArrayBuffer.scala:48); at is.hail.keytable.KeyTable$$anonfun$8$$anonfun$10.apply(KeyTable.scala:68); at is.hail.keytable.KeyTable$$anonfun$8$$anonfun$10.apply(KeyTable.scala:68); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.keytable.KeyT",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1275:1111,failure,failure,1111,https://hail.is,https://github.com/hail-is/hail/issues/1275,1,['failure'],['failure']
Availability,"bot.com/michel-kraemer/gradle-download-task/issues/284"">#284</a>). Thanks to <a href=""https://github.com/liblit""><code>@â€‹liblit</code></a> for testing!</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; <li>Improve documentation</li>; <li>Add integration tests for Gradle 6.9.3 and 7.6</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a0374fc7c895ae53309ea351e989571204e0ea5f""><code>a0374fc</code></a> Bump up version number to 5.3.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/612f57a382b8640cc730dc5e75d1c809e3e772bd""><code>612f57a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/291"">#291</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/53af1049f5514afe58e884d487d7c57dae47759d""><code>53af104</code></a> Bump http-cache-semantics from 4.1.0 to 4.1.1 in /screencast</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/398c14c05c6448b380ac35c6095598299c5e23c5""><code>398c14c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/15cf7eecfbc17d2466143828b9b69494c6cb6f2b""><code>15cf7ee</code></a> Bump up version number to 5.3.1-SNAPSHOT</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e3c65ffcb49b9c5a33fde5f31fb63043dbf21134""><code>e3c65ff</code></a> Allow extensions to be created from tasks</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/34e2dd41477f18b1ae3d6d5a71dca5449d6cd1e0""><code>34e2dd4</code></a> Downgrade slf4j to fix warning on console about missing slf4j provider</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b3fa29f9ffb4d4544e13ef84601e371fb2778ddf""><code>b3fa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:1611,down,download-task,1611,https://hail.is,https://github.com/hail-is/hail/pull/12707,1,['down'],['download-task']
Availability,"bout modifying the client code and how the current billing information is calculated. How this migration works is there are 5 phases:; 1. Compute the expected number of attempts to process for format version < 3. ; 2. Divide the search space into chunks of size 100 attempts (empirically determined this was the best chunk size) and randomize the order of the chunks.; 3. Serially process 5000 chunks with only 10 out of the 100 records as a ""burn in period"" to avoid the birthday problem when trying to insert records in parallel.; 4. In parallel, process all the chunks with 10 way parallelism (empirically determined to max CPU for a 4 core db instance); 5. Do an audit of the results to make sure the attempt resources now has the correct number of rows and the billing is within $0.001 per job with the old way and new way of computing the billing. The tolerance of $0.001 was empirically determined. At a threshold of $0.0001, 33/30,000,000 attempts failed. I think this is good enough as there's always going to be rounding errors. I did not do an explicit audit in the code to make sure the other aggregated_*_resources tables did not change. I spot checked this was correct in my test database. To do the complete audit during the actual migration would take more time. I made sure all the inserts were idempotent. Please double check this. The inserts use a temporary table with an isolation level of read committed. The reason for this is because `INSERT INTO ... SELECT` locks the next gap lock if the isolation level is not read committed. Maybe what I did is overkill and it's no longer a problem with the new burn in period. https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html I'd be interested to hear @danking feedback on what the best query here is to allow parallelism. There are ~30 million attempts that need to be processed for hail-vdc (~60% of the attempts). This will add ~20Gi to the existing database. I use 4 cores to get this migration to be ~3 hours, so we will",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11990:2036,error,errors,2036,https://hail.is,https://github.com/hail-is/hail/pull/11990,1,['error'],['errors']
Availability,"brew/lib/python3.10/site-packages/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/homebrew/lib/python3.10/site-packages/hail/context.py"", line 345, in init; return init_spark(; File ""<decorator-gen-1760>"", line 2, in init_spark; File ""/opt/homebrew/lib/python3.10/site-packages/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/homebrew/lib/python3.10/site-packages/hail/context.py"", line 424, in init_spark; backend = SparkBackend(; File ""/opt/homebrew/lib/python3.10/site-packages/hail/backend/spark_backend.py"", line 188, in __init__; self._jbackend = hail_package.backend.spark.SparkBackend.apply(; File ""/opt/homebrew/lib/python3.10/site-packages/py4j/java_gateway.py"", line 1304, in __call__; return_value = get_return_value(; File ""/opt/homebrew/lib/python3.10/site-packages/py4j/protocol.py"", line 326, in get_return_value; raise Py4JJavaError(; py4j.protocol.Py4JJavaError: An error occurred while calling z:is.hail.backend.spark.SparkBackend.apply.; : java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x4d740d85) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x4d740d85; 	at org.apache.spark.storage.StorageUtils$.<init>(StorageUtils.scala:213); 	at org.apache.spark.storage.StorageUtils$.<clinit>(StorageUtils.scala); 	at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:109); 	at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:371); 	at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:311); 	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:359); 	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:189); 	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:277); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:458); 	at is.hai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12630:1793,error,error,1793,https://hail.is,https://github.com/hail-is/hail/issues/12630,1,['error'],['error']
Availability,"bs: /usr/local/lib/python3.7/site-packages/setuptools/installer.py:30: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.; 890 | ==> amazon-ebs: SetuptoolsDeprecationWarning,; 891 | ==> amazon-ebs: /usr/local/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.; 892 | ==> amazon-ebs: setuptools.SetuptoolsDeprecationWarning,; 893 | amazon-ebs: sed '/^pyspark/d' python/requirements.txt \| grep -v '^#' \| xargs python3 -m pip install -U; 894 | amazon-ebs: Collecting aiohttp==3.8.1; 895 | amazon-ebs: Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB); 896 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.1/1.1 MB 68.3 MB/s eta 0:00:00; 897 | amazon-ebs: Collecting aiohttp_session<2.8,>=2.7; 898 | amazon-ebs: Downloading aiohttp_session-2.7.0-py3-none-any.whl (14 kB); 899 | amazon-ebs: Collecting asyncinit<0.3,>=0.2.4; 900 | amazon-ebs: Downloading asyncinit-0.2.4-py3-none-any.whl (2.8 kB); 901 | amazon-ebs: Collecting avro<1.12,>=1.10; 902 | amazon-ebs: Downloading avro-1.11.1.tar.gz (84 kB); 903 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 84.2/84.2 kB 22.0 MB/s eta 0:00:00; 904 | amazon-ebs: Installing build dependencies: started; 905 | amazon-ebs: Installing build dependencies: finished with status 'done'; 906 | amazon-ebs: Getting requirements to build wheel: started; 907 | amazon-ebs: Getting requirements to build wheel: finished with status 'done'; 908 | amazon-ebs: Preparing metadata (pyproject.toml): started; 909 | amazon-ebs: Preparing metadata (pyproject.toml): finished with status 'done'; 910 | amazon-ebs: Collecting azure-identity==1.6.0; 911 | amazon-ebs: Downloading azure_identity-1.6.0-py2.py3-none-any.whl (108 kB); 912 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:2004,Down,Downloading,2004,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,bug report here: https://discuss.hail.is/t/ld-prune-starts-and-stops-error/. @jbloom22 any ideas? You've worked on this stuff a bit,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6223:69,error,error,69,https://hail.is,https://github.com/hail-is/hail/issues/6223,1,['error'],['error']
Availability,"bugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py"", line 284, in run_file; runpy.run_path(target, run_name=""__main__""); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 321, in run_path; return _run_module_code(code, init_globals, run_name,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 135, in _run_module_code; _run_code(code, mod_globals, init_globals,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 124, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/test.py"", line 34, in <module>; main(); File ""/home/edmund/.local/src/hail/test.py"", line 28, in main; r2_adj = r2_adj.checkpoint(f'{tmp}/adj', overwrite=args.overwrite); File ""<decorator-gen-1508>"", line 2, in checkpoint; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/linalg/blockmatrix.py"", line 679, in checkpoint; self.write(path, overwrite, force_row_major, stage_locally); File ""<decorator-gen-1506>"", line 2, in write; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/linalg/blockmatrix.py"", line 656, in write; Env.backend().execute(BlockMatrixWrite(self._bmir, writer)); File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUT",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14537:3251,checkpoint,checkpoint,3251,https://hail.is,https://github.com/hail-is/hail/issues/14537,1,['checkpoint'],['checkpoint']
Availability,"bugpy/launcher/../../debugpy/../debugpy/server/cli.py"", line 284, in run_file; runpy.run_path(target, run_name=""__main__""); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 321, in run_path; return _run_module_code(code, init_globals, run_name,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 135, in _run_module_code; _run_code(code, mod_globals, init_globals,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 124, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/test.py"", line 34, in <module>; main(); File ""/home/edmund/.local/src/hail/test.py"", line 28, in main; r2_adj = r2_adj.checkpoint(f'{tmp}/adj', overwrite=args.overwrite); File ""<decorator-gen-1508>"", line 2, in checkpoint; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/linalg/blockmatrix.py"", line 679, in checkpoint; self.write(path, overwrite, force_row_major, stage_locally); File ""<decorator-gen-1506>"", line 2, in write; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/linalg/blockmatrix.py"", line 656, in write; Env.backend().execute(BlockMatrixWrite(self._bmir, writer)); File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/home/edmund/.local/src/hail/hail/python/ha",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14537:3343,checkpoint,checkpoint,3343,https://hail.is,https://github.com/hail-is/hail/issues/14537,1,['checkpoint'],['checkpoint']
Availability,build and make available devel jar artifacts in ci,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/754:15,avail,available,15,https://hail.is,https://github.com/hail-is/hail/issues/754,1,['avail'],['available']
Availability,"bump for approval, I fixed the lint error",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9985#issuecomment-773392574:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/pull/9985#issuecomment-773392574,1,['error'],['error']
Availability,bump. Test failure was unrelated.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13812#issuecomment-1798877987:11,failure,failure,11,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1798877987,1,['failure'],['failure']
Availability,bump. can we get this in? I want to PR the stacked changes so that Dan can see the batch failure modes,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6908#issuecomment-525915270:89,failure,failure,89,https://hail.is,https://github.com/hail-is/hail/pull/6908#issuecomment-525915270,1,['failure'],['failure']
Availability,bump... can we come to an agreement on what error we're catching?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10432#issuecomment-837286361:44,error,error,44,https://hail.is,https://github.com/hail-is/hail/pull/10432#issuecomment-837286361,1,['error'],['error']
Availability,"burden.vds'); [13:46:55]	[:makeHailDocs] .linreg_burden(key_name='gene',; [13:46:55]	[:makeHailDocs] variant_keys='va.genes',; [13:46:55]	[:makeHailDocs] single_key='false',; [13:46:55]	[:makeHailDocs] agg_expr='gs.map(g => g.gt).max()',; [13:46:55]	[:makeHailDocs] y='sa.burden.pheno',; [13:46:55]	[:makeHailDocs] covariates=['sa.burden.cov1', 'sa.burden.cov2'])); [13:46:55]	[:makeHailDocs] Exception raised:; [13:46:55]	[:makeHailDocs] Traceback (most recent call last):; [13:46:55]	[:makeHailDocs] File ""/usr/lib64/python2.7/doctest.py"", line 1315, in __run; [13:46:55]	[:makeHailDocs] compileflags, 1) in test.globs; [13:46:55]	[:makeHailDocs] File ""<doctest default[0]>"", line 7, in <module>; [13:46:55]	[:makeHailDocs] covariates=['sa.burden.cov1', 'sa.burden.cov2'])); [13:46:55]	[:makeHailDocs] File ""<decorator-gen-233>"", line 2, in linreg_burden; [13:46:55]	[:makeHailDocs] File ""/home/ec2-user/BuildAgent/work/c38e75e72b769a7c/python/hail/java.py"", line 119, in handle_py4j; [13:46:55]	[:makeHailDocs] 'Error summary: %s' % (msg, e.message, Env.hc().version, msg)); [13:46:55]	[:makeHailDocs] FatalError: An error occurred while calling into JVM, probably due to invalid parameter types.; [13:46:55]	[:makeHailDocs] ; [13:46:55]	[:makeHailDocs] Java stack trace:; [13:46:55]	[:makeHailDocs] An error occurred while calling o3918.linregBurden. Trace:; [13:46:55]	[:makeHailDocs] py4j.Py4JException: Method linregBurden([class java.lang.String, class java.lang.String, class java.lang.String, class java.lang.String, class java.lang.String, class [Ljava.lang.String;]) does not exist; [13:46:55]	[:makeHailDocs] 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); [13:46:55]	[:makeHailDocs] 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326); [13:46:55]	[:makeHailDocs] 	at py4j.Gateway.invoke(Gateway.java:272); [13:46:55]	[:makeHailDocs] 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); [13:46:55]	[:makeHailDocs] 	at",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1708#issuecomment-297039203:1401,Error,Error,1401,https://hail.is,https://github.com/hail-is/hail/pull/1708#issuecomment-297039203,1,['Error'],['Error']
Availability,but ends up throwing odd non-specific errors down the line,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1137:38,error,errors,38,https://hail.is,https://github.com/hail-is/hail/issues/1137,2,"['down', 'error']","['down', 'errors']"
Availability,bytecode verification error related to hl.agg._prev_nonnull,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5345:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/issues/5345,1,['error'],['error']
Availability,"c.indexBgen(jindexed_seq_args(path), index_file_map, joption(rg), contig_recoding, skip_invalid_loci); 1958; 1959. /share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /share/pkg/hail/2018-10-31/install/build/distributions/hail-python.zip/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 211 except pyspark.sql.utils.CapturedException as e:; 212 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: OutOfMemoryError: GC overhead limit exceeded. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.immutable.VectorBuilder.<init>(Vector.scala:713); at scala.collection.immutable.Vector$.newBuilder(Vector.scala:22); at scala.collection.immutable.IndexedSeq$.newBuilder(IndexedSeq.scala:46); at scala.collection.IndexedSeq$.newBuilder(IndexedSeq.scala:36); at scala.collection.IndexedSeq$$anon$1.apply(IndexedSeq.scala:34); at com.twitter.chill.TraversableSerializer.read(Traversable.scala:39); at com.twitter.chill.TraversableSerializer.read(Traversable.scala:21); at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); at co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:7030,failure,failure,7030,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['failure'],['failure']
Availability,"c/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hai",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:2670,echo,echo,2670,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545,1,['echo'],['echo']
Availability,"cal/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 239, in execute\n await self._query(query)\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 457, in _query\n await conn.query(q)\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 428, in query\n await self._read_query_result(unbuffered=unbuffered)\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 622, in _read_query_result\n await result.read()\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 1105, in read\n first_packet = await self.connection._read_packet()\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 593, in _read_packet\n packet.check_error()\n File \""/usr/local/lib/python3.6/dist-packages/pymysql/protocol.py\"", line 220, in check_error\n err.raise_mysql_exception(self._data)\n File \""/usr/local/lib/python3.6/dist-packages/pymysql/err.py\"", line 109, in raise_mysql_exception\n raise errorclass(errno, errval)\npymysql.err.OperationalError: (1213, 'Deadlock found when trying to get lock; try restarting transaction')""; }; {; ""levelname"": ""INFO"",; ""asctime"": ""2019-07-02 13:17:00,609"",; ""filename"": ""web_log.py"",; ""funcNameAndLine"": ""log:233"",; ""message"": ""10.32.4.181 [02/Jul/2019:13:17:00 +0000] \""POST /api/v1alpha/batches/278/jobs/create HTTP/1.0\"" 500 225 \""-\"" \""Python/3.7 aiohttp/3.5.4\"""",; ""remote_address"": ""10.32.4.181"",; ""request_start_time"": ""[02/Jul/2019:13:17:00 +0000]"",; ""first_request_line"": ""POST /api/v1alpha/batches/278/jobs/create HTTP/1.0"",; ""response_status"": 500,; ""response_size"": 225,; ""request_header"": {; ""Referer"": ""-"",; ""User-Agent"": ""Python/3.7 aiohttp/3.5.4""; }; }; ```; ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py"", line 418, in start; resp = await task; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 458, in _handle; resp = await handler(request); Fil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6543:2162,error,errorclass,2162,https://hail.is,https://github.com/hail-is/hail/issues/6543,1,['error'],['errorclass']
Availability,"cal/lib/python3.6/dist-packages/batch/front_end/front_end.py"", line 383, in ui_get_job_log; 'job_log': await _get_job_log(request.app, batch_id, job_id, user); File ""/usr/local/lib/python3.6/dist-packages/batch/front_end/front_end.py"", line 112, in _get_job_log; job_log = await job._read_logs(); File ""/usr/local/lib/python3.6/dist-packages/batch/batch.py"", line 49, in _read_logs; return await self.app['driver'].read_pod_logs(self._pod_name); File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 160, in __getitem__; return self._state[key]; KeyError: 'driver'; ```. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.6/dist-packages/google/cloud/storage/blob.py"", line 636, in download_to_file; self._do_download(transport, file_obj, download_url, headers, start, end); File ""/usr/local/lib/python3.6/dist-packages/google/cloud/storage/blob.py"", line 574, in _do_download; download.consume(transport); File ""/usr/local/lib/python3.6/dist-packages/google/resumable_media/requests/download.py"", line 171, in consume; self._process_response(result); File ""/usr/local/lib/python3.6/dist-packages/google/resumable_media/_download.py"", line 171, in _process_response; response, _ACCEPTABLE_STATUS_CODES, self._get_status_code; File ""/usr/local/lib/python3.6/dist-packages/google/resumable_media/_helpers.py"", line 96, in require_status_code; *status_codes; google.resumable_media.common.InvalidResponse: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py"", line 418, in start; resp = await task; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 458, in _handle; resp = await handler(request); File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_middlewares.py"", line 119, in impl; return await hand",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7412:2039,down,download,2039,https://hail.is,https://github.com/hail-is/hail/pull/7412,1,['down'],['download']
Availability,cala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at is.hail.expr.Parser$$anonfun$parseNamedExprs$3.apply(Parser.scala:229); 	at is.hail.expr.Parser$$anonfun$parseNamedExprs$3.apply(Parser.scala:228); 	at is.hail.expr.Parser$$anonfun$parseAnnotationExprs$4.apply(Parser.scala:115); 	at is.hail.expr.Parser$$anonfun$parseAnnotationExprs$4.apply(Parser.scala:114); 	at is.hail.variant.VariantSampleMatrix$$anonfun$34.apply(VariantSampleMatrix.scala:544); 	at is.hail.variant.VariantSampleMatrix$$anonfun$34.apply(VariantSampleMatrix.scala:540); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.variant.VariantSampleMatrix.annotateSamplesExpr(VariantSampleMatrix.scala:540); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: devel-e081278; Error summary: IndexOutOfBoundsException: 0; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1705:5904,Error,Error,5904,https://hail.is,https://github.com/hail-is/hail/issues/1705,1,['Error'],['Error']
Availability,cala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829); Caused by: is.hail.utils.HailException: cannot set missing field for required type +PFloat64; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:207); 	at is.hail.io.vcf.VCFLine.parseAddInfoArrayDouble(LoadVCF.scala:1034); 	at is.hail.io.vcf.VCFLine.parseAddInfoField(LoadVCF.scala:1055); 	at is.hail.io.vcf.VCFLine.addInfoField(LoadVCF.scala:1075); 	at is.hail.io.vcf.VCFLine.parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	... 21 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapte,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:9128,Error,ErrorHandling,9128,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['Error'],['ErrorHandling']
Availability,"cala:137); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Daniel King: JAR and ZIP are both deleted from google storage. for the record the bad SHA was 5702f5c6b299; ```. A discuss user [is seeing that the JVM crashes when he tries to use hail](http://discuss.hail.is/t/gcp-py4jnetworkerror-answer-from-java-side-is-empty/630):. ```; hl.init(); mt = hl.read_matrix_table('gs://hail-datasets/hail-data/1000_genomes_phase3_autosomes.GRCh37.mt'); mt.describe() ...; mt.rsid.show(5); ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1035, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 883, in send_command; response = connection.send_command(command); File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1040, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4239#issuecomment-417433186:3867,ERROR,ERROR,3867,https://hail.is,https://github.com/hail-is/hail/pull/4239#issuecomment-417433186,3,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,"cala:198); at org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:494); at is.hail.variant.VariantDatasetFunctions$.write$extension(VariantDataset.scala:751); at is.hail.variant.VariantDatasetFunctions.write(VariantDataset.scala:721); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748)org.apache.spark.SparkException: Job aborted due to stage failure: Task 754 in stage 1.0 failed 1 times, most recent failure: Lost task 754.0 in stage 1.0 (TID 1625, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:204); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1$$anonfun$3.apply(FileFormatWriter.scala:129); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1$$anonfun$3.apply(FileFormatWriter.scala:128); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at jav",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2407:4128,failure,failure,4128,https://hail.is,https://github.com/hail-is/hail/issues/2407,1,['failure'],['failure']
Availability,"cala:2118); at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); ... 1 more. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/b09ec92a-49f4-4d16-ad6d-efc5a5805e92/05_variant_qc.py"", line 201, in <module>; cumcounts = {'step0': rt.aggregate(hl.agg.sum(hl.cond(rt.qccum.step0, 1, 0))),; File ""<decorator-gen-519>"", line 2, in aggregate; File ""/home/hail/hail.zip/hail/utils/java.py"", line 191, in handle_py4j; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 6.0 failed 20 times, most recent failure: Lost task 7.19 in stage 6.0 (TID 179, robert1-w-0.c.ccdg-wgs.internal, executor 4): java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.annotations.RegionValueBuilder.endStruct(RegionValueBuilder.scala:109); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2645); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2615); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.colle",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3063:11852,failure,failure,11852,https://hail.is,https://github.com/hail-is/hail/issues/3063,1,['failure'],['failure']
Availability,cala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). is.hail.utils.HailException: cannot set missing field for required type +PFloat64; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:207); 	at is.hail.io.vcf.VCFLine.parseAddInfoArrayDouble(LoadVCF.scala:1034); 	at is.hail.io.vcf.VCFLine.parseAddInfoField(LoadVCF.scala:1055); 	at is.hail.io.vcf.VCFLine.addInfoField(LoadVCF.scala:1075); 	at is.hail.io.vcf.VCFLine.parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7$adapted(LoadVCF.scala:1909); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:515); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at __C678stream_Let.apply(Emit.scala); 	at is.hail.expr.ir.CompileIterator$$anon$2.step(Compile.scala:302); 	at is.hail.expr.ir.Comp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:18734,Error,ErrorHandling,18734,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['Error'],['ErrorHandling']
Availability,"call last):; File ""foo.py"", line 7, in <module>; t.write('foo.ht', overwrite=True); File ""/Users/cseed/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/cseed/hail/python/hail/table.py"", line 1183, in write; self._jt.write(output, overwrite, stage_locally, _codec_spec); File ""/Users/cseed/py4j/java_gateway.py"", line 1133, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/cseed/hail/python/hail/utils/java.py"", line 200, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: OrderedRVD error! Unexpected key in partition 7; Range bounds for partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Key should be in partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Invalid key: [0.9986274705095608]. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 2.0 failed 1 times, most recent failure: Lost task 7.0 in stage 2.0 (TID 23, localhost, executor driver): is.hail.utils.HailException: OrderedRVD error! Unexpected key in partition 7; Range bounds for partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Key should be in partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Invalid key: [0.9986274705095608]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1011); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.io.RichContextRDDRegionValue$.writeRowsPartition(RowStore.scala:1071); 	at is.hail.io.RichContextRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4096:1289,failure,failure,1289,https://hail.is,https://github.com/hail-is/hail/issues/4096,1,['failure'],['failure']
Availability,"cally created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. <details>; <summary>âš ï¸ <b>Warning</b></summary>. ```; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiohttp 3.8.5 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **551/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `41.0.2 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13366:1054,avail,available,1054,https://hail.is,https://github.com/hail-is/hail/pull/13366,1,['avail'],['available']
Availability,"can we dig into just one of these errors? Can you get the IR before and after streamify, so we know what it's doing wrong?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063#issuecomment-586599441:34,error,errors,34,https://hail.is,https://github.com/hail-is/hail/pull/8063#issuecomment-586599441,1,['error'],['errors']
Availability,"can you try running with the latest version? I fixed this specific issue recently, but it's possible you'll get another error (it's not tested as part of our CI)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5657#issuecomment-475096140:120,error,error,120,https://hail.is,https://github.com/hail-is/hail/issues/5657#issuecomment-475096140,1,['error'],['error']
Availability,"casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass'); print(""Filtering Common Variants""); common=passed.filter_rows(passed.variant_qc.AF > 0.01).persist(); common.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass.common'); print(""Pruning LD Variants""); pruned =hl.ld_prune(common,30,r2=0.1, memory_per_core=2048); pruned.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pruned'); print(""Sample 20% of variants for running PC-Relate""); pruned_subsample = pruned.sample_rows(0.2).persist(); print(""Running PC_Relate""); rel = hl.pc_relate(pruned_subsample.GT, 0.01, k=10); rel_df = rel.to_pandas(); rel_df.describe(); pprint(rel_df); rel_df.to_csv('gcad_5k.snv.rel.csv'); ```. ### What went wrong (all error messages here, including the full java stack trace):. Got a memory error. but not sure what memory needs to be increased. The job seems to restart but does not progress and need to kill. . java.lang.OutOfMemoryError: Java heap spaceop. Running on Apache Spark version 2.2.0; SparkUI available at http://10.48.225.55:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-63d60cc; NOTE: This is a beta version. Interfaces may change; during the beta period. We also recommend pulling; the latest changes weekly.; Read in PASS SNVs; Filtering Common Variants; [Stage 0:==================================================>(96600 + 1) / 96601]2018-04-27 20:54:43 Hail: INFO: wrote 11341822 items in 96601 partitions; Pruning LD Variants; [Stage 1:==================================================>(96598 + 3) / 96601]2018-04-27 21:19:04 Hail: INFO: Running LD prune with nSamples=4795, nVariants=11341822, nPartitions=96601, and maxQueueSize=429841.; [Stage 2:=========================================> (79823 + 18) / 96601]java.lang.OutOfMemoryError: Java heap spaceop""; at java.util.Arrays.copyOf(Arrays.java:3181); at java.util.ArrayList.toArray(ArrayList.java:376); at java.util.Collections$SynchronizedCollection.toArray(Collections.java:2024); at ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3463:2219,avail,available,2219,https://hail.is,https://github.com/hail-is/hail/issues/3463,1,['avail'],['available']
Availability,"case. I do explicitly pull the worker image (with one retry) before trying to run it.; - Batch and Job are gone. database.py is effectively gone. Almost everywhere interacts directly with the database using the simple gear.Database interface, and drops down to aiomysql directly when that is insufficient (e.g. transaction with multiple executemany for /jobs/create). When we pass around data representing a job or batch, it's normally a data record (a dict).; - Added the running log test from your PR.; - The job status is no longer written to a file, just in the database jobs.status.; - I moved the INSTANCE_ID to the database. There is now a table called tokens. It has the instance id and a token for securing communication between the front end and the driver (currently unused).; - Operations that need to be atomic in the database are now implemented as stored procedures which can be called with the check_call_procedure helper in database.py. They return a row with a field rc (return code) that is 0 on success and non-zero on failure.; - Renamed Driver => Scheduler. Scheduler has two threads, one that schedules jobs that are in the Ready state, and one that cancels cancelled jobs in the Running state. There is a new job state Ready. A job is Ready if its parents are complete and it is not scheduled (instance_id is null). A job is Running if it is scheduled (instance_id is not null).; - The full set of instances are mirrored in memory as Instance objects.; - Added a ready_cores table with a single row that has the total core count of the ready jobs. It is updated by the stored procedures as jobs are scheduled/unscheduled/marked complete. It is used by the instance pool control loop. This is great, and something we couldn't easily see before. Things that got removed that I will add back in the next PRs:; - Database retries; - Instance pool heal loop; - Instance health; - attempt tokens (from the Google backend). These are all pretty easy. Then back to scale tests. Let me",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7420:1598,failure,failure,1598,https://hail.is,https://github.com/hail-is/hail/pull/7420,1,['failure'],['failure']
Availability,"cc @cseed . Is this something you would be interested in having back in the codebase? Konrad and Alicia would like it, and it could be helpful for debugging, since Hail errors (say stuck jobs) often require the log, and users have to remember to persist those logs and send them to us.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7392:169,error,errors,169,https://hail.is,https://github.com/hail-is/hail/issues/7392,1,['error'],['errors']
Availability,"cc: @cseed . ---. Root issue is that `alpine` does not have `/bin/bash`, so we use `/bin/sh` instead. The syntax for the loops is POSIX compliant. ---. Interesting, these pods were failing due to:. ```; State: Terminated; Reason: ContainerCannotRun; Message: oci runtime error: container_linux.go:247: starting container process caused ""exec: \""/bin/bash\"": stat /bin/bash: no such file or directory"". Exit Code: 127; Started: Fri, 18 Jan 2019 16:15:45 -0500; Finished: Fri, 18 Jan 2019 16:15:45 -0500; Ready: False; ```. But this didn't fail the tests. I suppose because we cancel it faster than k8s realizes the container cannot run and notifies batch?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5175:271,error,error,271,https://hail.is,https://github.com/hail-is/hail/pull/5175,1,['error'],['error']
Availability,"cc: @cseed @konradjk . This PCRelate should handle larger data sizes than the previous one by avoiding shuffles. It avoids the shuffle by writing the vds to a temporary directory in block matrix form. It then loads this BlockMatrix directly. Form that point forward, the PCRelate algorithm is just non-shuffling linear algebra (however: matrix multiplication will require each node to communicate with approximately `n+m` other nodes). I'm vaguely uncomfortable with two things:. 1. I've added some hail expr lang to mean impute missing values. This is written in python. As such, correctly mean imputing is not tested by our test system any more. The mean imputation is pretty simple, so maybe we should just verify my code is right?. 2. I noticed that at some earlier point PCA was moved outside of Java as well. This also makes me uncomfortable for the same reason. Moving the tests into python is a fair lift because, AFAIK, we don't have as robust test infrastructure over there. I'm torn between the desire to get this out for @konradjk and the desire to follow our normal testing standards. ---. I've played a bit with this locally, but have not tried it on a large cluster. @konradjk, I would be very interested in how this performs on a large dataset, if you would be so kind. Please don't try this until the CI tests and doc builds pass on this PR though. I haven't run the tests locally, so I'm not certain it passes them :P",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2821:946,robust,robust,946,https://hail.is,https://github.com/hail-is/hail/pull/2821,1,['robust'],['robust']
Availability,"cc: @cseed @rcownie @catoverdrive . Amanda saw this error with these changes:. ```; amwang: fyi, this is the error the executor is seeing on a cluster with that jar:. ERROR: dlopen(""/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1535651898654_0001/container_1535651898654_0001_01_000002/tmp/libhail8271834084559267793.so""): /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1535651898654_0001/container_1535651898654_0001_01_000002/tmp/libhail8271834084559267793.so); FATAL: caught exception java.lang.UnsatisfiedLinkError: /hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1535651898654_0001/container_1535651898654_0001_01_000002/tmp/libhail8271834084559267793.so: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1535651898654_0001/container_1535651898654_0001_01_000002/tmp/libhail8271834084559267793.so); java.lang.UnsatisfiedLinkError: /hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1535651898654_0001/container_1535651898654_0001_01_000002/tmp/libhail8271834084559267793.so: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1535651898654_0001/container_1535651898654_0001_01_000002/tmp/libhail8271834084559267793.so); at java.lang.ClassLoader$NativeLibrary.load(Native Method); at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1824); at java.lang.Runtime.load0(Runtime.java:809); at java.lang.System.load(System.java:1086); at is.hail.nativecode.NativeCode.<clinit>(NativeCode.java:27); at is.hail.nativecode.NativeBase.<init>(NativeBase.scala:22); at is.hail.annotations.Region.<init>(Region.scala:33); at is.hail.annotations.Region$.apply(Region.scala:15); at is.hail.rvd.RVD",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4239#issuecomment-417433186:52,error,error,52,https://hail.is,https://github.com/hail-is/hail/pull/4239#issuecomment-417433186,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"cc: @daniel-goldstein is it possible to make the error more clear? The CI test job is a bit hard to read. Maybe the last line of the output should be something like ""XXXX file is out of date, run YYYY""",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11840#issuecomment-1325464620:49,error,error,49,https://hail.is,https://github.com/hail-is/hail/pull/11840#issuecomment-1325464620,2,['error'],['error']
Availability,"cc: @daniel-goldstein, this is a tricky asyncio situation which you should also keep in mind. OK, there were two problems:. 1. A timeout of 5s appears to be now too short for Google Cloud Storage. I am not sure why but we; timeout substantially more frequently. I have observed this myself on my laptop. Just this; morning I saw it happen to Daniel. 2. When using an `aiohttp.AsyncIterablePayload`, it is *critical* to always check if the coroutine; which actually writes to GCS (which is stashed in the variable `request_task`) is still; alive. In the current `main`, we do not do this which causes hangs (in particular the timeout; exceptions are never thrown ergo we never retry). To understand the second problem, you must first recall how writing works in aiogoogle. There are; two Tasks and an `asyncio.Queue`. The terms ""writer"" and ""reader"" are somewhat confusing, so let's; use left and right. The left Task has the owning reference to both the source ""file"" and the; destination ""file"". In particular, it is the *left* Task which closes both ""files"". Moreover, the; left Task reads chunks from the source file and places those chunks on the `asyncio.Queue`. The; right Task takes chunks off the queue and writes those chunks to the destination file. This situation can go awry in two ways. First, if the right Task encounters any kind of failure, it will stop taking chunks off of the; queue. When the queue (which has a size limit of one) is full, the left Task will hang. The system; is stuck. The left Task will wait forever for the right Task to empty the queue. The second scenario is exactly the same except that the left Task is trying to add the ""stop""; message to the queue rather than a chunk. In either case, it is critical that the left Task waits simultaneously on the queue operation *and*; on the right Task completing. If the right Task has died, no further writes can occur and the left; Task must raise an exception. In the first scenario, we do not observe the right Task'",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11830:539,alive,alive,539,https://hail.is,https://github.com/hail-is/hail/pull/11830,1,['alive'],['alive']
Availability,"cc: @danking . Here is the first major database migration. The goal is to add all attempt resources into the database for any attempt with batch format version less than 3. The node configuration was the same for all attempts back then with standard instances, 16 cores, and a 100GB boot disk. I figured out what the quantity for each resource should be by looking at how we compute quantities for resources in `batch/batch/resources.py`. I checked the inserted quantities are identical to the attempts that already exist in the database right after we converted the billing over to using resources. Once we have all resources for all attempts, the next step (future PR) is to do a scan and repopulate the new aggregated billing tables **by date**. In this PR, I don't try and add the usage to the existing `aggregated_*_resources` tables. I did this to cut down on time and space since we're eventually going to deprecate those tables anyways. Because I don't touch those tables, we don't need to worry about modifying the client code and how the current billing information is calculated. How this migration works is there are 5 phases:; 1. Compute the expected number of attempts to process for format version < 3. ; 2. Divide the search space into chunks of size 100 attempts (empirically determined this was the best chunk size) and randomize the order of the chunks.; 3. Serially process 5000 chunks with only 10 out of the 100 records as a ""burn in period"" to avoid the birthday problem when trying to insert records in parallel.; 4. In parallel, process all the chunks with 10 way parallelism (empirically determined to max CPU for a 4 core db instance); 5. Do an audit of the results to make sure the attempt resources now has the correct number of rows and the billing is within $0.001 per job with the old way and new way of computing the billing. The tolerance of $0.001 was empirically determined. At a threshold of $0.0001, 33/30,000,000 attempts failed. I think this is good enough as t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11990:858,down,down,858,https://hail.is,https://github.com/hail-is/hail/pull/11990,1,['down'],['down']
Availability,cc: @jigold. I am honestly not sure how this should interact with terraform. We do specify the; node pools there. I worry that using terraform to change the node pools would create; downtime.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11443:182,downtime,downtime,182,https://hail.is,https://github.com/hail-is/hail/pull/11443,1,['downtime'],['downtime']
Availability,cc: @tpoterba . Previously stderr ended up in the build log while stdout ended up in the per-task log. This change ensures all output (err or out) goes to the log. The only information in the build log is about the orchestration script. This should make debugging CI build failures much easier because stderr and stdout are in one place.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4581:273,failure,failures,273,https://hail.is,https://github.com/hail-is/hail/pull/4581,1,['failure'],['failures']
Availability,"cc: @tpoterba @konradjk . Include the words success and failure and some color, but preserve the exit code. Also, banish tabs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6054:56,failure,failure,56,https://hail.is,https://github.com/hail-is/hail/pull/6054,1,['failure'],['failure']
Availability,"cc: @tpoterba @patrick-schultz @catoverdrive . We are not allowed to clear a region we do not own. Someone should test this doesn't blow memory on a severe filter in the cloud. ---. Prevent segfaults when joining two tables using `t1.join(t2)`. This syntax does a ""product join"", i.e., a normal join. The `t2[t1.key]` syntax takes only one matching element from `t2` for each element in `t1`. When performing a ""product join"", hail keeps a side-buffer of region values from the right-hand-side table. This side buffer *must not be cleared* by down stream operations (it is owned by the join node). Unfortunately, hail's filter method was incorrectly clearing regions it might not own. This bug only appeared as a segfault when `t1.join(t2)` was followed by a filter.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5421:543,down,down,543,https://hail.is,https://github.com/hail-is/hail/pull/5421,1,['down'],['down']
Availability,"cc: @tpoterba I added some new type check stuff. I added `round` `ceil` and `floor` as I was writing tests and then I didn't need them. They still seem useful, so I included them. I had to add a tolerance parameter to `Table.same` and my implementation is kind of ugly and bad but I can't think of an obviously better way to do this. Example usages:. ```python; imputed_sex = methods.impute_sex(ds.v.locus(), ds.GT); ```. ```python; imputed_sex = methods.impute_sex(ds.v.locus(), ; ds.GT,; aaf=gnomad.AF); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2852:195,toler,tolerance,195,https://hail.is,https://github.com/hail-is/hail/pull/2852,1,['toler'],['tolerance']
Availability,"cc: the ""services team"" @cseed, @johnc1231. This fixes gateway to log the user's IP. Forthcoming PRs will fix all downstream; services. ---. There are two important pieces of which to be aware:. - The gateway pod are exposed via the gateway Service, which is the only; object modified in this PR.; - K8s fulfills our request for the gateway Service by creating a [Google TCP; LoadBalancer](https://console.cloud.google.com/net-services/loadbalancing/loadBalancers/list). Moreover,; we specify `loadBalancerIP` which is a manually (outside of k8s) allocated IP; which we expose on the public internet. When you `curl https://hail.is` this is what happens:. - Your packet travels across the internet until it reaches the Google TCP; LoadBalancer; - The Google TCP LoadBalancer selects one of the kubernetes nodes to send the; packet to (in principle, it could send the packet to *any* node, even nodes; that do not have a gateway pod).; - Some part of k8s receives the packet and discovers the nodes that host a; gateway pod.; - It selects a gateway pod and forwards the packet to the node (possibly itself); hosting that gateway pod. In doing so, *it must replace the source IP of the; packet with its own, internal, IP*. Note that this is happening at the TCP layer, so no HTTP headers are set. When; the gateway `nginx` receives the packet, there is no trace of the source; IP. Kubernetes has a feature called `externalTrafficPolicy` which is available; in GCP and Azure and preserves the source IP. Kubernetes achieves this by; failing the TCP LoadBalancer healthchecks on nodes without matching pods (in our; case, gateway). The k8s docs on [Source IPs](https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-type-loadbalancer) further explain this strategy. Here's what the healthchecks look like for two; nodes, one hosting a gateway pod and one not hosting a gateway pod (note the; HTTP status code):. ```; dking@gke-vdc-preemptible-pool-2-9aa4dbeb-wvxk ~ $ curl -v",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8045:114,down,downstream,114,https://hail.is,https://github.com/hail-is/hail/pull/8045,1,['down'],['downstream']
Availability,"ccessfully, the job is marked as scheduled.; 4. Once all requests complete, goto 1. On the worker, what happens inside `/api/v1alpha/batches/jobs/create`:; 1. Read metadata describing the job to schedule from the request body; 2. Using that information, load the full job spec from blob storage; 3. Spawn a task to run the job asynchronously; 4. Respond to the driver with a 200. The key point relevant to this issue is that the driver currently must wait for all the requests to workers in an iteration to complete before it starts the next iteration of the scheduler. This leaves the scheduler vulnerable to problematic workers or workers that happen to be preempted during the scheduling process. So, the driver sets a [2 second timeout](https://github.com/hail-is/hail/blob/b27737f67bf9e69f1abed2fec07fc7c921790ef8/batch/batch/driver/job.py#L585) on the call to `/api/v1alpha/batches/jobs/create`. Additionally, this general design means that in the event of a request timeout or transient error, Batch cannot guarantee that there is always at most one concurrent running attempt for a given job. This ends up being a fine (and intentional) concession in practice because the idempotent design of preemptible jobs tends to cover this scenario, but it is regardless wasted compute and cost to users. Nevertheless, we strive to minimize cases where we might halt the scheduling loop or double-schedule work, and one way to do that in the current design is to minimize the variance in latency of `/api/v1alpha/batches/jobs/create`. The largest source of this latency is the request to blob storage. While GCS and ABS are relatively fast and highly available, Batch in Azure Terra requires first obtaining SAS tokens from the Terra control plane, which can introduce much higher and more variable latency. There have also been occurrences in the past of corrupted or deleted specs, which introduce unexpected failure modes that should error the job but instead disrupt the scheduling loop. Many of the",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14456:1435,error,error,1435,https://hail.is,https://github.com/hail-is/hail/issues/14456,1,['error'],['error']
Availability,ccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745)is.hail.utils.HailException: malformed.vcf: caught htsjdk.tribble.TribbleException$InternalCodecException: The allele with index 10026357 is not defined in the REF/ALT columns in the record; offending line: 20	10026348	.	A	G	7535.22	PASS	HWP=1.0;AC=2;culprit=Inbreedi...; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:10); 	at is.hail.utils.package$.fatal(package.scala:20); 	at is.hail.utils.TextContext.wrapException(Context.scala:15); 	at is.hail.utils.WithContext.map(Context.scala:27); 	at is.hail.io.vcf.LoadVCF$$anonfun$14$$anonfun$apply$7.apply(LoadVCF.scala:301); 	at is.hail.io.vcf.LoadVCF$$anonfun$14$$anonfun$apply$7.apply(LoadVCF.scala:301); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$7$$anon$2.hasNext(OrderedRDD.scala:210); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1763); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1134); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1134); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882:6726,Error,ErrorHandling,6726,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882,1,['Error'],['ErrorHandling']
Availability,"cda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). ðŸ›  [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). ðŸ“š [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""8f2f7ae4-0cec-47e6-822f-e81b1067da22"",""prPublicId"":""8f2f7ae4-0cec-47e6-822f-e81b1067da22"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""numpy"",""from"":""1.21.3"",""to"":""1.22.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-NUMPY-2321964"",""SNYK-PYTHON-NUMPY-2321966"",""SNYK-PYTHON-NUMPY-2321970"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,null,null,null,509,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. ðŸ¦‰ [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); ðŸ¦‰ [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); ðŸ¦‰ [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); ðŸ¦‰ [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13871:7086,avail,available,7086,https://hail.is,https://github.com/hail-is/hail/pull/13871,1,['avail'],['available']
Availability,"cda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). ðŸ“š [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""f06f3836-ea3a-4143-ba99-12b7ad33753d"",""prPublicId"":""f06f3836-ea3a-4143-ba99-12b7ad33753d"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.2""},{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.11.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622"",""SNYK-PYTHON-AIOHTTP-6209406"",""SNYK-PYTHON-AIOHTTP-6209407"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-JUPYTERSERVER-6099119"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,531,null,null,null,509,384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. ðŸ¦‰ [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); ðŸ¦‰ [Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;)](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr); ðŸ¦‰ [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); ðŸ¦‰ [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14259:7735,avail,available,7735,https://hail.is,https://github.com/hail-is/hail/pull/14259,1,['avail'],['available']
Availability,"ce for Amanda:; ```; Traceback (most recent call last):; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/assign_subpops.py"", line 157, in <module>; main(args); File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/assign_subpops.py"", line 98, in main; pca_mt = hl.ld_prune(pca_mt, r2=0.1, n_cores=args.num_cores); File ""<decorator-gen-788>"", line 2, in ld_prune; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/hail-devel-38dbf156b630.zip/hail/typecheck/check.py"", line 490, in _typecheck; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/hail-devel-38dbf156b630.zip/hail/methods/statgen.py"", line 2918, in ld_prune; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/hail-devel-38dbf156b630.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 530 in stage 9.0 failed 20 times, most recent failure: Lost task 530.19 in stage 9.0 (TID 19101, gt1-w-78.c.broad-mpg-gnomad.internal, executor 199): java.lang.ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2; 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:643); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9$$anonfun$apply$10.apply(RVD.scala:222); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9$$anonfun$apply$10.apply(RVD.scala:221); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:221); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:220); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:220); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:218); 	at scala.collection.I",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:1024,failure,failure,1024,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627,1,['failure'],['failure']
Availability,"ced from <a href=""https://github.com/pallets/click/releases"">click's releases</a>.</em></p>; <blockquote>; <h2>8.1.3</h2>; <p>This is a fix release for the <a href=""https://github.com/pallets/click/releases/tag/8.1.0"">8.1.0</a> feature release.</p>; <ul>; <li>Changes: <a href=""https://click.palletsprojects.com/en/8.1.x/changes/#version-8-1-3"">https://click.palletsprojects.com/en/8.1.x/changes/#version-8-1-3</a></li>; <li>Milestone: <a href=""https://github.com/pallets/click/milestone/18?closed=1"">https://github.com/pallets/click/milestone/18?closed=1</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/click/blob/main/CHANGES.rst"">click's changelog</a>.</em></p>; <blockquote>; <h2>Version 8.1.3</h2>; <p>Released 2022-04-28</p>; <ul>; <li>Use verbose form of <code>typing.Callable</code> for <code>@command</code> and; <code>@group</code>. :issue:<code>2255</code></li>; <li>Show error when attempting to create an option with; <code>multiple=True, is_flag=True</code>. Use <code>count</code> instead.; :issue:<code>2246</code></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/click/commit/9c6f4c8e1bb8670ce827c98559f57f6ee5935cd0""><code>9c6f4c8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2262"">#2262</a> from pallets/release-8.1.3</li>; <li><a href=""https://github.com/pallets/click/commit/5ec77494bdf2c294d3b082bed429ebce78321431""><code>5ec7749</code></a> release version 8.1.3</li>; <li><a href=""https://github.com/pallets/click/commit/2ac3211cb79a63bae8e6f0441136b432ec2126bc""><code>2ac3211</code></a> update requirements</li>; <li><a href=""https://github.com/pallets/click/commit/5fd87bdf80ed450334b37344f6c99890c217d3db""><code>5fd87bd</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2248"">#2248</a> from jreese/8.1.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11973:1102,error,error,1102,https://hail.is,https://github.com/hail-is/hail/pull/11973,1,['error'],['error']
Availability,cessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.base/java.lang.Thread.run(Thread.java:834). is.hail.utils.HailException: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.variant.ReferenceGenome.checkLocus(ReferenceGenome.scala:210); 	at is.hail.variant.Locus$.apply(Locus.scala:18); 	at is.hail.variant.Locus$.annotation(Locus.scala:24); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$3(LoadPlink.scala:43); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$3$adapted(LoadPlink.scala:37); 	at is.hail.utils.WithContext.foreach(Context.scala:49); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2(LoadPlink.scala:37); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2$adapted(LoadPlink.scala:36); 	at scala.collection.Iterator.foreach(Iterator.scala:941); 	at scala.collection.Iterator.foreach$(Iterator.scala:941); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1(LoadPlink.scala:36); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1$adapted(LoadPlink.scala:35); 	at is.hail.io.fs.FS.$anonfun$readLines$1,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:5221,Error,ErrorHandling,5221,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['Error'],['ErrorHandling']
Availability,"ch bucket to pull the VEP cache data from. In more recent versions (tested with 0.2.130), this `VEP_REPLICATE` variable has been changed to `VEP_REPLICATE=australia-southeast1`, however the Australian bucket containing the VEP cache data is still `aus-sydney`, meaning that the VEP data is not copied into the dataproc cluster, and when trying to run VEP I get the error `No cache found for homo_sapiens, version 95`. ### Version. 0.2.130. ### Relevant log output. ```shell; FatalError: HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 241.; DBI connect('dbname=/opt/vep/.vep/loftee.sql','',...) failed: unable to open database file at /opt/vep/Plugins/LoF.pm line 126. -------------------- EXCEPTION --------------------; MSG: ERROR: No cache found for homo_sapiens, version 95. STACK Bio::EnsEMBL::VEP::CacheDir::dir /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:328; STACK Bio::EnsEMBL::VEP::CacheDir::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:227; STACK Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modul",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:1527,Error,Error,1527,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['Error'],['Error']
Availability,"ch is annoying. Anyway now when someone asks how to count the mutations in each gene by consequence type we can point them to the `counter` docs. ---. Adding a dataset caused a bunch of docs failure that lead me to change how we do doctesting. The changes are summarized below.; - ignore `python/.eggs`; - make `PARALLELISM` configurable in `Makefile`; - fix `make pytest` (it referenced a non-extant target); - add `make doctest` (this and `pytest` use setup.py to replicate the environment the user would have after installation, I prefer this approach because I need not manually install any dependencies, setup.py handles that, it also configures spark correctly without environment variables); - harmonize `doctest` and `pytest` parameters in `build.gradle` and `Makefile`; - clean up import order in `conftest.py` to match pylint's desired ordering; - use a `temple.TemporaryDirectory` for all doctest and test output, which is automatically cleaned up (if you want to interrogate it you can `ctrl-z` a running doctest); this allows us to not copy the entire python directory into a build directory before running pytest; - *important:* re-generate all input datasets on every run of the tests. Previously, there was a file `doctest_write_data.py` which you were supposed to run when you changed the datasets, but if Hail changes then the random datasets generated by `doctest_write_data.py` might change. This means when I came along to add a new dataset, I had to address all the test failures introduced since the last time `doctest_write_data.py`'s results were checked in. (the doctests still only take about 2 minutes); - I fixed several latent doc bugs caused by the aforementioned situation; - I changed ""Using Variants as Covariates"" in `guides/genetics.rst` because it seemed complicated and was broken by the aforementioned situation; - I removed `NOTEST` which was a custom pytest annotation that duplicates the functionality of `SKIP` (I changed all `NOTEST` annotations to `SKIP`)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6856:2024,failure,failures,2024,https://hail.is,https://github.com/hail-is/hail/pull/6856,1,['failure'],['failures']
Availability,chRDDRegionValue$$anonfun$5.apply(RowStore.scala:757); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:756); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:65); at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:246); at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$8.apply(TorrentBroadcast.scala:293); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:294); at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:226); at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); ... 18 more; Caused by: java.lang.ClassNotFoundException: is.hail.utils.SerializableHadoopConfiguration; at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:3,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342:4069,Error,Error,4069,https://hail.is,https://github.com/hail-is/hail/issues/3342,1,['Error'],['Error']
Availability,"ch_avx2::int32<8>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::int32<8>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::int32<8>]â€™; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:114:36: required from â€˜simdpp::arch_avx2::uint64<4>& simdpp::arch_avx2::uint64<4>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int32<8>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:300:19: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint64<4>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint64<4>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::int32<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:27,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:91:7: note: â€˜class simdpp::arch_avx2::uint64<4>â€™ declared here; class uint64<4, void> : public any_int64<4, uint64<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int32<8>; T = simdpp::arch_avx2::uint64<4>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:80237,error,error,80237,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"ch_avx2::int64<2>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::int64<2>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::int64<2>]â€™; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:129:36: required from â€˜simdpp::arch_avx2::uint64<2>& simdpp::arch_avx2::uint64<2>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::int64<2>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:270:19: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint64<2>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint64<2>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::int64<2>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:26,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:102:7: note: â€˜class simdpp::arch_avx2::uint64<2>â€™ declared here; class uint64<2, void> : public any_int64<2, uint64<2,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int32<4>; T = simdpp::arch_avx2::uint64<2>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:71306,error,error,71306,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,change OrderedRVD assertion to better error message for split_multi,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4130:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/pull/4130,1,['error'],['error']
Availability,chaos failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4541:6,failure,failure,6,https://hail.is,https://github.com/hail-is/hail/issues/4541,1,['failure'],['failure']
Availability,"che.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:753); at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:371); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:303); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Shell output: main : command provided 1; main : run as user is farrell; main : requested yarn user is farrell. Container exited with a non-zero exit code 1. Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container marked as failed: container_e2435_1542127286896_0109_02_000004 on host: scc-q06.scc.bu.edu. Exit status: 1. Diagnostics: Exception from container-launch.; Container id: container_e2435_1542127286896_0109_02_000004; Exit code: 1; Stack trace: ExitCodeException exitCode=1:; at org.apache.hadoop.util.Shell.runCommand(Shell.java:576); at org.apache.hadoop.util.Shell.run(Shell.java:487); at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:753); at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:371); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:303); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); at java",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-446057705:3258,failure,failure,3258,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-446057705,1,['failure'],['failure']
Availability,checkpoint could only run upstream if file is missing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5599:0,checkpoint,checkpoint,0,https://hail.is,https://github.com/hail-is/hail/issues/5599,1,['checkpoint'],['checkpoint']
Availability,"chel-kraemer/gradle-download-task) from 3.2.0 to 5.2.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/michel-kraemer/gradle-download-task/releases"">de.undercouch.download's releases</a>.</em></p>; <blockquote>; <h2>5.2.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Use pooling connection manager of Apache HttpClient instead of basic one. The basic one is not meant to be used by multiple threads. This fixes an issue that could cause an <code>IllegalStateException</code> with the message <code>Connection is still allocated</code>. Thanks to <a href=""https://github.com/dmarks2""><code>@â€‹dmarks2</code></a> for spotting this.</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.0</h2>; <p>New features:</p>; <ul>; <li>Add <code>eachFile</code> method that adds an action to be applied to each source URL before it is downloaded. The action can be used to modify the filename of the target file.</li>; <li>Add <code>runAsync</code> method to download extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:1066,down,download,1066,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['down'],['download']
Availability,"ches in 17 ms; 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms; 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms; [thread 46926922934016 also had an error][thread 46922053207808 also had an error][thread 46926901880576 also had an error][thread 46926888195840 also had an error][thread 46926887143168 also had an error][thread 46924854015744 also had an error]; [thread 46924847699712 also had an error]. 	#. 	# A fatal error has been detected by the Java Runtime Environment:. 	[thread 46926905038592 also had an error]#; 	# ; 	[thread 46926895564544 also had an error][thread 46926900827904 also had an error]. 	SIGSEGV (0xb) at pc=0x00002aaab5115c88, pid=34051, tid=0x00002aae05d1a700; 	#; 	# JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-b08); 	# Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 compressed oops); 	# Problematic frame:; 	[thread 46926929250048 also had an error]# ; 	[thread 46926881888000 also had an error]; 	J 5583 C2 __C111CompiledWithAggs.__m131wrapped(Lis/hail/annotations/Region;J)V (280 bytes) @ 0x00002aaab5115c88 [0x00002aaab5115ae0+0x1a8]; 	#; 	# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; 	#; 	[thread 46924863489792 also had an error]; 	[thread 46924861384448 also had an error]; 	# An error report file with more information is saved as:; 	# /local/scratch/app-20200610100916-0000/0/hs_err_pid34051.log; 	[thread 46926913459968 also had an error]; 	[thread 46924843489024 also had an error][thread 46926917670656 also had an error]. 	#; 	# If you would like to submit a bug report, please visit:; 	# http://bugreport.java.com/bugreport/crash.jsp; 	#. To summarize our observations:; * The issue does not occur when hail is initialized without an existing spark master; * The issue does not occur in HAIL versions prior to 0.2.43 (tested: 0",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:19272,error,error,19272,https://hail.is,https://github.com/hail-is/hail/issues/8944,2,['error'],['error']
Availability,"chols_model: generating genotypes for 1 populations, 1000 samples, and 50000 variants...; 	[Stage 9:> (0 + 18) / 18]; 	[FAIL] with 354 partitions; 	Traceback (most recent call last):; 	 File ""test_11_cluster_sampleqc.py"", line 20, in <module>; 		print(""\n[PASS] with"", N, ""partitions:"", Y.count()); 	 File ""/bmrn/apps/hail/0.2.44/python/hail-0.2.44-py3-none-any.egg/hail/matrixtable.py"", line 2426, in count; 		return Env.backend().execute(count_ir); 	 File ""/bmrn/apps/hail/0.2.44/python/hail-0.2.44-py3-none-any.egg/hail/backend/spark_backend.py"", line 296, in execute; 		result = json.loads(self._jhc.backend().executeJSON(jir)); 	 File ""/bmrn/apps/spark/2.4.5/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; 	 File ""/bmrn/apps/hail/0.2.44/python/hail-0.2.44-py3-none-any.egg/hail/backend/spark_backend.py"", line 41, in deco; 		'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 	hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: ResultStage 9 (runJob at RVD.scala:688) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:882) at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:878) at scala.collection.Iterator$class.foreach(Iterator.scala:891) at scala.collection.AbstractIterator.foreach(Iterator.scala:1334) at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:878) at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:691) at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.ite",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:3774,failure,failure,3774,https://hail.is,https://github.com/hail-is/hail/issues/8944,1,['failure'],['failure']
Availability,"ci failure:; ```; hail version: 0.2.109-c163bcb21073; Error summary: AssertionError: assertion failed; self = <test.hail.linalg.test_linalg.Tests testMethod=test_tree_matmul>. @fails_service_backend(); @fails_local_backend(); def test_tree_matmul(self):; nm = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]); m = BlockMatrix.from_numpy(nm, block_size=2); nrow = np.array([[7.0, 8.0, 9.0]]); row = BlockMatrix.from_numpy(nrow, block_size=2); ; > with BatchedAsserts() as b:. test/hail/linalg/test_linalg.py:612: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; test/hail/linalg/test_linalg.py:96: in __exit__; vals.extend(list(hl.eval(tuple([all_bms[k] for k in bm_keys[batch_start:batch_start + batch_size]])))); <decorator-gen-692>:2: in eval; ???; hail/typecheck/check.py:577: in wrapper; return __original_func(*args_, **kwargs_); hail/expr/expressions/expression_utils.py:191: in eval; return eval_timed(expression)[0]; <decorator-gen-690>:2: in eval_timed; ???; hail/typecheck/check.py:577: in wrapper; return __original_func(*args_, **kwargs_); hail/expr/expressions/expression_utils.py:161: in eval_timed; return Env.backend().execute(MakeTuple([ir]), timed=True)[0]; hail/backend/py4j_backend.py:82: in execute; raise e.maybe_user_error(ir) from None; hail/backend/py4j_backend.py:76: in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); ../../.venv/lib/python3.10/site-packages/py4j/java_gateway.py:1321: in __call__; return_value = get_return_value(; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . args = ('xro549', <py4j.clientserver.JavaClient object at 0x7fd0d58f6fb0>, 'o1', 'executeEncode'); kwargs = {}; pyspark = <module 'pyspark' from '/home/edmund/.local/src/hail/.venv/lib/python3.10/site-packages/pyspark/__init__.py'>; s = 'java.lang.AssertionError: assertion failed', tpl = JavaObject id=o550; deepest = 'AssertionError: assertion failed'; full = 'java.lang.AssertionError: asserti",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12754#issuecomment-1456467229:3,failure,failure,3,https://hail.is,https://github.com/hail-is/hail/pull/12754#issuecomment-1456467229,2,"['Error', 'failure']","['Error', 'failure']"
Availability,"ci""><code>@â€‹pre-commit-ci</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_core/graphs/contributors?from=2024-01-08&amp;to=2024-03-12&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_core+involves%3Ablink1073+updated%3A2024-01-08..2024-03-12&amp;type=Issues""><code>@â€‹blink1073</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_core+involves%3Apre-commit-ci+updated%3A2024-01-08..2024-03-12&amp;type=Issues""><code>@â€‹pre-commit-ci</code></a></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_core/blob/main/CHANGELOG.md"">jupyter-core's changelog</a>.</em></p>; <blockquote>; <h2>5.7.2</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_core/compare/v5.7.1...1264a81fc834f18db2b41e136ec4ac9d1a4ad993"">Full Changelog</a>)</p>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Update Release Scripts <a href=""https://redirect.github.com/jupyter/jupyter_core/pull/396"">#396</a> (<a href=""https://github.com/blink1073""><code>@â€‹blink1073</code></a>)</li>; <li>Enforce pytest 7 <a href=""https://redirect.github.com/jupyter/jupyter_core/pull/393"">#393</a> (<a href=""https://github.com/blink1073""><code>@â€‹blink1073</code></a>)</li>; <li>chore: update pre-commit hooks <a href=""https://redirect.github.com/jupyter/jupyter_core/pull/392"">#392</a> (<a href=""https://github.com/pre-commit-ci""><code>@â€‹pre-commit-ci</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_core/graphs/contributors?from=2024-01-08&amp;to=2024-03-12&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_core+involves%3Ablink1073+updated%3A2024-01-08..2024-03-12&amp;type=Issues""><code>@â€‹blink1073</code></a> | <a href=""https://github.com/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14484:1974,Mainten,Maintenance,1974,https://hail.is,https://github.com/hail-is/hail/pull/14484,1,['Mainten'],['Maintenance']
Availability,"cies [0x00007fbeaec3cbb8,0x00007fbeaec3cbc0] = 8; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #; FATAL: caught signal 6 SIGABRT; /tmp/libhail7224206977949339430.so(+0x1788c)[0x7fbdea5db88c]; /lib/x86_64-linux-gnu/libc.so.6(+0x33060)[0x7fbec2eae060]; /lib/x86_64-linux-gnu/libc.so.6(gsignal+0xcf)[0x7fbec2eadfff]; /lib/x86_64-linux-gnu/libc.so.6(abort+0x16a)[0x7fbec2eaf42a]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(+0x8c0259)[0x7fbec27f0259]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(+0xa744f8)[0x7fbec29a44f8]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(JVM_handle_linux_signal+0x265)[0x7fbec27f9e45]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(+0x8bd4c8)[0x7fbec27ed4c8]; /lib/x86_64-linux-gnu/libpthread.so.0(+0x110c0)[0x7fbec38580c0]; [0x7fbeaec3ca22]; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [828e66d5a71741d7ab2c8d6580997da3] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""pyhail.py"", line 132, in <module>; main(args, pass_through_args); File ""pyhail.py"", line 113, in main; subprocess.check_output(job); File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 573, in check_output; raise CalledProcessError(retcode, cmd, output=output); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', '/Users/gtiao/gnomad_qc/hail/variant_qc/make_var_annot_hists.py', '--cluster', 'gt3', '--files=gs://hail-common/builds/devel/jars/hail-devel-cadc5eefca6e-Spark-2.2.0.jar', '--py-files=gs://hail-common/builds/devel/python/hail-devel-cadc5eefca6e.zip,/var/folders/rn/t2xcx1ps4h96txll46qkkfsj2q8bnl/T/pyscripts_K7Vs59.zip', '--driver-log-levels', 'root=FATAL,is.hail=INFO', '--properties=spark.executor.extraClassPath=./hail-devel-cadc5eefca6e-Spark-2.2.0.jar,spark.driver.extraClassPath=./hail-devel-cadc5eefca6",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4418:4075,ERROR,ERROR,4075,https://hail.is,https://github.com/hail-is/hail/issues/4418,1,['ERROR'],['ERROR']
Availability,"cies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.6""},{""name"":""pyjwt"",""from"":""1.7.1"",""to"":""2.4.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""rsa"",""from"":""4.5"",""to"":""4.7""}],""packageManager"":""pip"",""projectPublicId"":""e7c92c7b-5282-49ea-940f-7a5797e2a45a"",""projectUrl"":""https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-PYJWT-2840625"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-RSA-1038401""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. ðŸ¦‰ [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); ðŸ¦‰ [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); ðŸ¦‰ [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); ðŸ¦‰ [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14134:11188,avail,available,11188,https://hail.is,https://github.com/hail-is/hail/pull/14134,1,['avail'],['available']
Availability,"ck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/catarina.gouveia/miniconda3/envs/hail/lib/python3.7/site-packages/hail/matrixtable.py"", line 2508, in write; Env.backend().execute(MatrixWrite(self._mir, writer)); File ""/home/catarina.gouveia/miniconda3/envs/hail/lib/python3.7/site-packages/hail/backend/backend.py"", line 109, in execute; result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); File ""/home/catarina.gouveia/miniconda3/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/home/catarina.gouveia/miniconda3/envs/hail/lib/python3.7/site-packages/hail/utils/java.py"", line 225, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: Hail only supports 8-bit probabilities, found 16. Java stack trace:; java.lang.RuntimeException: error while applying lowering 'InterpretNonCompilable'; 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:26); 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); 	at is.hail.expr.ir.CompileAndEvaluate$$anonfun$apply$1.apply(CompileAndEvaluate.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); 	at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:14); 	at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:56); 	at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:56); 	at is.hail.utils.package$.using(package.scala:596); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:10); 	at is.hail.expr.ir",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:1944,error,error,1944,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['error'],['error']
Availability,"ckendHttpHandler.handle(BackendServer.scala:81); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:82); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:80); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:848); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:817); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:201); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:560); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:526); 	at java.base/java.lang.Thread.run(Thread.java:829). is.hail.utils.HailException: gs://path/to/bucket/chrY.0002.hard_filtered_with_genotypes.vcf.gz:offset 23933331019603: error while parsing line; chrY	113	.	GG	G,*,AG,CG	596	PASS	AC=2,4,6,1;AF=1.23e-03,5.550e-05,4.44e-05,2.00e-04;AN=265;AS_AltDP=10,0,3,10;AS_BaseQRankSum=0.000,.,0.100,0.500;AS_FS=7.777,.,2.144,8.001;AS_MQ=55.75,.,38.98,40.20;AS_MQRankSum=0.200,.,-1.050,-0.500;AS_QD=0.50,0.00,0.25,0.52;AS_ReadPosRankSum=-0.200,.,0.500,-0.220;AS_SOR=2.300,.,1.600,3.000;BaseQRankSum=0.200;DP=600000;ExcessHet=0.0477;FS=0.900;MQ=55.02;MQRankSum=-0.553;QD=1.00;ReadPosRankSum=-0.162;SOR=0.792;VarDP=650	GT:AD:DP:GQ:PGT:PID:PL:PS:SB	0/0:.:21:30	0/0:.:300:20	0/0:.:30:72	0/0:.:31:98	0|1:29,3,0,0,0:33:78:0|1:113_GG_G:78,0,1100,140,1400,1200,172,1600,1200,1000,175,1100,1100,1300,1000:113:19,19,2,1	0/0:.:20:19	0/0:.:19:20	0/0:.:25:50		0|1:90,2,0,0,0:30:40:0|1:113_GG_G:40,0,600,70,650,600,90,640,900,300,60,800,400,900,900:113:2,14,2,0	0/0:.:20:10	0/0:.:9:20	0/0:.:30:40	0/0:.:37:38		0/4:5,0,0,0,1:5:33:.:.:30,40,400,50,220,220,38,270,270,270,0,200,200,200,202:.:5,0,0,1	. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.sc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:15849,error,error,15849,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['error'],['error']
Availability,clang: error: the clang compiler does not support '-march=native',MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11729:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/issues/11729,1,['error'],['error']
Availability,cloud.storage.StorageImpl.readAllBytes(StorageImpl.java:563); 	at is.hail.io.fs.GoogleStorageFS.$anonfun$readNoCompression$1(GoogleStorageFS.scala:288); 	at is.hail.services.package$.retryTransientErrors(package.scala:163); 	at is.hail.io.fs.GoogleStorageFS.readNoCompression(GoogleStorageFS.scala:286); 	at is.hail.io.fs.RouterFS.readNoCompression(RouterFS.scala:26); 	at is.hail.backend.service.ServiceBackend$$anon$4.call(ServiceBackend.scala:239); 	at is.hail.backend.service.ServiceBackend$$anon$4.call(ServiceBackend.scala:235); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). com.google.api.client.googleapis.json.GoogleJsonResponseException: 404 Not Found; GET https://storage.googleapis.com/download/storage/v1/b/wes-bipolar-tmp-4day/o/bge-wave-1-VQSR%2FparallelizeAndComputeWithIndex%2FgCyfD7XOt_MQrrCGc4Q-RrrWPb3cTAbhhcV28BCntiU=%2Fresult.2706?alt=media; No such object: wes-bipolar-tmp-4day/bge-wave-1-VQSR/parallelizeAndComputeWithIndex/gCyfD7XOt_MQrrCGc4Q-RrrWPb3cTAbhhcV28BCntiU=/result.2706; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:439); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1111); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:525); 	at com.google.api.clie,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13409:7009,down,download,7009,https://hail.is,https://github.com/hail-is/hail/issues/13409,1,['down'],['download']
Availability,cmd line:. ```; hail: info: running: importvcf TT.head.vcf.bgz; hail: importvcf: caught exception: null; ```. in hail.log:. ```; 2016-06-16 11:40:11 ERROR Hail:88 - hail: importvcf: caught exception: java.util.zip.ZipException: null; at org.broadinstitute.hail.io.compress.BGzipInputStream$BGzipHeader.<init>(BGzipInputStream.java:31); at org.broadinstitute.hail.io.compress.BGzipInputStream.decompressNextBlock(BGzipInputStream.java:139); at org.broadinstitute.hail.io.compress.BGzipInputStream.read(BGzipInputStream.java:170); at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284); at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326); at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178); at java.io.InputStreamReader.read(InputStreamReader.java:184); ...; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/425:149,ERROR,ERROR,149,https://hail.is,https://github.com/hail-is/hail/issues/425,1,['ERROR'],['ERROR']
Availability,"code>12.20.1</code>.</li>; </ul>; <h2>azure-storage-file-share_12.16.1</h2>; <h2>12.16.1 (2022-11-15)</h2>; <h3>Other Changes</h3>; <h4>Dependency Updates</h4>; <ul>; <li>Upgraded <code>azure-core</code> from <code>1.33.0</code> to version <code>1.34.0</code>.</li>; <li>Upgraded <code>azure-core-http-netty</code> from <code>1.12.6</code> to version <code>1.12.7</code>.</li>; <li>Upgraded <code>azure-storage-common</code> from <code>12.19.0</code> to version <code>12.19.1</code>.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/1b1b22e999541e8ce7ac3147eb468e0cde6c157a""><code>1b1b22e</code></a> Patch Release 11/15/2022 (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32171"">#32171</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/68d7b8992d77ad00cdd985bfd764b81f42085fe3""><code>68d7b89</code></a> Eagerly Convert Headers Always in Download (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32173"">#32173</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/c10e612d913b03f044ddd58aa591850615b61ecd""><code>c10e612</code></a> Sync eng/common directory with azure-sdk-tools for PR 4701 (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32168"">#32168</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/44682b71c0216aae1530af287e745803feeec2fc""><code>44682b7</code></a> Regenerate Storage Blobs with Fix for Download to File (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32163"">#32163</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/11f065d4d592d14977d178ddd58f6a6ec6b16276""><code>11f065d</code></a> Increment package versions for keyvault releases (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12477:3159,Down,Download,3159,https://hail.is,https://github.com/hail-is/hail/pull/12477,1,['Down'],['Download']
Availability,"code></a></li>; <li>Internationalise <code>intcomma</code> for de_DE locale (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/49"">#49</a>) <a href=""https://github.com/Luflosi""><code>@â€‹Luflosi</code></a></li>; </ul>; <h2>Fixed</h2>; <ul>; <li>Replace short scale with long scale for Polish numbers (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/54"">#54</a>) <a href=""https://github.com/mjmikulski""><code>@â€‹mjmikulski</code></a></li>; <li>Fix <code>intcomma()</code> failing with a string as input when <code>ndigits</code> is not <code>None</code> (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/52"">#52</a>) <a href=""https://github.com/Luflosi""><code>@â€‹Luflosi</code></a></li>; <li>Fix some pylint findings (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/42"">#42</a>) <a href=""https://github.com/hugovk""><code>@â€‹hugovk</code></a></li>; <li>Fix &quot;ValueError: math domain error&quot; for <code>metric(0)</code> (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/47"">#47</a>) <a href=""https://github.com/liukun""><code>@â€‹liukun</code></a></li>; </ul>; <h2>4.3.0</h2>; <h2>Added</h2>; <ul>; <li>Add Greek translation (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/46"">#46</a>) <a href=""https://github.com/waseigo""><code>@â€‹waseigo</code></a></li>; <li>Polish: Added thousand, fixed big numbers (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/43"">#43</a>) <a href=""https://github.com/dejurin""><code>@â€‹dejurin</code></a></li>; </ul>; <h2>Fixed</h2>; <ul>; <li>Fix intword for negative numbers (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/41"">#41</a>) <a href=""https://github.com/vishket""><code>@â€‹vishket</code></a></li>; </ul>; <h2>4.2.3</h2>; <h2>Fixed</h2>; <ul>; <li>Update annotations, docs, and tests: <code>naturaltime</code> can also ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12329:1718,error,error,1718,https://hail.is,https://github.com/hail-is/hail/pull/12329,1,['error'],['error']
Availability,"code>botocore</code>] Adds operation for custom plugin deletion (DeleteCustomPlugin) and adds new StateDescription field to DescribeCustomPlugin and DescribeConnector responses to return errors from asynchronous resource creation.</li>; </ul>; <h1>1.21.9</h1>; <ul>; <li>api-change:<code>finspace-data</code>: [<code>botocore</code>] Add new APIs for managing Users and Permission Groups.</li>; <li>api-change:<code>amplify</code>: [<code>botocore</code>] Add repositoryCloneMethod field for hosting an Amplify app. This field shows what authorization method is used to clone the repo: SSH, TOKEN, or SIGV4.</li>; <li>api-change:<code>fsx</code>: [<code>botocore</code>] This release adds support for the following FSx for OpenZFS features: snapshot lifecycle transition messages, force flag for deleting file systems with child resources, LZ4 data compression, custom record sizes, and unsetting volume quotas and reservations.</li>; <li>api-change:<code>fis</code>: [<code>botocore</code>] This release adds logging support for AWS Fault Injection Simulator experiments. Experiment templates can now be configured to send experiment activity logs to Amazon CloudWatch Logs or to an S3 bucket.</li>; <li>api-change:<code>route53-recovery-cluster</code>: [<code>botocore</code>] This release adds a new API option to enable overriding safety rules to allow routing control state updates.</li>; <li>api-change:<code>amplifyuibuilder</code>: [<code>botocore</code>] We are adding the ability to configure workflows and actions for components.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/boto/boto3/commit/67b84e02c185294c54a8e49510d4cb962e89cee2""><code>67b84e0</code></a> Merge branch 'release-1.21.13'</li>; <li><a href=""https://github.com/boto/boto3/commit/99acd545b20fe30ffa2f589a674c5a7ad74c266b""><code>99acd54</code></a> Bumping version to 1.21.13</li>; <li><a href=""https:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11504:4936,Fault,Fault,4936,https://hail.is,https://github.com/hail-is/hail/pull/11504,1,['Fault'],['Fault']
Availability,"code>botocore</code>] Adds operation for custom plugin deletion (DeleteCustomPlugin) and adds new StateDescription field to DescribeCustomPlugin and DescribeConnector responses to return errors from asynchronous resource creation.</li>; </ul>; <h1>1.21.9</h1>; <ul>; <li>api-change:<code>finspace-data</code>: [<code>botocore</code>] Add new APIs for managing Users and Permission Groups.</li>; <li>api-change:<code>amplify</code>: [<code>botocore</code>] Add repositoryCloneMethod field for hosting an Amplify app. This field shows what authorization method is used to clone the repo: SSH, TOKEN, or SIGV4.</li>; <li>api-change:<code>fsx</code>: [<code>botocore</code>] This release adds support for the following FSx for OpenZFS features: snapshot lifecycle transition messages, force flag for deleting file systems with child resources, LZ4 data compression, custom record sizes, and unsetting volume quotas and reservations.</li>; <li>api-change:<code>fis</code>: [<code>botocore</code>] This release adds logging support for AWS Fault Injection Simulator experiments. Experiment templates can now be configured to send experiment activity logs to Amazon CloudWatch Logs or to an S3 bucket.</li>; <li>api-change:<code>route53-recovery-cluster</code>: [<code>botocore</code>] This release adds a new API option to enable overriding safety rules to allow routing control state updates.</li>; <li>api-change:<code>amplifyuibuilder</code>: [<code>botocore</code>] We are adding the ability to configure workflows and actions for components.</li>; <li>api-change:<code>athena</code>: [<code>botocore</code>] This release adds support for updating an existing named query.</li>; <li>api-change:<code>ec2</code>: [<code>botocore</code>] This release adds support for new AMI property 'lastLaunchedTime'</li>; <li>api-change:<code>servicecatalog-appregistry</code>: [<code>botocore</code>] AppRegistry is deprecating Application and Attribute-Group Name update feature. In this release, we are marking th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11486:3489,Fault,Fault,3489,https://hail.is,https://github.com/hail-is/hail/pull/11486,1,['Fault'],['Fault']
Availability,"code>drs</code>: [<code>botocore</code>] Non breaking changes to existing APIs, and additional APIs added to support in-AWS failing back using AWS Elastic Disaster Recovery.</li>; <li>api-change:<code>ecs</code>: [<code>botocore</code>] This release adds support for ECS Service Connect, a new capability that simplifies writing and operating resilient distributed applications. This release updates the TaskDefinition, Cluster, Service mutation APIs with Service connect constructs and also adds a new ListServicesByNamespace API.</li>; <li>api-change:<code>efs</code>: [<code>botocore</code>] Update efs client to latest version</li>; <li>api-change:<code>iot-data</code>: [<code>botocore</code>] This release adds support for MQTT5 properties to AWS IoT HTTP Publish API.</li>; <li>api-change:<code>iot</code>: [<code>botocore</code>] Job scheduling enables the scheduled rollout of a Job with start and end times and a customizable end behavior when end time is reached. This is available for continuous and snapshot jobs. Added support for MQTT5 properties to AWS IoT TopicRule Republish Action.</li>; <li>api-change:<code>iotwireless</code>: [<code>botocore</code>] This release includes a new feature for customers to calculate the position of their devices by adding three new APIs: UpdateResourcePosition, GetResourcePosition, and GetPositionEstimate.</li>; <li>api-change:<code>kendra</code>: [<code>botocore</code>] Amazon Kendra now supports preview of table information from HTML tables in the search results. The most relevant cells with their corresponding rows, columns are displayed as a preview in the search result. The most relevant table cell or cells are also highlighted in table preview.</li>; <li>api-change:<code>logs</code>: [<code>botocore</code>] Updates to support CloudWatch Logs data protection and CloudWatch cross-account observability</li>; <li>api-change:<code>mgn</code>: [<code>botocore</code>] This release adds support for Application and Wave management. We a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12507:1695,avail,available,1695,https://hail.is,https://github.com/hail-is/hail/pull/12507,1,['avail'],['available']
Availability,"col.getObject(Protocol.java:302); 	at py4j.commands.AbstractCommand.getArguments(AbstractCommand.java:82); 	at py4j.commands.CallCommand.execute(CallCommand.java:77); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748); ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/Users/wang/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1035, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/Users/wang/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 883, in send_command; response = connection.send_command(command); File ""/Users/wang/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1040, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<stdin>"", line 5, in serialize_test; File ""<decorator-gen-466>"", line 2, in eval; File ""/Users/wang/code/hail/hail/python/hail/typecheck/check.py"", line 561, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/wang/code/hail/hail/python/hail/expr/expressions/expression_utils.py"", line 158, in eval; return eval_typed(expression)[0]; File ""<decorator-gen-468>"", line 2, in eval_typed; File ""/Users/wang/code/hail/hail/python/hail/typecheck/check.py"", line 561, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/wang/code/hail/hail/python/hail/expr/expressions/expression_utils.py"", line 199, in eval_typed; return (Env.backend().execute(expression._ir), expression.dtype); File ""/Users/wang/code/hail/hail/python/hail/backend/backend.py"", line 94, in execute; self._to_java_ir(ir)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5407#issuecomment-474983184:1847,Error,Error,1847,https://hail.is,https://github.com/hail-is/hail/issues/5407#issuecomment-474983184,1,['Error'],['Error']
Availability,collect(float32) triggers serialization error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5490:40,error,error,40,https://hail.is,https://github.com/hail-is/hail/issues/5490,1,['error'],['error']
Availability,"collections import Counter; from math import log, isnan; from pprint import pprint; # hail; import hail as hl; import hail.expr.aggregators as agg; import hail.expr.functions. hl.init(default_reference='GRCh38'); print(""Read in PASS SNVs""); passed=hl.read_matrix_table('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass'); print(""Filtering Common Variants""); common=passed.filter_rows(passed.variant_qc.AF > 0.01).persist(); common.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass.common'); print(""Pruning LD Variants""); pruned =hl.ld_prune(common,30,r2=0.1, memory_per_core=2048); pruned.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pruned'); print(""Sample 20% of variants for running PC-Relate""); pruned_subsample = pruned.sample_rows(0.2).persist(); print(""Running PC_Relate""); rel = hl.pc_relate(pruned_subsample.GT, 0.01, k=10); rel_df = rel.to_pandas(); rel_df.describe(); pprint(rel_df); rel_df.to_csv('gcad_5k.snv.rel.csv'); ```. ### What went wrong (all error messages here, including the full java stack trace):. Got a memory error. but not sure what memory needs to be increased. The job seems to restart but does not progress and need to kill. . java.lang.OutOfMemoryError: Java heap spaceop. Running on Apache Spark version 2.2.0; SparkUI available at http://10.48.225.55:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-63d60cc; NOTE: This is a beta version. Interfaces may change; during the beta period. We also recommend pulling; the latest changes weekly.; Read in PASS SNVs; Filtering Common Variants; [Stage 0:==================================================>(96600 + 1) / 96601]2018-04-27 20:54:43 Hail: INFO: wrote 11341822 items in 96601 partitions; Pruning LD Variants; [Stage 1:==================================================>(96598 + 3) / 96601]2018-04-27 21:19:04 Hail: INFO: Running LD prune with nSamples=4795, nVariants=11341822, nPartitions=96601, and maxQueueSize=429841.; [Stage 2:===============",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3463:1930,error,error,1930,https://hail.is,https://github.com/hail-is/hail/issues/3463,1,['error'],['error']
Availability,"com/cbeust/testng/pull/2826"">cbeust/testng#2826</a></li>; <li>GITHUB-2830 - Failsafe parameter.toString by <a href=""https://github.com/seregamorph""><code>@â€‹seregamorph</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2831"">cbeust/testng#2831</a></li>; <li>Changing assertion message of the osgitest by <a href=""https://github.com/krmahadevan""><code>@â€‹krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2832"">cbeust/testng#2832</a></li>; <li>hidden spotbugs in release <a href=""https://github-redirect.dependabot.com/cbeust/testng/issues/2829"">#2829</a> by <a href=""https://github.com/bobshie""><code>@â€‹bobshie</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2833"">cbeust/testng#2833</a></li>; <li>Enhancing the Matrix by <a href=""https://github.com/krmahadevan""><code>@â€‹krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2834"">cbeust/testng#2834</a></li>; <li>Avoid Compilation errors on Semeru JDK flavour. by <a href=""https://github.com/krmahadevan""><code>@â€‹krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2835"">cbeust/testng#2835</a></li>; <li>Add addition yml extension by <a href=""https://github.com/speedythesnail""><code>@â€‹speedythesnail</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2837"">cbeust/testng#2837</a></li>; <li>Support getting dependencies info for a test by <a href=""https://github.com/krmahadevan""><code>@â€‹krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2839"">cbeust/testng#2839</a></li>; <li>Honour regex in dependsOnMethods by <a href=""https://github.com/krmahadevan""><code>@â€‹krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2838"">cbeust/testng#2838</a></li>; <li>Ensure All tests run all the time by <a href=""https://github.com/krmahadevan""><code>@â€‹krmahadevan<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:6023,error,errors,6023,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['error'],['errors']
Availability,"com/pyca/cryptography/issues/8218"">#8218</a>) (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8228"">#8228</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/69527bc79095c9646d7e839121f0783477892ecc""><code>69527bc</code></a> bookworm is py311 now (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8200"">#8200</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/111deefb659b8d73c56d3ce89458f2df973d60e4""><code>111deef</code></a> backport main branch CI to 39.0.x (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8153"">#8153</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/338a65a7df74e189f6b5d1d3a6315ffa911b21c2""><code>338a65a</code></a> 39.0.0 version bump (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7954"">#7954</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/84a3cd7abb16f594d8c315e8aedb4be02583bf6a""><code>84a3cd7</code></a> automatically download and upload circleci wheels (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7949"">#7949</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/525c0b3d5d89eab7f953be5de5d2b75da1c816f8""><code>525c0b3</code></a> Type annotate release.py (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7951"">#7951</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/46d2a94d1b574abf5b9e88f84fa7400a138c4edb""><code>46d2a94</code></a> Use the latest 3.10 release when wheel building (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7953"">#7953</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/f150dc15582c05b1b94cf08ed3b1fbc9c4f52267""><code>f150dc1</code></a> fix CI to work with ubuntu 22.04 (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7950"">#7950</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/8867724b2b6db528d2900",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12668:4837,down,download,4837,https://hail.is,https://github.com/hail-is/hail/pull/12668,4,['down'],['download']
Availability,"command:. hail-new read -i /user/tpoterba/exac_reimport.vds \; filtersamples --remove -c ""file:///humgen/atgu1/fs03/wip/aganna/HCSCORE/CANCER/samples_to_keep.sample_list"" \; variantqc \; filtervariants --keep -c 'va.qc.MAC > 0' \; count \; filtersamples --keep -c 'false' \; write -o /user/aganna/exac_noCANCER.split.onlygeno.vep.NEWHAIL.vds. Error:. hail: info: running: write -o /user/aganna/exac_noCANCER.split.onlygeno.vep.NEWHAIL.vds; [Stage 2:> (0 + 72) / 14038]hail: write: caught exception: org.apache.spark.SparkException: Job aborted. [hail.log.txt](https://github.com/broadinstitute/hail/files/223029/hail.log.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/304:343,Error,Error,343,https://hail.is,https://github.com/hail-is/hail/issues/304,1,['Error'],['Error']
Availability,"commend pulling; the latest changes weekly.; [Stage 1:======================================================>(414 + 2) / 416]2018-04-15 14:38:32 Hail: INFO: Coerced almost-sorted dataset; [Stage 2:> (0 + 34) / 416]Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail/delly_vcf2vdf.py"", line 3, in <module>; hl.import_vcf('/project/casa/vcf.5k/delly/gcad.sv.delly.5k.vcf.bgz').write('/project/casa/vdf.5k/delly'); File ""<decorator-gen-552>"", line 2, in write; File ""/restricted/projectnb/genpro/github/hail/python/hail/typecheck/check.py"", line 481, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/restricted/projectnb/genpro/github/hail/python/hail/matrixtable.py"", line 1935, in write; self._jvds.write(output, overwrite, _codec_spec); File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: gcad.sv.delly.5k.vcf.bgz:column 80816: invalid character '-' in integer literal; ... 2:0:0:0:6 ./.:0,0,0:0:LowQual:0:0:0:-1:0:0:0:0 ./.:0,0,0:0:LowQual:0:0:0 ...; ^; offending line: chr1 152267996 DEL00028254 AATATATATACTTTACGTAAAGT A . PASS ...; see the Hail log for the full offending line. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 2.0 failed 4 times, most recent failure: Lost task 20.3 in stage 2.0 (TID 485, scc-q08.scc.bu.edu, executor 2): is.hail.utils.HailException: gcad.sv.delly.5k.vcf.bgz:column 80816: invalid character '-' in integer literal; ... 2:0:0:0:6 ./.:0,0,0:0:LowQual:0:0:0:-1:0:0:0:0 ./.:0,0,0:0:LowQual:0:0:0 ...; ^; offending line: chr1 152267996 DEL00028254 AATATATATACTTTACGTAAAGT A . PASS ...; see the Hail log for the full offending line; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.sca",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3379:2460,Error,Error,2460,https://hail.is,https://github.com/hail-is/hail/issues/3379,1,['Error'],['Error']
Availability,compile errors,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8603#issuecomment-618375915:8,error,errors,8,https://hail.is,https://github.com/hail-is/hail/pull/8603#issuecomment-618375915,1,['error'],['errors']
Availability,"computeLoadings': compute_loadings; --> 211 })).persist()); 212 ; 213 g = t.index_globals(). <decorator-gen-1340> in persist(self, storage_level). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in persist(self, storage_level); 2110 Persisted table.; 2111 """"""; -> 2112 return Env.backend().persist(self); 2113 ; 2114 def unpersist(self) -> 'Table':. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/backend.py in persist(self, dataset); 167 from hail.context import TemporaryFilename; 168 tempfile = TemporaryFilename(prefix=f'persist_{type(dataset).__name__}'); --> 169 persisted = dataset.checkpoint(tempfile.__enter__()); 170 self._persisted_locations[persisted] = (tempfile, dataset); 171 return persisted. <decorator-gen-1330> in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1329 ; 1330 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1331 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1332 _assert",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:3658,checkpoint,checkpoint,3658,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124,1,['checkpoint'],['checkpoint']
Availability,"computeOrReadCheckpoint(RDD.scala:324) at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) at org.apache.spark.rdd.Mappark.rdd.RDD.iterator(RDD.scala:288) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) at org.apache.spark.rdd.RDD.iteratoadCheckpoint(RDD.scala:324) at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartiti288) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scat org.apache.spark.scheduler.Task.run(Task.scala:121) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at ) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.rception: Failure while fetching StreamChunkId{streamId=830947795015, chunkIndex=0}: java.nio.file.NoSuchFileException: /data03/hadoop/yarn/local/usnio.fs.UnixException.translateToIOException(UnixException.java:86) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) xFileSystemProvider.java:214) at java.nio.file.Files.newByteChannel(Files.java:361) at java.nio.file.Files.newByteChannel(Files.java:407) at ckManager.getBlockData(BlockManager.scala:382) at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61non$11.next(Iterator.scala:410) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.apache.spark.networkessFetchRequest(TransportRequestHandler.java:130) at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.jnnel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.ielHandlerContext.java:340) at io.netty.handler.ti",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:20244,Failure,Failure,20244,https://hail.is,https://github.com/hail-is/hail/issues/8106,2,['Failure'],['Failure']
Availability,"conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.; Written by Roland McGrath and Ulrich Drepper.; ldd (GNU libc) 2.12; Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.; Written by Roland McGrath and Ulrich Drepper.; ldd (GNU libc) 2.12; Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.; Written by Roland McGrath and Ulrich Drepper.; ldd (GNU libc) 2.12; Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.; Written by Roland McGrath and Ulrich Drepper. ```. This is an error we are getting when submitted to the hadoop cluster. This runs fine locally. ```; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.4-d602a3d7472d; LOGGING: writing to /restricted/projectnb/ukbiobank/ad/analysis/ukb.v3/hail-20190122-0019-0.2.4-d602a3d7472d.log; 2019-01-22 00:19:54 Hail: INFO: Number of BGEN files parsed: 1; 2019-01-22 00:19:54 Hail: INFO: Number of samples in BGEN files: 487409; 2019-01-22 00:19:54 Hail: INFO: Number of variants across all BGEN files: 1261158; ----------------------------------------; Global fields:; None; ----------------------------------------; Column fields:; 's': str; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'rsid': str; 'varid': str; ----------------------------------------; Entry fields:; 'GT': call; 'GP': array<float64>; 'dosage': float64; ----------------------------------------; Column key: ['s']; Row key: ['locus', 'alleles']; ----------------------------------------; [Stag",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456417572:6031,error,error,6031,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456417572,1,['error'],['error']
Availability,"cope in comprehensions</li>; <li>Add support for new python 3.11 syntax</li>; <li>Unify output so it is always <code>filename:lineno:col: message</code></li>; <li>Properly report <code>SyntaxError</code> from stdin in python &lt; 3.9</li>; <li>Fix offsets of <code>SyntaxError</code>s in pypy</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/2a6e36bd43af9829e0818961b60a1e3aab01fafc""><code>2a6e36b</code></a> Release 2.5.0 (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/720"">#720</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/a153aeed8df60f4190e6114f77cd254d1493e411""><code>a153aee</code></a> remove special handling of pypy offsets since modern pypy gets it right (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/717"">#717</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/d875b02835fb9b1480a95c5245040eb31a384357""><code>d875b02</code></a> fix syntax error reporting from stdin (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/357"">#357</a>) (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/716"">#716</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/44ef321b0e608c61182ecf5d88f9edeececa5403""><code>44ef321</code></a> Fix pylint URL in README (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/714"">#714</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/2246217295dc8cb30ef4a7b9d8dc449ce32e603a""><code>2246217</code></a> burn the bridges with python 2.x (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/707"">#707</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/becbab65bae84e3e19fc388a42dfabcff0c323c8""><code>becbab6</code></a> upgrade flake8 to 4.0.1 (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/706"">#706</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12149:1556,error,error,1556,https://hail.is,https://github.com/hail-is/hail/pull/12149,1,['error'],['error']
Availability,"core, and 8Gi/core.; - Spot price is set to -1 for now until we figure out a better billing strategy; - We look for existing network security groups to tell if a VM has been fully cleaned up already in the garbage collection loop. # To-Do:. ## Services. - Use global config and make an `AzureConfig` (@daniel-goldstein not sure if you're already doing this) instead of optional environment variables; - Azure user disks are not implemented; There's a maximum number of disks that can be mounted per machine type with a maximum of 32 along with figuring out the API calls. We'll need a semaphore of some sort.; - No activity logs loop. Not necessary for initial development and preemption billing is not working how intended anyways (will add to the list to fix!). We also don't track vm creation success rates per zone like we do with GCP. It might be good to look for VM deletion events to remove instances that are no longer present and then do a deep delete as then we'll have some redundancy and faster response times.; - Figure out how to do a deep-delete as much as possible for VMs when using the create VM REST API. This is essential for cleaning up resources for idled out workers when the driver is down for a long period of time.; - User billing based on resources used based on the `AzureInstanceConfig`; - Spot billing strategy; - Check network IP settings in the worker; - Add garbage collection CLI commands to build.yaml to clean up VMs, disks, nics, public ip addresses, and network security groups based on a tag; - Fix batch tests to be cloud agnostic. ## Infrastructure. - Create a shared SSH public key on the VMs for development purposes; - Consider having every PR / namespace deploy resources in a separate resource group rather than having one resource group for all Batch resources! We'd need something to name the resource groups something like `hail-dev_jigold` and `jigold_jigold` for example to handle the case where we have two k8s clusters running in our subscription.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10970:2302,down,down,2302,https://hail.is,https://github.com/hail-is/hail/pull/10970,1,['down'],['down']
Availability,correction on downcode doc,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2487:14,down,downcode,14,https://hail.is,https://github.com/hail-is/hail/pull/2487,1,['down'],['downcode']
Availability,"cpu: 100m; memory: 500M; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /test-gsa-key; name: test-gsa-key; - mountPath: /gsa-key; name: gsa-key; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: default-token-8h99c; readOnly: true; dnsPolicy: ClusterFirst; enableServiceLinks: true; nodeName: gke-vdc-preemptible-pool-9c7148b2-1f89; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: default; serviceAccountName: default; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: test-gsa-key; secret:; defaultMode: 420; optional: false; secretName: test-gsa-key; - name: gsa-key; secret:; defaultMode: 420; secretName: ci-gsa-key; - name: default-token-8h99c; secret:; defaultMode: 420; secretName: default-token-8h99c; status:; conditions:; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; status: ""True""; type: Initialized; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: ContainersReady; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; status: ""True""; type: PodScheduled; containerStatuses:; - image: gcr.io/hail-vdc/ci-intermediate:oyyg6y2um4kx; imageID: """"; lastState: {}; name: main; ready: false; restartCount: 0; state:; waiting:; reason: ContainerCreating; hostIP: 10.128.0.101; phase: Pending; qosClass: Burstable; startTime: ""2019-07-12T17:17:15Z""; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6625:4541,toler,tolerationSeconds,4541,https://hail.is,https://github.com/hail-is/hail/issues/6625,1,['toler'],['tolerationSeconds']
Availability,"create_vm; await self.compute_client.post(f'/zones/{location}/instances', params=params, json=vm_config); File ""/usr/local/lib/python3.7/dist-packages/hailtop/aiocloud/common/base_client.py"", line 30, in post; async with await self._session.post(url, **kwargs) as resp:; File ""/usr/local/lib/python3.7/dist-packages/hailtop/aiocloud/common/session.py"", line 21, in post; return await self.request('POST', url, **kwargs); File ""/usr/local/lib/python3.7/dist-packages/hailtop/aiocloud/common/session.py"", line 103, in request; return await request_retry_transient_errors(self._http_session, method, url, **kwargs); File ""/usr/local/lib/python3.7/dist-packages/hailtop/utils/utils.py"", line 770, in request_retry_transient_errors; return await retry_transient_errors(session.request, method, url, **kwargs); File ""/usr/local/lib/python3.7/dist-packages/hailtop/utils/utils.py"", line 729, in retry_transient_errors; return await f(*args, **kwargs); File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 147, in request_and_raise_for_status; body=body; hailtop.httpx.ClientResponseError: 400, message='Bad Request', url=URL('https://compute.googleapis.com/compute/v1/projects/hail-vdc/zones/us-central1-a/instances?requestId=e2555a38-1583-47e2-ab15-c3d7ad84e700') body='{\n ""error"": {\n ""code"": 400,\n ""message"": ""Invalid value for field \'resource.scheduling.instanceTerminationAction\': \'DELETE\'. You cannot specify a termination action for a VM instance that has the standard provisioning model (default). To use instance termination action, the VM instance must use the Spot provisioning model."",\n ""errors"": [\n {\n ""message"": ""Invalid value for field \'resource.scheduling.instanceTerminationAction\': \'DELETE\'. You cannot specify a termination action for a VM instance that has the standard provisioning model (default). To use instance termination action, the VM instance must use the Spot provisioning model."",\n ""domain"": ""global"",\n ""reason"": ""invalid""\n }\n ]\n }\n}\n'; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11878#issuecomment-1144087728:1449,error,error,1449,https://hail.is,https://github.com/hail-is/hail/pull/11878#issuecomment-1144087728,2,['error'],"['error', 'errors']"
Availability,"created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/pinned-requirements.txt. <details>; <summary>âš ï¸ <b>Warning</b></summary>. ```; jupyter 1.0.0 requires notebook, which is not installed.; beautifulsoup4 4.12.2 requires soupsieve, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13718:1065,avail,available,1065,https://hail.is,https://github.com/hail-is/hail/pull/13718,1,['avail'],['available']
Availability,"created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. <details>; <summary>âš ï¸ <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14038:1151,avail,available,1151,https://hail.is,https://github.com/hail-is/hail/pull/14038,1,['avail'],['available']
Availability,"crets.token_urlsafe(64); b1 = self.client.create_batch(attributes={'tag': tag, 'name': 'b1'}); b1.create_job('alpine', ['sleep', '30']); b1.close(); ; b2 = self.client.create_batch(attributes={'tag': tag, 'name': 'b2'}); b2.create_job('alpine', ['echo', 'test']); b2.close(); ; def assert_batch_ids(expected, complete=None, success=None, attributes=None):; batches = self.client.list_batches(complete=complete, success=success, attributes=attributes); # list_batches returns all batches for all prev run tests; actual = set([batch.id for batch in batches]).intersection({b1.id, b2.id}); self.assertEqual(actual, expected); ; assert_batch_ids({b1.id, b2.id}, attributes={'tag': tag}); ; b2.wait(); ; > assert_batch_ids({b1.id}, complete=False, attributes={'tag': tag}). test/test_batch.py:93: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; test/test_batch.py:87: in assert_batch_ids; self.assertEqual(actual, expected); E AssertionError: Items in the second set but not the first:; E 19; ________________________________ test_callback _________________________________. client = <batch.client.BatchClient object at 0x7f0d1363ee80>. def test_callback(client):; from flask import Flask, request; app = Flask('test-client'); output = []; ; @app.route('/test', methods=['POST']); def test():; output.append(request.get_json()); return Response(status=200); ; try:; server = ServerThread(app); server.start(); batch = client.create_batch(callback=server.url_for('/test')); head = batch.create_job('alpine:3.8', command=['echo', 'head']); left = batch.create_job('alpine:3.8', command=['echo', 'left'], parents=[head]); right = batch.create_job('alpine:3.8', command=['echo', 'right'], parents=[head]); tail = batch.create_job('alpine:3.8', command=['echo', 'tail'], parents=[left, right]); batch.close(); batch.wait(); i = 0; while len(output) != 4:; time.sleep(0.100 * (3/2) ** i); i += 1; if i > 14:; break; > assert len(output) == 4; E assert 5 == 4; E -5; E +4. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6260#issuecomment-498852506:1889,echo,echo,1889,https://hail.is,https://github.com/hail-is/hail/pull/6260#issuecomment-498852506,4,['echo'],['echo']
Availability,"crossposting from a message I sent to the variants team. ---. #### executive summary. Excess JVM memory use is almost certainly not the issue. I've taken a close look at the import_gvs.py loop and the related Hail Python code. No obvious accumulation of RAM use. AFAICT, the oomkiller keeps killing the pipelines. We need to stop this because the oomkiller (a) acts before the JVM GC can free things and (b) prevents us from getting JVM diagnostics on failure. We control the JVM's max heap with hailctl's --master-memory-fraction (default is 0.8 for 80% of the master machine type's advertised RAM). I suggest we set this down to 0.6 and continue using an n1-highmem-16 driver.; If Hail is (incorrectly) accumulating garbage memory per-group, we'll have a better chance diagnosing that with a running JVM instead of one that's been SIGKILL'ed. To understand what's going on, we gotta see what is using RAM in the n1-highmem-16 case. If I could SSH to the cluster, a simple solution is a screen with top -s 300 -n 100 >memory.log (I'd guess no more than 500KiB per hour of logs) and retrieve that file if the cluster fails. If we could get Google Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the drive",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:452,failure,failure,452,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449,4,"['down', 'failure']","['down', 'failure']"
Availability,"cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6092044](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6092044) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Information Exposure <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6126975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6126975) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **561/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.5 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with yo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:9425,avail,available,9425,https://hail.is,https://github.com/hail-is/hail/pull/14327,1,['avail'],['available']
Availability,"csearch. ### What went wrong (all error messages here, including the full java stack trace):; ```; Traceback (most recent call last):; File ""/hail-elasticsearch-pipelines/hail_scripts/v01/load_clinvar_to_es_pipeline.py"", line 112, in <module>; export_globals_to_index_meta=True,; File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 142, in export_vds_to_elasticsearch; verbose=verbose); File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 287, in export_kt_to_elasticsearch; kt.export_elasticsearch(self._host, int(self._port), index_name, index_type_name, block_size, config=elasticsearch_config); File ""<decorator-gen-143>"", line 2, in export_elasticsearch; File ""/hail/build/distributions/hail-python.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 6.0.0. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 1 times, most recent failure: Lost task 0.0 in stage 12.0 (TID 20050, localhost): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot detect ES version - typically this happens if the network/Elasticsearch cluster is not accessible or when targeting a WAN/Cloud instance without the proper setting 'es.nodes.wan.only'; 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:247); 	at org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:545); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:58); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:1473,failure,failure,1473,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['failure'],['failure']
Availability,css nesting &amp;amp; variables (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/393&quot;&gt;#393&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/9bd4907682f10849dde1fe866b5a71402c74e551&quot;&gt;&lt;code&gt;9bd4907&lt;/code&gt;&lt;/a&gt; remove all read the doc documentation from the repo (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/405&quot;&gt;#405&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/21fafe40b19e7d1c8b4b8bceb7fe1410e2cbdc2a&quot;&gt;&lt;code&gt;21fafe4&lt;/code&gt;&lt;/a&gt; Document how to modify the environment section after tests are finished (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/400&quot;&gt;#400&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/8b7bdc1fc5f21e94610c3b7bcb06006271c27390&quot;&gt;&lt;code&gt;8b7bdc1&lt;/code&gt;&lt;/a&gt; Better error on missing CSS files. (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/390&quot;&gt;#390&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/817d04df5875b143bc23fa6f4c78d0bc9ccece58&quot;&gt;&lt;code&gt;817d04d&lt;/code&gt;&lt;/a&gt; Move documentation to read the docs (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/402&quot;&gt;#402&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/ba4f15431c42f6b650e78c9d3895e9212cf35663&quot;&gt;&lt;code&gt;ba4f154&lt;/code&gt;&lt;/a&gt; Re-enable pypy3-windows. Closes &lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/358&quot;&gt;#358&lt;/a&gt; (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/403&quot;&gt;#403&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11524:15614,error,error,15614,https://hail.is,https://github.com/hail-is/hail/pull/11524,1,['error'],['error']
Availability,"ct(self._jvdf.count(genotypes).toJavaMap()); 1130; 1131 def deduplicate(self):. /Users/tpoterba/spark-2.0.2-bin-hadoop2.7/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /Users/tpoterba/spark-2.0.2-bin-hadoop2.7/python/pyspark/sql/utils.pyc in deco(*a, **kw); 61 def deco(*a, **kw):; 62 try:; ---> 63 return f(*a, **kw); 64 except py4j.protocol.Py4JJavaError as e:; 65 s = e.java_exception.toString(). /Users/tpoterba/hail/python/hail/java.py in deco(*a, **kw); 109 # deepest = env.jutils.deepestMessage(e.java_exception); 110 # msg = env.jutils.getMinimalMessage(e.java_exception); --> 111 raise FatalError('%s\n\nJava stack trace:\n%s\n\nERROR SUMMARY: %s' % (deepest, full, deepest)); 112 except py4j.protocol.Py4JError as e:; 113 if e.args[0].startswith('An error occurred while calling'):. FatalError: HailException: malformed.vcf: caught htsjdk.tribble.TribbleException$InternalCodecException: The allele with index 10026357 is not defined in the REF/ALT columns in the record; offending line: 20	10026348	.	A	G	7535.22	PASS	HWP=1.0;AC=2;culprit=Inbreedi... Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3, localhost): is.hail.utils.HailException: malformed.vcf: caught htsjdk.tribble.TribbleException$InternalCodecException: The allele with index 10026357 is not defined in the REF/ALT columns in the record; offending line: 20	10026348	.	A	G	7535.22	PASS	HWP=1.0;AC=2;culprit=Inbreedi...; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:10); 	at is.hail.utils.package$.fatal(package.scala:20); 	at is.hail.utils.TextContext.wrapException(Context.scala:15); 	at is.hail.utils.WithContext.map(Context.scala:27); 	at is.h",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882:1440,error,error,1440,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882,1,['error'],['error']
Availability,"ct.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/requirements.txt. <details>; <summary>âš ï¸ <b>Warning</b></summary>. ```; sphinx 5.3.0 has requirement docutils<0.20,>=0.14, but you have docutils 0.20.1.; sphinx-rtd-theme 1.3.0 has requirement docutils<0.19, but you have docutils 0.20.1.; notebook 6.5.6 has requirement pyzmq<25,>=17, but you have pyzmq 25.1.2.; aiohttp-devtools 1.1 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;) <br/>[SNYK-PYTHON-AIOHTTP-6209406](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209406) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **718/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-6209407](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209407) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencie",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14227:1232,avail,available,1232,https://hail.is,https://github.com/hail-is/hail/pull/14227,1,['avail'],['available']
Availability,ct.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.base/java.lang.Thread.run(Thread.java:834). is.hail.utils.HailException: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.variant.ReferenceGenome.checkLocus(ReferenceGenome.scala:210); 	at is.hail.variant.Locus$.apply(Locus.scala:18); 	at is.hail.variant.Locus$.annotation(Locus.scala:24); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$3(LoadPlink.scala:43); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$3$adapted(LoadPlink.scala:37); 	at is.hail.utils.WithContext.foreach(Context.scala:49); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2(LoadPlink.scala:37); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2$adapted(LoadPlink.scala:36); 	at scala.collection.Iterator.foreach(Iterator.scala:941); 	at scala.collection.Iterator.foreach$(Iterator.scala:941); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1(LoadPlink.scala:36); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1$adapted(LoadPlink.scala:35); 	at is.hail.io.fs.FS.$a,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:5200,Error,ErrorHandling,5200,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['Error'],['ErrorHandling']
Availability,"ct.dependabot.com/kubernetes/kubernetes/pull/91637"">kubernetes/kubernetes#91637</a>, <a href=""https://github.com/robscott""><code>@â€‹robscott</code></a>) [SIG API Machinery, Apps, Auth, Cloud Provider, Instrumentation, Network and Testing]</li>; <li>CustomResourceDefinitions added support for marking versions as deprecated by setting <code>spec.versions[*].deprecated</code> to <code>true</code>, and for optionally overriding the default deprecation warning with a <code>spec.versions[*].deprecationWarning</code> field. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92329"">kubernetes/kubernetes#92329</a>, <a href=""https://github.com/liggitt""><code>@â€‹liggitt</code></a>) [SIG API Machinery]</li>; <li>EnvVarSource api doc bug fixes (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91194"">kubernetes/kubernetes#91194</a>, <a href=""https://github.com/wawa0210""><code>@â€‹wawa0210</code></a>) [SIG Apps]</li>; <li>Fix bug in reflector that couldn't recover from &quot;Too large resource version&quot; errors (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92537"">kubernetes/kubernetes#92537</a>, <a href=""https://github.com/wojtek-t""><code>@â€‹wojtek-t</code></a>) [SIG API Machinery]</li>; <li>Fixed: log timestamps now include trailing zeros to maintain a fixed width (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91207"">kubernetes/kubernetes#91207</a>, <a href=""https://github.com/iamchuckss""><code>@â€‹iamchuckss</code></a>) [SIG Apps and Node]</li>; <li>Generic ephemeral volumes, a new alpha feature under the <code>GenericEphemeralVolume</code> feature gate, provide a more flexible alternative to <code>EmptyDir</code> volumes: as with <code>EmptyDir</code>, volumes are created and deleted for each pod automatically by Kubernetes. But because the normal provisioning process is used (<code>PersistentVolumeClaim</code>), storage can be provided by third-party storage vendors and al",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:6628,recover,recover,6628,https://hail.is,https://github.com/hail-is/hail/pull/11462,2,"['error', 'recover']","['errors', 'recover']"
Availability,"ct/Next make DOM modification declarative, and very very easy. They provide a great deal of structure (especially with Next handling tooling), and thanks to the virtual dom / reconciliation process, performs, in many cases, much faster than directly modifying the DOM (HTML) (i.e plain JS). React also handles necessities like properly escaping all inputs, for XSS attack prevention. All of this in a bundle size that isn't significantly bigger than JQuery, without all of those benefits (and React is rapidly shrinking). It's possible to avoid Javascript. One can simulate interactivity by issuing a server GET request for a new page, i.e click on a link with a GET variable ?someVar=val and get a new page. This is slow (full round trip cost), and puts much more load on the server (since it not only needs to make the db call, but interpret PHP/Python to render the view). . There is a good reason why JS and monolithic single page applications became popular, with all of the initial-load (bundle size) downsides: client-side rendering allows perceived performance on the order of native mobile or desktop applications. Achieving interactive UI's without JS or Web Assembly, by using server-rendered pages, is ~impossible. We will achieve this interactivity without suffering the bundle-size-before-first-render cost, at minor developer costs vs server-side-only rendering. Lastly, it is possible to abuse any technology. Javascript brings to mind ""bloated""; this is an implementation issue. PHP/Python/Perl websites also used to be slow and ugly (Geocities).; * NodeJS/Javascript/V8 JIT is consistently faster than PHP, Python, and ~Java: https://www.techempower.com/benchmarks/. ## Why NodeJS, React, etc; 1. Javascript is the only language supported by modern browsers. Web assembly will change this (compile target == web assembly, language == rust | go | python), but is not nearly as mature; 2. Ecosystem. Chosen technologies are (likely) by far the most popular. We should quantify this be",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931:2341,down,downsides,2341,https://hail.is,https://github.com/hail-is/hail/pull/4931,1,['down'],['downsides']
Availability,"ction\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; INFO	2022-03-02 19:06:33,503	job_private.py	schedule_jobs_loop_body:142	starting scheduling jobs for jpim job-private; INFO	2022-03-02 19:06:33,533	job_private.py	schedule_jobs_loop_body:186	scheduled 0 jobs for jpim job-private; INFO	2022-03-02 19:06:34,964	pool.py	create_instances:244	pool highcpu n_instances 0 {'pending': 0, 'active': 0, 'inactive': 0, 'deleted': 0} free_cores 0.0 live_free_cores 0.0 ready_cores 0.0; ERROR	2022-03-02 19:06:35,376	job.py	schedule_job:473	error while scheduling job (94, 2) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:5404,error,error,5404,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['error'],['error']
Availability,ctl/hdinsight/cli.py'; adding 'hailtop/hailctl/hdinsight/start.py'; adding 'hailtop/hailctl/hdinsight/submit.py'; adding 'hailtop/utils/__init__.py'; adding 'hailtop/utils/filesize.py'; adding 'hailtop/utils/process.py'; adding 'hailtop/utils/rate_limiter.py'; adding 'hailtop/utils/rates.py'; adding 'hailtop/utils/rich_progress_bar.py'; adding 'hailtop/utils/serialization.py'; adding 'hailtop/utils/time.py'; adding 'hailtop/utils/utils.py'; adding 'hailtop/utils/validate/__init__.py'; adding 'hailtop/utils/validate/validate.py'; adding 'hail-0.2.124.dist-info/METADATA'; adding 'hail-0.2.124.dist-info/WHEEL'; adding 'hail-0.2.124.dist-info/entry_points.txt'; adding 'hail-0.2.124.dist-info/top_level.txt'; adding 'hail-0.2.124.dist-info/RECORD'; emoving build/bdist.linux-x86_64/wheel; python3 -m pip install 'pip-tools==6.13.0' && bash ../check_pip_requirements.sh python; Defaulting to user installation because normal site-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB); â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hoo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:29302,Down,Downloading,29302,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,1,['Down'],['Downloading']
Availability,"cts with <code>__getattr__</code>, like; :class:<code>~unittest.mock.Mock</code> to be treated as a; :func:<code>contextfunction</code>. :issue:<code>1145</code></li>; <li>Update <code>wordcount</code> filter to trigger :class:<code>Undefined</code> methods; by wrapping the input in :func:<code>soft_str</code>. :pr:<code>1160</code></li>; <li>Fix a hang when displaying tracebacks on Python 32-bit.; :issue:<code>1162</code></li>; <li>Showing an undefined error for an object that raises; <code>AttributeError</code> on access doesn't cause a recursion error.; :issue:<code>1177</code></li>; <li>Revert changes to :class:<code>~loaders.PackageLoader</code> from 2.10 which; removed the dependency on setuptools and pkg_resources, and added; limited support for namespace packages. The changes caused issues; when using Pytest. Due to the difficulty in supporting Python 2 and; :pep:<code>451</code> simultaneously, the changes are reverted until 3.0.; :pr:<code>1182</code></li>; <li>Fix line numbers in error messages when newlines are stripped.; :pr:<code>1178</code></li>; <li>The special <code>namespace()</code> assignment object in templates works in; async environments. :issue:<code>1180</code></li>; <li>Fix whitespace being removed before tags in the middle of lines when; <code>lstrip_blocks</code> is enabled. :issue:<code>1138</code></li>; <li>:class:<code>~nativetypes.NativeEnvironment</code> doesn't evaluate; intermediate strings during rendering. This prevents early; evaluation which could change the value of an expression.; :issue:<code>1186</code></li>; </ul>; <h2>Version 2.11.1</h2>; <p>Released 2020-01-30</p>; <ul>; <li>Fix a bug that prevented looking up a key after an attribute; (<code>{{ data.items[1:] }}</code>) in an async template. :issue:<code>1141</code></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/jinja/commit/cf215390d4a4d6f0a4",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10209:4170,error,error,4170,https://hail.is,https://github.com/hail-is/hail/pull/10209,1,['error'],['error']
Availability,current error message is a FileNotFoundException,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3856:8,error,error,8,https://hail.is,https://github.com/hail-is/hail/issues/3856,1,['error'],['error']
Availability,"current.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 		at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 		at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 		at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; 	Caused by: com.google.api.client.http.HttpResponseException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 		at com.google.api.client.http.HttpResponseException$Builder.build(HttpResponseException.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		... 48 more; Caused by: com.google.api.client.http.HttpResponseException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:26161,error,errors,26161,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['error'],['errors']
Availability,cutor.submit(DirectRetryingExecutor.java:103); 		at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 		at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.flushBuffer(BlobWriteChannel.java:189); 		at is.hail.relocated.com.google.cloud.BaseWriteChannel.flush(BaseWriteChannel.java:112); 		at is.hail.relocated.com.google.cloud.BaseWriteChannel.write(BaseWriteChannel.java:139); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$flush$1(GoogleStorageFS.scala:297); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:279); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.flush(GoogleStorageFS.scala:297); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.close(GoogleStorageFS.scala:306); 		at java.io.FilterOutputStream.close(FilterOutputStream.java:159); 		... 27 more; 	Suppressed: is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-6BO4gZ18Lheigp3ir9RSOh&uploadType=resumable&upload_id=ADPycduiXx2Jtiy_0Ll131_pPeEYKnnA23Hlk28_9TFESUMaubA9OqLK_n8Td5rPhTXnlpssGo796Q4bJxUeblhmSaYcCSWAMg2k; chunkOffset: 16777216; chunkLength: 0; localOffset: 1325400064; remoteOffset: 1342177280; lastChunk: false. 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:267); 		at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 		at ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756:6953,recover,recover,6953,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756,2,['recover'],['recover']
Availability,cutor.submit(DirectRetryingExecutor.java:103); 		at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 		at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.flushBuffer(BlobWriteChannel.java:189); 		at is.hail.relocated.com.google.cloud.BaseWriteChannel.flush(BaseWriteChannel.java:112); 		at is.hail.relocated.com.google.cloud.BaseWriteChannel.write(BaseWriteChannel.java:139); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$flush$1(GoogleStorageFS.scala:317); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:299); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.flush(GoogleStorageFS.scala:317); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.close(GoogleStorageFS.scala:326); 		at java.io.FilterOutputStream.close(FilterOutputStream.java:159); 		... 27 more; 	Suppressed: is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-2LzGioRNy6RqIS2pfXIoSO&uploadType=resumable&upload_id=ADPycdvZ5HhnGfOKt5TE1qXWiHpqIpZnXVTYWuWUCXNPRF9HqyCB-4LvRsxNX6SUWRgk13pYrzYaa9-wXlvNZt1oct0ptaEz0bS3; chunkOffset: 16777216; chunkLength: 0; localOffset: 268435456; remoteOffset: 285212672; lastChunk: false. 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:267); 		at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 		at co,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911:7144,recover,recover,7144,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911,1,['recover'],['recover']
Availability,"d Hail with default parameters...; using hail jar at /opt/conda/default/lib/python3.6/site-packages/hail/hail-all-spark.jar; Running on Apache Spark version 2.4.3; SparkUI available at http://dk-m.c.broad-ctsa.internal:4041; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.16-277ccc7aec45; LOGGING: writing to /tmp/66c1d088108948b2b76bb607f61d7b3f/hail-20190703-2330-0.2.16-277ccc7aec45.log; yo dawg. [Stage 0:> (0 + 1) / 1]OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x00007f2e73b00000, 1035468800, 0) failed; error='Cannot allocate memory' (errno=12); #; # There is insufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 1035468800 bytes for committing reserved memory.; # An error report file with more information is saved as:; # /tmp/66c1d088108948b2b76bb607f61d7b3f/hs_err_pid10896.log; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [66c1d088108948b2b76bb607f61d7b3f] failed with error:; Google Cloud Dataproc Agent reports job failure. If logs are available, they can be found in 'gs://dataproc-7f9e9d5e-03bd-4e95-bea1-fe0321239b35-us/google-cloud-dataproc-metainfo/f03fbc39-c07f-4e3e-8f21-47ffa986058e/jobs/66c1d088108948b2b76bb607f61d7b3f/driveroutput'.; Traceback (most recent call last):; File ""/usr/local/bin/hailctl"", line 10, in <module>; sys.exit(main()); File ""/usr/local/lib/python3.7/site-packages/hailtop/hailctl/__main__.py"", line 91, in main; cli.main(args); File ""/usr/local/lib/python3.7/site-packages/hailtop/hailctl/dataproc/cli.py"", line 99, in main; jmp[args.module].main(args, pass_through_args); File ""/usr/local/lib/python3.7/site-packages/hailtop/hailctl/dataproc/submit.py"", line 72, in main; check_call(cmd); File ""/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py"", line 347, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs'",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6565#issuecomment-508289815:1406,error,error,1406,https://hail.is,https://github.com/hail-is/hail/issues/6565#issuecomment-508289815,2,"['error', 'failure']","['error', 'failure']"
Availability,"d generic methods. We should have done this a long time ago.; - ModuleBuilder can now create type-specialized tuple types. This is used for EmitCode return values. I'm not sure if this is actually used yet.; - Require RVDType rowType to be required. Require TypeValue global type to be required. Fix lots of places to make this true. In a few spots (e.g. TableMap{Rows, Globals}), I had to wrap the IR being compiled in a Coalesce with a Die to make sure the return type is required.; - Cleaned up the dependent function interface to be closer to what we have now with MethodBuilder, etc. DependentFunctionBuilder is now just an `apply_method: DependentMethodBuilder`, EmitFunctionBuilder analogously. DependentMethodBuilder wraps a MethodBuilder, EmitMethodBuilder wraps a DependentMethodBuilder and an EmitMethodBuilder.; - Add equality comparison to TypeInfo[_]; - Add methods to convert IndexedSeq[Code[_]] to/from PCode and EmitCode. These are used to pass EmitCode as arguments to method invocation. If an emit parameter is required, the missingness boolean is omitted, otherwise it is present. Furthermore, this change also adds requiredness to many things and improves ptype interfaces:; - added PType.literalPType that infers PTypes from Scala literals, use in a few places (emit for Literal, BroadcastRegionValue constructor from annotation, etc.); - require Table global and row types to be required; - same for MatrixValue, but also cols and entries (the entries array, not individual entries, which an be missing); - Don't upcast globals in TableKeyBy and TableOrderBy; - added EType setRequired; - AbstractCodecSpecs assert row and global etypes are present at the toplevel, and setRequired(true) if they are coming from encoders written by previous versions; - rename PType.copyFromType to PType.copyFromAdddres. Modify it so it can ""downcast"": convert to a PType with greater requiredness. This is used in converting TableValues to MatrixValues to satisfy the requiredness assertions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8371:2810,down,downcast,2810,https://hail.is,https://github.com/hail-is/hail/pull/8371,1,['down'],['downcast']
Availability,"d | probands | n_probands | r_prob | idx | n_cum_probands |; +----------------+----------------+------------------------------------------+------------+-------------+-------+----------------+; | str | str | array<str> | int64 | float64 | int64 | int64 |; +----------------+----------------+------------------------------------------+------------+-------------+-------+----------------+; | RG1692 | RG1695 | [""RG1655"",""RG1681"",""RG1691"",""RG1706"",... | 8 | 1.71331e-01 | 0 | 8 |; | G01-GEA-28-PA | G01-GEA-28-MA | [""G01-GEA-28-HI""] | 1 | 4.93356e-02 | 867 | 717 |; | DEASD_0210_500 | DEASD_0210_600 | [""DEASD_0210_001""] | 1 | 4.93218e-02 | 866 | 716 |. ```; Then I do:; ```; keep_fams_ht = keep_fams_ht.annotate(relateds=keep_fams_ht.probands.append(keep_fams_ht.mother_id).append(keep_fams_ht.father_id)); relateds = keep_fams_ht.explode(keep_fams_ht.relateds).key_by('relateds').distinct(). ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; Py4JJavaError Traceback (most recent call last); <ipython-input-99-84209896ffb7> in <module>(); 1 keep_fams_ht = keep_fams_ht.annotate(relateds=keep_fams_ht.probands.append(keep_fams_ht.mother_id).append(keep_fams_ht.father_id)); ----> 2 relateds = keep_fams_ht.explode(keep_fams_ht.relateds).key_by('relateds').distinct(). /home/hail/hail.zip/hail/table.py in distinct(self); 2607 """"""; 2608 hail.methods.misc.require_key(self, ""distinct""); -> 2609 return Table(self._jt.distinctByKey()); 2610 ; 2611 table_type.set(Table). /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 182 import pyspark; 183 try:; --> 184 return f(*args, **kwargs); 185 except py4j.protocol.Py4JJavaError as e:; 186 s = e.java_except",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3814:1220,error,error,1220,https://hail.is,https://github.com/hail-is/hail/issues/3814,1,['error'],['error']
Availability,"d.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:82); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:80); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:692); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:664); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:159); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:442); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:408); 	at java.base/java.lang.Thread.run(Thread.java:834). Hail version: 0.2.128-ce3ca9c77507; Error summary: SocketTimeoutException: connect timed out; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/py4j_backend.py"", line 223, in _rpc; raise fatal_error_from_java_error_triplet(; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/table.py"", line 2002, in write; Env.backend().execute(; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/test.py"", line 6, in <module>; ht.write('gs://ehigham-hail-tmp/test_hail_in_notebook.ht'); hail.utils.java.FatalError: SocketTimeoutException: connect timed out. Java stack trace:; java.io.IOException: Error getting access token from metadata server at: http://169.254.169.254/com",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:10697,Error,Error,10697,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699,1,['Error'],['Error']
Availability,d.foreach$(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:13); at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:47); at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:416); at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:452); at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:70); at is.hail.utils.package$.using(package.scala:646); at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:70); at is.hail.utils.package$.using(package.scala:646); at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:59); at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:310); at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$1(SparkBackend.scala:449); at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); at is.hail.backend.spark.SparkBackend.executeEncode(SparkBackend.scala:448); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.base/java.lang.reflect.Method.invoke(Method.java:566); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:282); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:238); at java.base/java.lang.Thread.run(Thread.java:829). Hail version: 0.2.100-2ea2615a797a; Error summary: AssertionError: assertion failed; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12280:6308,Error,Error,6308,https://hail.is,https://github.com/hail-is/hail/issues/12280,1,['Error'],['Error']
Availability,d.scala:687); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.base/java.lang.Thread.run(Thread.java:834). is.hail.utils.HailException: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.variant.ReferenceGenome.checkLocus(ReferenceGenome.scala:210); 	at is.hail.variant.Locus$.apply(Locus.scala:18); 	at is.hail.variant.Locus$.annotation(Locus.scala:24); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$3(LoadPlink.scala:43); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$3$adapted(LoadPlink.scala:37); 	at is.hail.utils.WithContext.foreach(Context.scala:49); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2(LoadPlink.scala:37); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2$adapted(LoadPlink.scala:36); 	at scala.collection.Iterator.foreach(Iterator.scala:941); 	at scala.collection.Iterator.foreach$(Iterator.scala:941); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1(LoadPlink.scala:36); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1$adapte,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:5157,Error,ErrorHandling,5157,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['Error'],['ErrorHandling']
Availability,"d.status and Container.status in worker.py for the format. Example at the end. Note, ""container_statuses"" items have a field ""container_status"", because container is used in two ways: as a substep of a pod/job, and as docker container. My last renaming proposal got shot down, but we clearly need to improve this in a later PR.; - Heavily reworked worker.py. I believe this fixes https://github.com/hail-is/hail/issues/7350. The main design idea is to having all state creation and cleanup in Pod.run and Container.run.; - worker: Just support pods/status and pods/log, not container level status or logs.; - Pod now writes final status, not containers. Individual containers write their logs.; - I time all the steps of the Pod container (creating, starting, running, uploading log, etc.) with a timing called ""runtime"" which is how long the docker container itself took to start/run. That's usually 4-6 seconds. However, if you log into a machine and run `docker run --rm ubuntu:18.04 echo hi` it takes 1-2 seconds. It would be good to find out where the extra 3-4 seconds are coming from (I feel like @jigold might have some insight into this. Comparing our container config to the docker command line's might be useful here.); - Stop using (value, err) style exception handling. I think we should be able to design this with very little explicit exception handling, mainly in critical blocks to maintain the program invariants.; - Pods can have error status in 1 of 3 ways: the pod itself failed (e.g. couldn't read k8s secrets), one of the pod containers error out (e.g. pull failed due to invalid image), and the docker container finished but the final container status had an ""Error"" field. Next step is to remove pods and merge the pod and job tables. ```; {; ""name"": ""batch-2-job-1"",; ""batch_id"": 2,; ""job_id"": 1,; ""user"": ""test"",; ""state"": ""succeeded"",; ""container_statuses"": {; ""setup"": {; ""name"": ""setup"",; ""state"": ""succeeded"",; ""timing"": {; ""pulling"": 0.038861751556396484,; ""creating"": ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7354:1176,echo,echo,1176,https://hail.is,https://github.com/hail-is/hail/pull/7354,1,['echo'],['echo']
Availability,"d/Decoder.d -MT build/Decoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux ApproximateQuantiles_test.cpp -MG -M -MF build/ApproximateQuantiles_test.d -MT build/ApproximateQuantiles_test.o; g++ -o build/NativeBoot.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux -MD -MF build/NativeBoot.d -MT build/NativeBoot.o -c NativeBoot.cpp; g++ -fvisibility=default -rdynamic -shared -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux build/NativeBoot.o -o lib/linux-x86-64/libboot.so; g++ -o build/davies.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux -MD -MF build/davies.d -MT build/davies.o -c davies.cpp; davies.cpp: In member function â€˜real DaviesAlgo::qf(real*, real*, int*, int, real, real, int, real, real*, int*)â€™:; davies.cpp:241:8: error: variable â€˜qfvalâ€™ might be clobbered by â€˜longjmpâ€™ or â€˜vforkâ€™ [-Werror=clobbered]; real qfval;; ^; cc1plus: all warnings being treated as errors; make: *** [build/davies.o] Error 1; Makefile:63: recipe for target 'build/davies.o' failed; :nativeLib FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':nativeLib'.; > Process 'command 'make'' finished with non-zero exit value 2. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5659:7545,error,error,7545,https://hail.is,https://github.com/hail-is/hail/issues/5659,4,"['Error', 'FAILURE', 'error']","['Error', 'FAILURE', 'error', 'errors']"
Availability,"dBulk.doWriteObject(TemplatedBulk.java:71); 	at org.elasticsearch.hadoop.serialization.bulk.TemplatedBulk.write(TemplatedBulk.java:58); 	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:168); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.1-408f188; Error summary: EsHadoopIllegalArgumentException: Spark SQL types are not handled through basic RDD saveToEs() calls; typically this is a mistake(as the SQL schema will be ignored). Use 'org.elasticsearch.spark.sql' package instead; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [ffc9fb0b99f64080b674ab7a07962df9] entered state [ERROR] while waiting for [DONE].; ```. Ideally it would get exported as nested objects: https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html#_using_literal_nested_literal_fields_for_arrays_of_objects. with elasticsearch mapping:; ```; u'vep': {'type': 'nested', 'properties': {u'category': {'type': 'keyword'}, u'major_consequence': {'type': 'keyword'}, u'gene_id': {'type': 'keyword'}, u'major_consequence_rank': {'type': 'integer'}, u'gene_symbol': {'type': 'keyword'}, u'transcript_id': {'type': 'keyword'}, u'hgvs': {'type': 'keyword'}, u'protein_id': {'type': 'keyword'}}}, ; ```. I thought about switching to saveJsonToEs here: ; https://github.com/hail-is/hail/blob/0.1/src/main/scala/is/hail/io/ElasticsearchConnector.scala",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:11109,Error,Error,11109,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['Error'],['Error']
Availability,"dError as exc:; raise FatalError('Hail internal error. Please contact the Hail team and provide the following information.\n\n' + yamlx.dump({; 'service_backend_debug_info': self.debug_info(),; 'batch_debug_info': await self._batch.debug_info(); })) from exc; ; async with driver_output as outfile:; success = await read_bool(outfile); if success:; return await read_bytes(outfile); ; short_message = await read_str(outfile); expanded_message = await read_str(outfile); error_id = await read_int(outfile); ; reconstructed_error = fatal_error_from_java_error_triplet(short_message, expanded_message, error_id); if ir is None:; raise reconstructed_error; > raise reconstructed_error.maybe_user_error(ir); E hail.utils.java.FatalError: NativeIoException: readAddress(..) failed: Connection reset by peer; E ; E Java stack trace:; E io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer; E 	at ; E ; E ; E ; E Hail version: 0.2.115-330031a5d973; E Error summary: NativeIoException: readAddress(..) failed: Connection reset by peer. /usr/local/lib/python3.8/dist-packages/hail/backend/service_backend.py:477: FatalError; ------------------------------ Captured log call -------------------------------; INFO batch_client.aioclient:aioclient.py:753 created batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO backend.service_backend:java.py:190 _make_tsm: found 1000 variants after filtering out monomorphic sites.; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclien",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12980:4542,Error,Error,4542,https://hail.is,https://github.com/hail-is/hail/issues/12980,1,['Error'],['Error']
Availability,dSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:13); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:47); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:381); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:417); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:46); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:275); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$1(SparkBackend.scala:414); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.backend.spark.SparkBackend.executeEncode(SparkBackend.scala:413); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.81-edeb70bc789c; Error summary: ClassTooLargeException: Class too large: __C185collect_distributed_array; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12533:24319,Error,Error,24319,https://hail.is,https://github.com/hail-is/hail/issues/12533,1,['Error'],['Error']
Availability,"dStateSig +PInt64)) ()); (InitOp 1 (CallStats (CallStatsStateSig)); ((ArrayLen; (GetField alleles (Ref __iruid_4247)))))); (StreamFor __iruid_4244; (StreamFilter __iruid_4245; (StreamRange -1 False; (I32 0); (ArrayLen (Ref __iruid_4243)); (I32 1)); (ApplyUnaryPrimOp Bang; (IsNA; (ArrayRef -1; (Ref __iruid_4243); (Ref __iruid_4245))))); (Let __iruid_4246; (GetField GT; (ArrayRef -1; (Ref __iruid_4243); (Ref __iruid_4244))); (Let __void; (SeqOp 0 (Sum (TypedStateSig +PInt64)); ((Apply 18 toInt64 () Int64; (ApplyUnaryPrimOp Bang; (IsNA (Ref __iruid_4246)))))); (SeqOp 1 (CallStats (CallStatsStateSig)); ((Ref __iruid_4246))))))); (MakeTuple (0 1); (ResultOp 0 (Sum (TypedStateSig +PInt64))); (ResultOp 1 (CallStats (CallStatsStateSig))))); (InsertFields; (Ref __iruid_4247); None; (foo; (ApplyBinaryPrimOp Subtract; (GetTupleElement 0 (Ref __iruid_4268)); (Let __iruid_4249; (ToArray; (StreamFilter __iruid_4248; (ToStream False; (GetField homozygote_count; (GetTupleElement 1 (Ref __iruid_4268)))); (ApplyUnaryPrimOp Bang; (IsNA (Ref __iruid_4248))))); (Cast Int64; (StreamFold __iruid_4250 __iruid_4251; (ToStream False (Ref __iruid_4249)); (I32 0); (ApplyBinaryPrimOp Add; (Ref __iruid_4250); (Ref __iruid_4251)))))))))); None; (__uid___row_uid20; (GetField __uid___row_uid20 (Ref __iruid_4235))))); ```; (using sexpr printouts because ssa still doesn't handle aggregation well). The problem is the `AggLet` at the root of the result, which is not in an aggregation context. This happens because `__iruid_4247` is used inside an initOp arg, so the `StreamAgg` is rewritten inside the scope of `__iruid_4247` so it can be available in both init ops and the result post-processing. This behavior was added in #12092. As noted there, it was always an incomplete solution. I was already working on cleaning up and reorganizing `Extract.scala` when we got this bug report from a user; I will make sure the redesign handles this correctly. ### Version. 0.2.127. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14305:3479,avail,available,3479,https://hail.is,https://github.com/hail-is/hail/issues/14305,1,['avail'],['available']
Availability,"dTask(TaskSetManager.scala:693); at org.apache.spark.scheduler.TaskSchedulerImpl.handleFailedTask(TaskSchedulerImpl.scala:421); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply$mcV$sp(TaskResultGetter.scala:139); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:124); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:124); at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:124); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```; `pyhail-submit`:; ```bash; #!/bin/bash. if [ $# -ne 2 ]; then; echo 'usage: gcp-pyhail-submit <cluster> <py-file>'; exit 1; fi. cluster=$1; script=$2. echo cluster = $cluster; echo script = $script. HASH=`gsutil cat gs://hail-common/latest-hash.txt`. JAR_FILE=hail-hail-is-master-all-spark2.0.2-$HASH.jar; JAR=gs://hail-common/$JAR_FILE. PYHAIL_ZIP=gs://hail-common/pyhail-hail-is-master-$HASH.zip. gcloud dataproc jobs submit pyspark \; $script \; --cluster $cluster \; --files=$JAR \; --py-files=$PYHAIL_ZIP \; --properties=""spark.driver.extraClassPath=./$JAR_FILE,spark.executor.extraClassPath=./$JAR_FILE"" \; --; ```; cluster JSON:; ```; {; ""projectId"": ""broad-ctsa"",; ""clusterName"": ""cluster-2"",; ""config"": {; ""configBucket"": ""dataproc-7f9e9d5e-03bd-4e95-bea1-fe0321239b35-us"",; ""gceClusterConfig"": {; ""zoneUri"": ""https://www.googleapis.com/compute/v1/projects/broad-ctsa/zones/us-central1-f"",; ""networkUri"": ""https://www.googleapis.com/compute/v1/projects/broad-ctsa/global/networks/default"",; ""serviceAccountScopes"": [; ""https://www.googleapis.com/auth/bigquery"",; ""https://www.googleapis.com/auth/bigtable.admin.table"",; ""https://www.googleapis.com/auth/bigtable.dat",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027:2604,echo,echo,2604,https://hail.is,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027,4,['echo'],['echo']
Availability,"dapter.send(self, request, stream, timeout, verify, cert, proxies); 486 try:; --> 487 resp = conn.urlopen(; 488 method=request.method,; 489 url=url,; 490 body=request.body,; 491 headers=request.headers,; 492 redirect=False,; 493 assert_same_host=False,; 494 preload_content=False,; 495 decode_content=False,; 496 retries=self.max_retries,; 497 timeout=timeout,; 498 chunked=chunked,; 499 ); 501 except (ProtocolError, OSError) as err:. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:787, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 785 e = ProtocolError(""Connection aborted."", e); --> 787 retries = retries.increment(; 788 method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]; 789 ); 790 retries.sleep(). File /opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py:550, in Retry.increment(self, method, url, response, error, _pool, _stacktrace); 549 if read is False or not self._is_method_retryable(method):; --> 550 raise six.reraise(type(error), error, _stacktrace); 551 elif read is not None:. File /opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py:769, in reraise(tp, value, tb); 768 if value.__traceback__ is not tb:; --> 769 raise value.with_traceback(tb); 770 raise value. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:703, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 702 # Make the request on the httplib connection object.; --> 703 httplib_response = self._make_request(; 704 conn,; 705 method,; 706 url,; 707 timeout=timeout_obj,; 708 body=body,; 709 headers=headers,; 710 chunked=chunked,; 711 ); 713 # If we're going to release the connection in ``finally:``, then; 714 # the response doesn't need to know about the connection. Otherwise; 715 # it ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:7287,error,error,7287,https://hail.is,https://github.com/hail-is/hail/issues/13960,1,['error'],['error']
Availability,"dataset metadata and dataset versions.; - Simplify JS logic based on new JSON structure.; - Check-in and implement versioned deployment of the annotation db configuration JSON.; - Add a JS file to the website that defines `hail_version` and `hail_pip_version`.; - Add `key_properties` which currently supports two properties `gene` and `unique`. Gene keyed datasets require using the `gencode` dataset to crosswalk from locus to gene before joining.; - Rudimentary test of key properties functionality. Foundational Changes Outside Annotation DB:; - Define `__pip_version__` in `hail`.; - Teach `StructExpression` and `TupleExpression` how to slice by integers, facilitating the construction of structs of a prefix of fields.; - Make `ttuple` a mapping from integers to the tuple elements.; - Implement `Table._maybe_flexindex_table_by_expr` which, given a indexer expression, finds a prefix of the expression that can index the indexee, if such an expression exists. Unrelated changes:; - Clarify Makefile error echos with `ERROR:`. ---. ## flexindex. The primary use case for this is a dataset which is `locus, allele` keyed and needs to index into a `locus` keyed or `interval<locus>` keyed dataset. Hail's normal join logic will return a key mismatch error:. ```python; import hail as hl; t = hl.utils.range_table(10); t2 = t.key_by(x=t.idx, y=t.idx); t.index(t2.key); ```; ```; Traceback (most recent call last):; File ""<ipython-input-6-3ddc90774dfe>"", line 1, in <module>; t.index(t2.key); File ""/usr/local/lib/python3.7/site-packages/hail/table.py"", line 1536, in index; raise ExpressionException(f""Key type mismatch: cannot index table with given expressions:\n""; ExpressionException: Key type mismatch: cannot index table with given expressions:; Table key: int32; Index Expressions: int32, int32; ```. This new, private, method facilitates the annotation db which users expect to automatically find a compatible prefix of the key to use as an indexer. ---. Dice came up @chrisvittal, but I'",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7178:1521,error,error,1521,https://hail.is,https://github.com/hail-is/hail/pull/7178,3,"['ERROR', 'echo', 'error']","['ERROR', 'echos', 'error']"
Availability,"dates for Security Hub</li>; <li>api-change:<code>ssm-incidents</code>: [<code>botocore</code>] RelatedItems now have an ID field which can be used for referencing them else where. Introducing event references in TimelineEvent API and increasing maximum length of &quot;eventData&quot; to 12K characters.</li>; </ul>; <h1>1.26.7</h1>; <ul>; <li>api-change:<code>autoscaling</code>: [<code>botocore</code>] This release adds a new price capacity optimized allocation strategy for Spot Instances to help customers optimize provisioning of Spot Instances via EC2 Auto Scaling, EC2 Fleet, and Spot Fleet. It allocates Spot Instances based on both spare capacity availability and Spot Instance price.</li>; <li>api-change:<code>ec2</code>: [<code>botocore</code>] This release adds a new price capacity optimized allocation strategy for Spot Instances to help customers optimize provisioning of Spot Instances via EC2 Auto Scaling, EC2 Fleet, and Spot Fleet. It allocates Spot Instances based on both spare capacity availability and Spot Instance price.</li>; <li>api-change:<code>ecs</code>: [<code>botocore</code>] This release adds support for task scale-in protection with updateTaskProtection and getTaskProtection APIs. UpdateTaskProtection API can be used to protect a service managed task from being terminated by scale-in events and getTaskProtection API to get the scale-in protection status of a task.</li>; <li>api-change:<code>es</code>: [<code>botocore</code>] Amazon OpenSearch Service now offers managed VPC endpoints to connect to your Amazon OpenSearch Service VPC-enabled domain in a Virtual Private Cloud (VPC). This feature allows you to privately access OpenSearch Service domain without using public IPs or requiring traffic to traverse the Internet.</li>; <li>api-change:<code>resource-explorer-2</code>: [<code>botocore</code>] Text only updates to some Resource Explorer descriptions.</li>; <li>api-change:<code>scheduler</code>: [<code>botocore</code>] AWS introduces the new Ama",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12458:2555,avail,availability,2555,https://hail.is,https://github.com/hail-is/hail/pull/12458,2,['avail'],['availability']
Availability,"dbalancing/loadBalancers/list). Moreover,; we specify `loadBalancerIP` which is a manually (outside of k8s) allocated IP; which we expose on the public internet. When you `curl https://hail.is` this is what happens:. - Your packet travels across the internet until it reaches the Google TCP; LoadBalancer; - The Google TCP LoadBalancer selects one of the kubernetes nodes to send the; packet to (in principle, it could send the packet to *any* node, even nodes; that do not have a gateway pod).; - Some part of k8s receives the packet and discovers the nodes that host a; gateway pod.; - It selects a gateway pod and forwards the packet to the node (possibly itself); hosting that gateway pod. In doing so, *it must replace the source IP of the; packet with its own, internal, IP*. Note that this is happening at the TCP layer, so no HTTP headers are set. When; the gateway `nginx` receives the packet, there is no trace of the source; IP. Kubernetes has a feature called `externalTrafficPolicy` which is available; in GCP and Azure and preserves the source IP. Kubernetes achieves this by; failing the TCP LoadBalancer healthchecks on nodes without matching pods (in our; case, gateway). The k8s docs on [Source IPs](https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-type-loadbalancer) further explain this strategy. Here's what the healthchecks look like for two; nodes, one hosting a gateway pod and one not hosting a gateway pod (note the; HTTP status code):. ```; dking@gke-vdc-preemptible-pool-2-9aa4dbeb-wvxk ~ $ curl -v localhost:32029; * Trying 127.0.0.1...; * TCP_NODELAY set; * Connected to localhost (127.0.0.1) port 32029 (#0); > GET / HTTP/1.1; > Host: localhost:32029; > User-Agent: curl/7.64.1; > Accept: */*; >; < HTTP/1.1 200 OK; < Content-Type: application/json; < Date: Wed, 05 Feb 2020 20:59:27 GMT; < Content-Length: 88; <; {; 	""service"": {; 		""namespace"": ""default"",; 		""name"": ""gateway""; 	},; 	""localEndpoints"": 1; }; ```; ```; }dking@gke-vd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8045:1444,avail,available,1444,https://hail.is,https://github.com/hail-is/hail/pull/8045,1,['avail'],['available']
Availability,"dcasts""); -> 3614 r, t = Env.hc().eval_expr_typed(expression._ast.to_hql()); 3615 return r, t; 3616. <decorator-gen-1049> in eval_expr_typed(self, expr). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/utils/java.py in handle_py4j(func, *args, **kwargs); 153 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 154 'Hail version: %s\n'; --> 155 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); 156 except py4j.protocol.Py4JError as e:; 157 if e.args[0].startswith('An error occurred while calling'):. FatalError: HailException: `(' expected but `i' found; <input>:1:(if (true) ""T"" else ""F"" + if (true) ""T"" else ""F""); ^. Java stack trace:; is.hail.utils.HailException: `(' expected but `i' found; <input>:1:(if (true) ""T"" else ""F"" + if (true) ""T"" else ""F""); ^; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:27); 	at is.hail.expr.ParserUtils$.error(Parser.scala:32); 	at is.hail.expr.RichParser.parse(Parser.scala:16); 	at is.hail.expr.Parser$.parseExpr(Parser.scala:85); 	at is.hail.HailContext.eval(HailContext.scala:613); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-45429b1; Error summary: HailException: `(' expected but `i' found; <input>:1:(if (true) ""T"" else ""F"" + if (true) ""T"" else ""F""); ^; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2653:3711,Error,Error,3711,https://hail.is,https://github.com/hail-is/hail/issues/2653,1,['Error'],['Error']
Availability,"de = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<16>; T = simdpp::arch_avx2::uint64<8>]â€™; libsimdpp-2.0-rc2/simdpp/types/int32.h:105:36: required from â€˜simdpp::arch_avx2::uint32<N>& simdpp::arch_avx2::uint32<N>::operator=(const simdpp::arch_avx2::any_vec<(N * 4), V>&) [with V = simdpp::arch_avx2::uint64<8, simdpp::arch_avx2::expr_empty>; unsigned int N = 16]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:598:8: required from â€˜void simdpp::arch_avx2::detail::insn::v_sse_transpose32x4(V&, V&, V&, V&) [with V = simdpp::arch_avx2::uint32<16>; D = simdpp::arch_avx2::uint64<8>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:533:62: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint32<16>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint32<16>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint64<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:37,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32.h:86:7: note: â€˜class simdpp::arch_avx2::uint32<16>â€™ declared here; class uint32<N, void> : public any_int32<N, uint32<N,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:98875,error,error,98875,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"de> has been fixed for draft 2019. It's nonetheless; discouraged to use draft 2019 for any schemas, new or old.</li>; <li>Fix a number of minor annotation issues in <code>protocols.Validator</code></li>; </ul>; <h1>v4.13.0</h1>; <ul>; <li>Add support for creating validator classes whose metaschema uses a different; dialect than its schemas. In other words, they may use draft2020-12 to define; which schemas are valid, but the schemas themselves use draft7 (or a custom; dialect, etc.) to define which <em>instances</em> are valid. Doing this is likely; not something most users, even metaschema authors, may need, but occasionally; will be useful for advanced use cases.</li>; </ul>; <h1>v4.12.1</h1>; <ul>; <li>Fix some stray comments in the README.</li>; </ul>; <h1>v4.12.0</h1>; <ul>; <li>Warn at runtime when subclassing validator classes. Doing so was not; intended to be public API, though it seems some downstream libraries; do so. A future version will make this an error, as it is brittle and; better served by composing validator objects instead. Feel free to reach; out if there are any cases where changing existing code seems difficult; and I can try to provide guidance.</li>; </ul>; <h1>v4.11.0</h1>; <ul>; <li>Make the rendered README in PyPI simpler and fancier. Thanks Hynek (<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/issues/983"">#983</a>)!</li>; </ul>; <h1>v4.10.3</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/420fc6bd9a3ecc4cd637ece97cb4b482b4d0d37e""><code>420fc6b</code></a> Minor verbiage tweak for protocols.</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/8ce8250897e1b2e9b1fea6825965dbc876ec1f4d""><code>8ce8250</code></a> Don't show type checker functions in TypeChecker reprs.</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/6533d32",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12163:5764,error,error,5764,https://hail.is,https://github.com/hail-is/hail/pull/12163,1,['error'],['error']
Availability,"de> option and also introduces a new optional <code>--pod-interface-name-prefix</code> and <code>--pod-bridge-interface</code> flags to kube-proxy. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/95400"">kubernetes/kubernetes#95400</a>, <a href=""https://github.com/tssurya""><code>@â€‹tssurya</code></a>)</li>; <li>CEL CRD validation expressions may now reference existing object state using the identifier <code>oldSelf</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108073"">kubernetes/kubernetes#108073</a>, <a href=""https://github.com/benluddy""><code>@â€‹benluddy</code></a>)</li>; <li>CRD deep copies should no longer contain shallow copies of <code>JSONSchemaProps.XValidations</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107956"">kubernetes/kubernetes#107956</a>, <a href=""https://github.com/benluddy""><code>@â€‹benluddy</code></a>)</li>; <li>CRD writes will generate validation errors if a CEL validation rule references the identifier <code>oldSelf</code> on a part of the schema that does not support it. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108013"">kubernetes/kubernetes#108013</a>, <a href=""https://github.com/benluddy""><code>@â€‹benluddy</code></a>)</li>; <li>CSIStorageCapacity.storage.k8s.io: The v1beta1 version of this API is deprecated in favor of v1, and will be removed in v1.27. If a CSI driver supports storage capacity tracking, then it must get deployed with a release of external-provisioner that supports the v1 API. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108445"">kubernetes/kubernetes#108445</a>, <a href=""https://github.com/pohly""><code>@â€‹pohly</code></a>)</li>; <li>Custom resource requests with <code>fieldValidation=Strict</code> consistently require <code>apiVersion</code> and <code>kind</code>, matching non-strict requests (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pul",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:3676,error,errors,3676,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['error'],['errors']
Availability,"de></a> Bump pylint to 2.13.3, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/a880bd6d85d2487f509d1505b5146d608b15d870""><code>a880bd6</code></a> Change 'nonexistent-operator' to allow repeated unary ops (with space or pare...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c73353064f934ae49472eb6138e1f8071b6b733e""><code>c733530</code></a> <code>unnecessary-ellipsis</code> false positive: allow ellipsis as default argument (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6"">#6</a>...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/19e6531068cf95d602054ff8638adcb79971d552""><code>19e6531</code></a> Fix crash on unbalanced tuple unpacking</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/2066cab9bbe43341b84014ac9610e275db586431""><code>2066cab</code></a> Bump pylint to 2.13.2, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/6a25d7048edadc18a05e999021049ade86ef2bd9""><code>6a25d70</code></a> Better error message when we cant write the crash files (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5987"">#5987</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c42fe73a1613bbfb52a5ba9129efa45a3fd76401""><code>c42fe73</code></a> Fix false negative for <code>protected-access</code> on functions (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5990"">#5990</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/dec241b1787e6c99a092bb9ef6a993abf51fea91""><code>dec241b</code></a> Add regression test for <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5982"">#5982</a> upgrade astroid to 2.11.2 (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5988"">#5988</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b25859c4a56ccce61087f7a1270f40deaed68169""><code>b25859c</code></a> Fix false positive for <code>superfluous-parens</code> for <code>return (a or b) in iterable</code>...</li>; <l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11702:3432,error,error,3432,https://hail.is,https://github.com/hail-is/hail/pull/11702,1,['error'],['error']
Availability,"de></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86a15f1c16eb729dc71b6caf30237d07b8e0bb01""><code>86a15f1</code></a> Fix compiler warnings and deprecations</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86363072c8239330b28976109a622bdd073507b6""><code>8636307</code></a> Negative timeouts are actually not allowed</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4ff0ff0e63e0dd45f231990d0dcebffde6e6b709""><code>4ff0ff0</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a1858b494b5f3a51ccef7580c243c6dfdf520731""><code>a1858b4</code></a> Merge pull request <a href=""https://redirect.github.com/michel-kraemer/gradle-download-task/issues/295"">#295</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/c1e212c0fb41b3ea9185a9ea463fb1ea7142f748""><code>c1e212c</code></a> Add integration tests for Gradle 8.0 and 8.0.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/304f68e25f53633a92a4d2d6ce003a4986929503""><code>304f68e</code></a> Fix type inference issue</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.1...5.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.1&new-version=5.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:2310,down,download-task,2310,https://hail.is,https://github.com/hail-is/hail/pull/12893,1,['down'],['download-task']
Availability,"de>b94395d</code></a> Bump version to 7.7.1 for release</li>; <li><a href=""https://github.com/cbeust/testng/commit/89dc5845fcb46c26af187e50ea907a7382d06e72""><code>89dc584</code></a> Streamline overloaded assertion methods for Groovy</li>; <li><a href=""https://github.com/cbeust/testng/commit/5ac0021d14f7eb00804fe235aaefc5c2fbce57d1""><code>5ac0021</code></a> Adding release notes</li>; <li><a href=""https://github.com/cbeust/testng/commit/c0e1e772f1fc0ab2142f3a4114a2b8cfe60fa7e1""><code>c0e1e77</code></a> Adjust version reference in deprecation msgs.</li>; <li><a href=""https://github.com/cbeust/testng/commit/011527d9bf0f91a40539f5e5467cc106888810d9""><code>011527d</code></a> Bump version to 7.7.0 for release</li>; <li><a href=""https://github.com/cbeust/testng/commit/7846c444a411647f7e401a097224702188c93835""><code>7846c44</code></a> Deprecate support for running JUnit tests</li>; <li><a href=""https://github.com/cbeust/testng/commit/8630a7e8fe12985d71c00212f9362fd38fb0cb9e""><code>8630a7e</code></a> Ensure ITestContext available for JUnit4 tests</li>; <li><a href=""https://github.com/cbeust/testng/commit/7070b020def0089d0d9dc695a5762ad16e974ce6""><code>7070b02</code></a> Streamline dependsOnMethods for configurations</li>; <li><a href=""https://github.com/cbeust/testng/commit/d7e0bb1cbcd7933d34d704678e75cbaf42704505""><code>d7e0bb1</code></a> Deprecate support for running Spock Tests</li>; <li><a href=""https://github.com/cbeust/testng/commit/ca7a3a293008389096be75fea4936af8e5f79650""><code>ca7a3a2</code></a> Ensure All tests run all the time</li>; <li>Additional commits viewable in <a href=""https://github.com/cbeust/testng/compare/testng-6.8.21...7.7.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.testng:testng&package-manager=gradle&previous-version=6.8.21&new-version=7.7.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-depend",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:15897,avail,available,15897,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['avail'],['available']
Availability,"ded_gather`, allows it to be used recursively. In particular, suppose we had a semaphore of; 50. The outer `bounded_gather2` might need 20 slots to run its 20 paths in parallel. That leaves 30 slots of parallelism left over for its children. By passing the semaphore down, we let our children optimistically use some of that excess parallelism. 2. If we happen to have the `StatResult` for a particular object, we should never again look it up. In particular, getting the `StatResult` for every file in a directory can be done in O(1) requests. Getting the `StatResult` for each of those files individually (using their full paths) is necessarily O(N). If there was at least one glob and also there are no `suffix_components`, then we can use the `StatResult`s that we learned when checking the glog pattern. The latter point is perhaps a bit more clear with examples:. 1. `gs://foo/bar/baz`. Since there are no globs, we can make exactly one API request to list `gs://foo/bar/baz`. 2. `gs://foo/b*r/baz`. In this case, we must make one API request to list `gs://foo/`. This gives us a list of paths under that prefix. We check each path for conformance to the glob pattern `gs://foo/b*r`. For any path that matches, we must then list `<the matching path>/baz` which may itself be a directory containing files. Overall we make O(1) API requests to do the glob and then O(K) API requests to get the final `StatResult`s, where K is the number of paths matching the glob pattern. 3. `gs://foo/bar/b*z`. In this case, we must make one API request to list `gs://foo/bar/`. In `main`, we then throw away the `StatResult`s we got from that API request! Now we have to make O(K) requests to recover those `StatResult`s for all K paths that match the glob pattern. This PR just caches the `StatResult`s of the most recent globbing. If there is no suffix to later append, then we can just re-use the `StatResult`s we already have!. cc: @daniel-goldstein since you've reviewed this before. Might be of interest.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13253:1973,recover,recover,1973,https://hail.is,https://github.com/hail-is/hail/pull/13253,1,['recover'],['recover']
Availability,"def main(args):; hl.init(log='/variant_histograms.log'); data_type = 'genomes' if args.genomes else 'exomes'. metrics = ['FS', 'InbreedingCoeff', 'MQ', 'MQRankSum', 'QD', 'ReadPosRankSum', 'SOR', 'BaseQRankSum',; 'ClippingRankSum', 'DP', 'VQSLOD', 'rf_tp_probability', 'pab_max']. ht = hl.read_table(release_ht_path(data_type, nested=False)); # NOTE: histogram aggregations are done on the entire callset (not just PASS variants), on raw data. # Compute median and MAD on variant metrics; medmad_dict = {}; for metric in metrics:; medmad_dict[metric] = hl.struct(median=hl.median(hl.agg.collect(ht[metric])), mad=4*1.48268*hl.median(hl.abs(hl.agg.collect(ht[metric])-hl.median(hl.agg.collect(ht[metric]))))); medmad = ht.aggregate(hl.struct(**medmad_dict)); print(medmad); print(hl.eval_expr(hl.json(medmad))); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; [Stage 0:==================================================>(9853 + 93) / 10000]#; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fbeaec3ca22, pid=6662, tid=0x00007fbe3dd81700; #; # JRE version: OpenJDK Runtime Environment (8.0_181-b13) (build 1.8.0_181-8u181-b13-1~deb9u1-b13); # Java VM: OpenJDK 64-Bit Server VM (25.181-b13 mixed mode linux-amd64 compressed oops); # Problematic frame:; # J 14270 C1 is.hail.annotations.Region.storeInt(JI)V (6 bytes) @ 0x00007fbeaec3ca22 [0x00007fbeaec3c980+0xa2]; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /tmp/828e66d5a71741d7ab2c8d6580997da3/hs_err_pid6662.log; Compiled method (c1) 88328 14270 3 is.hail.annotations.Region::storeInt (6 bytes); total in heap [0x00007fbeaec3c810,0x00007fbeaec3cbc0] = 944; relocation [0x00007fbeaec3c938,0x00007fbeaec3c968] = 48; main code [0x00007fbeaec3c980,0x00007fbeaec3caa0] = 288; stub code [0x00007",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4418:1633,error,error,1633,https://hail.is,https://github.com/hail-is/hail/issues/4418,2,['error'],['error']
Availability,"defun patch code for Click 8.1.0 (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2966"">#2966</a>)</li>; <li><a href=""https://github.com/psf/black/commit/ac7402cbf6a0deb5c74e9abcffc5bd7b1148fda5""><code>ac7402c</code></a> Bump sphinx from 4.4.0 to 4.5.0 in /docs (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2959"">GH-2959</a>)</li>; <li><a href=""https://github.com/psf/black/commit/f239d227c003c52126239e1b9a37c36c2b2b8305""><code>f239d22</code></a> Enforce no formatting changes for PRs via CI (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2951"">GH-2951</a>)</li>; <li><a href=""https://github.com/psf/black/commit/bd1e98034907463f5d86f4d87e89202dc6c34dd4""><code>bd1e980</code></a> Remove unnecessary parentheses from <code>except</code> clauses (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2939"">#2939</a>)</li>; <li><a href=""https://github.com/psf/black/commit/14d84ba2e96c5ca1351b8fe4d0d415cc148f4117""><code>14d84ba</code></a> Resolve new flake8-bugbear errors (B020) (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2950"">GH-2950</a>)</li>; <li><a href=""https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579""><code>14e5ce5</code></a> Remove unnecessary parentheses from tuple unpacking in <code>for</code> loops (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2945"">#2945</a>)</li>; <li><a href=""https://github.com/psf/black/commit/3800ebd81df6a1c31d1eac8cc15899537b9cbb61""><code>3800ebd</code></a> Avoid magic-trailing-comma in single-element subscripts (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2942"">#2942</a>)</li>; <li><a href=""https://github.com/psf/black/commit/062b54931dc3ea35f673e755893fe28ff1f5a889""><code>062b549</code></a> Github now supports .git-blame-ignore-revs (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2948"">GH-2948</a>)</li>; <li><a href=""https://github.com/psf/black/commit/5379d4f3f460ec9b706",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11696:7790,error,errors,7790,https://hail.is,https://github.com/hail-is/hail/pull/11696,1,['error'],['errors']
Availability,"dependabot.com/aio-libs/aiodocker/issues/411"">#411</a>)</li>; <li>Implement docker exec protocol. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/415"">#415</a>)</li>; <li>Implement container commit, pause and unpause functionality. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/418"">#418</a>)</li>; <li>Implement auto-versioning of the docker API by default. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/419"">#419</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiodocker/blob/master/CHANGES.rst"">aiodocker's changelog</a>.</em></p>; <blockquote>; <h1>0.21.0 (2021-07-23)</h1>; <h2>Bugfixes</h2>; <ul>; <li>Use ssl_context passsed to Docker constructor for creating underlying connection to docker engine. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/536"">#536</a>)</li>; <li>Fix an error when attach/exec when container stops before close connection to it. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/608"">#608</a>)</li>; </ul>; <h1>0.20.0 (2021-07-21)</h1>; <h2>Bugfixes</h2>; <ul>; <li>Accept auth parameter by <code>run()</code> method; it allows auto-pulling absent image from private storages. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/295"">#295</a>)</li>; <li>Fix passing of JSON params. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/543"">#543</a>)</li>; <li>Fix issue with unclosed response object in attach/exec. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/604"">#604</a>)</li>; </ul>; <h1>0.19.1 (2020-07-09)</h1>; <h2>Bugfixes</h2>; <ul>; <li>Fix type annotations for <code>exec.start()</code>, <code>docker.images.pull()</code>,; <code>docker.images.push()</code>. Respect default arguments again.</li>; </ul>; <h1>0.19.0 (2020-07-07)</h1>; <h2>Features<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11537:1412,error,error,1412,https://hail.is,https://github.com/hail-is/hail/pull/11537,1,['error'],['error']
Availability,"dependabot.com/jupyter/jupyter_client/pull/882"">#882</a> (<a href=""https://github.com/kevin-bates""><code>@â€‹kevin-bates</code></a>)</li>; <li>Reconcile connection information <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/879"">#879</a> (<a href=""https://github.com/kevin-bates""><code>@â€‹kevin-bates</code></a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/5a12a3842563c682dd462eb73000adff1fcedd0f""><code>5a12a38</code></a> Publish 8.0.2</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/717d36edcd9ce595f727d8b5a27e270c2a6e2c46""><code>717d36e</code></a> Adopt more ruff rules (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/924"">#924</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/666eab0b8cd7991697a9957001cf78401a76c52d""><code>666eab0</code></a> Add papermill downstream check and fix kernel client replies (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/925"">#925</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/fac9c3a890599ca8d7ee73206f98d75574cf4ca8""><code>fac9c3a</code></a> Prefer print in kernelspecapp (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/923"">#923</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/9904c4163a60c5e98737c7934b9a876c806c58fa""><code>9904c41</code></a> Publish 8.0.1</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/dc6113c360e05122430b8e130374e9f4e4b701d7""><code>dc6113c</code></a> Fix json_output in kernelspec app (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/921"">#921</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/dac3cc2caa83dde06a69012e610717019026aa4e""><code>dac3cc2</code></a> Publish 8.0.0</li>; <li><a href=""htt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12656:6885,down,downstream,6885,https://hail.is,https://github.com/hail-is/hail/pull/12656,1,['down'],['downstream']
Availability,"deployment.yamls if I modify the trust sets. That seemed error prone. If I had one secret with all the certs, then when a service starts up it has to select the trusted ones and only insert those into its certificate store. This seems OK, but a little harder to inspect. Duplicating a cert for each trust list to which it belongs occupies what seems like a good spot to me from a developer ergonomics perspective:; - O(trusts) modifications necessary to update/revoke the cert; - O(1) configuration to load a trust list; - no pod-start-time configuration; - the trust list is on the container's file system, so its easy to inspect. Small point: I don't pin the incoming certs yet due to the mTLS challenges. ### create on each deploy. Only creating certs if they don't exist is an easy change. Seems fine, though leaves unresolved how to rotate the certs. I guess I'm inclined to always recreate because it makes rotation the common case, forcing us to make it work well. I think the only way to do a no-downtime rotation is:; 1. create fresh certs; 2. create the trust lists including a principal's fresh cert and previous generation cert; 3. update all the secrets; 4. somehow ensure everyone has the latest secrets?; 5. notify all servers to refresh their certificates (nginx: send SIGHUP, aiohttp: we have to write something). We could stick a generation uuid in the secrets and keep refreshing services until the certificate uuid they read is the one our deploy expects. ### mTLS. This PR will land. Things will break because the unmanaged services (router-resolver, gateway, internal-gateway) do not speak TLS. I'll manually deploy them. The default namespace and new PR namespaces should now function properly. Developers will need to redeploy from master. With this in place, I will make another PR with two main changes:; - enable client verification, and; - modify create_certs.py to load the unmanaged certificates from `default` rather than the local namespace.; That PR should pass all t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561#issuecomment-617428243:2841,downtime,downtime,2841,https://hail.is,https://github.com/hail-is/hail/pull/8561#issuecomment-617428243,2,['downtime'],['downtime']
Availability,"der: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 12:51:55 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 12:51:55 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 12:51:55 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 12:51:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 12 2017 14:00:23); SparkSession available as 'spark'. In [1]: from hail import *; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); <ipython-input-1-3181c5d8fca5> in <module>(); ----> 1 from hail import *. /opt/Software/hail/python/hail/__init__.py in <module>(); ----> 1 import hail.expr; 2 from hail.representation import *; 3 from hail.context import HailContext; 4 from hail.dataset import VariantDataset; 5 from hail.expr import *. /opt/Software/hail/python/hail/expr.py in <module>(); 1 import abc; 2 from hail.java import scala_object, Env, jset; ----> 3 from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; 4 ; 5 . /opt/Software/hail/python/hail/representation/__init__.py in <module>(); ----> 1 from hail.representation.variant import Variant, Locus, AltAllele; 2 from hail.representation.interval import Interval; 3 from hail.representation.genotype import Genotype, Call; 4 from hail.representa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-321152609:2148,avail,available,2148,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321152609,1,['avail'],['available']
Availability,"des, but I want to add three things on top of that:. 1. I don't want to have to do as much custom per IR node work; 2. I don't want to send the entire python stack trace over py4j to scala for every node; 3. I don't want the user to see a Java stack trace in this scenarios. This first PR is a proof of concept that adds this behavior for the `Die` node, which will catch any errors generated by uses of `CaseBuilder.or_error`. Follow up PRs should change `ArrayRef` to work this way, as well as catch things like looking up a key in a dictionary but not finding it. In an ideal future, we'd bolt on some extra mechanism to give types to these errors, and we could throw a proper `IndexError` in the `ArrayRef` case or `KeyError` in the dictionary case. . It feels a little bit messy right now, open to suggestions. I don't love using `-1` as the ""no error"" situation, but I thought it was probably easier than dealing with optionals between python and scala. . To give an example of what it looks like, the error message for this script:. ```; import hail as hl. ht = hl.utils.range_table(10); ht = ht.annotate(foo = hl.nd.array([[1], [2], [3]])); ht = ht.annotate(bar = ht.foo[0:4, 12]); ht.collect(); ```. is. ```; Traceback (most recent call last):; File ""better_error_test.py"", line 6, in <module>; ht.collect(); File ""<decorator-gen-1103>"", line 2, in collect; File ""/Users/johnc/Code/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/johnc/Code/hail/hail/python/hail/table.py"", line 1903, in collect; return Env.backend().execute(e._ir); File ""/Users/johnc/Code/hail/hail/python/hail/backend/spark_backend.py"", line 325, in execute; raise HailUserError(message_and_trace) from None; hail.utils.java.HailUserError: Error summary: HailException: Index 12 is out of bounds for axis 1 with size 1; ------------; Hail stack trace:; File ""better_error_test.py"", line 5, in <module>; ht = ht.annotate(bar = ht.foo[0:4, 12]). File",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9398:1305,error,error,1305,https://hail.is,https://github.com/hail-is/hail/pull/9398,1,['error'],['error']
Availability,"ding the full java stack trace):; ```; Traceback (most recent call last):; File ""/hail-elasticsearch-pipelines/hail_scripts/v01/load_clinvar_to_es_pipeline.py"", line 112, in <module>; export_globals_to_index_meta=True,; File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 142, in export_vds_to_elasticsearch; verbose=verbose); File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 287, in export_kt_to_elasticsearch; kt.export_elasticsearch(self._host, int(self._port), index_name, index_type_name, block_size, config=elasticsearch_config); File ""<decorator-gen-143>"", line 2, in export_elasticsearch; File ""/hail/build/distributions/hail-python.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 6.0.0. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 1 times, most recent failure: Lost task 0.0 in stage 12.0 (TID 20050, localhost): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot detect ES version - typically this happens if the network/Elasticsearch cluster is not accessible or when targeting a WAN/Cloud instance without the proper setting 'es.nodes.wan.only'; 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:247); 	at org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:545); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:58); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.run",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:1531,failure,failure,1531,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['failure'],['failure']
Availability,"direct.dependabot.com/inveniosoftware/dictdiffer/issues/85"">#85</a>)</li>; <li>Improves API documentation for <code>ignore</code> argument in <code>diff</code> function.; (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/79"">#79</a>)</li>; <li>Executes doctests during PyTest invocation.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/36506e4046e07e4d43e0b5af6f76c75ff7b2b6a3""><code>36506e4</code></a> ci: remove compilie_catalog</li>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/2cc6ff223bdc2f2fa6b3a1842c68fc12d9555645""><code>2cc6ff2</code></a> release: v0.9.0 (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/161"">#161</a>)</li>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/d2f84b7dbe5e2ea871c25f7cb013d36e3be221e8""><code>d2f84b7</code></a> diff: add support for absolute tolerance of floats (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/152"">#152</a>)</li>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/fb2064ad9400c3b1c46a9c5cc58a0d509b1c99fd""><code>fb2064a</code></a> global: drop support for Python&lt;3.5 (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/160"">#160</a>)</li>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/02446475a71a22de6f7ee3d1aba2655e625c8e31""><code>0244647</code></a> testing: add <code>assert_no_diff</code> helper to assist pytest users (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/153"">#153</a>)</li>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/09372ecfe8bccaacfeaf3d6bab5ce69f1947a949""><code>09372ec</code></a> tests: set minimum numpy installation to earliest version with a wheel (<a href=""https://github-redirect.dependabot.co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11485:6379,toler,tolerance,6379,https://hail.is,https://github.com/hail-is/hail/pull/11485,1,['toler'],['tolerance']
Availability,"direct.dependabot.com/psf/black/issues/3150"">#3150</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Vim plugin: prefix messages with <code>Black: </code> so it's clear they come from Black (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3194"">#3194</a>)</li>; <li>Docker: changed to a /opt/venv installation + added to PATH to be available to non-root users (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3202"">#3202</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>Change from deprecated <code>asyncio.get_event_loop()</code> to create our event loop which removes DeprecationWarning (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3164"">#3164</a>)</li>; <li>Remove logging from internal <code>blib2to3</code> library since it regularly emits error logs about failed caching that can and should be ignored (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3193"">#3193</a>)</li>; </ul>; <h3>Parser</h3>; <ul>; <li>Type comments are now included in the AST equivalence check consistently so accidental deletion raises an error. Though type comments can't be tracked when running on PyPy 3.7 due to standard library limitations. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2874"">#2874</a>)</li>; </ul>; <h3>Performance</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/black/blob/main/CHANGES.md"">black's changelog</a>.</em></p>; <blockquote>; <h2>22.8.0</h2>; <h3>Highlights</h3>; <ul>; <li>Python 3.11 is now supported, except for <em>blackd</em> as aiohttp does not support 3.11 as; of publishing (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3234"">#3234</a>)</li>; <li>This is the last release that supports running <em>Black</em> on Python 3.6 (formatting 3.6; code will continue to be supported until further notice)</li>; <li>Reword the stability policy to ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:4768,error,error,4768,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['error'],['error']
Availability,"dle/pydevd_runpy.py"", line 321, in run_path; return _run_module_code(code, init_globals, run_name,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 135, in _run_module_code; _run_code(code, mod_globals, init_globals,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 124, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/test.py"", line 34, in <module>; main(); File ""/home/edmund/.local/src/hail/test.py"", line 28, in main; r2_adj = r2_adj.checkpoint(f'{tmp}/adj', overwrite=args.overwrite); File ""<decorator-gen-1508>"", line 2, in checkpoint; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/linalg/blockmatrix.py"", line 679, in checkpoint; self.write(path, overwrite, force_row_major, stage_locally); File ""<decorator-gen-1506>"", line 2, in write; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/linalg/blockmatrix.py"", line 656, in write; Env.backend().execute(BlockMatrixWrite(self._bmir, writer)); File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/home/edmund/.local/src/hail/hail/python/hail/backend/service_backend.py"", line 498, in _rpc; return self._cancel_on_ctrl_c(self._async_rpc(action, payload)); File ""/home/edmund/.local/src/hail/hail/python/hail/backend/service_backend.py"", line 488, in _cancel_on_ctrl_c; return async_to_bloc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14537:3582,checkpoint,checkpoint,3582,https://hail.is,https://github.com/hail-is/hail/issues/14537,1,['checkpoint'],['checkpoint']
Availability,do I have test failures? I thought it passed,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8067#issuecomment-585439143:15,failure,failures,15,https://hail.is,https://github.com/hail-is/hail/pull/8067#issuecomment-585439143,1,['failure'],['failures']
Availability,do we have tests that verify we get errors if we try to rekey with annotate_rows?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4242#issuecomment-417758456:36,error,errors,36,https://hail.is,https://github.com/hail-is/hail/pull/4242#issuecomment-417758456,1,['error'],['errors']
Availability,docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc ']'; + echo HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc; HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc ']'; + echo HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc ']'; + echo HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc; + for varname in '$arguments'; + '[' -z '' ']'; + echo. + usage; + cat; ++ basename hail/scripts/release.sh; ++ basename hail/scripts/release.sh; usage: release.sh. All arguments are specified by environment variables. For example:. HAIL_PIP_VERSION=0.2.123; HAIL_VERSION=0.2.123-abcdef123; GIT_VERSION=abcdef123; REMOTE=origin; WHEEL=/path/to/the.whl; GITHUB_OAUTH_HEADER_FILE=/path/to/github/oauth/header/file; HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAILTOP_IMAGE=doc,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:4167,echo,echo,4167,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,1,['echo'],['echo']
Availability,docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc ']'; + echo HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc; HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc ']'; + echo HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc ']'; + echo HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc; + for varname in '$arguments'; + '[' -z x ']'; + echo WHEEL_FOR_AZURE=x; WHEEL_FOR_AZURE=x; + for varname in '$arguments'; + '[' -z /path/to/www.tar.gz ']'; + echo WEBSITE_TAR=/path/to/www.tar.gz; WEBSITE_TAR=/path/to/www.tar.gz; + exit 1. ```. ```sh; # WEBSITE_TAR=g WHEEL_FOR_AZURE=f HAIL_GENETICS_VEP_GRCH38_95_IMAGE=e HAIL_GENETICS_VEP_GRCH37_85_IMAGE=d HAIL_GENETICS_HAILTOP_IMAGE=c HAIL_GENETICS_HAIL_IMAGE_PY_3_11=b HAIL_GENETICS_HAIL_IMAGE_PY_3_10=a HAIL_GENETICS_HAIL_IMAGE=abc123 GITHUB_OAUTH_HEADER_FILE=abc123 DEPLOY_REMOTE=origin make -C hail release; HAIL_PIP_VERSION=0.2.128 \; HAIL_VERSION=0.2.128-91d328e7fc84 \; GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a \; REMOTE=origin \; WHEEL=build/deploy/dist/hail-0.2.128-py3-none-any.whl ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:9643,echo,echo,9643,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,1,['echo'],['echo']
Availability,"docker_prefix is not exactly the ""registry name"" in azure's definition, but it is `<registry_name>.azurecr.io` which `az acr login` accepts alternatively to just the registry name. Didn't seem worth adding a mostly redundant config field.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11301:215,redundant,redundant,215,https://hail.is,https://github.com/hail-is/hail/pull/11301,1,['redundant'],['redundant']
Availability,"doctest failure from show() changing the width, it seems",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5666#issuecomment-475778217:8,failure,failure,8,https://hail.is,https://github.com/hail-is/hail/pull/5666#issuecomment-475778217,1,['failure'],['failure']
Availability,doctest failures related to `ld_score_regression.sample.mt` -- either we need to mark those as SKIP or check that file in,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6510#issuecomment-506860319:8,failure,failures,8,https://hail.is,https://github.com/hail-is/hail/pull/6510#issuecomment-506860319,1,['failure'],['failures']
Availability,don't throw old version error when trying to read keytable as vds,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1689:24,error,error,24,https://hail.is,https://github.com/hail-is/hail/issues/1689,1,['error'],['error']
Availability,"doop.rest.RestRepository.writeToIndex(RestRepository.java:168); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.1-408f188; Error summary: EsHadoopIllegalArgumentException: Spark SQL types are not handled through basic RDD saveToEs() calls; typically this is a mistake(as the SQL schema will be ignored). Use 'org.elasticsearch.spark.sql' package instead; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [ffc9fb0b99f64080b674ab7a07962df9] entered state [ERROR] while waiting for [DONE].; ```. Ideally it would get exported as nested objects: https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html#_using_literal_nested_literal_fields_for_arrays_of_objects. with elasticsearch mapping:; ```; u'vep': {'type': 'nested', 'properties': {u'category': {'type': 'keyword'}, u'major_consequence': {'type': 'keyword'}, u'gene_id': {'type': 'keyword'}, u'major_consequence_rank': {'type': 'integer'}, u'gene_symbol': {'type': 'keyword'}, u'transcript_id': {'type': 'keyword'}, u'hgvs': {'type': 'keyword'}, u'protein_id': {'type': 'keyword'}}}, ; ```. I thought about switching to saveJsonToEs here: ; https://github.com/hail-is/hail/blob/0.1/src/main/scala/is/hail/io/ElasticsearchConnector.scala#L33; but not sure how to auto-convert to json before exporting; https://www.elastic.co/guide/en/elasticsearch/hadoop/6.x/spark.html#spark-streaming-write-json",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:11440,ERROR,ERROR,11440,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['ERROR'],['ERROR']
Availability,"doop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html</a></p>; <h2>Elasticsearch Hadoop 8.2.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html</a></p>; <h2>Elasticsearch Hadoop 8.1.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/a7873eb46985d849286ab89fa0a51f8b5374e02e""><code>a7873eb</code></a> Update index.adoc (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2000"">#2000</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2002"">#2002</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/9f44fe66d0ff82f18a13a38cae6abf3f72183a94""><code>9f44fe6</code></a> Bump to version 8.4.3</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/c9e3b114b98bb0e340555311c82e2d9f32c880b6""><code>c9e3b11</code></a> [DOCS] Add 8.4.2 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1998"">#1998</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1999"">#",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:4335,down,downloads,4335,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['down'],['downloads']
Availability,"down to 38 minutes, with the cleaning up GCP instances now a significant delay. <img width=""2031"" alt=""Screen Shot 2023-05-17 at 23 02 20"" src=""https://github.com/hail-is/hail/assets/106194/6b14d74e-877c-4259-bc26-fd4fed91fe26"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13076#issuecomment-1552339379:0,down,down,0,https://hail.is,https://github.com/hail-is/hail/pull/13076#issuecomment-1552339379,1,['down'],['down']
Availability,"download-task/commit/fa2739ded05333ba46d8f50bb3b2a3721cf0ca86""><code>fa2739d</code></a> Create target directories at a central place</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/02b8e1a79d9e00acd61f9ac42e5555619fe2247a""><code>02b8e1a</code></a> Prevent duplicate destination files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0b65ca2f17c8890a3ec34cf80cde52ee5413cbec""><code>0b65ca2</code></a> Call eachFile action only once per source</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/717877121299cea8f216d3a595eaa56731a6acd3""><code>7178771</code></a> Support changing a target file's relative path in an eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e5af1bd7f9daa8a9222aee0dd1b703727cb5e94e""><code>e5af1bd</code></a> Bump version number to 5.3.0-SNAPSHOT</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/3.2.0...5.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=3.2.0&new-version=5.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:5112,down,download-task,5112,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['down'],['download-task']
Availability,downsample aggregator throws null pointer exception for empty table,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4226:0,down,downsample,0,https://hail.is,https://github.com/hail-is/hail/pull/4226,1,['down'],['downsample']
Availability,"ds != None else None); 44 result = cmd.run(jstate,; ---> 45 cmd_args); 46 return VariantDataset(self, result.vds()); 47 . /Users/tpoterba/spark-1.6.2-bin-hadoop2.6/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py in __call__(self, *args); 811 answer = self.gateway_client.send_command(command); 812 return_value = get_return_value(; --> 813 answer, self.gateway_client, self.target_id, self.name); 814 ; 815 for temp_arg in temp_args:. /Users/tpoterba/spark-1.6.2-bin-hadoop2.6/python/pyspark/sql/utils.pyc in deco(*a, **kw); 43 def deco(*a, **kw):; 44 try:; ---> 45 return f(*a, **kw); 46 except py4j.protocol.Py4JJavaError as e:; 47 s = e.java_exception.toString(). /Users/tpoterba/spark-1.6.2-bin-hadoop2.6/python/lib/py4j-0.9-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 306 raise Py4JJavaError(; 307 ""An error occurred while calling {0}{1}{2}.\n"".; --> 308 format(target_id, ""."", name), value); 309 else:; 310 raise Py4JError(. Py4JJavaError: An error occurred while calling o92.run.; : org.broadinstitute.hail.utils.package$FatalException: arguments refer to no files; 	at org.broadinstitute.hail.utils.package$.fatal(package.scala:27); 	at org.broadinstitute.hail.driver.VCFImporter$class.globAllVcfs(ImportVCF.scala:17); 	at org.broadinstitute.hail.driver.ImportVCF$.globAllVcfs(ImportVCF.scala:33); 	at org.broadinstitute.hail.driver.ImportVCF$.run(ImportVCF.scala:83); 	at org.broadinstitute.hail.driver.ImportVCF$.run(ImportVCF.scala:33); 	at org.broadinstitute.hail.driver.Command.runCommand(Command.scala:258); 	at org.broadinstitute.hail.driver.Command.run(Command.scala:263); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231); 	at py4j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1096:1633,error,error,1633,https://hail.is,https://github.com/hail-is/hail/issues/1096,1,['error'],['error']
Availability,"duh you're totally right, I don't know why I thought retrying was happening higher up and not further down in the http client.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12199#issuecomment-1255528060:102,down,down,102,https://hail.is,https://github.com/hail-is/hail/pull/12199#issuecomment-1255528060,1,['down'],['down']
Availability,"e (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxMjY5MWQyMS0wMzk1LTQxYjMtODBkMi1mMjEyODM",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13873:3250,avail,available,3250,https://hail.is,https://github.com/hail-is/hail/pull/13873,1,['avail'],['available']
Availability,"e 2, in write; File ""/restricted/projectnb/genpro/github/hail/python/hail/typecheck/check.py"", line 481, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/restricted/projectnb/genpro/github/hail/python/hail/matrixtable.py"", line 1935, in write; self._jvds.write(output, overwrite, _codec_spec); File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: gcad.sv.delly.5k.vcf.bgz:column 80816: invalid character '-' in integer literal; ... 2:0:0:0:6 ./.:0,0,0:0:LowQual:0:0:0:-1:0:0:0:0 ./.:0,0,0:0:LowQual:0:0:0 ...; ^; offending line: chr1 152267996 DEL00028254 AATATATATACTTTACGTAAAGT A . PASS ...; see the Hail log for the full offending line. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 2.0 failed 4 times, most recent failure: Lost task 20.3 in stage 2.0 (TID 485, scc-q08.scc.bu.edu, executor 2): is.hail.utils.HailException: gcad.sv.delly.5k.vcf.bgz:column 80816: invalid character '-' in integer literal; ... 2:0:0:0:6 ./.:0,0,0:0:LowQual:0:0:0:-1:0:0:0:0 ./.:0,0,0:0:LowQual:0:0:0 ...; ^; offending line: chr1 152267996 DEL00028254 AATATATATACTTTACGTAAAGT A . PASS ...; see the Hail log for the full offending line; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:12); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:744); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); at is.hail.rvd.OrderedRVD$$anon$2.hasNext(OrderedRVD.scala:413); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(Order",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3379:2949,failure,failure,2949,https://hail.is,https://github.com/hail-is/hail/issues/3379,1,['failure'],['failure']
Availability,"e = True, center = True, normalize = True); bm_norm = BlockMatrix.read(out_dir + out_name + ""_norm"" + ""_bm""). # LD (unadjusted); starts_and_stops = hl.linalg.utils.locus_windows(mt.locus, radius = 2.1e6, _localize = False); bm_ld = (bm_norm @ bm_norm.T); bm_ld = BlockMatrix._from_java(bm_ld._jbm.filterRowIntervalsIR(Env.backend()._to_java_ir(starts_and_stops._ir), False)); bm_ld.write(out_dir + out_name + ""_LD"" + ""_bm"", overwrite = True); bm_ld = BlockMatrix.read(out_dir + out_name + ""_LD"" + ""_bm""). # Export LD matrices; list_range = [list(range(x.start_idx, x.end_idx + 1)) for x in list_meta[0:5]]; bms = [bm_ld.filter(x,x) for x in list_range]; hl.experimental.export_block_matrices(bms, out_dir + out_name + ""_tissue"" + ""_ld""). # Example image of problem:; <img width=""594"" alt=""Screen Shot 2019-06-13 at 5 36 58 PM"" src=""https://user-images.githubusercontent.com/24594616/59470325-52676800-8e05-11e9-93fe-e48c0e06e70b.png"">. If genotypes are normalized to N(0,1), then X @ X.T should never have values larger than 1 except for floating point precision. This is anecdotal, but I never had this problem when using > 100k samples, but here I'm using ~700 samples. I'm not sure what's causing this, but I had a conversation with @liameabbott a while ago about how one should normalize these matrices. His understanding was that hail normalizes by dividing by `sqrt(sum(x^2))` whereas one may prefer to divide `sd(x)`. The example he sent me to do this is below:. # Liam's example; g = BlockMatrix.read('gs://ukbb-ldsc-dev/1000_genomes.phase_3.europeans.GT.autosomes.bm'). n = g.shape[1]; m1 = g.sum(axis=1).cache(); m2 = (g**2).sum(axis=1).cache(). mean = m1 / n; stdev = ((m2-m1**2 / n) / (n-1)).sqrt(); g_std = ((g - mean) / stdev). g_std.write('gs://ukbb-ldsc-dev/1000_genomes.phase_3.europeans.GT_standardized.autosomes.bm', overwrite=True). I'll try this way of normalizing tomorrow to see if this is the root of the error and post back. Tagging @jbloom22 and @tpoterba 'cause why not :).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6351:2335,error,error,2335,https://hail.is,https://github.com/hail-is/hail/issues/6351,1,['error'],['error']
Availability,"e Hail 0.2.15, the memory in use by system processes on Dataproc driver nodes appears to have increased. Due to these two circumstances, the driver VM's memory usage can grow high enough to trigger the OOMKiller before the JVM triggers a GC. Consider, for example, these slices of the syslog of the n1-highmem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: All done; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. Notice:. 1. The total memory available on the machine is less than 52 GiB (= 53,248 MiB), indeed it is a full 1025 MiB below the advertised amount. 2. Once all the components of the Dataproc cluster have started (but before any Hail Query jobs are submitted) the total memory available is already depleted to 42760 MiB. Recall that Hail allocates 41 GiB (= 41,984 MiB) to its JVM. This leaves the Python process and all other daemons on the system only 776 MiB of excess RAM. For reference python3 -c 'import hail' needs 206 MiB. This PR modifies `hailctl dataproc start` and the meaning of `--master-memory-fraction`. Now, `--master-memory-fraction` is the precentage of the memory available to the master node after accounting for the missing 1GiB and the system daemons. We also increase the default memory fraction to 90%. For an n1-highmem-8, the driver has 36 GiB instead of 41 GiB. An n1-highmem-16 is unchanged at 83 GiB.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14066:2474,avail,available,2474,https://hail.is,https://github.com/hail-is/hail/pull/14066,3,['avail'],['available']
Availability,"e Windows PyPI builds.</li>; </ul>; <h2>3.9.15 - 2024-02-23</h2>; <h3>Fixed</h3>; <ul>; <li>Implement recursion limit of 1024 on <code>orjson.loads()</code>.</li>; <li>Use byte-exact read on <code>str</code> formatting SIMD path to avoid crash.</li>; </ul>; <h2>3.9.14 - 2024-02-14</h2>; <h3>Fixed</h3>; <ul>; <li>Fix crash serializing <code>str</code> introduced in 3.9.11.</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Build now depends on Rust 1.72 or later.</li>; </ul>; <h2>3.9.13 - 2024-02-03</h2>; <h3>Fixed</h3>; <ul>; <li>Serialization <code>str</code> escape uses only 128-bit SIMD.</li>; <li>Fix compatibility with CPython 3.13 alpha 3.</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Publish <code>musllinux_1_2</code> instead of <code>musllinux_1_1</code> wheels.</li>; <li>Serialization uses small integer optimization in CPython 3.12 or later.</li>; </ul>; <h2>3.9.12 - 2024-01-18</h2>; <h3>Changed</h3>; <ul>; <li>Update benchmarks in README.</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Minimal <code>musllinux_1_1</code> build due to sporadic CI failure.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/ijl/orjson/commit/11c7de8e5846fa65449aa1f6ffc05c5a1090df03""><code>11c7de8</code></a> 3.10.0</li>; <li><a href=""https://github.com/ijl/orjson/commit/1fc3ed80c24864607be709d29e0d5f47fc507626""><code>1fc3ed8</code></a> Support numpy.float16</li>; <li><a href=""https://github.com/ijl/orjson/commit/56c1a03216426c54dfbe9a4b6c3f70013c65a1f8""><code>56c1a03</code></a> cargo update, build misc</li>; <li><a href=""https://github.com/ijl/orjson/commit/a348f59f0b55d92a1364523560f52f5b3cf9c12a""><code>a348f59</code></a> 3.9.15</li>; <li><a href=""https://github.com/ijl/orjson/commit/b0e4d2c06ce06c6e63981bf0276e4b7c74e5845e""><code>b0e4d2c</code></a> yyjson 0eca326, recursion limit</li>; <li><a href=""https://github.com/ijl/orjson/commit/5067eadc84cf516e4eb33bcb09ad756bb59dc42e""><code>506",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14427:3112,failure,failure,3112,https://hail.is,https://github.com/hail-is/hail/pull/14427,1,['failure'],['failure']
Availability,"e a detour from adding job groups and get rid of how we currently do the batch update in MJC to allow for job groups in the future before putting in job groups tables so that I could slot in the appropriate state and time_completed updates to both batches and job_groups tables in the same place rather than relying on a trigger for the updates. I can think about which set of changes should go first (I'm not wedded to either PR coming first -- just thought this way was conceptually easier to understand when there was just a batches table). I haven't 100% convinced myself this change to tokenize the `batches_n_jobs_in_complete_states` table is absolutely necessary for nested job groups, but it seemed like we would want the performance improvements regardless. > 2. How come marking the batch as complete is moved into a separate transaction as marking the job complete? If it were in the same transaction wouldn't we not need this healing loop?. This is for performance reasons to avoid serialization and race conditions. If the update occurs in the same transaction, then each transaction will be serialized checking if `n_jobs == n_complete`. If we don't have a `SELECT ... FOR UPDATE`, I couldn't convince myself that there wouldn't be a race condition where a batch completion event isn't accidentally missed. . I think the healing loop would only happen if the batch driver got restarted in between:; 1. CALL mark_job_complete() in the database; 2. mark_batch_complete(). If 1. errors, the operation is aborted entirely. On second thought, it might be possible to use an optimistic locking strategy, but that's more complicated and I'd have to think about it some more. > It seems to me like it would be preferable to instead first update application code to mark the batch complete if it is not complete, then remove the now redundant marking complete of the batch from the trigger. Then there is no delay after the migration where batches are not complete for some time. Ah, good point!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13513#issuecomment-1701597732:3391,error,errors,3391,https://hail.is,https://github.com/hail-is/hail/pull/13513#issuecomment-1701597732,2,"['error', 'redundant']","['errors', 'redundant']"
Availability,"e an IR. This PR removes environment maintenance from the parser by deferring type annotation to a separate pass (which is simple, because it can use the Binds.scala infrastructure). One consequence is that we can't assign types to nodes like `Ref` during parsing, which means we can't ask for the type of any node during parsing, and by extension we can't ask for types of children in IR node constructors. Instead, all typechecking logic is moved to the `TypeCheck` pass. Some benefits of this change:; * The parser is simpler, as it doesn't have to maintain a typing environment.; * Binds.scala is now the single source of truth on the binding structure of the IR.; * Instead of typechecking being split in an ad-hoc way between IR constructors and the `TypeCheck` pass, all typechecking and type error reporting logic is in one place.; * The parser parses a context-free grammar, no more and no less. If the input is gramatically correct, the parser succeeds.; * We can round trip IR with type errors through the text representation. For instance, if we log an IR that fails TypeCheck, we can copy the IR from the log, parse it, then debug. This change was motivated by my work in progress to convert the parser to use the SSA grammar, which this should greatly simplify. I chose to make the type annotation pass after parsing mutate the IR in place (with the unfortunate exception of `Apply`, which can change into an `ApplyIR` or `ApplySpecial`. Do these really need to be separate nodes?). The type of a `Ref` node was already mutable to allow this sort of deferred annotation, and I've had to make a few other things mutable as well. Alternatively we could rebuild the entire IR to include type annotations, but I think the mutation is sufficiently well localized, and this is a common compiler pattern. This touches a lot of lines, but the high level changes are:; * Remove the `refMap` from the `IRParserEnvironment`, and remove all code that modifies the typing environment from the parser",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13990:1300,error,errors,1300,https://hail.is,https://github.com/hail-is/hail/pull/13990,1,['error'],['errors']
Availability,"e broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {""name"":""BlockingBufferSpec"",""blockSize"":65536,""child"":; {""name"":""ZstdBlockBufferSpec"",""blockSize"":65536,""child"":; {""name"":""StreamBlockBufferSpec""}}}}; ```; Error for run 1.; ```; Caused by: com.github.luben.zstd.ZstdException: Corrupted block detected; 	at com.github.luben.zstd.ZstdDecompressCtx.decompressByteArray(ZstdDecompressCtx.java:157) ~[zstd-jni-1.5.2-1.jar:1.5.2-1]; 	at is.hail.io.ZstdInputBlockBuffer.readBlock(InputBuffers.scala:655) ~[gs:__hail-query-ger0g_jars_fcaafc533ec130ae210b152afa81c0b5ac04592b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.BlockingInputBuffer.ensure(InputBuffers.scala:385) ~[gs:__hail-query-ger0g_jars_fcaafc533ec130ae210b152afa81c0b5ac04592b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.BlockingInputBuffer.readByte(InputBuffers.scala:403) ~[gs:__hail-query-ger0g_jars_fcaafc533ec130ae210b152afa81c0b5ac0",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:2157,Error,Error,2157,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623,1,['Error'],['Error']
Availability,"e copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input transfers and recorded the results. These are then tested on every pair of file systems: file to file, file to gs, gs to file, etc. To make this run reasonably, I parallelize using xdist and the full tests (1364 tests) now take about 2 minutes. (If you restrict to the just the local filesystem, the tests just take a couple seconds.) The second test verifies that all cases run without unexpected errors, and that the behavior is file system independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9822:2252,error,errors,2252,https://hail.is,https://github.com/hail-is/hail/pull/9822,2,['error'],['errors']
Availability,"e creation and cleanup in Pod.run and Container.run.; - worker: Just support pods/status and pods/log, not container level status or logs.; - Pod now writes final status, not containers. Individual containers write their logs.; - I time all the steps of the Pod container (creating, starting, running, uploading log, etc.) with a timing called ""runtime"" which is how long the docker container itself took to start/run. That's usually 4-6 seconds. However, if you log into a machine and run `docker run --rm ubuntu:18.04 echo hi` it takes 1-2 seconds. It would be good to find out where the extra 3-4 seconds are coming from (I feel like @jigold might have some insight into this. Comparing our container config to the docker command line's might be useful here.); - Stop using (value, err) style exception handling. I think we should be able to design this with very little explicit exception handling, mainly in critical blocks to maintain the program invariants.; - Pods can have error status in 1 of 3 ways: the pod itself failed (e.g. couldn't read k8s secrets), one of the pod containers error out (e.g. pull failed due to invalid image), and the docker container finished but the final container status had an ""Error"" field. Next step is to remove pods and merge the pod and job tables. ```; {; ""name"": ""batch-2-job-1"",; ""batch_id"": 2,; ""job_id"": 1,; ""user"": ""test"",; ""state"": ""succeeded"",; ""container_statuses"": {; ""setup"": {; ""name"": ""setup"",; ""state"": ""succeeded"",; ""timing"": {; ""pulling"": 0.038861751556396484,; ""creating"": 0.7245609760284424,; ""starting"": 4.770207166671753,; ""running"": 1.1384251117706299,; ""runtime"": 5.909235715866089,; ""uploading_log"": 0.3659687042236328,; ""deleting"": 0.013197660446166992; },; ""container_status"": {; ""state"": ""exited"",; ""started_at"": ""2019-10-22T09:25:42.477556224Z"",; ""finished_at"": ""2019-10-22T09:25:42.476019599Z"",; ""exit_code"": 0; }; },; ""main"": {; ""name"": ""main"",; ""state"": ""succeeded"",; ""timing"": {; ""pulling"": 0.031185626983642578,; ""creating"":",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7354:1638,error,error,1638,https://hail.is,https://github.com/hail-is/hail/pull/7354,1,['error'],['error']
Availability,"e full java stack trace): ; When exporting vcf to path that begins with 'file://', I get the error: `ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found`. I am using Spark 2.2.1 (prebuilt with hadoop2.7) with AWS-Hadoop 2.7.4. I have the following settings in spark config and am using a custom directParquetOutputCommitter. Standard writes to 'file://' of Spark dataframes work without issue. Thanks for any help!. ```; spark.sql.parquet.output.committer.class org.apache.spark.sql.parquet.DirectParquetOutputCommitter; spark.hadoop.mapred.output.committer.class org.apache.hadoop.mapred.DirectFileOutputCommitter; spark.hadoop.mapreduce.use.directfileoutputcommitter true; spark.hadoop.spark.sql.parquet.output.committer.class org.apache.spark.sql.parquet.DirectParquetOutputCommitter; ```. Code and stack trace:; ```; ================================================================================================== FAILURES ===================================================================================================; __________________________________________________________________________________________ TestHAIL.test_export_vcf ___________________________________________________________________________________________. self = <test_hail.TestHAIL testMethod=test_export_vcf>. def test_export_vcf(self):; # define files; bgen_file = os.path.join(self.testdir, 'example.10bits.bgen'); sample_file = os.path.join(self.testdir, 'example.sample'); # make index; self.hc.index_bgen(bgen_file); # load to vds; bgen_vds = self.hc.import_bgen(bgen_file, sample_file=sample_file); # export vcf; out_path = 'file://' + os.path.join(self.tmpdir, 'test_vcf_export.vcf.bgz'); > bgen_vds.export_vcf(out_path, export_pp=False, parallel=False). tests/hail/test_hail.py:55:; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3946:1104,FAILURE,FAILURES,1104,https://hail.is,https://github.com/hail-is/hail/issues/3946,1,['FAILURE'],['FAILURES']
Availability,"e handled exactly as described in input/output dependencies above.; - [ ] allow ""finalizer"" jobs. A finalizer job executes when its parents are all complete or cancelled. It is not cancelled when its parents are cancelled.; - [ ] add namespace dependencies. CI allocates anonymous namespaces as requested by the build process. All `exec`s are, by default, run in an anonymous namespace. CI adds a finalizer job that deletes namespaces when all relevant `exec`s are finished; - [ ] add image dependencies. CI can create a batch job that builds a docker image with an anonymous name and pushes it to the project's GCR. CI adds a finalizer job that deletes the image when all relevant `exec`s are finished.; - [ ] batch and notebook are parameterized by their worker namespace so they can use the namespaces described above; - [ ] hail's build steps are parameterized in a way that permits them to use a jar not built locally on this machine (hopefully the Make PR makes this easy, otherwise we have to fool gradle into not rebuilding the jar). To reliably handle clean up, we *must* persist batch jobs, so I think that should be either higher priority or at least happening in parallel to the above (i.e. two developers working in parallel). - [ ] persist batch jobs in a durable store with all of the fields in the beginning of `Job.__init__`. When batch starts up, before serving any requests, it restores its state from the durable store and then refreshes from k8s. The k8s label `hail.is/batch-instance` is retired. Instead, pods have `hail.is/batch-version` which is a monotonically increasing natural number. It is only incremented if batch is backwards incompatible with the pod specs. Probably batch should destroy any pods that are alive from an out-of-date version of batch.; - [ ] persist CI information in a durable store [this needs more detail]; - [ ] How do we configure the database? How do we create new tables? Should this be done in the applications themselves or during deployment?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5193:2864,reliab,reliably,2864,https://hail.is,https://github.com/hail-is/hail/issues/5193,2,"['alive', 'reliab']","['alive', 'reliably']"
Availability,"e information, describing how the alternate alleles are phased in relation to one another"">; ##FORMAT=<ID=PID,Number=1,Type=String,Description=""Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group"">; ##FORMAT=<ID=RGQ,Number=1,Type=Integer,Description=""Unconditional reference genotype confidence, encoded as a phred quality -10*log10 p(genotype call is wrong)"">; ##FORMAT=<ID=SB,Number=4,Type=Integer,Description=""Per-sample component statistics which comprise the Fisher's Exact Test to detect strand bias."">; ##GATKCommandLine=<ID=GenotypeGVCFs,CommandLine=""GenotypeGVCFs --output 3P5CH.new.vcf --use-new-qual-calculator true --annotation-group StandardAnnotation --annotation-group StandardHCAnnotation --dbsnp /home/fgc3/dbsnp/150/GRCh38/All_20170710.vcf.gz --variant 3P5CH.new.g.vcf.gz --reference /home/fgc3/10x/refdata-GRCh38-2.1.0/fasta/genome.fa --create-output-variant-index false --verbosity ERROR --annotate-with-num-discovered-alleles false --heterozygosity 0.001 --indel-heterozygosity 1.25E-4 --heterozygosity-stdev 0.01 --standard-min-confidence-threshold-for-calling 10.0 --max-alternate-alleles 6 --max-genotype-count 1024 --sample-ploidy 2 --disable-tool-default-annotations false --only-output-calls-starting-in-intervals false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --help false --version false --showHidden false --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --disable-tool-default-rea",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:23292,ERROR,ERROR,23292,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['ERROR'],['ERROR']
Availability,"e may be to increase `read_timeout` past 120 seconds, although depending on the causes of this issue, that may not eliminate the problem, and of course leaves a long delay, which may be unacceptable for the use-case. As for why read takes so long: not 100% sure yet, setting up batch and CI is still incomplete, and I have not triggered this error myself. My guess is that Kubernetes takes too long to generate the response, either due to garbage collection, or simply because the requested information takes N > 120 seconds to return. That would be a very long time for any reasonable response, so either the resource isn't ready and it waits, or there are network connectivity issues. If network issues, not sure what solutions are. If I were on AWS, I would think about using a larger instance, with a higher-bandwidth NIC.; * Possible connection: https://github.com/arangodb/arangodb/issues/7813 ; * Possible solution: Reduce work Kubernetes must do to return response. #### 2nd set of errors:; ```log; # Batch; ERROR	| 2018-12-18 21:25:00,095 	| server.py 	| run_forever:447 | run_forever: target kube_event_loop threw exception; Traceback (most recent call last):; File ""/usr/lib/python3.6/site-packages/urllib3/response.py"", line 601, in _update_chunk_length; self.chunk_left = int(line, 16); ValueError: invalid literal for int() with base 16: b''. # CI; ERROR	| 2018-12-18 21:25:22,041 	| app.py 	| log_exception:1761 | Exception on /refresh_batch_state [POST]; Traceback (most recent call last):; ...; File ""/home/hail-ci/.local/lib/python3.7/site-packages/batch/requests_helper.py"", line 11, in raise_on_failure; response=response; requests.exceptions.HTTPError: 500 Server Error for url http://batch.default/jobs. <!DOCTYPE HTML PUBLIC ""-//W3C//DTD HTML 3.2 Final//EN"">; <title>500 Internal Server Error</title>; ```; Initiator seems; https://github.com/datawire/ambassador/issues/554. Solution may be to catch and re-connect to Kubernetes; https://github.com/datawire/ambassador/pull/724",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4984#issuecomment-450444389:2097,error,errors,2097,https://hail.is,https://github.com/hail-is/hail/issues/4984#issuecomment-450444389,6,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'errors']"
Availability,"e pyzmq 25.1.2.; aiohttp-devtools 1.1 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;) <br/>[SNYK-PYTHON-AIOHTTP-6209406](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209406) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **718/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-6209407](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209407) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhZDFmMzFlYi1hYTcyLTQyMTYtOTgzNC01MDljMDdhOWFmNT",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14227:1696,avail,available,1696,https://hail.is,https://github.com/hail-is/hail/pull/14227,1,['avail'],['available']
Availability,"e reasons the line numbers reported in CI log don't quite match up (using either IntelliJ's goto def - which could say be the result of referencing a different copy on the system - or the [2.7.1 branch on GitHub](https://github.com/apache/hadoop/blob/branch-2.7.1/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java)), so I followed the parameterization. Still need to figure out why lines reported don't match, but I've seen line number differences before between that reported for the compiled binary, and the uncompiled source. Lines of evidence:; 1) The line specified in the ci log suggests that Hadoop's fileSystem.open() command fails. It appears from examining the line and source, that the Hadoop Configuration object could be null, which suggests a serialization error in HadoopFS. However, there are many others tests that by touch HadoopFS serialization, and none of them have problems. If it's not a serialization error (say the URI object that hadoop looks for is null, or CACHE is null), it would not seem PR specific. 2) On local, with or without the google storage connector, I cannot replicate the error in cluster-read-vcfs.py. Attempts to replicate:; 1) Local hail install, not using google storage connector, and reading 2 local vcfs:. ```python; gvcfs = ['./HG00096.g.vcf.gz',; './HG00268.g.vcf.gz']; hl.init(default_reference='GRCh38'); parts = [; {'start': {'locus': {'contig': 'chr20', 'position': 17821257}},; 'end': {'locus': {'contig': 'chr20', 'position': 18708366}},; 'includeStart': True,; 'includeEnd': True},; {'start': {'locus': {'contig': 'chr20', 'position': 18708367}},; 'end': {'locus': {'contig': 'chr20', 'position': 19776611}},; 'includeStart': True,; 'includeEnd': True},; {'start': {'locus': {'contig': 'chr20', 'position': 19776612}},; 'end': {'locus': {'contig': 'chr20', 'position': 21144633}},; 'includeStart': True,; 'includeEnd': True},; ]; parts_str = json.dumps(parts); vcfs = hl.import_vcfs(gvcfs, parts_str). ## W",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6083#issuecomment-494037803:2212,error,error,2212,https://hail.is,https://github.com/hail-is/hail/pull/6083#issuecomment-494037803,1,['error'],['error']
Availability,"e retention was set so using the default time retention"" duration=15d; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:322 msg=""Starting Prometheus"" version=""(version=2.10.0, branch=HEAD, revision=d20e84d0fb64aff2f62a977adc8cfb656da4e286)""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:323 build_context=""(go=go1.12.5, user=root@a49185acd9b0, date=20190525-12:28:13)""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:324 host_details=""(Linux 4.14.127+ #1 SMP Tue Jun 18 18:32:10 PDT 2019 x86_64 prometheus-0 (none))""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:325 fd_limits=""(soft=1048576, hard=1048576)""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:326 vm_limits=""(soft=unlimited, hard=unlimited)""; level=info ts=2019-07-31T15:45:51.993Z caller=main.go:645 msg=""Starting TSDB ...""; level=info ts=2019-07-31T15:45:51.994Z caller=web.go:417 component=web msg=""Start listening for connections"" address=0.0.0.0:9090; level=info ts=2019-07-31T15:45:51.996Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563105600000 maxt=1563170400000 ulid=01DFTDRJHCX1S9B0KPJTG8CRGW; level=info ts=2019-07-31T15:45:51.997Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563170400000 maxt=1563235200000 ulid=01DFWBK0336Z71ZCRRKS79T18P; level=info ts=2019-07-31T15:45:51.997Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563235200000 maxt=1563300000000 ulid=01DFY9C92NRA1S7FDVHFRFMFPF; level=info ts=2019-07-31T15:45:51.998Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563300000000 maxt=1563364800000 ulid=01DG075GN2MME91GM1DA5G3H07; level=info ts=2019-07-31T15:45:51.999Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563364800000 maxt=1563429600000 ulid=01DG24Z1SDJ7VXW96YYSY1FC8Y; level=info ts=2019-07-31T15:45:51.999Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563429600000 maxt=1563494400000 ulid=01DG42SDMFEK1AJPRJ5YWKZFJ8; level=info ts=2019",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6773:3401,repair,repair,3401,https://hail.is,https://github.com/hail-is/hail/issues/6773,1,['repair'],['repair']
Availability,"e script successfully downloaded and installed the various Java dependencies, but gcc chokes on the C source code. I get:; $ ./gradlew shadowJar; :compileJava UP-TO-DATE; :nativeLib; (cd libsimdpp-2.0-rc2 && cmake .); -- Configuring done; -- Generating done; -- Build files have been written to: /home/rmk/package_sources/hail/hail/src/main/c/libsimdpp-2.0-rc2; mkdir -p lib/linux-x86-64; g++ -fvisibility=hidden -rdynamic -shared -fPIC -ggdb -O3 -march=native -g -std=c++11 -Ilibsimdpp-2.0-rc2 -Wall -Werror ibs.cpp -o lib/linux-x86-64/libibs.so; In file included from ibs.cpp:1:0:; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h: In function â€˜uint64_t vector_popcnt(uint64vector)â€™:; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h:42:1: error: inlining failed in call to always_inline â€˜long long int _mm_popcnt_u64(long long unsigned int)â€™: target specific option mismatch; _mm_popcnt_u64 (unsigned long long __X); ^; ibs.cpp:14:48: error: called from here; uint64_t count = _mm_popcnt_u64(extract<0>(x));; ^; In file included from ibs.cpp:1:0:; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h:42:1: error: inlining failed in call to always_inline â€˜long long int _mm_popcnt_u64(long long unsigned int)â€™: target specific option mismatch; _mm_popcnt_u64 (unsigned long long __X); ^; ibs.cpp:16:41: error: called from here; count += _mm_popcnt_u64(extract<1>(x));; ^; make: *** [lib/linux-x86-64/libibs.so] Error 1; Makefile:52: recipe for target 'lib/linux-x86-64/libibs.so' failed; :nativeLib FAILED. Tim Poterba suggested defining `CXXFLAGS='-DHAIL_OVERRIDE_ARCH -DSIMDPP_ARCH_X86_SSE2'`, but to no avail. So, he suggested I open this issue. I'm running gcc version 4.9.2. Possibly relevant might be the processor I'm running,; $ lscpu; Architecture: x86_64; CPU op-mode(s): 32-bit, 64-bit; Byte Order: Little Endian; CPU(s): 2; On-line CPU(s) list: 0,1; Thread(s) per core: 1; Core(s) per socket: 2; Socket(s): 1; NUMA node(s): 1; Vendor ID: GenuineIntel; CPU family: 6",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1520:1108,error,error,1108,https://hail.is,https://github.com/hail-is/hail/issues/1520,1,['error'],['error']
Availability,"e should load the; class?). Every `ClassLoader` has a `parent` `ClassLoader`. The default implementation of `loadClass` and; `getResource` prefers loading classes from its parent ClassLoader before anything else. We invert; the loading order to allow multiple definitions of the same Class in the same JVM. In particular,; each instance of `LoadSelfFirstURLClassLoader` prefers to use its own definition of a Class. Each; `LoadSelfFirstURLClassLoader` instance knows about one version of the Hail JAR. The remaining subtle issue is how to load resources. For example, `HailBuildInfo` needs to load the; build info resource file. To do so, you need an instance of a `ClassLoader` that can find the; file you want. Often times, you use `this.getClass().getClassLoader()`, which is the class loader; used to load the current class. Hail does not do this. I believe we do not do this because of issues; with how TestNG loads classes. :sigh: As a result, I also modify the worker Thread's; ContextClassLoader for the duration of the execution of an alternative version of Hail. ---. I've already updated the cluster with the new bucket and the corresponding change to the; `global-config` secret. We'll should notify Leo et al. about the Terraform changes. ---. Small changes and fixes:. - Rename `key.json` to `/worker-key.json` for clarity, this is the worker's own GCP service account; key.; - Create a test query-gsa-key in test and dev namespaces.; - Add terraform rules for the query service account. It already existed, but it was missing from the; Terraform file. You can verify the permissions grant by inspecting `gsutil iam get; gs://hail-query`.; - The `query` user was missing from bootstrap-create-accounts.; - `hail-ubuntu-stmp` was missing from `docker/Makefile`'s `clean` rule; - Use a dummy `WorkerBackend` when we're on the worker. The worker isn't allowed to call these; methods anyway, that would amount to Hail Queries inside of Hail Queries, madness!; - New transient error in Java.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10279:2980,error,error,2980,https://hail.is,https://github.com/hail-is/hail/pull/10279,1,['error'],['error']
Availability,"e vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/requirements.txt. <details>; <summary>âš ï¸ <b>Warning</b></summary>. ```; sphinx 5.3.0 has requirement docutils<0.20,>=0.14, but you have docutils 0.20.1.; sphinx-rtd-theme 1.3.0 has requirement docutils<0.19, but you have docutils 0.20.1.; notebook 6.5.6 has requirement pyzmq<25,>=17, but you have pyzmq 25.1.1. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14026:1174,avail,available,1174,https://hail.is,https://github.com/hail-is/hail/pull/14026,1,['avail'],['available']
Availability,"e {worker_machine_type}; --region {region}; --project {gcs_project}; --service-account {account}; --num-master-local-ssds 1; --num-worker-local-ssds 1 ; --max-idle=60m; --max-age=1440m; --subnet=projects/{gcs_project}/regions/{region}/subnetworks/subnetwork; {cluster_name}; ```. </details>. I have the driver node syslogs as well as the Hail log file. For some reason all logs other than the Hail logs are missing from this file. We separately need to determine why all the Spark logs etc. are missing. Based on the syslog, after system start up and just before the Jupyter notebook starts, the system is already using ~8,500MiB:; ```; Nov 22 14:29:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43808 of 52223 MiB (83.89%), swap free: 0 of 0 MiB ( 0.00%); ```; So, the effective maximum memory that Hail could possibly use is around 43808MiB. After the Notebook and Spark initialize we're down to 42,700 MiB (about ~1000MiB more in use).; ```; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. `hailctl` sets the VM RAM limit to 80% of the instance type's memory, so 80% * 52GiB = 42598MiB. This means the JVM is permitted to effectively use all the remaining memory. At time of sigkill the total memory allocated by the JVM was about 2000MiB below the max heap size. Note that the heap is contained within all memory allocated by the JVM.; ```; Nov 22 15:31:05 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43 of 52223 MiB ( 0.08%), swap free: 0 of 0 MiB ( 0.00%); Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: low memory! at or below SIGTERM limits: mem 0.12%, swap 1.00%; Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM to process 8421 uid 0 ""java"": badness 1852, VmRSS 40578 MiB; ```. Indeed, the VmRSS is the memory in use from the kernel's perspective so it includes any off-heap memory created by Hail. The Hail log indicates the region pools ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419:1512,avail,avail,1512,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419,1,['avail'],['avail']
Availability,"e"",""from"":""0.8.4"",""to"":""2.0.3""},{""name"":""nbconvert"",""from"":""5.6.1"",""to"":""6.3.0b0""},{""name"":""notebook"",""from"":""5.7.16"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,624,531,604,589,726,434,589,449,696,589,479,519,509,711,701,586,586,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. ðŸ¦‰ [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); ðŸ¦‰ [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); ðŸ¦‰ [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); ðŸ¦‰ [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:12316,avail,available,12316,https://hail.is,https://github.com/hail-is/hail/pull/13717,1,['avail'],['available']
Availability,"e(mt_ld_fn); print(mt.count()); print(""running omit filter""); mt=mt.annotate_cols(pheno = table[mt.s]); mt = mt.filter_cols(mt.pheno.omit == 0); print(mt.count()); print(""running pc_relate""); pc_rel = hl.pc_relate(mt.GT, 0.01, k=10, statistics='kin',min_kinship=0.0883); pairs = pc_rel.filter(pc_rel['kin'] >= 0.0883); print(""finding Max ind set""); related_samples_to_remove = hl.maximal_independent_set(pairs.i, pairs.j,keep=False); print(""writing related samples to remove""); related_samples_to_remove.export(""file:////restricted/projectnb/adgc/topmed.r2.analysis/pc_relate/related_samples_""+pop+"".tsv""); result = mt.filter_cols(; hl.is_defined(related_samples_to_remove[mt.col_key]), keep=False); print(""final unrelated count""); print(result.count); eigenvalues, scores, loadings = hl.hwe_normalized_pca(result.GT, k=10); scores.export('file:////restricted/projectnb/adgc/topmed.r2.analysis/pc_relate/unrelated_pcs_'+pop+'.tsv'). ```. ```; Running on Apache Spark version 2.4.3; SparkUI available at http://scc-hadoop.bu.edu:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.46-6ef64c08b000; LOGGING: writing to logs/adgc_pc_relate.autosome_all.log; 2020-08-20 10:14:00 Hail: INFO: Reading table to impute column types; [Stage 0:===========================================================(1 + 0) / 1]2020-08-20 10:14:07 Hail: INFO: Loading 76 fields. Counts by type:; 66 fields: user-specified int32; 6 fields: user-specified str; 3 fields: user-specified float64; 1 field: imputed int32; (63110, 64048); running omit filter; [Stage 1:> (0 + 1) / 1](63110, 52877); running pc_relate; [Stage 3:==================================================>(12794 + 2) / 12796]2020-08-20 10:14:38 Hail: INFO: hwe_normalized_pca: running PCA using 63110 variants.; [Stage 5:==================================================>(12795 + 1) / 12796]2020-08-20 10:14:59 Hail: INFO: pca: running PCA with 10 components...; [Stage 102:========================================",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403:4103,avail,available,4103,https://hail.is,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403,1,['avail'],['available']
Availability,"e):; """"""Converts an answer received from the Java gateway into a Python object.; ; For example, string representation of integers are converted to Python; integer, string representation of objects are converted to JavaObject; instances, etc.; ; :param answer: the string returned by the Java gateway; :param gateway_client: the gateway client used to communicate with the Java; Gateway. Only necessary if the answer is a reference (e.g., object,; list, map); :param target_id: the name of the object from which the answer comes from; (e.g., *object1* in `object1.hello()`). Optional.; :param name: the name of the member from which the answer comes from; (e.g., *hello* in `object1.hello()`). Optional.; """"""; if is_error(answer)[0]:; if len(answer) > 1:; type = answer[1]; value = OUTPUT_CONVERTER[type](answer[2:], gateway_client); if answer[1] == REFERENCE_TYPE:; raise Py4JJavaError(; ""An error occurred while calling {0}{1}{2}.\n"".; format(target_id, ""."", name), value); else:; raise Py4JError(; ""An error occurred while calling {0}{1}{2}. Trace:\n{3}\n"".; > format(target_id, ""."", name, value)); E py4j.protocol.Py4JError: An error occurred while calling z:is.hail.HailContext.apply. Trace:; E py4j.Py4JException: Method apply([null, class java.lang.String, class scala.Some, class java.lang.String, class java.lang.String, class java.lang.Boolean, class java.lang.Boolean, class java.lang.Integer, class java.lang.Integer, class java.lang.String, class java.lang.Integer]) does not exist; E 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); E 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:339); E 	at py4j.Gateway.invoke(Gateway.java:276); E 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); E 	at py4j.commands.CallCommand.execute(CallCommand.java:79); E 	at py4j.GatewayConnection.run(GatewayConnection.java:238); E 	at java.lang.Thread.run(Thread.java:748). /miniconda3/envs/hail/lib/python3.6/site-packages/py4j/protoc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5878#issuecomment-484651928:3982,error,error,3982,https://hail.is,https://github.com/hail-is/hail/pull/5878#issuecomment-484651928,1,['error'],['error']
Availability,"e, GRCh37). hl.eval(hl.liftover(hl.locus('chr1', 1034245, 'GRCh38'), 'GRCh37')); # Locus(contig=1, position=969625, reference_genome=GRCh37); ```. However, when trying to lift over the entire table it fails:; ```; ht = ht.annotate(; locus_GRCh37 = hl.liftover(ht.locus, 'GRCh37'); ); ht.show(); ```. I got the same error when trying to lift over an older gnomAD version (2.1) from GRCh37 to GRCh38, which used to work according to my best knowledge. Also, this way of lifting over a hail table is following the recommended process on the documentation [here](https://hail.is/docs/0.2/guides/genetics.html?highlight=prs#liftover-variants-from-one-coordinate-system-to-another). I'm quite confident there must be something I'm doing wrong, but now I'm stuck, any help would be highly welcome. Thanks!. The code is running on a Google Cloud Dataproc cluster, Python 3.8, hail version: `'0.2.71-f3a54b530979'`. Error stack:; ```python; --------------------------------------------------------------------------- / 1]; FatalError Traceback (most recent call last); /opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj); 700 type_pprinters=self.type_printers,; 701 deferred_pprinters=self.deferred_printers); --> 702 printer.pretty(obj); 703 printer.flush(); 704 return stream.getvalue(). /opt/conda/miniconda3/lib/python3.8/site-packages/IPython/lib/pretty.py in pretty(self, obj); 392 if cls is not object \; 393 and callable(cls.__dict__.get('__repr__')):; --> 394 return _repr_pprint(obj, self, cycle); 395; 396 return _default_pprint(obj, self, cycle). /opt/conda/miniconda3/lib/python3.8/site-packages/IPython/lib/pretty.py in _repr_pprint(obj, p, cycle); 698 """"""A pprint that just redirects to the normal repr function.""""""; 699 # Find newlines and replace them with p.break_(); --> 700 output = repr(obj); 701 lines = output.splitlines(); 702 with p.group():. /opt/conda/miniconda3/lib/python3.8/site-packages/hail/table.py in __repr__(self); 1295; 1296",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:1380,Error,Error,1380,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['Error'],['Error']
Availability,"e-account; --key-file=/gsa-key/privateKeyData)) && gsutil -m cp -R /io/pipeline/pipeline-1cac3dd4e66d/__TASK__286/8926feac; gs://hail-wang-ukps2/pipeline/pipeline-1cac3dd4e66d/__TASK__286/8926feac; image: gcr.io/hail-vdc/batch:s32fqwbuz8nv; imagePullPolicy: IfNotPresent; name: cleanup; ports:; - containerPort: 5000; protocol: TCP; resources:; requests:; cpu: 500m; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /batch-gsa-key; name: batch-gsa-key; - mountPath: /gsa-key; name: gsa-key; - mountPath: /io; name: batch-12728-job-287-742170; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: batch-output-pod-token-8pkmz; readOnly: true; - command:; - /bin/sh; - -c; - ""\n set -ex\n python3 -m batch.keep_alive_sidecar\n ""; image: gcr.io/hail-vdc/batch:s32fqwbuz8nv; imagePullPolicy: IfNotPresent; name: keep-alive; ports:; - containerPort: 5001; protocol: TCP; resources:; requests:; cpu: 1m; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /gsa-key; name: gsa-key; - mountPath: /io; name: batch-12728-job-287-742170; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: batch-output-pod-token-8pkmz; readOnly: true; dnsPolicy: ClusterFirst; enableServiceLinks: true; initContainers:; - command:; - /bin/sh; - -c; - ""\n set -ex\n (gcloud -q auth activate-service-account --key-file=/batch-gsa-key/privateKeyData; || (sleep $(( 5 + (RANDOM % 5) )); gcloud -q auth activate-service-account --key-file=/batch-gsa-key/privateKeyData))\n; \ gsutil -q stat gs://hail-batch-3jmp5/cd50b95a89914efb897965a5e982a29d/12728/287/742170/container_logs; && exit 1\n rm -rf /io/*\n set -ex; (gcloud -q auth activate-service-account; --key-file=/gsa-key/privateKeyData || (sleep $(( 5 + (RANDOM % 5) )); gcloud; -q auth activate-service-account --key-file=/gsa-key/privateKeyData)) && mkdir; -p /io/pipeline/pipeline-1cac3dd4e66d/__TASK__0; gsutil -m cp -R gs://hail-wang-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7016:7655,alive,alive,7655,https://hail.is,https://github.com/hail-is/hail/issues/7016,1,['alive'],['alive']
Availability,"e-packages/hail/backend/spark_backend.py in persist_table(self, t, storage_level); 283 ; 284 def persist_table(self, t, storage_level):; --> 285 return Table._from_java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); 286 ; 287 def unpersist_table(self, t):. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:7510,error,error,7510,https://hail.is,https://github.com/hail-is/hail/issues/9939,1,['error'],['error']
Availability,"e. session, packages, modules, classes, functions) and allows tests to be run in those loops when marked accordingly. Pytest-asyncio currently assumes that async fixture scope is correlated with the new event loop scope. This prevents fixtures from being evaluated independently from the event loop scope and breaks some existing test suites (see <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/706"">#706</a>). For example, a test suite may require all fixtures and tests to run in the same event loop, but have async fixtures that are set up and torn down for each module. If you're affected by this issue, please continue using the v0.21 release, until it is resolved.</p>; <h2>pytest-asyncio 0.23.4</h2>; <h1>0.23.4 (2024-01-28)</h1>; <ul>; <li>pytest-asyncio no longer imports additional, unrelated packages during test collection <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/729"">#729</a></li>; <li>Addresses further issues that caused an internal pytest error during test collection</li>; <li>Declares incompatibility with pytest 8 <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/737"">#737</a></li>; </ul>; <h2>pytest-asyncio 0.23.4a2</h2>; <h1>0.23.4 (UNRELEASED)</h1>; <ul>; <li>pytest-asyncio no longer imports additional, unrelated packages during test collection <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/729"">#729</a></li>; <li>Addresses further issues that caused an internal pytest error during test collection</li>; </ul>; <h2>Known issues</h2>; <p>As of v0.23, pytest-asyncio attaches an asyncio event loop to each item of the test suite (i.e. session, packages, modules, classes, functions) and allows tests to be run in those loops when marked accordingly. Pytest-asyncio currently assumes that async fixture scope is correlated with the new event loop scope. This prevents fixtures from being evaluated independently from the event loop scope and breaks some existing test suites (see ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14507:5515,error,error,5515,https://hail.is,https://github.com/hail-is/hail/pull/14507,1,['error'],['error']
Availability,"e. | version | cold | warm |; | --- | --- | --- |; | this PR | 48 | 39.35 |; | this PR with one monolithic method | 235 | 73 |; | master (5fe6737263b4) | 91s | 83.5 |. I was disappointed with the performance of the monolithic method, so I dug in with `-XX:+PrintCompilation` and found that the JIT was having trouble doing on-stack replacement of the entry parsing loop. There was a cryptic message about the stack not being empty during an OSR compilation. I take this result as evidence that, in the JVM, small, fine-grained methods are critical for reliable performance. The new code, after JIT warming, is reading at 250 MB/s (1GB / 40 seconds) which is a half to a third of the performance of `cat`. It's more than twice as fast as the old code. Aside: using the staged stuff is hard, especially when using multiple methods. A couple thoughts:; - Because SRVB generates a fresh SRVB for arrays and structs, you must thread the srvb through your code gen rather than using a single field, this is annoying and error prone; - `init` is not a first class thing in `FunctionBuilder` and I've arguably made the whole situation more ugly by exposing `addInitInstructions`. Without the ability to place code in the constructor, it is hard to coordinate work between multiple methods.; - When using lots of methods, there's a lot of bookkeeping. I would like a way to define a ""staged class"" that wraps up some of the boilerplate. Not totally clear what I want here, just less boilerplate. Aside2: This is still pretty slow!? Splitting into multiple methods allowed me to interrogate where time was spent. The answer is ""method4"" which is `parseEntries`. This code includes the loop, the srvb state management, the Region manipulation, and checking for the missing value. I'd be surprised its the checking for missing value because I delegate to `String.regionMatches` for the heavy lifting and that does not show up in the profiler. I'm left to conclude that either srvb state management or writing/rea",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6987:2261,error,error,2261,https://hail.is,https://github.com/hail-is/hail/pull/6987,1,['error'],['error']
Availability,e.g. https://ci.hail.is/repository/download/HailSourceCode_HailMainline_BuildDocsSpark220/55915:id/www/index.html,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2878:35,down,download,35,https://hail.is,https://github.com/hail-is/hail/issues/2878,1,['down'],['download']
Availability,"e.g.; ```; # cat Makefile; foo:; 	echo '[ \; hello \; '; # make foo; echo '[ \; hello \; '; [ hello ; ```. If you create such a Makefile and run Make do you see `[ hello ` echo'd or do you see something else, possibly including newlines?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14138#issuecomment-1889782238:34,echo,echo,34,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1889782238,3,['echo'],['echo']
Availability,e.parseAddInfoField(LoadVCF.scala:1055); 	at is.hail.io.vcf.VCFLine.addInfoField(LoadVCF.scala:1075); 	at is.hail.io.vcf.VCFLine.parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7$adapted(LoadVCF.scala:1909); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:515); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at __C678stream_Let.apply(Emit.scala); 	at is.hail.expr.ir.CompileIterator$$anon$2.step(Compile.scala:302); 	at is.hail.expr.ir.CompileIterator$LongIteratorWrapper.hasNext(Compile.scala:155); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Hail version: 0.2.126-ee77707f4fab; Error summary: HailException: cannot set missing field for required type +PFloat64; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:20927,Error,Error,20927,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['Error'],['Error']
Availability,"e2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x] (@daniel-goldstein) 7f1b1363e9 [query-service] use two containers sharing an empty volume; - [x] (@daniel-goldstein) 2a8f23404a [query-service] in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdri",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10100:2324,error,error,2324,https://hail.is,https://github.com/hail-is/hail/pull/10100,1,['error'],['error']
Availability,"e756f08dc78616040ab8fbd7db20903137ccf0c7"">e756f08</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>fix intersphinx link for 'requests-oauthlib' (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/921"">#921</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/967be4f4e2a43ba7e240d7acb01b6b992d40e6ec"">967be4f</a>)</li>; <li>note ValueError in <code>verify_oauth2_token</code> (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/928"">#928</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/82bc5f08111de78a2b475b0310d3f35470680dbe"">82bc5f0</a>)</li>; </ul>; <h2>v2.3.3</h2>; <h3>Bug Fixes</h3>; <ul>; <li>add fetch_id_token_credentials (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/866"">#866</a>) (<a href=""https://www.github.com/googleapis/google-auth-library-python/commit/8f1e9cfd56dbaae0dff64499e1d0cf55abc5b97e"">8f1e9cf</a>)</li>; <li>fix error in sign_bytes (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/905"">#905</a>) (<a href=""https://www.github.com/googleapis/google-auth-library-python/commit/ef3128474431b07d1d519209ea61622bc245ce91"">ef31284</a>)</li>; <li>use 'int.to_bytes' and 'int.from_bytes' for py3 (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/904"">#904</a>) (<a href=""https://www.github.com/googleapis/google-auth-library-python/commit/bd0ccc5fe77d55f7a19f5278d6b60587c393ee3c"">bd0ccc5</a>)</li>; </ul>; <h2>v2.3.2</h2>; <h3>Bug Fixes</h3>; <ul>; <li>add clock_skew_in_seconds to verify_token functions (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/894"">#894</a>) (<a href=""https://www.github.com/googleapis/google-auth-library-python/commit/8e95c1e458793593972b6b05a355aaeaecd31670"">8e95c1e</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11546:3950,error,error,3950,https://hail.is,https://github.com/hail-is/hail/pull/11546,1,['error'],['error']
Availability,"e: ubuntu; Port: <none>; Host Port: <none>; Command:; /bin/bash; -c; set -e; mkdir -p /io/pipeline/pipeline-cb568b8f204e/__TASK__2750/; /bin/sh -c ""sleep $(( 60 + (RANDOM % 20) ))""; Requests:; cpu: 100m; memory: 500M; Environment:; POD_IP: (v1:status.podIP); POD_NAME: batch-101-job-2751-90f13d (v1:metadata.name); Mounts:; /gsa-key from gsa-key (rw); /var/run/secrets/kubernetes.io/serviceaccount from batch-output-pod-token-8pkmz (ro); cleanup:; Image: gcr.io/hail-vdc/batch:w1eqo739af4d; Port: <none>; Host Port: <none>; Command:; /bin/sh; -c; ; set -ex; python3 -m batch.sidecar; ; Requests:; cpu: 500m; Environment:; INSTANCE_ID: cd50b95a89914efb897965a5e982a29d; BATCH_ID: 101; JOB_ID: 2751; TOKEN: 90f13d; BATCH_BUCKET_NAME: hail-batch-3jmp5; COPY_OUTPUT_CMD: true; HAIL_POD_NAMESPACE: batch-pods; KUBERNETES_TIMEOUT_IN_SECONDS: 5.0; REFRESH_INTERVAL_IN_SECONDS: 300; POD_NAME: batch-101-job-2751-90f13d (v1:metadata.name); Mounts:; /batch-gsa-key from batch-gsa-key (rw); /gsa-key from gsa-key (rw); /var/run/secrets/kubernetes.io/serviceaccount from batch-output-pod-token-8pkmz (ro); Volumes:; gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: dking-gsa-key; Optional: false; batch-gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: batch-gsa-key; Optional: false; batch-output-pod-token-8pkmz:; Type: Secret (a volume populated by a Secret); SecretName: batch-output-pod-token-8pkmz; Optional: false; QoS Class: Burstable; Node-Selectors: <none>; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s; node.kubernetes.io/unreachable:NoExecute for 300s; preemptible=true; Events:; Type Reason Age From Message; ---- ------ ---- ---- -------; Normal Scheduled 21m default-scheduler Successfully assigned batch-pods/batch-101-job-2751-90f13d to gke-vdc-non-preemptible-pool-0106a51b-5znv; Warning OutOfcpu 21m kubelet, gke-vdc-non-preemptible-pool-0106a51b-5znv Node didn't have enough resource: cpu, requested: 600, used: 7371, capacity: 7910; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6709:2650,Toler,Tolerations,2650,https://hail.is,https://github.com/hail-is/hail/issues/6709,1,['Toler'],['Tolerations']
Availability,"e; -- Build files have been written to: /home/rmk/package_sources/hail/hail/src/main/c/libsimdpp-2.0-rc2; mkdir -p lib/linux-x86-64; g++ -fvisibility=hidden -rdynamic -shared -fPIC -ggdb -O3 -march=native -g -std=c++11 -Ilibsimdpp-2.0-rc2 -Wall -Werror ibs.cpp -o lib/linux-x86-64/libibs.so; In file included from ibs.cpp:1:0:; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h: In function â€˜uint64_t vector_popcnt(uint64vector)â€™:; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h:42:1: error: inlining failed in call to always_inline â€˜long long int _mm_popcnt_u64(long long unsigned int)â€™: target specific option mismatch; _mm_popcnt_u64 (unsigned long long __X); ^; ibs.cpp:14:48: error: called from here; uint64_t count = _mm_popcnt_u64(extract<0>(x));; ^; In file included from ibs.cpp:1:0:; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h:42:1: error: inlining failed in call to always_inline â€˜long long int _mm_popcnt_u64(long long unsigned int)â€™: target specific option mismatch; _mm_popcnt_u64 (unsigned long long __X); ^; ibs.cpp:16:41: error: called from here; count += _mm_popcnt_u64(extract<1>(x));; ^; make: *** [lib/linux-x86-64/libibs.so] Error 1; Makefile:52: recipe for target 'lib/linux-x86-64/libibs.so' failed; :nativeLib FAILED. Tim Poterba suggested defining `CXXFLAGS='-DHAIL_OVERRIDE_ARCH -DSIMDPP_ARCH_X86_SSE2'`, but to no avail. So, he suggested I open this issue. I'm running gcc version 4.9.2. Possibly relevant might be the processor I'm running,; $ lscpu; Architecture: x86_64; CPU op-mode(s): 32-bit, 64-bit; Byte Order: Little Endian; CPU(s): 2; On-line CPU(s) list: 0,1; Thread(s) per core: 1; Core(s) per socket: 2; Socket(s): 1; NUMA node(s): 1; Vendor ID: GenuineIntel; CPU family: 6; Model: 23; Model name: Intel(R) Core(TM)2 CPU P8600 @ 2.40GHz; Stepping: 10; CPU MHz: 800.000; CPU max MHz: 2401.0000; CPU min MHz: 800.0000; BogoMIPS: 4800.16; Virtualization: VT-x; L1d cache: 32K; L1i cache: 32K; L2 cache: 3072K; NUMA node0 CPU(s): 0,1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1520:1480,error,error,1480,https://hail.is,https://github.com/hail-is/hail/issues/1520,3,"['Error', 'avail', 'error']","['Error', 'avail', 'error']"
Availability,"e>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/2cab9ecc641e962565c6254a5091f90c47f59b35""><code>2cab9ec</code></a> v1.1.1</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/521e40050cb386a499f68f483fefd144c493053c""><code>521e400</code></a> forbid dict parameter</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/7f032a699d55340f05101deb4d7d4f63db4adc11""><code>7f032a6</code></a> remove coveralls from requirements</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/69f6c7439bee14784e0ea70ae107af6446cc0c67""><code>69f6c74</code></a> ruff format</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/b4ed6884a1105df0a27f948f52b3e81d5585634f""><code>b4ed688</code></a> test json - mariadb without JSON type (<a href=""https://redirect.github.com/PyMySQL/PyMySQL/issues/1165"">#1165</a>)</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/bbd049f40db9c696574ce6f31669880042c56d79""><code>bbd049f</code></a> Support error packet without sqlstate (<a href=""https://redirect.github.com/PyMySQL/PyMySQL/issues/1160"">#1160</a>)</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/9694747ae619e88b792a8e0b4c08036572452584""><code>9694747</code></a> pyupgrade</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/1f0b7856de4008e7e4c1e8c1b215d5d4dfaecd1a""><code>1f0b785</code></a> chore(deps): update codecov/codecov-action action to v4 (<a href=""https://redirect.github.com/PyMySQL/PyMySQL/issues/1158"">#1158</a>)</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/1e28be81c24dde66f8acbf4c5e24f60d6b5e72e7""><code>1e28be8</code></a> chore(deps): update github/codeql-action action to v3 (<a href=""https://redirect.github.com/PyMySQL/PyMySQL/issues/1154"">#1154</a>)</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/f13f054abcc18b39855a760a84be0a517f0da658""><code>f13f054</code></a> chore(deps): update actions/setup-python action to v5 (<a href=""https://redirect.g",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14556:6230,error,error,6230,https://hail.is,https://github.com/hail-is/hail/pull/14556,1,['error'],['error']
Availability,"eAggregate(new BDV[Double](new Array[Double](nt)))(; seqOp = (U, v) => {; RowMatrix.dspr(1.0, v, U.data); U; }, combOp = (U1, U2) => U1 += U2). RowMatrix.triuToFull(n, GU.data); }; ```. dspr calls to the corresponding BLAS Level 2 command, which updates A to A + x.t \* x in place:; http://www.netlib.org/lapack/explore-html/d7/d15/group__double__blas__level2_ga22adb497a4f41eabc6a8dcac6f326183.html#ga22adb497a4f41eabc6a8dcac6f326183. Down the line we might also consider using BLAS level 3 dsyrk on each partition, which updates A to A + B.t \* B:; http://www.netlib.org/lapack/explore-html/d1/d54/group__double__blas__level3_gae0ba56279ae3fa27c75fefbc4cc73ddf.html#gae0ba56279ae3fa27c75fefbc4cc73ddf. @cseed The ArrayIndex exception on profile225k in the current master is concerning, and may be related to serialization. Here is the full stack trace:. ```; hail: grm: caught exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 3.0 failed 1 times, most recent failure: Lost task 5.0 in stage 3.0 (TID 45, localhost): java.lang.ArrayIndexOutOfBoundsException: 1048578; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:345); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:47); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:804); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:570); at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:194); at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:147); at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:185); at org.apache.spark.util.collection.ExternalAppendOnlyMap.spill(ExternalAppendOnlyMap.scala:206); at org.apache.spark.util.collection.ExternalAppendOnlyMap.spill(ExternalAppendOnlyMap.scala:55); at org.apache.spark.util.collection.Spillable$class.maybeSpill(Spillable.scala:93); at org.apache.spark.util.coll",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/801#issuecomment-247861703:2157,failure,failure,2157,https://hail.is,https://github.com/hail-is/hail/pull/801#issuecomment-247861703,2,['failure'],['failure']
Availability,"eContext.scala:18); at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:229); at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:303); at is.hail.backend.spark.SparkBackend.executeJSON(SparkBackend.scala:323); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:282); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:238); at java.lang.Thread.run(Thread.java:745). org.apache.spark.SparkException: Job aborted due to stage failure: Task 12 in stage 103.0 failed 4 times, most recent failure: Lost task 12.3 in stage 103.0 (TID 644994, scc-q21.scc.bu.edu, executor 2): java.io.FileNotFoundException: /scratch/.writeBlocksRDD-l5om7fTy3akZKCYbLDY4AD.crc (Too many open files); at java.io.FileOutputStream.open0(Native Method); at java.io.FileOutputStream.open(FileOutputStream.java:270); at java.io.FileOutputStream.<init>(FileOutputStream.java:213); at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:222); at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209); at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307); at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296); at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328); at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:402);",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403:9585,failure,failure,9585,https://hail.is,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403,1,['failure'],['failure']
Availability,"eContext.scala:18); at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:229); at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:303); at is.hail.backend.spark.SparkBackend.executeJSON(SparkBackend.scala:323); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:282); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:238); at java.lang.Thread.run(Thread.java:745). org.apache.spark.SparkException: Job aborted due to stage failure: Task 9586 in stage 2.0 failed 4 times, most recent failure: Lost task 9586.3 in stage 2.0 (TID 40203, scc-q21.scc.bu.edu, executor 13): java.lang.IllegalArgumentException: Self-suppression not permitted; at java.lang.Throwable.addSuppressed(Throwable.java:1043); at java.io.FilterOutputStream.close(FilterOutputStream.java:159); at is.hail.utils.package$.using(package.scala:603); at is.hail.io.RichContextRDDRegionValue$.writeSplitRegion(RichContextRDDRegionValue.scala:99); at is.hail.rvd.RVD$$anonfun$25.apply(RVD.scala:939); at is.hail.rvd.RVD$$anonfun$25.apply(RVD.scala:937); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18.apply(ContextRDD.scala:248); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18.apply(ContextRDD.scala:248); at is.hail.utils.richUtils.RichContextRDD$$anonfun$cleanupRegions$1$$anonfun$1.apply(RichContextRDD.scala:22); at is.hail.utils.richUtils.RichContextRDD$$anonfun$cleanupReg",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293:5141,failure,failure,5141,https://hail.is,https://github.com/hail-is/hail/issues/9293,1,['failure'],['failure']
Availability,eOutputStreamWithMode(RawLocalFileSystem.java:307); at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296); at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328); at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:402); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:778); at is.hail.io.fs.HadoopFS.createNoCompression(HadoopFS.scala:60); at is.hail.io.fs.FS$class.create(FS.scala:151); at is.hail.io.fs.HadoopFS.create(HadoopFS.scala:56); at is.hail.linalg.WriteBlocksRDD$$anonfun$62.apply(BlockMatrix.scala:1838); at is.hail.linalg.WriteBlocksRDD$$anonfun$62.apply(BlockMatrix.scala:1829); at scala.Array$.tabulate(Array.scala:331); at is.hail.linalg.WriteBlocksRDD.compute(BlockMatrix.scala:1829); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Hail version: 0.2.46-6ef64c08b000; Error summary: FileNotFoundException: /scratch/.writeBlocksRDD-l5om7fTy3akZKCYbLDY4AD.crc (Too many open files). ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403:19932,Error,Error,19932,https://hail.is,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403,1,['Error'],['Error']
Availability,"e_genome); 255; 256 def remove_liftover(self, name, dest_reference_genome):. /opt/conda/miniconda3/lib/python3.10/site-packages/py4j/java_gateway.py in __call__(self, *args); 1319; 1320 answer = self.gateway_client.send_command(command); -> 1321 return_value = get_return_value(; 1322 answer, self.gateway_client, self.target_id, self.name); 1323. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 63 tpl = Env.jutils().handleForPython(e.java_exception); 64 deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); ---> 65 raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; 66 except pyspark.sql.utils.CapturedException as e:; 67 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: HailException: Chain file 'grch37_to_grch38.over.chain.gz' does not exist. Java stack trace:; is.hail.utils.HailException: Chain file 'grch37_to_grch38.over.chain.gz' does not exist.; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.variant.ReferenceGenome.addLiftover(ReferenceGenome.scala:407); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$2(SparkBackend.scala:613); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$2$adapted(SparkBackend.scala:612); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:657); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:657); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:62); 	at is.hail.backend.spark.SparkBackend.$anonfun$withExecuteContext$1(SparkBackend.scala:347); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$1(SparkBackend.scala:612); 	at is.hail.backen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13993:3438,Error,ErrorHandling,3438,https://hail.is,https://github.com/hail-is/hail/issues/13993,1,['Error'],['ErrorHandling']
Availability,"e_outer[i].row_field_name),; hl.range(0, hl.len(ht.global_field_name_outer[i].global_field_name)); .map(lambda _: hl.null(ht.row_field_name_outer[i].row_field_name.dtype.element_type)),; ht.row_field_name_outer[i].row_field_name),; hl.range(hl.len(ht.global_field_name_outer)))); ht = ht.transmute_globals(inner_global=hl.flatmap(lambda x: x.global_field_name, ht.global_field_name_outer)); mt = ht._unlocalize_entries('inner_row', 'inner_global', globals_for_col_key); return mt. all_hts = list(map(lambda x: unify_saige_ht_schema(hl.read_table(x)), all_variant_outputs)); mt = join_pheno_hts_to_mt(all_hts, row_keys, col_keys, pheno_dict, f'{temp_bucket}/{pop}/variant',; inner_mode=inner_mode, repartition_final=20000); mt = mt.annotate_cols(saige_heritability=heritability_dict[mt.col_key]); mt = mt.filter_cols(mt.pheno != """").drop('varT', 'varTstar', 'Is.SPA.converge'); mt.key_rows_by('locus', 'alleles').write(get_variant_results_path(pop, 'mt'), overwrite=args.overwrite); ```; I'm getting the following error:; ```; hail.utils.java.FatalError: RuntimeException: found inconsistent agg or scan environments:; left: true, true; right: false, false. Java stack trace:; java.lang.RuntimeException: found inconsistent agg or scan environments:; left: true, true; right: false, false; at is.hail.expr.ir.BindingEnv.merge(Env.scala:68); at is.hail.expr.ir.FreeVariables$$anonfun$is$hail$expr$ir$FreeVariables$$compute$1$2.apply(FreeVariables.scala:38); at is.hail.expr.ir.FreeVariables$$anonfun$is$hail$expr$ir$FreeVariables$$compute$1$2.apply(FreeVariables.scala:38); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.fo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:2999,error,error,2999,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['error'],['error']
Availability,"eac; Mounts:; /batch-gsa-key from batch-gsa-key (rw); /gsa-key from gsa-key (rw); /io from batch-12728-job-287-742170 (rw); /var/run/secrets/kubernetes.io/serviceaccount from batch-output-pod-token-8pkmz (ro); keep-alive:; Container ID: ; Image: gcr.io/hail-vdc/batch:s32fqwbuz8nv; Image ID: ; Port: 5001/TCP; Host Port: 0/TCP; Command:; /bin/sh; -c; ; set -ex; python3 -m batch.keep_alive_sidecar; ; State: Waiting; Reason: PodInitializing; Ready: False; Restart Count: 0; Requests:; cpu: 1m; Environment: <none>; Mounts:; /gsa-key from gsa-key (rw); /io from batch-12728-job-287-742170 (rw); /var/run/secrets/kubernetes.io/serviceaccount from batch-output-pod-token-8pkmz (ro); Conditions:; Type Status; Initialized False ; Ready False ; ContainersReady False ; PodScheduled True ; Volumes:; gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: wang-gsa-key; Optional: false; batch-gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: batch-gsa-key; Optional: false; batch-12728-job-287-742170:; Type: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace); ClaimName: batch-12728-job-287-742170; ReadOnly: false; batch-output-pod-token-8pkmz:; Type: Secret (a volume populated by a Secret); SecretName: batch-output-pod-token-8pkmz; Optional: false; QoS Class: Burstable; Node-Selectors: <none>; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s; node.kubernetes.io/unreachable:NoExecute for 300s; preemptible=true; Events: <none>; ```; ```; # k get pods -n batch-pods batch-12728-job-287-742170 -o yaml; apiVersion: v1; kind: Pod; metadata:; creationTimestamp: 2019-09-05T19:12:22Z; labels:; app: batch-job; batch_id: ""12728""; hail.is/batch-instance: cd50b95a89914efb897965a5e982a29d; job_id: ""287""; user: wang; uuid: ca985fd90f9d46968ab9c480af9c931c; name: batch-12728-job-287-742170; namespace: batch-pods; resourceVersion: ""116541360""; selfLink: /api/v1/namespaces/batch-pods/pods/batch-12728-job-287-742170; uid: 1681dd0",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7016:4743,Toler,Tolerations,4743,https://hail.is,https://github.com/hail-is/hail/issues/7016,1,['Toler'],['Tolerations']
Availability,"ead.py"", line 58, in run; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py"", line 163, in <lambda>; thread_pool, lambda: fun(*args, **kwargs)); OSError: [Errno 39] Directory not empty: '/tmp/JnQ2m'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py"", line 409, in rmtree; await rm_dir(pool, contents_tasks_by_dir.get(path, []), path); File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py"", line 387, in rm_dir; excs = [exc; File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py"", line 389, in <listcomp>; for exc in [t.exception()]; File ""/usr/lib/python3.9/asyncio/futures.py"", line 214, in exception; raise exc; asyncio.exceptions.CancelledError. [2023-08-02 05:33:14] test/hail/utils/test_hl_hadoop_and_hail_fs.py::test_hadoop_methods_3[local] ERROR; [2023-08-02 05:43:14] test/hail/utils/test_hl_hadoop_and_hail_fs.py::test_read_overwrite[remote] SKIPPED; ```; ```; ==================================== ERRORS ====================================; ______________ ERROR at teardown of test_hadoop_methods_3[local] _______________. pool = <hailtop.utils.utils.OnlineBoundedGather2 object at 0x7f263d7a6fa0>; contents_tasks = [<Task finished name='Task-63869' coro=<OnlineBoundedGather2.call.<locals>.run_and_cleanup() done, defined at /usr/loc...2.call.<locals>.run_and_cleanup() done, defined at /usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py:398>>]; path = '/tmp/JnQ2m'. async def rm_dir(pool: OnlineBoundedGather2,; contents_tasks: List[asyncio.Task],; path: str):; assert listener is not None; listener(1); if contents_tasks:; await pool.wait(contents_tasks); try:; > await self.rmdir(path). /usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py:378: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13361:4550,ERROR,ERROR,4550,https://hail.is,https://github.com/hail-is/hail/issues/13361,1,['ERROR'],['ERROR']
Availability,"eamBufferSpec""}', timed); 177 try:; --> 178 result, timings = self._rpc(ActionTag.EXECUTE, payload); 179 except FatalError as e:; 180 raise e.maybe_user_error(ir) from None. File /opt/conda/lib/python3.10/site-packages/hail/backend/py4j_backend.py:213, in Py4JBackend._rpc(self, action, payload); 211 if resp.status_code >= 400:; 212 error_json = orjson.loads(resp.content); --> 213 raise fatal_error_from_java_error_triplet(error_json['short'], error_json['expanded'], error_json['error_id']); 214 return resp.content, resp.headers.get('X-Hail-Timings', ''). FatalError: HailException: cannot set missing field for required type +PFloat64. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 6.0 failed 4 times, most recent failure: Lost task 5.3 in stage 6.0 (TID 67) (saturn-machinenumber.c.terra-code.internal executor 4): is.hail.utils.HailException: gs://path/to/bucket/chrY.0002.hard_filtered_with_genotypes.vcf.gz:offset 23933331019603: error while parsing line; chrY	113	.	GG	G,*,AG,CG	596	PASS	AC=2,4,6,1;AF=1.23e-03,5.550e-05,4.44e-05,2.00e-04;AN=265;AS_AltDP=10,0,3,10;AS_BaseQRankSum=0.000,.,0.100,0.500;AS_FS=7.777,.,2.144,8.001;AS_MQ=55.75,.,38.98,40.20;AS_MQRankSum=0.200,.,-1.050,-0.500;AS_QD=0.50,0.00,0.25,0.52;AS_ReadPosRankSum=-0.200,.,0.500,-0.220;AS_SOR=2.300,.,1.600,3.000;BaseQRankSum=0.200;DP=600000;ExcessHet=0.0477;FS=0.900;MQ=55.02;MQRankSum=-0.553;QD=1.00;ReadPosRankSum=-0.162;SOR=0.792;VarDP=650	GT:AD:DP:GQ:PGT:PID:PL:PS:SB	0/0:.:21:30	0/0:.:300:20	0/0:.:30:72	0/0:.:31:98	0|1:29,3,0,0,0:33:78:0|1:113_GG_G:78,0,1100,140,1400,1200,172,1600,1200,1000,175,1100,1100,1300,1000:113:19,19,2,1	0/0:.:20:19	0/0:.:19:20	0/0:.:25:50		0|1:90,2,0,0,0:30:40:0|1:113_GG_G:40,0,600,70,650,600,90,640,900,300,60,800,400,900,900:113:2,14,2,0	0/0:.:20:10	0/0:.:9:20	0/0:.:30:40	0/0:.:37:38		0/4:5,0,0,0,1:5:33:.:.:30,40,400,50,220,220,38,270,270,270,0,200,200,200,202:.:5,0,0,1	. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.sc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:6295,error,error,6295,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['error'],['error']
Availability,"ebook', request, userdata)\n File \""/usr/local/lib/python3.6/dist-packages/notebook/notebook.py\"", line 278, in _post_notebook\n pod = await start_pod(k8s, service, userdata, notebook_token, jupyter_token)\n File \""/usr/local/lib/python3.6/dist-packages/notebook/notebook.py\"", line 167, in start_pod\n _request_timeout=KUBERNETES_TIMEOUT_IN_SECONDS)\n File \""/usr/local/lib/python3.6/dist-packages/kubernetes_asyncio/client/api_client.py\"", line 166, in __call_api\n _request_timeout=_request_timeout)\n File \""/usr/local/lib/python3.6/dist-packages/kubernetes_asyncio/client/rest.py\"", line 230, in POST\n body=body))\n File \""/usr/local/lib/python3.6/dist-packages/kubernetes_asyncio/client/rest.py\"", line 181, in request\n raise ApiException(http_resp=r)\nkubernetes_asyncio.client.rest.ApiException: (422)\nReason: Unprocessable Entity\nHTTP response headers: <CIMultiDictProxy('Audit-Id': '16158e81-8543-457e-8bea-5d5e1a8c39f3', 'Content-Type': 'application/json', 'Date': 'Sun, 29 Sep 2019 03:43:05 GMT', 'Content-Length': '901')>\nHTTP response body: {\""kind\"":\""Status\"",\""apiVersion\"":\""v1\"",\""metadata\"":{},\""status\"":\""Failure\"",\""message\"":\""Pod \\\""notebook-worker-9z6tg\\\"" is invalid: [spec.volumes[1].secret.secretName: Required value, spec.volumes[2].secret.secretName: Required value, spec.containers[0].volumeMounts[1].name: Not found: \\\""gsa-key\\\"", spec.containers[0].volumeMounts[2].name: Not found: \\\""user-tokens\\\""]\"",\""reason\"":\""Invalid\"",\""details\"":{\""name\"":\""notebook-worker-9z6tg\"",\""kind\"":\""Pod\"",\""causes\"":[{\""reason\"":\""FieldValueRequired\"",\""message\"":\""Required value\"",\""field\"":\""spec.volumes[1].secret.secretName\""},{\""reason\"":\""FieldValueRequired\"",\""message\"":\""Required value\"",\""field\"":\""spec.volumes[2].secret.secretName\""},{\""reason\"":\""FieldValueNotFound\"",\""message\"":\""Not found: \\\""gsa-key\\\""\"",\""field\"":\""spec.containers[0].volumeMounts[1].name\""},{\""reason\"":\""FieldValueNotFound\"",\""message\"":\""Not found: \\\""user-tokens\\\""\"",\""fiel",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7145#issuecomment-536245851:2548,Failure,Failure,2548,https://hail.is,https://github.com/hail-is/hail/pull/7145#issuecomment-536245851,1,['Failure'],['Failure']
Availability,"ebook-create-services-and-pods; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services #this was causing the error, and of course the create-services role is superseded by the the create-services-and-pods role; apiGroup: """"; ---; ```. After:; ```yaml; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: create-services-and-pods; rules:; - apiGroups: [""""]; resources: [""services""]; verbs: [""*""]; - apiGroups: [""""]; resources: [""pods""]; verbs: [""*""]; ---; kind: RoleBinding; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: notebook-create-services-and-pods; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services-and-pods; apiGroup: """"; ---; ```. ### Results of test runs. Before:. ```sh; kubectl apply -f k8s-config.yaml; ERROR: (gcloud.compute.addresses.describe) Could not fetch resource:; - Required 'compute.addresses.get' permission for 'projects/hail-vdc-staging/regions/us-central1/addresses/site'. namespace/batch-pods unchanged; ...; The RoleBinding ""notebook-create-services-and-pods"" is invalid: roleRef: Invalid value: rbac.RoleRef{APIGroup:""rbac.authorization.k8s.io"", Kind:""Role"", Name:""create-services""}: cannot change roleRef; make: *** [k8s-config] Error 1; ```. After:; ```sh; ERROR: (gcloud.compute.addresses.describe) Could not fetch resource:; - Required 'compute.addresses.get' permission for 'projects/hail-vdc-staging/regions/us-central1/addresses/site'. ...; role.rbac.authorization.k8s.io/create-services-and-pods unchanged; rolebinding.rbac.authorization.k8s.io/notebook-create-services-and-pods configured; role.rbac.authorization.k8s.io/read-get-user-secret unchanged; rolebinding.rbac.authorization.k8s.io/notebook-read-get-users-secret configured; ```. I think the error just reflects my not having hail-vdc-staging permissions, that is unaffected by this PR. cc @cseed, @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5746:2853,Error,Error,2853,https://hail.is,https://github.com/hail-is/hail/pull/5746,3,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,"ebug_string; st = ''.join(traceback.format_stack()); . The most recent error was <class 'hailtop.httpx.ClientResponseError'> 500, message='Internal Server Error', url=URL('http://batch.hail/api/v1alpha/batches/485962/updates/1/jobs/create') body='500 Internal Server Error\n\nServer got itself in trouble'. ; Traceback (most recent call last):; File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 809, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/aiocloud/common/session.py"", line 117, in _request_with_valid_authn; return await self._http_session.request(method, url, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/httpx.py"", line 148, in request_and_raise_for_status; raise ClientResponseError(; hailtop.httpx.ClientResponseError: 500, message='Internal Server Error', url=URL('http://batch.hail/api/v1alpha/batches/485962/updates/1/jobs/create') body='500 Internal Server Error\n\nServer got itself in trouble'; 2024-09-25 01:54:55,288 - hailtop.utils 835 - WARNING - A transient error occured. We will automatically retry. We have thus far seen 50 transient errors (next delay: 60.0s).; ```. The corresponding server-side error was. ```; pymysql.err.DataError: (1406, \""Data too long for column 'value' at row 106\""); ```. coming from the `INSERT INTO job_attributes â€¦` query in `insert_jobs_into_db()`. We write a list of the samples being processed as a job attribute, and it turned out that for at least some of the jobs of this batch this list had grown to longer than 64K of text. The `job_attributes.value` database field is of type TEXT, which limits each individual attribute to 64KiB bytes. While writing a long list of sample ids as an attribute may or may not be a great idea :smile: it is fair to say that 64K is not a large maximum for user-supplied data here in the 21st century!. It may be worth adding a database migration to change the `job_attribute",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14702:1481,Error,Error,1481,https://hail.is,https://github.com/hail-is/hail/issues/14702,1,['Error'],['Error']
Availability,"ec3cb48,0x00007fbeaec3cb78] = 48; scopes pcs [0x00007fbeaec3cb78,0x00007fbeaec3cbb8] = 64; dependencies [0x00007fbeaec3cbb8,0x00007fbeaec3cbc0] = 8; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #; FATAL: caught signal 6 SIGABRT; /tmp/libhail7224206977949339430.so(+0x1788c)[0x7fbdea5db88c]; /lib/x86_64-linux-gnu/libc.so.6(+0x33060)[0x7fbec2eae060]; /lib/x86_64-linux-gnu/libc.so.6(gsignal+0xcf)[0x7fbec2eadfff]; /lib/x86_64-linux-gnu/libc.so.6(abort+0x16a)[0x7fbec2eaf42a]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(+0x8c0259)[0x7fbec27f0259]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(+0xa744f8)[0x7fbec29a44f8]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(JVM_handle_linux_signal+0x265)[0x7fbec27f9e45]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(+0x8bd4c8)[0x7fbec27ed4c8]; /lib/x86_64-linux-gnu/libpthread.so.0(+0x110c0)[0x7fbec38580c0]; [0x7fbeaec3ca22]; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [828e66d5a71741d7ab2c8d6580997da3] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""pyhail.py"", line 132, in <module>; main(args, pass_through_args); File ""pyhail.py"", line 113, in main; subprocess.check_output(job); File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 573, in check_output; raise CalledProcessError(retcode, cmd, output=output); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', '/Users/gtiao/gnomad_qc/hail/variant_qc/make_var_annot_hists.py', '--cluster', 'gt3', '--files=gs://hail-common/builds/devel/jars/hail-devel-cadc5eefca6e-Spark-2.2.0.jar', '--py-files=gs://hail-common/builds/devel/python/hail-devel-cadc5eefca6e.zip,/var/folders/rn/t2xcx1ps4h96txll46qkkfsj2q8bnl/T/pyscripts_K7Vs59.zip', '--driver-log-levels', 'root=FATAL,is.hail=INFO', '--properties=spark.executor.extraClas",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4418:3976,ERROR,ERROR,3976,https://hail.is,https://github.com/hail-is/hail/issues/4418,1,['ERROR'],['ERROR']
Availability,echo HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE_PY_3_11=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc ']'; + echo HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc; HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc ']'; + echo HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc ']'; + echo HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc; + for varname in '$arguments'; + '[' -z '' '],MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:3455,echo,echo,3455,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,1,['echo'],['echo']
Availability,echo HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc ']'; + echo HAIL_GENETICS_HAIL_IMAGE_PY_3_11=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hail:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc ']'; + echo HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc; HAIL_GENETICS_HAILTOP_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/hailtop:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc ']'; + echo HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85:deploy-123abc; + for varname in '$arguments'; + '[' -z docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc ']'; + echo HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:deploy-123abc; + for varname in '$arguments'; + '[' -z x ']',MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:8931,echo,echo,8931,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,1,['echo'],['echo']
Availability,"ecrets/kubernetes.io/serviceaccount from default-token-8h99c (ro); Conditions:; Type Status; Initialized True ; Ready False ; ContainersReady False ; PodScheduled True ; Volumes:; test-gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: test-gsa-key; Optional: false; gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: ci-gsa-key; Optional: false; default-token-8h99c:; Type: Secret (a volume populated by a Secret); SecretName: default-token-8h99c; Optional: false; QoS Class: Burstable; Node-Selectors: <none>; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s; node.kubernetes.io/unreachable:NoExecute for 300s; preemptible=true; Events:; Type Reason Age From Message; ---- ------ ---- ---- -------; Normal Scheduled 13m default-scheduler Successfully assigned batch-pods/batch-3-job-41-39d17b to gke-vdc-preemptible-pool-9c7148b2-1f89; Warning FailedCreatePodSandBox 13m kubelet, gke-vdc-preemptible-pool-9c7148b2-1f89 Failed create pod sandbox: rpc error: code = Unknown desc = failed to set up sandbox container ""99ac9edad98221dbfaf4ab8eb443bc6d3fdc6df84164594469900813652fd913"" network for pod ""batch-3-job-41-39d17b"": NetworkPlugin kubenet failed to set up pod ""batch-3-job-41-39d17b_batch-pods"" network: Error adding container to network: failed to set bridge addr: could not add IP address to ""cbr0"": file exists; ```. ```; $ kubectl -n batch-pods get pods -o yaml batch-3-job-41-39d17b; apiVersion: v1; kind: Pod; metadata:; creationTimestamp: ""2019-07-12T17:17:15Z""; labels:; app: batch-job; batch_id: ""3""; hail.is/batch-instance: cd50b95a89914efb897965a5e982a29d; job_id: ""41""; task: main; user: ci; uuid: f53f127847864f1cbf7d4bdc911a6646; name: batch-3-job-41-39d17b; namespace: batch-pods; resourceVersion: ""87247110""; selfLink: /api/v1/namespaces/batch-pods/pods/batch-3-job-41-39d17b; uid: e4d87ac3-a4c8-11e9-a4bb-42010a8000af; spec:; containers:; - command:; - bash; - -c; - |-; set -e; gcloud -q auth activate-service-account --key-fil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6625:2296,error,error,2296,https://hail.is,https://github.com/hail-is/hail/issues/6625,2,"['Error', 'error']","['Error', 'error']"
Availability,"ect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **449/1000** <br/> **Why?** Has a fix available, CVSS 4.7 | Access Restriction Bypass <br/>[SNYK-PYTHON-NOTEBOOK-2928995](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **399/1000** <br/> **Why?** Has a fix available, CVSS 3.7 | Race Condition <br/>[SNYK-PYTHON-PROMPTTOOLKIT-6141120](https://snyk.io/vuln/SNYK-PYTHON-PROMPTTOOLKIT-6141120) | `prompt-toolkit:` <br> `1.0.18 -> 3.0.13` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **696/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-1086606](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1086606) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-PYGMENTS-1088505](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1088505) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:5429,avail,available,5429,https://hail.is,https://github.com/hail-is/hail/pull/14205,1,['avail'],['available']
Availability,"ect id=o1962, deepest = 'NoSuchElementException: next on empty iterator'; full = 'java.lang.RuntimeException: typ: inference failure: \n(MakeArray Array[Int32])\n\tat is.hail.expr.ir.IR$class.typ(IR....a:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\n\n'. def deco(*args, **kwargs):; import pyspark; try:; return f(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; s = e.java_exception.toString(); ; # py4j catches NoSuchElementExceptions to stop array iteration; if s.startswith('java.util.NoSuchElementException'):; raise; ; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full = tpl._1(), tpl._2(); raise FatalError('%s\n\nJava stack trace:\n%s\n'; 'Hail version: %s\n'; > 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; E hail.utils.java.FatalError: NoSuchElementException: next on empty iterator; E ; E Java stack trace:; E java.lang.RuntimeException: typ: inference failure: ; E (MakeArray Array[Int32]); E 	at is.hail.expr.ir.IR$class.typ(IR.scala:34); E 	at is.hail.expr.ir.MakeArray.typ(IR.scala:135); E 	at is.hail.expr.ir.IRParser$.ir_value_expr_1(Parser.scala:889); E 	at is.hail.expr.ir.IRParser$.ir_value_expr(Parser.scala:680); E 	at is.hail.expr.ir.IRParser$$anonfun$ir_value_children$1.apply(Parser.scala:676); E 	at is.hail.expr.ir.IRParser$$anonfun$ir_value_children$1.apply(Parser.scala:676); E 	at is.hail.expr.ir.IRParser$.repUntil(Parser.scala:301); E 	at is.hail.expr.ir.IRParser$.ir_value_children(Parser.scala:676); E 	at is.hail.expr.ir.IRParser$.ir_value_expr_1(Parser.scala:1084); E 	at is.hail.expr.ir.IRParser$.ir_value_expr(Parser.scala:680); E 	at is.hail.expr.ir.IRParser$$anonfun$parse_value_ir$2.apply(Parser.scala:1597); E 	at is.hail.expr.ir.IRParser$$anonfun$parse_value_ir$2.apply(Parser.scala:1597); E 	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1591); E 	at is.hail.expr.ir.IRParser$.parse_value_ir(Parser.scala:1597); E 	at is.hail.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7969#issuecomment-579035930:3690,failure,failure,3690,https://hail.is,https://github.com/hail-is/hail/pull/7969#issuecomment-579035930,1,['failure'],['failure']
Availability,"ect.dependabot.com/axios/axios/pull/3712"">#3712</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3717"">#3717</a>)</li>; <li>Updating content-type header for application/json to not contain charset field, according do RFC 8259 (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2154"">#2154</a>)</li>; <li>Fixing tests by bumping karma-sauce-launcher version (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3813"">#3813</a>)</li>; <li>Changing testing process from Travis CI to GitHub Actions (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3938"">#3938</a>)</li>; </ul>; <p>Documentation:</p>; <ul>; <li>Updating documentation around the use of <code>AUTH_TOKEN</code> with multiple domain endpoints (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3539"">#3539</a>)</li>; <li>Remove duplication of item in changelog (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3523"">#3523</a>)</li>; <li>Fixing gramatical errors (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2642"">#2642</a>)</li>; <li>Fixing spelling error (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3567"">#3567</a>)</li>; <li>Moving gitpod metion (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2637"">#2637</a>)</li>; <li>Adding new axios documentation website link (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3681"">#3681</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3707"">#3707</a>)</li>; <li>Updating documentation around dispatching requests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3772"">#3772</a>)</li>; <li>Adding documentation for the type guard isAxiosError (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3767"">#3767</a>)</li>; <li>Adding explanation of cancel token (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3803"">#3803</a>)</li>; <li>Updating CI status bad",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:3314,error,errors,3314,https://hail.is,https://github.com/hail-is/hail/pull/11080,4,['error'],['errors']
Availability,"ects/hail/hail/python/hail/backend/backend.py:188, in Backend.execute(self, ir, timed); 186 payload = ExecutePayload(self._render_ir(ir), '{""name"":""StreamBufferSpec""}', timed); 187 try:; --> 188 result, timings = self._rpc(ActionTag.EXECUTE, payload); 189 except FatalError as e:; 190 raise e.maybe_user_error(ir) from None. File ~/projects/hail/hail/python/hail/backend/py4j_backend.py:223, in Py4JBackend._rpc(self, action, payload); 221 if resp.status_code >= 400:; 222 error_json = orjson.loads(resp.content); --> 223 raise fatal_error_from_java_error_triplet(; 224 error_json['short'], error_json['expanded'], error_json['error_id']; 225 ); 226 return resp.content, resp.headers.get('X-Hail-Timings', ''). FatalError: NoSuchElementException: Ref with name __iruid_1834 could not be resolved in env BindingEnv((__iruid_1832 -> struct{},__iruid_2157 -> struct{}),None,None,()). Java stack trace:; is.hail.utils.HailException: error after applying LowerToDistributedArray; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:23); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:23); 	at is.hail.utils.package$.fatal(package.scala:89); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:32); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:205); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$ano",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14245:3403,Error,ErrorHandling,3403,https://hail.is,https://github.com/hail-is/hail/issues/14245,1,['Error'],['ErrorHandling']
Availability,"ecutor.Executor$TaskRunner.run(Executor.scala:414) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748). Spark Worker Logs (truncated to crash):. 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms; 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms; 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms; 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms; [thread 46926922934016 also had an error][thread 46922053207808 also had an error][thread 46926901880576 also had an error][thread 46926888195840 also had an error][thread 46926887143168 also had an error][thread 46924854015744 also had an error]; [thread 46924847699712 also had an error]. 	#. 	# A fatal error has been detected by the Java Runtime Environment:. 	[thread 46926905038592 also had an error]#; 	# ; 	[thread 46926895564544 also had an error][thread 46926900827904 also had an error]. 	SIGSEGV (0xb) at pc=0x00002aaab5115c88, pid=34051, tid=0x00002aae05d1a700; 	#; 	# JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-b08); 	# Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 compressed oops); 	# Problematic frame:; 	[thread 46926929250048 also had an error]# ; 	[thread 46926881888000 also had an error]; 	J 5583 C2 __C111CompiledWithAggs.__m131wrapped(Lis/hail/annotations/Region;J)V (280 bytes) @ 0x00002aaab5115c88 [0x00002aaab5115ae0+0x1a8]; 	#; 	# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; 	#; 	[thread 46924863489792 also had an error]; 	[thread 46924861384448 also had an error]; 	# An error report file with more information is saved as:; 	# /local/scratch/app-20200610",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:18769,error,error,18769,https://hail.is,https://github.com/hail-is/hail/issues/8944,1,['error'],['error']
Availability,"ed URLs which don't have an explicit scheme <a href=""https://redirect.github.com/urllib3/urllib3/pull/2950"">#2950</a></li>; <li>Fixed response decoding with Zstandard when compressed data is made of several frames. <a href=""https://redirect.github.com/urllib3/urllib3/issues/3008"">#3008</a></li>; <li>Fixed <code>assert_hostname=False</code> to correctly skip hostname check. <a href=""https://redirect.github.com/urllib3/urllib3/issues/3051"">#3051</a></li>; </ul>; <h2>2.0.2</h2>; <ul>; <li>Fixed <code>HTTPResponse.stream()</code> to continue yielding bytes if buffered decompressed data was still available to be read even if the underlying socket is closed. This prevents a compressed response from being truncated. (<a href=""https://redirect.github.com/urllib3/urllib3/issues/3009"">urllib3/urllib3#3009</a>)</li>; </ul>; <h2>2.0.1</h2>; <ul>; <li>Fixed a socket leak when fingerprint or hostname verifications fail. (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2991"">#2991</a>)</li>; <li>Fixed an error when <code>HTTPResponse.read(0)</code> was the first <code>read</code> call or when the internal response body buffer was otherwise empty. (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2998"">#2998</a>)</li>; </ul>; <h2>2.0.0</h2>; <p>Read the <a href=""https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html"">v2.0 migration guide</a> for help upgrading to the latest version of urllib3.</p>; <h1>Removed</h1>; <ul>; <li>Removed support for Python 2.7, 3.5, and 3.6 (<a href=""https://redirect.github.com/urllib3/urllib3/issues/883"">#883</a>, <a href=""https://redirect.github.com/urllib3/urllib3/issues/2336"">#2336</a>).</li>; <li>Removed fallback on certificate <code>commonName</code> in <code>match_hostname()</code> function. This behavior was deprecated in May 2000 in RFC 2818. Instead only <code>subjectAltName</code> is used to verify the hostname by default. To enable verifying the hostname against <code>commonName</code> use <code>SSLContext.ho",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13768:2993,error,error,2993,https://hail.is,https://github.com/hail-is/hail/pull/13768,3,['error'],['error']
Availability,"ed dataset; Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail/test.py"", line 3, in <module>; hl.import_vcf('/project/casa/vcf.5k/gatk.hc/adsp-5k.hg38.tileDB.recalibrate_SNP.chr22.biallelic.4795samples.g.vcf.bgz').write('/project/casa/vdf.5k/test. vdf'); File ""<decorator-gen-546>"", line 2, in write; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 481, in _typecheck; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 1956, in write; File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: ClassNotFoundException: is.hail.utils.SerializableHadoopConfiguration. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 2.0 failed 4 times, most recent failure: Lost task 6.3 in stage 2.0 (TID 2 53, scc-q15.scc.bu.edu, executor 1): java.io.IOException: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:757); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:756); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.R",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342:2338,failure,failure,2338,https://hail.is,https://github.com/hail-is/hail/issues/3342,1,['failure'],['failure']
Availability,"ed due to stage failure: Task 0 in stage 24.0 failed 20 times, most recent failure: Lost task 0.19 in stage 24.0 (TID 1813, lfrani-sw-hqb8.c.broad-mpg-gnomad.internal, executor 159): is.hail.utils.HailException: found out of bounds index -1; Resulted from trying to merge -0.0; Indices are [0.0, 2.0, 4.0, 6.0, 8.0, 10.0, 12.0, 14.0, 16.0, 18.0, 20.0, 22.0, 24.0, 26.0, 28.0, 30.0, 32.0, 34.0, 36.0, 38.0, 40.0, 42.0, 44.0, 46.0, 48.0, 50.0, 52.0, 54.0, 56.0, 58.0, 60.0, 62.0, 64.0, 66.0, 68.0, 70.0, 72.0, 74.0, 76.0, 78.0, 80.0, 82.0, 84.0, 86.0, 88.0, 90.0, 92.0, 94.0, 96.0, 98.0, 100.0, 102.0, 104.0, 106.0, 108.0, 110.0, 112.0, 114.0, 116.0, 118.0, 120.0, 122.0, 124.0, 126.0, 128.0, 130.0, 132.0, 134.0, 136.0, 138.0, 140.0, 142.0, 144.0, 146.0, 148.0, 150.0, 152.0, 154.0, 156.0, 158.0, 160.0, 162.0, 164.0, 166.0, 168.0, 170.0, 172.0, 174.0, 176.0, 178.0, 180.0, 182.0, 184.0, 186.0, 188.0, 190.0, 192.0, 194.0, 196.0, 198.0, 200.0]; Binary search index was -1; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.stats.HistogramCombiner.merge(HistogramCombiner.scala:42); 	at is.hail.annotations.aggregators.RegionValueHistogramAggregator.seqOp(RegionValueHistogramAggregator.scala:31); 	at is.hail.codegen.generated.C95.apply(Unknown Source); 	at is.hail.codegen.generated.C95.apply(Unknown Source); 	at is.hail.expr.ir.Interpret$$anonfun$27.apply(Interpret.scala:809); 	at is.hail.expr.ir.Interpret$$anonfun$27.apply(Interpret.scala:808); 	at is.hail.rvd.RVD$$anonfun$20$$anonfun$apply$11.apply(RVD.scala:551); 	at is.hail.rvd.RVD$$anonfun$20$$anonfun$apply$11.apply(RVD.scala:550); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.rvd.RVD$$anonfun$20.apply(RVD.scala:550); 	at is.hail.rvd.RVD$$anonfun$20.apply(RVD.scala:547); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$appl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5846:3777,Error,ErrorHandling,3777,https://hail.is,https://github.com/hail-is/hail/issues/5846,1,['Error'],['ErrorHandling']
Availability,"ed in two places: Binds.scala, and the parser. We need the binding structure in the parser to propagate the environment, so we can annotate `Ref` nodes (and a few other things) with their types. But we can't use Binds.scala because we don't yet have an IR. This PR removes environment maintenance from the parser by deferring type annotation to a separate pass (which is simple, because it can use the Binds.scala infrastructure). One consequence is that we can't assign types to nodes like `Ref` during parsing, which means we can't ask for the type of any node during parsing, and by extension we can't ask for types of children in IR node constructors. Instead, all typechecking logic is moved to the `TypeCheck` pass. Some benefits of this change:; * The parser is simpler, as it doesn't have to maintain a typing environment.; * Binds.scala is now the single source of truth on the binding structure of the IR.; * Instead of typechecking being split in an ad-hoc way between IR constructors and the `TypeCheck` pass, all typechecking and type error reporting logic is in one place.; * The parser parses a context-free grammar, no more and no less. If the input is gramatically correct, the parser succeeds.; * We can round trip IR with type errors through the text representation. For instance, if we log an IR that fails TypeCheck, we can copy the IR from the log, parse it, then debug. This change was motivated by my work in progress to convert the parser to use the SSA grammar, which this should greatly simplify. I chose to make the type annotation pass after parsing mutate the IR in place (with the unfortunate exception of `Apply`, which can change into an `ApplyIR` or `ApplySpecial`. Do these really need to be separate nodes?). The type of a `Ref` node was already mutable to allow this sort of deferred annotation, and I've had to make a few other things mutable as well. Alternatively we could rebuild the entire IR to include type annotations, but I think the mutation is sufficien",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13990:1102,error,error,1102,https://hail.is,https://github.com/hail-is/hail/pull/13990,1,['error'],['error']
Availability,"ed int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int32<8>]â€™; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:110:36: required from â€˜simdpp::arch_avx2::uint8<32>::uint8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int32<8>]â€™; libsimdpp-2.0-rc2/simdpp/detail/extract128.h:40:82: required from â€˜simdpp::arch_avx2::int32x4 simdpp::arch_avx2::detail::extract128(const int32x8&) [with unsigned int s = 0; simdpp::arch_avx2::int32x4 = simdpp::arch_avx2::int32<4>; simdpp::arch_avx2::int32x8 = simdpp::arch_avx2::int32<8>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_reduce_add.h:356:49: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint8<32>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint8<32>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::int32<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:91:7: note: â€˜class simdpp::arch_avx2::uint8<32>â€™ declared here; class uint8<32, void> : public any_int8<32, uint8<32,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int32<4>; T = simdpp::arch_avx2::uint8<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:121179,error,error,121179,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"ed int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int64<4>]â€™; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:110:36: required from â€˜simdpp::arch_avx2::uint8<32>::uint8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int64<4>]â€™; libsimdpp-2.0-rc2/simdpp/detail/extract128.h:42:82: required from â€˜simdpp::arch_avx2::int64x2 simdpp::arch_avx2::detail::extract128(const int64x4&) [with unsigned int s = 0; simdpp::arch_avx2::int64x2 = simdpp::arch_avx2::int64<2>; simdpp::arch_avx2::int64x4 = simdpp::arch_avx2::int64<4>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/i_reduce_max.h:478:40: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint8<32>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint8<32>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::int64<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:91:7: note: â€˜class simdpp::arch_avx2::uint8<32>â€™ declared here; class uint8<32, void> : public any_int8<32, uint8<32,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int64<2>; T = simdpp::arch_avx2::uint8<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:125293,error,error,125293,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"ed?. Note: this is an Azure-specific issue. When submitting a batch/job that requests more storage than is available on the temp disk of any standing worker, but doesn't request a specific number of cores or amount of memory, a NotImplementedError is raised in `batch/cloud/azure/worker/disk.py`. See this Batch record for an example of the issue in action: https://batch.azure.hail.is/batches/4563654/jobs/1. The corresponding base case to reproduce this is:. ```python; import hailtop.batch as hb; backend = hb.ServiceBackend(billing_project=""<YOUR BILLING PROJECT>""); b = hb.Batch(backend=backend, name=""storage_test""); j = b.new_job(); j.image(""ubuntu:20.04""); j.storage(""700GiB""); j.command(""df -h""); b.run(wait=False); ```. On the cluster azure.hail.is this job gets scheduled on a `Standard_D16ds_v4` instance which has a 600 GiB temp disk. On GCP, when requests exceed this amount a data disk is provisioned to service the request. While this is feasible on Azure and could be implemented, it may not be the recommended solution as temp disks are much better suited to ephemeral workloads than data disks. On clusters with a smaller standing worker (i.e. fewer cores) there is a workaround, which also possibly suggests a reasonable partial solution. This workaround is to specify a required number of cores that forces a larger VM of the same family to be provisioned. This makes a larger temp disk available for the job to leverage. The corresponding partial solution would be to take knowledge of the temp disk size for any VM into account when scheduling jobs and provision larger VMs when warranted by the storage requirement of a job. . Based on current limitations for VM core count (16) this suggests a ceiling on storage that can be allocated to any job in Azure of 600 GiB. At that point it would be necessary to allocate a data disk. This issue reproduces on both azure.hail.is and our own Azure cluster.; . ### Version. 0.2.126-cdd2c132bfa2. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14522:1423,avail,available,1423,https://hail.is,https://github.com/hail-is/hail/issues/14522,1,['avail'],['available']
Availability,"edRVD.scala:649); 	at is.hail.methods.SplitMulti$.unionMovedVariants(SplitMulti.scala:237); 	at is.hail.methods.SplitMulti.split(SplitMulti.scala:332); 	at is.hail.methods.SplitMulti$.apply(SplitMulti.scala:232); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)is.hail.utils.HailException: invalid allele ""GN""; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); 	at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:28); 	at is.hail.variant.AltAlleleMethods$.isStar(AltAlleleMethods.scala:73); 	at is.hail.variant.VariantMethods$$anonfun$minRep$1.apply(VariantMethods.scala:43); 	at is.hail.variant.VariantMethods$$anonfun$minRep$1.apply(VariantMethods.scala:43); 	at scala.collection.IndexedSeqOptimized$class.prefixLengthImpl(IndexedSeqOptimized.scala:38); 	at scala.collection.IndexedSeqOptimized$class.forall(IndexedSeqOptimized.scala:43); 	at scala.collection.mutable.WrappedArray.forall(WrappedArray.scala:35); 	at is.hail.variant.VariantMethods$.minRep(VariantMethods.scala:43); 	at is.hail.methods.SplitMultiPartitionContext$$anonfun$2.apply(SplitMulti.scala:196); 	at is.hail.methods.SplitMultiPartitionContext$$anonfun$2.apply(SplitMulti.scala:192); 	at scala.coll",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3480:8746,Error,ErrorHandling,8746,https://hail.is,https://github.com/hail-is/hail/issues/3480,1,['Error'],['ErrorHandling']
Availability,"edit:. Issue seems to be something else; may be having issue connecting to sql host on cluster, at least when executed by ci. @jigold I'll fix it, then ping you.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5618#issuecomment-477827672:152,ping,ping,152,https://hail.is,https://github.com/hail-is/hail/pull/5618#issuecomment-477827672,1,['ping'],['ping']
Availability,edited line in Docs formatting error in multi-way-zip-join #7945,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7985:31,error,error,31,https://hail.is,https://github.com/hail-is/hail/pull/7985,1,['error'],['error']
Availability,"eepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); ---> 31 raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; 32 except pyspark.sql.utils.CapturedException as e:; 33 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: SparkException: Job aborted due to stage failure: Task 0 in stage 23.0 failed 4 times, most recent failure: Lost task 0.3 in stage 23.0 (TID 26) (all-of-us-56-w-0.c.terra-vpc-sc-8f5cdfd2.internal executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_1691092255852_0001_01_000005 on host: all-of-us-56-w-0.c.terra-vpc-sc-8f5cdfd2.internal. Exit status: 137. Diagnostics: [2023-08-03 20:14:25.441]Container killed on request. Exit code is 137; [2023-08-03 20:14:25.442]Container exited with a non-zero exit code 137. ; [2023-08-03 20:14:25.442]Killed by external signal; .; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 23.0 failed 4 times, most recent failure: Lost task 0.3 in stage 23.0 (TID 26) (all-of-us-56-w-0.c.terra-vpc-sc-8f5cdfd2.internal executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_1691092255852_0001_01_000005 on host: all-of-us-56-w-0.c.terra-vpc-sc-8f5cdfd2.internal. Exit status: 137. Diagnostics: [2023-08-03 20:14:25.441]Container killed on request. Exit code is 137; [2023-08-03 20:14:25.442]Container exited with a non-zero exit code 137. ; [2023-08-03 20:14:25.442]Killed by external signal; .; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:6",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619:4451,failure,failure,4451,https://hail.is,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619,1,['failure'],['failure']
Availability,"ef=""https://github-redirect.dependabot.com/prometheus/client_python/issues/726"">#726</a></p>; <h2>0.12.0 / 2021-10-29</h2>; <p>[FEATURE] Exemplar support (excludes multiprocess) <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/669"">#669</a>; [ENHANCEMENT] Add support for Python 3.10 <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/706"">#706</a>; [ENHANCEMENT] Restricted Registry will handle metrics added after restricting <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/675"">#675</a>, <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/680"">#680</a><br />; [ENHANCEMENT] Raise a more helpful error if a metric is not observable <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/666"">#666</a>; [BUGFIX] Fix instance_ip_grouping_key not working on MacOS <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/687"">#687</a>; [BUGFIX] Fix assertion error from favicion.ico with Python 2.7 <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/715"">#715</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/prometheus/client_python/commit/a234283a853238dc73fa22651532590330fd72a1""><code>a234283</code></a> Release 0.13.1</li>; <li><a href=""https://github.com/prometheus/client_python/commit/557d123b349f3881cd6475a29ff4c79088a85a26""><code>557d123</code></a> Relax type constraints Timestamp</li>; <li><a href=""https://github.com/prometheus/client_python/commit/b44b63e59b168c6a8498ca31ddcce3ea5e46dcdc""><code>b44b63e</code></a> Declare <code>registry</code> on <code>MetricWrapperBase</code> as <code>Optional</code> (<a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/754"">#754</a>)</li>; <li><a href=""https://github.com/prometheus/client_python/commit/b3271a3f1842dbbddeab822063a3f08911f3c190""><code>b3271a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11515:2800,error,error,2800,https://hail.is,https://github.com/hail-is/hail/pull/11515,1,['error'],['error']
Availability,eflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745)is.hail.utils.HailException: malformed.vcf: caught htsjdk.tribble.TribbleException$InternalCodecException: The allele with index 10026357 is not defined in the REF/ALT columns in the record; offending line: 20	10026348	.	A	G	7535.22	PASS	HWP=1.0;AC=2;culprit=Inbreedi...; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:10); 	at is.hail.utils.package$.fatal(package.scala:20); 	at is.hail.utils.TextContext.wrapException(Context.scala:15); 	at is.hail.utils.WithContext.map(Context.scala:27); 	at is.hail.io.vcf.LoadVCF$$anonfun$14$$anonfun$apply$7.apply(LoadVCF.scala:301); 	at is.hail.io.vcf.LoadVCF$$anonfun$14$$anonfun$apply$7.apply(LoadVCF.scala:301); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$7$$anon$2.hasNext(OrderedRDD.scala:210); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1763); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1134); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1134); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882:6700,Error,ErrorHandling,6700,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882,1,['Error'],['ErrorHandling']
Availability,"eh / jinja2 folks but thought I'd let you know in case you hit this issue. ```; ../conda/envs/glow/lib/python3.7/site-packages/bokeh/core/templates.py:43: in <module>; from jinja2 import Environment, Markup, FileSystemLoader; E ImportError: cannot import name 'Markup' from 'jinja2' (/home/circleci/conda/envs/lib/python3.7/site-packages/jinja2/__init__.py); [error] java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; [error] 	at scala.Predef$.require(Predef.scala:281); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14(build.sbt:288); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14$adapted(build.sbt:278); [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49); [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62); [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:67); [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:280); [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19); [error] 	at sbt.Execute.work(Execute.scala:289); [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:280); [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); [error] 	at java.lang.Thread.run(Thread.java:748); [error] (hail / hailtest) java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; ```. To report a bug, fill in the information below. ; For support and feature ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11705:1441,Error,ErrorHandling,1441,https://hail.is,https://github.com/hail-is/hail/issues/11705,1,['Error'],['ErrorHandling']
Availability,"el.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081); at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128); at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070); at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163); at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463); at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858); at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138); at java.lang.Thread.run(Thread.java:748); Caused by: java.nio.channels.ClosedChannelException; at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source); 2019-07-14 20:55:04 YarnScheduler: ERROR: Lost executor 1 on bw2-sw-dp3j.c.seqr-project.internal: Slave lost; 2019-07-14 20:55:04 TaskSetManager: WARN: Lost task 1574.1 in stage 8.0 (TID 21699, bw2-sw-dp3j.c.seqr-project.internal, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Slave lost; 2019-07-14 20:55:04 TaskSetManager: WARN: Lost task 1559.1 in stage 8.0 (TID 21702, bw2-sw-dp3j.c.seqr-project.internal, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Slave lost; 2019-07-14 20:55:04 TaskSetManager: WARN: Lost task 1561.1 in stage 8.0 (TID 21701, bw2-sw-dp3j.c.seqr-project.internal, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Slave lost; 2019-07-14 20:55:04 TaskSetManager: WARN: Lost task 1541.2 in stage 8.0 (TID 21700, bw2-sw-dp3j.c.seqr-project.internal, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Slave lost; 2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6635:3972,ERROR,ERROR,3972,https://hail.is,https://github.com/hail-is/hail/issues/6635,1,['ERROR'],['ERROR']
Availability,"elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:168); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.1-408f188; Error summary: EsHadoopIllegalArgumentException: Spark SQL types are not handled through basic RDD saveToEs() calls; typically this is a mistake(as the SQL schema will be ignored). Use 'org.elasticsearch.spark.sql' package instead; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [ffc9fb0b99f64080b674ab7a07962df9] entered state [ERROR] while waiting for [DONE].; ```. Ideally it would get exported as nested objects: https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html#_using_literal_nested_literal_fields_for_arrays_of_objects. with elasticsearch mapping:; ```; u'vep': {'type': 'nested', 'properties': {u'category': {'type': 'keyword'}, u'major_consequence': {'type': 'keyword'}, u'gene_id': {'type': 'keyword'}, u'major_consequence_rank': {'type': 'integer'}, u'gene_symbol': {'type': 'keyword'}, u'transcript_id': {'type': 'keyword'}, u'hgvs': {'type': 'keyword'}, u'protein_id': {'type': 'keyword'}}}, ; ```. I thought about switching to saveJsonToEs here: ; https://github.com/hail-is/hail/blob/0.1/src/main/scala/is/hail/io/ElasticsearchConnector.scala#L33; but not sure how to auto-convert to json before exporting; https://www.elastic.co/guide/en/elasticsearch/hadoop/6.x/spark.html#spark-strea",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:11341,ERROR,ERROR,11341,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['ERROR'],['ERROR']
Availability,"elasticsearch; disable_index_for_fields=(""sortedTranscriptConsequences"", ),; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/load_dataset_to_es.py"", line 358, in export_to_elasticsearch; verbose=True,; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/hail_scripts.zip/hail_scripts/v01/utils/elasticsearch_client.py"", line 140, in export_vds_to_elasticsearch; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/hail_scripts.zip/hail_scripts/v01/utils/elasticsearch_client.py"", line 287, in export_kt_to_elasticsearch; File ""<decorator-gen-143>"", line 2, in export_elasticsearch; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/hail-0.1-es-6.2.4-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: EsHadoopIllegalArgumentException: Spark SQL types are not handled through basic RDD saveToEs() calls; typically this is a mistake(as the SQL schema will be ignored). Use 'org.elasticsearch.spark.sql' package instead. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 68 in stage 3.0 failed 20 times, most recent failure: Lost task 68.19 in stage 3.0 (TID 3771, vep-grch37-sw-9767.c.seqr-project.internal): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Spark SQL types are not handled through basic RDD saveToEs() calls; typically this is a mistake(as the SQL schema will be ignored). Use 'org.elasticsearch.spark.sql' package instead; 	at org.elasticsearch.spark.serialization.ScalaValueWriter.doWriteScala(ScalaValueWriter.scala:124); 	at org.elasticsearch.spark.serialization.ScalaValueWriter.doWrite(ScalaValueWriter.scala:50); 	at org.elasticsearch.spark.serialization.ScalaValueWriter$$anonfun$doWriteScala$3.apply(ScalaValueWriter.scala:78); 	at org.elasticsearch.spark.serialization.ScalaValueWriter$$anonfun$doWriteScala$3.apply(ScalaValueWriter.scala:77); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.elast",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:2464,failure,failure,2464,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['failure'],['failure']
Availability,"elease notes</summary>; <p><em>Sourced from <a href=""https://github.com/michel-kraemer/gradle-download-task/releases"">de.undercouch.download's releases</a>.</em></p>; <blockquote>; <h2>5.2.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Use pooling connection manager of Apache HttpClient instead of basic one. The basic one is not meant to be used by multiple threads. This fixes an issue that could cause an <code>IllegalStateException</code> with the message <code>Connection is still allocated</code>. Thanks to <a href=""https://github.com/dmarks2""><code>@â€‹dmarks2</code></a> for spotting this.</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.0</h2>; <p>New features:</p>; <ul>; <li>Add <code>eachFile</code> method that adds an action to be applied to each source URL before it is downloaded. The action can be used to modify the filename of the target file.</li>; <li>Add <code>runAsync</code> method to download extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:1119,down,downloaded,1119,https://hail.is,https://github.com/hail-is/hail/pull/12332,2,['down'],"['download', 'downloaded']"
Availability,"elect_rows(self, caller, key_struct, value_struct, pk_size); 2814; 2815 return cleanup(MatrixTable(base._jvds.selectRows(row._ast.to_hql(),; -> 2816 new_key))); 2817; 2818 @typecheck_method(caller=str,. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-c8ca698c6ed5.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NegativeArraySizeException: null. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 24 in stage 9.0 failed 20 times, most recent failure: Lost task 24.19 in stage 9.0 (TID 2874, berylc-sw-68wx.c.broad-mpg-gnomad.internal, executor 39): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:140); 	at is.hail.annotations.Region.allocate(Region.scala:153); 	at is.hail.annotations.Region.allocate(Region.scala:160); 	at is.hail.codegen.generated.C11.apply(Unknown Source); 	at is.hail.codegen.generated.C11.apply(Unknown Source); 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:650); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:245); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:218); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$czip$1$$anon$1.next(ContextRDD.scala:333); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3583:3647,failure,failure,3647,https://hail.is,https://github.com/hail-is/hail/issues/3583,1,['failure'],['failure']
Availability,"eles']; ----------------------------------------; [Stage 0:> (0 + 16) / 292]Traceback (most recent call last):; File ""/restricted/projectnb/ukbiobank/ad/analysis/ukb.v3/bgen_count.py"", line 13, in <module>; print(""Count:"",mt.count()); File ""/restricted/projectnb/genpro/github/hail/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 2131, in count; File ""/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 210, in deco; hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: Task 7 in stage 0.0 failed 4 times, most recent failure: Lost task 7.3 in stage 0.0 (TID 86, scc-q16.scc.bu.edu, executor 26): ExecutorLostFailure (executor 26 exited caused by one of the running tasks) Reason: Slave lost; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 0.0 failed 4 times, most recent failure: Lost task 7.3 in stage 0.0 (TID 86, scc-q16.scc.bu.edu, executor 26): ExecutorLostFailure (executor 26 exited caused by one of the running tasks) Reason: Slave lost; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFaile",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456417572:8006,failure,failure,8006,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456417572,1,['failure'],['failure']
Availability,"elf, exprs, broadcast_f); 1487 ; 1488 def cache(self):. ~/hail/python/hail/utils/misc.py in process_joins(obj, exprs, broadcast_f); 364 data = hail.Struct(**{b.uid: b.value for b in broadcasts}); 365 data_json = t._to_json(data); --> 366 left = broadcast_f(left, data_json, t._jtype); 367 ; 368 def cleanup(table):. ~/hail/python/hail/table.py in broadcast_f(left, data, jt); 1483 def _process_joins(self, *exprs):; 1484 def broadcast_f(left, data, jt):; -> 1485 return Table(left._jt.annotateGlobalJSON(data, jt)); 1486 return process_joins(self, exprs, broadcast_f); 1487 . ~/apache/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. ~/hail/python/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: JsonParseException: Non-standard token 'NaN': enable JsonParser.Feature.ALLOW_NON_NUMERIC_NUMBERS to allow; at [Source: {""__uid_3"": [NaN, Infinity, -Infinity]}; line: 1, column: 17]. Java stack trace:; com.fasterxml.jackson.core.JsonParseException: Non-standard token 'NaN': enable JsonParser.Feature.ALLOW_NON_NUMERIC_NUMBERS to allow; at [Source: {""__uid_3"": [NaN, Infinity, -Infinity]}; line: 1, column: 17]; 	at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1581); 	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:533); 	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._handleOddValue(ReaderBasedJsonParser.java:1602); 	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.nextToken(R",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3785:4787,Error,Error,4787,https://hail.is,https://github.com/hail-is/hail/issues/3785,1,['Error'],['Error']
Availability,"emory parameters, but once we have some user feedback I'd like to consider re-implementing computeGramianLargeN to use BLAS3 outer product on blocks of (fewer than m) rows of the n x m matrix rather than inner product on all pairs of columns, which I think will boost speed and make it reasonable to kill the smallN routine entirely (the current largeN case benefits from dot product of sparse vectors when using hard calls, but that also goes away when we move to generic 0.2 and rip out the hardcall/dosage complexity). Then it will be natural for maxSize to control the number of rows in a block. - Added accuracy and iterations parameters to allow users to tune Davies, with R settings for Davies (1e-6, 10k) as default. This allows users to re-run groups with tiny p-values if desired to obtain greater accuracy. The R package runs additional p-value routines that may be faster when the p-value is very small, will keep in mind should this become an issue. - In remark above the Skat class, I've added an overview of how math in paper corresponds to implementation. - Simplified and re-organized the Skat class to cut down on the number and complexity of passed parameters and make the meaning of the code more transparent with respect to the overview. Killed the SkatModel class. - Fixed an oversight whereby the largeN route was never called by logistic. - Fixed a bug whereby a weight of null was passed to DoubleNumericConversion.to and then Option rather than the other way around to prevent null match exception. - Modified R test code to use Adjustment=False to avoid the small-sample adjustment made in the logistic case when running using than 2000 samples. I could then reduce the Balding-Nichols example from 2001 and 500 samples and run logistic on the smaller test set as well. - Further cleaned up the tests, and added a test of the size column and maxSize parameter. - More descriptive error message should Cholesky or inversion fail in logistic case. - Updated docs accordingly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2248:1719,down,down,1719,https://hail.is,https://github.com/hail-is/hail/pull/2248,2,"['down', 'error']","['down', 'error']"
Availability,"emoving batch workers' reliance on the docker daemon and docker in general, in favor of a lower level of abstraction that gives us finer control over resources on the worker like overlays and network namespaces, allowing us to shortcut and pre-configure some of the overhead that goes into running a job. ## What this does differently; Currently, the high-level process for running a job involves communicating with the docker daemon to:; 1. Pull an image for a job; 2. Start a container from that image; 3. Run the container; 4. Delete the container and its associated resources. We offload some of these responsibilities into the worker code and onto [crun](https://github.com/containers/crun), a lightweight low-level runtime with the same API as `runc`, what docker uses to run containers. Once docker has retrieved an image, if we see that the pulled image has a new digest from one we currently have cached on the worker, we extract the image's filesystem into a directory on the worker's disk. We then:. - use `mount` to create an overlay on top of the image that the container will use as its rootfs; - use `xfs_quota` to limit the container's storage in the overlay; - invoke `crun` to run a container with the overlay as its root filesystem and an appropriate network namespace that we set up at worker-start time. Since we control the overlay, we can set the XFS quota before creating the container. So what was separate calls to docker create/start/run/delete is just a single `crun run`. Fewer steps, less back and forth with a single daemon, and pre-configuring the networks gives some sizable performance gains reliable, as well as reliable and consistent performance. ## What this doesn't solve; - Docker is still running the worker container. I don't see any real challenge to this it's just a matter of translating the docker parameters; - Still using docker to pull images and extract filesystems / environment variables from them. I don't have a substitute for this at the moment.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10376:1653,reliab,reliable,1653,https://hail.is,https://github.com/hail-is/hail/pull/10376,2,['reliab'],['reliable']
Availability,"emp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:8064,ERROR,ERROR,8064,https://hail.is,https://github.com/hail-is/hail/issues/9939,1,['ERROR'],['ERROR']
Availability,"empty>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/mem_unpack.h:471:8: required from â€˜void simdpp::arch_avx2::detail::insn::v_mem_unpack4_impl16_128(T&, T&, T&, T&) [with T = simdpp::arch_avx2::uint16<8>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/mem_unpack.h:585:29: required from â€˜void simdpp::arch_avx2::detail::insn::mem_unpack4(simdpp::arch_avx2::uint16<N>&, simdpp::arch_avx2::uint16<N>&, simdpp::arch_avx2::uint16<N>&, simdpp::arch_avx2::uint16<N>&) [with unsigned int N = 8]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/load_packed4.h:238:16: required from â€˜void simdpp::arch_avx2::detail::insn::v128_load_packed4(V&, V&, V&, V&, const char*) [with V = simdpp::arch_avx2::uint16<8>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/load_packed4.h:71:36: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint64<2>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint64<2>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint16<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:26,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:102:7: note: â€˜class simdpp::arch_avx2::uint64<2>â€™ declared here; class uint64<2, void> : public any_int64<2, uint64<2,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint16<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:140998,error,error,140998,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"ems()}; --> 896 base, cleanup = self._process_joins(*named_exprs.values()); 897; 898 for k, v in named_exprs.items():. /home/hail/hail.zip/hail/matrixtable.py in _process_joins(self, *exprs); 2205 for j in list(e._joins)[::-1]:; 2206 if j.uid not in used_uids:; -> 2207 left = j.join_function(left); 2208 all_uids.extend(j.temp_vars); 2209 used_uids.add(j.uid). /home/hail/hail.zip/hail/matrixtable.py in <lambda>(left); 2157 prefix = 'va'; 2158 joiner = lambda left: (; -> 2159 MatrixTable(left._jvds.annotateRowsVDS(right._jvds, uid))); 2160 else:; 2161 return self.rows().index(*exprs). /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 236 # this is a hack to suppress the original error's stack trace; 237 if _exception:; --> 238 raise _exception; 239; 240 return deco. FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.variant.MatrixTable.orderedRVDLeftJoinDistinctAndInsert(MatrixTable.scala:982); 	at is.hail.variant.MatrixTable.annotateRowsVDS(MatrixTable.scala:1449); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.ja",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3119:2219,error,error,2219,https://hail.is,https://github.com/hail-is/hail/issues/3119,1,['error'],['error']
Availability,"en/2.2.x/changes/#version-2-2-0</a></li>; <li>Milestone: <a href=""https://github.com/pallets/werkzeug/milestone/20?closed=1"">https://github.com/pallets/werkzeug/milestone/20?closed=1</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/werkzeug/blob/main/CHANGES.rst"">werkzeug's changelog</a>.</em></p>; <blockquote>; <h2>Version 2.2.2</h2>; <p>Released 2022-08-08</p>; <ul>; <li>Fix router to restore the 2.1 <code>strict_slashes == False</code> behaviour; whereby leaf-requests match branch rules and vice; versa. :pr:<code>2489</code></li>; <li>Fix router to identify invalid rules rather than hang parsing them,; and to correctly parse <code>/</code> within converter arguments. :pr:<code>2489</code></li>; <li>Update subpackage imports in :mod:<code>werkzeug.routing</code> to use the; <code>import as</code> syntax for explicitly re-exporting public attributes.; :pr:<code>2493</code></li>; <li>Parsing of some invalid header characters is more robust. :pr:<code>2494</code></li>; <li>When starting the development server, a warning not to use it in a; production deployment is always shown. :issue:<code>2480</code></li>; <li><code>LocalProxy.__wrapped__</code> is always set to the wrapped object when; the proxy is unbound, fixing an issue in doctest that would cause it; to fail. :issue:<code>2485</code></li>; <li>Address one <code>ResourceWarning</code> related to the socket used by; <code>run_simple</code>. :issue:<code>2421</code></li>; </ul>; <h2>Version 2.2.1</h2>; <p>Released 2022-07-27</p>; <ul>; <li>Fix router so that <code>/path/</code> will match a rule <code>/path</code> if strict; slashes mode is disabled for the rule. :issue:<code>2467</code></li>; <li>Fix router so that partial part matches are not allowed; i.e. <code>/2df</code> does not match <code>/&lt;int&gt;</code>. :pr:<code>2470</code></li>; <li>Fix router static part weighting, so that simpler routes are matched; before",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12119:2802,robust,robust,2802,https://hail.is,https://github.com/hail-is/hail/pull/12119,1,['robust'],['robust']
Availability,"en/anaconda/envs/hail-env/lib/python3.7/site-packages/hailctl/dataproc/cli.py"", line 99, in main; jmp[args.module].main(args, pass_through_args); File ""/Users/cchen/anaconda/envs/hail-env/lib/python3.7/site-packages/hailctl/dataproc/submit.py"", line 72, in main; check_call(cmd); File ""/Users/cchen/anaconda/envs/hail-env/lib/python3.7/subprocess.py"", line 347, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', 'ukbb_hdpca.py', '--cluster=chen', '--files=', '--py-files=/var/folders/6h/ll2dv8t15zs9pzf4g6kjb2rrt2fc9q/T/pyscripts_2740r0cj.zip', '--properties=']' returned non-zero exit status 1.; ```; The file does not exist but there are files with the same prefix but a `.000000001` suffix or similar. Grace reports (a possibly unrelated issue) https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/Cryptic.20array.20concordance.20error:; ```; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [873db5659acd43f7b539dcb17182959d] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""/miniconda3/bin/hailctl"", line 10, in <module>; sys.exit(main()); File ""/miniconda3/lib/python3.7/site-packages/hailctl/__main__.py"", line 90, in main; module(args); File ""/miniconda3/lib/python3.7/site-packages/hailctl/dataproc/cli.py"", line 99, in main; jmp[args.module].main(args, pass_through_args); File ""/miniconda3/lib/python3.7/site-packages/hailctl/dataproc/submit.py"", line 72, in main; check_call(cmd); File ""/miniconda3/lib/python3.7/subprocess.py"", line 341, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', '/Users/gtiao/ukbb_qc/scratch.py', '--cluster=gt1', '--files=', '--py-files=/var/folders/rn/t2xcx1ps4h96txll46qkkfsj2q8bnl/T/pyscripts_lh2k36v4.zip', '--properties=', '--', '--slack_channel', '@grace']' returned non-zero exit status 1.; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6565:1871,ERROR,ERROR,1871,https://hail.is,https://github.com/hail-is/hail/issues/6565,1,['ERROR'],['ERROR']
Availability,"end.py"", line 94, in execute; self._to_java_ir(ir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/utils/java.py"", line 227, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): is.hail.utils.HailException: foo: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; offending line: 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:20); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.utils.Context.wrapException(Context.scala:19); 	at is.hail.utils.WithContext.wrap(Context.scala:43); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:375); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:575); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:573); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.apply(ContextRDD.scala:405); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.apply(ContextRDD.scala:405); 	at is.hail.sparkextras.Conte",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:2860,Error,ErrorHandling,2860,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['Error'],['ErrorHandling']
Availability,"endencies</li>; <li>update linters</li>; <li>update docs deployment branches</li>; </ul>; </li>; <li>misc test/ci updates; <ul>; <li>test forks</li>; <li>tidy OS &amp; Python version tests</li>; <li>bump primary python version 3.7 =&gt; 3.8</li>; <li>beta py3.10 testing</li>; <li>fix py2.7 tests</li>; <li>better timeout handling</li>; </ul>; </li>; </ul>; <h2>tqdm v4.62.2 stable</h2>; <ul>; <li>fix notebook memory leak (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1216"">#1216</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tqdm/tqdm/commit/6791e8c5b3d6c30bdd2060c346996bfb5a6f10d1""><code>6791e8c</code></a> bump version, merge pull request <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1366"">#1366</a> from tqdm/devel</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/754186291e6b4e28ea8b56c9493adc03bf14c404""><code>7541862</code></a> tests: hotfix skip windows errors</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/8fb3d91f561e2a286a7fda13291eda16613dac39""><code>8fb3d91</code></a> fix ipywidgets&gt;=8 display</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/05e3d32a5fc8559e133e6d627d44afda93018637""><code>05e3d32</code></a> fix jupyterlab display</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/4f208e72552c4d916aa4fe6a955349ee8b2ed353""><code>4f208e7</code></a> bump version, merge branch 'slack'</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/1d29dec4b07de3dab34d3557baa9520cd9d46e38""><code>1d29dec</code></a> add <code>[slack]</code> extra dependency</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/4a1d10e19fdca00db47fd50725715dc5e4aa68e6""><code>4a1d10e</code></a> consistent ordering</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/bf6c960f60f8a390b47ac55d2ece3ffc419e5dcd""><code>bf6c960</code></a> emoji bars</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/7994aa828",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12260:4390,error,errors,4390,https://hail.is,https://github.com/hail-is/hail/pull/12260,1,['error'],['errors']
Availability,"ents. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.4.0/whatsnew/v1.4.0.html"">full whatsnew</a> for a list of all the changes. pandas 1.4.0 supports Python 3.8 and higher.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <pre><code>conda install -c conda-forge pandas; </code></pre>; <p>Or via PyPI:</p>; <pre><code>python3 -m pip install --upgrade pandas; </code></pre>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; <h2>Pandas 1.4.0rc0</h2>; <p>We are pleased to announce a release candidate for pandas 1.4.0. If all goes well, we'll release pandas 1.4.0 in about two weeks.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.4/whatsnew/v1.4.0.html"">whatsnew</a> for a list of all the changes. pandas 1.4.0 supports Python 3.8 and higher.</p>; <p>The release will be available on conda-forge and PyPI.</p>; <p>The release can be installed from PyPI</p>; <pre><code>python -m pip install --upgrade --pre pandas==1.4.0rc0; </code></pre>; <p>Or from conda-forge</p>; <pre><code>conda install -c conda-forge/label/pandas_rc pandas==1.4.0rc0; </code></pre>; <p>Please report any issues with the release candidate on the pandas issue tracker.</p>; <h2>Pandas 1.3.5</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pandas-dev/pandas/commit/06d230151e6f18fdb8139d09abf539867a8cd481""><code>06d2301</code></a> RLS: 1.4.1</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/47e3b409deb41f18e30e447579cba3a246db050e""><code>47e3b40</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45587"">#45587</a>: DOC: append deprecation (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45942"">#45942</",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11539:2030,avail,available,2030,https://hail.is,https://github.com/hail-is/hail/pull/11539,1,['avail'],['available']
Availability,"ependabot.com/pallets/click/issues/2238"">#2238</a> from pallets/release-8.1.2</li>; <li><a href=""https://github.com/pallets/click/commit/2f1c35a43652e565802c230dbc47a9a358a0c6fd""><code>2f1c35a</code></a> release version 8.1.2</li>; <li><a href=""https://github.com/pallets/click/commit/77dd30f8c54ebbdfbf461cedcd3d1fc1d7673f95""><code>77dd30f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2237"">#2237</a> from pallets/param-order</li>; <li><a href=""https://github.com/pallets/click/commit/b36bf8f9b36ab7db8cf03cd8eff714dfc33f0c29""><code>b36bf8f</code></a> restore Path param order</li>; <li><a href=""https://github.com/pallets/click/commit/a66119abe973f55b4f5e28dbb0da6f3c32c21af7""><code>a66119a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2236"">#2236</a> from shadchin/patch-1</li>; <li><a href=""https://github.com/pallets/click/commit/92cebe902aa7f03a89f6b261d897964dd9c5fa43""><code>92cebe9</code></a> fix readable path check error message</li>; <li><a href=""https://github.com/pallets/click/commit/456fbb6b0053fb01bedf90b64999b0a3c645a3cd""><code>456fbb6</code></a> start version 8.1.2</li>; <li><a href=""https://github.com/pallets/click/commit/a41e349ae738c55bce46dfb8715159463074d6e9""><code>a41e349</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2234"">#2234</a> from pallets/release-8.1.1</li>; <li><a href=""https://github.com/pallets/click/commit/3c301ebacbfe8ec7dc3d9d46ebf517082a8ee4b1""><code>3c301eb</code></a> release version 8.1.1</li>; <li><a href=""https://github.com/pallets/click/commit/d5741a2ca2ebc21d525c903f628b1bebad75b735""><code>d5741a2</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2233"">#2233</a> from henryiii/henryiii/fix/commandtype</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/click/compare/8.0.4...8.1.2"">compare view</a></li>; </u",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11801:5769,error,error,5769,https://hail.is,https://github.com/hail-is/hail/pull/11801,1,['error'],['error']
Availability,"ependabot.com/pallets/click/issues/2238"">#2238</a> from pallets/release-8.1.2</li>; <li><a href=""https://github.com/pallets/click/commit/2f1c35a43652e565802c230dbc47a9a358a0c6fd""><code>2f1c35a</code></a> release version 8.1.2</li>; <li><a href=""https://github.com/pallets/click/commit/77dd30f8c54ebbdfbf461cedcd3d1fc1d7673f95""><code>77dd30f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2237"">#2237</a> from pallets/param-order</li>; <li><a href=""https://github.com/pallets/click/commit/b36bf8f9b36ab7db8cf03cd8eff714dfc33f0c29""><code>b36bf8f</code></a> restore Path param order</li>; <li><a href=""https://github.com/pallets/click/commit/a66119abe973f55b4f5e28dbb0da6f3c32c21af7""><code>a66119a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2236"">#2236</a> from shadchin/patch-1</li>; <li><a href=""https://github.com/pallets/click/commit/92cebe902aa7f03a89f6b261d897964dd9c5fa43""><code>92cebe9</code></a> fix readable path check error message</li>; <li><a href=""https://github.com/pallets/click/commit/456fbb6b0053fb01bedf90b64999b0a3c645a3cd""><code>456fbb6</code></a> start version 8.1.2</li>; <li>See full diff in <a href=""https://github.com/pallets/click/compare/8.1.1...8.1.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=click&package-manager=pip&previous-version=8.1.1&new-version=8.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot act",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11726:2581,error,error,2581,https://hail.is,https://github.com/hail-is/hail/pull/11726,1,['error'],['error']
Availability,"ependencies</h3>; <ul>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.24 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2158"">#2158</a>) (<a href=""https://github.com/googleapis/java-storage/commit/4f5682a4f6d6d5372a2d382ae3e47dace490ca0d"">4f5682a</a>)</li>; </ul>; <h2>v2.26.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.25.0...v2.26.0"">2.26.0</a> (2023-08-03)</h2>; <h3>Features</h3>; <ul>; <li>Implement BufferToDiskThenUpload BlobWriteSessionConfig (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2139"">#2139</a>) (<a href=""https://github.com/googleapis/java-storage/commit/4dad2d5c3a81eda7190ad4f95316471e7fa30f66"">4dad2d5</a>)</li>; <li>Introduce new BlobWriteSession (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2123"">#2123</a>) (<a href=""https://github.com/googleapis/java-storage/commit/e0191b518e50a49fae0691894b50f0c5f33fc6af"">e0191b5</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li><strong>grpc:</strong> Return error if credentials are detected to be null (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2142"">#2142</a>) (<a href=""https://github.com/googleapis/java-storage/commit/b61a9764a9d953d2b214edb2b543b8df42fbfa06"">b61a976</a>)</li>; <li>Possible NPE when HttpStorageOptions deserialized (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2153"">#2153</a>) (<a href=""https://github.com/googleapis/java-storage/commit/68ad8e7357097e3dd161c2ab5f7a42a060a3702c"">68ad8e7</a>)</li>; <li>Update grpc default metadata projection to include acl same as json (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2150"">#2150</a>) (<a href=""https://github.com/googleapis/java-storage/commit/330e795040592e5df22d44fb5216ad7cf2448e81"">330e795</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency com.google.cloud:google-cloud-shared-dependencies to v3.14.0 (<a href=""https://redirect.github.com/google",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13605:2082,error,error,2082,https://hail.is,https://github.com/hail-is/hail/pull/13605,1,['error'],['error']
Availability,"eps, then a `vds.write`; The error is probably caused by one of the previous steps. If it helps I can comment out earlier parts to narrow down what actually triggers the error. ### What went wrong (all error messages here, including the full java stack trace):; ```; [Stage 6:> (0 + 8) / 5000]; [Stage 6:> (0 + 4) / 5000]; [Stage 6:> (0 + 8) / 5000]Traceback (most recent call last):; File ""/home/hail/hail.zip/hail/utils/java.py"", line 185, in handle_py4j; File ""/home/hail/hail.zip/hail/table.py"", line 1058, in aggregate; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o30335.query.; : org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 6.0 failed 20 times, most recent failure: Lost task 7.19 in stage 6.0 (TID 179, robert1-w-0.c.ccdg-wgs.internal, executor 4): java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.annotations.RegionValueBuilder.endStruct(RegionValueBuilder.scala:109); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2645); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2615); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3063:1318,failure,failure,1318,https://hail.is,https://github.com/hail-is/hail/issues/3063,1,['failure'],['failure']
Availability,"eption); --> 111 raise FatalError('%s\n\nJava stack trace:\n%s\n\nERROR SUMMARY: %s' % (deepest, full, deepest)); 112 except py4j.protocol.Py4JError as e:; 113 if e.args[0].startswith('An error occurred while calling'):. FatalError: HailException: malformed.vcf: caught htsjdk.tribble.TribbleException$InternalCodecException: The allele with index 10026357 is not defined in the REF/ALT columns in the record; offending line: 20	10026348	.	A	G	7535.22	PASS	HWP=1.0;AC=2;culprit=Inbreedi... Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3, localhost): is.hail.utils.HailException: malformed.vcf: caught htsjdk.tribble.TribbleException$InternalCodecException: The allele with index 10026357 is not defined in the REF/ALT columns in the record; offending line: 20	10026348	.	A	G	7535.22	PASS	HWP=1.0;AC=2;culprit=Inbreedi...; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:10); 	at is.hail.utils.package$.fatal(package.scala:20); 	at is.hail.utils.TextContext.wrapException(Context.scala:15); 	at is.hail.utils.WithContext.map(Context.scala:27); 	at is.hail.io.vcf.LoadVCF$$anonfun$14$$anonfun$apply$7.apply(LoadVCF.scala:301); 	at is.hail.io.vcf.LoadVCF$$anonfun$14$$anonfun$apply$7.apply(LoadVCF.scala:301); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$7$$anon$2.hasNext(OrderedRDD.scala:210); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1763); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1134); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1134); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882:2248,Error,ErrorHandling,2248,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882,1,['Error'],['ErrorHandling']
Availability,"eption.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		... 48 more; Caused by: com.google.api.client.http.HttpResponseException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 	at com.google.api.client.http.HttpResponseException$Builder.build(HttpResponseException.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ResumableMedia.lambda$startUploadForBlobInfo$0(ResumableMedia.java:40) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:27512,error,errors,27512,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['error'],['errors']
Availability,"eputy problem: it issues a callback in response; to a batch finishing. That callback is issued from within the cluster and; therefore can name many of our services which are not exposed to the; internet. With the introduction of TLS everywhere, a confused deputy callback; will fail because the victim will not receive a valid Batch certificate (batch; purposely does not send certificates with the callbacks). Batch only uses its; certificate to send a callback for CI. This is safe because we control CI and; ensure it is not compromised. In the long run, I want to fix batch to use an entirely different network for; callbacks. ### Notes of Annoyance. `aiohttp` silently ignores most invalid TLS requests, this makes debugging a TLS; issue difficult. `aiohttp`'s `raise_for_status` does not include the HTTP body in the; message. NGINX sometimes returns 400 in response to TLS issues with a proxy. It; includes crucial details in the HTTP body. I usually debug these issues by; sshing to the client pod and using curl to manually reproduce the error. Readiness and liveness probes cannot use HTTP. Although k8s supports HTTPS, it; does not support so-called ""mTLS"" or ""mutual TLS."" This is fancy verbiage for; servers that require clients to send trusted certificates. I will eventually require; this. There is a lot of information in GitHub issues and the Istio web pages; about this, but at the end of the day, kubernetes does not support this. TCP; probes are the best we can do. There [was a; PR](kubernetes/kubernetes#61231) to allow httpGet probes; to send the kubelet certificate, but it was closed because, apparently, the; [httpGet probes can be targeted at arbitrary IP; addresses](kubernetes/kubernetes#61231 (review)) (what; the hell?), ergo Confused Deputy. ### Future Work. - Require TLS 1.3 everywhere.; - Comply with Mozilla's ""Modern"" recommendations.; - [Incoming Trust](#incoming-trust).; - Refresh certificates after deploying new ones. ### Footnotes. [1] TLS: Transport Layer ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:10621,error,error,10621,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['error'],['error']
Availability,"eqr_loading.py"", line 54, in run; self.read_vcf_write_mt(); File ""/tmp/c7e0443c47b54e91b295e2bff7b554b9/seqr_loading.py"", line 84, in read_vcf_write_mt; mt.write(self.output().path, stage_locally=True, overwrite=True); File ""<decorator-gen-1092>"", line 2, in write; File ""/opt/conda/default/lib/python3.6/site-packages/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/conda/default/lib/python3.6/site-packages/hail/matrixtable.py"", line 2529, in write; Env.backend().execute(MatrixWrite(self._mir, writer)); File ""/opt/conda/default/lib/python3.6/site-packages/hail/backend/backend.py"", line 109, in execute; result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); File ""/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/opt/conda/default/lib/python3.6/site-packages/hail/utils/java.py"", line 225, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: cannot set missing field for required type +PCStruct{info:PCStruct{ALLELEID:PInt32}}. Java stack trace:; java.lang.RuntimeException: error while applying lowering 'InterpretNonCompilable'; 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:26); 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:27); 	at is.hail.backend.Backend.is$hail$backend$Backend$$_execute(Backend.scala:90); 	at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:78); 	at is.hail.backend.Backend$$anonfun$",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:48786,Error,Error,48786,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['Error'],['Error']
Availability,"equirement already satisfied: boto3<2.0,>=1.17 in /usr/local/lib/python3.7/site-packages (1.24.78); 922 | amazon-ebs: Requirement already satisfied: botocore<2.0,>=1.20 in /usr/local/lib/python3.7/site-packages (1.27.78); 923 | amazon-ebs: Collecting decorator<5; 924 | amazon-ebs: Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); 925 | amazon-ebs: Collecting Deprecated<1.3,>=1.2.10; 926 | amazon-ebs: Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB); 927 | amazon-ebs: Collecting dill<0.4,>=0.3.1.1; 928 | amazon-ebs: Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB); 929 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 95.8/95.8 kB 15.3 MB/s eta 0:00:00; 930 | amazon-ebs: Collecting google-auth==1.27.0; 931 | amazon-ebs: Downloading google_auth-1.27.0-py2.py3-none-any.whl (135 kB); 932 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 135.6/135.6 kB 30.6 MB/s eta 0:00:00; 933 | amazon-ebs: Collecting google-cloud-storage==1.25.*; 934 | amazon-ebs: Downloading google_cloud_storage-1.25.0-py2.py3-none-any.whl (73 kB); 935 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 73.4/73.4 kB 22.1 MB/s eta 0:00:00; 936 | amazon-ebs: Collecting humanize==1.0.0; 937 | amazon-ebs: Downloading humanize-1.0.0-py2.py3-none-any.whl (51 kB); 938 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 51.9/51.9 kB 14.6 MB/s eta 0:00:00; 939 | amazon-ebs: Collecting hurry.filesize==0.9; 940 | amazon-ebs: Downloading hurry.filesize-0.9.tar.gz (2.8 kB); 941 | amazon-ebs: Preparing metadata (setup.py): started; 942 | amazon-ebs: Preparing metadata (setup.py): finished with status 'done'; 943 | amazon-ebs: Collecting janus<1.1,>=0.6; 944 | amazon-ebs: Downloading janus-1.0.0-py3-none-any.whl (6.9 kB); 945 | amazon-ebs: Requirement already satisfied: Jinja2==3.0.3 in /usr/local/lib/python3.7/site-packages (3.0.3); 946 | amazon-ebs: Collecting nest_asyncio==1.5.4; 947 | amazon-ebs: Downloading nest_asyncio-1.5.4-py3-none-any.whl (5.1 kB); 948 | amazon-ebs: R",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:4635,Down,Downloading,4635,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,"equirement pyzmq<25,>=17, but you have pyzmq 25.1.1.; aiohttp-devtools 1.1 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1M2U3Mjk0MS01YmVjLTQ2MjYtYTY2Ny0wNzIxYjUwNjZ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14043:1659,avail,available,1659,https://hail.is,https://github.com/hail-is/hail/pull/14043,1,['avail'],['available']
Availability,"er file (~900 exomes) and I got:. hail: writekudu: caught exception:; org.kududb.client.NonRecoverableException: Too many attempts:; KuduRpc(method=IsCreateTableDone, tablet=null, attempt=6,; DeadlineTracker(timeout=10000, elapsed=7721),; Deferred@1490962783(state=PENDING, result=null, callback=(continuation; of Deferred@813205641 after; org.kududb.client.AsyncKuduClient$4@2c0dff53@739114835) ->; (continuation of Deferred@1748842457 after; org.kududb.client.AsyncKuduClient$5@42031f30@1107500848) ->; (continuation of Deferred@919337785 after; org.kududb.client.AsyncKuduClient$5@75ff6dd4@1979674068) ->; (continuation of Deferred@1962741581 after; org.kududb.client.AsyncKuduClient$5@2edd647d@786261117) ->; (continuation of Deferred@1202081964 after; org.kududb.client.AsyncKuduClient$5@49391441@1228477505),; errback=(continuation of Deferred@813205641 after; org.kududb.client.AsyncKuduClient$4@2c0dff53@739114835) ->; (continuation of Deferred@1748842457 after; org.kududb.client.AsyncKuduClient$5@42031f30@11075008; 48) -> (continuation of Deferred@919337785 after; org.kududb.client.AsyncKuduClient$5@75ff6dd4@1979674068) ->; (continuation of Deferred@1962741581 after; org.kududb.client.AsyncKuduClient$5@2edd647d@786261117) ->; (continuation of Deferred@1202081964 after; org.kududb.client.AsyncKuduClient$5@49391441@1228477505))). In the Kudu logs, I'm seeing tons of:. W0411 15:20:09.832504 129721 catalog_manager.cc:1880] TS; a72be89d736f49a799e1b544197675be: Create Tablet RPC failed for tablet; 6652d540f73a4ba5a0b9758a3aeeb1e4: Remote error: Service unavailable:; CreateTablet request on kudu.tserver.TabletServerAdminService from; 69.173.65.227:42904 dropped due to backpressure. The service queue is; full; it has 50 items. Suggestions on how to proceed? Should I increase the service queue size?. â€”; You are receiving this because you authored the thread.; Reply to this email directly or view it on GitHub; https://github.com/broadinstitute/hail/pull/242#issuecomment-208516279",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/242#issuecomment-208722298:2490,error,error,2490,https://hail.is,https://github.com/hail-is/hail/pull/242#issuecomment-208722298,1,['error'],['error']
Availability,er of jobs / number of files. The GCS best practices states the initial capacity is 5000 read requests / second per bucket including list operations until the bucket has time to scale up its capacity. https://cloud.google.com/storage/docs/request-rate#best-practices. ```. ==============================================================================; DIAGNOSTIC RESULTS ; ==============================================================================. ------------------------------------------------------------------------------; Latency ; ------------------------------------------------------------------------------; Operation Size Trials Mean (ms) Std Dev (ms) Median (ms) 90th % (ms); ========= ========= ====== ========= ============ =========== ===========; Delete 0 B 5 43.1 6.4 40.9 50.9 ; Delete 1 KiB 5 44.2 12.7 42.5 58.1 ; Delete 100 KiB 5 44.7 10.4 42.8 56.3 ; Delete 1 MiB 5 41.5 3.7 40.2 45.7 ; Download 0 B 5 74.6 7.9 73.2 84.0 ; Download 1 KiB 5 84.3 15.9 80.6 103.4 ; Download 100 KiB 5 81.9 16.0 82.7 99.6 ; Download 1 MiB 5 90.6 6.5 94.5 96.8 ; Metadata 0 B 5 23.6 2.7 23.6 26.3 ; Metadata 1 KiB 5 25.5 2.1 26.9 27.4 ; Metadata 100 KiB 5 26.2 3.6 27.3 29.9 ; Metadata 1 MiB 5 24.0 3.7 23.3 28.4 ; Upload 0 B 5 98.1 16.6 95.5 117.9 ; Upload 1 KiB 5 116.7 21.8 115.5 142.1 ; Upload 100 KiB 5 116.5 17.8 115.1 135.1 ; Upload 1 MiB 5 168.2 18.5 179.6 185.6 . ------------------------------------------------------------------------------; Write Throughput ; ------------------------------------------------------------------------------; Copied 5 512 MiB file(s) for a total transfer size of 2.5 GiB.; Write throughput: 977.7 Mibit/s.; Parallelism strategy: both. ------------------------------------------------------------------------------; Read Throughput ; ------------------------------------------------------------------------------; Copied 5 512 MiB file(s) for a total transfer size of 2.5 GiB.; Read throughput: 1.11 Gibit/s.; Parallelism strategy: both. -------------,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12923#issuecomment-1577071597:1360,Down,Download,1360,https://hail.is,https://github.com/hail-is/hail/issues/12923#issuecomment-1577071597,1,['Down'],['Download']
Availability,"er$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:393); 	at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:631); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:89); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:82); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:80); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:848); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:817); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:201); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:560); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:526); 	at java.base/java.lang.Thread.run(Thread.java:829). Hail version: 0.2.127-bb535cd096c5; Error summary: ClassTooLargeException: Class too large: __C67907collect_distributed_array_table_collect; ```. Hail log (in chunks, as it is 77 MB large):; [hail-20240227-1113-0.2.127-bb535cd096c5.log.chunk1.txt](https://github.com/hail-is/hail/files/14418491/hail-20240227-1113-0.2.127-bb535cd096c5.log.chunk1.txt); [hail-20240227-1113-0.2.127-bb535cd096c5.log.chunk2.txt](https://github.com/hail-is/hail/files/14418492/hail-20240227-1113-0.2.127-bb535cd096c5.log.chunk2.txt); [hail-20240227-1113-0.2.127-bb535cd096c5.log.chunk3.txt](https://github.com/hail-is/hail/files/14418560/hail-20240227-1113-0.2.127-bb535cd096c5.log.chunk3.txt); [hail-20240227-1113-0.2.127-bb535cd096c5.log.chunk4.txt](https://github.com/hail-is/hail/files/14418551/hail-20240227-1113-0.2.127-bb535cd096c5.log.chunk4.txt). ### Version. 0.2.127-bb535cd096c5. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14362:19744,Error,Error,19744,https://hail.is,https://github.com/hail-is/hail/issues/14362,1,['Error'],['Error']
Availability,"er-call</code> for non-direct parents (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6956"">#6956</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/fb6be5933ab270d542d80589be6fdea8abc82665""><code>fb6be59</code></a> Fix <code>undefined-variable</code> for <code>__class__</code> in inner methods (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6957"">#6957</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b9ecb4d70d23f7a6d05cc14e94c26fd8d3261d0f""><code>b9ecb4d</code></a> Fix false positive for <code>useless-super-delegation</code> for variadics (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6949"">#6949</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/f881219a66deaf9cef6467ba27c3385bc98dad82""><code>f881219</code></a> Bump pylint to 2.14.2, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/988d882b56f9eca8ba1825b86b59e92b824ca1c3""><code>988d882</code></a> Treat <code>--errors-only</code> as a disable, not a paired enable/disable (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6937"">#6937</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/386e7782b78a6e1baf0edd57cff893f3a08fb33c""><code>386e778</code></a> Mix incorrect parsing of multi-line options in <code>ini</code> files</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/7cd7c8cbedd8258ad151e13da4036b42602351a7""><code>7cd7c8c</code></a> Add regression test for <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6895"">#6895</a> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6898"">#6898</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/d6fa3416825fb7c398e4d8bee11a8ae0b3a39f07""><code>d6fa341</code></a> Mark <code>no-self-use</code> as moved to extensions (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6932"">#6932</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/P",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11971:1688,error,errors-only,1688,https://hail.is,https://github.com/hail-is/hail/pull/11971,1,['error'],['errors-only']
Availability,"er-event-loop-8"" Exception in thread ""refresh progress"" java.lang.OutOfMemoryError: GC overhead limit exceeded; at java.util.zip.ZipCoder.getBytes(ZipCoder.java:80); at java.util.zip.ZipFile.getEntry(ZipFile.java:310); at java.util.jar.JarFile.getEntry(JarFile.java:240); at java.util.jar.JarFile.getJarEntry(JarFile.java:223); at sun.misc.URLClassPath$JarLoader.getResource(URLClassPath.java:1042); at sun.misc.URLClassPath.getResource(URLClassPath.java:239); at java.net.URLClassLoader$1.run(URLClassLoader.java:365); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.appl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:2049,Heartbeat,HeartbeatReceiver,2049,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Heartbeat'],['HeartbeatReceiver']
Availability,"er; as such it's easier to hide sensitive information. . Mobile and desktop apps have dealt with this for 2 decades. We should build a robust infrastructure, and not one that requires server-rendered web pages for security. Currently it seems Auth0 may not be the best choice: it does not interface for us with third-party API's; requires us to either insecurely store 3rd party access tokens (with at least 1 extra round trip), or altogether proxy all third-party requests through our own resource server... Firebase Auth seems to avoid these limitations. ## TODO:; 1. Create a structured description of this pull request; 2. Incorporate Firebase Auth in place of Auth0 for 3rd party access token benefits.; 3: Scorecard; 3a. Draft working GraphQL V4 scorecard implementation; 3b. Finish authenticated GraphQL V4 scorecard implementation; 4. Batch; 4a: Setup dev batch endpoint; 4b: Call batch endpoint (no auth), and return any data; 4c: List all available jobs; * By querying Batch api, or Kubernetes directly; 4d: Receive current status of 1 job; 4e: Authentication; 4f: Polish (longest step): make interacting with batch achievable within perceived 16ms.; * goal: subscribe to events in web socket; * may want to save user job state in a Hail-controlled database (possible to use Firebase or Mongo, may prefer relational db, maybe Postgres or MySQL).; 4other: Figure out state question (sufficient to use Kubernetes); 5. Basic notebook interface.; 6. Connect websocket logic (non-GraphQL); 7. Authenticate web socket via Oauth2; 8. Incorporate GraphQL subscriptions (first: GitHub API); 9. Write tests; 10. Mock GraphQL endpoints; 11. Integrate web and api server bits into CI (maybe should be prioritized earlier...I prefer to get draft of major functions done first; am new to writing tests for React/Node). ## Near-term goals (<= 6 mo); 1. Upload, download; 2. Launch clusters, pay for them; 3. ?. ## Longer-term goals; 1. Much simpler interface to Hail. I would like steps that can be perform",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931:7101,avail,available,7101,https://hail.is,https://github.com/hail-is/hail/pull/4931,1,['avail'],['available']
Availability,erExecutor.launchContainer(LinuxContainerExecutor.java:371); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:303); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Shell output: main : command provided 1; main : run as user is farrell; main : requested yarn user is farrell. Container exited with a non-zero exit code 1. 2019-01-22 13:11:53 BlockManagerMaster: INFO: Removal of executor 8 requested; 2019-01-22 13:11:53 BlockManagerMasterEndpoint: INFO: Trying to remove executor 8 from BlockManagerMaster.; 2019-01-22 13:11:53 YarnSchedulerBackend$YarnDriverEndpoint: INFO: Asked to remove non-existent executor 8; 2019-01-22 13:11:55 YarnScheduler: ERROR: Lost executor 9 on scc-q01.scc.bu.edu: Container marked as failed: container_e2435_1542127286896_0174_01_000010 on host: scc-q01.scc.bu.edu. Exit status: 1. Diagnostics: Exception from container-launch.; Container id: container_e2435_1542127286896_0174_01_000010; Exit code: 1; Stack trace: ExitCodeException exitCode=1:; at org.apache.hadoop.util.Shell.runCommand(Shell.java:576); at org.apache.hadoop.util.Shell.run(Shell.java:487); at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:753); at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:371); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:303); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.u,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:115987,ERROR,ERROR,115987,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['ERROR'],['ERROR']
Availability,"erba/hail/python/hail/dataset.py in linreg(self, y, covariates, root, min_ac, min_af); 2216 """"""; 2217; -> 2218 jvds = self._jvdf.linreg(y, jarray(env.jvm.java.lang.String, covariates), root, min_ac, min_af); 2219 return VariantDataset(self.hc, jvds); 2220. /Users/tpoterba/spark-2.0.2-bin-hadoop2.7/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /Users/tpoterba/spark-2.0.2-bin-hadoop2.7/python/pyspark/sql/utils.pyc in deco(*a, **kw); 61 def deco(*a, **kw):; 62 try:; ---> 63 return f(*a, **kw); 64 except py4j.protocol.Py4JJavaError as e:; 65 s = e.java_exception.toString(). /Users/tpoterba/hail/python/hail/java.py in deco(*a, **kw); 113 if e.args[0].startswith('An error occurred while calling'):; 114 msg = 'An error occurred while calling into JVM, probably due to invalid parameter types'; --> 115 raise FatalError('%s\n\nJava stack trace:\n%s\n\nERROR SUMMARY: %s' % (msg, e.message, msg)); 116; 117 return deco. FatalError: An error occurred while calling into JVM, probably due to invalid parameter types. Java stack trace:; An error occurred while calling o29.linreg. Trace:; py4j.Py4JException: Method linreg([class java.util.ArrayList, class [Ljava.lang.String;, class java.lang.String, class java.lang.Integer, class java.lang.Double]) does not exist; 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326); 	at py4j.Gateway.invoke(Gateway.java:272); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). ERROR SUMMARY: An error occurred while calling into JVM, probably due to ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287190787:1169,error,error,1169,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287190787,2,['error'],['error']
Availability,"ernetes#92438</a>, <a href=""https://github.com/liggitt""><code>@â€‹liggitt</code></a>) [SIG API Machinery, Auth, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Network, Node, Release, Storage and Testing]</li>; <li>Hide managedFields from kubectl edit command (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91946"">kubernetes/kubernetes#91946</a>, <a href=""https://github.com/soltysh""><code>@â€‹soltysh</code></a>) [SIG CLI]</li>; <li>K8s.io/apimachinery - scheme.Convert() now uses only explicitly registered conversions - default reflection based conversion is no longer available. <code>+k8s:conversion-gen</code> tags can be used with the <code>k8s.io/code-generator</code> component to generate conversions. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/90018"">kubernetes/kubernetes#90018</a>, <a href=""https://github.com/wojtek-t""><code>@â€‹wojtek-t</code></a>) [SIG API Machinery, Apps and Testing]</li>; <li>Kube-proxy: add <code>--bind-address-hard-fail</code> flag to treat failure to bind to a port as fatal (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89350"">kubernetes/kubernetes#89350</a>, <a href=""https://github.com/SataQiu""><code>@â€‹SataQiu</code></a>) [SIG Cluster Lifecycle and Network]</li>; <li>Kubebuilder validation tags are set on metav1.Condition for CRD generation (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92660"">kubernetes/kubernetes#92660</a>, <a href=""https://github.com/damemi""><code>@â€‹damemi</code></a>) [SIG API Machinery]</li>; <li>Kubelet's --runonce option is now also available in Kubelet's config file as <code>runOnce</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89128"">kubernetes/kubernetes#89128</a>, <a href=""https://github.com/vincent178""><code>@â€‹vincent178</code></a>) [SIG Node]</li>; <li>Kubelet: add '--logging-format' flag to support structured logging (<a href=""https://github-redirect.d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:9235,failure,failure,9235,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['failure'],['failure']
Availability,"erride>::run(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint32<4>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint32<4>]â€™; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:133:36: required from â€˜simdpp::arch_avx2::uint16<8>& simdpp::arch_avx2::uint16<8>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint32<4, simdpp::arch_avx2::expr_bit_and<simdpp::arch_avx2::uint32<4, simdpp::arch_avx2::uint16<8> >, simdpp::arch_avx2::uint32<4, simdpp::arch_avx2::uint32<4> > > >]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/unzip_lo.h:80:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint16<8>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint16<8>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint32<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:21,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:104:7: note: â€˜class simdpp::arch_avx2::uint16<8>â€™ declared here; class uint16<8, void> : public any_int16<8, uint16<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint32<8>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:32601,error,error,32601,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"error for using ""importannotations table""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/561:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/issues/561,1,['error'],['error']
Availability,error if compiling PackDecoder on master,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3521:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/pull/3521,1,['error'],['error']
Availability,error in annotation filtering for t2d vcf,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/120:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/issues/120,1,['error'],['error']
Availability,error in linreg aggregator based on placement of '1',MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8349:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/issues/8349,1,['error'],['error']
Availability,"error in test java:; ```; [[TestNGClassFinder]] Unable to read methods on class is.hail.relocated.com.indeed.util.varexport.servlet.ViewExportedVariablesServlet - unable to resolve class reference freemarker/template/ObjectWrapper; Exception in thread ""main"" java.lang.NoClassDefFoundError: freemarker/template/ObjectWrapper; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8576#issuecomment-615459260:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/pull/8576#issuecomment-615459260,1,['error'],['error']
Availability,error message for TStruct.insert when inserting into missing struct with a required field,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2424:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/pull/2424,1,['error'],['error']
Availability,error message from lambda in filter expr,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1623:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/issues/1623,1,['error'],['error']
Availability,error message needs fixing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3362:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/issues/3362,1,['error'],['error']
Availability,error with textTableReader --impute with one-line file,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/750:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/issues/750,1,['error'],['error']
Availability,ers/dking/projects/hail/hail/scripts; + arguments='HAIL_PIP_VERSION HAIL_VERSION GIT_VERSION REMOTE WHEEL GITHUB_OAUTH_HEADER_FILE HAIL_GENETICS_HAIL_IMAGE HAIL_GENETICS_HAIL_IMAGE_PY_3_10 HAIL_GENETICS_HAIL_IMAGE_PY_3_11 HAIL_GENETICS_HAILTOP_IMAGE HAIL_GENETICS_VEP_GRCH37_85_IMAGE HAIL_GENETICS_VEP_GRCH38_95_IMAGE WHEEL_FOR_AZURE WEBSITE_TAR'; + for varname in '$arguments'; + '[' -z 0.2.128 ']'; + echo HAIL_PIP_VERSION=0.2.128; HAIL_PIP_VERSION=0.2.128; + for varname in '$arguments'; + '[' -z 0.2.128-91d328e7fc84 ']'; + echo HAIL_VERSION=0.2.128-91d328e7fc84; HAIL_VERSION=0.2.128-91d328e7fc84; + for varname in '$arguments'; + '[' -z 91d328e7fc84686936ffd4f370c8c104b2d78b2a ']'; + echo GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a; GIT_VERSION=91d328e7fc84686936ffd4f370c8c104b2d78b2a; + for varname in '$arguments'; + '[' -z origin ']'; + echo REMOTE=origin; REMOTE=origin; + for varname in '$arguments'; + '[' -z build/deploy/dist/hail-0.2.128-py3-none-any.whl ']'; + echo WHEEL=build/deploy/dist/hail-0.2.128-py3-none-any.whl; WHEEL=build/deploy/dist/hail-0.2.128-py3-none-any.whl; + for varname in '$arguments'; + '[' -z abc123 ']'; + echo GITHUB_OAUTH_HEADER_FILE=abc123; GITHUB_OAUTH_HEADER_FILE=abc123; + for varname in '$arguments'; + '[' -z abc123 ']'; + echo HAIL_GENETICS_HAIL_IMAGE=abc123; HAIL_GENETICS_HAIL_IMAGE=abc123; + for varname in '$arguments'; + '[' -z a ']'; + echo HAIL_GENETICS_HAIL_IMAGE_PY_3_10=a; HAIL_GENETICS_HAIL_IMAGE_PY_3_10=a; + for varname in '$arguments'; + '[' -z b ']'; + echo HAIL_GENETICS_HAIL_IMAGE_PY_3_11=b; HAIL_GENETICS_HAIL_IMAGE_PY_3_11=b; + for varname in '$arguments'; + '[' -z c ']'; + echo HAIL_GENETICS_HAILTOP_IMAGE=c; HAIL_GENETICS_HAILTOP_IMAGE=c; + for varname in '$arguments'; + '[' -z d ']'; + echo HAIL_GENETICS_VEP_GRCH37_85_IMAGE=d; HAIL_GENETICS_VEP_GRCH37_85_IMAGE=d; + for varname in '$arguments'; + '[' -z e ']'; + echo HAIL_GENETICS_VEP_GRCH38_95_IMAGE=e; HAIL_GENETICS_VEP_GRCH38_95_IMAGE=e; + for varname in '$argum,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409:12027,echo,echo,12027,https://hail.is,https://github.com/hail-is/hail/pull/14323#issuecomment-1955223409,1,['echo'],['echo']
Availability,"es portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6050294](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6050294) | `cryptography:` <br> `41.0.7 -> 42.0.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Information Exposure <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6126975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6126975) | `cryptography:` <br> `41.0.7 -> 42.0.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxNjVmNDVkMi00ZDM3LTRmNzAtOGU1OC00OGIxOGJhN",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14203:1501,avail,available,1501,https://hail.is,https://github.com/hail-is/hail/pull/14203,1,['avail'],['available']
Availability,"es some new features, bug fixes, and performance improvements. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.5.0/whatsnew/v1.5.0.html"">full whatsnew</a> for a list of all the changes. pandas 1.5.0 supports Python 3.8 and higher.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <p><code>conda install -c conda-forge pandas</code></p>; <p>Or via PyPI:</p>; <p><code>python3 -m pip install --upgrade pandas</code></p>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; <h2>Pandas 1.5.0rc0</h2>; <p>We are pleased to announce a release candidate for pandas 1.5.0. If all goes well, we'll release pandas 1.5.0 in about two weeks.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.5/whatsnew/v1.5.0.html"">whatsnew</a> for a list of all the changes.</p>; <p>The release will be available on conda-forge and PyPI.</p>; <p>The release can be installed from PyPI</p>; <pre><code>python -m pip install --upgrade --pre pandas==1.5.0rc0; </code></pre>; <p>Or from conda-forge</p>; <pre><code>conda install -c conda-forge/label/pandas_rc pandas==1.5.0rc0; </code></pre>; <p>Please report any issues with the release candidate on the pandas issue tracker.</p>; <h2>Pandas 1.4.4</h2>; <p>This is a patch release in the 1.4.x series and includes some regression and bug fixes. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.4.4/whatsnew/v1.4.4.html"">full whatsnew</a> for a list of all the changes.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <pre><code>conda install pandas; </code></pre>; <p>Or via PyPI:</p>; <pre><code>python3 -m pip install --upgrade pandas; </code></pre>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12292:1286,avail,available,1286,https://hail.is,https://github.com/hail-is/hail/pull/12292,1,['avail'],['available']
Availability,"es were respected (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3237"">#3237</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Recommend using BlackConnect in IntelliJ IDEs (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3150"">#3150</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Vim plugin: prefix messages with <code>Black: </code> so it's clear they come from Black (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3194"">#3194</a>)</li>; <li>Docker: changed to a /opt/venv installation + added to PATH to be available to non-root users (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3202"">#3202</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>Change from deprecated <code>asyncio.get_event_loop()</code> to create our event loop which removes DeprecationWarning (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3164"">#3164</a>)</li>; <li>Remove logging from internal <code>blib2to3</code> library since it regularly emits error logs about failed caching that can and should be ignored (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3193"">#3193</a>)</li>; </ul>; <h3>Parser</h3>; <ul>; <li>Type comments are now included in the AST equivalence check consistently so accidental deletion raises an error. Though type comments can't be tracked when running on PyPy 3.7 due to standard library limitations. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2874"">#2874</a>)</li>; </ul>; <h3>Performance</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/black/blob/main/CHANGES.md"">black's changelog</a>.</em></p>; <blockquote>; <h2>22.8.0</h2>; <h3>Highlights</h3>; <ul>; <li>Python 3.11 is now supported, except for <em>blackd</em> as aiohttp does not support 3.11 as; of publishing (<a href=""https://github-redirect.dependabot.com/psf/black/issue",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:4476,error,error,4476,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['error'],['error']
Availability,"es. Notably, <code>Allele</code> became an interface instead of a concrete class. <code>SimpleAllele</code> may be used as a replacement if you have classes which previously subclassed allele.</p>; <p>New Plugin Infrastructure:; 6a60de7c2 Move API marker annotations into new annotation package. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1558"">#1558</a>); 7ac95d5f7 Plugin framework and interfaces for versioned file format codecs (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1525"">#1525</a>); d40fe5412 Beta implementation of Bundles. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1546"">#1546</a>)</p>; <p>CRAM; 489c4192d Support CRAM reference regions. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1605"">#1605</a>); 22aec6782 Fix decoding of CRAM Scores read feature during normalization. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1592"">#1592</a>); 6507249a4 Make the CRAM MD5 failure message more user friendly. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1607"">#1607</a>); b5af659e6 Fix restoration of read base feature code. <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1379"">#1379</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1590"">#1590</a>); e63c34a92 Ignore TC, TN on CRAM read (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1578"">#1578</a>)</p>; <p>BAM/SAM; 1449dec45 Support loading of CSI from URLs/streams. <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1507"">#1507</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1595"">#1595</a>); a38c78d6c Add an option to SAMFileWriter to disable checking of ordering of recâ€¦ (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1599"">#1599</a>); 51aa6ed2b Validate that SAM header tag keys are exactly 2 characters long (<a href",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:2420,failure,failure,2420,https://hail.is,https://github.com/hail-is/hail/pull/12229,2,['failure'],['failure']
Availability,"es/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; INFO	2022-03-02 19:06:35,620	pool.py	create_instances:244	pool standard n_instances 1 {'pending': 0, 'active': 1, 'inactive': 0, 'deleted': 0} free_cores 0.0 live_free_cores 8.0 ready_cores 11.0; INFO	2022-03-02 19:06:35,620	pool.py	create_instances_from_ready_cores:206	creating 1 new instances; INFO	2022-03-02 19:06:35,848	pool.py	create_instances:244	pool highmem n_instances 1 {'pending': 0, 'active': 1, 'inactive': 0, 'deleted': 0} free_cores 4.0 live_free_cores 4.0 ready_cores 0.0; ERROR	2022-03-02 19:06:37,336	job.py	schedule_job:473	error while scheduling job (94, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:9905,error,error,9905,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['error'],['error']
Availability,"ess=progress); /usr/local/lib/python3.8/dist-packages/hail/backend/service_backend.py:451: in _rpc; result_bytes = await retry_transient_errors(self._read_output, ir, iodir + '/out'); /usr/local/lib/python3.8/dist-packages/hailtop/utils/utils.py:781: in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); /usr/local/lib/python3.8/dist-packages/hailtop/utils/utils.py:794: in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <hail.backend.service_backend.ServiceBackend object at 0x7f63d6b90bb0>; ir = <hail.ir.ir.TableWrite object at 0x7f63d4e70c70>; output_uri = 'hail-az://haildevtest/test/tmp/hail/FCIxoO1REfjctjXVpyHiF1/vwzzlTSQqo/out'. async def _read_output(self, ir: Optional[BaseIR], output_uri: str) -> bytes:; assert self._batch; ; try:; driver_output = await self._async_fs.open(output_uri); except FileNotFoundError as exc:; raise FatalError('Hail internal error. Please contact the Hail team and provide the following information.\n\n' + yamlx.dump({; 'service_backend_debug_info': self.debug_info(),; 'batch_debug_info': await self._batch.debug_info(); })) from exc; ; async with driver_output as outfile:; success = await read_bool(outfile); if success:; return await read_bytes(outfile); ; short_message = await read_str(outfile); expanded_message = await read_str(outfile); error_id = await read_int(outfile); ; reconstructed_error = fatal_error_from_java_error_triplet(short_message, expanded_message, error_id); if ir is None:; raise reconstructed_error; > raise reconstructed_error.maybe_user_error(ir); E hail.utils.java.FatalError: NativeIoException: readAddress(..) failed: Connection reset by peer; E ; E Java stack trace:; E io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer; E 	at ; E ; E ; E ; E Hail version: 0.2.115-330031a5d973; E Error summary: NativeI",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12980:3603,error,error,3603,https://hail.is,https://github.com/hail-is/hail/issues/12980,1,['error'],['error']
Availability,"ession source mismatch, which may be due to `annotate_entries` being done separately from `_annotate_all` in the joiner for `index_entries` AST:; ```; def joiner(left: MatrixTable):; localized = Table(self._jvds.localizeEntries(row_uid)); src_cols_indexed = self.cols().add_index(col_uid); src_cols_indexed = src_cols_indexed.annotate(**{col_uid: hl.int32(src_cols_indexed[col_uid])}); left = left._annotate_all(row_exprs = {row_uid: localized.index(*row_exprs)[row_uid]},; col_exprs = {col_uid: src_cols_indexed.index(*col_exprs)[col_uid]}); return left.annotate_entries(**{uid: left[row_uid][left[col_uid]]}); ```. ### Hail version:; master; b1ac051d34bcc4c26fe9dea58aeac53038f2963e. ### What you did:. ```; mt = hl.utils.range_matrix_table(4, 4); mt2 = hl.utils.range_matrix_table(4, 4); mt2 = mt2.annotate_entries(x=mt2.row_idx + mt2.col_idx); mt.select_entries(a=mt2[mt.row_idx, mt.col_idx].x,; b=mt2[mt.row_idx, mt.col_idx].x)._force_count_rows(); ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; Error; Traceback (most recent call last):; File ""/Users/jbloom/anaconda/envs/py36/lib/python3.6/unittest/case.py"", line 59, in testPartExecutor; yield; File ""/Users/jbloom/anaconda/envs/py36/lib/python3.6/unittest/case.py"", line 605, in run; testMethod(); File ""/Users/jbloom/hail/python/hail/tests/test_api.py"", line 1557, in test_force_bug; b=mt2[mt.row_idx, mt.col_idx].x)._force_count_rows(); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 1171, in select_entries; return self._select_entries(""MatrixTable.select_entries"", hl.struct(**entry)); File ""/Users/jbloom/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2844, in _select_entries; base, cleanup = self._process_joins(s); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2503, in _process_joins; return process_joins(self, exprs, broadcast_f); File ""/Users/jbloom/hail/p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3763:1164,error,error,1164,https://hail.is,https://github.com/hail-is/hail/issues/3763,1,['error'],['error']
Availability,"est version of jinja2. Downgrading jinja2 to 3.0.0 solves the problem, and it seems like other people have seen this too with the latest release of jinja2:. https://github.com/holoviz/panel/issues/3260. This may be transient and may be solved by bokeh / jinja2 folks but thought I'd let you know in case you hit this issue. ```; ../conda/envs/glow/lib/python3.7/site-packages/bokeh/core/templates.py:43: in <module>; from jinja2 import Environment, Markup, FileSystemLoader; E ImportError: cannot import name 'Markup' from 'jinja2' (/home/circleci/conda/envs/lib/python3.7/site-packages/jinja2/__init__.py); [error] java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; [error] 	at scala.Predef$.require(Predef.scala:281); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14(build.sbt:288); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14$adapted(build.sbt:278); [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49); [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62); [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:67); [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:280); [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19); [error] 	at sbt.Execute.work(Execute.scala:289); [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:280); [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); [err",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11705:1198,error,error,1198,https://hail.is,https://github.com/hail-is/hail/issues/11705,1,['error'],['error']
Availability,"est='wald', covariates=[1.0]).describe(); ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[9], line 4; 2 mt = hl.utils.range_matrix_table(2,2); 3 mt = mt.annotate_entries(prod = mt.row_idx * mt.col_idx); ----> 4 hl.logistic_regression_rows(y=mt.row_idx, x=mt.prod, test='wald', covariates=[1.0]).describe(). File <decorator-gen-1708>:2, in logistic_regression_rows(test, y, x, covariates, pass_through, max_iterations, tolerance). File ~/projects/hail/hail/python/hail/typecheck/check.py:587, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 584 @decorator; 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_). File ~/projects/hail/hail/python/hail/methods/statgen.py:921, in logistic_regression_rows(test, y, x, covariates, pass_through, max_iterations, tolerance); 918 if not y_is_list:; 919 result = result.transmute(**result.logistic_regression[0]); --> 921 return result.persist(). File <decorator-gen-1242>:2, in persist(self, storage_level). File ~/projects/hail/hail/python/hail/typecheck/check.py:587, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 584 @decorator; 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_). File ~/projects/hail/hail/python/hail/table.py:2112, in Table.persist(self, storage_level); 2076 @typecheck_method(storage_level=storage_level); 2077 def persist(self, storage_level='MEMORY_AND_DISK') -> 'Table':; 2078 """"""Persist this table in memory or on disk.; 2079 ; 2080 Examples; (...); 2110 Persisted table.; 2111 """"""; -> 2112 return Env.backend().persist(self). File ~/projects/hail/hail/python/hail/backend/backend.py",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13788:1236,toler,tolerance,1236,https://hail.is,https://github.com/hail-is/hail/issues/13788,1,['toler'],['tolerance']
Availability,estimate standard error for h2 in lmmreg,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1720:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/1720,1,['error'],['error']
Availability,"et.py in linreg(self, y, covariates, root, min_ac, min_af); 2216 """"""; 2217; -> 2218 jvds = self._jvdf.linreg(y, jarray(env.jvm.java.lang.String, covariates), root, min_ac, min_af); 2219 return VariantDataset(self.hc, jvds); 2220. /Users/tpoterba/spark-2.0.2-bin-hadoop2.7/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /Users/tpoterba/spark-2.0.2-bin-hadoop2.7/python/pyspark/sql/utils.pyc in deco(*a, **kw); 61 def deco(*a, **kw):; 62 try:; ---> 63 return f(*a, **kw); 64 except py4j.protocol.Py4JJavaError as e:; 65 s = e.java_exception.toString(). /Users/tpoterba/hail/python/hail/java.py in deco(*a, **kw); 113 if e.args[0].startswith('An error occurred while calling'):; 114 msg = 'An error occurred while calling into JVM, probably due to invalid parameter types'; --> 115 raise FatalError('%s\n\nJava stack trace:\n%s\n\nERROR SUMMARY: %s' % (msg, e.message, msg)); 116; 117 return deco. FatalError: An error occurred while calling into JVM, probably due to invalid parameter types. Java stack trace:; An error occurred while calling o29.linreg. Trace:; py4j.Py4JException: Method linreg([class java.util.ArrayList, class [Ljava.lang.String;, class java.lang.String, class java.lang.Integer, class java.lang.Double]) does not exist; 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326); 	at py4j.Gateway.invoke(Gateway.java:272); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). ERROR SUMMARY: An error occurred while calling into JVM, probably due to invalid parameter types```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287190787:1436,error,error,1436,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287190787,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"ethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). org.apache.spark.SparkException: Job aborted due to stage failure: Task 40 in stage 7.0 failed 20 times, most recent failure: Lost task 40.19 in stage 7.0 (TID 3171, seqr-loading-cluster-sw-z91p.c.seqr-project.internal, executor 14): is.hail.utils.HailException: cannot set missing field for required type +PCStruct{info:PCStruct{ALLELEID:PInt32}}; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:74); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:210); 	at is.hail.rvd.RVD$$anonfun$24$$anonfun$apply$17.apply(RVD.scala:974); 	at is.hail.rvd.RVD$$anonfun$24$$anonfun$apply$17.apply(RVD.scala:967); 	at is.hail.utils.FlipbookIterator$$anon$5.<init>(FlipbookIterator.scala:176); 	at is.hail.utils.FlipbookIterator.map(FlipbookIterator.scala:174); 	at is.hail.utils.FlipbookIterator.map(FlipbookIterator.scala:145); 	at is.hail.rvd.RVD$$anonfun$24.apply(RVD.scala:967); 	at is.hail.rvd.RVD$$anonfun$24.apply(RVD.scala:963); 	at is.hail.rvd.KeyedRVD$$anonfun$orderedLeftJoinDistinct$1.apply(KeyedRVD.scala:147); 	at is.hail.rvd.KeyedRVD$$anonfun$orderedLeftJoinDistinct$1.apply(KeyedRVD.scala:146); 	at is.hail.sparkextras.ContextRDD$$anonfun$czipPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$czipPartitions$1$$anonfun$appl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:51422,Error,ErrorHandling,51422,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['Error'],['ErrorHandling']
Availability,"ets/jinja/security/advisories/GHSA-h5c8-rqwp-cp95"">GHSA-h5c8-rqwp-cp95</a>. You are affected if you are using <code>xmlattr</code> and passing user input as attribute keys.</li>; <li>Changes: <a href=""https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-3"">https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-3</a></li>; <li>Milestone: <a href=""https://github.com/pallets/jinja/milestone/15?closed=1"">https://github.com/pallets/jinja/milestone/15?closed=1</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/jinja/blob/main/CHANGES.rst"">jinja2's changelog</a>.</em></p>; <blockquote>; <h2>Version 3.1.3</h2>; <p>Released 2024-01-10</p>; <ul>; <li>Fix compiler error when checking if required blocks in parent templates are; empty. :pr:<code>1858</code></li>; <li><code>xmlattr</code> filter does not allow keys with spaces. GHSA-h5c8-rqwp-cp95</li>; <li>Make error messages stemming from invalid nesting of <code>{% trans %}</code> blocks; more helpful. :pr:<code>1918</code></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/jinja/commit/d9de4bb215fd1cc8092a410fb834c7c4060b1fc1""><code>d9de4bb</code></a> release version 3.1.3</li>; <li><a href=""https://github.com/pallets/jinja/commit/50124e16561f17f6c1ec85a692f6551418971cdc""><code>50124e1</code></a> skip test pypi</li>; <li><a href=""https://github.com/pallets/jinja/commit/9ea7222ef3f184480be0d0884e30ccfb4172b17b""><code>9ea7222</code></a> use trusted publishing</li>; <li><a href=""https://github.com/pallets/jinja/commit/da703f7aae36b1e88baaa20de334d7ff6378fdde""><code>da703f7</code></a> use trusted publishing</li>; <li><a href=""https://github.com/pallets/jinja/commit/bce174692547464512383ec40e0f8338b8811983""><code>bce1746</code></a> use trusted publishing</li>; <li><a href=""https://github.com/pallets/jinja/commit/7277d8068be593deab3555c7c14f974ada373a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14144:1332,error,error,1332,https://hail.is,https://github.com/hail-is/hail/pull/14144,3,['error'],['error']
Availability,"evel to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 2.2.3; SparkUI available at http://10.200.100.39:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.11-cf54f08305d1; LOGGING: writing to /home/unix/dking/hail-20190307-1908-0.2.11-cf54f08305d1.log; 2019-03-07 19:08:30 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 100 samples, and 100 variants...; ^[[A; In [3]: t = hl.linear_regression_rows(x=mt.GT.n_alt_alleles(), y=mt.pop, covariates=[1]) ; [Stage 0:============================================> (6 + 1) / 8]2019-03-07 19:08:39 Hail: INFO: Coerced sorted dataset; 2019-03-07 19:08:40 Hail: INFO: linear_regression_rows: running on 100 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; /broad/software/free/Linux/redhat_7_x86_64/pkgs/jdk1.8.0_181/bin/java: symbol lookup error: /tmp/jniloader1327638724610654731netlib-native_system-linux-x86_64.so: undefined symbol: cblas_dgemm; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/home/unix/dking/.conda/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/home/unix/dking/.conda/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/home/unix/dking/.conda/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ---------------------------------------------------------------------------; Py4JError Traceback",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5559:1513,error,error,1513,https://hail.is,https://github.com/hail-is/hail/issues/5559,1,['error'],['error']
Availability,"evel-5d0f74cef4f2-Spark-2.2.0.zip. ### What you did:; 1. Import VCF file into MatrixTable.; 2. Annotate VCF file with `output = hl.vep(input, 'vep.properties', csq=True)`.; 3. Attempt to view output with `output.rows().show()`. With `csq=False`, step 3 succeeds. ### What went wrong (all error messages here, including the full java stack trace):; ```; 2018-06-19 17:15:41 Hail: INFO: vep: annotated 2 variants; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/opt/hail/python/hail/table.py"", line 1195, in show; print(self._show(n,width, truncate, types)); File ""/opt/hail/python/hail/table.py"", line 1198, in _show; return self._jt.showString(n, joption(truncate), types, width); File ""/opt/spark-2.2.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/opt/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;). Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 11.0 failed 1 times, most recent failure: Lost task 0.0 in stage 11.0 (TID 11, localhost, executor driver): scala.MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;); 	at is.hail.annotations.RegionValueBuilder.addAnnotation(RegionValueBuilder.scala:489); 	at is.hail.methods.VEP$$anonfun$9$$anonfun$apply$4.apply(VEP.scala:350); 	at is.hail.methods.VEP$$anonfun$9$$anonfun$apply$4.apply(VEP.scala:345); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:926); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:920); 	at scala.colle",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3790:1109,Error,Error,1109,https://hail.is,https://github.com/hail-is/hail/issues/3790,1,['Error'],['Error']
Availability,"ex: in importing annotations from a dbNSFP table, using --impute imputes the Chromosome as an Int as opposed to a String, and brings up errors.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/520:136,error,errors,136,https://hail.is,https://github.com/hail-is/hail/issues/520,1,['error'],['errors']
Availability,example failure: https://ci.hail.is/batches/179008/jobs/30,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10017#issuecomment-775554336:8,failure,failure,8,https://hail.is,https://github.com/hail-is/hail/pull/10017#issuecomment-775554336,1,['failure'],['failure']
Availability,"exit code 0 but actually a timeout. ```; {; ""batch_id"": 27671,; ""job_id"": 65,; ""name"": ""test_pipeline"",; ""state"": ""Error"",; ""exit_code"": 0,; ""duration"": 1211266,; ""msec_mcpu"": 1200805000,; ""cost"": ""$0.0072"",; ""status"": {; ""worker"": ""batch-worker-default-i68pm"",; ""batch_id"": 27671,; ""job_id"": 65,; ""attempt_id"": ""bpqqnj"",; ""user"": ""ci"",; ""state"": ""error"",; ""format_version"": 2,; ""container_statuses"": {; ""input"": {; ""name"": ""input"",; ""state"": ""succeeded"",; ""timing"": {; ""pulling"": {; ""start_time"": 1586188234696,; ""finish_time"": 1586188234698,; ""duration"": 2; },; ""creating"": {; ""start_time"": 1586188234699,; ""finish_time"": 1586188234766,; ""duration"": 67; },; ""runtime"": {; ""start_time"": 1586188234766,; ""finish_time"": 1586188245227,; ""duration"": 10461; },; ""starting"": {; ""start_time"": 1586188234767,; ""finish_time"": 1586188236190,; ""duration"": 1423; },; ""running"": {; ""start_time"": 1586188236190,; ""finish_time"": 1586188245227,; ""duration"": 9037; },; ""uploading_log"": {; ""start_time"": 1586188245231,; ""finish_time"": 1586188245276,; ""duration"": 45; },; ""deleting"": {; ""start_time"": 1586188245276,; ""finish_time"": 1586188245305,; ""duration"": 29; }; },; ""container_status"": {; ""state"": ""exited"",; ""started_at"": ""2020-04-06T15:50:36.182009912Z"",; ""finished_at"": ""2020-04-06T15:50:44.884808909Z"",; ""out_of_memory"": false,; ""exit_code"": 0; }; },; ""main"": {; ""name"": ""main"",; ""state"": ""error"",; ""timing"": {; ""pulling"": {; ""start_time"": 1586188245305,; ""finish_time"": 1586188245404,; ""duration"": 99; },; ""creating"": {; ""start_time"": 1586188245404,; ""finish_time"": 1586188245457,; ""duration"": 53; },; ""runtime"": {; ""start_time"": 1586188245458,; ""finish_time"": 1586189446263,; ""duration"": 1200805; },; ""starting"": {; ""start_time"": 1586188245458,; ""finish_time"": 1586188246261,; ""duration"": 803; },; ""running"": {; ""start_time"": 1586188246262,; ""finish_time"": 1586189446263,; ""duration"": 1200001; },; ""uploading_log"": {; ""start_time"": 1586189446266,; ""finish_time"": 1586189446350,; ""duration"": 84; },; ""deleting",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8473:115,Error,Error,115,https://hail.is,https://github.com/hail-is/hail/issues/8473,2,"['Error', 'error']","['Error', 'error']"
Availability,export_bgen bad error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8161:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/issues/8161,1,['error'],['error']
Availability,expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:39); 	at is.hail.expr.ir.CompileAndEvaluate$.evaluateToJSON(CompileAndEvaluate.scala:14); 	at is.hail.expr.ir.CompileAndEvaluate.evaluateToJSON(CompileAndEvaluate.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:745). is.hail.utils.HailException: foo: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; offending line: 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:20); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.utils.Context.wrapException(Context.scala:19); 	at is.hail.utils.WithContext.wrap(Context.scala:43); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:375); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:575); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:573); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.app,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:10014,Error,Error,10014,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['Error'],['Error']
Availability,"extensions-for-python/issues/110"">#110</a> from AzureAD/persistence-factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/d0696aeb6f65168b1e0d405cd871b80bb101cd76""><code>d0696ae</code></a> Add build_encrypted_persistence() factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/289a94f694645c642ae67b2d5972d3f9fdadb928""><code>289a94f</code></a> Remove old classes that are deprecated for 2 years</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/fa1f45b556341b2c34e9bf63c06a5068571cd337""><code>fa1f45b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/108"">#108</a> from AzureAD/actionable-encryption-exceptions</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/effe77842d25a8b093d18d9e33347f13e2ee094f""><code>effe778</code></a> Provide actionable messages for 2 dpapi errors</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/b674b6a07ca27b2c1b6f371040f035a546cfd468""><code>b674b6a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/107"">#107</a> from AzureAD/file600</li>; <li>Additional commits viewable in <a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/compare/0.3.1...1.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=msal-extensions&package-manager=pip&previous-version=0.3.1&new-version=1.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:4065,error,errors,4065,https://hail.is,https://github.com/hail-is/hail/pull/11992,1,['error'],['errors']
Availability,"f â€˜const class simdpp::arch_avx2::float64<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:30,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/float32x8.h:32:7: note: â€˜class simdpp::arch_avx2::float32<8>â€™ declared here; class float32<8, void> : public any_float32<8, float32<8,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint8<32>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint8<32>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint8<32>]â€™; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:115:37: required from â€˜simdpp::arch_avx2::uint16<16>& simdpp::arch_avx2::uint16<16>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint8<32, simdpp::arch_avx2::expr_empty>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:404:25: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint16<16>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint16<16>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint8<32>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:50450,Mask,MaskCastOverride,50450,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"f). /share/pkg/hail/2018-06-18/install/build/distributions/hail-python.zip/hail/matrixtable.py in write(self, output, overwrite, _codec_spec); 2111 """"""; 2112; -> 2113 self._jvds.write(output, overwrite, _codec_spec); 2114; 2115 def globals_table(self) -> Table:. /share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /share/pkg/hail/2018-06-18/install/build/distributions/hail-python.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: SparkException: Job 2 cancelled because SparkContext was shut down. Java stack trace:; org.apache.spark.SparkException: Job 2 cancelled because SparkContext was shut down; at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:820); at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:818); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:818); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1732); at org.apache.spark.util.EventLoop.stop(EventLoop.scala:83); at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1651); at org.apache.spark.SparkContext$$anonfun$stop$8.apply$mcV$sp(SparkContext.scala:1921); at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317); at org.apache.spark.SparkContext.stop(SparkContext.scala:1920); at org.apache.spark.SparkC",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755:3156,down,down,3156,https://hail.is,https://github.com/hail-is/hail/issues/4755,1,['down'],['down']
Availability,"f, ir, timed=False):; --> 108 result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); 109 value = ir.typ._from_json(result['value']); 110 timings = result['timings']. /usr/lib/spark/python/lib/py4j-src.zip/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /usr/local/lib/python3.6/site-packages/hail/utils/java.py in deco(*args, **kwargs); 223 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 224 'Hail version: %s\n'; --> 225 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 226 except pyspark.sql.utils.CapturedException as e:; 227 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NoSuchElementException: key not found: GRCh37. ```. ### Traces No. 1: . ```java ; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 16.0 failed 4 times, most recent failure: Lost task 15.3 in stage 16.0 (TID 178, ip-172-31-1-20.ec2.internal, executor 4): org.json4s.package$MappingException: unknown error; 	at org.json4s.Extraction$.extract(Extraction.scala:43); 	at org.json4s.ExtractableJsonAstNode.extract(ExtractableJsonAstNode.scala:21); 	at is.hail.io.index.IndexReader$.readMetadata(IndexReader.scala:65); 	at is.hail.io.index.IndexReader.<init>(IndexReader.scala:90); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.HailContext$$anon$3$$anonfun$20.apply(HailContext.scala:879); 	at is.hail.HailContext$$anon$3$$anonfun$20.apply(HailContext.scala:877); 	at scala.Option.map(Option.scala:146); 	at is.hail.HailContext$$anon$3.compute(HailContext.scala:877); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:5177,failure,failure,5177,https://hail.is,https://github.com/hail-is/hail/issues/7044,1,['failure'],['failure']
Availability,"f01ce""><code>3e4c14b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9751"">#9751</a> from fabianegli/main</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/7f924b13a50a05b8dc894418fa7faf779201e129""><code>7f924b1</code></a> Fix typo in deprecation documentation</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/4a8f8ada431974f2837260af3ed36299fd382814""><code>4a8f8ad</code></a> build(deps): Bump django from 4.0.2 to 4.0.3 in /testing/plugins_integration ...</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/c0fd2d883940f1292d5e8234803beaacd08315e6""><code>c0fd2d8</code></a> build(deps): Bump pytest-asyncio from 0.18.1 to 0.18.2 in /testing/plugins_in...</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/843e01824c257c3190792a9df430289c3abe349d""><code>843e018</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9732"">#9732</a> from nicoddemus/9730-toml-failure</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/bc43d66b47b917d43a22e0c703ecfe4eea342263""><code>bc43d66</code></a> [automated] Update plugin list (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9733"">#9733</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/e38d1cac489e42f4bdbecbb50f9f25dc9c36c19f""><code>e38d1ca</code></a> Improve error message for malformed pyproject.toml files</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest/compare/6.2.5...7.1.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest&package-manager=pip&previous-version=6.2.5&new-version=7.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11571:6144,failure,failure,6144,https://hail.is,https://github.com/hail-is/hail/pull/11571,2,['failure'],['failure']
Availability,f41a81995c53a28e375c26b.jar.jar:?]; 	at is.hail.relocated.org.json4s.jackson.JsonMethods$.parse(JsonMethods.scala:71) ~[gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar:?]; 	at is.hail.backend.service.ServiceBackendAPI$.$anonfun$main$5(ServiceBackend.scala:467) ~[gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar:?]; 	at is.hail.utils.package$.using(package.scala:673) ~[gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar:?]; 	at is.hail.backend.service.ServiceBackendAPI$.main(ServiceBackend.scala:467) ~[gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar:?]; 	at is.hail.backend.service.Main$.main(Main.scala:10) ~[gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar:?]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar:?]; 	... 12 more; 2024-11-05 02:43:37.787 JVMEntryway: ERROR: Exception encountered in QoB cancel thread.; org.newsclub.net.unix.SocketClosedException: Not open; 	at org.newsclub.net.unix.AFCore.validFdOrException(AFCore.java:90) ~[jvm-entryway.jar:?]; 	at org.newsclub.net.unix.AFSocketImpl$AFInputStreamImpl.read(AFSocketImpl.java:510) ~[jvm-entryway.jar:?]; 	at java.io.DataInputStream.readInt(DataInputStream.java:393) ~[?:?]; 	at is.hail.JVMEntryway$2.run(JVMEntryway.java:136) [jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]; 	at java.lang.Thread.run(Thread.java:829) [?:?]; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14749:6848,ERROR,ERROR,6848,https://hail.is,https://github.com/hail-is/hail/issues/14749,1,['ERROR'],['ERROR']
Availability,"f; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: batch-output-pod; serviceAccountName: batch-output-pod; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: gsa-key; secret:; defaultMode: 420; secretName: wang-gsa-key; - name: batch-gsa-key; secret:; defaultMode: 420; secretName: batch-gsa-key; - name: batch-12728-job-287-742170; persistentVolumeClaim:; claimName: batch-12728-job-287-742170; - name: batch-output-pod-token-8pkmz; secret:; defaultMode: 420; secretName: batch-output-pod-token-8pkmz; status:; conditions:; - lastProbeTime: null; lastTransitionTime: 2019-09-05T19:15:42Z; message: 'containers with incomplete status: [setup]'; reason: ContainersNotInitialized; status: ""False""; type: Initialized; - lastProbeTime: null; lastTransitionTime: 2019-09-05T19:15:42Z; message: 'containers with unready status: [main cleanup keep-alive]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: 2019-09-05T19:15:42Z; message: 'containers with unready status: [main cleanup keep-alive]'; reason: ContainersNotReady; status: ""False""; type: ContainersReady; - lastProbeTime: null; lastTransitionTime: 2019-09-05T19:15:42Z; status: ""True""; type: PodScheduled; containerStatuses:; - image: gcr.io/hail-vdc/batch:s32fqwbuz8nv; imageID: """"; lastState: {}; name: cleanup; ready: false; restartCount: 0; state:; waiting:; reason: PodInitializing; - image: gcr.io/hail-vdc/batch:s32fqwbuz8nv; imageID: """"; lastState: {}; name: keep-alive; ready: false; restartCount: 0; state:; waiting:; reason: PodInitializing; - image: gcr.io/broad-ctsa/benchmark_wang:latest; imageID: """"; lastState: {}; name: main; ready: false; r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7016:9856,toler,tolerationSeconds,9856,https://hail.is,https://github.com/hail-is/hail/issues/7016,3,"['alive', 'toler']","['alive', 'tolerationSeconds']"
Availability,"f=""https://github-redirect.dependabot.com/docker/docker-py/pull/3056"">docker/docker-py#3056</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/ArchiMoebius""><code>@â€‹ArchiMoebius</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3031"">docker/docker-py#3031</a></li>; <li><a href=""https://github.com/nicks""><code>@â€‹nicks</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3056"">docker/docker-py#3056</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/docker/docker-py/compare/6.0.0...6.0.1"">https://github.com/docker/docker-py/compare/6.0.0...6.0.1</a></p>; <h2>6.0.0</h2>; <h3>â„¹ï¸ Upgrade Notes</h3>; <ul>; <li>Minimum supported Python version is 3.7+</li>; <li>When installing with pip, the <code>docker[tls]</code> extra is deprecated and a no-op,; use <code>docker</code> for same functionality (TLS support is always available now)</li>; <li>Native Python SSH client (used by default / <code>use_ssh_client=False</code>) will now; reject unknown host keys with <code>paramiko.ssh_exception.SSHException</code></li>; <li>Short IDs are now 12 characters instead of 10 characters (same as Docker CLI)</li>; <li>Version metadata is now exposed as <code>__version__</code></li>; </ul>; <h3>âœ¨ Features</h3>; <ul>; <li>Python 3.10 support</li>; <li>Automatically negotiate most secure TLS version</li>; <li>Add <code>platform</code> (e.g. <code>linux/amd64</code>, <code>darwin/arm64</code>) to container create &amp; run</li>; <li>Add support for <code>GlobalJob</code> and <code>ReplicatedJobs</code> for Swarm</li>; <li>Add <code>remove()</code> method on <code>Image</code></li>; <li>Add <code>force</code> param to <code>disable()</code> on <code>Plugin</code></li>; </ul>; <h3>ðŸ› Bugfixes</h3>; <ul>; <li>Fix install issues on Windows related to <code>pywin32</code></li>; <li>Do not accept unknown SSH host keys ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12475:2720,avail,available,2720,https://hail.is,https://github.com/hail-is/hail/pull/12475,1,['avail'],['available']
Availability,"f=""https://github-redirect.dependabot.com/prometheus/client_python/issues/747"">#747</a>; [BUGFIX] Remove trailing slashes from pushgateway URLS. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/722"">#722</a>; [BUGFIX] Catch non-integer bucket/count values. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/726"">#726</a></p>; <h2>0.12.0 / 2021-10-29</h2>; <p>[FEATURE] Exemplar support (excludes multiprocess) <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/669"">#669</a>; [ENHANCEMENT] Add support for Python 3.10 <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/706"">#706</a>; [ENHANCEMENT] Restricted Registry will handle metrics added after restricting <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/675"">#675</a>, <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/680"">#680</a><br />; [ENHANCEMENT] Raise a more helpful error if a metric is not observable <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/666"">#666</a>; [BUGFIX] Fix instance_ip_grouping_key not working on MacOS <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/687"">#687</a>; [BUGFIX] Fix assertion error from favicion.ico with Python 2.7 <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/715"">#715</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/prometheus/client_python/commit/a234283a853238dc73fa22651532590330fd72a1""><code>a234283</code></a> Release 0.13.1</li>; <li><a href=""https://github.com/prometheus/client_python/commit/557d123b349f3881cd6475a29ff4c79088a85a26""><code>557d123</code></a> Relax type constraints Timestamp</li>; <li><a href=""https://github.com/prometheus/client_python/commit/b44b63e59b168c6a8498ca31ddcce3ea5e46dcdc""><code>b44b63e</code></a> Declare <code>reg",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11515:2492,error,error,2492,https://hail.is,https://github.com/hail-is/hail/pull/11515,1,['error'],['error']
Availability,"f=""https://github.com/aio-libs/aioredis-py/commit/7f65c4ccb0e954c17f2a3e1ecc665c62e4a1aaeb""><code>7f65c4c</code></a> Remove <strong>del</strong> from Redis (Fixes <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1115"">#1115</a>) (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1227"">#1227</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/5062740974e493c390fb8db33982f97d6e08df2d""><code>5062740</code></a> Fix typing on blpop (etc) timeout argument (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1224"">#1224</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/dbdd0add63f986f2ed2d56c9736303d133add23c""><code>dbdd0ad</code></a> fix socket.error raises (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1129"">#1129</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/2ba15fb6947fa2347d401ba436e362ad62ed38ff""><code>2ba15fb</code></a> Fix buffer is closed error when using PythonParser class (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1213"">#1213</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/0aa06df10b9531f4ba734ec7567f8621c00e65e9""><code>0aa06df</code></a> Fix typing on evalsha keys_and_args argument (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1215"">#1215</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/33b2dbd0a40ac148e6a36ba2fc7ab5d438a9a71d""><code>33b2dbd</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1201"">#1201</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/a708bd14b1a8bec0a1f3d469bf5384eb2726b5fa""><code>a708bd1</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1162"">#1162</a> from aio-libs/dependabot/pip/flake8-4.0.1</li>; <li><a href=""htt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11569:5262,error,error,5262,https://hail.is,https://github.com/hail-is/hail/pull/11569,1,['error'],['error']
Availability,"f=""https://github.com/jupyter/jupyter_client/compare/v7.3.5...760a7835d8b20a9daea3737759b1751d5e55dad8"">Full Changelog</a>)</p>; <p>This release is primarily focused on improving <code>asyncio</code> support, while aiming to have minimal API changes.</p>; <h3>Enhancements made</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_client/blob/main/CHANGELOG.md"">jupyter-client's changelog</a>.</em></p>; <blockquote>; <h2>8.0.2</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v8.0.1...717d36edcd9ce595f727d8b5a27e270c2a6e2c46"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Add papermill downstream check and fix kernel client replies <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/925"">#925</a> (<a href=""https://github.com/blink1073""><code>@â€‹blink1073</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Adopt more ruff rules <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/924"">#924</a> (<a href=""https://github.com/blink1073""><code>@â€‹blink1073</code></a>)</li>; <li>Prefer print in kernelspecapp <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/923"">#923</a> (<a href=""https://github.com/blink1073""><code>@â€‹blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2023-01-26&amp;to=2023-01-30&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2023-01-26..2023-01-30&amp;type=Issues""><code>@â€‹blink1073</code></a></p>; <!-- raw HTML omitted -->; <h2>8.0.1</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v8.0.0...dc6113c360e05122430b8e130374e9f4e4b701d7"">Full Changelog</a>)</p>; <h3>B",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12656:3366,Mainten,Maintenance,3366,https://hail.is,https://github.com/hail-is/hail/pull/12656,1,['Mainten'],['Maintenance']
Availability,"f=""https://github.com/pre-commit/pre-commit/commit/b22b313e4b042867bf0835f0e842a7281f6faf91""><code>b22b313</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2158"">#2158</a> from mblayman/lua</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/54331dca6fcfff1a06c43defb29b395898c65ce8""><code>54331dc</code></a> get lua version from luarocks itself</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/3f8be7400d523fafe8c6d2d0fa4fb1560e7ae21d""><code>3f8be74</code></a> Add naive and untested version of Lua language support.</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/7a305e5d9ab5e94f2d93599008d20e38f5842ac9""><code>7a305e5</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2210"">#2210</a> from pre-commit/git-version</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/c05f58b776603dc2a5222f035c2dc058426497de""><code>c05f58b</code></a> add git version to error output</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/12b482345b4eee0153ebabbd3911614ac48d6687""><code>12b4823</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2207"">#2207</a> from xhochy/mamba</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/83aa65c4291b8a1a134cd024fbe071323f400c83""><code>83aa65c</code></a> Add mamba support to <code>language: conda</code></li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/657e76ba77ef4ae5b6e2ebe5f06cacdbf22a19a2""><code>657e76b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2205"">#2205</a> from jalessio/jamie/upgrade-rbenv</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/428dc6e46eb68065bfc115419927949cdd056811""><code>428dc6e</code></a> Update rbenv / ruby-build versions</li>; <li>Additional commits viewable in <a href=""http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11460:13347,error,error,13347,https://hail.is,https://github.com/hail-is/hail/pull/11460,2,['error'],['error']
Availability,"fc428ad</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9822"">#9822</a> from jakobandersen/intersphinx_role</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/5d595ec0c4294f45f3138c4c581b84c39cae5e29""><code>5d595ec</code></a> intersphinx role, simplify role_name check</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/6ee0ecbe40ab8a3251538409cf35ffcc04765bfa""><code>6ee0ecb</code></a> intersphinx role, simplify role name matching</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/3bf8bcd6e151a78b0dd003a3e76ff4c65566b6e6""><code>3bf8bcd</code></a> intersphinx role, update docs</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/c11b109d591a74f87de071ec4782ac3ab782ea38""><code>c11b109</code></a> intersphinx role: :external+inv:<strong>: instead of :external:inv+</strong>:</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/9589a2bc0531598cdd69f260f2f2c2dbc5852d6e""><code>9589a2b</code></a> intersphinx role, remove redundant method</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/941db550f02d76ee2b93300584ac85dc599d21e6""><code>941db55</code></a> intersphinx role, fix flake8 warnings</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/9a3f2b85421948c98647b10106c1bbb5ff1b0628""><code>9a3f2b8</code></a> intersphinx role, CHANGES</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/540d76035cc6bbf7ee18d0eb9bf63e4c3651d1f9""><code>540d760</code></a> intersphinx role, documentation</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v4.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=4.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-comp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11522:6597,redundant,redundant,6597,https://hail.is,https://github.com/hail-is/hail/pull/11522,2,['redundant'],['redundant']
Availability,"figuration option (<code>python-cell-magics</code>) to format cells with custom magics in Jupyter Notebooks (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2744"">#2744</a>)</li>; <li>Allow setting custom cache directory on all platforms with environment variable <code>BLACK_CACHE_DIR</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2739"">#2739</a>).</li>; <li>Enable Python 3.10+ by default, without any extra need to specify -<code>-target-version=py310</code>. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2758"">#2758</a>)</li>; <li>Make passing <code>SRC</code> or <code>--code</code> mandatory and mutually exclusive (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2804"">#2804</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>Improve error message for invalid regular expression (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2678"">#2678</a>)</li>; <li>Improve error message when parsing fails during AST safety check by embedding the underlying SyntaxError (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2693"">#2693</a>)</li>; <li>No longer color diff headers white as it's unreadable in light themed terminals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2691"">#2691</a>)</li>; <li>Text coloring added in the final statistics (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2712"">#2712</a>)</li>; <li>Verbose mode also now describes how a project root was discovered and which paths will be formatted. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2526"">#2526</a>)</li>; </ul>; <h3>Packaging</h3>; <ul>; <li>All upper version bounds on dependencies have been removed (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2718"">#2718</a>)</li>; <li><code>typing-extensions</code> is no longer a required dependency in Python 3.10+ (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2772"">#2772",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:5697,error,error,5697,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['error'],['error']
Availability,"file. ```; # hexdump /tmp/bar; 0000000 ef bb bf 73 61 6d 70 6c 65 5f 69 64 0a 66 6f 6f; 0000010 0a ; 0000011; # ipython; import hail asPython 3.7.3 (default, Mar 27 2019, 09:23:15) ; Type 'copyright', 'credits' or 'license' for more information; IPython 7.5.0 -- An enhanced Interactive Python. Type '?' for help. In [1]: import hail as hl ; hl.import_; In [2]: t = hl.import_table('/tmp/bar') ; ...: t.describe() ; ...: t = t.key_by('sample_id') ; Initializing Spark and Hail with default parameters...; using hail jar at /usr/local/lib/python3.7/site-packages/hail/hail-all-spark.jar; 19/06/13 14:08:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 2.4.1; SparkUI available at http://wm06b-953.broadinstitute.org:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.14-5cb00c115421; LOGGING: writing to /Users/dking/projects/hail/hail/hail-20190613-1408-0.2.14-5cb00c115421.log; 2019-06-13 14:08:15 Hail: INFO: Reading table with no type imputation; Loading column '?sample_id' as type 'str' (type not specified). ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'ï»¿sample_id': str ; ----------------------------------------; Key: []; ----------------------------------------; ---------------------------------------------------------------------------; LookupError Traceback (most recent call last); <ipython-input-2-6b119cf7ec41> in <module>; 1 t = hl.import_table('/tmp/bar'); 2 t.describe(); ----> 3 t = t.key_by('sample_id'). </usr/local/lib/python3.7/site-packages/decorator.py:decorator-gen-958> in key_by(self, *keys, **named_keys). /usr/local/lib/python3.7",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6342:1539,avail,available,1539,https://hail.is,https://github.com/hail-is/hail/issues/6342,1,['avail'],['available']
Availability,"file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" which is different from old value """"; printf ""0.2.124"" > env/HAIL_PIP_VERSION; echo 0.2.124-13536b531342 > python/hail/hail_version; echo 0.2.124 > python/hail/hail_pip_version; cp -f python/hail/hail_version python/hailtop/hail_version; printf 'hail_version=""0.2.124-13536b531342"";' > python/hail/docs/_static/hail_version.js; printf 'hail_pip_version=""0.2.124""' >> python/hail/docs/_static/hail_version.js; cloud_base is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" > env/cloud_base; wheel_cloud_path is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:1763,echo,echo,1763,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,1,['echo'],['echo']
Availability,filteralleles needs to error when running on hardcalls,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1283:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/issues/1283,1,['error'],['error']
Availability,"filteralleles, or more specifically, the subset and downcode processes do not particularly work on hardcalls (it finds the next most likely genotypes in the PLs, which are nonexistent). One possible workaround would be to force users to `filter_altered_genotypes=True` but this will probably require some new code. But otherwise, this should definitely throw an error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1283:52,down,downcode,52,https://hail.is,https://github.com/hail-is/hail/issues/1283,2,"['down', 'error']","['downcode', 'error']"
Availability,fix CallStatsCombiner error message when it gets an allele > nAlleles,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4379:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/issues/4379,1,['error'],['error']
Availability,fix VCF format parser missing array element error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5169:44,error,error,44,https://hail.is,https://github.com/hail-is/hail/issues/5169,1,['error'],['error']
Availability,fix concordance divide by 0 error in the info message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7974:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/issues/7974,1,['error'],['error']
Availability,fix deploy failure caused by use of relative paths,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14429:11,failure,failure,11,https://hail.is,https://github.com/hail-is/hail/pull/14429,1,['failure'],['failure']
Availability,fix doc syntax error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4041:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/4041,1,['error'],['error']
Availability,fix lambda error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/786:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/issues/786,1,['error'],['error']
Availability,fix pipeline failure message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6475:13,failure,failure,13,https://hail.is,https://github.com/hail-is/hail/issues/6475,1,['failure'],['failure']
Availability,fix str formatting on error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4378:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/4378,1,['error'],['error']
Availability,fix sum array aggregator match error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1020:31,error,error,31,https://hail.is,https://github.com/hail-is/hail/pull/1020,1,['error'],['error']
Availability,fix toleration when building pod spec,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7326:4,toler,toleration,4,https://hail.is,https://github.com/hail-is/hail/pull/7326,1,['toler'],['toleration']
Availability,fix trio matrix filter_to typecheck error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5294:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/pull/5294,1,['error'],['error']
Availability,fix wrong error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1347:10,error,error,10,https://hail.is,https://github.com/hail-is/hail/pull/1347,1,['error'],['error']
Availability,fixed bash scripts in docs build so exit if error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/949:44,error,error,44,https://hail.is,https://github.com/hail-is/hail/pull/949,1,['error'],['error']
Availability,fixed bug in error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1980:13,error,error,13,https://hail.is,https://github.com/hail-is/hail/pull/1980,1,['error'],['error']
Availability,fixed bug in gen failure printlns,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/448:17,failure,failure,17,https://hail.is,https://github.com/hail-is/hail/pull/448,1,['failure'],['failure']
Availability,fixed ipython checkpoint error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1577:14,checkpoint,checkpoint,14,https://hail.is,https://github.com/hail-is/hail/pull/1577,2,"['checkpoint', 'error']","['checkpoint', 'error']"
Availability,fixed pluralization in error message for expr types,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/857:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/pull/857,1,['error'],['error']
Availability,"fixed</h3>; <ul>; <li>Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15386"">#15386</a>: Improve scrolling to heading <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15565"">#15565</a> (<a href=""https://github.com/krassowski""><code>@â€‹krassowski</code></a>)</li>; <li>Workaround focus leaving input box on consecutive submissions <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15479"">#15479</a> (<a href=""https://github.com/krassowski""><code>@â€‹krassowski</code></a>)</li>; <li>Fix search coming back in notebook and editor <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15443"">#15443</a> (<a href=""https://github.com/krassowski""><code>@â€‹krassowski</code></a>)</li>; <li>Fix <code>jupyter labextension watch --help</code> <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15542"">#15542</a> (<a href=""https://github.com/akx""><code>@â€‹akx</code></a>)</li>; <li>Fix <code>FormComponent</code> showing error indicators in all fields when using a <code>customValidate</code> function <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15464"">#15464</a> (<a href=""https://github.com/mmichilot""><code>@â€‹mmichilot</code></a>)</li>; <li>Fix Shift + L not working in stdin <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15440"">#15440</a> (<a href=""https://github.com/krassowski""><code>@â€‹krassowski</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15499"">#15499</a>: Adopt ruff format <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15564"">#15564</a> (<a href=""https://github.com/krassowski""><code>@â€‹krassowski</code></a>)</li>; <li>Pin <code>actions/labeler</code> to v4 to fix failing CI action <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15496"">#15496</a> (<a href=""https://github.com/krassowski""><code>@â€‹krassowski</code></a>)</li>; <li>Fix U",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14184:4271,error,error,4271,https://hail.is,https://github.com/hail-is/hail/pull/14184,2,['error'],['error']
Availability,"fixes #13407. CHANGELOG: Resolves #13407 in which uses of `union_rows` could reduce parallelism to one partition resulting in severely degraded performance. TableUnion was always collapsing to a single partition when the key was empty. This adds a special case handling, which just concatenates partitions. The body of the resulting TableStage is a little hacky: it does a StreamMultiMerge, but where exactly one input stream is non-empty. I think that should have fine performance, and I didnâ€™t see any simpler ways to do it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13414:135,degraded,degraded,135,https://hail.is,https://github.com/hail-is/hail/pull/13414,1,['degraded'],['degraded']
Availability,"fixes #4656 . The deploy service account does not have privileges to create anything in `batch-pods` (as noted by the error message in #4656). The correct namespace in which to create the notebook service is `default`. That is rectified here with the `-n` or ""namespace"" argument.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4657:118,error,error,118,https://hail.is,https://github.com/hail-is/hail/pull/4657,1,['error'],['error']
Availability,fixes. ```; + gcloud -q auth activate-service-account --key-file=/test-gsa-key/key.json; Activated service account credentials for: [test-665@hail-vdc.iam.gserviceaccount.com]; + set +e; + gcloud -q compute instances list --filter 'tags.items=batch2-agent AND labels.namespace=pr-7890-default-b9qytu01zuim' '--format=value(name)' --project hail-vdc; + xargs -r gcloud -q compute instances delete --zone us-central1-a --project hail-vdc; Deleted [https://www.googleapis.com/compute/v1/projects/hail-vdc/zones/us-central1-a/instances/batch-worker-pr-7890-default-b9qytu01zuim-15e3g].; ERROR: (gcloud.compute.instances.delete) Could not fetch resource:; - The resource 'projects/hail-vdc/zones/us-central1-a/instances/batch-worker-pr-7890-default-b9qytu01zuim-hr6b9' was not found; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7905:583,ERROR,ERROR,583,https://hail.is,https://github.com/hail-is/hail/pull/7905,1,['ERROR'],['ERROR']
Availability,"fmtlib looks promising, but. a) I'm not keen to mix in non-standard third-party source code into our; codebase; unless it's a significant win over the functionality that is; available everywhere; and familiar to everyone. printf has been getting the job done for; decades. b) the speed test shows it still slower than printf (iirc 1.56s vs; 1.35s), just not a; *lot* slower (whereas C++ iostreams are very slow). On Fri, Aug 3, 2018 at 10:45 AM Patrick Schultz <notifications@github.com>; wrote:. > *@patrick-schultz* commented on this pull request.; > ------------------------------; >; > In src/main/c/NativeModule.cpp; > <https://github.com/hail-is/hail/pull/3973#discussion_r207566438>:; >; > > +#include <sys/stat.h>; > +#include <sys/time.h>; > +#include <unistd.h>; > +#include <atomic>; > +#include <memory>; > +#include <mutex>; > +#include <iostream>; > +#include <sstream>; > +#include <string>; > +#include <vector>; > +; > +#if 0; > +#define D(fmt, ...) { \; > + char buf[1024]; \; > + sprintf(buf, fmt, ##__VA_ARGS__); \; > + fprintf(stderr, ""DEBUG: %s,%d: %s"", __FILE__, __LINE__, buf); \; >; > @cseed <https://github.com/cseed> suggested using the fmt library (; > https://github.com/fmtlib/fmt), which I believe is being proposed for; > standardization. That is my preference also. It appears to be as safe as; > IOstreams and as fast as printf. It supports both Python style and C; > style formatting, e.g.; >; > fmt::print(""Hello, {}!"", ""world""); // uses Python-like format string syntaxfmt::printf(""Hello, %s!"", ""world""); // uses printf format string syntax; >; > Format strings are checked at compile time, as are argument types.; >; > â€”; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/pull/3973#discussion_r207566438>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AJzExrljAAlcA6ksqZiNPyOw8wgC0hheks5uNGH7gaJpZM4VbZpP>; > .; >",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-410319504:174,avail,available,174,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410319504,1,['avail'],['available']
Availability,"fo: Coerced sorted dataset; 14:17:30.368 [ERROR] [system.err] .hail: info: Coerced sorted dataset; 14:17:31.306 [ERROR] [system.err] ...; 14:17:31.904 [ERROR] [system.err] ==================================================================; 14:17:31.905 [ERROR] [system.err] ERROR: test_dataset (hail.tests.ContextTests); 14:17:31.905 [ERROR] [system.err] ----------------------------------------------------------------------; 14:17:31.905 [ERROR] [system.err] Traceback (most recent call last):; 14:17:31.905 [ERROR] [system.err] File ""/scratch/PI/dpwall/computeEnvironments/hail/python/hail/tests.py"", line 181, in test_dataset; 14:17:31.906 [ERROR] [system.err] sample2.grm('gcta-grm-bin', '/tmp/sample2.grm'); 14:17:31.906 [ERROR] [system.err] File ""/scratch/PI/dpwall/computeEnvironments/hail/python/hail/dataset.py"", line 1988, in grm; 14:17:31.906 [ERROR] [system.err] self.hc._run_command(self, pargs); 14:17:31.906 [ERROR] [system.err] File ""/scratch/PI/dpwall/computeEnvironments/hail/python/hail/context.py"", line 90, in _run_command; 14:17:31.907 [ERROR] [system.err] raise_py4j_exception(e); 14:17:31.907 [ERROR] [system.err] File ""/scratch/PI/dpwall/computeEnvironments/hail/python/hail/java.py"", line 87, in raise_py4j_exception; 14:17:31.907 [ERROR] [system.err] raise FatalError(msg, e.java_exception); 14:17:31.908 [ERROR] [system.err] FatalError: NoSuchMethodError: breeze.linalg.DenseVector$.canSetD()Lbreeze/generic/UFunc$InPlaceImpl2;; 14:17:31.908 [ERROR] [system.err]; 14:17:31.908 [ERROR] [system.err] ----------------------------------------------------------------------; 14:17:31.908 [ERROR] [system.err] Ran 7 tests in 83.523s. I noticed that a previous issue #209 from early last year had the exact same issue in a different context where the function `breeze.linalg.DenseVector$.canSetD()Lbreeze/generic/UFunc$InPlaceImpl2;` didn't exist. However, when I use spark 2.0.2, it is able to run almost all tests successfully. Perhaps a problem with the paths in spark 2.1.0?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1419:1536,ERROR,ERROR,1536,https://hail.is,https://github.com/hail-is/hail/issues/1419,7,['ERROR'],['ERROR']
Availability,"for `vds.linreg('sa.pheno', 'sa.cov1')` the error is now:. ```; sa.cov1 is not an array; ```. rather than. ```; FatalError Traceback (most recent call last); <ipython-input-18-89d0abef0d0a> in <module>(); ----> 1 vds1 = vds.linreg('sa.pheno', 'sa.cov1').count(). <decorator-gen-240> in linreg(self, y, covariates, root, use_dosages, min_ac, min_af). /Users/jbloom/hail/python/hail/java.pyc in handle_py4j(func, *args, **kwargs); 111 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 112 'Hail version: %s\n'; --> 113 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); 114 except py4j.protocol.Py4JError as e:; 115 if e.args[0].startswith('An error occurred while calling'):. FatalError: HailException: symbol `a' not found; Available symbols:; s: String; sa: Struct ; <input>:1:a; ^. Java stack trace:; is.hail.utils.HailException: symbol `a' not found; Available symbols:; s: String; sa: Struct ; <input>:1:a; ^; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:20); at is.hail.expr.ParserUtils$.error(Parser.scala:24); at is.hail.expr.AST.parseError(AST.scala:222); at is.hail.expr.SymRef.typecheckThis(AST.scala:648); at is.hail.expr.AST.typecheck(AST.scala:219); at is.hail.expr.Parser$.is$hail$expr$Parser$$eval(Parser.scala:57); at is.hail.expr.Parser$.parseExpr(Parser.scala:67); at is.hail.stats.RegressionUtils$$anonfun$3.apply(RegressionUtils.scala:36); at is.hail.stats.RegressionUtils$$anonfun$3.apply(RegressionUtils.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); at is.hail.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1654:44,error,error,44,https://hail.is,https://github.com/hail-is/hail/pull/1654,7,"['Avail', 'Error', 'error']","['Available', 'Error', 'ErrorHandling', 'error']"
Availability,"for better or worse. I believe the behavior is the same and the code and user ergonomics seem better. The one known issue I haven't figured out to fix is the usage output on unknown flags:. ```; $ hailctl --fleep auth login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep. $ hailctl auth --fleep login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep; ```. This implies argparse should allow hailctl flags to appear after auth, but that isn't the case. For example:. ```; $ hailctl dataproc connect --beta foo nb; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --beta; ```. I will keep investigating a fix for this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9836:305,error,error,305,https://hail.is,https://github.com/hail-is/hail/pull/9836,3,['error'],['error']
Availability,for error responses coming from our services. I think I got all occurrences of this by searching for `e.message` across the codebase. The only instances I see left of this are error-handling withing `front_end.py` (which isn't a problem because this is an issue of the reason phrase not making it between server -> client) and exceptions from aiodocker which is not within our control.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12400:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/pull/12400,2,['error'],"['error', 'error-handling']"
Availability,"for some reason I guess I tagged this issue wrong from the PR?. We traced this down to a Spark problem with the iterator that comes out of the shuffle, and so #4228 should fix the memory leak issue for this specific case.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4202#issuecomment-416762038:79,down,down,79,https://hail.is,https://github.com/hail-is/hail/issues/4202#issuecomment-416762038,1,['down'],['down']
Availability,"form_entries; return hl.bind(with_local_a_index, lai); <decorator-gen-746>:2: in bind; ???; /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/typecheck/check.py:584: in wrapper; return __original_func(*args_, **kwargs_); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/expr/functions.py:537: in bind; lambda_result = to_expr(f(*args)); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/experimental/sparse_mt/sparse_split_multi.py:190: in with_local_a_index; return hl.bind(with_pl, new_pl); <decorator-gen-746>:2: in bind; ???; /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/typecheck/check.py:584: in wrapper; return __original_func(*args_, **kwargs_); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/expr/functions.py:537: in bind; lambda_result = to_expr(f(*args)); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/experimental/sparse_mt/sparse_split_multi.py:156: in with_pl; new_exprs['PGT'] = hl.rbind(; /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/expr/functions.py:588: in rbind; return hl.bind(f, *args, _ctx=_ctx); <decorator-gen-746>:2: in bind; ???; /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/typecheck/check.py:584: in wrapper; return __original_func(*args_, **kwargs_); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/expr/functions.py:537: in bind; lambda_result = to_expr(f(*args)); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . lpgt = <StringExpression of type str>. > lambda lpgt: hl.if_else(lpgt.is_non_ref(), hl.downcode(lpgt, hl.or_else(; local_a_index, hl.len(old_entry.LA))), lpgt)); E AttributeError: 'StringExpression' object has no attribute 'is_non_ref'. /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/experimental/sparse_mt/sparse_split_multi.py:158: AttributeError; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13337:5128,down,downcode,5128,https://hail.is,https://github.com/hail-is/hail/issues/13337,1,['down'],['downcode']
Availability,"formation below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: master build . ### What you did:; Ran python script ; [root@]cat hail/Hail_Tutorial.py; **from hail import * ; hc = HailContext()** ; import numpy as np ; import pandas as pd ; import matplotlib.pyplot as plt ; import matplotlib.patches as mpatches ; from collections import Counter ; from math import log, isnan ; from pprint import pprint ; import seaborn ; vds = hc.read('/gpfs/hail/test_hail_qnsnodes_2500c_spark2_20170515.vds') ; vds.summarize().report() ; vds.query_variants('variants.take(5)'); vds.query_samples('samples.take(5)'); vds.sample_ids[:5]; vds.query_genotypes('gs.take(5)'); #%%sh; #head data/1kg_annotations.txt | column -t; table = hc.import_table('data/1kg_annotations.txt', impute=True)\; .key_by('Sample'); print(table.schema); pprint(table.schema); table.to_dataframe().show(10); vds = vds.annotate_samples_table(table, root='sa'); pprint(vds.sample_schema); pprint(table.query('SuperPopulation.counter()')); pprint(table.query('CaffeineConsumption.stats()')); table.count(); vds.num_samples; vds.query_samples('samples.map(s => sa.SuperPopulation).counter()'); table.count(); vds.num_samples. #common_vds = (vds; # .filter_variants_expr('va.qc.AF > 0.01'); # .ld_prune(memory_per_core=256, num_cores=4)); pca = vds.pca('sa.pca', k=5, eigenvalues='global.eigen'); pprint(pca.globals). #vds = vds.filter_samples_expr('sa.qc.dpMean >= 4 && sa.qc.callRate >= 0.97'); #print('After filter, %d/1000 samples remain.' % vds.num_samples). df = vds.samples_table().to_pandas(); df.head(). ### What went wrong (all error messages here, including the full java stack trace):. **File ""/hail/Hail_Tutorial.py"", line 2, in <module>; hc = HailContext() ; NameError: name 'HailContext' is not defined; + /software/spark/spark-2.2.0-bin-hadoop2.7//sbin/stop-master.sh**",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3102:1784,error,error,1784,https://hail.is,https://github.com/hail-is/hail/issues/3102,1,['error'],['error']
Availability,"from @zaczap; ```; 2018-02-21 15:30:31 Hail: INFO: interval filter loaded 89 of 1274 partitions; Traceback (most recent call last):; File ""/tmp/85fbcd66-b973-4c5c-9216-ef00b9a7f3a7/temp_vep.py"", line 34, in <module>; vds = hl.filter_intervals(vds, intervals); File ""<decorator-gen-718>"", line 2, in filter_intervals; File ""/tmp/85fbcd66-b973-4c5c-9216-ef00b9a7f3a7/hail-devel-5b95158ed055.zip/hail/utils/java.py"", line 198, in handle_py4j; hail.utils.java.FatalError: requirement failed. Java stack trace:; scala.Predef$.require(Predef.scala:212); at is.hail.rvd.OrderedRVDPartitioner.<init>(OrderedRVDPartitioner.scala:28); at is.hail.rvd.OrderedRVDPartitioner.copy(OrderedRVDPartitioner.scala:98); at is.hail.rvd.OrderedRVD.filterIntervals(OrderedRVD.scala:270); at is.hail.methods.FilterIntervals$.apply(FilterIntervals.scala:23); at is.hail.methods.FilterIntervals$.apply(FilterIntervals.scala:18); at is.hail.methods.FilterIntervals.apply(FilterIntervals.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748); Hail version: devel-5b95158; Error summary: requirement failed; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [85fbcd66-b973-4c5c-9216-ef00b9a7f3a7] entered state [ERROR] while waiting for [DONE].; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2949:1697,Error,Error,1697,https://hail.is,https://github.com/hail-is/hail/issues/2949,3,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,"from an array of â€˜const class simdpp::arch_avx2::uint64<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:38,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64.h:30:7: note: â€˜class simdpp::arch_avx2::int64<8>â€™ declared here; class int64<N, void> : public any_int64<N, int64<N,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int16<32>; T = simdpp::arch_avx2::uint16<32>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int16<32>; T = simdpp::arch_avx2::uint16<32>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int16<32>; T = simdpp::arch_avx2::uint16<32>]â€™; libsimdpp-2.0-rc2/simdpp/types/int16.h:50:35: required from â€˜simdpp::arch_avx2::int16<N>& simdpp::arch_avx2::int16<N>::operator=(const simdpp::arch_avx2::any_vec<(N * 2), V>&) [with V = simdpp::arch_avx2::uint16<32>; unsigned int N = 32]â€™; libsimdpp-2.0-rc2/simdpp/types/int16.h:43:73: required from â€˜simdpp::arch_avx2::int16<N>::int16(const simdpp::arch_avx2::uint16<N, E>&) [with E = void; unsigned int N = 32]â€™; libsimdpp-2.0-rc2/simdpp/core/combine.h:66:69: required from â€˜simdpp::arch_avx2::int16<(N * 2)> simdpp::arch_avx2::combine(const simdpp::arch_avx2::int16<N, E>&, const simdpp::arch_avx2::int16<N, E2>&) [with unsigned int N = 16; E1 = void; E2 = void]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/to_int16",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:137382,Mask,MaskCastOverride,137382,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,from gsa-key (rw); /io from batch-12728-job-287-742170 (rw); /var/run/secrets/kubernetes.io/serviceaccount from batch-output-pod-token-8pkmz (ro); cleanup:; Container ID: ; Image: gcr.io/hail-vdc/batch:s32fqwbuz8nv; Image ID: ; Port: 5000/TCP; Host Port: 0/TCP; Command:; /bin/sh; -c; ; set -ex; python3 -m batch.cleanup_sidecar; ; State: Waiting; Reason: PodInitializing; Ready: False; Restart Count: 0; Requests:; cpu: 500m; Environment:; COPY_OUTPUT_CMD: set -ex; (gcloud -q auth activate-service-account --key-file=/gsa-key/privateKeyData || (sleep $(( 5 + (RANDOM % 5) )); gcloud -q auth activate-service-account --key-file=/gsa-key/privateKeyData)) && gsutil -m cp -R /io/pipeline/pipeline-1cac3dd4e66d/__TASK__286/8926feac gs://hail-wang-ukps2/pipeline/pipeline-1cac3dd4e66d/__TASK__286/8926feac; Mounts:; /batch-gsa-key from batch-gsa-key (rw); /gsa-key from gsa-key (rw); /io from batch-12728-job-287-742170 (rw); /var/run/secrets/kubernetes.io/serviceaccount from batch-output-pod-token-8pkmz (ro); keep-alive:; Container ID: ; Image: gcr.io/hail-vdc/batch:s32fqwbuz8nv; Image ID: ; Port: 5001/TCP; Host Port: 0/TCP; Command:; /bin/sh; -c; ; set -ex; python3 -m batch.keep_alive_sidecar; ; State: Waiting; Reason: PodInitializing; Ready: False; Restart Count: 0; Requests:; cpu: 1m; Environment: <none>; Mounts:; /gsa-key from gsa-key (rw); /io from batch-12728-job-287-742170 (rw); /var/run/secrets/kubernetes.io/serviceaccount from batch-output-pod-token-8pkmz (ro); Conditions:; Type Status; Initialized False ; Ready False ; ContainersReady False ; PodScheduled True ; Volumes:; gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: wang-gsa-key; Optional: false; batch-gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: batch-gsa-key; Optional: false; batch-12728-job-287-742170:; Type: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace); ClaimName: batch-12728-job-287-742170; ReadOnly: false; batch-output-pod-token-,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7016:3597,alive,alive,3597,https://hail.is,https://github.com/hail-is/hail/issues/7016,1,['alive'],['alive']
Availability,"from: https://discuss.hail.is/t/zip-length-mismatch-error/3548. ```; > ; > 2023-08-09 15:56:05.872 Hail: INFO: wrote table with 104 rows in 104 partitions to gs://gnomad-tmp-4day/__iruid_845-wg8w0gBbPsilRDfRegbVW3; INFO (constraint_pipeline 463): Copying log to logging bucket...; 2023-08-09 15:56:33.276 Hail: INFO: copying log to 'gs://gnomad-tmp/gnomad_v2.1.1_testing/constraint/logging/constraint_pipeline.log'...; Traceback (most recent call last):; File ""/tmp/17e6dae80e9548a9a94895fd07e6dee0/constraint_pipeline.py"", line 785, in <module>; main(args); File ""/tmp/17e6dae80e9548a9a94895fd07e6dee0/constraint_pipeline.py"", line 412, in main; oe_ht = apply_models(; File ""/tmp/17e6dae80e9548a9a94895fd07e6dee0/pyscripts_ge6ozu1m.zip/gnomad_constraint/utils/constraint.py"", line 396, in apply_models; File ""/tmp/17e6dae80e9548a9a94895fd07e6dee0/pyscripts_ge6ozu1m.zip/gnomad_constraint/utils/constraint.py"", line 279, in create_observed_and_possible_ht; File ""<decorator-gen-1118>"", line 2, in checkpoint; File ""/opt/conda/default/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/conda/default/lib/python3.10/site-packages/hail/table.py"", line 1331, in checkpoint; self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); File ""<decorator-gen-1120>"", line 2, in write; File ""/opt/conda/default/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/conda/default/lib/python3.10/site-packages/hail/table.py"", line 1377, in write; Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); File ""/opt/conda/default/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 82, in execute; raise e.maybe_user_error(ir) from None; File ""/opt/conda/default/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 76, in execu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13486:52,error,error,52,https://hail.is,https://github.com/hail-is/hail/issues/13486,2,"['checkpoint', 'error']","['checkpoint', 'error']"
Availability,fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.net.URI.checkPath(URI.java:1823); 	at java.net.URI.<init>(URI.java:745); 	at org.apache.hadoop.fs.Path.initialize(Path.java:202); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.58-3f304aae6ce2; Error summary: URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9607:6832,Error,Error,6832,https://hail.is,https://github.com/hail-is/hail/issues/9607,1,['Error'],['Error']
Availability,"full control canned ACL to be set when Athena writes query results to S3 buckets.</li>; <li>api-change:<code>keyspaces</code>: [<code>botocore</code>] This release adds support for data definition language (DDL) operations</li>; <li>api-change:<code>ecr</code>: [<code>botocore</code>] This release adds support for tracking images lastRecordedPullTime.</li>; </ul>; <h1>1.21.10</h1>; <ul>; <li>api-change:<code>mediapackage</code>: [<code>botocore</code>] This release adds Hybridcast as an available profile option for Dash Origin Endpoints.</li>; <li>api-change:<code>rds</code>: [<code>botocore</code>] Documentation updates for Multi-AZ DB clusters.</li>; <li>api-change:<code>mgn</code>: [<code>botocore</code>] Add support for GP3 and IO2 volume types. Add bootMode to LaunchConfiguration object (and as a parameter to UpdateLaunchConfigurationRequest).</li>; <li>api-change:<code>kafkaconnect</code>: [<code>botocore</code>] Adds operation for custom plugin deletion (DeleteCustomPlugin) and adds new StateDescription field to DescribeCustomPlugin and DescribeConnector responses to return errors from asynchronous resource creation.</li>; </ul>; <h1>1.21.9</h1>; <ul>; <li>api-change:<code>finspace-data</code>: [<code>botocore</code>] Add new APIs for managing Users and Permission Groups.</li>; <li>api-change:<code>amplify</code>: [<code>botocore</code>] Add repositoryCloneMethod field for hosting an Amplify app. This field shows what authorization method is used to clone the repo: SSH, TOKEN, or SIGV4.</li>; <li>api-change:<code>fsx</code>: [<code>botocore</code>] This release adds support for the following FSx for OpenZFS features: snapshot lifecycle transition messages, force flag for deleting file systems with child resources, LZ4 data compression, custom record sizes, and unsetting volume quotas and reservations.</li>; <li>api-change:<code>fis</code>: [<code>botocore</code>] This release adds logging support for AWS Fault Injection Simulator experiments. Experiment templa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11486:2642,error,errors,2642,https://hail.is,https://github.com/hail-is/hail/pull/11486,2,['error'],['errors']
Availability,"func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561 ; 562 return wrapper. ~/anaconda2/envs/foofoo/lib/python3.7/site-packages/hail/methods/impex.py in import_table(paths, key, min_partitions, impute, no_header, comment, delimiter, missing, types, quote, skip_blank_lines, force_bgz); 1326 jt = Env.hc()._jhc.importTable(paths, key, min_partitions, jtypes, comment,; 1327 delimiter, missing, no_header, impute, quote,; -> 1328 skip_blank_lines, force_bgz); 1329 return Table._from_java(jt); 1330 . ~/anaconda2/envs/foofoo/lib/python3.7/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. ~/anaconda2/envs/foofoo/lib/python3.7/site-packages/hail/utils/java.py in deco(*args, **kwargs); 225 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 226 'Hail version: %s\n'; --> 227 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 228 except pyspark.sql.utils.CapturedException as e:; 229 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: MalformedInputException: Input length = 1. Java stack trace:; java.nio.charset.MalformedInputException: Input length = 1; 	at java.nio.charset.CoderResult.throwException(CoderResult.java:281); 	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:339); 	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178); 	at java.io.InputStreamReader.read(InputStreamReader.java:184); 	at java.io.BufferedReader.fill(BufferedReader.java:161); 	at java.io.BufferedReader.readLine(BufferedReader.java:324); 	at java.io.BufferedReader.readLine(BufferedReader.java:389); 	at scala.io.BufferedSource$BufferedLineIterator.hasNext(BufferedSource.scala:72); 	at scala.collection.Iterator$$anon$21.hasNext(Iterator.scala:836); 	at scala.collection.Iterator$$anon$11.hasNext(Iterato",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5221:1952,Error,Error,1952,https://hail.is,https://github.com/hail-is/hail/issues/5221,1,['Error'],['Error']
Availability,"func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561; 562 return wrapper. /share/pkg/hail/2018-10-31/install/build/distributions/hail-python.zip/hail/methods/impex.py in index_bgen(path, index_file_map, reference_genome, contig_recoding, skip_invalid_loci); 1955 index_file_map = tdict(tstr, tstr)._convert_to_j(index_file_map); 1956; -> 1957 Env.hc()._jhc.indexBgen(jindexed_seq_args(path), index_file_map, joption(rg), contig_recoding, skip_invalid_loci); 1958; 1959. /share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /share/pkg/hail/2018-10-31/install/build/distributions/hail-python.zip/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 211 except pyspark.sql.utils.CapturedException as e:; 212 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: OutOfMemoryError: GC overhead limit exceeded. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.immutable.VectorBuilder.<init>(Vector.scala:713); at scala.collection.immutable.Vector$.newBuilder(Vector.scala:22); at scala.collection.immutable.IndexedSeq$.newBuilder(IndexedSeq.scala:46); at scala.collection.IndexedSeq$.newBuilder(IndexedSeq.scala:36); at scala.collection.IndexedSeq$$anon$1.apply(IndexedSeq.scala:34); at com.twitter.chill.TraversableSerializer.read(Traversable.scala:39); at com.twitter.chill.TraversableSerializer",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:6654,Error,Error,6654,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Error'],['Error']
Availability,"fwiw, `j.env(VAR, VAL)` is also available though that would set it for all the commands in the job.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12840#issuecomment-1495034877:32,avail,available,32,https://hail.is,https://github.com/hail-is/hail/pull/12840#issuecomment-1495034877,1,['avail'],['available']
Availability,"fy JS logic based on new JSON structure.; - Check-in and implement versioned deployment of the annotation db configuration JSON.; - Add a JS file to the website that defines `hail_version` and `hail_pip_version`.; - Add `key_properties` which currently supports two properties `gene` and `unique`. Gene keyed datasets require using the `gencode` dataset to crosswalk from locus to gene before joining.; - Rudimentary test of key properties functionality. Foundational Changes Outside Annotation DB:; - Define `__pip_version__` in `hail`.; - Teach `StructExpression` and `TupleExpression` how to slice by integers, facilitating the construction of structs of a prefix of fields.; - Make `ttuple` a mapping from integers to the tuple elements.; - Implement `Table._maybe_flexindex_table_by_expr` which, given a indexer expression, finds a prefix of the expression that can index the indexee, if such an expression exists. Unrelated changes:; - Clarify Makefile error echos with `ERROR:`. ---. ## flexindex. The primary use case for this is a dataset which is `locus, allele` keyed and needs to index into a `locus` keyed or `interval<locus>` keyed dataset. Hail's normal join logic will return a key mismatch error:. ```python; import hail as hl; t = hl.utils.range_table(10); t2 = t.key_by(x=t.idx, y=t.idx); t.index(t2.key); ```; ```; Traceback (most recent call last):; File ""<ipython-input-6-3ddc90774dfe>"", line 1, in <module>; t.index(t2.key); File ""/usr/local/lib/python3.7/site-packages/hail/table.py"", line 1536, in index; raise ExpressionException(f""Key type mismatch: cannot index table with given expressions:\n""; ExpressionException: Key type mismatch: cannot index table with given expressions:; Table key: int32; Index Expressions: int32, int32; ```. This new, private, method facilitates the annotation db which users expect to automatically find a compatible prefix of the key to use as an indexer. ---. Dice came up @chrisvittal, but I'm curious to hear @tpoterba 's feedback as well.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7178:1769,error,error,1769,https://hail.is,https://github.com/hail-is/hail/pull/7178,1,['error'],['error']
Availability,"g JUnit 4 Tests using TestNG (Krishnan Mahadevan); Fixed: GITHUB-2847: Deprecate support for running JUnit tests (Krishnan Mahadevan); Fixed: GITHUB-2844: Deprecate support for running Spock Tests (Krishnan Mahadevan); Fixed: GITHUB-550: Weird <a href=""https://github.com/BeforeMethod""><code>@â€‹BeforeMethod</code></a> and <a href=""https://github.com/AfterMethod""><code>@â€‹AfterMethod</code></a> behaviour with dependsOnMethods (Krishnan Mahadevan); Fixed: GITHUB-893: TestNG should provide an Api which allow to find all dependent of a specific test (Krishnan Mahadevan); New: Added .yml file extension for yaml suite files, previously only .yaml was allowed for yaml (Steven Jubb); Fixed: GITHUB-141: regular expression in &quot;dependsOnMethods&quot; does not work (Krishnan Mahadevan); Fixed: GITHUB-2770: FileAlreadyExistsException when report is generated (melloware); Fixed: GITHUB-2825: Programmatically Loading TestNG Suite from JAR File Fails to Delete Temporary Copy of Suite File (Steven Jubb); Fixed: GITHUB-2818: Add configuration key for callback discrepancy behavior (Krishnan Mahadevan); Fixed: GITHUB-2819: Ability to retry a data provider in case of failures (Krishnan Mahadevan); Fixed: GITHUB-2308: StringIndexOutOfBoundsException in findClassesInPackage - Surefire/Maven - JDK 11 fails (Krishnan Mahadevan); Fixed: GITHUB:2788: TestResult.isSuccess() is TRUE when test fails due to expectedExceptions (Krishnan Mahadevan); Fixed: GITHUB-2800: Running Test Classes with Inherited <a href=""https://github.com/Factory""><code>@â€‹Factory</code></a> and <a href=""https://github.com/DataProvider""><code>@â€‹DataProvider</code></a> Annotated Non-Static Methods Fail (Krishnan Mahadevan); New: Ability to provide custom error message for assertThrows\expectThrows methods (Anatolii Yuzhakov); Fixed: GITHUB-2780: Use SpotBugs instead of abandoned FindBugs; Fixed: GITHUB-2801: JUnitReportReporter is too slow; Fixed: GITHUB-2807: buildStackTrace should be fail-safe (Sergey Chernov); Fixed: G",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:11245,failure,failures,11245,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['failure'],['failures']
Availability,"g++ --version; g++ (GCC) 8.1.0; Copyright (C) 2018 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. tar -xzf libsimdpp-2.0-rc2.tar.gz; g++ -O3 -march=native -std=c++11 -Ilibsimdpp-2.0-rc2 -Wall -Werror -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux -c -o ibs.o ibs.cpp; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4, simdpp::arch_avx2::expr_empty>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4, simdpp::arch_avx2::expr_empty>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4, simdpp::arch_avx2::expr_empty>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:253:45: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::float64<2>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::float64<2>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::float32<4, simdpp::arch_avx2::expr_empty>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:32,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:1563,Mask,MaskCastOverride,1563,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"g, quiet, append, ---> 62 parquet_compression, min_block_size, branching_factor, tmp_dir) 63 64 self._jsc = self._jhc.sc() /share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args) 1131 answer = self.gateway_client.send_command(command) 1132 return_value = get_return_value( -> 1133 answer, self.gateway_client, self.target_id, self.name) 1134 1135 for temp_arg in temp_args: /share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/pyspark/sql/utils.py in deco(*a, **kw) 61 def deco(*a, **kw): 62 try: ---> 63 return f(*a, **kw) 64 except py4j.protocol.Py4JJavaError as e: 65 s = e.java_exception.toString() /share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name) 317 raise Py4JJavaError( 318 ""An error occurred while calling {0}{1}{2}.\n"". --> 319 format(target_id, ""."", name), value) 320 else: 321 raise Py4JError( Py4JJavaError: An error occurred while calling o68.apply. : org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at: org.apache.spark.SparkContext.<init>(SparkContext.scala:76) is.hail.HailContext$.configureAndCreateSparkContext(HailContext.scala:84) is.hail.HailContext$.apply(HailContext.scala:164) sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) java.lang.reflect.Method.invoke(Method.java:498) py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357) py4j.Gateway.invoke(Gateway.java:280) py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) py4j.commands.CallCommand.exec",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1525:4723,error,error,4723,https://hail.is,https://github.com/hail-is/hail/issues/1525,1,['error'],['error']
Availability,"g,; 891 | ==> amazon-ebs: /usr/local/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.; 892 | ==> amazon-ebs: setuptools.SetuptoolsDeprecationWarning,; 893 | amazon-ebs: sed '/^pyspark/d' python/requirements.txt \| grep -v '^#' \| xargs python3 -m pip install -U; 894 | amazon-ebs: Collecting aiohttp==3.8.1; 895 | amazon-ebs: Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB); 896 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.1/1.1 MB 68.3 MB/s eta 0:00:00; 897 | amazon-ebs: Collecting aiohttp_session<2.8,>=2.7; 898 | amazon-ebs: Downloading aiohttp_session-2.7.0-py3-none-any.whl (14 kB); 899 | amazon-ebs: Collecting asyncinit<0.3,>=0.2.4; 900 | amazon-ebs: Downloading asyncinit-0.2.4-py3-none-any.whl (2.8 kB); 901 | amazon-ebs: Collecting avro<1.12,>=1.10; 902 | amazon-ebs: Downloading avro-1.11.1.tar.gz (84 kB); 903 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 84.2/84.2 kB 22.0 MB/s eta 0:00:00; 904 | amazon-ebs: Installing build dependencies: started; 905 | amazon-ebs: Installing build dependencies: finished with status 'done'; 906 | amazon-ebs: Getting requirements to build wheel: started; 907 | amazon-ebs: Getting requirements to build wheel: finished with status 'done'; 908 | amazon-ebs: Preparing metadata (pyproject.toml): started; 909 | amazon-ebs: Preparing metadata (pyproject.toml): finished with status 'done'; 910 | amazon-ebs: Collecting azure-identity==1.6.0; 911 | amazon-ebs: Downloading azure_identity-1.6.0-py2.py3-none-any.whl (108 kB); 912 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 108.5/108.5 kB 28.5 MB/s eta 0:00:00; 913 | amazon-ebs: Collecting azure-storage-blob==12.11.0; 914 | amazon-ebs: Downloading azure_storage_blob-12.11.0-py3-none-any.whl (346 kB); 915 | amazon-ebs: â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 346.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:2254,Down,Downloading,2254,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Down'],['Downloading']
Availability,"g.Thread.run(Thread.java:745). Shell output: main : command provided 1; main : run as user is farrell; main : requested yarn user is farrell. Container exited with a non-zero exit code 1. 2019-01-22 13:12:05 BlockManagerMaster: INFO: Removal of executor 21 requested; 2019-01-22 13:12:05 BlockManagerMasterEndpoint: INFO: Trying to remove executor 21 from BlockManagerMaster.; 2019-01-22 13:12:05 YarnSchedulerBackend$YarnDriverEndpoint: INFO: Asked to remove non-existent executor 21; 2019-01-22 13:12:06 YarnSchedulerBackend$YarnDriverEndpoint: INFO: Disabling executor 14.; 2019-01-22 13:12:06 DAGScheduler: INFO: Executor lost: 14 (epoch 16); 2019-01-22 13:12:06 BlockManagerMasterEndpoint: INFO: Trying to remove executor 14 from BlockManagerMaster.; 2019-01-22 13:12:06 BlockManagerMasterEndpoint: INFO: Removing block manager BlockManagerId(14, scc-q05.scc.bu.edu, 42935, None); 2019-01-22 13:12:06 BlockManagerMaster: INFO: Removed 14 successfully in removeExecutor; 2019-01-22 13:12:06 DAGScheduler: INFO: Shuffle files lost for executor: 14 (epoch 16); 2019-01-22 13:12:06 YarnScheduler: ERROR: Lost executor 12 on scc-q03.scc.bu.edu: Container marked as failed: container_e2435_1542127286896_0174_01_000022 on host: scc-q03.scc.bu.edu. Exit status: 1. Diagnostics: Exception from container-launch.; Container id: container_e2435_1542127286896_0174_01_000022; Exit code: 1; Stack trace: ExitCodeException exitCode=1:; at org.apache.hadoop.util.Shell.runCommand(Shell.java:576); at org.apache.hadoop.util.Shell.run(Shell.java:487); at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:753); at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:371); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:303); at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); at java.util.concurrent.Fu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:190210,ERROR,ERROR,190210,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,1,['ERROR'],['ERROR']
Availability,"g.count()); File ""</opt/conda/lib/python3.6/site-packages/decorator.py:decorator-gen-764>"", line 2, in aggregate; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/typecheck/check.py"", line 560, in wrapper; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/table.py"", line 1133, in aggregate; File ""</opt/conda/lib/python3.6/site-packages/decorator.py:decorator-gen-436>"", line 2, in analyze; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/typecheck/check.py"", line 560, in wrapper; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/expr/expressions/expression_utils.py"", line 94, in analyze; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/expr/expressions/expression_utils.py"", line 237, in get_refs; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/expr/expressions/expression_utils.py"", line 212, in _get_refs; AttributeError: 'NoneType' object has no attribute '_indices_from_ref'; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [251cbf7beb5f4503ba74e4d69bd09ec3] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""/Users/laurent/tools/gnomad_hail/pyhail.py"", line 132, in <module>; main(args, pass_through_args); File ""/Users/laurent/tools/gnomad_hail/pyhail.py"", line 113, in main; subprocess.check_output(job); File ""/anaconda3/lib/python3.6/subprocess.py"", line 336, in check_output; **kwargs).stdout; File ""/anaconda3/lib/python3.6/subprocess.py"", line 418, in run; output=stdout, stderr=stderr); ```. Note that first filtering the table, then running agg.group_by it works, if I just run agg_filter without agg.group_by (just agg.count()), it also works. For ref, this is `pops_ht` schema:; ```; ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 's': str ; 'known_pop': str ; 'known_subpop': str ; '_kgp': bool ; 'pop': st",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5296:1837,ERROR,ERROR,1837,https://hail.is,https://github.com/hail-is/hail/issues/5296,1,['ERROR'],['ERROR']
Availability,"gWarning(TaskSetManager.scala:52); at org.apache.spark.scheduler.TaskSetManager.handleFailedTask(TaskSetManager.scala:693); at org.apache.spark.scheduler.TaskSchedulerImpl.handleFailedTask(TaskSchedulerImpl.scala:421); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply$mcV$sp(TaskResultGetter.scala:139); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:124); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:124); at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:124); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```; `pyhail-submit`:; ```bash; #!/bin/bash. if [ $# -ne 2 ]; then; echo 'usage: gcp-pyhail-submit <cluster> <py-file>'; exit 1; fi. cluster=$1; script=$2. echo cluster = $cluster; echo script = $script. HASH=`gsutil cat gs://hail-common/latest-hash.txt`. JAR_FILE=hail-hail-is-master-all-spark2.0.2-$HASH.jar; JAR=gs://hail-common/$JAR_FILE. PYHAIL_ZIP=gs://hail-common/pyhail-hail-is-master-$HASH.zip. gcloud dataproc jobs submit pyspark \; $script \; --cluster $cluster \; --files=$JAR \; --py-files=$PYHAIL_ZIP \; --properties=""spark.driver.extraClassPath=./$JAR_FILE,spark.executor.extraClassPath=./$JAR_FILE"" \; --; ```; cluster JSON:; ```; {; ""projectId"": ""broad-ctsa"",; ""clusterName"": ""cluster-2"",; ""config"": {; ""configBucket"": ""dataproc-7f9e9d5e-03bd-4e95-bea1-fe0321239b35-us"",; ""gceClusterConfig"": {; ""zoneUri"": ""https://www.googleapis.com/compute/v1/projects/broad-ctsa/zones/us-central1-f"",; ""networkUri"": ""https://www.googleapis.com/compute/v1/projects/broad-ctsa/global/networks/default"",; ""serviceAccountScopes"": [; ""https://www.googleapis.com/auth/bigquery"",; ""https://ww",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027:2516,echo,echo,2516,https://hail.is,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027,2,['echo'],['echo']
Availability,"gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:7984,error,error,7984,https://hail.is,https://github.com/hail-is/hail/issues/9939,1,['error'],['error']
Availability,"gatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:745). 2019-01-22 13:12:06 YarnClientSchedulerBackend: INFO: Interrupting monitor thread; 2019-01-22 13:12:06 YarnClientSchedulerBackend: INFO: Shutting down all executors; 2019-01-22 13:12:06 YarnSchedulerBackend$YarnDriverEndpoint: INFO: Asking each executor to shut down; 2019-01-22 13:12:06 SchedulerExtensionServices: INFO: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-22 13:12:06 YarnClientSchedulerBackend: INFO: Stopped; 2019-01-22 13:12:06 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!; 2019-01-22 13:12:06 MemoryStore: INFO: MemoryStore cleared; 2019-01-22 13:12:06 BlockManager: INFO: BlockManager stopped; 2019-01-22 13:12:06 BlockManagerMaster: INFO: BlockManagerMaster stopped; 2019-01-22 13:12:06 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!; 2019-01-22 13:12:06 TransportResponseHandler: ERROR: Still have 1 requests outstanding when connection from /192.168.18.203:44844 is closed; 2019-01-22 13:12:06 YarnSchedulerBackend$YarnSchedulerEndpoint: WARN: Attempted to get executor loss reason for executor id 14 at RPC address 192.168.18.189:50356, but got no response. Marking as slave lost.; java.io.IOException: Connection from /192.168.18.203:44844 closed; at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146); at org.apache.spark.network.server.TransportChannelHandler.channelInactive(Transpo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:209487,down,down,209487,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,5,"['ERROR', 'down']","['ERROR', 'down']"
Availability,gcc error when building,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1520:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/1520,1,['error'],['error']
Availability,ge$.using(package.scala:657); E 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); E 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:62); E 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$1(LocalBackend.scala:109); E 	at is.hail.backend.local.LocalBackend.executeToEncoded(LocalBackend.scala:208); E 	at is.hail.backend.local.LocalBackend.$anonfun$executeEncode$2(LocalBackend.scala:237); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:76); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:76); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); E 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:62); E 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$1(LocalBackend.scala:109); E 	at is.hail.backend.local.LocalBackend.$anonfun$executeEncode$1(LocalBackend.scala:236); E 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); E 	at is.hail.backend.local.LocalBackend.executeEncode(LocalBackend.scala:234); E 	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source); E 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); E 	at java.lang.reflect.Method.invoke(Method.java:498); E 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); E 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); E 	at py4j.Gateway.invoke(Gateway.java:282); E 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); E 	at py4j.commands.CallCommand.execute(CallCommand.java:79); E 	at py4j.GatewayConnection.run(GatewayConnection.java:238); E 	at java.lang.Thread.run(Thread.java:750); E ; E ; E ; E Hail version: 0.2.124-b31f1dcea5d2; E Error summary: RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:15240,Error,Error,15240,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198,1,['Error'],['Error']
Availability,"ge(1, 10)}. # import bgen(s); mt = hl.methods.import_bgen('gs://fc-7d5088b4-7673-45b5-95c2-17ae00a04183/imputed/ukb_imp_chr{22}_v3.bgen',; ['dosage'],; sample_file='gs://phenotype_31063/ukb31063.imputed_v3.autosomes.sample',; contig_recoding=contigs). # load scoring sample; sampleids = hl.import_table('gs://ukb31063-mega-gwas/hail-0.1/qc/ukb31063.gwas_samples.txt', delimiter='\s+').key_by('s'). # merge sumstats on bgen matrixtable; mt = mt.annotate_rows(ss=sumstats[mt.locus]). # handle strand/sign flips -- score in terms of alt allele; mt = mt.annotate_rows(beta = hl.case(); .when(((mt.alleles[0] == mt.ss.nt1) &; (mt.alleles[1] == mt.ss.nt2)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt1) &; (flip_text(mt.alleles[1]) == mt.ss.nt2)),; (-1*mt.ss.ldpred_inf_beta)); .when(((mt.alleles[0] == mt.ss.nt2) &; (mt.alleles[1] == mt.ss.nt1)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt2) &; (flip_text(mt.alleles[1]) == mt.ss.nt1)),; mt.ss.ldpred_inf_beta); .or_missing()). # filter bgen matrixtable down to only SNPs with betas; mt = mt.filter_rows(hl.is_defined(mt.beta)). # filter bgen matrixtable to only include people in scoring sample; mt = mt.filter_cols(hl.is_defined(sampleids[mt.s])). # score sample; mt = mt.annotate_cols(prs=hl.agg.sum(mt.beta * mt.dosage)). # write out table with sample IDs and PRS scores; mt.cols().export('gs://ukbb_prs/prs/UKB_'+pheno+'_PRS_22.txt'). parser = argparse.ArgumentParser(); parser.add_argument(""--phenotype"", help=""name of the sumstat phenotype""); args = parser.parse_args(). try:; start = time.time(); main(args.phenotype); end = time.time(); message = ""Success! Job was completed in %s"" % time.strftime(""%H:%M:%S"", time.gmtime(end - start)); send_message(message); except Exception as e:; send_message(""Fail.""); ```. ""Failure Reason"":; ```; Job aborted due to stage failure: Task 98 in stage 13.0 failed 20 times, most recent failure: Lost task 98.19 in stage 13.0 (TID 22699, ccarey-sw-xt4j.c.ukbb-robinson.internal, executor 68): java.lang.NegativeArrayS",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:2031,down,down,2031,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681,1,['down'],['down']
Availability,ge.scala:596); 	at is.hail.annotations.Region$.scoped(Region.scala:18); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:7); 	at is.hail.backend.Backend.execute(Backend.scala:56); 	at is.hail.backend.Backend.executeJSON(Backend.scala:62); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). org.json4s.package$MappingException: unknown error; 	at org.json4s.Extraction$.extract(Extraction.scala:43); 	at org.json4s.ExtractableJsonAstNode.extract(ExtractableJsonAstNode.scala:21); 	at is.hail.io.index.IndexReader$.readMetadata(IndexReader.scala:65); 	at is.hail.io.index.IndexReader.<init>(IndexReader.scala:90); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.HailContext$$anon$3$$anonfun$20.apply(HailContext.scala:879); 	at is.hail.HailContext$$anon$3$$anonfun$20.apply(HailContext.scala:877); 	at scala.Option.map(Option.scala:146); 	at is.hail.HailContext$$anon$3.compute(HailContext.scala:877); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at or,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:17094,error,error,17094,https://hail.is,https://github.com/hail-is/hail/issues/7044,2,['error'],['error']
Availability,"ge:. ```; int32 the number of strings to expect; (; int32 the number of bytes in the next string; byte* UTF-8 string; )*; ```. The array of strings is interpreted as:. ```; comma-spearated-classpath; main-class-name; arg0; arg1; ...; ```. The entryway constructs a URLClassLoader with the given classpath, reflectively allocates an; instance of the mainclass and invokes the `main` method with the remaining arguments. This is; obviously a security risk. The system bans JARs from locations not controlled (and locked down) by; Hail Team. You should require me to hardcode the mainclass as; `is.hail.backend.service.ServiceBackendSocketAPI2` before we merge; however, this flexibility was; useful during development. The JVMEntryway will eventually be useful because we will keep a ClassLoader full of a bunch of; JIT-optimized Hail classes. I did not include that in this PR because we need to finish eliminating; global state used by Hail. Currently, two executions would try to re-use compiled class names for; different code, leading to very weird errors. # Changes to File Systems. Hail has three four file system interfaces:. | File System Interface | Public | Language | Async |; | ----------------------- | ------ | -------- | ----- |; | hail.utils.hadoop_utils | Yes | Python | no |; | hail.fs | Yes | Python | no |; | hailtop.aiotools.fs | No | Python | yes |; | is.hail.io.fs | No | Scala | no |. `hail.fs` is technically in the public API (via `hl.current_backend().fs`), but I doubt anyone uses; it. `hail.utils.hadoop_utils` is a shim over `hail.fs`, there are no direct concrete implementations of; it. This PR adds `hail.fs.RouterFS` to `hail.fs`, a synchronous wrapper around; `hailtop.aiotools.fs.AsyncRouterFS`. A ""router"" file system is one which operates on URLs instead of; paths. It uses the URL's protocol to determine which concrete file system to use. For example, a; router fs can `open` both `gs://danking/abc` and `s3a://danking/abc`. Each Hail Query Python Backend is as",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11194:4235,error,errors,4235,https://hail.is,https://github.com/hail-is/hail/pull/11194,1,['error'],['errors']
Availability,"gene_variant|MODIFIER|WASH7P|ENSG00000227232|Transcript|ENST00000488147|unprocessed_pseudogene|||||||||||2206|-1||HGNC|HGNC:38034|||||||||||||||||||||||||||;DP=3;AF=0.5;MLEAC=1;MLEAF=0.5;AN=2;AC=1	GT:AD:DP:GQ:PL	./.:.:.:.:.	0/1:1,2:3:37:77,0,37; ```. Getting this error message:; ```; INFO: [pid 11941] Worker Worker(salt=943636132, workers=1, host=seqr-loading-cluster-m, username=root, pid=11941) running SeqrVCFToMTTask(source_paths=gs://seqr-bw/merged_phased_3P5CH.split.vcf.gz, dest_path=gs://seqr-bw/merged_phased_3P5CH.mt, genome_version=38, vep_runner=VEP, reference_ht_path=gs://seqr-reference-data/GRCh38/all_reference_data/combined_reference_data_grch38.ht, clinvar_ht_path=gs://seqr-reference-data/GRCh38/clinvar/clinvar.GRCh38.2020-03-29.ht, hgmd_ht_path=None, sample_type=WGS, validate=False, dataset_type=VARIANTS, remap_path=, subset_path=, vep_config_json_path=); Initializing Spark and Hail with default parameters...; Running on Apache Spark version 2.4.5; SparkUI available at http://seqr-loading-cluster-m.c.seqr-project.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.34-914bd8a10ca2; LOGGING: writing to /tmp/c7e0443c47b54e91b295e2bff7b554b9/hail-20200405-1408-0.2.34-914bd8a10ca2.log; {'_Task__hash': -3818947167740532127,; 'clinvar_ht_path': 'gs://seqr-reference-data/GRCh38/clinvar/clinvar.GRCh38.2020-03-29.ht',; 'dataset_type': 'VARIANTS',; 'decrease_running_resources': <bound method TaskStatusReporter.decrease_running_resources of <luigi.worker.TaskStatusReporter object at 0x7f0583f0f588>>,; 'dest_path': 'gs://seqr-bw/merged_phased_3P5CH.mt',; 'genome_version': '38',; 'hgmd_ht_path': None,; 'param_kwargs': {'clinvar_ht_path': 'gs://seqr-reference-data/GRCh38/clinvar/clinvar.GRCh38.2020-03-29.ht',; 'dataset_type': 'VARIANTS',; 'dest_path': 'gs://seqr-bw/merged_phased_3P5CH.mt',; 'genome_version': '38',; 'hgmd_ht_path': None,; 'reference_ht_path': 'gs://seqr-reference-data/GRCh38/all_reference_data/combined_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:36742,avail,available,36742,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['avail'],['available']
Availability,"generate a better error message than ""part file not found"" on read if a MT/TAble is written to a non-network-visible file path",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5093:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/issues/5093,1,['error'],['error']
Availability,"genome, contig_recoding, array_elements_required, skip_invalid_loci); 1893 skip_invalid_loci,; 1894 force_bgz,; -> 1895 force; 1896 ); 1897 return MatrixTable(jmt). ~/bin/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. ~/bin/anaconda3/lib/python3.6/site-packages/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 211 except pyspark.sql.utils.CapturedException as e:; 212 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:633); 	at is.hail.io.vcf.MatrixVCFReader.<init>(LoadVCF.scala:894); 	at is.hail.io.vcf.LoadVCF$.pyApply(LoadVCF.scala:850); 	at is.hail.io.vcf.LoadVCF.pyApply(LoadVCF.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4775:2471,Error,ErrorHandling,2471,https://hail.is,https://github.com/hail-is/hail/issues/4775,1,['Error'],['ErrorHandling']
Availability,"ges here, including the full java stack trace):; ```; 2018-06-19 17:15:41 Hail: INFO: vep: annotated 2 variants; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/opt/hail/python/hail/table.py"", line 1195, in show; print(self._show(n,width, truncate, types)); File ""/opt/hail/python/hail/table.py"", line 1198, in _show; return self._jt.showString(n, joption(truncate), types, width); File ""/opt/spark-2.2.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/opt/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;). Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 11.0 failed 1 times, most recent failure: Lost task 0.0 in stage 11.0 (TID 11, localhost, executor driver): scala.MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;); 	at is.hail.annotations.RegionValueBuilder.addAnnotation(RegionValueBuilder.scala:489); 	at is.hail.methods.VEP$$anonfun$9$$anonfun$apply$4.apply(VEP.scala:350); 	at is.hail.methods.VEP$$anonfun$9$$anonfun$apply$4.apply(VEP.scala:345); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:926); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:920); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.RVD$$anonfun$3$$anon$1.hasNext(R",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3790:1421,failure,failure,1421,https://hail.is,https://github.com/hail-is/hail/issues/3790,1,['failure'],['failure']
Availability,get sphinx to generate an error when references are missing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2897:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/issues/2897,1,['error'],['error']
Availability,github status should be pending if success but build out of date; protect entire build/deploy with try/catch; build_state: merge_failure => error; report build error in pr page; don't merge/deploy if target sha is None. Not showing deploy error yet.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6069:140,error,error,140,https://hail.is,https://github.com/hail-is/hail/pull/6069,3,['error'],['error']
Availability,"github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10007"">#10007</a>: Drop <code>setuptools</code></li>; </ul>; <h2>Features added</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9075"">#9075</a>: autodoc: Add a config variable :confval:<code>autodoc_typehints_format</code>; to suppress the leading module names of typehints of function signatures (ex.; <code>io.StringIO</code> -&gt; <code>StringIO</code>)</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9831"">#9831</a>: Autosummary now documents only the members specified in a module's; <code>__all__</code> attribute if :confval:<code>autosummary_ignore_module_all</code> is set to; <code>False</code>. The default behaviour is unchanged. Autogen also now supports; this behavior with the <code>--respect-module-all</code> switch.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9555"">#9555</a>: autosummary: Improve error messages on failure to load target object</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9800"">#9800</a>: extlinks: Emit warning if a hardcoded link is replaceable; by an extlink, suggesting a replacement.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9961"">#9961</a>: html: Support nested <!-- raw HTML omitted --> HTML elements in other HTML builders</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10013"">#10013</a>: html: Allow to change the loading method of JS via <code>loading_method</code>; parameter for :meth:<code>Sphinx.add_js_file()</code></li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9551"">#9551</a>: html search: &quot;Hide Search Matches&quot; link removes &quot;highlight&quot; parameter; from URL</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9815"">#9815</a>: html theme: Wrap sidebar components in div t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11522:1893,error,error,1893,https://hail.is,https://github.com/hail-is/hail/pull/11522,4,"['error', 'failure']","['error', 'failure']"
Availability,"github.com/scipy/scipy/commit/6b098c25223e224ff44101f86bbc86efecffe1d9""><code>6b098c2</code></a> TST: optimize.milp: remove problematic timeout/iteration test</li>; <li><a href=""https://github.com/scipy/scipy/commit/24dce9760b87934f1be046ec817c758b0f3952dc""><code>24dce97</code></a> DOC: stats.pearsonr: typo in coeffic<em>i</em>ent (<a href=""https://github-redirect.dependabot.com/scipy/scipy/issues/17153"">#17153</a>)</li>; <li><a href=""https://github.com/scipy/scipy/commit/a6ba7cad3b54c35d2ccb55c595691689004742c1""><code>a6ba7ca</code></a> MAINT: misc 1.9.2 updates</li>; <li><a href=""https://github.com/scipy/scipy/commit/ed9760e60a28b8f13e5644494033e2dab9aafbcd""><code>ed9760e</code></a> MAINT: stats.pearson3: fix ppf for negative skew (<a href=""https://github-redirect.dependabot.com/scipy/scipy/issues/17055"">#17055</a>)</li>; <li><a href=""https://github.com/scipy/scipy/commit/6fb67007dd7105755057f3379fb7ef423eae524e""><code>6fb6700</code></a> FIX: optimize.milp: return feasible solution if available on timeout/node lim...</li>; <li><a href=""https://github.com/scipy/scipy/commit/bcfce27fc061cbde6ac6531799362e0420ea4796""><code>bcfce27</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/scipy/scipy/issues/17132"">#17132</a> from tylerjereddy/treddy_192_backports</li>; <li><a href=""https://github.com/scipy/scipy/commit/2bc973a2c28c4b6b5bea0e288631834fe34b526e""><code>2bc973a</code></a> BLD: set version to 1.9.2.dev0 (and trigger wheel build CI)</li>; <li>Additional commits viewable in <a href=""https://github.com/scipy/scipy/compare/v1.2.1...v1.9.2"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by comm",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12352:2831,avail,available,2831,https://hail.is,https://github.com/hail-is/hail/pull/12352,1,['avail'],['available']
Availability,"google died:; ```; E Log:	{'main': ""ERROR: (gcloud.auth.activate-service-account) There was a problem refreshing your current auth tokens: {u'status': u'UNAVAILABLE', u'message': u'The service is currently unavailable.', u'code': 503}\nPlease run:\n\n $ gcloud auth login\n\nto obtain new credentials, or if you have already logged in with a\ndifferent account:\n\n $ gcloud config set account ACCOUNT\n\nto select an already authenticated account to use.\n""}; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5934#issuecomment-486735019:36,ERROR,ERROR,36,https://hail.is,https://github.com/hail-is/hail/pull/5934#issuecomment-486735019,1,['ERROR'],['ERROR']
Availability,"got a doctest error:; ```; ______________ [doctest] hail.experimental.ldscsim.get_cov_matrix ______________; 035 trait 3 & trait 4 :math:`r_g` = 0.6; 036 To obtain the covariance matrix corresponding to this scenario :math:`h^2` values are; 037 ordered according to user specification and :math:`r_g` values are ordered by the ; 038 order in which the corresponding genetic covariance terms will appear in the ; 039 covariance matrix, reading lines in the upper triangular matrix from left to; 040 right, top to bottom (read first row left to right, read second row left to ; 041 right, etc.), exluding the diagonal.; 042 ; 043 >>> cov_matrix, rg = get_cov_matrix(h2=[0.1, 0.3, 0.2, 0.6], rg=[0.4, 0.3, 0.1, 0.2, 0.15, 0.6]); 044 >>> print(cov_matrix); Differences (unified diff with -expected +actual):; @@ -1,4 +1,4 @@; -array([[0.1 , 0.06928203, 0.04242641, 0.0244949 ],; - [0.06928203, 0.3 , 0.04898979, 0.06363961],; - [0.04242641, 0.04898979, 0.2 , 0.2078461 ],; - [0.0244949 , 0.06363961, 0.2078461 , 0.6 ]]; +[[0.1 0.06928203 0.04242641 0.0244949 ]; + [0.06928203 0.3 0.04898979 0.06363961]; + [0.04242641 0.04898979 0.2 0.2078461 ]; + [0.0244949 0.06363961 0.2078461 0.6 ]]. /hail/python/hail/experimental/ldscsim.py:44: DocTestFailure. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8265#issuecomment-601360575:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/pull/8265#issuecomment-601360575,1,['error'],['error']
Availability,got test failure: https://ci.hail.is/batches/13670/jobs/33/log,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7092#issuecomment-533282019:9,failure,failure,9,https://hail.is,https://github.com/hail-is/hail/pull/7092#issuecomment-533282019,1,['failure'],['failure']
Availability,"grm error - ""org.apache.spark.SparkException: Kryo serialization failed: Buffer overflow. Available: 6, required: 8""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/321:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/321,2,"['Avail', 'error']","['Available', 'error']"
Availability,"gs, **kwargs); 505 def _typecheck(__orig_func__, *args, **kwargs):; 506 args_, kwargs_ = check_all(__orig_func__, args, kwargs, checkers, is_method=True); --> 507 return __orig_func__(*args_, **kwargs_); 508; 509 return decorator(_typecheck). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-c8ca698c6ed5.zip/hail/matrixtable.py in _select_rows(self, caller, key_struct, value_struct, pk_size); 2814; 2815 return cleanup(MatrixTable(base._jvds.selectRows(row._ast.to_hql(),; -> 2816 new_key))); 2817; 2818 @typecheck_method(caller=str,. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-c8ca698c6ed5.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NegativeArraySizeException: null. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 24 in stage 9.0 failed 20 times, most recent failure: Lost task 24.19 in stage 9.0 (TID 2874, berylc-sw-68wx.c.broad-mpg-gnomad.internal, executor 39): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:140); 	at is.hail.annotations.Region.allocate(Region.scala:153); 	at is.hail.annotations.Region.allocate(Region.scala:160); 	at is.hail.codegen.generated.C11.apply(Unknown Source); 	at is.hail.codegen.generated.C11.apply(Unknown Source); 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:650); 	at is.hail.HailContext$$anon$2.next(HailCo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3583:3340,Error,Error,3340,https://hail.is,https://github.com/hail-is/hail/issues/3583,1,['Error'],['Error']
Availability,"h/issues/11790"">#11790</a> [component: build] Bryanv/pin sphinx 42</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11797"">#11797</a> Add OS to bokeh info</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11805"">#11805</a> More 3.0 -&gt; 2.4.2 backports</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11810"">#11810</a> [component: docs] Update docs for new issue forms</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11824"">#11824</a> Updates for release</li>; </ul>; </li>; </ul>; <h2>2021-10-13 2.4.1:</h2>; <ul>; <li>; <p>bugfixes:</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11119"">#11119</a> [component: bokehjs] [BUG] varea_stack() and vline_stack() fails to update correctly when new source data is different length</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11625"">#11625</a> [component: tests] [BUG] Codebase test failures in Windows</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11627"">#11627</a> [BUG] mypy tests fail in Windows</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11629"">#11629</a> [BUG] Hover tool takes long time to render</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11633"">#11633</a> [component: bokehjs] [BUG] RangesUpdate not emitted when using xwheel_pan</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11645"">#11645</a> [component: bokehjs] [BUG] <code>bokeh init</code> creates a <code>package.json</code> which refers to the deprecated Bokeh JS node package</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11646"">#11646</a> [component: bokehjs] [BUG] Using band_hatch_pattern with images doesn't work</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11661"">#11661</a> [component: bokehjs] [BUG] Issue wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11540:3384,failure,failures,3384,https://hail.is,https://github.com/hail-is/hail/pull/11540,1,['failure'],['failures']
Availability,"h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. <details>; <summary>âš ï¸ <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiohttp 3.8.5 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **661/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 7.5 | Improper Neutralization of Special Elements in Data Query Logic <br/>[SNYK-PYTHON-MSAL-5904284](https://snyk.io/vuln/SNYK-PYTHON-MSAL-5904284) | `msal:` <br> `1.24.0 -> 1.24.1` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2NWVkZTk2ZC0xYjZkLTQ1ZjktOT",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13754:1125,avail,available,1125,https://hail.is,https://github.com/hail-is/hail/pull/13754,1,['avail'],['available']
Availability,"h_avx2::uint64<8>]â€™; libsimdpp-2.0-rc2/simdpp/types/int64.h:49:35: required from â€˜simdpp::arch_avx2::int64<N>& simdpp::arch_avx2::int64<N>::operator=(const simdpp::arch_avx2::any_vec<(N * 8), V>&) [with V = simdpp::arch_avx2::uint64<8>; unsigned int N = 8]â€™; libsimdpp-2.0-rc2/simdpp/types/int64.h:42:73: required from â€˜simdpp::arch_avx2::int64<N>::int64(const simdpp::arch_avx2::uint64<N, E>&) [with E = void; unsigned int N = 8]â€™; libsimdpp-2.0-rc2/simdpp/core/combine.h:80:69: required from â€˜simdpp::arch_avx2::int64<(N * 2)> simdpp::arch_avx2::combine(const simdpp::arch_avx2::int64<N, E>&, const simdpp::arch_avx2::int64<N, E2>&) [with unsigned int N = 4; E1 = void; E2 = void]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/to_int64.h:70:26: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::int64<8>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::int64<8>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint64<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:38,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64.h:30:7: note: â€˜class simdpp::arch_avx2::int64<8>â€™ declared here; class int64<N, void> : public any_int64<N, int64<N,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int16<32>; T = simdpp::arch_avx2::uint16<32>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:136247,error,error,136247,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"h_avx2::uint8<16>; T = simdpp::arch_avx2::uint16<8>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::uint16<8>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::uint16<8>]â€™; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:129:36: required from â€˜simdpp::arch_avx2::uint8<16>::uint8(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint16<8>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_or.h:69:42: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint8<16>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint8<16>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint16<8>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:19,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:104:7: note: â€˜class simdpp::arch_avx2::uint8<16>â€™ declared here; class uint8<16, void> : public any_int8<16, uint8<16,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint8<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:5608,error,error,5608,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"haha, you are an Awk Queen! This looks great to me, I'm glad we were able to nail down the security.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9076#issuecomment-662526023:82,down,down,82,https://hail.is,https://github.com/hail-is/hail/pull/9076#issuecomment-662526023,1,['down'],['down']
Availability,"hail 0.2.33, python 3.7.3. `hl.init(sc); Traceback (most recent call last):; File ""<console>"", line 1, in <module>; File ""<decorator-gen-1214>"", line 2, in init; File ""/tmp/conda-9cc77aa7-66f1-4cac-870e-53c3df210a16/real/envs/conda-env/lib/python3.7/site-packages/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/tmp/conda-9cc77aa7-66f1-4cac-870e-53c3df210a16/real/envs/conda-env/lib/python3.7/site-packages/hail/context.py"", line 290, in init; _optimizer_iterations,_backend); File ""<decorator-gen-1212>"", line 2, in __init__; File ""/tmp/conda-9cc77aa7-66f1-4cac-870e-53c3df210a16/real/envs/conda-env/lib/python3.7/site-packages/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/tmp/conda-9cc77aa7-66f1-4cac-870e-53c3df210a16/real/envs/conda-env/lib/python3.7/site-packages/hail/context.py"", line 121, in __init__; min_block_size, branching_factor, tmp_dir, optimizer_iterations); File ""/tmp/conda-9cc77aa7-66f1-4cac-870e-53c3df210a16/real/envs/conda-env/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1286, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/tmp/conda-9cc77aa7-66f1-4cac-870e-53c3df210a16/real/envs/conda-env/lib/python3.7/site-packages/transforms/_java_utils.py"", line 237, in wrapper; return func(*args, **kwargs); File ""/tmp/conda-9cc77aa7-66f1-4cac-870e-53c3df210a16/real/envs/conda-env/lib/python3.7/site-packages/py4j/protocol.py"", line 332, in get_return_value; format(target_id, ""."", name, value)); py4j.protocol.Py4JError: An error occurred while calling z:is.hail.HailContext.apply. Trace:; py4j.Py4JException: Method apply([class org.apache.spark.SparkContext, class java.lang.String, class scala.None$, class java.lang.String, class java.lang.String, class java.lang.Boolean, class java.lang.Boolean, class java.lang.Integer, class java.lang.Integer, class java.lang.String, class java.lang.Integer]) does not exist`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8423#issuecomment-607430617:1585,error,error,1585,https://hail.is,https://github.com/hail-is/hail/issues/8423#issuecomment-607430617,1,['error'],['error']
Availability,"hail currently only supports v5.4. The current version v6.3.2 (https://www.elastic.co/downloads/elasticsearch) has some nice new features such as field aliases.; The main breaking change from v5.x is that ""mapping_types"" have been removed, so the ; kt.export_elasticsearch `mapping_type` arg isn't needed anymore (https://www.elastic.co/guide/en/elasticsearch/reference/6.0/breaking-changes-6.0.html). ### Hail version:; 0.1, 0.2. ### What you did:. kt.export_elasticsearch. ### What went wrong (all error messages here, including the full java stack trace):; ```; Traceback (most recent call last):; File ""/hail-elasticsearch-pipelines/hail_scripts/v01/load_clinvar_to_es_pipeline.py"", line 112, in <module>; export_globals_to_index_meta=True,; File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 142, in export_vds_to_elasticsearch; verbose=verbose); File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 287, in export_kt_to_elasticsearch; kt.export_elasticsearch(self._host, int(self._port), index_name, index_type_name, block_size, config=elasticsearch_config); File ""<decorator-gen-143>"", line 2, in export_elasticsearch; File ""/hail/build/distributions/hail-python.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 6.0.0. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 1 times, most recent failure: Lost task 0.0 in stage 12.0 (TID 20050, localhost): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot detect ES version - typically this happens if the network/Elasticsearch cluster is not accessible or when targeting a WAN/Cloud instance without the proper setting 'es.nodes.wan.only'; 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:247); 	at org.elasticsearch.hadoop.rest.RestService.createWri",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:86,down,downloads,86,https://hail.is,https://github.com/hail-is/hail/issues/4138,2,"['down', 'error']","['downloads', 'error']"
Availability,hail v0.2.124 on AWS - java error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/issues/13837,1,['error'],['error']
Availability,"hail version: 0.2.12-13681278eb89. When running `x.aggregate(hl.agg.hist(x.FS, 0, 200, 100))`, I got the following error. First setting `-0.0` values to `0.0` fixed the problem. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-56-b39eaa27c3df> in <module>; 9 ); 10 ); ---> 11 hist_data = x.aggregate(hl.agg.hist(x.FS, 0, 200, 100)); 12 # show(hl.plot.histogram(x.FS)). </opt/conda/lib/python3.6/site-packages/decorator.py:decorator-gen-931> in aggregate(self, expr, _localize). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 559 def wrapper(__original_func, *args, **kwargs):; 560 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 561 return __original_func(*args_, **kwargs_); 562 ; 563 return wrapper. /home/hail/hail.zip/hail/table.py in aggregate(self, expr, _localize); 1138 ; 1139 if _localize:; -> 1140 return Env.backend().execute(agg_ir); 1141 else:; 1142 return construct_expr(agg_ir, expr.dtype). /home/hail/hail.zip/hail/backend/backend.py in execute(self, ir); 91 return ir.typ._from_json(; 92 Env.hail().backend.spark.SparkBackend.executeJSON(; ---> 93 self._to_java_ir(ir))); 94 ; 95 def value_type(self, ir):. /usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 226 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 227 'Hail version: %s\n'; --> 228 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 229 except pyspark.sql.utils.CapturedException as e:; 230 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: HailException: found out of bounds index -1; Resul",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5846:115,error,error,115,https://hail.is,https://github.com/hail-is/hail/issues/5846,1,['error'],['error']
Availability,hail-new importvcf /user/lfran/MacArthur_Merck_Finns.vcf.bgz splitmulti \; write -o /user/aganna/MacArthur_Merck_Finns.vds. Error: (1525 + 59) / 23758]hail: write: caught exception: org.apache.spark.SparkException: Job aborted. [hail.log.txt](https://github.com/broadinstitute/hail/files/222377/hail.log.txt),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/301:124,Error,Error,124,https://hail.is,https://github.com/hail-is/hail/issues/301,1,['Error'],['Error']
Availability,"hail.expr.ir.CallFunctionsSuite.constructors` to run one test, or `mill test -threadcount 4 -parallel classes` to use 4 threads and parallelize over test classes; * `mill test.testOnly is.hail.expr.ir.CallFunctionsSuite` - run all tests in one or more specified classes. You can use `*` to match anything, e.g. `mill test.testOnly ""*.CallFunctionsSuite""`, or `mill test.testOnly ""is.hail.expr.ir.*""`. You can pass options to the test runner (TestNG currently) after a `--`, e.g. `mill test.testOnly ""is.hail.expr.ir.*"" -- -parallel classes`; * `mill __.testCached` - once the codebase is more modularized, will run tests on only modules whose dependencies have changed since the last test run; * `mill reformat` - runs scalafmt on all sources in the root module (currently that's all scala sources, but hopefully not for long). `mill __.reformat` runs scalaformat on all sources in all modules. `mill __.checkFormat` only checks for rule failures (we run this in ci); * `mill fix` - runs scalafix on all sources in the root module (currently that's all scala sources, but hopefully not for long). `mill __.fix` runs scalafix on all sources in all modules. `mill __.fix --check` only checks for rule failures (we run this in ci). You can pass any options to scalafix, e.g. `mill fix --help`.; * `mill inspect` - see the docstring and dependencies for any target, e.g. `mill inspect compile`; * `mill ivyDepsTree` - show the tree of external dependencies of the root module, highlighting potential incompatibilities in transitive dependencies. `mill ivyDepsTree --withCompile --withRuntime` includes compile-only and runtime-only dependencies. Use `--whatDependsOn` to see an inverted tree showing how a transitive dependency is getting pulled in, e.g. `mill ivyDepsTree --withCompile --withRuntime --whatDependsOn org.slf4j:slf4j-api`; * `mill mill.scalalib.Dependency/showUpdates` - show outdated dependencies (we have a lot!). See [here](https://mill-build.com/mill/Intro_to_Mill.html) and [here](ht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14147:2099,failure,failures,2099,https://hail.is,https://github.com/hail-is/hail/pull/14147,1,['failure'],['failures']
Availability,"hail/table.py"", line 1335, in write; Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 105, in execute; raise e.maybe_user_error(ir) from None; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 99, in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); File ""/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py"", line 1304, in __call__; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 31, in deco; raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; hail.utils.java.FatalError: ClassFormatError: Too many arguments in method signature in class file __C2866stream. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 8.0 failed 20 times, most recent failure: Lost task 3.19 in stage 8.0 (TID 54368) (leo-test-w-8.australia-southeast1-a.c.ourdna-browser.internal executor 14): java.lang.ClassFormatError: Too many arguments in method signature in class file __C2866stream; 	at java.lang.ClassLoader.defineClass1(Native Method); 	at java.lang.ClassLoader.defineClass(ClassLoader.java:756); 	at java.lang.ClassLoader.defineClass(ClassLoader.java:635); 	at is.hail.asm4s.HailClassLoader.liftedTree1$1(HailClassLoader.scala:10); 	at is.hail.asm4s.HailClassLoader.loadOrDefineClass(HailClassLoader.scala:6); 	at is.hail.asm4s.ClassesBytes.$anonfun$load$1(ClassBuilder.scala:64); 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198); 	at is.hail.asm4s.ClassesBytes.load(ClassBuilder.scala:62); 	at is.hail.expr.ir.EmitClassBuilder$$anon$1.apply(EmitClassBuilder.scala:715)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:3205,failure,failure,3205,https://hail.is,https://github.com/hail-is/hail/issues/12532,1,['failure'],['failure']
Availability,hailctl config is too user unfriendly; it should: error or warn on invalid names and document the list of valid names,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13195:50,error,error,50,https://hail.is,https://github.com/hail-is/hail/issues/13195,1,['error'],['error']
Availability,"hailctl dataproc start \; 	--max-idle 12h \; 	--init gs://gnomad-public/tools/inits/master-init.sh \; 	--packages slackclient==2.0.0,websocket-client,sklearn,tabulate,statsmodels,scikit-learn,hdbscan,matplotlib bw2. Fails with the following error:; ```; gcloud beta dataproc clusters create \; bw2 \; --image-version=1.4-debian9 \; --properties=spark:spark.driver.maxResultSize=0,spark:spark.task.maxFailures=20,spark:spark.kryoserializer.buffer.max=1g,spark:spark.driver.extraJavaOptions=-Xss4M,spark:spark.executor.extraJavaOptions=-Xss4M,hdfs:dfs.replication=1,dataproc:dataproc.logging.stackdriver.enable=false,dataproc:dataproc.monitoring.stackdriver.enable=false,spark:spark.driver.memory=41g \; --initialization-actions=gs://hail-common/hailctl/dataproc/0.2.18/init_notebook.py,gs://gnomad-public/tools/inits/master-init.sh \; --metadata=^|||^WHEEL=gs://hail-common/hailctl/dataproc/0.2.18/hail-0.2.18-py3-none-any.whl|||PKGS=aiohttp|bokeh>1.1,<1.3|decorator<5|gcsfs==0.2.1|hurry.filesize==0.9|ipykernel<5|nest_asyncio|numpy<2|pandas>0.22,<0.24|parsimonious<0.9|PyJWT|python-json-logger==0.1.11|requests>=2.21.0,<2.21.1|scipy>1.2,<1.4|tabulate==0.8.3|slackclient==2.0.0|websocket-client|sklearn|tabulate|statsmodels|scikit-learn|hdbscan|matplotlib \; --master-machine-type=n1-highmem-8 \; --master-boot-disk-size=100GB \; --num-master-local-ssds=0 \; --num-preemptible-workers=0 \; --num-worker-local-ssds=0 \; --num-workers=2 \; --preemptible-worker-boot-disk-size=40GB \; --worker-boot-disk-size=40 \; --worker-machine-type=n1-standard-8 \; --zone=us-central1-b \; --initialization-action-timeout=20m \; --labels=creator=weisburd_broadinstitute_org \; --max-idle=12h; Starting cluster 'bw2'...; Waiting on operation [projects/seqr-project/regions/global/operations/46f1d37d-798a-3fc0-8f70-eac304448a08].; Waiting for cluster creation operation...; WARNING: For PD-Standard without local SSDs, we strongly recommend provisioning 1TB or larger to ensure consistently high I/O performance. See h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6634:241,error,error,241,https://hail.is,https://github.com/hail-is/hail/issues/6634,1,['error'],['error']
Availability,"hailctl dataproc start error in gs://hail-common/hailctl/dataproc/0.2.18/init_notebook.py: ""Double requirement given: tabulate""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6634:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/issues/6634,1,['error'],['error']
Availability,"hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" > env/wheel_cloud_path; rm -f python/hailtop/hailctl/deploy.yaml; echo ""dataproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT bu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:3798,echo,echo,3798,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,1,['echo'],['echo']
Availability,hand deploying the last working master that is:; ```; * | | | | 49ec05df2 - (7 hours ago) [query] Throw a validation error for queries that read/write same path (#8327) - Tim Poterba (HEAD); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8523#issuecomment-611791434:117,error,error,117,https://hail.is,https://github.com/hail-is/hail/pull/8523#issuecomment-611791434,1,['error'],['error']
Availability,handle empty case for downsample,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4226:22,down,downsample,22,https://hail.is,https://github.com/hail-is/hail/pull/4226,1,['down'],['downsample']
Availability,handle fatal exceptions inside run_command to avoid bad python error msgs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1096:63,error,error,63,https://hail.is,https://github.com/hail-is/hail/issues/1096,1,['error'],['error']
Availability,handle_py4j; hail.java.FatalError: IllegalStateException: Bytecode failed verification 2. Java stack trace:; java.lang.IllegalStateException: Bytecode failed verification 2; 	at is.hail.asm4s.FunctionBuilder.classAsBytes(FunctionBuilder.scala:196); 	at is.hail.asm4s.FunctionBuilder.result(FunctionBuilder.scala:208); 	at is.hail.expr.CM.runWithDelayedValues(CM.scala:78); 	at is.hail.expr.Parser$.is$hail$expr$Parser$$evalNoTypeCheck(Parser.scala:49); 	at is.hail.expr.Parser$.is$hail$expr$Parser$$eval(Parser.scala:62); 	at is.hail.expr.Parser$.parseExpr(Parser.scala:77); 	at is.hail.expr.Parser$.parseTypedExpr(Parser.scala:87); 	at is.hail.methods.IBDPrune$$anonfun$16.apply(IBD.scala:308); 	at is.hail.methods.IBDPrune$$anonfun$16.apply(IBD.scala:308); 	at scala.Option.map(Option.scala:146); 	at is.hail.methods.IBDPrune$.apply(IBD.scala:308); 	at is.hail.variant.VariantDatasetFunctions$.ibdPrune$extension(VariantDataset.scala:529); 	at is.hail.variant.VariantDatasetFunctions.ibdPrune(VariantDataset.scala:526); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.1-dfca956; Error summary: IllegalStateException: Bytecode failed verification 2; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [0a89b0df-1299-4db1-9e90-0efc77501684] entered state [ERROR] while waiting for [DONE].```. Any idea what's wrong? Thanks!,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2178:3435,Error,Error,3435,https://hail.is,https://github.com/hail-is/hail/issues/2178,3,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,"hanged. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/102534"">kubernetes/kubernetes#102534</a>, <a href=""https://github.com/wangyysde""><code>@â€‹wangyysde</code></a>) [SIG API Machinery, Apps, Auth, Autoscaling and Testing]</li>; <li>Ephemeral containers graduated to beta and are now available by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105405"">kubernetes/kubernetes#105405</a>, <a href=""https://github.com/verb""><code>@â€‹verb</code></a>)</li>; <li>Fix kube-proxy regression on UDP services because the logic to detect stale connections was not considering if the endpoint was ready. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106163"">kubernetes/kubernetes#106163</a>, <a href=""https://github.com/aojea""><code>@â€‹aojea</code></a>) [SIG API Machinery, Apps, Architecture, Auth, Autoscaling, CLI, Cloud Provider, Contributor Experience, Instrumentation, Network, Node, Release, Scalability, Scheduling, Storage, Testing and Windows]</li>; <li>If a conflict occurs when creating an object with <code>generateName</code>, the server now returns an &quot;AlreadyExists&quot; error with a retry option. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104699"">kubernetes/kubernetes#104699</a>, <a href=""https://github.com/vincepri""><code>@â€‹vincepri</code></a>)</li>; <li>Implement support for recovering from volume expansion failures (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106154"">kubernetes/kubernetes#106154</a>, <a href=""https://github.com/gnufied""><code>@â€‹gnufied</code></a>) [SIG API Machinery, Apps and Storage]</li>; <li>In kubelet, log verbosity and flush frequency can also be configured via the configuration file and not just via command line flags. In other commands (kube-apiserver, kube-controller-manager), the flags are listed in the &quot;Logs flags&quot; group and not under &quot;Global&quot; or &quot;Misc&quot;. The",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:4337,error,error,4337,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['error'],['error']
Availability,"hanks and https://anaconda.org; >>> import hail; >>> hc = hail.HailContext(); Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://192.168.1.4:4041; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.1-0320a61; Error summary: HailException: arguments refer to no files; ```; How can",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076:2187,Error,ErrorHandling,2187,https://hail.is,https://github.com/hail-is/hail/issues/2076,1,['Error'],['ErrorHandling']
Availability,"hannels.SocketChannel.open(SocketChannel.java:145); at org.apache.hadoop.net.StandardSocketFactory.createSocket(StandardSocketFactory.java:62); at org.apache.hadoop.hdfs.DFSOutputStream.createSocketForPipeline(DFSOutputStream.java:1531); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1309); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1262); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448). Hail version: 0.2.46-6ef64c08b000; Error summary: SocketException: Too many open files; ```. This is the hail-submit script; ```bash; #!/bin/bash -l; module purge; echo ""Loading modules""; module load python3/3.7.7 #cj: new; module load gcc/8.3.0 #cj: new; module load spark/2.4.3; module load hail/0.2.46 #cj: new. export LD_LIBRARY_PATH=""$LD_LIBRARY_PATH:/usr/hdp/2.6.5.0-292/hadoop/lib/native/""; echo $LD_LIBRARY_PATH; echo ""Export env vars""; export PYTHONPATH=""$PYTHONPATH:$SPARK_HOME/python""; export PYTHONPATH=""$PYTHONPATH:$SPARK_HOME/python/lib/py4j-*-src.zip""; echo ""Submitting Spark job""; spark-submit \; --executor-cores 5 \; --executor-memory 40G \; --driver-memory 20g \; --driver-cores 5 \; --num-executors 40 \; --conf spark.yarn.appMasterEnv.LD_LIBRARY_PATH=$LD_LIBRARY_PATH \; --conf spark.executor.extraLibraryPath=$LD_LIBRARY_PATH \; --conf spark.yarn.appMasterEnv.PYTHONPATH=$PYTHONPATH \; --conf spark.yarn.appMasterEnv.PATH=$PATH \; --conf spark.yarn.jars=/share/pkg.7/spark/2.4.3/install/jars/*jar\; --jars $HAIL_HOME/backend/hail-all-spark.jar \; --master yarn \; --deploy-mode client \; --conf spark.driver.memory=20G \; --conf spark.executor.memory=40G \; --conf spark.driver.extraClassPath=\""$HAIL_HOME/backend/hail-all-spark.jar\"" \; --conf spark.executor.extraClassPath=""/usr/lib64/atlas"" \; --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \; --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator \; ""$@""; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293:18750,echo,echo,18750,https://hail.is,https://github.com/hail-is/hail/issues/9293,3,['echo'],['echo']
Availability,"happens:). ```; >>> def serialize_test(n):; ... t = [i for i in range(n)]; ... t1 = datetime.now(); ... print(len(t)); ... print(hl.eval(hl.len(hl.array(t)))); ... t2 = datetime.now(); ... print(t2 - t1); ... ; >>> serialize_test(40000000); 40000000; Exception in thread ""Thread-2"" java.lang.OutOfMemoryError: Java heap space; 	at java.util.Arrays.copyOf(Arrays.java:3332); 	at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:124); 	at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:649); 	at java.lang.StringBuilder.append(StringBuilder.java:202); 	at py4j.StringUtil.unescape(StringUtil.java:57); 	at py4j.Protocol.getString(Protocol.java:475); 	at py4j.Protocol.getObject(Protocol.java:302); 	at py4j.commands.AbstractCommand.getArguments(AbstractCommand.java:82); 	at py4j.commands.CallCommand.execute(CallCommand.java:77); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748); ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/Users/wang/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1035, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/Users/wang/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 883, in send_command; response = connection.send_command(command); File ""/Users/wang/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1040, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<stdin>"", line 5, in serialize_test; File ""<decorator-gen-466>"", line 2, in eval; File ""/Users/wang",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5407#issuecomment-474983184:1116,ERROR,ERROR,1116,https://hail.is,https://github.com/hail-is/hail/issues/5407#issuecomment-474983184,1,['ERROR'],['ERROR']
Availability,have Scala tests error if memory leak is detected,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4237:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/4237,1,['error'],['error']
Availability,"hb.Batch(backend=backend, name=batch_name) error when batch_name is not a string",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9050:43,error,error,43,https://hail.is,https://github.com/hail-is/hail/issues/9050,1,['error'],['error']
Availability,"hc.backend().executeJSON(self._to_java_ir(ir))); 109 value = ir.typ._from_json(result['value']); 110 timings = result['timings']. /usr/lib/spark/python/lib/py4j-src.zip/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /usr/local/lib/python3.6/site-packages/hail/utils/java.py in deco(*args, **kwargs); 223 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 224 'Hail version: %s\n'; --> 225 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 226 except pyspark.sql.utils.CapturedException as e:; 227 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NoSuchElementException: key not found: GRCh37. ```. ### Traces No. 1: . ```java ; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 16.0 failed 4 times, most recent failure: Lost task 15.3 in stage 16.0 (TID 178, ip-172-31-1-20.ec2.internal, executor 4): org.json4s.package$MappingException: unknown error; 	at org.json4s.Extraction$.extract(Extraction.scala:43); 	at org.json4s.ExtractableJsonAstNode.extract(ExtractableJsonAstNode.scala:21); 	at is.hail.io.index.IndexReader$.readMetadata(IndexReader.scala:65); 	at is.hail.io.index.IndexReader.<init>(IndexReader.scala:90); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.HailContext$$anon$3$$anonfun$20.apply(HailContext.scala:879); 	at is.hail.HailContext$$anon$3$$anonfun$20.apply(HailContext.scala:877); 	at scala.Option.map(Option.scala:146); 	at is.hail.HailContext$$anon$3.compute(HailContext.scala:877); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:5236,failure,failure,5236,https://hail.is,https://github.com/hail-is/hail/issues/7044,1,['failure'],['failure']
Availability,"he GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceb",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:8739,error,error,8739,https://hail.is,https://github.com/hail-is/hail/issues/9939,1,['error'],['error']
Availability,"he Hadoop Configuration object could be null, which suggests a serialization error in HadoopFS. However, there are many others tests that by touch HadoopFS serialization, and none of them have problems. If it's not a serialization error (say the URI object that hadoop looks for is null, or CACHE is null), it would not seem PR specific. 2) On local, with or without the google storage connector, I cannot replicate the error in cluster-read-vcfs.py. Attempts to replicate:; 1) Local hail install, not using google storage connector, and reading 2 local vcfs:. ```python; gvcfs = ['./HG00096.g.vcf.gz',; './HG00268.g.vcf.gz']; hl.init(default_reference='GRCh38'); parts = [; {'start': {'locus': {'contig': 'chr20', 'position': 17821257}},; 'end': {'locus': {'contig': 'chr20', 'position': 18708366}},; 'includeStart': True,; 'includeEnd': True},; {'start': {'locus': {'contig': 'chr20', 'position': 18708367}},; 'end': {'locus': {'contig': 'chr20', 'position': 19776611}},; 'includeStart': True,; 'includeEnd': True},; {'start': {'locus': {'contig': 'chr20', 'position': 19776612}},; 'end': {'locus': {'contig': 'chr20', 'position': 21144633}},; 'includeStart': True,; 'includeEnd': True},; ]; parts_str = json.dumps(parts); vcfs = hl.import_vcfs(gvcfs, parts_str). ## Works fine; print(vcfs); ```; 2) Docker install based on Dockerfile.hail-build (built on top of the hail base image). This does use the gcs connector, and some sa key that has access to the bucket I specified. ```python; gvcfs = ['gs://user-nrru16jaxrwmnzkv5f35xfibg/HG00096.g.vcf.gz',; 'gs://user-nrru16jaxrwmnzkv5f35xfibg/HG00268.g.vcf.gz']; # ...; ## Works fine; print(vcfs); ```. ### TODO:; Manually replicate on a Dataproc cluster. Currently working on this, have a Java gateway closed error during hl.init(), which could be caused by a misspecified JAVA_HOME. So at the moment, I either believe it's either a permission issue, or some Dataproc configuration issue. If you have suggestions, I'd love to hear them. cc @tpoterba",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6083#issuecomment-494037803:3741,error,error,3741,https://hail.is,https://github.com/hail-is/hail/pull/6083#issuecomment-494037803,1,['error'],['error']
Availability,"he following pieces of infrastructure:. - Fully scripted bootstrapping process, from creating a managed identity to run terraform through (instead of the current service principal), to creating a VM to run the bootstrap process off of, through all following steps until running bootstrap.py; - Adds the root CA certificate that azure uses to sign the MySQL server certificates so that we can connect to the database with `VERIFY_CA`. Unlike gcp, however, this still doesn't allow us to use mTLS since it doesn't look like we can request a client cert/key for our database. Still this is not so bad for now.; - Creates a separate k8s module for terraform. This currently just holds the global-config and sql-config resources, but establishes a boundary between the cloud-specific terraform and purely k8s terraform. Later on I'll refactor the GCP terraform to use the k8s module so that different clouds can use the same k8s configuration.; - Adds a pool of spot instances to the AKS cluster and adds the required toleration to all of our preemptible deployments. Part of the node selection process for a pod requires that exist a toleration on the pod for every taint on the node. In other words, it is ok for a pod to have redundant tolerations, so it's fine to have azure-specific tolerations even if we're running in gcp.; - Refactor the az-create-worker-image.sh script to complete the entire batch worker image creation process from start to finish. This involved sending a command over ssh that previously had to be executed by hand. This meant we could combine the two-script process into one shell script. This fully matches the google setup we have currently up until running `bootstrap.py`, which is still google-specific, mainly w.r.t. gcp service accounts. The next step is to adapt this to azure, but I think we need to come to a decision about exactly how we're representing application credentials (just service principals vs managed identities?). Once we have that figured out the res",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10919:1024,toler,toleration,1024,https://hail.is,https://github.com/hail-is/hail/pull/10919,1,['toler'],['toleration']
Availability,"he result of referencing a different copy on the system - or the [2.7.1 branch on GitHub](https://github.com/apache/hadoop/blob/branch-2.7.1/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java)), so I followed the parameterization. Still need to figure out why lines reported don't match, but I've seen line number differences before between that reported for the compiled binary, and the uncompiled source. Lines of evidence:; 1) The line specified in the ci log suggests that Hadoop's fileSystem.open() command fails. It appears from examining the line and source, that the Hadoop Configuration object could be null, which suggests a serialization error in HadoopFS. However, there are many others tests that by touch HadoopFS serialization, and none of them have problems. If it's not a serialization error (say the URI object that hadoop looks for is null, or CACHE is null), it would not seem PR specific. 2) On local, with or without the google storage connector, I cannot replicate the error in cluster-read-vcfs.py. Attempts to replicate:; 1) Local hail install, not using google storage connector, and reading 2 local vcfs:. ```python; gvcfs = ['./HG00096.g.vcf.gz',; './HG00268.g.vcf.gz']; hl.init(default_reference='GRCh38'); parts = [; {'start': {'locus': {'contig': 'chr20', 'position': 17821257}},; 'end': {'locus': {'contig': 'chr20', 'position': 18708366}},; 'includeStart': True,; 'includeEnd': True},; {'start': {'locus': {'contig': 'chr20', 'position': 18708367}},; 'end': {'locus': {'contig': 'chr20', 'position': 19776611}},; 'includeStart': True,; 'includeEnd': True},; {'start': {'locus': {'contig': 'chr20', 'position': 19776612}},; 'end': {'locus': {'contig': 'chr20', 'position': 21144633}},; 'includeStart': True,; 'includeEnd': True},; ]; parts_str = json.dumps(parts); vcfs = hl.import_vcfs(gvcfs, parts_str). ## Works fine; print(vcfs); ```; 2) Docker install based on Dockerfile.hail-build (built on top of the hail base image). This ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6083#issuecomment-494037803:2401,error,error,2401,https://hail.is,https://github.com/hail-is/hail/pull/6083#issuecomment-494037803,1,['error'],['error']
Availability,"he results of each benchmark are outputted as json lines (`.jsonl`) to the file specified by the `--output` pytest arg or stdout. The folder structure should be familiar, resembling our `test/` directory.; I believe this is flexible enough to add `hailtop` benchmarks should we so wish:; ```; pytest.ini - hoisted from `test/` to include benchmark marks; benchmark/; - conftest.py for custom pytest command line args ; - hail/; - confest.py for custom plugin that runs hail benchmarks; - benchmark_*.py hail query benchmark code; - tools/; - shared utilites, including the `@benchmark`; ```; Supporting pytest fixtures required writing a custom plugin to run benchmarks, as using off-the-shelf; solutions like `pytest-benchmark` would forbid method level fixtures like `tmp_path` etc.; The plugin is designed to run ""macro-benchmarks"" (ie long-running tests) and fully supports pytest parameterisation.; For each benchmark, the plugin initialises hail and then repeats (for a number of iterations defined by the pytest mark); acquiring fixtures, timing invocation and tearing-down fixtures, finally stopping hail. It is therefore unsuitable for; microbenchmarks, for which we currenly have none in python. If we add them we'd need to tweak this so support them.; Perhaps an inner loop or something. The process of submitting benchmarks to batch is greatly simplified as the old `Makefile` infrastructure for ; building wheels and docker images etc has been replaced with the script `benchmark_in_batch.py`.; Benchmark images are now based off the `hail-dev` image built in CI (or via the `hail-dev-image` make target). ; Furthermore, you can control the number of ""replicate"" jobs created for each benchmark at the benchmark level using; the `@benchmark(batch_jobs=N)` decotator. Limitations/shortcomings:; - Output is currently jsonl only. Some more human friendly output might be nice on a per iteration basis.; - Old `benchmark-hail` utilities are broken. I'll restore these in subsequent changes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14565:1831,down,down,1831,https://hail.is,https://github.com/hail-is/hail/pull/14565,1,['down'],['down']
Availability,he.spark.rdd.RDD.collect(RDD.scala:935); 	at is.hail.io.RichRDDRegionValue$.writeRowsSplit$extension(RowStore.scala:847); 	at is.hail.variant.MatrixTable.write(MatrixTable.scala:2712); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)is.hail.utils.HailException: found non-left aligned variant: 18:76051965:C:G; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.methods.SplitMultiPartitionContext.splitRow(SplitMulti.scala:98); 	at is.hail.methods.SplitMulti$$anonfun$split$1$$anonfun$apply$1.apply(SplitMulti.scala:226); 	at is.hail.methods.SplitMulti$$anonfun$split$1$$anonfun$apply$1.apply(SplitMulti.scala:225); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.hasNext(OrderedRVD.scala:733); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.hasNext(OrderedRVD.scala:733); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.sparkextras.OrderedJoinDistinctIterator.advanceRight1(OrderedJoinDistinctIterator.scala:36); 	at is.hail.sparkextras.OrderedJoinDistinctIterator.advanceRight(OrderedJoinDistinctIterator.scala:,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3040:9671,Error,ErrorHandling,9671,https://hail.is,https://github.com/hail-is/hail/issues/3040,1,['Error'],['ErrorHandling']
Availability,"heck.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). /home/hail/hail.zip/hail/matrixtable.py in from_rows_table(cls, table, partition_key); 3107 elif list(table.key)[:len(partition_key)] != partition_key:; 3108 raise ValueError('partition_key must be a prefix of table key'); -> 3109 jmt = scala_object(Env.hail().variant, 'MatrixTable').fromRowsTable(table._jt, partition_key); 3110 return MatrixTable(jmt); 3111 . /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: ArrayIndexOutOfBoundsException: 0. Java stack trace:; java.lang.ArrayIndexOutOfBoundsException: 0; 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:173); 	at org.apache.spark.sql.Row$class.apply(Row.scala:163); 	at org.apache.spark.sql.catalyst.expressions.GenericRow.apply(rows.scala:165); 	at is.hail.annotations.Annotation$$anonfun$isSafe$1.apply$mcZI$sp(Annotation.scala:70); 	at is.hail.annotations.Annotation$$anonfun$isSafe$1.apply(Annotation.scala:70); 	at is.hail.annotations.Annotation$$anonfun$isSafe$1.apply(Annotation.scala:70); 	at scala.collection.IndexedSeqOptimized$class.prefixLengthImpl(IndexedSeqOptimized.scala:38); 	at scala.collection.IndexedSeqOptimized$class.forall(IndexedSeqOptimized.scala:43); 	at scala.collection.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3668:1766,Error,Error,1766,https://hail.is,https://github.com/hail-is/hail/issues/3668,1,['Error'],['Error']
Availability,"hed sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0f43ce67de72bd511d849c07bd7728c0d6f2e6dd""><code>0f43ce6</code></a> Document path and relativePath properties</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a8504f9d60d0264808894e4bb80d4a73b8086a3e""><code>a8504f9</code></a> Bump up version number to 5.3.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/708067cd11c4a013da7a8c15d91f7f946967cf94""><code>708067c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0fdebf3c7ad43ed4739d0400c333a72b32f5d514""><code>0fdebf3</code></a> Improve verify example</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/019089b9554692674d6baee7df7d4d884f310cc9""><code>019089b</code></a> Correctly create list of output files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/fa2739ded05333ba46d8f50bb3b2a3721cf0ca86""><code>fa2739d</code></a> Create target directories at a central place</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/02b8e1a79d9e00acd61f9ac42e5555619fe2247a""><code>02b8e1a</code></a> Prevent duplicate destination files</li>; <li><a href=""http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:3406,down,download-task,3406,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['down'],['download-task']
Availability,hedulerBackend$YarnSchedulerEndpoint$$anonfun$org$apache$spark$scheduler$cluster$YarnSchedulerBackend$$handleExecutorDisconnectedFromDriver$2.apply(YarnSchedulerBackend.scala:252); at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:253); at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293); at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136); at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40); at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248); at scala.concurrent.Promise$class.complete(Promise.scala:55); at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153); at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326); at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293); at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136); at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40); at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248); at scala.concurrent.Promise$class.complete(Promise.scala:55); at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293); at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionCon,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:216037,recover,recover,216037,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['recover'],['recover']
Availability,hedulerBackend.scala:253); at org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint$$anonfun$org$apache$spark$scheduler$cluster$YarnSchedulerBackend$$handleExecutorDisconnectedFromDriver$2.apply(YarnSchedulerBackend.scala:252); at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:253); at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293); at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136); at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40); at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248); at scala.concurrent.Promise$class.complete(Promise.scala:55); at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153); at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326); at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293); at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136); at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40); at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248); at scala.concurrent.Promise$class.complete(Promise.scala:55); at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293); at ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:215966,recover,recover,215966,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['recover'],['recover']
Availability,"heh, cc: @daniel-goldstein I think we both hit the same transient error",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11943#issuecomment-1163390424:66,error,error,66,https://hail.is,https://github.com/hail-is/hail/pull/11943#issuecomment-1163390424,1,['error'],['error']
Availability,"heh, wow, the situation wrt kube-dns is pretty bad eh? https://github.com/kubernetes/kubernetes/issues/57659. My understanding is that the other kube-system pods tolerate every taint (by their special kube-system nature), so I think this argument only applies to kube-dns, is that your understanding?. We should stay alert to DNS issues, even with this change, because all our DNS queries will be routed to non-preemptible nodes (see: https://github.com/kubernetes/kubernetes/issues/57659#issuecomment-477009356).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7784#issuecomment-570278981:162,toler,tolerate,162,https://hail.is,https://github.com/hail-is/hail/pull/7784#issuecomment-570278981,1,['toler'],['tolerate']
Availability,"here are some example error msgs:; ```; In [2]: vds.linreg([]); ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-2-b8bbc41a5ebd> in <module>(); ----> 1 vds.linreg([]). /Users/tpoterba/hail/python/hail/dataset.py in linreg(self, y, covariates, root, min_ac, min_af); 2216 """"""; 2217; -> 2218 jvds = self._jvdf.linreg(y, jarray(env.jvm.java.lang.String, covariates), root, min_ac, min_af); 2219 return VariantDataset(self.hc, jvds); 2220. /Users/tpoterba/spark-2.0.2-bin-hadoop2.7/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /Users/tpoterba/spark-2.0.2-bin-hadoop2.7/python/pyspark/sql/utils.pyc in deco(*a, **kw); 61 def deco(*a, **kw):; 62 try:; ---> 63 return f(*a, **kw); 64 except py4j.protocol.Py4JJavaError as e:; 65 s = e.java_exception.toString(). /Users/tpoterba/hail/python/hail/java.py in deco(*a, **kw); 113 if e.args[0].startswith('An error occurred while calling'):; 114 msg = 'An error occurred while calling into JVM, probably due to invalid parameter types'; --> 115 raise FatalError('%s\n\nJava stack trace:\n%s\n\nERROR SUMMARY: %s' % (msg, e.message, msg)); 116; 117 return deco. FatalError: An error occurred while calling into JVM, probably due to invalid parameter types. Java stack trace:; An error occurred while calling o29.linreg. Trace:; py4j.Py4JException: Method linreg([class java.util.ArrayList, class [Ljava.lang.String;, class java.lang.String, class java.lang.Integer, class java.lang.Double]) does not exist; 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326); 	at py4j.Gateway.invoke(Gateway.java:272); 	at py4j.commands.AbstractCommand.invokeMe",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287190787:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287190787,1,['error'],['error']
Availability,"here is skipping going on. In both cases, we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {""name"":""BlockingBufferSpec"",""blockSize"":65536,""child"":; {""name"":""ZstdBlockBufferSpec"",""blockSize"":65536,""child"":; {""name"":""StreamBlockBufferSpec""}}}}; ```; Error for run 1.; ```; Caused by: com.github.luben.zstd.ZstdException: Corrupted block detected; 	at com.github.luben.zstd.ZstdDecompressCtx.decompressByteArray(ZstdDecompressCtx.java:157) ~[zstd-jni-1.5.2-1.jar:1.5.2-1]; 	at is.hail.io.ZstdInputBlo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:1413,error,error,1413,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623,1,['error'],['error']
Availability,"hink for Stanley Center stuff we; should use GCP auth. > I'm getting proxy timeouts. We need an ready endpoint and something on the; > client side to poll and redirect. Actually, awesome if it doesn't poll but; > uses, say, websockets, and the server watches the pod for a notification for; > k8s (or does this and also polls, which seems to be our standard pattern). The proxy timeouts might be because I shut the whole thing down? But yeah, I; also saw timeouts if a pod can't be scheduled right away. > Should we have an auto-scaling non-preemptible pool and schedule these there?. We already have such a pool, and these pods do not tolerate the preemptible; taint, so they are forced to get scheduled on non-preemptibles. > If we do that, to optimize startup time, we should have imagePullPolicy: Never; > and then pull the image on startup and push it on update. I think `imagePullPolicy: Never` is a bad idea. If there's a bug where the image; is not present, then we get stuck. I think we should rely on k8s to pull the 5GB; jupyter image in a reasonable time period. If we cannot rely on that, we just; start up N nodes before the tutorial, ssh to each and pull the image. If; somehow the image disappears, `imagePullPolicy: IfNotPresent` ensures we just; experience a delay rather than complete interruption. > When do you reap jupyter pods? jupyterhub has a simple management console that; > lets you shut down notebooks. I just run `make clean-jobs`, but we could add a delete endpoint and a little; web page. > I don't think you can do this dynamically using headers. Blueprints seem to be; > the answer in Flask:; > https://stackoverflow.com/questions/18967441/add-a-prefix-to-all-flask-routes/18969161#18969161. ah, cool. > Is there a reason you didn't make it a subdomain? I thought we decided we; > preferred that. I thought it would take less time to get a subdirectory working than figure out; how to add a new domain and a cert and deal with DNS. Long term a subdomain makes sense.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4576#issuecomment-431185878:2225,down,down,2225,https://hail.is,https://github.com/hail-is/hail/pull/4576#issuecomment-431185878,2,['down'],['down']
Availability,"his cluster for our larger dataset. ```; [Stage 10:=====> (69 + 656) / 729]; raise err; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 98, in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); File ""/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py"", line 1304, in __call__; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 31, in deco; raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.project-.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.gbsc-project.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12290:1796,failure,failure,1796,https://hail.is,https://github.com/hail-is/hail/issues/12290,1,['failure'],['failure']
Availability,"his pull request, linked above, I chose Starlette, and it is a thin abstraction, nearly identical performance, over Uvicorn + httptools, which were both written by Yury Selivanov, the asyncio person I mention above. Starlette and Uvicorn are currently the fastest options, (Sanic isn't tested), by a relatively large margin, on Techempower's benchmarks. If there is a reference standard benchmark of http library performance, Techempower is it: https://www.techempower.com/benchmarks/#section=data-r17 . Starlette is something like base Go performance (though 1/5-1/10th the performance of Go's fasthttp library for simple responses, and much closer for anything involving database calls). Sanic also uses httptools and uvloop, but has more stuff.. so yeah maybe a bit slower than Starlette, or not, but the diff will probably be small. Regarding the benchmark you linked, it is benchmarking the power of sleep. There is something deeply wrong with their results. Sanic has 1800 timeouts, vs 200 for aiohttp, and 3x the connection errors. Fine, so Sanic is super slow. But look at their non-db tests. Sanic is >2x as fast, 0 timeouts. They aren't using anything Sanic specific to query the database, and both use the same event loop. Adding asyncio Postgres to two programs that fundamentally differ mainly in how the handle http requests and responses, shows the one that is faster at http requests/responses (Sanic) becoming much slower, and in fact reversing its relationship to Aiohttp. This is strange to say the least. I was really curious about this, so I ran the bench. First, I upgraded Sanic to a recent version. Then I ran their test. In short, their results were not what I found. Sanic is 50% faster, and the timeouts are what you'd expect. 26 timeouts for Sanic, 45 for aiohttp. Sanic Run 1:; Running 1m test @ http://localhost:8000/db; 12 threads and 2000 connections; Thread Stats Avg Stdev Max +/- Stdev; Latency 640.64ms 947.31ms 7.97s 85.89%; Req/Sec 385.62 137.55 2.32k 77.21%; 274",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5242#issuecomment-461259030:3069,error,errors,3069,https://hail.is,https://github.com/hail-is/hail/pull/5242#issuecomment-461259030,2,['error'],['errors']
Availability,hl.cond same type error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3103:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/issues/3103,1,['error'],['error']
Availability,hl.eval(table.index_globals()) prints a bad error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4901:44,error,error,44,https://hail.is,https://github.com/hail-is/hail/issues/4901,1,['error'],['error']
Availability,"hl.hadoop_ls error when filename contains ""::"" (eg. ""CCDG::133.tsv.bgz"")",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9607:13,error,error,13,https://hail.is,https://github.com/hail-is/hail/issues/9607,1,['error'],['error']
Availability,hl.init fails with Spark error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12630:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/issues/12630,1,['error'],['error']
Availability,hl.init(sc=sc) retuns error since hail-0.2.92,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11827:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/issues/11827,1,['error'],['error']
Availability,hmm; ```; $ make publish-python-dill && make mirror-dockerhub-images; DOCKER_PREFIX=us-docker.pkg.dev/hail-vdc/hail bash python-dill/push.sh; + for version in 3.8 3.8-slim 3.9 3.9-slim 3.10 3.10-slim 3.11 3.11-slim; + public=hailgenetics/python-dill:3.8; + DOCKER_BUILDKIT=1; + docker build --build-arg PYTHON_VERSION=3.8 --file Dockerfile.out --build-arg BUILDKIT_INLINE_CACHE=1 --tag hailgenetics/python-dill:3.8 .; [+] Building 0.0s (2/2) FINISHED docker:desktop-linux; => [internal] load build definition from Dockerfile.out 0.0s; => => transferring dockerfile: 2B 0.0s; => [internal] load .dockerignore 0.0s; => => transferring context: 2B 0.0s; ERROR: failed to solve: failed to read dockerfile: open /var/lib/docker/tmp/buildkit-mount969738803/Dockerfile.out: no such file or directory; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13310#issuecomment-1652511856:651,ERROR,ERROR,651,https://hail.is,https://github.com/hail-is/hail/pull/13310#issuecomment-1652511856,1,['ERROR'],['ERROR']
Availability,"hodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748); Caused by: is.hail.utils.HailException: hybrid.m37m.vcf.bgz: caught htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 458249: unparsable vcf record with allele M; offending line: 3	60830534	.	M	C	40	.	.	GT:AD	1/1:0,40; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.utils.Context.wrapException(Context.scala:23); 	at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:742); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.hasNext(OrderedRVD.scala:733); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$11.apply(OrderedRVD.scala:491); 	at is.hail.rvd.OrderedRVD$$anonfun$11.apply(OrderedRVD.scala:490); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3015:5983,Error,ErrorHandling,5983,https://hail.is,https://github.com/hail-is/hail/issues/3015,1,['Error'],['ErrorHandling']
Availability,"hon3.6/socket.py"", line 586, in readinto; return self._sock.recv_into(b); File ""/usr/lib/python3.6/ssl.py"", line 1012, in recv_into; return self.read(nbytes, buffer); File ""/usr/lib/python3.6/ssl.py"", line 874, in read; return self._sslobj.read(len, buffer); File ""/usr/lib/python3.6/ssl.py"", line 631, in read; v = self._sslobj.read(len, buffer); socket.timeout: The read operation timed out. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/lib/python3/dist-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/usr/lib/python3/dist-packages/pip/commands/install.py"", line 342, in run; requirement_set.prepare_files(finder); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 821, in unpack_url; hashes=hashes; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 659, in unpack_http_url; hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 882, in _download_http_url; _download_url(resp, link, content_file, hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 603, in _download_url; hashes.check_against_chunks(downloaded_chunks); File ""/usr/lib/python3/dist-packages/pip/utils/hashes.py"", line 46, in check_against_chunks; for chunk in chunks:; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 571, in written_chunks; for chunk in chunks:; File ""/usr/lib/python3/dist-packages/pip/utils/ui.py"", line 139, in iter; for x in it:; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 560, in resp_read; decode_content=False):; File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 436, in stream; data = self.read(amt=amt, decode_con",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8390:1517,down,download,1517,https://hail.is,https://github.com/hail-is/hail/issues/8390,1,['down'],['download']
Availability,"hread.java:748); Caused by: java.lang.ClassNotFoundException: com.amazonaws.AmazonClientException; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:382); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:419); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:352); 	... 27 more. During handling of the above exception, another exception occurred:. Py4JJavaError Traceback (most recent call last); /bmrn/apps/hail/0.2.72-spark-3.1.2/python/hail-0.2.72-py3-none-any.egg/hail/backend/py4j_backend.py in deco(*args, **kwargs); 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:. /bmrn/apps/python/miniconda/64/3.7/envs/piranha_0.2.0_20210812/lib/python3.7/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 327 ""An error occurred while calling {0}{1}{2}.\n"".; --> 328 format(target_id, ""."", name), value); 329 else:. Py4JJavaError: An error occurred while calling z:is.hail.backend.spark.SparkBackend.apply.; : java.lang.IllegalArgumentException: requirement failed; 	at scala.Predef$.require(Predef.scala:268); 	at is.hail.backend.spark.SparkBackend$.apply(SparkBackend.scala:218); 	at is.hail.backend.spark.SparkBackend.apply(SparkBackend.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(T",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10590#issuecomment-899322610:3120,error,error,3120,https://hail.is,https://github.com/hail-is/hail/issues/10590#issuecomment-899322610,1,['error'],['error']
Availability,"ht = ht.join(ht2); ```; FatalError: NoSuchElementException: key not found: downsamplings_1. Java stack trace:; is.hail.utils.HailException: error trying to rebuild IR:; (TableJoin inner 5; (TableUnion; (TableRead ""gs://gnomad-resources/constraint/hail-0.2/weighted/prop_observed.ht"" False None); (TableRead ""gs://gnomad-resources/constraint/hail-0.2/weighted/prop_observed_x.ht"" False None); (TableRead ""gs://gnomad-resources/constraint/hail-0.2/weighted/prop_observed_y.ht"" False None)); (TableUnion; (TableRead ""gs://gnomad-resources/constraint/hail-0.2/standard/prop_observed.ht"" False None); (TableRead ""gs://gnomad-resources/constraint/hail-0.2/standard/prop_observed_x.ht"" False None); (TableRead ""gs://gnomad-resources/constraint/hail-0.2/standard/prop_observed_y.ht"" False None))); ```; Where downsampling is a global in each table",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4311:140,error,error,140,https://hail.is,https://github.com/hail-is/hail/issues/4311,2,"['down', 'error']","['downsampling', 'error']"
Availability,"html#polygenic-score-calculation), getting error with stacktrace:. `2022-05-14 12:09:07 Hail: INFO: Running Hail version 0.2.94-f0b38d6c436f; 2022-05-14 12:09:08 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.; 2022-05-14 12:09:08 root: INFO: RegionPool: initialized for thread 30: Thread-4; 2022-05-14 12:09:09 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 34.3 KiB, free 434.4 MiB); 2022-05-14 12:09:09 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 434.4 MiB); 2022-05-14 12:09:09 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on 10.40.3.21:33951 (size: 3.2 KiB, free: 434.4 MiB); 2022-05-14 12:09:09 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:311; 2022-05-14 12:09:11 root: INFO: RegionPool: FREE: 64.0K allocated (64.0K blocks / 0 chunks), regions.size = 1, 0 current java objects, thread 30: Thread-4; 2022-05-14 12:09:11 root: ERROR: HailException: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; From is.hail.utils.HailException: /data/public/prs/ex_antonk.bim:1013423: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; offending line: 11	.	0	135009883	CT	C; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:30); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:28); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.utils.Context.wrapException(Context.scala:21); 	at is.hail.utils.WithContext.foreach(Context.scala:51); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2(LoadPlink.scala:37); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2$adapted(LoadPlink.scala:36); 	at scala.collection.Iterator.foreach(Iterator.scala:941); 	at scala.collection.Iterator.foreach$(Iterator.scala:941); 	at scala.collection.AbstractIt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:1148,ERROR,ERROR,1148,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['ERROR'],['ERROR']
Availability,"http-session, google-auth, nest-asyncio, uvloop, humanize, hurry.filesize, decorator, requests, Deprecated, aiohttp, asyncinit, numpy, pyspark, sortedcontainers, boto3, pandas. -----------------------------------------------------------------------------. Importing hail via the IPython console in Spyder causes the following error:. Python 3.8.12 (default, Oct 12 2021, 06:23:56) ; IPython 8.2.0 -- An enhanced Interactive Python. In [1]: `import hail`. > [SpyderKernelApp] ERROR | Exception in message handler:; > Traceback (most recent call last):; > File ""/Users/jacobbayer/opt/anaconda3/lib/python3.8/site-packages/spyder_kernels/comms/frontendcomm.py"", line 164, in poll_one; > asyncio.run(handler(out_stream, ident, msg)); > File ""/Users/jacobbayer/opt/anaconda3/lib/python3.8/site-packages/nest_asyncio.py"", line 36, in run; > task = asyncio.ensure_future(main); > File ""/Users/jacobbayer/opt/anaconda3/lib/python3.8/asyncio/tasks.py"", line 684, in ensure_future; > raise TypeError('An asyncio.Future, a coroutine or an awaitable is '; > TypeError: An asyncio.Future, a coroutine or an awaitable is required; > [SpyderKernelApp] ERROR | Exception in message handler:; > Traceback (most recent call last):; > File ""/Users/jacobbayer/opt/anaconda3/lib/python3.8/site-packages/spyder_kernels/comms/frontendcomm.py"", line 164, in poll_one; > asyncio.run(handler(out_stream, ident, msg)); > File ""/Users/jacobbayer/opt/anaconda3/lib/python3.8/site-packages/nest_asyncio.py"", line 36, in run; > task = asyncio.ensure_future(main); > File ""/Users/jacobbayer/opt/anaconda3/lib/python3.8/asyncio/tasks.py"", line 684, in ensure_future; > raise TypeError('An asyncio.Future, a coroutine or an awaitable is '; > TypeError: An asyncio.Future, a coroutine or an awaitable is required. After importing hail, running any other command whatsoever (ex: print(""Hello World"")) triggers the same error. This does not occur in the python console running in my MacOS terminal, nor does it occur in Jupyter Notebook.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11758:1913,ERROR,ERROR,1913,https://hail.is,https://github.com/hail-is/hail/issues/11758,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,http://discuss.hail.is/t/sample-qc-error/556,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3900#issuecomment-403211589:35,error,error,35,https://hail.is,https://github.com/hail-is/hail/issues/3900#issuecomment-403211589,1,['error'],['error']
Availability,"https://discuss.hail.is/. These are the following commands I ran in a ipython shell:-; import hail as hl; mt = hl.balding_nichols_model(n_populations=3,; n_samples=10,; n_variants=100); mt.show(). I am using Hail 0.2.77. ; I am getting an error â€œPy4JJavaError: An error occurred while calling z:is.hail.backend.spark.SparkBackend.apply.â€ while running the second line. . Thanks!; -----------------------------------------------------------------------------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10903:239,error,error,239,https://hail.is,https://github.com/hail-is/hail/issues/10903,2,['error'],['error']
Availability,https://github.com/hail-is/hail/pull/6678 addresses this vulnerability in our notebook service. A long term fix is to upgrade to a version of k8s where this vulnerability is fixed. 1.13.7 is available and I believe it addresses this vulnerability. We should do this as well.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6679:191,avail,available,191,https://hail.is,https://github.com/hail-is/hail/issues/6679,1,['avail'],['available']
Availability,"https://github.com/jupyterlab/jupyterlab/commit/e7a1af706875c8ab183101ff68b38e836181028c""><code>e7a1af7</code></a> [ci skip] Publish 4.0.12</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/69079ec413cbe6d173f0a667c15802b76423ece5""><code>69079ec</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15710"">#15710</a>: Removes Python 3.0, Notebook 5 mentions from contributor ...</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/353707e4d0d3fe788a4a2a5b1f228352f1918806""><code>353707e</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15524"">#15524</a>: Fix visual tests (<a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15578"">#15578</a>)</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/482aaa0054a2de18a257d7b5520234eb44648a9f""><code>482aaa0</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15650"">#15650</a>: Fix jupyterlab downgrade issue on extension installation ...</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/58fb4a9b630cd22d7b064b3c8fef503b11afe077""><code>58fb4a9</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15690"">#15690</a>: Fix search highlights removal on clearing input box (<a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15712"">#15712</a>)</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/5062929f60ac770c7048350260636d3f63ea1c8d""><code>5062929</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15703"">#15703</a> on branch 4.0.x (Add scroll margin to headings for better ...</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/c00b0ca0cc631992c7681473d88208fcc74de00e""><code>c00b0ca</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15642"">#15642</a>: Fix outputarea package from not detecting updates ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14218:12452,down,downgrade,12452,https://hail.is,https://github.com/hail-is/hail/pull/14218,1,['down'],['downgrade']
Availability,https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/Error.20writing.20vcf,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4011#issuecomment-408512050:76,Error,Error,76,https://hail.is,https://github.com/hail-is/hail/issues/4011#issuecomment-408512050,1,['Error'],['Error']
Availability,https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/Error.20summary.3A.20ClassTooLargeException.3A.20Class.20too.20large/near/419319423,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14232#issuecomment-1922106113:80,Error,Error,80,https://hail.is,https://github.com/hail-is/hail/pull/14232#issuecomment-1922106113,1,['Error'],['Error']
Availability,https://hail.zulipchat.com/#narrow/stream/379853-Hail.2FVariants/topic/Echo.20VDS/near/396801065,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13823#issuecomment-1764943591:71,Echo,Echo,71,https://hail.is,https://github.com/hail-is/hail/issues/13823#issuecomment-1764943591,1,['Echo'],['Echo']
Availability,"https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **604/1000** <br/> **Why?** Has a fix available, CVSS 7.8 | Improper Privilege Management <br/>[SNYK-PYTHON-JUPYTERCORE-3063766](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERCORE-3063766) | `jupyter-core:` <br> `4.6.3 -> 4.11.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-MISTUNE-2940625](https://snyk.io/vuln/SNYK-PYTHON-MISTUNE-2940625) | `mistune:` <br> `0.8.4 -> 2.0.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **726/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 8.1 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-NBCONVERT-2979829](https://snyk.io/vuln/SNYK-PYTHON-NBCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **434/1000** <br/> **Why?** Has a fix available, CVSS 4.4 | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/up",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:3320,avail,available,3320,https://hail.is,https://github.com/hail-is/hail/pull/13717,2,['avail'],['available']
Availability,"https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-5750273) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **711/1000** <br/> **Why?** Mature exploit, Has a fix available, CVSS 6.5 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-SPHINX-570772](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-570772) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **701/1000** <br/> **Why?** Mature exploit, Has a fix available, CVSS 6.3 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-SPHINX-570773](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-570773) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **586/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.3 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5811865](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5811865) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![medium severity](https://res.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:6630,avail,available,6630,https://hail.is,https://github.com/hail-is/hail/pull/13717,3,['avail'],['available']
Availability,"hub.com/apache/commons-codec/blob/rel/commons-codec-1.15/RELEASE-NOTES.txt"">commons-codec's changelog</a>.</em></p>; <blockquote>; <pre><code> Apache Commons Codec 1.15 RELEASE NOTES; September 1 2020; </code></pre>; <p>The Apache Commons Codec package contains simple encoder and decoders for; various formats such as Base64 and Hexadecimal. In addition to these; widely used encoders and decoders, the codec package also maintains a; collection of phonetic encoding utilities.</p>; <p>Feature and fix release.</p>; <p>Changes in this version include:</p>; <p>New features:; o CODEC-290: Base16Codec and Base16Input/OutputStream. Thanks to Adam Retter.; o CODEC-291: Hex encode/decode with existing arrays. Thanks to Adam Retter.</p>; <p>Fixed Bugs:; o CODEC-264: MurmurHash3: Ensure hash128 maintains the sign extension bug.; Thanks to Andy Seaborne.</p>; <p>Changes:; o CODEC-280: Base32/Base64/BCodec: Added strict decoding property to control; handling of trailing bits. Default lenient mode discards them; without error. Strict mode raise an exception.; o CODEC-289: Base32/Base64 Input/OutputStream: Added strict decoding property; to control handling of trailing bits. Default lenient mode; discards them without error. Strict mode raise an exception.; o Update tests from JUnit 4.12 to 4.13. Thanks to Gary Gregory.; o Update actions/checkout from v1 to v2.3.2 <a href=""https://github-redirect.dependabot.com/apache/commons-codec/issues/50"">#50</a>, <a href=""https://github-redirect.dependabot.com/apache/commons-codec/issues/56"">#56</a>.; Thanks to Dependabot.; o Update actions/setup-java from v1.4.0 to v1.4.1 <a href=""https://github-redirect.dependabot.com/apache/commons-codec/issues/57"">#57</a>.; Thanks to Dependabot.</p>; <p>For complete information on Apache Commons Codec, including instructions on how; to submit bug reports, patches, or suggestions for improvement, see the; Apache Commons Codec website:</p>; <p><a href=""https://commons.apache.org/proper/commons-codec/"">https://",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12385:1184,error,error,1184,https://hail.is,https://github.com/hail-is/hail/pull/12385,1,['error'],['error']
Availability,"hub.com/python-pillow/Pillow/issues/7669"">#7669</a>, <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7672"">#7672</a>; [radarhere, nulano]</p>; </li>; <li>; <p>Deprecate IptcImagePlugin helpers <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7664"">#7664</a>; [nulano, hugovk, radarhere]</p>; </li>; <li>; <p>Allow uncompressed TIFF images to be saved in chunks <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7650"">#7650</a>; [radarhere]</p>; </li>; <li>; <p>Concatenate multiple JPEG EXIF markers <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7496"">#7496</a>; [radarhere]</p>; </li>; <li>; <p>Changed IPTC tile tuple to match other plugins <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7661"">#7661</a>; [radarhere]</p>; </li>; <li>; <p>Do not assign new fp attribute when exiting context manager <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7566"">#7566</a>; [radarhere]</p>; </li>; <li>; <p>Support arbitrary masks for uncompressed RGB DDS images <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7589"">#7589</a>; [radarhere, akx]</p>; </li>; <li>; <p>Support setting ROWSPERSTRIP tag <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7654"">#7654</a>; [radarhere]</p>; </li>; <li>; <p>Apply ImageFont.MAX_STRING_LENGTH to ImageFont.getmask() <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7662"">#7662</a>; [radarhere]</p>; </li>; <li>; <p>Optimise <code>ImageColor</code> using <code>functools.lru_cache</code> <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7657"">#7657</a>; [hugovk]</p>; </li>; <li>; <p>Restricted environment keys for ImageMath.eval() <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7655"">#7655</a>; [wiredfool, radarhere]</p>; </li>; <li>; <p>Optimise <code>ImageMode.getmode</code> using <code>functools.lru_cache</code> <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14191:11231,mask,masks,11231,https://hail.is,https://github.com/hail-is/hail/pull/14191,3,['mask'],['masks']
Availability,i think the better solution is to check that the ordered key inside the partitioner is the same as the implicit ordered key supplied. this also could have caught the errors,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1864#issuecomment-302978822:166,error,errors,166,https://hail.is,https://github.com/hail-is/hail/pull/1864#issuecomment-302978822,1,['error'],['errors']
Availability,"i><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1b5d69760d19cb7f88cbc837ee46456c494c0696""><code>1b5d697</code></a> Bump up version number to 5.2.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/7d6de83037ca41cd2f2f31830b43e43720e45b3a""><code>7d6de83</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1da8f078e22412475b694ce07b890148b8a5e4fc""><code>1da8f07</code></a> Add comment</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/9703f764df56c52626f7d6f44bca8b1d51312389""><code>9703f76</code></a> Use pooling connection manager instead of basic one</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/306172e4c6532e185c8a6a9998bca7d22d2d0c63""><code>306172e</code></a> Bump up version number to 5.2.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b9df0c0daa080450772c365f16a9406fe0ca607a""><code>b9df0c0</code></a> Document eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/05a4433770f7020ff845add9348bdc12c82793dd""><code>05a4433</code></a> Add eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/09d1eca91afbf21ace3672be24c68d9028ee1e33""><code>09d1eca</code></a> Document runAsync method</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/800e3df1647c5ce65bffdd25c3240dfa5244e6c5""><code>800e3df</code></a> Add runAsync method to download extension</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/80f04c6a46fe7df053ac55bcfc6f90ff74c4b873""><code>80f04c6</code></a> Bump up version number to 5.1.3</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/3.2.0...5.2.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badge",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:3936,down,download-task,3936,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['down'],['download-task']
Availability,"i><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86363072c8239330b28976109a622bdd073507b6""><code>8636307</code></a> Negative timeouts are actually not allowed</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4ff0ff0e63e0dd45f231990d0dcebffde6e6b709""><code>4ff0ff0</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a1858b494b5f3a51ccef7580c243c6dfdf520731""><code>a1858b4</code></a> Merge pull request <a href=""https://redirect.github.com/michel-kraemer/gradle-download-task/issues/295"">#295</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/c1e212c0fb41b3ea9185a9ea463fb1ea7142f748""><code>c1e212c</code></a> Add integration tests for Gradle 8.0 and 8.0.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/304f68e25f53633a92a4d2d6ce003a4986929503""><code>304f68e</code></a> Fix type inference issue</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.1...5.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.1&new-version=5.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:2505,down,download-task,2505,https://hail.is,https://github.com/hail-is/hail/pull/12893,1,['down'],['download-task']
Availability,"i><a href=""https://redirect.github.com/numpy/numpy/pull/23030"">#23030</a>: DOC: Add version added information for the strict parameter in...</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/23031"">#23031</a>: BUG: use <code>_Alignof</code> rather than <code>offsetof()</code> on most compilers</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/23147"">#23147</a>: BUG: Fix for npyv__trunc_s32_f32 (VXE)</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/23148"">#23148</a>: BUG: Fix integer / float scalar promotion</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/23149"">#23149</a>: BUG: Add missing &lt;type_traits&gt; header.</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/23150"">#23150</a>: TYP, MAINT: Add a missing explicit <code>Any</code> parameter to the <code>npt.ArrayLike</code>...</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/23161"">#23161</a>: BLD: remove redundant definition of npy_nextafter [wheel build]</li>; </ul>; <h2>Checksums</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/numpy/numpy/commit/85f38ab180ece5290f64e8ddbd9cf06ad8fa4a5e""><code>85f38ab</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/23159"">#23159</a> from charris/prepare-1.24.2-release</li>; <li><a href=""https://github.com/numpy/numpy/commit/124252537f526a059b6a5ee3ac1e3bf1442bbc13""><code>1242525</code></a> REL: Prepare for the NumPy 1.24.2 release</li>; <li><a href=""https://github.com/numpy/numpy/commit/de0ee415e45b09c86d1ddc04f51c11192b1e2fe6""><code>de0ee41</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/23161"">#23161</a> from mattip/npy_nextafter</li>; <li><a href=""https://github.com/numpy/numpy/commit/ed09037473581908f6b52ecc3cabc82a414e2a54""><code>ed09037</code></a> BLD: remove redundant definition of npy_nextafter [w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12898:3494,redundant,redundant,3494,https://hail.is,https://github.com/hail-is/hail/pull/12898,1,['redundant'],['redundant']
Availability,"i>Remove unnecessary parentheses from <code>except</code> statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2939"">#2939</a>)</li>; <li>Remove unnecessary parentheses from tuple unpacking in <code>for</code> loops (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2945"">#2945</a>)</li>; <li>Avoid magic-trailing-comma in single-element subscripts (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2942"">#2942</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Do not format <code>__pypackages__</code> directories by default (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2836"">#2836</a>)</li>; <li>Add support for specifying stable version with <code>--required-version</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2832"">#2832</a>).</li>; <li>Avoid crashing when the user has no homedir (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2814"">#2814</a>)</li>; <li>Avoid crashing when md5 is not available (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2905"">#2905</a>)</li>; <li>Fix handling of directory junctions on Windows (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2904"">#2904</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Update pylint config documentation (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2931"">#2931</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Move test to disable plugin in Vim/Neovim, which speeds up loading (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2896"">#2896</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>In verbose, mode, log when <em>Black</em> is using user-level config (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2861"">#2861</a>)</li>; </ul>; <h3>Packaging</h3>; <ul>; <li>Fix Black to work with Click 8.1.0 (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2966"">#2966</a>)</li>; <li>On Python 3.11 and newer, ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11696:1467,avail,available,1467,https://hail.is,https://github.com/hail-is/hail/pull/11696,2,['avail'],['available']
Availability,"ib/python3.6/concurrent/futures/thread.py"", line 56, in run; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/lib/python3.6/dist-packages/batch/blocking_to_async.py"", line 6, in <lambda>; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/apis/core_v1_api.py"", line 18538, in read_namespaced_pod_log; (data) = self.read_namespaced_pod_log_with_http_info(name, namespace, **kwargs); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/apis/core_v1_api.py"", line 18644, in read_namespaced_pod_log_with_http_info; collection_formats=collection_formats); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 334, in call_api; _return_http_data_only, collection_formats, _preload_content, _request_timeout); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 168, in __call_api; _request_timeout=_request_timeout); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 355, in request; headers=headers); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/rest.py"", line 231, in GET; query_params=query_params); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/rest.py"", line 222, in request; raise ApiException(http_resp=r); {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:39,924"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""mark_complete:591"", ""message"": ""no logs for batch-9-job-1-c8b9b2 due to previous error, rescheduling pod Error: (400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Audit-Id': '6a744afc-154f-4b48-b4bb-51a15078d999', 'Content-Type': 'application/json', 'Date': 'Thu, 11 Jul 2019 14:19:39 GMT', 'Content-Length': '179'})\nHTTP response body: {\""kind\"":\""Status\"",\""apiVersion\"":\""v1\"",\""metadata\"":{},\""status\"":\""Failure\"",\""message\"":\""container \\\""main\\\"" in pod \\\""batch-9-job-1-c8b9b2\\\"" is terminated\"",\""reason\"":\""BadRequest\"",\""code\"":400}\n\n""}; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6616:9482,error,error,9482,https://hail.is,https://github.com/hail-is/hail/issues/6616,3,"['Error', 'Failure', 'error']","['Error', 'Failure', 'error']"
Availability,"ib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceb",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:8091,error,error,8091,https://hail.is,https://github.com/hail-is/hail/issues/9939,1,['error'],['error']
Availability,"ib3.HTTPResponse.from_httplib</code> (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2648"">#2648</a>).</li>; <li>Removed default value of <code>None</code> for the <code>request_context</code> parameter of <code>urllib3.PoolManager.connection_from_pool_key</code>. This change should have no effect on users as the default value of <code>None</code> was an invalid option and was never used (<a href=""https://redirect.github.com/urllib3/urllib3/issues/1897"">#1897</a>).</li>; <li>Removed the <code>urllib3.request</code> module. <code>urllib3.request.RequestMethods</code> has been made a private API. This change was made to ensure that <code>from urllib3 import request</code> imported the top-level <code>request()</code> function instead of the <code>urllib3.request</code> module (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2269"">#2269</a>).</li>; <li>Removed support for SSLv3.0 from the <code>urllib3.contrib.pyopenssl</code> even when support is available from the compiled OpenSSL library (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2233"">#2233</a>).</li>; <li>Removed the deprecated <code>urllib3.contrib.ntlmpool</code> module (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2339"">#2339</a>).</li>; <li>Removed <code>DEFAULT_CIPHERS</code>, <code>HAS_SNI</code>, <code>USE_DEFAULT_SSLCONTEXT_CIPHERS</code>, from the private module <code>urllib3.util.ssl_</code> (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2168"">#2168</a>).</li>; <li>Removed <code>urllib3.exceptions.SNIMissingWarning</code> (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2168"">#2168</a>).</li>; <li>Removed the <code>_prepare_conn</code> method from <code>HTTPConnectionPool</code>. Previously this was only used to call <code>HTTPSConnection.set_cert()</code> by <code>HTTPSConnectionPool</code> (<a href=""https://redirect.github.com/urllib3/urllib3/issues/1985"">#1985</a>).</li>; <li>Removed <code>tls_in_tls_required</code> pro",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13768:6275,avail,available,6275,https://hail.is,https://github.com/hail-is/hail/pull/13768,3,['avail'],['available']
Availability,"ice] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdrive) c985d3e3de [query-service] remove old test code; - [ ] (@catoverdrive) 0a5dc8c651 [query-service] all operations are idempotent; - [ ] (@cseed) 6d02d173fa [make] fix config.mk; - [x] (@daniel-goldstein) d21df54e63 [devbin] teach devbin/functions.py about multiple containers; - [x] (@jigold) 38878f7874 [batch] remove batch_worker_image false dependency on service_base_image; - [x] (@daniel-goldstein) f03defab3d [java-services] avoid NPEs in isTransientError; - [x] (@jigold) e535bdc00d [dependencies] upgrade gcsfs to 0.7.2 to fix GoogleFS rmtree issue; - [x] (@cseed) 743b5ba62f [query-service] enable auto-scaling for PR and dev deploy; - [ ] (@cseed) 6a52d45f6f [query-service] retry EndOfStream errors from java; - [ ] (@jigold) 5853a0bec4 [batch] remove restrictions on PR and dev batch pools; - [ ] (@cseed) 035b19642a [query-service] resolve last two issues",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10100:4133,error,errors,4133,https://hail.is,https://github.com/hail-is/hail/pull/10100,1,['error'],['errors']
Availability,"icks/python/lib/python3.8/site-packages/hail/backend/spark_backend.py in persist_table(self, t, storage_level); 294 ; 295 def persist_table(self, t, storage_level):; --> 296 return Table._from_java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); 297 ; 298 def unpersist_table(self, t):. /databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py in __call__(self, *args); 1302 ; 1303 answer = self.gateway_client.send_command(command); -> 1304 return_value = get_return_value(; 1305 answer, self.gateway_client, self.target_id, self.name); 1306 . /databricks/spark/python/pyspark/sql/utils.py in deco(*a, **kw); 115 def deco(*a, **kw):; 116 try:; --> 117 return f(*a, **kw); 118 except py4j.protocol.Py4JJavaError as e:; 119 converted = convert_exception(e.java_exception). /databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 324 value = OUTPUT_CONVERTER[type](answer[2:], gateway_client); 325 if answer[1] == REFERENCE_TYPE:; --> 326 raise Py4JJavaError(; 327 ""An error occurred while calling {0}{1}{2}.\n"".; 328 format(target_id, ""."", name), value). Py4JJavaError: An error occurred while calling o504.pyPersistTable.; : is.hail.utils.HailException: 1 samples and 12 covariates (including x) implies -11 degrees of freedom.; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:11); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:11); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.methods.LinearRegressionRowsSingle.execute(LinearRegression.scala:51); 	at is.hail.expr.ir.functions.WrappedMatrixToTableFunction.execute(RelationalFunctions.scala:51); 	at is.hail.expr.ir.TableToTableApply.execute(TableIR.scala:2936); 	at is.hail.expr.ir.TableIR.analyzeAndExecute(TableIR.scala:57); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:27); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyPersistTable$2(SparkBackend.scala:502); 	at is.hail.back",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11413:3508,error,error,3508,https://hail.is,https://github.com/hail-is/hail/issues/11413,1,['error'],['error']
Availability,"icsearch-spark-20_2.12](https://github.com/elastic/elasticsearch-hadoop) from 7.17.1 to 8.4.3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/elastic/elasticsearch-hadoop/releases"">elasticsearch-spark-20_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.4.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html</a></p>; <h2>Elasticsearch Hadoop 8.4.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html</a></p>; <h2>Elasticsearch Hadoop 8.4.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12358:1000,Down,Downloads,1000,https://hail.is,https://github.com/hail-is/hail/pull/12358,1,['Down'],['Downloads']
Availability,"ide = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<8>; T = simdpp::arch_avx2::uint32<16>]â€™; libsimdpp-2.0-rc2/simdpp/types/int64.h:106:36: required from â€˜simdpp::arch_avx2::uint64<N>& simdpp::arch_avx2::uint64<N>::operator=(const simdpp::arch_avx2::any_vec<(N * 8), V>&) [with V = simdpp::arch_avx2::uint32<16, simdpp::arch_avx2::expr_empty>; unsigned int N = 8]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:590:8: required from â€˜void simdpp::arch_avx2::detail::insn::v_sse_transpose32x4(V&, V&, V&, V&) [with V = simdpp::arch_avx2::uint32<16>; D = simdpp::arch_avx2::uint64<8>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:533:62: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint64<8>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint64<8>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint32<16>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:38,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64.h:87:7: note: â€˜class simdpp::arch_avx2::uint64<8>â€™ declared here; class uint64<N, void> : public any_int64<N, uint64<N,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<16>; T = simdpp::arch_avx2::uint64<8>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:96792,error,error,96792,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"ient.py"", line 334, in call_api; _return_http_data_only, collection_formats, _preload_content, _request_timeout); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 168, in __call_api; _request_timeout=_request_timeout); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 355, in request; headers=headers); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/rest.py"", line 231, in GET; query_params=query_params); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/rest.py"", line 222, in request; raise ApiException(http_resp=r); {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:39,924"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""mark_complete:591"", ""message"": ""no logs for batch-9-job-1-c8b9b2 due to previous error, rescheduling pod Error: (400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Audit-Id': '6a744afc-154f-4b48-b4bb-51a15078d999', 'Content-Type': 'application/json', 'Date': 'Thu, 11 Jul 2019 14:19:39 GMT', 'Content-Length': '179'})\nHTTP response body: {\""kind\"":\""Status\"",\""apiVersion\"":\""v1\"",\""metadata\"":{},\""status\"":\""Failure\"",\""message\"":\""container \\\""main\\\"" in pod \\\""batch-9-job-1-c8b9b2\\\"" is terminated\"",\""reason\"":\""BadRequest\"",\""code\"":400}\n\n""}; ```. And finally, this k8s refresh loop sequence repeats until CI kills the tests due to a timeout. ```; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,070"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""refresh_k8s_state:1261"", ""message"": ""started k8s state refresh""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,085"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""refresh_k8s_pods:1210"", ""message"": ""k8s had 3 pods""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,088"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (11, 1, 'output') with pod batch-11-job-1-4f1118""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,090"", ""fil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6617:14173,error,error,14173,https://hail.is,https://github.com/hail-is/hail/issues/6617,3,"['Error', 'Failure', 'error']","['Error', 'Failure', 'error']"
Availability,"ient.send_command(command); -> 1304 return_value = get_return_value(; 1305 answer, self.gateway_client, self.target_id, self.name); 1306 . /databricks/spark/python/pyspark/sql/utils.py in deco(*a, **kw); 115 def deco(*a, **kw):; 116 try:; --> 117 return f(*a, **kw); 118 except py4j.protocol.Py4JJavaError as e:; 119 converted = convert_exception(e.java_exception). /databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 324 value = OUTPUT_CONVERTER[type](answer[2:], gateway_client); 325 if answer[1] == REFERENCE_TYPE:; --> 326 raise Py4JJavaError(; 327 ""An error occurred while calling {0}{1}{2}.\n"".; 328 format(target_id, ""."", name), value). Py4JJavaError: An error occurred while calling o504.pyPersistTable.; : is.hail.utils.HailException: 1 samples and 12 covariates (including x) implies -11 degrees of freedom.; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:11); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:11); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.methods.LinearRegressionRowsSingle.execute(LinearRegression.scala:51); 	at is.hail.expr.ir.functions.WrappedMatrixToTableFunction.execute(RelationalFunctions.scala:51); 	at is.hail.expr.ir.TableToTableApply.execute(TableIR.scala:2936); 	at is.hail.expr.ir.TableIR.analyzeAndExecute(TableIR.scala:57); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:27); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyPersistTable$2(SparkBackend.scala:502); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:46); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11413:3872,Error,ErrorHandling,3872,https://hail.is,https://github.com/hail-is/hail/issues/11413,1,['Error'],['ErrorHandling']
Availability,"if the code snippet that I wrote above works, I think we should either cache the results of `classAsBytes` and reuse them in `result`, or honestly just throw an error if you try to call `result` multiple times on the same function builder. (what would be the use case? If we want to use the same function multiple times we generally call `val f = fb.result()` once and use `f` as many times as necessary to get instances of the desired function.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7384#issuecomment-546392520:161,error,error,161,https://hail.is,https://github.com/hail-is/hail/issues/7384#issuecomment-546392520,1,['error'],['error']
Availability,"if the comparison returns missing for two non-missing values, we throw an error (and user-facing comparison functions are constructed to never hit this case). I accidentally did this in one of the test cases and the interpreter didn't have the same behavior so the tests were passing. I've fixed the Interpret behavior as well; this was caught in the tests for #5283.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5442:74,error,error,74,https://hail.is,https://github.com/hail-is/hail/pull/5442,1,['error'],['error']
Availability,"ight: 729 total samples; 2018-01-17 18:32:10 Hail: WARN: converting OrderedRVD => OrderedRDD; [Stage 0:====================================================>(4627 + 1) / 4628]2018-01-17 18:47:04 Hail: INFO: Coerced sorted dataset; 2018-01-17 18:47:04 Hail: WARN: converting OrderedRVD => OrderedRDD; [Stage 1:> (7 + 28) / 4969]Traceback (most recent call last):; File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/concordance.py"", line 38, in <module>; main(args); File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/concordance.py"", line 19, in main; bi_summary, bi_samples, bi_variants = methods.concordance(bi_past_vds, bi_future_vds); File ""<decorator-gen-1304>"", line 2, in concordance; File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/hail-devel-08a15431a0ef.zip/hail/utils/java.py"", line 155, in handle_py4j; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 30 in stage 1.0 failed 20 times, most recent failure: Lost task 30.19 in stage 1.0 (TID 4847, lfdev2-sw-f5w2.c.broad-mpg-gnomad.internal): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:1926,failure,failure,1926,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['failure'],['failure']
Availability,"ignal 1.3.1 requires frozenlist, which is not installed.; aiodocker 0.21.0 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxZjc1YjVmNi00MjFkLTQyN2YtYTk3OC0yNTBhNTgyNTI",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14035:1473,avail,available,1473,https://hail.is,https://github.com/hail-is/hail/pull/14035,1,['avail'],['available']
Availability,il.backend.service.ServiceBackend.$anonfun$parallelizeAndComputeWithIndex$3(ServiceBackend.scala:114); E 	at is.hail.backend.service.ServiceBackend.$anonfun$parallelizeAndComputeWithIndex$3$adapted(ServiceBackend.scala:114); E 	at is.hail.backend.service.ServiceBackend$$anon$2.$anonfun$call$1(ServiceBackend.scala:122); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.services.package$.retryTransientErrors(package.scala:124); E 	at is.hail.backend.service.ServiceBackend$$anon$2.call(ServiceBackend.scala:122); E 	at is.hail.backend.service.ServiceBackend$$anon$2.call(ServiceBackend.scala:119); E 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); E 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); E 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); E 	at java.lang.Thread.run(Thread.java:750); E ; E ; E ; E ; E Hail version: 0.2.115-f6017673dbb6; E Error summary: RuntimeException: Stream is already closed. /usr/local/lib/python3.8/dist-packages/hail/backend/service_backend.py:477: FatalError; ------------------------------ Captured log call -------------------------------; INFO batch_client.aioclient:aioclient.py:753 created batch 3776913; INFO batch_client.aioclient:aioclient.py:770 updated batch 3776913; INFO batch_client.aioclient:aioclient.py:770 updated batch 3776913; INFO batch_client.aioclient:aioclient.py:770 updated batch 3776913; INFO batch_client.aioclient:aioclient.py:770 updated batch 3776913; INFO batch_client.aioclient:aioclient.py:770 updated batch 3776913; INFO batch_client.aioclient:aioclient.py:770 updated batch 3776913; INFO batch_client.aioclient:aioclient.py:770 updated batch 3776913; INFO batch_client.aioclient:aioclient.py:770 updated batch 3776913; INFO backend.service_backend:java.py:190 krylov_factorization: Beginning iteration 1/4; INFO batch_client.aioclient:aioclient.py:770 updated batch 3776913; INFO backend.service_b,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12976:23239,Error,Error,23239,https://hail.is,https://github.com/hail-is/hail/issues/12976,1,['Error'],['Error']
Availability,"il.backend.service.ServiceBackend.$anonfun$parallelizeAndComputeWithIndex$3(ServiceBackend.scala:114); E 	at is.hail.backend.service.ServiceBackend.$anonfun$parallelizeAndComputeWithIndex$3$adapted(ServiceBackend.scala:114); E 	at is.hail.backend.service.ServiceBackend$$anon$2.$anonfun$call$1(ServiceBackend.scala:122); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.services.package$.retryTransientErrors(package.scala:124); E 	at is.hail.backend.service.ServiceBackend$$anon$2.call(ServiceBackend.scala:122); E 	at is.hail.backend.service.ServiceBackend$$anon$2.call(ServiceBackend.scala:119); E 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); E 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); E 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); E 	at java.lang.Thread.run(Thread.java:750); E ; E ; E ; E ; E Hail version: 0.2.115-f6017673dbb6; E Error summary: RuntimeException: Stream is already closed.; ```. ### Version. 0.2.115-f6017673dbb6. ### Relevant log output. ```shell; ________________________________ test_spectra_4 ________________________________; [gw2] linux -- Python 3.8.10 /usr/bin/python3. def test_spectra_4():; > spectra_helper(spec4). test/hail/methods/test_pca.py:229: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; test/hail/methods/test_pca.py:172: in spectra_helper; hail_V = (np.array(scores.scores.collect()) / singulars).T; <decorator-gen-538>:2: in collect; ???; /usr/local/lib/python3.8/dist-packages/hail/typecheck/check.py:584: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.8/dist-packages/hail/expr/expressions/base_expression.py:1132: in collect; return hl.eval(e); <decorator-gen-702>:2: in eval; ???; /usr/local/lib/python3.8/dist-packages/hail/typecheck/check.py:584: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.8/dist-pack",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12976:9621,Error,Error,9621,https://hail.is,https://github.com/hail-is/hail/issues/12976,1,['Error'],['Error']
Availability,il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748)org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.1-f69b497; Error summary: SparkException: Failed to get broadcast_4_piece0 of broadcast_4; >>> ; ```; @danking,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:8612,Error,Error,8612,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807,1,['Error'],['Error']
Availability,il.utils.package$.using(package.scala:587); 	at is.hail.annotations.Region$.scoped(Region.scala:20); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2.apply(Graph.scala:54); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2.apply(Graph.scala:53); 	at is.hail.utils.BinaryHeap.isLeftFavoredTie(BinaryHeap.scala:16); 	at is.hail.utils.BinaryHeap.is$hail$utils$BinaryHeap$$bubbleUp(BinaryHeap.scala:161); 	at is.hail.utils.BinaryHeap.insert(BinaryHeap.scala:40); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:91); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:90); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:90); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:76); 	at is.hail.utils.Graph.maximalIndependentSet(Graph.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2-29fbaeaf265e; Error summary: MatchError: cmg_exomes (of class java.lang.String); ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4857:5401,Error,Error,5401,https://hail.is,https://github.com/hail-is/hail/issues/4857,1,['Error'],['Error']
Availability,"il/utils/java.py in deco(*args, **kwargs); 225 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 226 'Hail version: %s\n'; --> 227 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 228 except pyspark.sql.utils.CapturedException as e:; 229 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: AssertionError: assertion failed: type mismatch:; name: global; actual: Struct{bn:Struct{n_populations:Int32,n_samples:Int32,n_variants:Int32,n_partitions:Int32,pop_dist:Array[Int32],fst:Array[Float64],mixture:Boolean},__uid_882:Array[Struct{sample_idx:Int32,pop:Int32,s:String}]}; expect: Struct{bn:Struct{n_populations:Int32,n_samples:Int32,n_variants:Int32,n_partitions:Int32,pop_dist:Array[Int32],fst:Array[Float64],mixture:Boolean},__cols:Array[Struct{sample_idx:Int32,pop:Int32,s:String}]}. Java stack trace:; is.hail.utils.HailException: Error while typechecking IR:; (MakeStruct; (bn; (GetField bn; (Ref global)))); 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.expr.ir.TypeCheck$.apply(TypeCheck.scala:16); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:45); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:32); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:77); 	at is.hail.expr.ir.TableMapGlobals$$anonfun$38.apply(TableIR.scala:856); 	at is.hail.expr.ir.TableMapGlobals$$anonfun$38.apply(TableIR.scala:846); 	at is.hail.utils.package$.using(package.scala:587); 	at is.hail.annotations.Region$.scoped(Region.scala:13); 	at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:846); 	at is.hail.expr.ir.TableKeyBy.execute(TableIR.scala:237); 	at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:696); 	at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:838); 	at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:696); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:42); 	at is.hail.table.Table.x$3$lzycompute(Table.scala:211); 	at is.hail.table.Table.x",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5212:3279,Error,ErrorHandling,3279,https://hail.is,https://github.com/hail-is/hail/issues/5212,1,['Error'],['ErrorHandling']
Availability,ilder$$anonfun$result$6.apply(Extraction.scala:514); at org.json4s.Extraction$ClassInstanceBuilder$$anonfun$result$6.apply(Extraction.scala:512); at org.json4s.Extraction$.org$json4s$Extraction$$customOrElse(Extraction.scala:524); at org.json4s.Extraction$ClassInstanceBuilder.result(Extraction.scala:512); at org.json4s.Extraction$.extract(Extraction.scala:351); at org.json4s.Extraction$.extract(Extraction.scala:42); at org.json4s.ExtractableJsonAstNode.extract(ExtractableJsonAstNode.scala:21); at org.json4s.jackson.Serialization$.read(Serialization.scala:50); at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1094); at is.hail.expr.ir.IRParser$.matrix_ir(Parser.scala:1030); at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$2.apply(Parser.scala:1246); at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$2.apply(Parser.scala:1246); at is.hail.expr.ir.IRParser$.parse(Parser.scala:1230); at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1246); at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1245); at is.hail.expr.ir.IRParser.parse_matrix_ir(Parser.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:282); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:745). Hail version: 0.2.12-9409c0635781; Error summary: MappingException: Parsed JSON values do not match with class constructor; args=; arg types=; constructor=public is.hail.variant.AbstractMatrixTableSpec(). ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5744:5911,Error,Error,5911,https://hail.is,https://github.com/hail-is/hail/issues/5744,1,['Error'],['Error']
Availability,"ile ""/tmp/59d4e99c253d424a9211eec0bdb4cd37/write_hardcall_mt.py"", line 20, in <module>; hl.export_bgen(mt, f'gs://ukbb-hail/ukb31063.dosage.hard_call.gwas_samples.chr{chrom}', gp=mt.GP, varid=mt.rsid); File ""</opt/conda/default/lib/python3.6/site-packages/decorator.py:decorator-gen-1226>"", line 2, in export_bgen; File ""/opt/conda/default/lib/python3.6/site-packages/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/conda/default/lib/python3.6/site-packages/hail/methods/impex.py"", line 235, in export_bgen; Env.hail().utils.ExportType.getExportType(parallel)))); File ""/opt/conda/default/lib/python3.6/site-packages/hail/backend/backend.py"", line 109, in execute; result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); File ""/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/opt/conda/default/lib/python3.6/site-packages/hail/utils/java.py"", line 225, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.RuntimeException: error while applying lowering 'InterpretNonCompilable'; at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:26); at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); at is.hail.expr.ir.CompileAndEvaluate$$anonfun$apply$1.apply(CompileAndEvaluate.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:14); at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:56); at is.hail.backend.Backend$$anonfun$exe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8161:1033,Error,Error,1033,https://hail.is,https://github.com/hail-is/hail/issues/8161,1,['Error'],['Error']
Availability,"ile ""<ipython-input-9-304965820738>"", line 1, in <module>; x.key_by('y').show(); File ""<decorator-gen-598>"", line 2, in show; File ""/Users/konradk/Dropbox/src/python/hail/typecheck/check.py"", line 486, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/Users/konradk/Dropbox/src/python/hail/table.py"", line 1101, in show; print(self._show(n,width, truncate, types)); File ""/Users/konradk/Dropbox/src/python/hail/table.py"", line 1104, in _show; return self._jt.showString(n, joption(truncate), types, width); File ""/Users/konradk/programs/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/konradk/Dropbox/src/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: AssertionError: assertion failed; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9.0 (TID 49, localhost, executor driver): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:926); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:908); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:349); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:433); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:433); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1$$anonfun$apply$34.apply(ContextRDD.scala:458); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1$$anonfun$apply$34.apply(ContextRDD.scala:458); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3516:1761,failure,failure,1761,https://hail.is,https://github.com/hail-is/hail/issues/3516,1,['failure'],['failure']
Availability,"ile ~/projects/hail/hail/python/hail/backend/backend.py:208, in Backend.persist(self, dataset); 206 from hail.context import TemporaryFilename; 207 tempfile = TemporaryFilename(prefix=f'persist_{type(dataset).__name__}'); --> 208 persisted = dataset.checkpoint(tempfile.__enter__()); 209 self._persisted_locations[persisted] = (tempfile, dataset); 210 return persisted. File <decorator-gen-1232>:2, in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). File ~/projects/hail/hail/python/hail/typecheck/check.py:587, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 584 @decorator; 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_). File ~/projects/hail/hail/python/hail/table.py:1331, in Table.checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1328 hl.current_backend().validate_file(output); 1330 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1331 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1332 _assert_type = self._type; 1333 _load_refs = False. File <decorator-gen-1234>:2, in write(self, output, overwrite, stage_locally, _codec_spec). File ~/projects/hail/hail/python/hail/typecheck/check.py:587, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 584 @decorator; 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_). File ~/projects/hail/hail/python/hail/table.py:1377, in Table.write(self, output, overwrite, stage_locally, _codec_spec); 1351 """"""Write to disk.; 1352 ; 1353 Examples; (...); 1372 If ``True``, overwrit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13788:3104,checkpoint,checkpoint,3104,https://hail.is,https://github.com/hail-is/hail/issues/13788,1,['checkpoint'],['checkpoint']
Availability,"ile</code> actions can also change the relative path of a target file and not only its name</li>; <li>Duplicate destination files are now prevented. Specifying a duplicate destination file (e.g. in an <code>eachFile</code> action) will lead to an exception being thrown.</li>; </ul>; <p>Bug fixes:</p>; <ul>; <li>Call <code>eachFile</code> action only once per source</li>; <li>Correctly create list of output files (even if the destination is the project's build directory)</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Use pooling connection manager of Apache HttpClient instead of basic one. The basic one is not meant to be used by multiple threads. This fixes an issue that could cause an <code>IllegalStateException</code> with the message <code>Connection is still allocated</code>. Thanks to <a href=""https://github.com/dmarks2""><code>@â€‹dmarks2</code></a> for spotting this.</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.0</h2>; <p>New features:</p>; <ul>; <li>Add <code>eachFile</code> method that adds an action to be applied to each source URL before it is downloaded. The action can be used to modify the filename of the target file.</li>; <li>Add <code>runAsync</code> method to download extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:1453,Mainten,Maintenance,1453,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['Mainten'],['Maintenance']
Availability,ileAndEvaluate.scala:47); at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:450); at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:486); at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:70); at is.hail.utils.package$.using(package.scala:635); at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:70); at is.hail.utils.package$.using(package.scala:635); at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:59); at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:339); at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$1(SparkBackend.scala:483); at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); at is.hail.backend.spark.SparkBackend.executeEncode(SparkBackend.scala:482); at jdk.internal.reflect.GeneratedMethodAccessor60.invoke(Unknown Source); at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.base/java.lang.reflect.Method.invoke(Method.java:566); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:282); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:238); at java.base/java.lang.Thread.run(Thread.java:829). Hail version: 0.2.105-acd89e80c345; Error summary: ClassCastException: class org.apache.spark.sql.catalyst.expressions.GenericRow cannot be cast to class is.hail.variant.Locus (org.apache.spark.sql.catalyst.expressions.GenericRow is in unnamed module of loader 'app'; is.hail.variant.Locus is in unnamed module of loader org.apache.spark.util.MutableURLClassLoader @62435e70); ```. ### Version. 0.2.105. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13046:5511,Error,Error,5511,https://hail.is,https://github.com/hail-is/hail/issues/13046,1,['Error'],['Error']
Availability,"iled: Connection reset by peer; E 	at ; E ; E ; E ; E Hail version: 0.2.115-330031a5d973; E Error summary: NativeIoException: readAddress(..) failed: Connection reset by peer; ```. I'm not sure why we lost the stack trace. ### Version. 330031a5d9734fd33a50e5651e7a2505f352b239. ### Relevant log output. ```shell; ________________________ test_pc_relate_against_R_truth ________________________; [gw2] linux -- Python 3.8.10 /usr/bin/python3. def test_pc_relate_against_R_truth():; mt = hl.import_vcf(resource('pc_relate_bn_input.vcf.bgz')); > hail_kin = hl.pc_relate(mt.GT, 0.00, k=2).checkpoint(utils.new_temp_file(extension='ht')). test/hail/methods/relatedness/test_pc_relate.py:9: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; <decorator-gen-1104>:2: in checkpoint; ???; /usr/local/lib/python3.8/dist-packages/hail/typecheck/check.py:584: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.8/dist-packages/hail/table.py:1347: in checkpoint; self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); <decorator-gen-1106>:2: in write; ???; /usr/local/lib/python3.8/dist-packages/hail/typecheck/check.py:584: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.8/dist-packages/hail/table.py:1393: in write; Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); /usr/local/lib/python3.8/dist-packages/hail/backend/service_backend.py:490: in execute; return self._cancel_on_ctrl_c(self._async_execute(ir, timed=timed)); /usr/local/lib/python3.8/dist-packages/hail/backend/service_backend.py:481: in _cancel_on_ctrl_c; return async_to_blocking(coro); /usr/local/lib/python3.8/dist-packages/hailtop/utils/utils.py:152: in async_to_blocking; return loop.run_until_complete(task); /usr/local/lib/python3.8/dist-packages/nest_asyncio.py:90: in run_until_complete; return f.result(); /usr/lib/python3.8/asynci",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12980:1265,checkpoint,checkpoint,1265,https://hail.is,https://github.com/hail-is/hail/issues/12980,1,['checkpoint'],['checkpoint']
Availability,"ils/process.py'; adding 'hailtop/utils/rate_limiter.py'; adding 'hailtop/utils/rates.py'; adding 'hailtop/utils/rich_progress_bar.py'; adding 'hailtop/utils/serialization.py'; adding 'hailtop/utils/time.py'; adding 'hailtop/utils/utils.py'; adding 'hailtop/utils/validate/__init__.py'; adding 'hailtop/utils/validate/validate.py'; adding 'hail-0.2.124.dist-info/METADATA'; adding 'hail-0.2.124.dist-info/WHEEL'; adding 'hail-0.2.124.dist-info/entry_points.txt'; adding 'hail-0.2.124.dist-info/top_level.txt'; adding 'hail-0.2.124.dist-info/RECORD'; emoving build/bdist.linux-x86_64/wheel; python3 -m pip install 'pip-tools==6.13.0' && bash ../check_pip_requirements.sh python; Defaulting to user installation because normal site-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB); â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, cli",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:29523,Down,Downloading,29523,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,1,['Down'],['Downloading']
Availability,"ils<0.20,>=0.14, but you have docutils 0.20.1.; sphinx-rtd-theme 1.3.0 has requirement docutils<0.19, but you have docutils 0.20.1.; notebook 6.5.6 has requirement pyzmq<25,>=17, but you have pyzmq 25.1.2. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:**",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14244:1483,avail,available,1483,https://hail.is,https://github.com/hail-is/hail/pull/14244,1,['avail'],['available']
Availability,"ils>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/ijl/orjson/releases"">orjson's releases</a>.</em></p>; <blockquote>; <h2>3.9.15</h2>; <h3>Fixed</h3>; <ul>; <li>Implement recursion limit of 1024 on <code>orjson.loads()</code>.</li>; <li>Use byte-exact read on <code>str</code> formatting SIMD path to avoid crash.</li>; </ul>; <h2>3.9.14</h2>; <h3>Fixed</h3>; <ul>; <li>Fix crash serializing <code>str</code> introduced in 3.9.11.</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Build now depends on Rust 1.72 or later.</li>; </ul>; <h2>3.9.13</h2>; <h3>Fixed</h3>; <ul>; <li>Serialization <code>str</code> escape uses only 128-bit SIMD.</li>; <li>Fix compatibility with CPython 3.13 alpha 3.</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Publish <code>musllinux_1_2</code> instead of <code>musllinux_1_1</code> wheels.</li>; <li>Serialization uses small integer optimization in CPython 3.12 or later.</li>; </ul>; <h2>3.9.12</h2>; <h3>Fixed</h3>; <ul>; <li>Minimal <code>musllinux_1_1</code> build due to sporadic CI failure.</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Update benchmarks in README.</li>; </ul>; <h2>3.9.11</h2>; <h3>Changed</h3>; <ul>; <li>Improve performance of serializing. <code>str</code> is significantly faster. Documents; using <code>dict</code>, <code>list</code>, and <code>tuple</code> are somewhat faster.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/ijl/orjson/blob/master/CHANGELOG.md"">orjson's changelog</a>.</em></p>; <blockquote>; <h2>3.9.15 - 2024-02-23</h2>; <h3>Fixed</h3>; <ul>; <li>Implement recursion limit of 1024 on <code>orjson.loads()</code>.</li>; <li>Use byte-exact read on <code>str</code> formatting SIMD path to avoid crash.</li>; </ul>; <h2>3.9.14 - 2024-02-14</h2>; <h3>Fixed</h3>; <ul>; <li>Fix crash serializing <code>str</code> introduced in 3.9.11.</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Build now depends on Rust 1.72 or later.</li>; </",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14357:1119,failure,failure,1119,https://hail.is,https://github.com/hail-is/hail/pull/14357,3,['failure'],['failure']
Availability,"imdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint64<4>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint64<4>]â€™; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:115:37: required from â€˜simdpp::arch_avx2::uint16<16>& simdpp::arch_avx2::uint16<16>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint64<4, simdpp::arch_avx2::expr_empty>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:488:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint16<16>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint16<16>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint64<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:22,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:92:7: note: â€˜class simdpp::arch_avx2::uint16<16>â€™ declared here; class uint16<16, void> : public any_int16<16, uint16<16,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::int8<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = si",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:54833,error,error,54833,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"imdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint8<32>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint8<32>]â€™; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:115:37: required from â€˜simdpp::arch_avx2::uint16<16>& simdpp::arch_avx2::uint16<16>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint8<32, simdpp::arch_avx2::expr_empty>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:404:25: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint16<16>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint16<16>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint8<32>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:22,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:92:7: note: â€˜class simdpp::arch_avx2::uint16<16>â€™ declared here; class uint16<16, void> : public any_int16<16, uint16<16,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint64<2>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:51148,error,error,51148,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"imeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; INFO	2022-03-02 19:06:38,141	resource_manager.py	create_vm:191	created machine batch-worker-pr-11438-default-g6cibyji6520-standard-4d9n8; ERROR	2022-03-02 19:06:39,183	job.py	schedule_job:473	error while scheduling job (98, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:20070,error,error,20070,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['error'],['error']
Availability,"imer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:79); 	at sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:83); 	at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:82); 	at sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:822); 	at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:79); 	at sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:794); 	at sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:199); 	at sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:544); 	at sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:509); 	at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.127-d2615543476b; Error summary: NoSuchElementException: Ref with name __iruid_1834 could not be resolved in env BindingEnv((__iruid_1832 -> struct{},__iruid_2157 -> struct{}),None,None,()); ```. ### Version. 0.2.127. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14245:21817,Error,Error,21817,https://hail.is,https://github.com/hail-is/hail/issues/14245,1,['Error'],['Error']
Availability,"imits; await _handle_api_error(_edit_billing_limit, db, billing_project, limit); File ""/usr/local/lib/python3.7/dist-packages/batch/front_end/front_end.py"", line 212, in _handle_api_error; await f(*args, **kwargs); File ""/usr/local/lib/python3.7/dist-packages/batch/front_end/front_end.py"", line 2227, in _edit_billing_limit; await insert() # pylint: disable=no-value-for-parameter; File ""/usr/local/lib/python3.7/dist-packages/gear/database.py"", line 34, in wrapper; return await f(*args, **kwargs); File ""/usr/local/lib/python3.7/dist-packages/gear/database.py"", line 64, in wrapper; return await fun(tx, *args, **kwargs); File ""/usr/local/lib/python3.7/dist-packages/batch/front_end/front_end.py"", line 2212, in insert; (billing_project,),; File ""/usr/local/lib/python3.7/dist-packages/gear/database.py"", line 209, in execute_and_fetchone; await cursor.execute(sql, args); File ""/usr/local/lib/python3.7/dist-packages/aiomysql/cursors.py"", line 239, in execute; await self._query(query); File ""/usr/local/lib/python3.7/dist-packages/aiomysql/cursors.py"", line 457, in _query; await conn.query(q); File ""/usr/local/lib/python3.7/dist-packages/aiomysql/connection.py"", line 469, in query; await self._read_query_result(unbuffered=unbuffered); File ""/usr/local/lib/python3.7/dist-packages/aiomysql/connection.py"", line 672, in _read_query_result; await result.read(); File ""/usr/local/lib/python3.7/dist-packages/aiomysql/connection.py"", line 1153, in read; first_packet = await self.connection._read_packet(); File ""/usr/local/lib/python3.7/dist-packages/aiomysql/connection.py"", line 641, in _read_packet; packet.raise_for_error(); File ""/usr/local/lib/python3.7/dist-packages/pymysql/protocol.py"", line 221, in raise_for_error; err.raise_mysql_exception(self._data); File ""/usr/local/lib/python3.7/dist-packages/pymysql/err.py"", line 143, in raise_mysql_exception; raise errorclass(errno, errval); pymysql.err.OperationalError: (1205, 'Lock wait timeout exceeded; try restarting transaction'); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12652#issuecomment-1416434586:2262,error,errorclass,2262,https://hail.is,https://github.com/hail-is/hail/pull/12652#issuecomment-1416434586,1,['error'],['errorclass']
Availability,import_gen default tolerance is 0.02 instead of 0.2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1481:19,toler,tolerance,19,https://hail.is,https://github.com/hail-is/hail/issues/1481,1,['toler'],['tolerance']
Availability,"import_matrix_table error on bad keys, also default to int col_ids",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3019:20,error,error,20,https://hail.is,https://github.com/hail-is/hail/pull/3019,1,['error'],['error']
Availability,import_table error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1818:13,error,error,13,https://hail.is,https://github.com/hail-is/hail/issues/1818,1,['error'],['error']
Availability,import_table gives bad error message if a column has a $,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5119:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/issues/5119,1,['error'],['error']
Availability,import_table on a directory has a bad error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2818:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/issues/2818,1,['error'],['error']
Availability,"import_vcf should tolerate files not named "".vcf"" with a warning",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5461:18,toler,tolerate,18,https://hail.is,https://github.com/hail-is/hail/issues/5461,1,['toler'],['tolerate']
Availability,improve error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/486:8,error,error,8,https://hail.is,https://github.com/hail-is/hail/issues/486,1,['error'],['error']
Availability,improve error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1490:8,error,error,8,https://hail.is,https://github.com/hail-is/hail/pull/1490,1,['error'],['error']
Availability,improve import vcf error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4289:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/4289,1,['error'],['error']
Availability,"in 14.135243 ms; 2018-10-09 15:04:38 CodeGenerator: INFO: Code generated in 8.306294 ms; 2018-10-09 15:04:38 Executor: INFO: Finished task 0.0 in stage 5.0 (TID 5). 1119 bytes result sent to driver; ```; </details>. <details>; <summary>Broken hail.log</summary>. ```; 2018-10-09 14:46:38 Hail: INFO: SparkUI: http://10.32.119.167:4040; 2018-10-09 14:46:38 Hail: INFO: Running Hail version devel-e7552fd55a9d; 2018-10-09 14:46:38 SharedState: INFO: loading hive config file: file:/Users/michafla/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml; 2018-10-09 14:46:38 SharedState: INFO: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/').; 2018-10-09 14:46:38 SharedState: INFO: Warehouse path is 'file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/'.; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@28f0ac7{/SQL,null,AVAILABLE,@Spark}; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@49a30f89{/SQL/json,null,AVAILABLE,@Spark}; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4495af6e{/SQL/execution,null,AVAILABLE,@Spark}; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6baf9f3b{/SQL/execution/json,null,AVAILABLE,@Spark}; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@562ad221{/static/sql,null,AVAILABLE,@Spark}; 2018-10-09 14:46:39 StateStoreCoordinatorRef: INFO: Registered StateStoreCoordinator endpoint; 2018-10-09 14:46:39 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 14:46:39 SparkSqlParser: INFO: Parsing command: SHOW TABLES; 2018-10-09 14:46:40 SparkContext: INFO: Starting job: collect at utils.scala:44; 2018-10-09 14:46:40 DAGScheduler: INFO: Got job 0 (collect at utils.scala:44) with 1 output partitions; 2018-10-09 14:4",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:31649,AVAIL,AVAILABLE,31649,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['AVAIL'],['AVAILABLE']
Availability,"in 7.2 seconds; > ...; > The 20 seconds is: clone from github.com, git-merge; > The 7.2 seconds is: download from GCS, untar; > Just ran the test in the cloud using the google cloud sdk image started by k run, 3.7 seconds; > The download is super fast, like a second; > the untar is about the same in both contexts, 1.2 seconds; > But the download drops from 4.7 to ~1.5. Chris pointed out I should skip going to disk and pipe into tar, I have not timed that yet. I was seeing fetch being more like 8 minutes to my repository. My repository is significantly larger than Alex's. I could delete some old branches to address this. ---. > for inputs/outputs, I wonder if we should have a flag that indicates it is an archive and do the archive/extract automatically (like you've done here but more generally), and stop using cp -r. I almost went down this route. It would save a couple lines of tar/untar in runImage steps. I felt the savings wasn't worth the effort of implementing it. In the buildImage case (what this PR addressed), I think it's worth it to keep images small. > for downstream steps that only need a small part of the repo, is it better to copy out different pieces (archived or no) rather than copy the whole thing and extra the parts you need?. I haven't investigated this. I agree, there exists an inflection point where the size of data overcomes GCS latency and GCS-throughput / tar-decompress is the bottleneck. There's something to be said for tar'ing everything except for `.git`, but I didn't carefully check which steps need it and which steps do not. ---. In conclusion, I'd say this PR is necessary for #7534, and #7534 is a big quality of life improvement for those of us with large repos running tests on images that are deep on the critical path (the shuffler test is behind 3 images and build hail, which also clones the repo, so for my repo I wait at least 2 minutes before I even have a chance to get feedback; with this PR and #7534 I should wait like 45 seconds?).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7626#issuecomment-560442927:1442,down,downstream,1442,https://hail.is,https://github.com/hail-is/hail/pull/7626#issuecomment-560442927,2,['down'],['downstream']
Availability,"in case you hit this issue. ```; ../conda/envs/glow/lib/python3.7/site-packages/bokeh/core/templates.py:43: in <module>; from jinja2 import Environment, Markup, FileSystemLoader; E ImportError: cannot import name 'Markup' from 'jinja2' (/home/circleci/conda/envs/lib/python3.7/site-packages/jinja2/__init__.py); [error] java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; [error] 	at scala.Predef$.require(Predef.scala:281); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14(build.sbt:288); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14$adapted(build.sbt:278); [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49); [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62); [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:67); [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:280); [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19); [error] 	at sbt.Execute.work(Execute.scala:289); [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:280); [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); [error] 	at java.lang.Thread.run(Thread.java:748); [error] (hail / hailtest) java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; ```. To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; ht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11705:1494,error,error,1494,https://hail.is,https://github.com/hail-is/hail/issues/11705,1,['error'],['error']
Availability,"in eval_expr_typed(expression); 3612 if len(expression._joins) > 0:; 3613 raise ExpressionException(""'eval_expr' methods do not support joins or broadcasts""); -> 3614 r, t = Env.hc().eval_expr_typed(expression._ast.to_hql()); 3615 return r, t; 3616. <decorator-gen-1049> in eval_expr_typed(self, expr). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/utils/java.py in handle_py4j(func, *args, **kwargs); 153 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 154 'Hail version: %s\n'; --> 155 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); 156 except py4j.protocol.Py4JError as e:; 157 if e.args[0].startswith('An error occurred while calling'):. FatalError: HailException: `(' expected but `i' found; <input>:1:(if (true) ""T"" else ""F"" + if (true) ""T"" else ""F""); ^. Java stack trace:; is.hail.utils.HailException: `(' expected but `i' found; <input>:1:(if (true) ""T"" else ""F"" + if (true) ""T"" else ""F""); ^; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:27); 	at is.hail.expr.ParserUtils$.error(Parser.scala:32); 	at is.hail.expr.RichParser.parse(Parser.scala:16); 	at is.hail.expr.Parser$.parseExpr(Parser.scala:85); 	at is.hail.HailContext.eval(HailContext.scala:613); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2653:2683,Error,ErrorHandling,2683,https://hail.is,https://github.com/hail-is/hail/issues/2653,1,['Error'],['ErrorHandling']
Availability,"in eval_timed; return Env.backend().execute(expression._ir, True); hail/backend/backend.py:109: in execute; result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); hail/backend/backend.py:105: in _to_java_ir; ir._jir = ir.parse(r(ir), ir_map=r.jirs); hail/ir/base_ir.py:244: in parse; ir_map); /miniconda3/lib/python3.7/site-packages/py4j/java_gateway.py:1257: in __call__; answer, self.gateway_client, self.target_id, self.name); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. args = ('xro1961', <py4j.java_gateway.GatewayClient object at 0x7ffa62e9e390>, 'z:is.hail.expr.ir.IRParser', 'parse_value_ir'), kwargs = {}; pyspark = <module 'pyspark' from '/miniconda3/lib/python3.7/site-packages/pyspark/__init__.py'>, s = 'java.lang.RuntimeException: typ: inference failure: \n(MakeArray Array[Int32])'; tpl = JavaObject id=o1962, deepest = 'NoSuchElementException: next on empty iterator'; full = 'java.lang.RuntimeException: typ: inference failure: \n(MakeArray Array[Int32])\n\tat is.hail.expr.ir.IR$class.typ(IR....a:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\n\n'. def deco(*args, **kwargs):; import pyspark; try:; return f(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; s = e.java_exception.toString(); ; # py4j catches NoSuchElementExceptions to stop array iteration; if s.startswith('java.util.NoSuchElementException'):; raise; ; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full = tpl._1(), tpl._2(); raise FatalError('%s\n\nJava stack trace:\n%s\n'; 'Hail version: %s\n'; > 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; E hail.utils.java.FatalError: NoSuchElementException: next on empty iterator; E ; E Java stack trace:; E java.lang.RuntimeException: typ: inference failure: ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7969#issuecomment-579035930:2646,failure,failure,2646,https://hail.is,https://github.com/hail-is/hail/pull/7969#issuecomment-579035930,1,['failure'],['failure']
Availability,"in stage 1.0 (TID 4, localhost): org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.sql.execution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:261); at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: org.apache.spark.sql.catalyst.expressions.GenericRow is not a valid external type for schema of boolean; named_struct(contig, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 0, contig), StringType), true), start, validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), Struc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1260:7294,Error,Error,7294,https://hail.is,https://github.com/hail-is/hail/issues/1260,1,['Error'],['Error']
Availability,"in; module(args); File ""/Users/cchen/anaconda/envs/hail-env/lib/python3.7/site-packages/hailctl/dataproc/cli.py"", line 99, in main; jmp[args.module].main(args, pass_through_args); File ""/Users/cchen/anaconda/envs/hail-env/lib/python3.7/site-packages/hailctl/dataproc/submit.py"", line 72, in main; check_call(cmd); File ""/Users/cchen/anaconda/envs/hail-env/lib/python3.7/subprocess.py"", line 347, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', 'ukbb_hdpca.py', '--cluster=chen', '--files=', '--py-files=/var/folders/6h/ll2dv8t15zs9pzf4g6kjb2rrt2fc9q/T/pyscripts_2740r0cj.zip', '--properties=']' returned non-zero exit status 1.; ```; The file does not exist but there are files with the same prefix but a `.000000001` suffix or similar. Grace reports (a possibly unrelated issue) https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/Cryptic.20array.20concordance.20error:; ```; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [873db5659acd43f7b539dcb17182959d] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""/miniconda3/bin/hailctl"", line 10, in <module>; sys.exit(main()); File ""/miniconda3/lib/python3.7/site-packages/hailctl/__main__.py"", line 90, in main; module(args); File ""/miniconda3/lib/python3.7/site-packages/hailctl/dataproc/cli.py"", line 99, in main; jmp[args.module].main(args, pass_through_args); File ""/miniconda3/lib/python3.7/site-packages/hailctl/dataproc/submit.py"", line 72, in main; check_call(cmd); File ""/miniconda3/lib/python3.7/subprocess.py"", line 341, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', '/Users/gtiao/ukbb_qc/scratch.py', '--cluster=gt1', '--files=', '--py-files=/var/folders/rn/t2xcx1ps4h96txll46qkkfsj2q8bnl/T/pyscripts_lh2k36v4.zip', '--properties=', '--', '--slack_channel', '@grace']' ret",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6565:1772,ERROR,ERROR,1772,https://hail.is,https://github.com/hail-is/hail/issues/6565,1,['ERROR'],['ERROR']
Availability,"ince 1.20+. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107527"">kubernetes/kubernetes#107527</a>, <a href=""https://github.com/wojtek-t""><code>@â€‹wojtek-t</code></a>)</li>; <li>Kubelet external Credential Provider feature is moved to Beta. Credential Provider Plugin and Credential Provider Config API's updated from v1alpha1 to v1beta1 with no API changes. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108847"">kubernetes/kubernetes#108847</a>, <a href=""https://github.com/adisky""><code>@â€‹adisky</code></a>)</li>; <li>Make STS available replicas optional again. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/109241"">kubernetes/kubernetes#109241</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@â€‹ravisantoshgudimetla</code></a>)</li>; <li>MaxUnavailable for StatefulSets, allows faster RollingUpdate by taking down more than 1 pod at a time. The number of pods you want to take down during a RollingUpdate is configurable using maxUnavailable parameter. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/82162"">kubernetes/kubernetes#82162</a>, <a href=""https://github.com/krmayankk""><code>@â€‹krmayankk</code></a>)</li>; <li>Non-graceful node shutdown handling is enabled for stateful workload failovers (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108486"">kubernetes/kubernetes#108486</a>, <a href=""https://github.com/sonasingh46""><code>@â€‹sonasingh46</code></a>)</li>; <li>Omit enum declarations from the static openapi file captured at <a href=""https://git.k8s.io/kubernetes/api/openapi-spec"">https://git.k8s.io/kubernetes/api/openapi-spec</a>. This file is used to generate API clients, and use of enums in those generated clients (rather than strings) can break forward compatibility with additional future values in those fields. See <a href=""https://issue.k8s.io/109177"">https://issue.k8s.io/109177</a> for details. (<a href=""https://gi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:9872,down,down,9872,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['down'],['down']
Availability,"ind(c => c.consequence_terms.contains(va.vep.most_severe_consequence)).impact == ""HIGH"")' \; annotatevariants expr -c 'va.andrea.damaging = (va.vep.transcript_consequences.find(c => c.canonical == 1).consequence_terms.contains(""missense_variant"") || (va.vep.transcript_consequences.find(c => c.canonical == 1).canonical.isMissing && va.vep.most_severe_consequence == ""missense_variant"") || ; va.vep.transcript_consequences.find(c => c.canonical == 1).consequence_terms.contains(""inframe_deletion"") || (va.vep.transcript_consequences.find(c => c.canonical == 1).canonical.isMissing && va.vep.most_severe_consequence == ""inframe_deletion"") ||; va.vep.transcript_consequences.find(c => c.canonical == 1).consequence_terms.contains(""inframe_insertion"") || (va.vep.transcript_consequences.find(c => c.canonical == 1).canonical.isMissing && va.vep.most_severe_consequence == ""inframe_insertion"")) ; && ""D"" ~ va.dbNSFP.Polyphen2_HDIV_pred && ""D"" ~ va.dbNSFP.Polyphen2_HVAR_pred && ""D"" ~ va.dbNSFP.SIFT_pred && ""D"" ~ va.dbNSFP.LRT_pred && ""[AD]"" ~ va.dbNSFP.MutationTaster_pred && ""[HM]"" ~ va.dbNSFP.MutationAssessor_pred && ""D"" ~ va.dbNSFP.PROVEAN_pred ' \; annotatevariants expr -c 'va.andrea.synonymous = va.vep.transcript_consequences.find(c => c.canonical == 1).consequence_terms.contains(""synonymous_variant"") || (va.vep.transcript_consequences.find(c => c.canonical == 1).canonical.isMissing && va.vep.most_severe_consequence == ""synonymous_variant"")' \; annotatevariants expr -c 'va.andrea.genename = if (va.vep.transcript_consequences.find(c => c.canonical == 1).canonical.isMissing) va.vep.transcript_consequences.find(c => c.consequence_terms.contains(va.vep.most_severe_consequence)).gene_symbol else va.vep.transcript_consequences.find(c => c.canonical == 1).gene_symbol' \; write -o /user/aganna/IBD_ANNOT.vep.qced.otherann.vds. error:. hail: write: caught exception: org.apache.spark.SparkException: Job aborted. [hail.log.txt](https://github.com/broadinstitute/hail/files/227035/hail.log.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/320:3271,error,error,3271,https://hail.is,https://github.com/hail-is/hail/issues/320,1,['error'],['error']
Availability,"ine 463): Copying log to logging bucket...; 2023-08-09 15:56:33.276 Hail: INFO: copying log to 'gs://gnomad-tmp/gnomad_v2.1.1_testing/constraint/logging/constraint_pipeline.log'...; Traceback (most recent call last):; File ""/tmp/17e6dae80e9548a9a94895fd07e6dee0/constraint_pipeline.py"", line 785, in <module>; main(args); File ""/tmp/17e6dae80e9548a9a94895fd07e6dee0/constraint_pipeline.py"", line 412, in main; oe_ht = apply_models(; File ""/tmp/17e6dae80e9548a9a94895fd07e6dee0/pyscripts_ge6ozu1m.zip/gnomad_constraint/utils/constraint.py"", line 396, in apply_models; File ""/tmp/17e6dae80e9548a9a94895fd07e6dee0/pyscripts_ge6ozu1m.zip/gnomad_constraint/utils/constraint.py"", line 279, in create_observed_and_possible_ht; File ""<decorator-gen-1118>"", line 2, in checkpoint; File ""/opt/conda/default/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/conda/default/lib/python3.10/site-packages/hail/table.py"", line 1331, in checkpoint; self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); File ""<decorator-gen-1120>"", line 2, in write; File ""/opt/conda/default/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/conda/default/lib/python3.10/site-packages/hail/table.py"", line 1377, in write; Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); File ""/opt/conda/default/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 82, in execute; raise e.maybe_user_error(ir) from None; File ""/opt/conda/default/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 76, in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); File ""/usr/lib/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py"", line 1321, in __call__; File ""/opt/conda/default/lib/python3.10/site-packages/hail/b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13486:1238,checkpoint,checkpoint,1238,https://hail.is,https://github.com/hail-is/hail/issues/13486,1,['checkpoint'],['checkpoint']
Availability,"ine 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/cseed/hail/python/hail/table.py"", line 1183, in write; self._jt.write(output, overwrite, stage_locally, _codec_spec); File ""/Users/cseed/py4j/java_gateway.py"", line 1133, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/cseed/hail/python/hail/utils/java.py"", line 200, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: OrderedRVD error! Unexpected key in partition 7; Range bounds for partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Key should be in partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Invalid key: [0.9986274705095608]. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 2.0 failed 1 times, most recent failure: Lost task 7.0 in stage 2.0 (TID 23, localhost, executor driver): is.hail.utils.HailException: OrderedRVD error! Unexpected key in partition 7; Range bounds for partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Key should be in partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Invalid key: [0.9986274705095608]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1011); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.io.RichContextRDDRegionValue$.writeRowsPartition(RowStore.scala:1071); 	at is.hail.io.RichContextRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:1096); 	at is.hail.io.RichContextRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:1096); 	at is.hail.utils.richUtils.RichCon",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4096:1403,error,error,1403,https://hail.is,https://github.com/hail-is/hail/issues/4096,1,['error'],['error']
Availability,"info ts=2019-07-31T15:45:52.004Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563883200000 maxt=1563948000000 ulid=01DGHKFKSD0THQ0VWGY9MM01GG; level=info ts=2019-07-31T15:45:52.004Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563948000000 maxt=1564012800000 ulid=01DGKH5AFC7KQ1CN0JE7AA3G6Y; level=info ts=2019-07-31T15:45:52.005Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1564012800000 maxt=1564077600000 ulid=01DGNEZMRJM9XKV1N0SA1Y9S3F; level=info ts=2019-07-31T15:45:52.005Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1564077600000 maxt=1564142400000 ulid=01DGQCQYYCJDT3DQTVTBHS7N6G; level=info ts=2019-07-31T15:45:52.006Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1564142400000 maxt=1564207200000 ulid=01DGSAYGB5QEMACHZK7ZE89H70; level=info ts=2019-07-31T15:45:52.006Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1564207200000 maxt=1564272000000 ulid=01DGV8AWDDHKPSN407Z08FBHVZ; level=info ts=2019-07-31T15:45:52.007Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1564272000000 maxt=1564336800000 ulid=01DGX64B6GVNNF4P09GB4YM3TV; level=info ts=2019-07-31T15:45:52.007Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1564401600000 maxt=1564408800000 ulid=01DGZ3XMWQ04MNAJTWJNXGHNZ5; level=info ts=2019-07-31T15:45:52.008Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1564336800000 maxt=1564401600000 ulid=01DGZ426ED23NR5759BDAQM0H6; level=info ts=2019-07-31T15:45:52.008Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1564408800000 maxt=1564416000000 ulid=01DGZASC8TRTFRM61J3MX4PHX4; level=info ts=2019-07-31T15:45:52.009Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1564416000000 maxt=1564423200000 ulid=01DGZHN38ENTPENE3MM35HVS42; level=info ts=2019-07-31T15:45:52.020Z caller=web.go:461 component=web msg=""router prefix"" prefix=/monitoring/prometheus; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6773:6479,repair,repair,6479,https://hail.is,https://github.com/hail-is/hail/issues/6773,5,['repair'],['repair']
Availability,"ing too small a starting maxPartition size and openCost size. I'm uncertain how to change these parameters even after extensive googling. Any Ideas? Thank you!. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/scratch/PI/dpwall/computeEnvironments/hail/python/hail/context.py"", line 64, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); File ""/share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o18.apply.; : is.hail.utils.package$FatalException: Found problems with SparkContext configuration:; Invalid config parameter 'spark.sql.files.openCostInBytes=': too small. Found 0, require at least 50G; Invalid config parameter 'spark.sql.files.maxPartitionBytes=': too small. Found 0, require at least 50G; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:5); 	at is.hail.utils.package$.fatal(package.scala:20); 	at is.hail.HailContext$.checkSparkConfiguration(HailContext.scala:104); 	at is.hail.HailContext$.apply(HailContext.scala:162); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1507#issuecomment-285792978:1167,Error,ErrorHandling,1167,https://hail.is,https://github.com/hail-is/hail/pull/1507#issuecomment-285792978,2,['Error'],['ErrorHandling']
Availability,"ing:; ```; def generate_downsamplings_cumulative(mt: hl.MatrixTable) -> Tuple[hl.MatrixTable, List[int]]:; pop_data = [x[0] for x in get_sample_data(mt, [mt.meta.pop])]; pops = Counter(pop_data); downsamplings = DOWNSAMPLINGS + list(pops.values()); downsamplings = sorted([x for x in downsamplings if x <= sum(pops.values())]); kt = mt.cols(); kt = kt.annotate(r=hl.rand_unif(0, 1)); kt = kt.order_by(kt.r).add_index('global_idx'). for i, pop in enumerate(pops):; pop_kt = kt.filter(kt.meta.pop == pop).add_index('pop_idx'); if not i:; global_kt = pop_kt; else:; global_kt = global_kt.union(pop_kt). return mt.annotate_cols(downsampling=global_kt[mt.s]), downsamplings. ```; Getting this. Guessing it's something with the ordering?; ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-8-0255aa65130d> in <module>(); 48 ; 49 if calculate_downsampling:; ---> 50 mt, downsamplings = generate_downsamplings_cumulative(mt); 51 print(f'Got {len(downsamplings)} downsamplings: {downsamplings}'); 52 cut_dict = {'pop': hl.agg.counter(hl.agg.filter(hl.is_defined(mt.meta.pop), mt.meta.pop)),. <ipython-input-8-0255aa65130d> in generate_downsamplings_cumulative(mt); 18 global_kt = pop_kt; 19 else:; ---> 20 global_kt = global_kt.union(pop_kt); 21 ; 22 return mt.annotate_cols(downsampling=global_kt[mt.s]), downsamplings. /home/hail/hail.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). /home/hail/hail.zip/hail/table.py in union(self, *tables); 1718 f"" Expected: {self.row.dtype}\n""; 1719 f"" Table {i}: {ht.row.dtype}""); -> 1720 elif list(ht.key) != list(self.key):; 1721 raise TypeError(f""'union': table {i} has a different key.""; 1722 f"" Expected: {list(self.key)}\n"". TypeError: 'NoneType' object is not iterable; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4080:1361,down,downsampling,1361,https://hail.is,https://github.com/hail-is/hail/issues/4080,2,['down'],"['downsampling', 'downsamplings']"
Availability,"init__</code> attribute) is very large.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5679"">PyCQA/pylint#5679</a></p>; </li>; <li>; <p>Inlcude names of keyword-only arguments in <code>astroid.scoped_nodes.Lambda.argnames</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5771"">PyCQA/pylint#5771</a></p>; </li>; <li>; <p>Fixed a crash inferring on a <code>NewType</code> named with an f-string.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5770"">PyCQA/pylint#5770</a></p>; </li>; <li>; <p>Add support for <a href=""https://github.com/python-attrs/attrs/releases/tag/21.3.0"">attrs v21.3.0</a> which; added a new <code>attrs</code> module alongside the existing <code>attr</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1330"">#1330</a></p>; </li>; <li>; <p>Use the <code>end_lineno</code> attribute for the <code>NodeNG.tolineno</code> property; when it is available.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1350"">#1350</a></p>; </li>; <li>; <p>Add <code>is_dataclass</code> attribute to <code>ClassDef</code> nodes.</p>; </li>; <li>; <p>Use <code>sysconfig</code> instead of <code>distutils</code> to determine the location of; python stdlib files and packages.</p>; <p>Related pull requests: <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1322"">#1322</a>, <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1323"">#1323</a>, <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1324"">#1324</a>; Closes <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1282"">#1282</a>; Ref <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1103"">#1103</a></p>; </li>; <li>; <p>Fixed crash with recursion error for inference of class attributes that referenced; the class itself.</p>; <p>Closes <a href=""https://github-redi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11463:2028,avail,available,2028,https://hail.is,https://github.com/hail-is/hail/pull/11463,2,['avail'],['available']
Availability,"ins.com/pages/viewpage.action?pageId=74845225#HowTo...-SetUpTeamCitybehindaProxyServer):. ``` apache; <IfModule mod_ssl.c>; <VirtualHost *:443>; # The ServerName directive sets the request scheme, hostname and port that; # the server uses to identify itself. This is used when creating; # redirection URLs. In the context of virtual hosts, the ServerName; # specifies what hostname must appear in the request's Host: header to; # match this virtual host. For the default virtual host (this file) this; # value is not decisive as it is used as a last resort host regardless.; # However, you must set it for any further virtual host explicitly.; ServerName hail.is; ServerAlias www.hail.is. ServerAdmin webmaster@localhost; DocumentRoot /var/www/html. RedirectMatch 404 /\.git. # Available loglevels: trace8, ..., trace1, debug, info, notice, warn,; # error, crit, alert, emerg.; # It is also possible to configure the loglevel for particular; # modules, e.g.; #LogLevel info ssl:warn. ErrorLog ${APACHE_LOG_DIR}/error.log; CustomLog ${APACHE_LOG_DIR}/access.log combined. # For most configuration files from conf-available/, which are; # enabled or disabled at a global level, it is possible to; # include a line for only one particular virtual host. For example the; # following line enables the CGI configuration for this host only; # after it has been globally disabled with ""a2disconf"".; #Include conf-available/serve-cgi-bin.conf; SSLCertificateFile /etc/letsencrypt/live/hail.is/fullchain.pem; SSLCertificateKeyFile /etc/letsencrypt/live/hail.is/privkey.pem; Include /etc/letsencrypt/options-ssl-apache.conf; </VirtualHost>. <VirtualHost *:443>; ServerName ci.hail.is; ServerAdmin webmaster@localhost. LoadModule proxy_module /usr/lib/apache2/modules/mod_proxy.so; LoadModule proxy_http_module /usr/lib/apache2/modules/mod_proxy_http.so; LoadModule headers_module /usr/lib/apache2/modules/mod_headers.so; LoadModule proxy_wstunnel_module /usr/lib/apache2/modules/mod_proxy_wstunnel.so. ProxyRequ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/674#issuecomment-243899170:1452,Error,ErrorLog,1452,https://hail.is,https://github.com/hail-is/hail/issues/674#issuecomment-243899170,2,"['Error', 'error']","['ErrorLog', 'error']"
Availability,"instead we get:; ```; Python 3.7.5 (default, Nov 1 2019, 02:16:32) ; Type 'copyright', 'credits' or 'license' for more information; IPython 7.5.0 -- An enhanced Interactive Python. Type '?' for help. In [1]: %%time ; ...: import os ; ...: import sys ; ...: ; ...: from hailtop import pipeline as pl ; ...: ; ...: BENCHMARK_IMAGE = 'ubuntu:18.04' ; ...: p = pl.Pipeline(name='download_data_fail', ; ...: backend=pl.BatchBackend(billing_project='hail'), ; ...: default_image=BENCHMARK_IMAGE, ; ...: default_cpu=1) ; ...: ; ...: for i in range(1): ; ...: t = p.new_task(f'replicate_{i}') ; ...: t.command('echo ' + 'a' * 1000) ; ...: p.run(wait=False) ; aenter; aexit; submit jobs timing {'create': 264, 'total': 265}; Traceback (most recent call last):; File ""<timed exec>"", line 15, in <module>; File ""/Users/dking/projects/hail/hail/python/hailtop/pipeline/pipeline.py"", line 395, in run; self._backend._run(self, dry_run, verbose, delete_scratch_on_exit, **backend_kwargs); File ""/Users/dking/projects/hail/hail/python/hailtop/pipeline/backend.py"", line 329, in _run; batch = batch.submit(); File ""/Users/dking/projects/hail/hail/python/hailtop/batch_client/client.py"", line 164, in submit; async_batch = async_to_blocking(self._async_builder.submit()); File ""/Users/dking/projects/hail/hail/python/hailtop/batch_client/client.py"", line 7, in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); File ""/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py"", line 579, in run_until_complete; return future.result(); File ""/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/futures.py"", line 178, in result; raise self._exception; File ""/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/Users/dking/projects/hail/hail/python/hailtop/batch_client/aioclient.py"", line 500, ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7839:603,echo,echo,603,https://hail.is,https://github.com/hail-is/hail/issues/7839,1,['echo'],['echo']
Availability,"int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::float32<4>; T = simdpp::arch_avx2::float64<2>]â€™; libsimdpp-2.0-rc2/simdpp/types/float32x4.h:59:37: required from â€˜simdpp::arch_avx2::float32<4>& simdpp::arch_avx2::float32<4>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::float64<2, simdpp::arch_avx2::expr_empty>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:598:8: required from â€˜void simdpp::arch_avx2::detail::insn::v_sse_transpose32x4(V&, V&, V&, V&) [with V = simdpp::arch_avx2::float32<4>; D = simdpp::arch_avx2::float64<2>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:549:63: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::float32<4>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::float32<4>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::float64<2>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:29,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/float32x4.h:32:7: note: â€˜class simdpp::arch_avx2::float32<4>â€™ declared here; class float32<4, void> : public any_float32<4, float32<4,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int16<8>; T = simdpp::arch_avx2::uint16<8>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:103023,error,error,103023,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4>]â€™; libsimdpp-2.0-rc2/simdpp/types/float64x2.h:58:37: required from â€˜simdpp::arch_avx2::float64<2>& simdpp::arch_avx2::float64<2>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::float32<4, simdpp::arch_avx2::expr_empty>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:590:8: required from â€˜void simdpp::arch_avx2::detail::insn::v_sse_transpose32x4(V&, V&, V&, V&) [with V = simdpp::arch_avx2::float32<4>; D = simdpp::arch_avx2::float64<2>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:549:63: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::float64<2>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::float64<2>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::float32<4>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:32,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/float64x2.h:32:7: note: â€˜class simdpp::arch_avx2::float64<2>â€™ declared here; class float64<2, void> : public any_float64<2, float64<2,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::float32<4>; T = simdpp::arch_avx2::float64<2>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:100944,error,error,100944,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,int typecheck on hl.literal() errors out with None,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3690:30,error,errors,30,https://hail.is,https://github.com/hail-is/hail/issues/3690,1,['error'],['errors']
Availability,"int8<32>; T = simdpp::arch_avx2::int16<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int16<16>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int16<16>]â€™; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:110:36: required from â€˜simdpp::arch_avx2::uint8<32>::uint8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int16<16>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/shuffle_bytes16.h:91:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::uint8<32>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::uint8<32>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::int16<16>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:91:7: note: â€˜class simdpp::arch_avx2::uint8<32>â€™ declared here; class uint8<32, void> : public any_int8<32, uint8<32,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint32<8>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:21605,error,error,21605,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"int8<32>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int16<16>; T = simdpp::arch_avx2::uint8<32>; unsigned int MaskCastOverride = 0]â€™; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from â€˜R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int16<16>; T = simdpp::arch_avx2::uint8<32>]â€™; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:56:36: required from â€˜simdpp::arch_avx2::int16<16>& simdpp::arch_avx2::int16<16>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint8<32>]â€™; libsimdpp-2.0-rc2/simdpp/detail/insn/shuffle_bytes16.h:85:11: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: â€˜void* memcpy(void*, const void*, size_t)â€™ copying an object of type â€˜class simdpp::arch_avx2::int16<16>â€™ with â€˜privateâ€™ member â€˜simdpp::arch_avx2::int16<16>::d_â€™ from an array of â€˜const class simdpp::arch_avx2::uint8<32>â€™; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:22,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:33:7: note: â€˜class simdpp::arch_avx2::int16<16>â€™ declared here; class int16<16, void> : public any_int16<16, int16<16,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of â€˜R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int16<16>]â€™:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from â€˜static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:19828,error,error,19828,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,introduced dummy failure to test.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4448#issuecomment-424758306:17,failure,failure,17,https://hail.is,https://github.com/hail-is/hail/pull/4448#issuecomment-424758306,1,['failure'],['failure']
Availability,"io-libs/aiohttp_session/issues/398"">#398</a>)</li>; </ul>; <h1>2.8.0 (2019-09-17)</h1>; <ul>; <li>Make this compatible with Python 3.7+. Import from collections.abc, instead; of from collections. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/373"">#373</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/af0560812d3dc2043565de1108ac41b65caac7d0""><code>af05608</code></a> Release 2.11 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/673"">#673</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/16aa24292125aa59fed1ab4292c6576d800295f1""><code>16aa242</code></a> Bump pytest-mock from 3.6.1 to 3.7.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/674"">#674</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/72d199d40689cb0a83f2b911044ab0ed9f6cc08e""><code>72d199d</code></a> Fix error in example</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/44e60f51bdb1ecfc22fa8bc87e8d025f2f17cd90""><code>44e60f5</code></a> Minor changes to typing. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/672"">#672</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/bf9a5f0b87470dd145cff326b0b05f898f775d94""><code>bf9a5f0</code></a> Fix session resetting before expiry. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/671"">#671</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/36b8a0a5ed2caaaba9d5d3ece8aaf03ca45b6c34""><code>36b8a0a</code></a> Allow passing Fernet to Encrypted Cookie Storage (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/448"">#448</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/984decc496fe92e053c14949c8d3a60bacd62426""><code>984decc</code></a> Test on ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11544:2358,error,error,2358,https://hail.is,https://github.com/hail-is/hail/pull/11544,1,['error'],['error']
Availability,"io-libs/aiomysql/issues/540"">#540</a>)</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/0fc109d16c939a7dd06ef2abf078632f7b336c39""><code>0fc109d</code></a> Fill changelog for 0.0.21 release (<a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/538"">#538</a>)</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/d842ec3f95614a2042a9107d7b65edfcf661d614""><code>d842ec3</code></a> Fix tests to pass under Python 3.7 and 3.8</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/e4cba8f07c95b5f655b01cacc3103626db9eba11""><code>e4cba8f</code></a> Support python 3.7 and 3.8 in tests and travis CI</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/f9b86aa08576c677afe16caf41aa2ab685b0f995""><code>f9b86aa</code></a> Update dependencies (<a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/485"">#485</a>)</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/e3c1bb808d0af308e21d2488be75a40dfd054b78""><code>e3c1bb8</code></a> chore(flake8): fixed flake8 errors (<a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/484"">#484</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiomysql/compare/v0.0.20...v0.0.22"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiomysql&package-manager=pip&previous-version=0.0.20&new-version=0.0.22)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11543:5971,error,errors,5971,https://hail.is,https://github.com/hail-is/hail/pull/11543,1,['error'],['errors']
